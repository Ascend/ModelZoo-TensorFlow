Author: Tao Wu (taowu1@huawei.com), Salli Moustafa (salli.moustafa@huawei.com)


# Graph Convolutional Network

This repository contains the training (in Tensorflow 1.15) and inference (in pyACL) of graph convolution network (GCN). 

## References
Our training code is a re-implementation of the [GCN paper](https://arxiv.org/abs/1609.02907). 

The original implementations by the author are available at:
- Kipf, T. N. (2017). *GitHub - tkips/gcn: Implementation of Graph Convolutional Networks in TensorFlow*. <https://github.com/tkipf/gcn>
- Kipf, T. N. (2017). *GitHub - tkips/keras-gcn: Keras implementation of Graph Convolutional Networks*. <https://github.com/tkipf/keras-gcn>

Our data preprocessing procedure closely follows:
- Shchur, O. (2018). *GitHub - shchur/gnn-benchmark: Framework for evaluating Graph Neural Network models on semi-supervised node classification task*. <https://github.com/shchur/gnn-benchmark>


## Usage

### Prepare datasets

- Download Cora and Cora-full datasets (in \{cora, cora_full\}.npz) from: <https://github.com/shchur/gnn-benchmark/tree/master/data/npz>

- Move the npz files to the subdirectory `./data/`
```
├── data
│   ├── cora.npz
│   ├── cora_full.npz
```

### Prepare environment

- On CPU or GPU:

  Create [conda](https://docs.conda.io/en/latest/miniconda.html) environment:
  ```
  conda create -n env_gcn python=3.7.9
  conda activate env_gcn
  ```
  
  Install required dependencies (on CPU):
  ```
  conda install 'tensorflow=1.15' scipy matplotlib
  ```
  
  Install required dependencies (on GPU):
  ```
  conda install 'tensorflow-gpu=1.15' scipy matplotlib
  ```
  
  Alternatively, you can use the *pyenv* as Python version management and *venv* to create virtual environments.
  ```
  pyenv local 3.7.9
  python -m venv env_gcn
  python -m pip install -U pip
  python -m pip install -r requirements.txt
  source env_gcn/bin/activate
  ```
   
- On NPU:

  Install [Python 3.7.5](https://www.python.org/downloads/release/python-375/), [Tensorflow 1.15](https://www.tensorflow.org/install), [Ascend CANN 3.3](https://www.hiascend.com/software/cann/community), and [Ascend Tensorflow Adaptor](https://www.hiascend.com/software/ai-frameworks/community). See [installation guide](https://support.huaweicloud.com/intl/en-us/instg-cli-cann330/atlasrun_03_0002.html).
  
  Install additional dependencies via pip:
  ```
  python3.7.5 -m pip install scipy==1.6.2 matplotlib==3.3.4
  ```
  
- The code is tested on Ubuntu 18.04 with x86_64 or aarch64 architecture. Adaptation may be required under a different OS. 

  
### Run training

- Train on Cora with GPU:
```
bash scripts/train_cora_gpu.sh
```

- Train on Cora with CPU:
```
bash scripts/train_cora_cpu.sh
```

- Train on Cora with NPU:
```
bash scripts/train_cora_npu.sh
```

- Train on Cora-full with GPU:
```
bash scripts/train_corafull_gpu.sh
```

- Train on Cora-full with CPU:
```
bash scripts/train_corafull_cpu.sh
```

- Train on Cora-full with NPU:
```
bash scripts/train_corafull_npu.sh
```

### Results on training

- Final test accuracy on Cora: 0.8150 ![](./images/training-metrics-cora.png)

- Final test accuracy on Cora-full: 0.6095 ![](./images/training-metrics-corafull.png)



### Run inference
Running inference requires first generating the offline model from the model obtained after training

- Obtaining original trained model file and input data files

The input dataset is generated during the training phase. At the end of the training, an archive (`data/inference_files-DATASET.tar.gz` where `DATASET` is either `cora` or `corafull`) containing the model file, the *features* and *adjacency* matrices, *labels* and *mask* is generated. The user then needs to transfer that archive from the training platform to the inference platform, in the same directory (`data/`). The archive will be automatically decompressed during offline model generation. One should note that input data files generated after two training jobs are not identical. This is due a randomness within Cora dataset. Hence, it is mandatory to use the data files and model file generated by the same training job. Otherwise, the inference accuracy will not be similar to that of the training.

- Generating offline model (Cora)
```
bash scripts/generate_om_cora.sh
```

- Generating offline model (Cora-full)
```
bash scripts/generate_om_corafull.sh
```

- Executing inference (Cora)
```
bash scripts/run_inference_cora.sh
```

- Executing inference (Cora-full)
```
bash scripts/run_inference_corafull.sh
```

**Accuracy and performance of the inference using 1 Ascend 310**

|                    | Cora     | Corafull  |
| ------------- |:-------------:| -----:    |
| Elapsed Time (s)   | 0.552548 | 1.111138  |
| Accuracy (\%)      | 81.5     |   60.0    |
