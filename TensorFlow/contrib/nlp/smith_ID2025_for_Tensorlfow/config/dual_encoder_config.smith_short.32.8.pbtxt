# Definition of the experimental settings.
# proto-file: smith/experiment_config.proto
# proto-message: DualEncoderConfig

encoder_config {
  model_name: "smith_dual_encoder"
  init_checkpoint: "/home/test_user06/tc_workspace/data/bert/uncased_L-12_H-768_A-12/bert_model.ckpt"
  bert_config_file: "/home/test_user06/tc_workspace/tmp/smith_force_fp32/config/bert_config.json"
  doc_bert_config_file: "/home/test_user06/tc_workspace/tmp/smith_force_fp32/config/doc_bert_3l_768h_config.json"
  vocab_file: "/home/test_user06/tc_workspace/data/bert/uncased_L-12_H-768_A-12/vocab.txt"
  max_seq_length: 32
  max_predictions_per_seq: 5
  max_sent_length_by_word: 32
  max_doc_length_by_sentence: 64
  loop_sent_number_per_doc: 8
  sent_bert_trainable: true
  max_masked_sent_per_doc: 0
  use_masked_sentence_lm_loss: false
  num_labels: 2
  doc_rep_combine_mode: "normal"
  doc_rep_combine_attention_size: 256
}
train_eval_config {
  input_file_for_train: "/home/test_user06/tc_workspace/data/output_file/tianchen_0311.tfrecord"
  input_file_for_eval: "/home/test_user06/tc_workspace/data/output_file/tianchen_0311.tfrecord"
  train_batch_size: 32
  eval_batch_size: 32
  predict_batch_size: 32
  max_eval_steps: 54
  save_checkpoints_steps: 10
  iterations_per_loop: 10
  eval_with_eval_data: true
  neg_to_pos_example_ratio: 1.0
}
loss_config {
  similarity_score_amplifier: 6.0
}
