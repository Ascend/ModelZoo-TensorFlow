nohup: ignoring input
WARNING:tensorflow:From /usr/local/Ascend/tfplugin/latest/python/site-packages/npu_bridge/estimator/npu/npu_optimizer.py:128: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: tensorflow_datasets==3.0.0 in /home/test_user01/.local/lib/python3.7/site-packages (3.0.0)
Requirement already satisfied: termcolor in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (1.1.0)
Requirement already satisfied: absl-py in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (0.10.0)
Requirement already satisfied: numpy in /home/test_user01/.local/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (1.18.0)
Requirement already satisfied: dill in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (0.3.4)
Requirement already satisfied: six in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (1.15.0)
Requirement already satisfied: wrapt in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (1.12.1)
Requirement already satisfied: attrs>=18.1.0 in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (20.2.0)
Requirement already satisfied: promise in /home/test_user01/.local/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (2.3)
Requirement already satisfied: tqdm in /usr/local/python3.7.5/lib/python3.7/site-packages/tqdm-4.62.3-py3.7.egg (from tensorflow_datasets==3.0.0) (4.62.3)
Requirement already satisfied: future in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (0.18.2)
Requirement already satisfied: requests>=2.19.0 in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (2.25.0)
Requirement already satisfied: tensorflow-metadata in /home/test_user01/.local/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (1.9.0)
Requirement already satisfied: protobuf>=3.6.1 in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow_datasets==3.0.0) (3.13.0)
Requirement already satisfied: setuptools in /usr/local/python3.7.5/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow_datasets==3.0.0) (59.0.1)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python3.7.5/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets==3.0.0) (2020.6.20)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/python3.7.5/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets==3.0.0) (3.0.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/python3.7.5/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets==3.0.0) (1.26.2)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/python3.7.5/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets==3.0.0) (2.10)
Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/python3.7.5/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow_datasets==3.0.0) (1.53.0)
WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.
You should consider upgrading via the '/usr/local/python3.7.5/bin/python3.7 -m pip install --upgrade pip' command.
WARNING:tensorflow:From train_slot.py:67: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

W0818 20:17:51.557755 140034352527168 module_wrapper.py:139] From train_slot.py:67: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

I0818 20:17:51.559530 140034352527168 dataset_info.py:361] Load dataset info from /home/test_user01/slot-attention/data/clevr/3.1.0
I0818 20:17:51.563001 140034352527168 dataset_builder.py:283] Reusing dataset clevr (/home/test_user01/slot-attention/data/clevr/3.1.0)
I0818 20:17:51.563147 140034352527168 dataset_builder.py:479] Constructing tf.data.Dataset for split train, from /home/test_user01/slot-attention/data/clevr/3.1.0
WARNING:tensorflow:From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0818 20:17:51.573142 140034352527168 deprecation.py:323] From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2022-08-18 20:17:51.923376: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:/usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/driver:/usr/local/python3.7.5/lib:/usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:/usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/driver:/usr/local/python3.7.5/lib:/usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:/usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/driver:/usr/local/python3.7.5/lib:/usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:/usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/driver:/usr/local/python3.7.5/lib:
2022-08-18 20:17:51.923408: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2022-08-18 20:17:51.923424: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist
W0818 20:17:52.441161 140034352527168 tf_compat.py:84] Deprecation warning: `tf.data.Dataset.make_one_shot_iterator` is deprecated. It will be removed after April 10, 2020. Please use `tf.compat.v1.data.make_one_shot_iterator(ds)` instead.
__________image________
(64, 128, 128, 3)
WARNING:tensorflow:From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0818 20:17:52.484007 140034352527168 deprecation.py:506] From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
----------x------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x1------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x2------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x3------- <class 'tensorflow.python.framework.ops.Tensor'>
_________xshape___________
(64, 16384, 64)
______________slotattentioninputs_____________
Tensor("slot_attention_auto_encoder/slot_attention/layer_normalization_1/batchnorm/add_1:0", shape=(64, 16384, 64), dtype=float32)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
-----------slot-------- <class 'tensorflow.python.framework.ops.Tensor'>
WARNING:tensorflow:From train_slot.py:80: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0818 20:17:53.934642 140034352527168 module_wrapper.py:139] From train_slot.py:80: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

----------x------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x1------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x2------- <class 'tensorflow.python.framework.ops.Tensor'>
----------x3------- <class 'tensorflow.python.framework.ops.Tensor'>
_________xshape___________
(64, 16384, 64)
______________slotattentioninputs_____________
Tensor("model/slot_attention_auto_encoder/slot_attention/layer_normalization_1/batchnorm/add_1:0", shape=(64, 16384, 64), dtype=float32)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
__________slotattentionslots___________
(64, 7, 64)
____________________________slotattentionkandq.shape__________________
(64, 16384, 64)
(64, 7, 64)
-----------slot-------- <class 'tensorflow.python.framework.ops.Tensor'>
WARNING:tensorflow:From train_slot.py:89: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0818 20:17:54.559977 140034352527168 module_wrapper.py:139] From train_slot.py:89: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /usr/local/Ascend/tfplugin/latest/python/site-packages/npu_bridge/estimator/npu/npu_loss_scale_optimizer.py:60: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0818 20:17:55.689749 140034352527168 module_wrapper.py:139] From /usr/local/Ascend/tfplugin/latest/python/site-packages/npu_bridge/estimator/npu/npu_loss_scale_optimizer.py:60: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From train_slot.py:105: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W0818 20:17:56.342716 140034352527168 module_wrapper.py:139] From train_slot.py:105: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From train_slot.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0818 20:17:56.343522 140034352527168 module_wrapper.py:139] From train_slot.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train_slot.py:109: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0818 20:17:56.345036 140034352527168 module_wrapper.py:139] From train_slot.py:109: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train_slot.py:112: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.

W0818 20:17:56.482018 140034352527168 module_wrapper.py:139] From train_slot.py:112: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.

WARNING:tensorflow:From train_slot.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0818 20:17:56.482200 140034352527168 module_wrapper.py:139] From train_slot.py:115: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train_slot.py:127: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0818 20:17:56.482373 140034352527168 module_wrapper.py:139] From train_slot.py:127: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-08-18 20:17:56.482636: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-08-18 20:17:56.517142: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600000000 Hz
2022-08-18 20:17:56.523266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559132ed5960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-08-18 20:17:56.523322: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
I0818 20:17:56.533076 140034352527168 train_slot.py:132] Initializing from scratch.
2022-08-18 20:18:01.883507: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 1
2022-08-18 20:18:14.643873: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 11
2022-08-18 20:18:14.783883: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 21
2022-08-18 20:18:16.771644: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 31
2022-08-18 20:19:01.421735: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 41
I0818 20:19:21.429772 140034352527168 train_slot.py:155] Step: 100, Loss: 0.053188, Time: 0:01:07.617746
I0818 20:19:41.655684 140034352527168 train_slot.py:155] Step: 200, Loss: 0.040912, Time: 0:01:27.843807
I0818 20:20:01.306877 140034352527168 train_slot.py:155] Step: 300, Loss: 0.037217, Time: 0:01:47.495019
I0818 20:20:20.902972 140034352527168 train_slot.py:155] Step: 400, Loss: 0.036148, Time: 0:02:07.090960
I0818 20:20:40.508795 140034352527168 train_slot.py:155] Step: 500, Loss: 0.033735, Time: 0:02:26.696805
I0818 20:21:02.830143 140034352527168 train_slot.py:155] Step: 600, Loss: 0.040354, Time: 0:02:49.018341
I0818 20:21:26.306944 140034352527168 train_slot.py:155] Step: 700, Loss: 0.030799, Time: 0:03:12.494936
I0818 20:21:49.974817 140034352527168 train_slot.py:155] Step: 800, Loss: 0.035226, Time: 0:03:36.163044
I0818 20:22:14.058948 140034352527168 train_slot.py:155] Step: 900, Loss: 0.037220, Time: 0:04:00.246932
I0818 20:22:38.536920 140034352527168 train_slot.py:155] Step: 1000, Loss: 0.031424, Time: 0:04:24.725072
2022-08-18 20:22:38.771679: I tf_adapter/kernels/geop_npu.cc:822] The model has been compiled on the Ascend AI processor, current graph id is: 51
I0818 20:22:42.593561 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-1000
I0818 20:22:43.749951 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 1000
I0818 20:23:07.623275 140034352527168 train_slot.py:155] Step: 1100, Loss: 0.025654, Time: 0:04:53.811439
I0818 20:23:31.652567 140034352527168 train_slot.py:155] Step: 1200, Loss: 0.026023, Time: 0:05:17.840551
I0818 20:23:55.168341 140034352527168 train_slot.py:155] Step: 1300, Loss: 0.023606, Time: 0:05:41.356567
I0818 20:24:19.001393 140034352527168 train_slot.py:155] Step: 1400, Loss: 0.026259, Time: 0:06:05.189347
I0818 20:24:42.784525 140034352527168 train_slot.py:155] Step: 1500, Loss: 0.022012, Time: 0:06:28.972736
I0818 20:25:06.269227 140034352527168 train_slot.py:155] Step: 1600, Loss: 0.023390, Time: 0:06:52.457134
I0818 20:25:30.187215 140034352527168 train_slot.py:155] Step: 1700, Loss: 0.019676, Time: 0:07:16.375453
I0818 20:25:53.823980 140034352527168 train_slot.py:155] Step: 1800, Loss: 0.018952, Time: 0:07:40.012155
I0818 20:26:17.404519 140034352527168 train_slot.py:155] Step: 1900, Loss: 0.018997, Time: 0:08:03.592720
I0818 20:26:41.125081 140034352527168 train_slot.py:155] Step: 2000, Loss: 0.018855, Time: 0:08:27.313288
I0818 20:26:41.497310 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-2000
I0818 20:26:42.566919 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 2000
I0818 20:27:06.330947 140034352527168 train_slot.py:155] Step: 2100, Loss: 0.019580, Time: 0:08:52.518970
I0818 20:27:30.353623 140034352527168 train_slot.py:155] Step: 2200, Loss: 0.016836, Time: 0:09:16.541808
I0818 20:27:54.110253 140034352527168 train_slot.py:155] Step: 2300, Loss: 0.019547, Time: 0:09:40.298428
I0818 20:28:17.659135 140034352527168 train_slot.py:155] Step: 2400, Loss: 0.017053, Time: 0:10:03.847307
I0818 20:28:41.026010 140034352527168 train_slot.py:155] Step: 2500, Loss: 0.016620, Time: 0:10:27.214240
I0818 20:29:04.538580 140034352527168 train_slot.py:155] Step: 2600, Loss: 0.015125, Time: 0:10:50.726755
I0818 20:29:28.197018 140034352527168 train_slot.py:155] Step: 2700, Loss: 0.014446, Time: 0:11:14.385166
I0818 20:29:51.611564 140034352527168 train_slot.py:155] Step: 2800, Loss: 0.012506, Time: 0:11:37.799795
I0818 20:30:15.186000 140034352527168 train_slot.py:155] Step: 2900, Loss: 0.013037, Time: 0:12:01.373936
I0818 20:30:38.631035 140034352527168 train_slot.py:155] Step: 3000, Loss: 0.013552, Time: 0:12:24.819260
I0818 20:30:38.998674 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-3000
I0818 20:30:40.141105 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 3000
I0818 20:31:03.700677 140034352527168 train_slot.py:155] Step: 3100, Loss: 0.012407, Time: 0:12:49.888196
I0818 20:31:27.156548 140034352527168 train_slot.py:155] Step: 3200, Loss: 0.012251, Time: 0:13:13.344776
I0818 20:31:50.976830 140034352527168 train_slot.py:155] Step: 3300, Loss: 0.012933, Time: 0:13:37.165017
I0818 20:32:14.723090 140034352527168 train_slot.py:155] Step: 3400, Loss: 0.012052, Time: 0:14:00.911317
I0818 20:32:38.459706 140034352527168 train_slot.py:155] Step: 3500, Loss: 0.010657, Time: 0:14:24.647863
I0818 20:33:02.584392 140034352527168 train_slot.py:155] Step: 3600, Loss: 0.010233, Time: 0:14:48.772518
I0818 20:33:26.330664 140034352527168 train_slot.py:155] Step: 3700, Loss: 0.009833, Time: 0:15:12.518858
I0818 20:33:50.294403 140034352527168 train_slot.py:155] Step: 3800, Loss: 0.010320, Time: 0:15:36.482347
I0818 20:34:13.801057 140034352527168 train_slot.py:155] Step: 3900, Loss: 0.010281, Time: 0:15:59.989213
I0818 20:34:37.395194 140034352527168 train_slot.py:155] Step: 4000, Loss: 0.011247, Time: 0:16:23.583229
I0818 20:34:37.733900 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-4000
I0818 20:34:38.841529 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 4000
I0818 20:35:02.416832 140034352527168 train_slot.py:155] Step: 4100, Loss: 0.008548, Time: 0:16:48.604989
I0818 20:35:25.856355 140034352527168 train_slot.py:155] Step: 4200, Loss: 0.008151, Time: 0:17:12.044483
I0818 20:35:49.428945 140034352527168 train_slot.py:155] Step: 4300, Loss: 0.008285, Time: 0:17:35.617051
I0818 20:36:13.157167 140034352527168 train_slot.py:155] Step: 4400, Loss: 0.009003, Time: 0:17:59.345343
I0818 20:36:36.746453 140034352527168 train_slot.py:155] Step: 4500, Loss: 0.008165, Time: 0:18:22.934660
I0818 20:37:00.759677 140034352527168 train_slot.py:155] Step: 4600, Loss: 0.009089, Time: 0:18:46.947183
I0818 20:37:24.309717 140034352527168 train_slot.py:155] Step: 4700, Loss: 0.007463, Time: 0:19:10.497919
I0818 20:37:47.856691 140034352527168 train_slot.py:155] Step: 4800, Loss: 0.007207, Time: 0:19:34.044899
I0818 20:38:11.592325 140034352527168 train_slot.py:155] Step: 4900, Loss: 0.008360, Time: 0:19:57.780346
I0818 20:38:35.051666 140034352527168 train_slot.py:155] Step: 5000, Loss: 0.007631, Time: 0:20:21.239867
I0818 20:38:35.383338 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-5000
I0818 20:38:36.524528 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 5000
I0818 20:39:00.035718 140034352527168 train_slot.py:155] Step: 5100, Loss: 0.008121, Time: 0:20:46.223925
I0818 20:39:23.538946 140034352527168 train_slot.py:155] Step: 5200, Loss: 0.007974, Time: 0:21:09.727100
I0818 20:39:47.012365 140034352527168 train_slot.py:155] Step: 5300, Loss: 0.007804, Time: 0:21:33.200501
I0818 20:40:10.431906 140034352527168 train_slot.py:155] Step: 5400, Loss: 0.008018, Time: 0:21:56.620136
I0818 20:40:34.227827 140034352527168 train_slot.py:155] Step: 5500, Loss: 0.009452, Time: 0:22:20.415893
I0818 20:40:58.148567 140034352527168 train_slot.py:155] Step: 5600, Loss: 0.008838, Time: 0:22:44.336783
I0818 20:41:21.644590 140034352527168 train_slot.py:155] Step: 5700, Loss: 0.007083, Time: 0:23:07.832823
I0818 20:41:45.098620 140034352527168 train_slot.py:155] Step: 5800, Loss: 0.007237, Time: 0:23:31.286811
I0818 20:42:08.661917 140034352527168 train_slot.py:155] Step: 5900, Loss: 0.007981, Time: 0:23:54.850116
I0818 20:42:32.384937 140034352527168 train_slot.py:155] Step: 6000, Loss: 0.007040, Time: 0:24:18.573145
WARNING:tensorflow:From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0818 20:42:32.420650 140034352527168 deprecation.py:323] From /usr/local/python3.7.5/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I0818 20:42:32.752216 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-6000
I0818 20:42:33.884349 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 6000
I0818 20:42:57.316396 140034352527168 train_slot.py:155] Step: 6100, Loss: 0.006267, Time: 0:24:43.504628
I0818 20:43:20.997606 140034352527168 train_slot.py:155] Step: 6200, Loss: 0.006969, Time: 0:25:07.185807
I0818 20:43:44.540320 140034352527168 train_slot.py:155] Step: 6300, Loss: 0.006327, Time: 0:25:30.728549
I0818 20:44:07.985341 140034352527168 train_slot.py:155] Step: 6400, Loss: 0.006892, Time: 0:25:54.173314
I0818 20:44:31.613361 140034352527168 train_slot.py:155] Step: 6500, Loss: 0.007237, Time: 0:26:17.801570
I0818 20:44:55.112281 140034352527168 train_slot.py:155] Step: 6600, Loss: 0.006815, Time: 0:26:41.300478
I0818 20:45:18.742662 140034352527168 train_slot.py:155] Step: 6700, Loss: 0.006669, Time: 0:27:04.930863
I0818 20:45:42.274518 140034352527168 train_slot.py:155] Step: 6800, Loss: 0.005722, Time: 0:27:28.462542
I0818 20:46:05.763321 140034352527168 train_slot.py:155] Step: 6900, Loss: 0.005241, Time: 0:27:51.951544
I0818 20:46:29.169207 140034352527168 train_slot.py:155] Step: 7000, Loss: 0.006634, Time: 0:28:15.357405
I0818 20:46:29.539329 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-7000
I0818 20:46:30.689158 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 7000
I0818 20:46:54.402474 140034352527168 train_slot.py:155] Step: 7100, Loss: 0.006090, Time: 0:28:40.590616
I0818 20:47:17.905079 140034352527168 train_slot.py:155] Step: 7200, Loss: 0.006757, Time: 0:29:04.093309
I0818 20:47:41.387135 140034352527168 train_slot.py:155] Step: 7300, Loss: 0.006931, Time: 0:29:27.575314
I0818 20:48:04.897594 140034352527168 train_slot.py:155] Step: 7400, Loss: 0.006788, Time: 0:29:51.085747
I0818 20:48:28.368171 140034352527168 train_slot.py:155] Step: 7500, Loss: 0.006296, Time: 0:30:14.556379
I0818 20:48:52.003962 140034352527168 train_slot.py:155] Step: 7600, Loss: 0.008156, Time: 0:30:38.192192
I0818 20:49:15.646711 140034352527168 train_slot.py:155] Step: 7700, Loss: 0.006818, Time: 0:31:01.834917
I0818 20:49:39.461096 140034352527168 train_slot.py:155] Step: 7800, Loss: 0.006658, Time: 0:31:25.649251
I0818 20:50:02.939457 140034352527168 train_slot.py:155] Step: 7900, Loss: 0.006398, Time: 0:31:49.127685
I0818 20:50:26.458575 140034352527168 train_slot.py:155] Step: 8000, Loss: 0.006140, Time: 0:32:12.646701
I0818 20:50:26.782173 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-8000
I0818 20:50:27.913141 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 8000
I0818 20:50:51.545426 140034352527168 train_slot.py:155] Step: 8100, Loss: 0.006631, Time: 0:32:37.733638
I0818 20:51:15.362034 140034352527168 train_slot.py:155] Step: 8200, Loss: 0.006318, Time: 0:33:01.550233
I0818 20:51:38.932267 140034352527168 train_slot.py:155] Step: 8300, Loss: 0.006526, Time: 0:33:25.120286
I0818 20:52:02.450373 140034352527168 train_slot.py:155] Step: 8400, Loss: 0.006201, Time: 0:33:48.638573
I0818 20:52:25.989739 140034352527168 train_slot.py:155] Step: 8500, Loss: 0.007154, Time: 0:34:12.177865
I0818 20:52:49.501466 140034352527168 train_slot.py:155] Step: 8600, Loss: 0.007487, Time: 0:34:35.689672
I0818 20:53:13.189413 140034352527168 train_slot.py:155] Step: 8700, Loss: 0.005632, Time: 0:34:59.377639
I0818 20:53:36.605772 140034352527168 train_slot.py:155] Step: 8800, Loss: 0.005131, Time: 0:35:22.794002
I0818 20:54:00.129070 140034352527168 train_slot.py:155] Step: 8900, Loss: 0.006731, Time: 0:35:46.317033
I0818 20:54:23.511632 140034352527168 train_slot.py:155] Step: 9000, Loss: 0.005483, Time: 0:36:09.699812
I0818 20:54:23.837056 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-9000
I0818 20:54:24.969315 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 9000
I0818 20:54:48.421748 140034352527168 train_slot.py:155] Step: 9100, Loss: 0.005479, Time: 0:36:34.609950
I0818 20:55:11.970363 140034352527168 train_slot.py:155] Step: 9200, Loss: 0.006315, Time: 0:36:58.158567
I0818 20:55:35.736869 140034352527168 train_slot.py:155] Step: 9300, Loss: 0.006112, Time: 0:37:21.925009
I0818 20:55:59.161090 140034352527168 train_slot.py:155] Step: 9400, Loss: 0.008459, Time: 0:37:45.349298
I0818 20:56:22.970147 140034352527168 train_slot.py:155] Step: 9500, Loss: 0.006328, Time: 0:38:09.158344
I0818 20:56:46.753400 140034352527168 train_slot.py:155] Step: 9600, Loss: 0.006124, Time: 0:38:32.941551
I0818 20:57:10.212146 140034352527168 train_slot.py:155] Step: 9700, Loss: 0.006192, Time: 0:38:56.400341
I0818 20:57:33.817583 140034352527168 train_slot.py:155] Step: 9800, Loss: 0.007712, Time: 0:39:20.005815
I0818 20:57:57.318232 140034352527168 train_slot.py:155] Step: 9900, Loss: 0.005830, Time: 0:39:43.506431
I0818 20:58:20.776266 140034352527168 train_slot.py:155] Step: 10000, Loss: 0.005025, Time: 0:40:06.964406
I0818 20:58:21.092834 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-10000
I0818 20:58:22.227720 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 10000
I0818 20:58:45.739703 140034352527168 train_slot.py:155] Step: 10100, Loss: 0.006457, Time: 0:40:31.927902
I0818 20:59:09.261325 140034352527168 train_slot.py:155] Step: 10200, Loss: 0.005544, Time: 0:40:55.449524
I0818 20:59:33.011837 140034352527168 train_slot.py:155] Step: 10300, Loss: 0.005512, Time: 0:41:19.199948
I0818 20:59:56.692079 140034352527168 train_slot.py:155] Step: 10400, Loss: 0.005174, Time: 0:41:42.880281
I0818 21:00:20.351772 140034352527168 train_slot.py:155] Step: 10500, Loss: 0.005584, Time: 0:42:06.539940
I0818 21:00:43.923880 140034352527168 train_slot.py:155] Step: 10600, Loss: 0.005787, Time: 0:42:30.111912
I0818 21:01:07.456373 140034352527168 train_slot.py:155] Step: 10700, Loss: 0.005215, Time: 0:42:53.644571
I0818 21:01:30.964601 140034352527168 train_slot.py:155] Step: 10800, Loss: 0.005278, Time: 0:43:17.152807
I0818 21:01:54.781526 140034352527168 train_slot.py:155] Step: 10900, Loss: 0.005157, Time: 0:43:40.969043
I0818 21:02:18.762367 140034352527168 train_slot.py:155] Step: 11000, Loss: 0.006140, Time: 0:44:04.950480
I0818 21:02:19.110218 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-11000
I0818 21:02:20.263404 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 11000
I0818 21:02:44.084229 140034352527168 train_slot.py:155] Step: 11100, Loss: 0.005134, Time: 0:44:30.272437
I0818 21:03:07.624584 140034352527168 train_slot.py:155] Step: 11200, Loss: 0.005927, Time: 0:44:53.812575
I0818 21:03:31.133010 140034352527168 train_slot.py:155] Step: 11300, Loss: 0.005619, Time: 0:45:17.321239
I0818 21:03:54.996405 140034352527168 train_slot.py:155] Step: 11400, Loss: 0.006058, Time: 0:45:41.184559
I0818 21:04:18.619976 140034352527168 train_slot.py:155] Step: 11500, Loss: 0.004644, Time: 0:46:04.808206
I0818 21:04:42.209455 140034352527168 train_slot.py:155] Step: 11600, Loss: 0.005000, Time: 0:46:28.397500
I0818 21:05:05.727489 140034352527168 train_slot.py:155] Step: 11700, Loss: 0.006015, Time: 0:46:51.915669
I0818 21:05:29.306401 140034352527168 train_slot.py:155] Step: 11800, Loss: 0.006080, Time: 0:47:15.494612
I0818 21:05:52.808437 140034352527168 train_slot.py:155] Step: 11900, Loss: 0.005868, Time: 0:47:38.996544
I0818 21:06:16.591660 140034352527168 train_slot.py:155] Step: 12000, Loss: 0.005089, Time: 0:48:02.779842
I0818 21:06:16.957542 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-12000
I0818 21:06:18.085176 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 12000
I0818 21:06:41.964336 140034352527168 train_slot.py:155] Step: 12100, Loss: 0.004596, Time: 0:48:28.152536
I0818 21:07:05.584353 140034352527168 train_slot.py:155] Step: 12200, Loss: 0.005268, Time: 0:48:51.772449
I0818 21:07:29.117958 140034352527168 train_slot.py:155] Step: 12300, Loss: 0.004429, Time: 0:49:15.306170
I0818 21:07:53.883862 140034352527168 train_slot.py:155] Step: 12400, Loss: 0.004868, Time: 0:49:40.072068
I0818 21:08:18.269811 140034352527168 train_slot.py:155] Step: 12500, Loss: 0.004680, Time: 0:50:04.458019
I0818 21:08:41.853215 140034352527168 train_slot.py:155] Step: 12600, Loss: 0.004558, Time: 0:50:28.041233
I0818 21:09:05.988568 140034352527168 train_slot.py:155] Step: 12700, Loss: 0.004805, Time: 0:50:52.176802
I0818 21:09:30.158787 140034352527168 train_slot.py:155] Step: 12800, Loss: 0.004437, Time: 0:51:16.347016
I0818 21:09:53.895400 140034352527168 train_slot.py:155] Step: 12900, Loss: 0.004803, Time: 0:51:40.083467
I0818 21:10:17.504959 140034352527168 train_slot.py:155] Step: 13000, Loss: 0.004821, Time: 0:52:03.693145
I0818 21:10:17.898097 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-13000
I0818 21:10:19.046410 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 13000
I0818 21:10:42.729949 140034352527168 train_slot.py:155] Step: 13100, Loss: 0.004364, Time: 0:52:28.918184
I0818 21:11:06.222726 140034352527168 train_slot.py:155] Step: 13200, Loss: 0.004589, Time: 0:52:52.410754
I0818 21:11:29.784289 140034352527168 train_slot.py:155] Step: 13300, Loss: 0.005349, Time: 0:53:15.972495
I0818 21:11:53.281903 140034352527168 train_slot.py:155] Step: 13400, Loss: 0.004207, Time: 0:53:39.470107
I0818 21:12:17.249749 140034352527168 train_slot.py:155] Step: 13500, Loss: 0.005477, Time: 0:54:03.437747
I0818 21:12:40.962895 140034352527168 train_slot.py:155] Step: 13600, Loss: 0.004903, Time: 0:54:27.151078
I0818 21:13:04.475615 140034352527168 train_slot.py:155] Step: 13700, Loss: 0.004693, Time: 0:54:50.663822
I0818 21:13:28.004631 140034352527168 train_slot.py:155] Step: 13800, Loss: 0.005146, Time: 0:55:14.192841
I0818 21:13:51.445197 140034352527168 train_slot.py:155] Step: 13900, Loss: 0.004220, Time: 0:55:37.633339
I0818 21:14:14.968499 140034352527168 train_slot.py:155] Step: 14000, Loss: 0.004430, Time: 0:56:01.156709
I0818 21:14:15.342578 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-14000
I0818 21:14:16.480155 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 14000
I0818 21:14:40.260924 140034352527168 train_slot.py:155] Step: 14100, Loss: 0.004824, Time: 0:56:26.448897
I0818 21:15:03.759912 140034352527168 train_slot.py:155] Step: 14200, Loss: 0.004821, Time: 0:56:49.948122
I0818 21:15:27.233309 140034352527168 train_slot.py:155] Step: 14300, Loss: 0.004495, Time: 0:57:13.421517
I0818 21:15:50.771904 140034352527168 train_slot.py:155] Step: 14400, Loss: 0.004146, Time: 0:57:36.960122
I0818 21:16:14.503856 140034352527168 train_slot.py:155] Step: 14500, Loss: 0.005127, Time: 0:58:00.691728
I0818 21:16:37.963584 140034352527168 train_slot.py:155] Step: 14600, Loss: 0.004126, Time: 0:58:24.151808
I0818 21:17:01.693133 140034352527168 train_slot.py:155] Step: 14700, Loss: 0.004182, Time: 0:58:47.881361
I0818 21:17:25.277341 140034352527168 train_slot.py:155] Step: 14800, Loss: 0.004219, Time: 0:59:11.465344
I0818 21:17:48.822495 140034352527168 train_slot.py:155] Step: 14900, Loss: 0.003982, Time: 0:59:35.010694
I0818 21:18:12.366072 140034352527168 train_slot.py:155] Step: 15000, Loss: 0.004696, Time: 0:59:58.554269
I0818 21:18:12.694650 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-15000
I0818 21:18:13.827967 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 15000
I0818 21:18:37.325814 140034352527168 train_slot.py:155] Step: 15100, Loss: 0.004221, Time: 1:00:23.513340
I0818 21:19:01.148466 140034352527168 train_slot.py:155] Step: 15200, Loss: 0.004398, Time: 1:00:47.336578
I0818 21:19:24.970322 140034352527168 train_slot.py:155] Step: 15300, Loss: 0.004820, Time: 1:01:11.158531
I0818 21:19:48.531574 140034352527168 train_slot.py:155] Step: 15400, Loss: 0.004432, Time: 1:01:34.719743
I0818 21:20:11.982053 140034352527168 train_slot.py:155] Step: 15500, Loss: 0.003939, Time: 1:01:58.170248
I0818 21:20:35.502482 140034352527168 train_slot.py:155] Step: 15600, Loss: 0.004261, Time: 1:02:21.690680
I0818 21:20:59.260720 140034352527168 train_slot.py:155] Step: 15700, Loss: 0.003615, Time: 1:02:45.448826
I0818 21:21:23.270896 140034352527168 train_slot.py:155] Step: 15800, Loss: 0.004342, Time: 1:03:09.459123
I0818 21:21:46.761882 140034352527168 train_slot.py:155] Step: 15900, Loss: 0.003429, Time: 1:03:32.950013
I0818 21:22:10.313108 140034352527168 train_slot.py:155] Step: 16000, Loss: 0.004644, Time: 1:03:56.501266
I0818 21:22:10.635959 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-16000
I0818 21:22:11.766046 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 16000
I0818 21:22:35.179105 140034352527168 train_slot.py:155] Step: 16100, Loss: 0.004338, Time: 1:04:21.367309
I0818 21:22:58.960216 140034352527168 train_slot.py:155] Step: 16200, Loss: 0.004603, Time: 1:04:45.148431
I0818 21:23:22.575247 140034352527168 train_slot.py:155] Step: 16300, Loss: 0.004016, Time: 1:05:08.763263
I0818 21:23:46.034239 140034352527168 train_slot.py:155] Step: 16400, Loss: 0.003496, Time: 1:05:32.222437
I0818 21:24:09.596340 140034352527168 train_slot.py:155] Step: 16500, Loss: 0.004120, Time: 1:05:55.784574
I0818 21:24:32.998848 140034352527168 train_slot.py:155] Step: 16600, Loss: 0.004508, Time: 1:06:19.186698
I0818 21:24:56.405611 140034352527168 train_slot.py:155] Step: 16700, Loss: 0.004642, Time: 1:06:42.593838
I0818 21:25:19.934763 140034352527168 train_slot.py:155] Step: 16800, Loss: 0.005518, Time: 1:07:06.122994
I0818 21:25:43.688671 140034352527168 train_slot.py:155] Step: 16900, Loss: 0.004136, Time: 1:07:29.876901
I0818 21:26:07.171070 140034352527168 train_slot.py:155] Step: 17000, Loss: 0.003914, Time: 1:07:53.359200
I0818 21:26:07.496211 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-17000
I0818 21:26:08.626933 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 17000
I0818 21:26:32.534907 140034352527168 train_slot.py:155] Step: 17100, Loss: 0.004421, Time: 1:08:18.723106
I0818 21:26:56.352638 140034352527168 train_slot.py:155] Step: 17200, Loss: 0.004497, Time: 1:08:42.540838
I0818 21:27:19.868422 140034352527168 train_slot.py:155] Step: 17300, Loss: 0.003965, Time: 1:09:06.056470
I0818 21:27:43.623433 140034352527168 train_slot.py:155] Step: 17400, Loss: 0.004819, Time: 1:09:29.811630
I0818 21:28:07.131236 140034352527168 train_slot.py:155] Step: 17500, Loss: 0.003670, Time: 1:09:53.319343
I0818 21:28:30.678534 140034352527168 train_slot.py:155] Step: 17600, Loss: 0.004146, Time: 1:10:16.866744
I0818 21:28:54.314597 140034352527168 train_slot.py:155] Step: 17700, Loss: 0.004368, Time: 1:10:40.502800
I0818 21:29:17.739748 140034352527168 train_slot.py:155] Step: 17800, Loss: 0.004384, Time: 1:11:03.927703
I0818 21:29:41.397124 140034352527168 train_slot.py:155] Step: 17900, Loss: 0.003079, Time: 1:11:27.585320
I0818 21:30:04.943895 140034352527168 train_slot.py:155] Step: 18000, Loss: 0.003380, Time: 1:11:51.132095
I0818 21:30:05.256906 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-18000
I0818 21:30:06.366136 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 18000
I0818 21:30:29.864504 140034352527168 train_slot.py:155] Step: 18100, Loss: 0.004631, Time: 1:12:16.052470
I0818 21:30:53.350650 140034352527168 train_slot.py:155] Step: 18200, Loss: 0.003228, Time: 1:12:39.538846
I0818 21:31:17.143446 140034352527168 train_slot.py:155] Step: 18300, Loss: 0.003684, Time: 1:13:03.331650
I0818 21:31:40.568322 140034352527168 train_slot.py:155] Step: 18400, Loss: 0.003618, Time: 1:13:26.756444
I0818 21:32:04.529980 140034352527168 train_slot.py:155] Step: 18500, Loss: 0.003625, Time: 1:13:50.718180
I0818 21:32:28.152969 140034352527168 train_slot.py:155] Step: 18600, Loss: 0.003504, Time: 1:14:14.341198
I0818 21:32:51.732508 140034352527168 train_slot.py:155] Step: 18700, Loss: 0.003688, Time: 1:14:37.920673
I0818 21:33:15.301722 140034352527168 train_slot.py:155] Step: 18800, Loss: 0.003661, Time: 1:15:01.489920
I0818 21:33:38.907331 140034352527168 train_slot.py:155] Step: 18900, Loss: 0.002952, Time: 1:15:25.095533
I0818 21:34:02.569541 140034352527168 train_slot.py:155] Step: 19000, Loss: 0.004467, Time: 1:15:48.757668
I0818 21:34:02.889597 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-19000
I0818 21:34:04.020549 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 19000
I0818 21:34:27.521555 140034352527168 train_slot.py:155] Step: 19100, Loss: 0.003677, Time: 1:16:13.709755
I0818 21:34:51.271065 140034352527168 train_slot.py:155] Step: 19200, Loss: 0.004576, Time: 1:16:37.459264
I0818 21:35:14.796630 140034352527168 train_slot.py:155] Step: 19300, Loss: 0.004151, Time: 1:17:00.984644
I0818 21:35:38.376550 140034352527168 train_slot.py:155] Step: 19400, Loss: 0.004154, Time: 1:17:24.564740
I0818 21:36:01.803848 140034352527168 train_slot.py:155] Step: 19500, Loss: 0.003479, Time: 1:17:47.992052
I0818 21:36:25.590623 140034352527168 train_slot.py:155] Step: 19600, Loss: 0.003309, Time: 1:18:11.778830
I0818 21:36:49.144417 140034352527168 train_slot.py:155] Step: 19700, Loss: 0.002801, Time: 1:18:35.332316
I0818 21:37:12.600360 140034352527168 train_slot.py:155] Step: 19800, Loss: 0.003703, Time: 1:18:58.788562
I0818 21:37:36.008239 140034352527168 train_slot.py:155] Step: 19900, Loss: 0.004015, Time: 1:19:22.196467
I0818 21:37:59.832660 140034352527168 train_slot.py:155] Step: 20000, Loss: 0.003209, Time: 1:19:46.020775
I0818 21:38:00.216275 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-20000
I0818 21:38:01.351593 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 20000
I0818 21:38:25.132625 140034352527168 train_slot.py:155] Step: 20100, Loss: 0.003820, Time: 1:20:11.320787
I0818 21:38:48.662460 140034352527168 train_slot.py:155] Step: 20200, Loss: 0.004030, Time: 1:20:34.850656
I0818 21:39:12.189376 140034352527168 train_slot.py:155] Step: 20300, Loss: 0.003744, Time: 1:20:58.377283
I0818 21:39:35.613806 140034352527168 train_slot.py:155] Step: 20400, Loss: 0.003525, Time: 1:21:21.802009
I0818 21:39:59.053770 140034352527168 train_slot.py:155] Step: 20500, Loss: 0.003617, Time: 1:21:45.241967
I0818 21:40:22.615759 140034352527168 train_slot.py:155] Step: 20600, Loss: 0.004086, Time: 1:22:08.803891
I0818 21:40:46.324578 140034352527168 train_slot.py:155] Step: 20700, Loss: 0.005010, Time: 1:22:32.512751
I0818 21:41:09.846843 140034352527168 train_slot.py:155] Step: 20800, Loss: 0.003657, Time: 1:22:56.035057
I0818 21:41:33.312792 140034352527168 train_slot.py:155] Step: 20900, Loss: 0.003236, Time: 1:23:19.500993
I0818 21:41:56.839882 140034352527168 train_slot.py:155] Step: 21000, Loss: 0.003304, Time: 1:23:43.027883
I0818 21:41:57.224673 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-21000
I0818 21:41:58.317859 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 21000
I0818 21:42:21.834988 140034352527168 train_slot.py:155] Step: 21100, Loss: 0.002957, Time: 1:24:08.023195
I0818 21:42:45.606987 140034352527168 train_slot.py:155] Step: 21200, Loss: 0.003796, Time: 1:24:31.795186
I0818 21:43:09.152553 140034352527168 train_slot.py:155] Step: 21300, Loss: 0.003753, Time: 1:24:55.340783
I0818 21:43:32.603855 140034352527168 train_slot.py:155] Step: 21400, Loss: 0.004084, Time: 1:25:18.791876
I0818 21:43:56.193766 140034352527168 train_slot.py:155] Step: 21500, Loss: 0.003197, Time: 1:25:42.381930
I0818 21:44:19.775073 140034352527168 train_slot.py:155] Step: 21600, Loss: 0.003745, Time: 1:26:05.963277
I0818 21:44:43.471839 140034352527168 train_slot.py:155] Step: 21700, Loss: 0.003232, Time: 1:26:29.659828
I0818 21:45:07.018461 140034352527168 train_slot.py:155] Step: 21800, Loss: 0.003603, Time: 1:26:53.206671
I0818 21:45:30.542912 140034352527168 train_slot.py:155] Step: 21900, Loss: 0.003557, Time: 1:27:16.731071
I0818 21:45:53.910190 140034352527168 train_slot.py:155] Step: 22000, Loss: 0.002852, Time: 1:27:40.098383
I0818 21:45:54.267624 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-22000
I0818 21:45:55.375667 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 22000
I0818 21:46:18.818939 140034352527168 train_slot.py:155] Step: 22100, Loss: 0.003586, Time: 1:28:05.007106
I0818 21:46:42.297014 140034352527168 train_slot.py:155] Step: 22200, Loss: 0.002626, Time: 1:28:28.485210
I0818 21:47:06.170997 140034352527168 train_slot.py:155] Step: 22300, Loss: 0.003317, Time: 1:28:52.359201
I0818 21:47:29.848485 140034352527168 train_slot.py:155] Step: 22400, Loss: 0.004317, Time: 1:29:16.036513
I0818 21:47:53.469449 140034352527168 train_slot.py:155] Step: 22500, Loss: 0.003707, Time: 1:29:39.657645
I0818 21:48:17.131048 140034352527168 train_slot.py:155] Step: 22600, Loss: 0.003678, Time: 1:30:03.319243
I0818 21:48:40.692950 140034352527168 train_slot.py:155] Step: 22700, Loss: 0.003537, Time: 1:30:26.881027
I0818 21:49:04.410418 140034352527168 train_slot.py:155] Step: 22800, Loss: 0.003731, Time: 1:30:50.598612
I0818 21:49:28.028190 140034352527168 train_slot.py:155] Step: 22900, Loss: 0.003107, Time: 1:31:14.216388
I0818 21:49:51.817697 140034352527168 train_slot.py:155] Step: 23000, Loss: 0.002911, Time: 1:31:38.005836
I0818 21:49:52.124387 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-23000
I0818 21:49:53.193629 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 23000
I0818 21:50:17.024564 140034352527168 train_slot.py:155] Step: 23100, Loss: 0.003585, Time: 1:32:03.212777
I0818 21:50:40.768741 140034352527168 train_slot.py:155] Step: 23200, Loss: 0.003095, Time: 1:32:26.956970
I0818 21:51:04.234534 140034352527168 train_slot.py:155] Step: 23300, Loss: 0.003050, Time: 1:32:50.422583
I0818 21:51:27.966284 140034352527168 train_slot.py:155] Step: 23400, Loss: 0.003388, Time: 1:33:14.154483
I0818 21:51:51.647271 140034352527168 train_slot.py:155] Step: 23500, Loss: 0.003608, Time: 1:33:37.835499
I0818 21:52:15.103267 140034352527168 train_slot.py:155] Step: 23600, Loss: 0.003240, Time: 1:34:01.291364
I0818 21:52:38.629803 140034352527168 train_slot.py:155] Step: 23700, Loss: 0.003324, Time: 1:34:24.817989
I0818 21:53:02.315212 140034352527168 train_slot.py:155] Step: 23800, Loss: 0.003085, Time: 1:34:48.503420
I0818 21:53:26.093177 140034352527168 train_slot.py:155] Step: 23900, Loss: 0.003782, Time: 1:35:12.281281
I0818 21:53:49.604491 140034352527168 train_slot.py:155] Step: 24000, Loss: 0.002941, Time: 1:35:35.792667
I0818 21:53:49.977907 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-24000
I0818 21:53:51.051555 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 24000
I0818 21:54:14.699345 140034352527168 train_slot.py:155] Step: 24100, Loss: 0.002946, Time: 1:36:00.887555
I0818 21:54:38.464053 140034352527168 train_slot.py:155] Step: 24200, Loss: 0.003378, Time: 1:36:24.652009
I0818 21:55:02.645215 140034352527168 train_slot.py:155] Step: 24300, Loss: 0.003560, Time: 1:36:48.833367
I0818 21:55:26.646428 140034352527168 train_slot.py:155] Step: 24400, Loss: 0.003687, Time: 1:37:12.834627
I0818 21:55:50.144232 140034352527168 train_slot.py:155] Step: 24500, Loss: 0.002853, Time: 1:37:36.332358
I0818 21:56:13.728627 140034352527168 train_slot.py:155] Step: 24600, Loss: 0.003178, Time: 1:37:59.916838
I0818 21:56:37.354703 140034352527168 train_slot.py:155] Step: 24700, Loss: 0.003730, Time: 1:38:23.542903
I0818 21:57:00.917218 140034352527168 train_slot.py:155] Step: 24800, Loss: 0.003938, Time: 1:38:47.105193
I0818 21:57:24.650457 140034352527168 train_slot.py:155] Step: 24900, Loss: 0.002800, Time: 1:39:10.838681
I0818 21:57:48.404103 140034352527168 train_slot.py:155] Step: 25000, Loss: 0.003601, Time: 1:39:34.592300
I0818 21:57:48.775854 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-25000
I0818 21:57:49.845262 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 25000
I0818 21:58:13.596413 140034352527168 train_slot.py:155] Step: 25100, Loss: 0.002893, Time: 1:39:59.784384
I0818 21:58:37.130277 140034352527168 train_slot.py:155] Step: 25200, Loss: 0.003407, Time: 1:40:23.318476
I0818 21:59:00.761632 140034352527168 train_slot.py:155] Step: 25300, Loss: 0.003720, Time: 1:40:46.949749
I0818 21:59:24.283700 140034352527168 train_slot.py:155] Step: 25400, Loss: 0.003285, Time: 1:41:10.471900
I0818 21:59:47.925361 140034352527168 train_slot.py:155] Step: 25500, Loss: 0.003034, Time: 1:41:34.113561
I0818 22:00:11.560036 140034352527168 train_slot.py:155] Step: 25600, Loss: 0.002936, Time: 1:41:57.748236
I0818 22:00:35.035925 140034352527168 train_slot.py:155] Step: 25700, Loss: 0.002761, Time: 1:42:21.224055
I0818 22:00:58.778437 140034352527168 train_slot.py:155] Step: 25800, Loss: 0.003666, Time: 1:42:44.966638
I0818 22:01:22.361216 140034352527168 train_slot.py:155] Step: 25900, Loss: 0.002999, Time: 1:43:08.549419
I0818 22:01:45.772493 140034352527168 train_slot.py:155] Step: 26000, Loss: 0.003204, Time: 1:43:31.960078
I0818 22:01:46.101632 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-26000
I0818 22:01:47.180219 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 26000
I0818 22:02:10.917988 140034352527168 train_slot.py:155] Step: 26100, Loss: 0.002893, Time: 1:43:57.106219
I0818 22:02:34.508201 140034352527168 train_slot.py:155] Step: 26200, Loss: 0.002867, Time: 1:44:20.696410
I0818 22:02:58.035079 140034352527168 train_slot.py:155] Step: 26300, Loss: 0.002685, Time: 1:44:44.223089
I0818 22:03:21.581970 140034352527168 train_slot.py:155] Step: 26400, Loss: 0.003344, Time: 1:45:07.770167
I0818 22:03:45.073900 140034352527168 train_slot.py:155] Step: 26500, Loss: 0.003142, Time: 1:45:31.262119
I0818 22:04:08.764967 140034352527168 train_slot.py:155] Step: 26600, Loss: 0.002899, Time: 1:45:54.952841
I0818 22:04:32.397249 140034352527168 train_slot.py:155] Step: 26700, Loss: 0.003629, Time: 1:46:18.585357
I0818 22:04:56.066392 140034352527168 train_slot.py:155] Step: 26800, Loss: 0.003000, Time: 1:46:42.254590
I0818 22:05:19.771590 140034352527168 train_slot.py:155] Step: 26900, Loss: 0.003157, Time: 1:47:05.959748
I0818 22:05:43.558309 140034352527168 train_slot.py:155] Step: 27000, Loss: 0.002898, Time: 1:47:29.746482
I0818 22:05:43.919446 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-27000
I0818 22:05:44.992932 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 27000
I0818 22:06:08.452565 140034352527168 train_slot.py:155] Step: 27100, Loss: 0.004120, Time: 1:47:54.640769
I0818 22:06:32.159707 140034352527168 train_slot.py:155] Step: 27200, Loss: 0.002764, Time: 1:48:18.347906
I0818 22:06:55.672161 140034352527168 train_slot.py:155] Step: 27300, Loss: 0.003104, Time: 1:48:41.860289
I0818 22:07:19.252073 140034352527168 train_slot.py:155] Step: 27400, Loss: 0.002693, Time: 1:49:05.440192
I0818 22:07:42.827531 140034352527168 train_slot.py:155] Step: 27500, Loss: 0.002790, Time: 1:49:29.015741
I0818 22:08:06.267938 140034352527168 train_slot.py:155] Step: 27600, Loss: 0.002607, Time: 1:49:52.456133
I0818 22:08:30.076008 140034352527168 train_slot.py:155] Step: 27700, Loss: 0.002634, Time: 1:50:16.263969
I0818 22:08:53.674036 140034352527168 train_slot.py:155] Step: 27800, Loss: 0.002698, Time: 1:50:39.862203
I0818 22:09:17.193115 140034352527168 train_slot.py:155] Step: 27900, Loss: 0.002952, Time: 1:51:03.381313
I0818 22:09:40.755900 140034352527168 train_slot.py:155] Step: 28000, Loss: 0.002989, Time: 1:51:26.944014
I0818 22:09:41.100365 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-28000
I0818 22:09:42.175425 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 28000
I0818 22:10:05.646039 140034352527168 train_slot.py:155] Step: 28100, Loss: 0.002720, Time: 1:51:51.834210
I0818 22:10:29.386603 140034352527168 train_slot.py:155] Step: 28200, Loss: 0.003399, Time: 1:52:15.574801
I0818 22:10:52.915019 140034352527168 train_slot.py:155] Step: 28300, Loss: 0.002921, Time: 1:52:39.103024
I0818 22:11:16.434564 140034352527168 train_slot.py:155] Step: 28400, Loss: 0.002725, Time: 1:53:02.622780
I0818 22:11:39.858088 140034352527168 train_slot.py:155] Step: 28500, Loss: 0.002503, Time: 1:53:26.046316
I0818 22:12:03.303859 140034352527168 train_slot.py:155] Step: 28600, Loss: 0.003473, Time: 1:53:49.492093
I0818 22:12:26.762550 140034352527168 train_slot.py:155] Step: 28700, Loss: 0.002866, Time: 1:54:12.950619
I0818 22:12:50.672405 140034352527168 train_slot.py:155] Step: 28800, Loss: 0.002957, Time: 1:54:36.860507
I0818 22:13:14.349795 140034352527168 train_slot.py:155] Step: 28900, Loss: 0.003149, Time: 1:55:00.538026
I0818 22:13:37.743957 140034352527168 train_slot.py:155] Step: 29000, Loss: 0.003192, Time: 1:55:23.932092
I0818 22:13:38.088867 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-29000
I0818 22:13:39.227284 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 29000
I0818 22:14:02.668439 140034352527168 train_slot.py:155] Step: 29100, Loss: 0.003001, Time: 1:55:48.856643
I0818 22:14:26.173155 140034352527168 train_slot.py:155] Step: 29200, Loss: 0.002771, Time: 1:56:12.361351
I0818 22:14:49.920946 140034352527168 train_slot.py:155] Step: 29300, Loss: 0.003241, Time: 1:56:36.109047
I0818 22:15:13.396957 140034352527168 train_slot.py:155] Step: 29400, Loss: 0.003004, Time: 1:56:59.585138
I0818 22:15:36.965541 140034352527168 train_slot.py:155] Step: 29500, Loss: 0.003411, Time: 1:57:23.153740
I0818 22:16:00.336749 140034352527168 train_slot.py:155] Step: 29600, Loss: 0.002961, Time: 1:57:46.524872
I0818 22:16:23.946541 140034352527168 train_slot.py:155] Step: 29700, Loss: 0.002462, Time: 1:58:10.134740
I0818 22:16:47.459352 140034352527168 train_slot.py:155] Step: 29800, Loss: 0.002737, Time: 1:58:33.647372
I0818 22:17:11.181252 140034352527168 train_slot.py:155] Step: 29900, Loss: 0.002688, Time: 1:58:57.369427
I0818 22:17:34.768763 140034352527168 train_slot.py:155] Step: 30000, Loss: 0.002941, Time: 1:59:20.956961
I0818 22:17:35.134357 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-30000
I0818 22:17:36.263203 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 30000
I0818 22:17:59.854405 140034352527168 train_slot.py:155] Step: 30100, Loss: 0.002621, Time: 1:59:46.042482
I0818 22:18:23.342463 140034352527168 train_slot.py:155] Step: 30200, Loss: 0.003040, Time: 2:00:09.530629
I0818 22:18:46.825667 140034352527168 train_slot.py:155] Step: 30300, Loss: 0.002771, Time: 2:00:33.013898
I0818 22:19:10.527800 140034352527168 train_slot.py:155] Step: 30400, Loss: 0.002762, Time: 2:00:56.716031
I0818 22:19:33.993385 140034352527168 train_slot.py:155] Step: 30500, Loss: 0.002882, Time: 2:01:20.181584
I0818 22:19:57.504996 140034352527168 train_slot.py:155] Step: 30600, Loss: 0.003436, Time: 2:01:43.692915
I0818 22:20:20.971252 140034352527168 train_slot.py:155] Step: 30700, Loss: 0.002794, Time: 2:02:07.159458
I0818 22:20:44.618697 140034352527168 train_slot.py:155] Step: 30800, Loss: 0.002477, Time: 2:02:30.806905
I0818 22:21:07.989564 140034352527168 train_slot.py:155] Step: 30900, Loss: 0.002717, Time: 2:02:54.177680
I0818 22:21:31.713340 140034352527168 train_slot.py:155] Step: 31000, Loss: 0.002673, Time: 2:03:17.901516
I0818 22:21:32.115445 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-31000
I0818 22:21:33.197448 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 31000
I0818 22:21:57.005657 140034352527168 train_slot.py:155] Step: 31100, Loss: 0.003464, Time: 2:03:43.193852
I0818 22:22:20.524749 140034352527168 train_slot.py:155] Step: 31200, Loss: 0.002410, Time: 2:04:06.712688
I0818 22:22:44.127796 140034352527168 train_slot.py:155] Step: 31300, Loss: 0.003511, Time: 2:04:30.315993
I0818 22:23:07.566168 140034352527168 train_slot.py:155] Step: 31400, Loss: 0.003649, Time: 2:04:53.754368
I0818 22:23:31.267960 140034352527168 train_slot.py:155] Step: 31500, Loss: 0.002944, Time: 2:05:17.456163
I0818 22:23:54.750917 140034352527168 train_slot.py:155] Step: 31600, Loss: 0.002640, Time: 2:05:40.939152
I0818 22:24:18.223019 140034352527168 train_slot.py:155] Step: 31700, Loss: 0.003036, Time: 2:06:04.411223
I0818 22:24:41.733351 140034352527168 train_slot.py:155] Step: 31800, Loss: 0.003161, Time: 2:06:27.921498
I0818 22:25:05.130333 140034352527168 train_slot.py:155] Step: 31900, Loss: 0.004525, Time: 2:06:51.318305
I0818 22:25:28.827971 140034352527168 train_slot.py:155] Step: 32000, Loss: 0.003629, Time: 2:07:15.016176
I0818 22:25:29.168021 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-32000
I0818 22:25:30.239597 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 32000
I0818 22:25:53.693297 140034352527168 train_slot.py:155] Step: 32100, Loss: 0.002376, Time: 2:07:39.881525
I0818 22:26:17.298314 140034352527168 train_slot.py:155] Step: 32200, Loss: 0.002617, Time: 2:08:03.486439
I0818 22:26:41.006652 140034352527168 train_slot.py:155] Step: 32300, Loss: 0.002747, Time: 2:08:27.194864
I0818 22:27:04.570735 140034352527168 train_slot.py:155] Step: 32400, Loss: 0.003272, Time: 2:08:50.758946
I0818 22:27:28.107425 140034352527168 train_slot.py:155] Step: 32500, Loss: 0.002434, Time: 2:09:14.295322
I0818 22:27:52.153125 140034352527168 train_slot.py:155] Step: 32600, Loss: 0.002322, Time: 2:09:38.341198
I0818 22:28:15.767900 140034352527168 train_slot.py:155] Step: 32700, Loss: 0.002731, Time: 2:10:01.955918
I0818 22:28:39.260308 140034352527168 train_slot.py:155] Step: 32800, Loss: 0.002060, Time: 2:10:25.448485
I0818 22:29:02.795882 140034352527168 train_slot.py:155] Step: 32900, Loss: 0.002812, Time: 2:10:48.984088
I0818 22:29:26.426241 140034352527168 train_slot.py:155] Step: 33000, Loss: 0.002423, Time: 2:11:12.614470
I0818 22:29:26.738378 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-33000
I0818 22:29:27.807079 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 33000
I0818 22:29:51.515242 140034352527168 train_slot.py:155] Step: 33100, Loss: 0.002959, Time: 2:11:37.703363
I0818 22:30:15.070300 140034352527168 train_slot.py:155] Step: 33200, Loss: 0.002136, Time: 2:12:01.258502
I0818 22:30:38.672331 140034352527168 train_slot.py:155] Step: 33300, Loss: 0.002416, Time: 2:12:24.860541
I0818 22:31:02.225985 140034352527168 train_slot.py:155] Step: 33400, Loss: 0.002797, Time: 2:12:48.414136
I0818 22:31:25.700991 140034352527168 train_slot.py:155] Step: 33500, Loss: 0.003181, Time: 2:13:11.889150
I0818 22:31:49.272525 140034352527168 train_slot.py:155] Step: 33600, Loss: 0.003075, Time: 2:13:35.460723
I0818 22:32:13.081116 140034352527168 train_slot.py:155] Step: 33700, Loss: 0.002951, Time: 2:13:59.269235
I0818 22:32:36.433638 140034352527168 train_slot.py:155] Step: 33800, Loss: 0.002496, Time: 2:14:22.621860
I0818 22:32:59.907163 140034352527168 train_slot.py:155] Step: 33900, Loss: 0.002460, Time: 2:14:46.095360
I0818 22:33:23.373978 140034352527168 train_slot.py:155] Step: 34000, Loss: 0.002423, Time: 2:15:09.562178
I0818 22:33:23.771871 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-34000
I0818 22:33:24.842542 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 34000
I0818 22:33:48.351795 140034352527168 train_slot.py:155] Step: 34100, Loss: 0.002515, Time: 2:15:34.539902
I0818 22:34:12.076111 140034352527168 train_slot.py:155] Step: 34200, Loss: 0.003123, Time: 2:15:58.264302
I0818 22:34:35.536598 140034352527168 train_slot.py:155] Step: 34300, Loss: 0.002124, Time: 2:16:21.724803
I0818 22:34:59.116967 140034352527168 train_slot.py:155] Step: 34400, Loss: 0.002176, Time: 2:16:45.305100
I0818 22:35:22.609172 140034352527168 train_slot.py:155] Step: 34500, Loss: 0.002831, Time: 2:17:08.797349
I0818 22:35:46.368409 140034352527168 train_slot.py:155] Step: 34600, Loss: 0.002458, Time: 2:17:32.556609
I0818 22:36:10.076884 140034352527168 train_slot.py:155] Step: 34700, Loss: 0.003661, Time: 2:17:56.264814
I0818 22:36:33.770357 140034352527168 train_slot.py:155] Step: 34800, Loss: 0.002191, Time: 2:18:19.958562
I0818 22:36:57.363340 140034352527168 train_slot.py:155] Step: 34900, Loss: 0.002735, Time: 2:18:43.551453
I0818 22:37:20.846421 140034352527168 train_slot.py:155] Step: 35000, Loss: 0.002940, Time: 2:19:07.034626
I0818 22:37:21.179311 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-35000
I0818 22:37:22.312303 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 35000
I0818 22:37:45.927646 140034352527168 train_slot.py:155] Step: 35100, Loss: 0.004286, Time: 2:19:32.115875
I0818 22:38:09.361605 140034352527168 train_slot.py:155] Step: 35200, Loss: 0.002681, Time: 2:19:55.549740
I0818 22:38:33.155444 140034352527168 train_slot.py:155] Step: 35300, Loss: 0.002619, Time: 2:20:19.343640
I0818 22:38:56.676810 140034352527168 train_slot.py:155] Step: 35400, Loss: 0.002413, Time: 2:20:42.865011
I0818 22:39:20.188707 140034352527168 train_slot.py:155] Step: 35500, Loss: 0.002492, Time: 2:21:06.376687
I0818 22:39:43.770817 140034352527168 train_slot.py:155] Step: 35600, Loss: 0.002660, Time: 2:21:29.959037
I0818 22:40:07.337502 140034352527168 train_slot.py:155] Step: 35700, Loss: 0.002283, Time: 2:21:53.525703
I0818 22:40:30.987135 140034352527168 train_slot.py:155] Step: 35800, Loss: 0.002964, Time: 2:22:17.175334
I0818 22:40:54.568995 140034352527168 train_slot.py:155] Step: 35900, Loss: 0.002357, Time: 2:22:40.757082
I0818 22:41:18.019857 140034352527168 train_slot.py:155] Step: 36000, Loss: 0.002424, Time: 2:23:04.207956
I0818 22:41:18.382566 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-36000
I0818 22:41:19.491488 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 36000
I0818 22:41:42.988491 140034352527168 train_slot.py:155] Step: 36100, Loss: 0.002527, Time: 2:23:29.176696
I0818 22:42:06.713315 140034352527168 train_slot.py:155] Step: 36200, Loss: 0.002622, Time: 2:23:52.901546
I0818 22:42:30.306029 140034352527168 train_slot.py:155] Step: 36300, Loss: 0.002680, Time: 2:24:16.494228
I0818 22:42:54.309332 140034352527168 train_slot.py:155] Step: 36400, Loss: 0.002352, Time: 2:24:40.497459
I0818 22:43:17.927963 140034352527168 train_slot.py:155] Step: 36500, Loss: 0.002442, Time: 2:25:04.116161
I0818 22:43:41.557337 140034352527168 train_slot.py:155] Step: 36600, Loss: 0.002595, Time: 2:25:27.745356
I0818 22:44:05.120400 140034352527168 train_slot.py:155] Step: 36700, Loss: 0.002280, Time: 2:25:51.308597
I0818 22:44:28.664198 140034352527168 train_slot.py:155] Step: 36800, Loss: 0.003254, Time: 2:26:14.852407
I0818 22:44:52.491589 140034352527168 train_slot.py:155] Step: 36900, Loss: 0.002351, Time: 2:26:38.679817
I0818 22:45:16.073988 140034352527168 train_slot.py:155] Step: 37000, Loss: 0.002470, Time: 2:27:02.261962
I0818 22:45:16.454130 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-37000
I0818 22:45:17.592819 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 37000
I0818 22:45:40.987453 140034352527168 train_slot.py:155] Step: 37100, Loss: 0.002486, Time: 2:27:27.175652
I0818 22:46:04.428349 140034352527168 train_slot.py:155] Step: 37200, Loss: 0.002050, Time: 2:27:50.616549
I0818 22:46:27.957079 140034352527168 train_slot.py:155] Step: 37300, Loss: 0.002479, Time: 2:28:14.145283
I0818 22:46:51.413452 140034352527168 train_slot.py:155] Step: 37400, Loss: 0.002632, Time: 2:28:37.601439
I0818 22:47:15.176001 140034352527168 train_slot.py:155] Step: 37500, Loss: 0.002213, Time: 2:29:01.364223
I0818 22:47:38.762494 140034352527168 train_slot.py:155] Step: 37600, Loss: 0.002643, Time: 2:29:24.950700
I0818 22:48:02.247739 140034352527168 train_slot.py:155] Step: 37700, Loss: 0.002157, Time: 2:29:48.435751
I0818 22:48:25.765488 140034352527168 train_slot.py:155] Step: 37800, Loss: 0.002845, Time: 2:30:11.953627
I0818 22:48:49.267743 140034352527168 train_slot.py:155] Step: 37900, Loss: 0.002687, Time: 2:30:35.455969
I0818 22:49:13.171826 140034352527168 train_slot.py:155] Step: 38000, Loss: 0.002249, Time: 2:30:59.359854
I0818 22:49:13.572652 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-38000
I0818 22:49:14.657297 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 38000
I0818 22:49:38.542333 140034352527168 train_slot.py:155] Step: 38100, Loss: 0.003369, Time: 2:31:24.730544
I0818 22:50:02.017204 140034352527168 train_slot.py:155] Step: 38200, Loss: 0.002507, Time: 2:31:48.205228
I0818 22:50:25.552932 140034352527168 train_slot.py:155] Step: 38300, Loss: 0.002158, Time: 2:32:11.741069
I0818 22:50:48.980037 140034352527168 train_slot.py:155] Step: 38400, Loss: 0.002226, Time: 2:32:35.168245
I0818 22:51:12.452304 140034352527168 train_slot.py:155] Step: 38500, Loss: 0.002728, Time: 2:32:58.640383
I0818 22:51:36.425568 140034352527168 train_slot.py:155] Step: 38600, Loss: 0.002070, Time: 2:33:22.613775
I0818 22:51:59.856114 140034352527168 train_slot.py:155] Step: 38700, Loss: 0.002479, Time: 2:33:46.044314
I0818 22:52:23.451444 140034352527168 train_slot.py:155] Step: 38800, Loss: 0.002104, Time: 2:34:09.639453
I0818 22:52:46.926608 140034352527168 train_slot.py:155] Step: 38900, Loss: 0.003067, Time: 2:34:33.114740
I0818 22:53:10.475363 140034352527168 train_slot.py:155] Step: 39000, Loss: 0.002327, Time: 2:34:56.663595
I0818 22:53:10.842912 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-39000
I0818 22:53:11.918897 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 39000
I0818 22:53:35.671292 140034352527168 train_slot.py:155] Step: 39100, Loss: 0.002122, Time: 2:35:21.859493
I0818 22:53:59.106707 140034352527168 train_slot.py:155] Step: 39200, Loss: 0.002847, Time: 2:35:45.294729
I0818 22:54:22.563405 140034352527168 train_slot.py:155] Step: 39300, Loss: 0.002411, Time: 2:36:08.751617
I0818 22:54:46.069145 140034352527168 train_slot.py:155] Step: 39400, Loss: 0.002453, Time: 2:36:32.257354
I0818 22:55:09.644823 140034352527168 train_slot.py:155] Step: 39500, Loss: 0.002404, Time: 2:36:55.832864
I0818 22:55:33.338595 140034352527168 train_slot.py:155] Step: 39600, Loss: 0.002185, Time: 2:37:19.526815
I0818 22:55:56.783978 140034352527168 train_slot.py:155] Step: 39700, Loss: 0.002394, Time: 2:37:42.972181
I0818 22:56:20.350222 140034352527168 train_slot.py:155] Step: 39800, Loss: 0.002341, Time: 2:38:06.538352
I0818 22:56:43.898816 140034352527168 train_slot.py:155] Step: 39900, Loss: 0.003219, Time: 2:38:30.086953
I0818 22:57:07.314614 140034352527168 train_slot.py:155] Step: 40000, Loss: 0.002125, Time: 2:38:53.502844
I0818 22:57:07.688621 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-40000
I0818 22:57:08.885223 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 40000
I0818 22:57:32.367798 140034352527168 train_slot.py:155] Step: 40100, Loss: 0.002478, Time: 2:39:18.556006
I0818 22:57:56.118559 140034352527168 train_slot.py:155] Step: 40200, Loss: 0.002438, Time: 2:39:42.306757
I0818 22:58:19.707344 140034352527168 train_slot.py:155] Step: 40300, Loss: 0.002200, Time: 2:40:05.895480
I0818 22:58:43.229533 140034352527168 train_slot.py:155] Step: 40400, Loss: 0.002444, Time: 2:40:29.417743
I0818 22:59:06.978869 140034352527168 train_slot.py:155] Step: 40500, Loss: 0.002379, Time: 2:40:53.167069
I0818 22:59:30.492911 140034352527168 train_slot.py:155] Step: 40600, Loss: 0.003434, Time: 2:41:16.681040
I0818 22:59:54.405069 140034352527168 train_slot.py:155] Step: 40700, Loss: 0.001926, Time: 2:41:40.593257
I0818 23:00:17.829529 140034352527168 train_slot.py:155] Step: 40800, Loss: 0.002778, Time: 2:42:04.017733
I0818 23:00:41.277688 140034352527168 train_slot.py:155] Step: 40900, Loss: 0.002640, Time: 2:42:27.465889
I0818 23:01:04.805150 140034352527168 train_slot.py:155] Step: 41000, Loss: 0.001861, Time: 2:42:50.993070
I0818 23:01:05.190840 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-41000
I0818 23:01:06.323278 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 41000
I0818 23:01:29.829666 140034352527168 train_slot.py:155] Step: 41100, Loss: 0.003414, Time: 2:43:16.017895
I0818 23:01:53.352413 140034352527168 train_slot.py:155] Step: 41200, Loss: 0.002115, Time: 2:43:39.540615
I0818 23:02:17.078974 140034352527168 train_slot.py:155] Step: 41300, Loss: 0.002222, Time: 2:44:03.266970
I0818 23:02:40.631637 140034352527168 train_slot.py:155] Step: 41400, Loss: 0.002385, Time: 2:44:26.819824
I0818 23:03:04.142437 140034352527168 train_slot.py:155] Step: 41500, Loss: 0.002260, Time: 2:44:50.330666
I0818 23:03:27.700354 140034352527168 train_slot.py:155] Step: 41600, Loss: 0.002498, Time: 2:45:13.888555
I0818 23:03:51.188045 140034352527168 train_slot.py:155] Step: 41700, Loss: 0.002285, Time: 2:45:37.376068
I0818 23:04:14.911703 140034352527168 train_slot.py:155] Step: 41800, Loss: 0.002775, Time: 2:46:01.099935
I0818 23:04:38.405556 140034352527168 train_slot.py:155] Step: 41900, Loss: 0.002266, Time: 2:46:24.593764
I0818 23:05:01.985638 140034352527168 train_slot.py:155] Step: 42000, Loss: 0.002312, Time: 2:46:48.173768
I0818 23:05:02.346168 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-42000
I0818 23:05:03.411684 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 42000
I0818 23:05:26.959676 140034352527168 train_slot.py:155] Step: 42100, Loss: 0.002313, Time: 2:47:13.147828
I0818 23:05:50.376673 140034352527168 train_slot.py:155] Step: 42200, Loss: 0.001747, Time: 2:47:36.564873
I0818 23:06:13.893889 140034352527168 train_slot.py:155] Step: 42300, Loss: 0.002300, Time: 2:48:00.082090
I0818 23:06:37.775599 140034352527168 train_slot.py:155] Step: 42400, Loss: 0.002129, Time: 2:48:23.963617
I0818 23:07:01.339596 140034352527168 train_slot.py:155] Step: 42500, Loss: 0.001863, Time: 2:48:47.527797
I0818 23:07:24.847233 140034352527168 train_slot.py:155] Step: 42600, Loss: 0.002524, Time: 2:49:11.035432
I0818 23:07:48.425189 140034352527168 train_slot.py:155] Step: 42700, Loss: 0.002544, Time: 2:49:34.612685
I0818 23:08:11.933026 140034352527168 train_slot.py:155] Step: 42800, Loss: 0.002067, Time: 2:49:58.121242
I0818 23:08:35.939046 140034352527168 train_slot.py:155] Step: 42900, Loss: 0.002024, Time: 2:50:22.127252
I0818 23:08:59.397249 140034352527168 train_slot.py:155] Step: 43000, Loss: 0.002768, Time: 2:50:45.585230
I0818 23:08:59.741420 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-43000
I0818 23:09:00.842964 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 43000
I0818 23:09:24.457020 140034352527168 train_slot.py:155] Step: 43100, Loss: 0.002890, Time: 2:51:10.645216
I0818 23:09:47.927722 140034352527168 train_slot.py:155] Step: 43200, Loss: 0.002184, Time: 2:51:34.115926
I0818 23:10:11.463047 140034352527168 train_slot.py:155] Step: 43300, Loss: 0.002093, Time: 2:51:57.651031
I0818 23:10:35.270520 140034352527168 train_slot.py:155] Step: 43400, Loss: 0.002446, Time: 2:52:21.458529
I0818 23:10:58.807098 140034352527168 train_slot.py:155] Step: 43500, Loss: 0.002402, Time: 2:52:44.995315
I0818 23:11:22.379863 140034352527168 train_slot.py:155] Step: 43600, Loss: 0.002333, Time: 2:53:08.567984
I0818 23:11:45.970788 140034352527168 train_slot.py:155] Step: 43700, Loss: 0.002574, Time: 2:53:32.158981
I0818 23:12:09.523665 140034352527168 train_slot.py:155] Step: 43800, Loss: 0.002339, Time: 2:53:55.711864
I0818 23:12:32.942088 140034352527168 train_slot.py:155] Step: 43900, Loss: 0.002285, Time: 2:54:19.130109
I0818 23:12:56.682242 140034352527168 train_slot.py:155] Step: 44000, Loss: 0.002338, Time: 2:54:42.870466
I0818 23:12:57.073338 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-44000
I0818 23:12:58.196449 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 44000
I0818 23:13:21.809564 140034352527168 train_slot.py:155] Step: 44100, Loss: 0.002501, Time: 2:55:07.997796
I0818 23:13:45.342911 140034352527168 train_slot.py:155] Step: 44200, Loss: 0.002124, Time: 2:55:31.531053
I0818 23:14:08.863809 140034352527168 train_slot.py:155] Step: 44300, Loss: 0.002289, Time: 2:55:55.052007
I0818 23:14:32.337842 140034352527168 train_slot.py:155] Step: 44400, Loss: 0.002337, Time: 2:56:18.526039
I0818 23:14:56.100877 140034352527168 train_slot.py:155] Step: 44500, Loss: 0.001971, Time: 2:56:42.289034
I0818 23:15:19.640410 140034352527168 train_slot.py:155] Step: 44600, Loss: 0.002696, Time: 2:57:05.828601
I0818 23:15:43.170710 140034352527168 train_slot.py:155] Step: 44700, Loss: 0.002577, Time: 2:57:29.358908
I0818 23:16:06.711308 140034352527168 train_slot.py:155] Step: 44800, Loss: 0.002363, Time: 2:57:52.899433
I0818 23:16:30.214035 140034352527168 train_slot.py:155] Step: 44900, Loss: 0.002218, Time: 2:58:16.402272
I0818 23:16:53.726113 140034352527168 train_slot.py:155] Step: 45000, Loss: 0.002134, Time: 2:58:39.914309
I0818 23:16:54.101652 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-45000
I0818 23:16:55.231175 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 45000
I0818 23:17:19.577181 140034352527168 train_slot.py:155] Step: 45100, Loss: 0.002918, Time: 2:59:05.765383
I0818 23:17:43.087032 140034352527168 train_slot.py:155] Step: 45200, Loss: 0.002618, Time: 2:59:29.275156
I0818 23:18:06.532135 140034352527168 train_slot.py:155] Step: 45300, Loss: 0.002210, Time: 2:59:52.720361
I0818 23:18:30.140915 140034352527168 train_slot.py:155] Step: 45400, Loss: 0.002295, Time: 3:00:16.329135
I0818 23:18:53.783939 140034352527168 train_slot.py:155] Step: 45500, Loss: 0.001966, Time: 3:00:39.971954
I0818 23:19:17.904434 140034352527168 train_slot.py:155] Step: 45600, Loss: 0.002540, Time: 3:01:04.092614
I0818 23:19:41.978374 140034352527168 train_slot.py:155] Step: 45700, Loss: 0.002394, Time: 3:01:28.166572
I0818 23:20:05.544806 140034352527168 train_slot.py:155] Step: 45800, Loss: 0.002473, Time: 3:01:51.732483
I0818 23:20:29.056556 140034352527168 train_slot.py:155] Step: 45900, Loss: 0.002103, Time: 3:02:15.244788
I0818 23:20:52.587396 140034352527168 train_slot.py:155] Step: 46000, Loss: 0.002144, Time: 3:02:38.775463
I0818 23:20:52.921764 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-46000
I0818 23:20:53.994418 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 46000
I0818 23:21:17.398083 140034352527168 train_slot.py:155] Step: 46100, Loss: 0.001865, Time: 3:03:03.586282
I0818 23:21:41.111430 140034352527168 train_slot.py:155] Step: 46200, Loss: 0.001925, Time: 3:03:27.299541
I0818 23:22:04.668950 140034352527168 train_slot.py:155] Step: 46300, Loss: 0.002549, Time: 3:03:50.857156
I0818 23:22:28.165264 140034352527168 train_slot.py:155] Step: 46400, Loss: 0.002313, Time: 3:04:14.353333
I0818 23:22:51.687784 140034352527168 train_slot.py:155] Step: 46500, Loss: 0.002452, Time: 3:04:37.875926
I0818 23:23:15.097151 140034352527168 train_slot.py:155] Step: 46600, Loss: 0.002137, Time: 3:05:01.285382
I0818 23:23:38.871826 140034352527168 train_slot.py:155] Step: 46700, Loss: 0.002926, Time: 3:05:25.059605
I0818 23:24:02.418644 140034352527168 train_slot.py:155] Step: 46800, Loss: 0.002032, Time: 3:05:48.606836
I0818 23:24:26.033942 140034352527168 train_slot.py:155] Step: 46900, Loss: 0.002527, Time: 3:06:12.222146
I0818 23:24:49.556814 140034352527168 train_slot.py:155] Step: 47000, Loss: 0.002097, Time: 3:06:35.744921
I0818 23:24:49.923680 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-47000
I0818 23:24:50.994740 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 47000
I0818 23:25:14.524310 140034352527168 train_slot.py:155] Step: 47100, Loss: 0.002189, Time: 3:07:00.712456
I0818 23:25:38.173847 140034352527168 train_slot.py:155] Step: 47200, Loss: 0.002078, Time: 3:07:24.362077
I0818 23:26:01.583449 140034352527168 train_slot.py:155] Step: 47300, Loss: 0.001904, Time: 3:07:47.771679
I0818 23:26:25.342187 140034352527168 train_slot.py:155] Step: 47400, Loss: 0.001856, Time: 3:08:11.530088
I0818 23:26:48.960081 140034352527168 train_slot.py:155] Step: 47500, Loss: 0.001892, Time: 3:08:35.148284
I0818 23:27:12.554759 140034352527168 train_slot.py:155] Step: 47600, Loss: 0.002111, Time: 3:08:58.742957
I0818 23:27:36.105486 140034352527168 train_slot.py:155] Step: 47700, Loss: 0.002314, Time: 3:09:22.293537
I0818 23:27:59.807312 140034352527168 train_slot.py:155] Step: 47800, Loss: 0.002250, Time: 3:09:45.995493
I0818 23:28:23.432859 140034352527168 train_slot.py:155] Step: 47900, Loss: 0.002086, Time: 3:10:09.621043
I0818 23:28:46.960221 140034352527168 train_slot.py:155] Step: 48000, Loss: 0.002036, Time: 3:10:33.148359
I0818 23:28:47.326949 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-48000
I0818 23:28:48.400792 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 48000
I0818 23:29:11.905236 140034352527168 train_slot.py:155] Step: 48100, Loss: 0.002772, Time: 3:10:58.093423
I0818 23:29:35.265113 140034352527168 train_slot.py:155] Step: 48200, Loss: 0.002437, Time: 3:11:21.453314
I0818 23:29:59.048585 140034352527168 train_slot.py:155] Step: 48300, Loss: 0.002444, Time: 3:11:45.236780
I0818 23:30:22.858278 140034352527168 train_slot.py:155] Step: 48400, Loss: 0.001943, Time: 3:12:09.046275
I0818 23:30:46.651753 140034352527168 train_slot.py:155] Step: 48500, Loss: 0.002207, Time: 3:12:32.839955
I0818 23:31:10.178966 140034352527168 train_slot.py:155] Step: 48600, Loss: 0.001586, Time: 3:12:56.366951
I0818 23:31:33.637930 140034352527168 train_slot.py:155] Step: 48700, Loss: 0.002183, Time: 3:13:19.826132
I0818 23:31:57.107500 140034352527168 train_slot.py:155] Step: 48800, Loss: 0.002575, Time: 3:13:43.295701
I0818 23:32:20.851684 140034352527168 train_slot.py:155] Step: 48900, Loss: 0.002163, Time: 3:14:07.039886
I0818 23:32:44.607300 140034352527168 train_slot.py:155] Step: 49000, Loss: 0.002556, Time: 3:14:30.795446
I0818 23:32:44.957904 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-49000
I0818 23:32:46.032316 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 49000
I0818 23:33:09.546809 140034352527168 train_slot.py:155] Step: 49100, Loss: 0.001877, Time: 3:14:55.735021
I0818 23:33:33.321606 140034352527168 train_slot.py:155] Step: 49200, Loss: 0.002294, Time: 3:15:19.509812
I0818 23:33:56.845145 140034352527168 train_slot.py:155] Step: 49300, Loss: 0.002187, Time: 3:15:43.033274
I0818 23:34:20.455302 140034352527168 train_slot.py:155] Step: 49400, Loss: 0.002429, Time: 3:16:06.643489
I0818 23:34:43.947397 140034352527168 train_slot.py:155] Step: 49500, Loss: 0.001900, Time: 3:16:30.135602
I0818 23:35:07.420076 140034352527168 train_slot.py:155] Step: 49600, Loss: 0.001818, Time: 3:16:53.608204
I0818 23:35:30.965439 140034352527168 train_slot.py:155] Step: 49700, Loss: 0.002332, Time: 3:17:17.153627
I0818 23:35:54.425423 140034352527168 train_slot.py:155] Step: 49800, Loss: 0.002235, Time: 3:17:40.613623
I0818 23:36:17.983407 140034352527168 train_slot.py:155] Step: 49900, Loss: 0.002206, Time: 3:18:04.171303
I0818 23:36:41.709433 140034352527168 train_slot.py:155] Step: 50000, Loss: 0.002098, Time: 3:18:27.897590
I0818 23:36:42.050879 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-50000
I0818 23:36:43.185388 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 50000
I0818 23:37:06.802762 140034352527168 train_slot.py:155] Step: 50100, Loss: 0.002444, Time: 3:18:52.990963
I0818 23:37:30.375703 140034352527168 train_slot.py:155] Step: 50200, Loss: 0.001917, Time: 3:19:16.563823
I0818 23:37:54.026317 140034352527168 train_slot.py:155] Step: 50300, Loss: 0.001987, Time: 3:19:40.214491
I0818 23:38:17.760761 140034352527168 train_slot.py:155] Step: 50400, Loss: 0.002068, Time: 3:20:03.948995
I0818 23:38:41.463992 140034352527168 train_slot.py:155] Step: 50500, Loss: 0.001784, Time: 3:20:27.652183
I0818 23:39:04.825304 140034352527168 train_slot.py:155] Step: 50600, Loss: 0.002097, Time: 3:20:51.012939
I0818 23:39:28.335068 140034352527168 train_slot.py:155] Step: 50700, Loss: 0.002251, Time: 3:21:14.523268
I0818 23:39:51.789389 140034352527168 train_slot.py:155] Step: 50800, Loss: 0.002123, Time: 3:21:37.977587
I0818 23:40:15.282833 140034352527168 train_slot.py:155] Step: 50900, Loss: 0.001844, Time: 3:22:01.471031
I0818 23:40:39.044512 140034352527168 train_slot.py:155] Step: 51000, Loss: 0.002390, Time: 3:22:25.232472
I0818 23:40:39.433409 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-51000
I0818 23:40:40.500156 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 51000
I0818 23:41:04.083952 140034352527168 train_slot.py:155] Step: 51100, Loss: 0.002294, Time: 3:22:50.272180
I0818 23:41:27.569555 140034352527168 train_slot.py:155] Step: 51200, Loss: 0.002310, Time: 3:23:13.757755
I0818 23:41:51.039465 140034352527168 train_slot.py:155] Step: 51300, Loss: 0.001820, Time: 3:23:37.227564
I0818 23:42:14.445030 140034352527168 train_slot.py:155] Step: 51400, Loss: 0.002185, Time: 3:24:00.633202
I0818 23:42:37.899266 140034352527168 train_slot.py:155] Step: 51500, Loss: 0.002136, Time: 3:24:24.087471
I0818 23:43:01.866037 140034352527168 train_slot.py:155] Step: 51600, Loss: 0.002068, Time: 3:24:48.054155
I0818 23:43:25.336776 140034352527168 train_slot.py:155] Step: 51700, Loss: 0.002141, Time: 3:25:11.524926
I0818 23:43:48.807082 140034352527168 train_slot.py:155] Step: 51800, Loss: 0.001860, Time: 3:25:34.995280
I0818 23:44:12.213162 140034352527168 train_slot.py:155] Step: 51900, Loss: 0.002043, Time: 3:25:58.401371
I0818 23:44:35.572743 140034352527168 train_slot.py:155] Step: 52000, Loss: 0.002144, Time: 3:26:21.760802
I0818 23:44:35.905605 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-52000
I0818 23:44:36.976474 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 52000
I0818 23:45:00.612665 140034352527168 train_slot.py:155] Step: 52100, Loss: 0.001808, Time: 3:26:46.800848
I0818 23:45:23.965686 140034352527168 train_slot.py:155] Step: 52200, Loss: 0.002106, Time: 3:27:10.153883
I0818 23:45:47.401089 140034352527168 train_slot.py:155] Step: 52300, Loss: 0.002060, Time: 3:27:33.589218
I0818 23:46:10.850676 140034352527168 train_slot.py:155] Step: 52400, Loss: 0.001842, Time: 3:27:57.038873
I0818 23:46:34.336262 140034352527168 train_slot.py:155] Step: 52500, Loss: 0.002174, Time: 3:28:20.524398
I0818 23:46:57.873035 140034352527168 train_slot.py:155] Step: 52600, Loss: 0.001934, Time: 3:28:44.061233
I0818 23:47:22.116058 140034352527168 train_slot.py:155] Step: 52700, Loss: 0.001804, Time: 3:29:08.304048
I0818 23:47:45.590937 140034352527168 train_slot.py:155] Step: 52800, Loss: 0.001782, Time: 3:29:31.779137
I0818 23:48:09.354701 140034352527168 train_slot.py:155] Step: 52900, Loss: 0.001917, Time: 3:29:55.542895
I0818 23:48:33.133191 140034352527168 train_slot.py:155] Step: 53000, Loss: 0.002314, Time: 3:30:19.321395
I0818 23:48:33.459005 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-53000
I0818 23:48:34.578470 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 53000
I0818 23:48:58.135483 140034352527168 train_slot.py:155] Step: 53100, Loss: 0.001840, Time: 3:30:44.323679
I0818 23:49:21.847234 140034352527168 train_slot.py:155] Step: 53200, Loss: 0.001746, Time: 3:31:08.035357
I0818 23:49:45.349356 140034352527168 train_slot.py:155] Step: 53300, Loss: 0.002362, Time: 3:31:31.537586
I0818 23:50:08.900934 140034352527168 train_slot.py:155] Step: 53400, Loss: 0.002000, Time: 3:31:55.089149
I0818 23:50:32.357749 140034352527168 train_slot.py:155] Step: 53500, Loss: 0.002412, Time: 3:32:18.545981
I0818 23:50:55.854686 140034352527168 train_slot.py:155] Step: 53600, Loss: 0.002178, Time: 3:32:42.042814
I0818 23:51:19.324057 140034352527168 train_slot.py:155] Step: 53700, Loss: 0.001877, Time: 3:33:05.512264
I0818 23:51:43.089559 140034352527168 train_slot.py:155] Step: 53800, Loss: 0.001775, Time: 3:33:29.277757
I0818 23:52:06.698432 140034352527168 train_slot.py:155] Step: 53900, Loss: 0.002094, Time: 3:33:52.886576
I0818 23:52:30.302493 140034352527168 train_slot.py:155] Step: 54000, Loss: 0.002402, Time: 3:34:16.490692
I0818 23:52:30.670233 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-54000
I0818 23:52:31.740033 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 54000
I0818 23:52:55.518883 140034352527168 train_slot.py:155] Step: 54100, Loss: 0.001909, Time: 3:34:41.707079
I0818 23:53:19.092020 140034352527168 train_slot.py:155] Step: 54200, Loss: 0.001832, Time: 3:35:05.280223
I0818 23:53:42.894325 140034352527168 train_slot.py:155] Step: 54300, Loss: 0.001967, Time: 3:35:29.082438
I0818 23:54:06.525262 140034352527168 train_slot.py:155] Step: 54400, Loss: 0.001823, Time: 3:35:52.713462
I0818 23:54:30.128112 140034352527168 train_slot.py:155] Step: 54500, Loss: 0.002427, Time: 3:36:16.316113
I0818 23:54:53.893957 140034352527168 train_slot.py:155] Step: 54600, Loss: 0.001837, Time: 3:36:40.082161
I0818 23:55:17.329462 140034352527168 train_slot.py:155] Step: 54700, Loss: 0.001657, Time: 3:37:03.517659
I0818 23:55:41.139260 140034352527168 train_slot.py:155] Step: 54800, Loss: 0.001936, Time: 3:37:27.327458
I0818 23:56:04.689262 140034352527168 train_slot.py:155] Step: 54900, Loss: 0.002026, Time: 3:37:50.877403
I0818 23:56:28.186382 140034352527168 train_slot.py:155] Step: 55000, Loss: 0.001784, Time: 3:38:14.374537
I0818 23:56:28.579154 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-55000
I0818 23:56:29.697243 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 55000
I0818 23:56:53.219298 140034352527168 train_slot.py:155] Step: 55100, Loss: 0.001768, Time: 3:38:39.407531
I0818 23:57:16.751308 140034352527168 train_slot.py:155] Step: 55200, Loss: 0.002201, Time: 3:39:02.939516
I0818 23:57:40.190560 140034352527168 train_slot.py:155] Step: 55300, Loss: 0.002030, Time: 3:39:26.378607
I0818 23:58:03.969392 140034352527168 train_slot.py:155] Step: 55400, Loss: 0.001989, Time: 3:39:50.157568
I0818 23:58:27.456946 140034352527168 train_slot.py:155] Step: 55500, Loss: 0.001934, Time: 3:40:13.645177
I0818 23:58:51.022691 140034352527168 train_slot.py:155] Step: 55600, Loss: 0.002099, Time: 3:40:37.210796
I0818 23:59:14.469700 140034352527168 train_slot.py:155] Step: 55700, Loss: 0.002309, Time: 3:41:00.657872
I0818 23:59:37.938316 140034352527168 train_slot.py:155] Step: 55800, Loss: 0.002312, Time: 3:41:24.126550
I0819 00:00:01.664374 140034352527168 train_slot.py:155] Step: 55900, Loss: 0.002205, Time: 3:41:47.852571
I0819 00:00:25.142014 140034352527168 train_slot.py:155] Step: 56000, Loss: 0.002129, Time: 3:42:11.330049
I0819 00:00:25.540492 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-56000
I0819 00:00:26.680590 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 56000
I0819 00:00:50.223390 140034352527168 train_slot.py:155] Step: 56100, Loss: 0.002323, Time: 3:42:36.411619
I0819 00:01:13.950440 140034352527168 train_slot.py:155] Step: 56200, Loss: 0.001537, Time: 3:43:00.138641
I0819 00:01:37.478920 140034352527168 train_slot.py:155] Step: 56300, Loss: 0.001918, Time: 3:43:23.667123
I0819 00:02:00.882373 140034352527168 train_slot.py:155] Step: 56400, Loss: 0.002347, Time: 3:43:47.070477
I0819 00:02:24.640799 140034352527168 train_slot.py:155] Step: 56500, Loss: 0.002300, Time: 3:44:10.829013
I0819 00:02:48.153251 140034352527168 train_slot.py:155] Step: 56600, Loss: 0.001895, Time: 3:44:34.341449
I0819 00:03:11.536704 140034352527168 train_slot.py:155] Step: 56700, Loss: 0.002036, Time: 3:44:57.724838
I0819 00:03:35.063413 140034352527168 train_slot.py:155] Step: 56800, Loss: 0.002681, Time: 3:45:21.251619
I0819 00:03:58.532642 140034352527168 train_slot.py:155] Step: 56900, Loss: 0.001959, Time: 3:45:44.720841
I0819 00:04:22.358888 140034352527168 train_slot.py:155] Step: 57000, Loss: 0.001948, Time: 3:46:08.547085
I0819 00:04:22.723231 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-57000
I0819 00:04:23.796001 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 57000
I0819 00:04:47.319191 140034352527168 train_slot.py:155] Step: 57100, Loss: 0.002415, Time: 3:46:33.507211
I0819 00:05:11.233562 140034352527168 train_slot.py:155] Step: 57200, Loss: 0.001889, Time: 3:46:57.421778
I0819 00:05:34.840597 140034352527168 train_slot.py:155] Step: 57300, Loss: 0.002336, Time: 3:47:21.028795
I0819 00:05:58.536615 140034352527168 train_slot.py:155] Step: 57400, Loss: 0.002032, Time: 3:47:44.724822
I0819 00:06:22.340579 140034352527168 train_slot.py:155] Step: 57500, Loss: 0.001952, Time: 3:48:08.528696
I0819 00:06:46.115209 140034352527168 train_slot.py:155] Step: 57600, Loss: 0.002391, Time: 3:48:32.303395
I0819 00:07:09.609577 140034352527168 train_slot.py:155] Step: 57700, Loss: 0.001748, Time: 3:48:55.797776
I0819 00:07:33.107702 140034352527168 train_slot.py:155] Step: 57800, Loss: 0.002538, Time: 3:49:19.295666
I0819 00:07:56.644941 140034352527168 train_slot.py:155] Step: 57900, Loss: 0.002006, Time: 3:49:42.833149
I0819 00:08:20.200412 140034352527168 train_slot.py:155] Step: 58000, Loss: 0.001819, Time: 3:50:06.388552
I0819 00:08:20.526030 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-58000
I0819 00:08:21.659266 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 58000
I0819 00:08:45.381296 140034352527168 train_slot.py:155] Step: 58100, Loss: 0.002211, Time: 3:50:31.569469
I0819 00:09:08.911178 140034352527168 train_slot.py:155] Step: 58200, Loss: 0.002421, Time: 3:50:55.099407
I0819 00:09:32.368119 140034352527168 train_slot.py:155] Step: 58300, Loss: 0.002033, Time: 3:51:18.556282
I0819 00:09:55.912389 140034352527168 train_slot.py:155] Step: 58400, Loss: 0.001822, Time: 3:51:42.100405
I0819 00:10:19.283923 140034352527168 train_slot.py:155] Step: 58500, Loss: 0.001795, Time: 3:52:05.472120
I0819 00:10:43.218288 140034352527168 train_slot.py:155] Step: 58600, Loss: 0.002754, Time: 3:52:29.406483
I0819 00:11:06.833714 140034352527168 train_slot.py:155] Step: 58700, Loss: 0.002320, Time: 3:52:53.021717
I0819 00:11:30.310580 140034352527168 train_slot.py:155] Step: 58800, Loss: 0.001521, Time: 3:53:16.498787
I0819 00:11:53.749967 140034352527168 train_slot.py:155] Step: 58900, Loss: 0.002311, Time: 3:53:39.938163
I0819 00:12:17.282972 140034352527168 train_slot.py:155] Step: 59000, Loss: 0.001647, Time: 3:54:03.471112
I0819 00:12:17.623747 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-59000
I0819 00:12:18.698697 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 59000
I0819 00:12:42.196974 140034352527168 train_slot.py:155] Step: 59100, Loss: 0.001956, Time: 3:54:28.385180
I0819 00:13:06.080169 140034352527168 train_slot.py:155] Step: 59200, Loss: 0.002024, Time: 3:54:52.268366
I0819 00:13:29.442418 140034352527168 train_slot.py:155] Step: 59300, Loss: 0.001737, Time: 3:55:15.630647
I0819 00:13:52.967601 140034352527168 train_slot.py:155] Step: 59400, Loss: 0.002332, Time: 3:55:39.155799
I0819 00:14:16.396188 140034352527168 train_slot.py:155] Step: 59500, Loss: 0.001949, Time: 3:56:02.584396
I0819 00:14:39.884443 140034352527168 train_slot.py:155] Step: 59600, Loss: 0.001907, Time: 3:56:26.072437
I0819 00:15:03.678337 140034352527168 train_slot.py:155] Step: 59700, Loss: 0.001805, Time: 3:56:49.866545
I0819 00:15:27.236630 140034352527168 train_slot.py:155] Step: 59800, Loss: 0.002109, Time: 3:57:13.424692
I0819 00:15:50.961392 140034352527168 train_slot.py:155] Step: 59900, Loss: 0.002366, Time: 3:57:37.149568
I0819 00:16:14.737261 140034352527168 train_slot.py:155] Step: 60000, Loss: 0.001975, Time: 3:58:00.925481
I0819 00:16:15.057432 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-60000
I0819 00:16:16.158068 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 60000
I0819 00:16:39.636578 140034352527168 train_slot.py:155] Step: 60100, Loss: 0.002340, Time: 3:58:25.824777
I0819 00:17:03.107929 140034352527168 train_slot.py:155] Step: 60200, Loss: 0.001982, Time: 3:58:49.296080
I0819 00:17:27.087053 140034352527168 train_slot.py:155] Step: 60300, Loss: 0.002114, Time: 3:59:13.275161
I0819 00:17:51.066931 140034352527168 train_slot.py:155] Step: 60400, Loss: 0.002218, Time: 3:59:37.255139
I0819 00:18:14.889818 140034352527168 train_slot.py:155] Step: 60500, Loss: 0.002009, Time: 4:00:01.077889
I0819 00:18:38.825999 140034352527168 train_slot.py:155] Step: 60600, Loss: 0.002605, Time: 4:00:25.014203
I0819 00:19:02.689932 140034352527168 train_slot.py:155] Step: 60700, Loss: 0.001809, Time: 4:00:48.878126
I0819 00:19:26.867449 140034352527168 train_slot.py:155] Step: 60800, Loss: 0.001791, Time: 4:01:13.055452
I0819 00:19:50.365126 140034352527168 train_slot.py:155] Step: 60900, Loss: 0.001941, Time: 4:01:36.553288
I0819 00:20:13.791243 140034352527168 train_slot.py:155] Step: 61000, Loss: 0.001665, Time: 4:01:59.979442
I0819 00:20:14.118181 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-61000
I0819 00:20:15.251186 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 61000
I0819 00:20:38.902651 140034352527168 train_slot.py:155] Step: 61100, Loss: 0.001493, Time: 4:02:25.090861
I0819 00:21:02.393555 140034352527168 train_slot.py:155] Step: 61200, Loss: 0.001512, Time: 4:02:48.581683
I0819 00:21:26.142492 140034352527168 train_slot.py:155] Step: 61300, Loss: 0.002122, Time: 4:03:12.330713
I0819 00:21:49.654628 140034352527168 train_slot.py:155] Step: 61400, Loss: 0.001823, Time: 4:03:35.842833
I0819 00:22:13.116805 140034352527168 train_slot.py:155] Step: 61500, Loss: 0.001857, Time: 4:03:59.305035
I0819 00:22:36.535811 140034352527168 train_slot.py:155] Step: 61600, Loss: 0.001970, Time: 4:04:22.723926
I0819 00:23:00.101569 140034352527168 train_slot.py:155] Step: 61700, Loss: 0.001955, Time: 4:04:46.289672
I0819 00:23:23.575242 140034352527168 train_slot.py:155] Step: 61800, Loss: 0.001660, Time: 4:05:09.763461
I0819 00:23:47.564102 140034352527168 train_slot.py:155] Step: 61900, Loss: 0.001861, Time: 4:05:33.752309
I0819 00:24:11.329959 140034352527168 train_slot.py:155] Step: 62000, Loss: 0.002122, Time: 4:05:57.517961
I0819 00:24:11.675007 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-62000
I0819 00:24:12.745984 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 62000
I0819 00:24:36.517317 140034352527168 train_slot.py:155] Step: 62100, Loss: 0.002132, Time: 4:06:22.705488
I0819 00:25:00.263713 140034352527168 train_slot.py:155] Step: 62200, Loss: 0.001680, Time: 4:06:46.451943
I0819 00:25:23.753729 140034352527168 train_slot.py:155] Step: 62300, Loss: 0.002088, Time: 4:07:09.941775
I0819 00:25:47.443995 140034352527168 train_slot.py:155] Step: 62400, Loss: 0.001644, Time: 4:07:33.632137
I0819 00:26:10.956398 140034352527168 train_slot.py:155] Step: 62500, Loss: 0.001528, Time: 4:07:57.144633
I0819 00:26:34.552031 140034352527168 train_slot.py:155] Step: 62600, Loss: 0.002215, Time: 4:08:20.740047
I0819 00:26:58.167752 140034352527168 train_slot.py:155] Step: 62700, Loss: 0.001856, Time: 4:08:44.355850
I0819 00:27:21.692439 140034352527168 train_slot.py:155] Step: 62800, Loss: 0.002339, Time: 4:09:07.880637
I0819 00:27:45.111658 140034352527168 train_slot.py:155] Step: 62900, Loss: 0.001735, Time: 4:09:31.299783
I0819 00:28:08.857888 140034352527168 train_slot.py:155] Step: 63000, Loss: 0.001806, Time: 4:09:55.046084
I0819 00:28:09.229098 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-63000
I0819 00:28:10.298407 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 63000
I0819 00:28:33.931920 140034352527168 train_slot.py:155] Step: 63100, Loss: 0.001547, Time: 4:10:20.120149
I0819 00:28:57.397938 140034352527168 train_slot.py:155] Step: 63200, Loss: 0.001855, Time: 4:10:43.585990
I0819 00:29:21.386471 140034352527168 train_slot.py:155] Step: 63300, Loss: 0.001968, Time: 4:11:07.574689
I0819 00:29:44.822555 140034352527168 train_slot.py:155] Step: 63400, Loss: 0.001919, Time: 4:11:31.010754
I0819 00:30:08.528555 140034352527168 train_slot.py:155] Step: 63500, Loss: 0.001872, Time: 4:11:54.716698
I0819 00:30:31.968257 140034352527168 train_slot.py:155] Step: 63600, Loss: 0.001683, Time: 4:12:18.156457
I0819 00:30:55.545770 140034352527168 train_slot.py:155] Step: 63700, Loss: 0.002119, Time: 4:12:41.733974
I0819 00:31:18.932365 140034352527168 train_slot.py:155] Step: 63800, Loss: 0.001796, Time: 4:13:05.120595
I0819 00:31:42.489549 140034352527168 train_slot.py:155] Step: 63900, Loss: 0.002083, Time: 4:13:28.677545
I0819 00:32:05.989033 140034352527168 train_slot.py:155] Step: 64000, Loss: 0.001761, Time: 4:13:52.177262
I0819 00:32:06.377853 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-64000
I0819 00:32:07.447550 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 64000
I0819 00:32:31.199457 140034352527168 train_slot.py:155] Step: 64100, Loss: 0.001875, Time: 4:14:17.387661
I0819 00:32:54.646385 140034352527168 train_slot.py:155] Step: 64200, Loss: 0.001780, Time: 4:14:40.834083
I0819 00:33:18.137982 140034352527168 train_slot.py:155] Step: 64300, Loss: 0.001463, Time: 4:15:04.326154
I0819 00:33:41.696006 140034352527168 train_slot.py:155] Step: 64400, Loss: 0.001979, Time: 4:15:27.884237
I0819 00:34:05.176438 140034352527168 train_slot.py:155] Step: 64500, Loss: 0.002097, Time: 4:15:51.364671
I0819 00:34:28.839575 140034352527168 train_slot.py:155] Step: 64600, Loss: 0.001745, Time: 4:16:15.027702
I0819 00:34:52.410599 140034352527168 train_slot.py:155] Step: 64700, Loss: 0.002528, Time: 4:16:38.598782
I0819 00:35:16.212737 140034352527168 train_slot.py:155] Step: 64800, Loss: 0.001546, Time: 4:17:02.400966
I0819 00:35:40.086017 140034352527168 train_slot.py:155] Step: 64900, Loss: 0.001847, Time: 4:17:26.274252
I0819 00:36:03.525250 140034352527168 train_slot.py:155] Step: 65000, Loss: 0.002247, Time: 4:17:49.713244
I0819 00:36:03.868025 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-65000
I0819 00:36:04.938893 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 65000
I0819 00:36:28.876759 140034352527168 train_slot.py:155] Step: 65100, Loss: 0.001543, Time: 4:18:15.064958
I0819 00:36:52.389461 140034352527168 train_slot.py:155] Step: 65200, Loss: 0.001997, Time: 4:18:38.577674
I0819 00:37:15.855939 140034352527168 train_slot.py:155] Step: 65300, Loss: 0.001720, Time: 4:19:02.043931
I0819 00:37:39.311196 140034352527168 train_slot.py:155] Step: 65400, Loss: 0.002272, Time: 4:19:25.499395
I0819 00:38:02.938169 140034352527168 train_slot.py:155] Step: 65500, Loss: 0.002146, Time: 4:19:49.126373
I0819 00:38:26.398203 140034352527168 train_slot.py:155] Step: 65600, Loss: 0.001564, Time: 4:20:12.586137
I0819 00:38:50.157405 140034352527168 train_slot.py:155] Step: 65700, Loss: 0.001979, Time: 4:20:36.345605
I0819 00:39:13.777949 140034352527168 train_slot.py:155] Step: 65800, Loss: 0.001917, Time: 4:20:59.966176
I0819 00:39:37.272765 140034352527168 train_slot.py:155] Step: 65900, Loss: 0.002218, Time: 4:21:23.460876
I0819 00:40:00.723898 140034352527168 train_slot.py:155] Step: 66000, Loss: 0.001814, Time: 4:21:46.912133
I0819 00:40:01.047772 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-66000
I0819 00:40:02.118810 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 66000
I0819 00:40:25.738349 140034352527168 train_slot.py:155] Step: 66100, Loss: 0.002099, Time: 4:22:11.926565
I0819 00:40:49.366911 140034352527168 train_slot.py:155] Step: 66200, Loss: 0.001723, Time: 4:22:35.555142
I0819 00:41:13.039783 140034352527168 train_slot.py:155] Step: 66300, Loss: 0.001901, Time: 4:22:59.227744
I0819 00:41:36.645366 140034352527168 train_slot.py:155] Step: 66400, Loss: 0.001923, Time: 4:23:22.833575
I0819 00:42:00.294397 140034352527168 train_slot.py:155] Step: 66500, Loss: 0.001903, Time: 4:23:46.482600
I0819 00:42:23.812818 140034352527168 train_slot.py:155] Step: 66600, Loss: 0.002456, Time: 4:24:10.001020
I0819 00:42:47.328975 140034352527168 train_slot.py:155] Step: 66700, Loss: 0.001725, Time: 4:24:33.517078
I0819 00:43:10.946114 140034352527168 train_slot.py:155] Step: 66800, Loss: 0.001693, Time: 4:24:57.134315
I0819 00:43:34.402157 140034352527168 train_slot.py:155] Step: 66900, Loss: 0.001842, Time: 4:25:20.590389
I0819 00:43:57.939461 140034352527168 train_slot.py:155] Step: 67000, Loss: 0.002319, Time: 4:25:44.127563
I0819 00:43:58.300266 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-67000
I0819 00:43:59.370918 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 67000
I0819 00:44:22.954657 140034352527168 train_slot.py:155] Step: 67100, Loss: 0.001812, Time: 4:26:09.142858
I0819 00:44:46.464291 140034352527168 train_slot.py:155] Step: 67200, Loss: 0.001987, Time: 4:26:32.652488
I0819 00:45:10.256617 140034352527168 train_slot.py:155] Step: 67300, Loss: 0.002113, Time: 4:26:56.444816
I0819 00:45:33.842639 140034352527168 train_slot.py:155] Step: 67400, Loss: 0.001465, Time: 4:27:20.030873
I0819 00:45:57.349074 140034352527168 train_slot.py:155] Step: 67500, Loss: 0.001879, Time: 4:27:43.537203
I0819 00:46:20.835523 140034352527168 train_slot.py:155] Step: 67600, Loss: 0.002676, Time: 4:28:07.023731
I0819 00:46:44.513691 140034352527168 train_slot.py:155] Step: 67700, Loss: 0.001636, Time: 4:28:30.701921
I0819 00:47:08.005825 140034352527168 train_slot.py:155] Step: 67800, Loss: 0.001975, Time: 4:28:54.193950
I0819 00:47:31.698819 140034352527168 train_slot.py:155] Step: 67900, Loss: 0.001758, Time: 4:29:17.887024
I0819 00:47:55.251642 140034352527168 train_slot.py:155] Step: 68000, Loss: 0.001813, Time: 4:29:41.439761
I0819 00:47:55.629796 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-68000
I0819 00:47:56.761069 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 68000
I0819 00:48:20.270639 140034352527168 train_slot.py:155] Step: 68100, Loss: 0.001574, Time: 4:30:06.458813
I0819 00:48:43.740077 140034352527168 train_slot.py:155] Step: 68200, Loss: 0.001723, Time: 4:30:29.928276
I0819 00:49:07.313560 140034352527168 train_slot.py:155] Step: 68300, Loss: 0.001832, Time: 4:30:53.501714
I0819 00:49:31.143370 140034352527168 train_slot.py:155] Step: 68400, Loss: 0.002086, Time: 4:31:17.331451
I0819 00:49:54.872209 140034352527168 train_slot.py:155] Step: 68500, Loss: 0.002240, Time: 4:31:41.060409
I0819 00:50:18.459202 140034352527168 train_slot.py:155] Step: 68600, Loss: 0.001717, Time: 4:32:04.647177
I0819 00:50:42.133300 140034352527168 train_slot.py:155] Step: 68700, Loss: 0.001834, Time: 4:32:28.321511
I0819 00:51:05.779614 140034352527168 train_slot.py:155] Step: 68800, Loss: 0.001859, Time: 4:32:51.967813
I0819 00:51:30.014607 140034352527168 train_slot.py:155] Step: 68900, Loss: 0.002011, Time: 4:33:16.202837
I0819 00:51:53.802260 140034352527168 train_slot.py:155] Step: 69000, Loss: 0.001825, Time: 4:33:39.990310
I0819 00:51:54.139657 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-69000
I0819 00:51:55.214389 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 69000
I0819 00:52:19.324956 140034352527168 train_slot.py:155] Step: 69100, Loss: 0.002244, Time: 4:34:05.513099
I0819 00:52:43.235632 140034352527168 train_slot.py:155] Step: 69200, Loss: 0.001714, Time: 4:34:29.423828
I0819 00:53:07.180209 140034352527168 train_slot.py:155] Step: 69300, Loss: 0.001630, Time: 4:34:53.368425
I0819 00:53:31.093021 140034352527168 train_slot.py:155] Step: 69400, Loss: 0.001731, Time: 4:35:17.281150
I0819 00:53:54.946420 140034352527168 train_slot.py:155] Step: 69500, Loss: 0.001986, Time: 4:35:41.134608
I0819 00:54:18.555677 140034352527168 train_slot.py:155] Step: 69600, Loss: 0.001469, Time: 4:36:04.743875
I0819 00:54:42.010833 140034352527168 train_slot.py:155] Step: 69700, Loss: 0.002283, Time: 4:36:28.198868
I0819 00:55:05.509422 140034352527168 train_slot.py:155] Step: 69800, Loss: 0.001951, Time: 4:36:51.697598
I0819 00:55:29.162988 140034352527168 train_slot.py:155] Step: 69900, Loss: 0.002232, Time: 4:37:15.351187
I0819 00:55:52.939543 140034352527168 train_slot.py:155] Step: 70000, Loss: 0.001737, Time: 4:37:39.127688
I0819 00:55:53.272038 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-70000
I0819 00:55:54.406353 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 70000
I0819 00:56:17.901581 140034352527168 train_slot.py:155] Step: 70100, Loss: 0.002046, Time: 4:38:04.089781
I0819 00:56:41.606162 140034352527168 train_slot.py:155] Step: 70200, Loss: 0.002256, Time: 4:38:27.794362
I0819 00:57:05.244784 140034352527168 train_slot.py:155] Step: 70300, Loss: 0.001977, Time: 4:38:51.432984
I0819 00:57:28.693071 140034352527168 train_slot.py:155] Step: 70400, Loss: 0.001800, Time: 4:39:14.881231
I0819 00:57:52.146683 140034352527168 train_slot.py:155] Step: 70500, Loss: 0.002179, Time: 4:39:38.334878
I0819 00:58:15.939418 140034352527168 train_slot.py:155] Step: 70600, Loss: 0.001676, Time: 4:40:02.127638
I0819 00:58:39.471672 140034352527168 train_slot.py:155] Step: 70700, Loss: 0.001806, Time: 4:40:25.659806
I0819 00:59:03.065185 140034352527168 train_slot.py:155] Step: 70800, Loss: 0.002120, Time: 4:40:49.253393
I0819 00:59:26.584963 140034352527168 train_slot.py:155] Step: 70900, Loss: 0.001693, Time: 4:41:12.773163
I0819 00:59:50.088841 140034352527168 train_slot.py:155] Step: 71000, Loss: 0.001718, Time: 4:41:36.276981
I0819 00:59:50.430204 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-71000
I0819 00:59:51.499493 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 71000
I0819 01:00:15.215056 140034352527168 train_slot.py:155] Step: 71100, Loss: 0.001883, Time: 4:42:01.403254
I0819 01:00:38.834808 140034352527168 train_slot.py:155] Step: 71200, Loss: 0.001762, Time: 4:42:25.023008
I0819 01:01:02.591638 140034352527168 train_slot.py:155] Step: 71300, Loss: 0.001781, Time: 4:42:48.779617
I0819 01:01:26.283463 140034352527168 train_slot.py:155] Step: 71400, Loss: 0.001469, Time: 4:43:12.471589
I0819 01:01:50.027271 140034352527168 train_slot.py:155] Step: 71500, Loss: 0.001610, Time: 4:43:36.215500
I0819 01:02:13.775849 140034352527168 train_slot.py:155] Step: 71600, Loss: 0.001748, Time: 4:43:59.964005
I0819 01:02:37.751445 140034352527168 train_slot.py:155] Step: 71700, Loss: 0.001637, Time: 4:44:23.939634
I0819 01:03:01.733920 140034352527168 train_slot.py:155] Step: 71800, Loss: 0.001851, Time: 4:44:47.922121
I0819 01:03:25.468008 140034352527168 train_slot.py:155] Step: 71900, Loss: 0.001862, Time: 4:45:11.656113
I0819 01:03:49.164560 140034352527168 train_slot.py:155] Step: 72000, Loss: 0.001576, Time: 4:45:35.352769
I0819 01:03:49.576114 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-72000
I0819 01:03:50.718755 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 72000
I0819 01:04:14.601179 140034352527168 train_slot.py:155] Step: 72100, Loss: 0.001829, Time: 4:46:00.789370
I0819 01:04:38.462813 140034352527168 train_slot.py:155] Step: 72200, Loss: 0.001985, Time: 4:46:24.650797
I0819 01:05:02.209964 140034352527168 train_slot.py:155] Step: 72300, Loss: 0.001843, Time: 4:46:48.398146
I0819 01:05:25.774441 140034352527168 train_slot.py:155] Step: 72400, Loss: 0.001467, Time: 4:47:11.962643
I0819 01:05:49.316342 140034352527168 train_slot.py:155] Step: 72500, Loss: 0.001758, Time: 4:47:35.504553
I0819 01:06:12.891142 140034352527168 train_slot.py:155] Step: 72600, Loss: 0.001784, Time: 4:47:59.079254
I0819 01:06:36.604161 140034352527168 train_slot.py:155] Step: 72700, Loss: 0.001483, Time: 4:48:22.792357
I0819 01:07:00.135395 140034352527168 train_slot.py:155] Step: 72800, Loss: 0.001891, Time: 4:48:46.323597
I0819 01:07:23.718240 140034352527168 train_slot.py:155] Step: 72900, Loss: 0.001694, Time: 4:49:09.906364
I0819 01:07:47.237898 140034352527168 train_slot.py:155] Step: 73000, Loss: 0.001883, Time: 4:49:33.425975
I0819 01:07:47.620992 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-73000
I0819 01:07:48.758137 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 73000
I0819 01:08:12.325587 140034352527168 train_slot.py:155] Step: 73100, Loss: 0.001468, Time: 4:49:58.513786
I0819 01:08:35.827706 140034352527168 train_slot.py:155] Step: 73200, Loss: 0.001749, Time: 4:50:22.015820
I0819 01:08:59.593384 140034352527168 train_slot.py:155] Step: 73300, Loss: 0.002048, Time: 4:50:45.781585
I0819 01:09:23.119948 140034352527168 train_slot.py:155] Step: 73400, Loss: 0.001620, Time: 4:51:09.308147
I0819 01:09:46.883633 140034352527168 train_slot.py:155] Step: 73500, Loss: 0.001581, Time: 4:51:33.071866
I0819 01:10:10.353934 140034352527168 train_slot.py:155] Step: 73600, Loss: 0.001747, Time: 4:51:56.542063
I0819 01:10:33.931086 140034352527168 train_slot.py:155] Step: 73700, Loss: 0.001750, Time: 4:52:20.119287
I0819 01:10:57.485527 140034352527168 train_slot.py:155] Step: 73800, Loss: 0.001966, Time: 4:52:43.673730
I0819 01:11:21.074735 140034352527168 train_slot.py:155] Step: 73900, Loss: 0.001743, Time: 4:53:07.262934
I0819 01:11:44.636547 140034352527168 train_slot.py:155] Step: 74000, Loss: 0.001940, Time: 4:53:30.824702
I0819 01:11:45.023304 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-74000
I0819 01:11:46.116235 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 74000
I0819 01:12:09.616135 140034352527168 train_slot.py:155] Step: 74100, Loss: 0.001998, Time: 4:53:55.804307
I0819 01:12:33.065436 140034352527168 train_slot.py:155] Step: 74200, Loss: 0.001932, Time: 4:54:19.253633
I0819 01:12:56.829033 140034352527168 train_slot.py:155] Step: 74300, Loss: 0.001805, Time: 4:54:43.017234
I0819 01:13:20.571330 140034352527168 train_slot.py:155] Step: 74400, Loss: 0.001709, Time: 4:55:06.759318
I0819 01:13:44.065273 140034352527168 train_slot.py:155] Step: 74500, Loss: 0.001910, Time: 4:55:30.253477
I0819 01:14:07.527381 140034352527168 train_slot.py:155] Step: 74600, Loss: 0.001874, Time: 4:55:53.715616
I0819 01:14:31.092603 140034352527168 train_slot.py:155] Step: 74700, Loss: 0.001711, Time: 4:56:17.280801
I0819 01:14:54.499673 140034352527168 train_slot.py:155] Step: 74800, Loss: 0.001470, Time: 4:56:40.687701
I0819 01:15:18.280030 140034352527168 train_slot.py:155] Step: 74900, Loss: 0.002240, Time: 4:57:04.468224
I0819 01:15:41.818843 140034352527168 train_slot.py:155] Step: 75000, Loss: 0.001490, Time: 4:57:28.006974
I0819 01:15:42.195060 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-75000
I0819 01:15:43.308782 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 75000
I0819 01:16:06.829100 140034352527168 train_slot.py:155] Step: 75100, Loss: 0.001840, Time: 4:57:53.017287
I0819 01:16:30.359070 140034352527168 train_slot.py:155] Step: 75200, Loss: 0.001697, Time: 4:58:16.547272
I0819 01:16:53.819553 140034352527168 train_slot.py:155] Step: 75300, Loss: 0.001410, Time: 4:58:40.007769
I0819 01:17:17.443998 140034352527168 train_slot.py:155] Step: 75400, Loss: 0.002137, Time: 4:59:03.632115
I0819 01:17:40.930860 140034352527168 train_slot.py:155] Step: 75500, Loss: 0.002047, Time: 4:59:27.119064
I0819 01:18:04.779891 140034352527168 train_slot.py:155] Step: 75600, Loss: 0.001297, Time: 4:59:50.968086
I0819 01:18:28.813630 140034352527168 train_slot.py:155] Step: 75700, Loss: 0.001463, Time: 5:00:15.001664
I0819 01:18:52.472392 140034352527168 train_slot.py:155] Step: 75800, Loss: 0.001876, Time: 5:00:38.660590
I0819 01:19:16.156672 140034352527168 train_slot.py:155] Step: 75900, Loss: 0.001886, Time: 5:01:02.344871
I0819 01:19:39.897876 140034352527168 train_slot.py:155] Step: 76000, Loss: 0.001710, Time: 5:01:26.086002
I0819 01:19:40.218402 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-76000
I0819 01:19:41.295873 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 76000
I0819 01:20:04.669635 140034352527168 train_slot.py:155] Step: 76100, Loss: 0.001651, Time: 5:01:50.857836
I0819 01:20:28.222532 140034352527168 train_slot.py:155] Step: 76200, Loss: 0.001668, Time: 5:02:14.410725
I0819 01:20:51.797527 140034352527168 train_slot.py:155] Step: 76300, Loss: 0.001808, Time: 5:02:37.985671
I0819 01:21:15.314940 140034352527168 train_slot.py:155] Step: 76400, Loss: 0.001306, Time: 5:03:01.503139
I0819 01:21:39.076139 140034352527168 train_slot.py:155] Step: 76500, Loss: 0.001944, Time: 5:03:25.264272
I0819 01:22:02.616658 140034352527168 train_slot.py:155] Step: 76600, Loss: 0.001491, Time: 5:03:48.804790
I0819 01:22:26.002279 140034352527168 train_slot.py:155] Step: 76700, Loss: 0.001387, Time: 5:04:12.190506
I0819 01:22:49.534642 140034352527168 train_slot.py:155] Step: 76800, Loss: 0.001703, Time: 5:04:35.722842
I0819 01:23:13.062917 140034352527168 train_slot.py:155] Step: 76900, Loss: 0.001409, Time: 5:04:59.251048
I0819 01:23:36.645835 140034352527168 train_slot.py:155] Step: 77000, Loss: 0.001737, Time: 5:05:22.834047
I0819 01:23:36.982228 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-77000
I0819 01:23:38.123949 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 77000
I0819 01:24:01.834728 140034352527168 train_slot.py:155] Step: 77100, Loss: 0.001786, Time: 5:05:48.022929
I0819 01:24:25.352730 140034352527168 train_slot.py:155] Step: 77200, Loss: 0.001545, Time: 5:06:11.540937
I0819 01:24:48.831573 140034352527168 train_slot.py:155] Step: 77300, Loss: 0.001844, Time: 5:06:35.019675
I0819 01:25:12.346763 140034352527168 train_slot.py:155] Step: 77400, Loss: 0.001933, Time: 5:06:58.534962
I0819 01:25:36.083019 140034352527168 train_slot.py:155] Step: 77500, Loss: 0.001585, Time: 5:07:22.271214
I0819 01:25:59.833280 140034352527168 train_slot.py:155] Step: 77600, Loss: 0.001602, Time: 5:07:46.021481
I0819 01:26:23.378818 140034352527168 train_slot.py:155] Step: 77700, Loss: 0.001445, Time: 5:08:09.566959
I0819 01:26:46.979498 140034352527168 train_slot.py:155] Step: 77800, Loss: 0.001822, Time: 5:08:33.167683
I0819 01:27:10.461177 140034352527168 train_slot.py:155] Step: 77900, Loss: 0.001456, Time: 5:08:56.649378
I0819 01:27:33.979257 140034352527168 train_slot.py:155] Step: 78000, Loss: 0.001777, Time: 5:09:20.167396
I0819 01:27:34.290885 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-78000
I0819 01:27:35.360282 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 78000
I0819 01:27:58.832977 140034352527168 train_slot.py:155] Step: 78100, Loss: 0.001878, Time: 5:09:45.021097
I0819 01:28:22.614070 140034352527168 train_slot.py:155] Step: 78200, Loss: 0.001411, Time: 5:10:08.802304
I0819 01:28:46.142994 140034352527168 train_slot.py:155] Step: 78300, Loss: 0.001850, Time: 5:10:32.331107
I0819 01:29:09.556550 140034352527168 train_slot.py:155] Step: 78400, Loss: 0.001773, Time: 5:10:55.744757
I0819 01:29:33.064276 140034352527168 train_slot.py:155] Step: 78500, Loss: 0.001892, Time: 5:11:19.252484
I0819 01:29:56.612597 140034352527168 train_slot.py:155] Step: 78600, Loss: 0.001723, Time: 5:11:42.800797
I0819 01:30:20.318037 140034352527168 train_slot.py:155] Step: 78700, Loss: 0.001435, Time: 5:12:06.506182
I0819 01:30:43.813808 140034352527168 train_slot.py:155] Step: 78800, Loss: 0.002123, Time: 5:12:30.002011
I0819 01:31:07.400452 140034352527168 train_slot.py:155] Step: 78900, Loss: 0.001698, Time: 5:12:53.588662
I0819 01:31:30.914310 140034352527168 train_slot.py:155] Step: 79000, Loss: 0.001785, Time: 5:13:17.102432
I0819 01:31:31.250890 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-79000
I0819 01:31:32.383907 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 79000
I0819 01:31:55.886252 140034352527168 train_slot.py:155] Step: 79100, Loss: 0.001837, Time: 5:13:42.074450
I0819 01:32:19.694478 140034352527168 train_slot.py:155] Step: 79200, Loss: 0.001696, Time: 5:14:05.882708
I0819 01:32:43.232152 140034352527168 train_slot.py:155] Step: 79300, Loss: 0.001569, Time: 5:14:29.420289
I0819 01:33:06.639563 140034352527168 train_slot.py:155] Step: 79400, Loss: 0.001469, Time: 5:14:52.827796
I0819 01:33:30.126779 140034352527168 train_slot.py:155] Step: 79500, Loss: 0.001732, Time: 5:15:16.314978
I0819 01:33:53.981080 140034352527168 train_slot.py:155] Step: 79600, Loss: 0.002489, Time: 5:15:40.169205
I0819 01:34:17.697839 140034352527168 train_slot.py:155] Step: 79700, Loss: 0.001494, Time: 5:16:03.886049
I0819 01:34:41.631302 140034352527168 train_slot.py:155] Step: 79800, Loss: 0.001817, Time: 5:16:27.819525
I0819 01:35:05.086387 140034352527168 train_slot.py:155] Step: 79900, Loss: 0.001436, Time: 5:16:51.274611
I0819 01:35:28.517277 140034352527168 train_slot.py:155] Step: 80000, Loss: 0.001808, Time: 5:17:14.705420
I0819 01:35:28.845267 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-80000
I0819 01:35:29.976890 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 80000
I0819 01:35:53.677996 140034352527168 train_slot.py:155] Step: 80100, Loss: 0.001632, Time: 5:17:39.866214
I0819 01:36:17.189815 140034352527168 train_slot.py:155] Step: 80200, Loss: 0.001742, Time: 5:18:03.378019
I0819 01:36:40.899960 140034352527168 train_slot.py:155] Step: 80300, Loss: 0.001714, Time: 5:18:27.088161
I0819 01:37:04.306859 140034352527168 train_slot.py:155] Step: 80400, Loss: 0.001706, Time: 5:18:50.494790
I0819 01:37:27.794367 140034352527168 train_slot.py:155] Step: 80500, Loss: 0.001378, Time: 5:19:13.982601
I0819 01:37:51.427776 140034352527168 train_slot.py:155] Step: 80600, Loss: 0.001496, Time: 5:19:37.615982
I0819 01:38:14.889305 140034352527168 train_slot.py:155] Step: 80700, Loss: 0.001949, Time: 5:20:01.077250
I0819 01:38:38.342527 140034352527168 train_slot.py:155] Step: 80800, Loss: 0.001667, Time: 5:20:24.530726
I0819 01:39:02.007757 140034352527168 train_slot.py:155] Step: 80900, Loss: 0.001585, Time: 5:20:48.195966
I0819 01:39:25.653542 140034352527168 train_slot.py:155] Step: 81000, Loss: 0.001684, Time: 5:21:11.841680
I0819 01:39:26.024738 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-81000
I0819 01:39:27.143537 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 81000
I0819 01:39:50.503138 140034352527168 train_slot.py:155] Step: 81100, Loss: 0.001809, Time: 5:21:36.691281
I0819 01:40:13.966353 140034352527168 train_slot.py:155] Step: 81200, Loss: 0.001566, Time: 5:22:00.154581
I0819 01:40:37.451783 140034352527168 train_slot.py:155] Step: 81300, Loss: 0.001676, Time: 5:22:23.640018
I0819 01:41:01.086682 140034352527168 train_slot.py:155] Step: 81400, Loss: 0.001583, Time: 5:22:47.274812
I0819 01:41:24.527651 140034352527168 train_slot.py:155] Step: 81500, Loss: 0.001447, Time: 5:23:10.715856
I0819 01:41:48.033489 140034352527168 train_slot.py:155] Step: 81600, Loss: 0.001821, Time: 5:23:34.221691
I0819 01:42:11.389360 140034352527168 train_slot.py:155] Step: 81700, Loss: 0.001794, Time: 5:23:57.577561
I0819 01:42:34.908530 140034352527168 train_slot.py:155] Step: 81800, Loss: 0.001316, Time: 5:24:21.096746
I0819 01:42:58.288517 140034352527168 train_slot.py:155] Step: 81900, Loss: 0.001256, Time: 5:24:44.476748
I0819 01:43:22.004699 140034352527168 train_slot.py:155] Step: 82000, Loss: 0.001766, Time: 5:25:08.192814
I0819 01:43:22.311137 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-82000
I0819 01:43:23.425269 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 82000
I0819 01:43:46.944900 140034352527168 train_slot.py:155] Step: 82100, Loss: 0.001886, Time: 5:25:33.133086
I0819 01:44:10.744131 140034352527168 train_slot.py:155] Step: 82200, Loss: 0.001933, Time: 5:25:56.932331
I0819 01:44:34.557193 140034352527168 train_slot.py:155] Step: 82300, Loss: 0.001666, Time: 5:26:20.745320
I0819 01:44:58.008301 140034352527168 train_slot.py:155] Step: 82400, Loss: 0.001413, Time: 5:26:44.196453
I0819 01:45:21.826306 140034352527168 train_slot.py:155] Step: 82500, Loss: 0.001537, Time: 5:27:08.014539
I0819 01:45:45.353611 140034352527168 train_slot.py:155] Step: 82600, Loss: 0.001420, Time: 5:27:31.541749
I0819 01:46:08.870605 140034352527168 train_slot.py:155] Step: 82700, Loss: 0.001466, Time: 5:27:55.058752
I0819 01:46:32.404200 140034352527168 train_slot.py:155] Step: 82800, Loss: 0.001760, Time: 5:28:18.592432
I0819 01:46:55.987458 140034352527168 train_slot.py:155] Step: 82900, Loss: 0.001504, Time: 5:28:42.175575
I0819 01:47:19.602322 140034352527168 train_slot.py:155] Step: 83000, Loss: 0.001513, Time: 5:29:05.790503
I0819 01:47:19.997298 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-83000
I0819 01:47:21.071884 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 83000
I0819 01:47:44.658041 140034352527168 train_slot.py:155] Step: 83100, Loss: 0.001690, Time: 5:29:30.846240
I0819 01:48:08.166934 140034352527168 train_slot.py:155] Step: 83200, Loss: 0.001745, Time: 5:29:54.355134
I0819 01:48:31.707802 140034352527168 train_slot.py:155] Step: 83300, Loss: 0.001979, Time: 5:30:17.895766
I0819 01:48:55.398765 140034352527168 train_slot.py:155] Step: 83400, Loss: 0.001922, Time: 5:30:41.586963
I0819 01:49:19.068069 140034352527168 train_slot.py:155] Step: 83500, Loss: 0.002065, Time: 5:31:05.256243
I0819 01:49:42.708786 140034352527168 train_slot.py:155] Step: 83600, Loss: 0.001406, Time: 5:31:28.896984
I0819 01:50:06.433483 140034352527168 train_slot.py:155] Step: 83700, Loss: 0.001649, Time: 5:31:52.621454
I0819 01:50:30.048779 140034352527168 train_slot.py:155] Step: 83800, Loss: 0.001550, Time: 5:32:16.236964
I0819 01:50:53.606599 140034352527168 train_slot.py:155] Step: 83900, Loss: 0.001432, Time: 5:32:39.794809
I0819 01:51:17.075829 140034352527168 train_slot.py:155] Step: 84000, Loss: 0.001811, Time: 5:33:03.263927
I0819 01:51:17.470029 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-84000
I0819 01:51:18.549772 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 84000
I0819 01:51:42.276619 140034352527168 train_slot.py:155] Step: 84100, Loss: 0.001317, Time: 5:33:28.464825
I0819 01:52:05.799035 140034352527168 train_slot.py:155] Step: 84200, Loss: 0.001414, Time: 5:33:51.987237
I0819 01:52:29.282703 140034352527168 train_slot.py:155] Step: 84300, Loss: 0.001327, Time: 5:34:15.470294
I0819 01:52:52.767859 140034352527168 train_slot.py:155] Step: 84400, Loss: 0.001698, Time: 5:34:38.956080
I0819 01:53:16.566920 140034352527168 train_slot.py:155] Step: 84500, Loss: 0.001462, Time: 5:35:02.755131
I0819 01:53:40.023138 140034352527168 train_slot.py:155] Step: 84600, Loss: 0.001384, Time: 5:35:26.211196
I0819 01:54:03.799845 140034352527168 train_slot.py:155] Step: 84700, Loss: 0.001707, Time: 5:35:49.988071
I0819 01:54:27.323163 140034352527168 train_slot.py:155] Step: 84800, Loss: 0.001958, Time: 5:36:13.511394
I0819 01:54:50.847013 140034352527168 train_slot.py:155] Step: 84900, Loss: 0.001478, Time: 5:36:37.034891
I0819 01:55:14.237565 140034352527168 train_slot.py:155] Step: 85000, Loss: 0.001461, Time: 5:37:00.425752
I0819 01:55:14.580378 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-85000
I0819 01:55:15.663122 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 85000
I0819 01:55:39.118815 140034352527168 train_slot.py:155] Step: 85100, Loss: 0.001420, Time: 5:37:25.307014
I0819 01:56:02.936252 140034352527168 train_slot.py:155] Step: 85200, Loss: 0.001591, Time: 5:37:49.124315
I0819 01:56:26.376178 140034352527168 train_slot.py:155] Step: 85300, Loss: 0.001481, Time: 5:38:12.564378
I0819 01:56:49.942685 140034352527168 train_slot.py:155] Step: 85400, Loss: 0.001436, Time: 5:38:36.130840
I0819 01:57:13.446805 140034352527168 train_slot.py:155] Step: 85500, Loss: 0.001774, Time: 5:38:59.635037
I0819 01:57:37.214714 140034352527168 train_slot.py:155] Step: 85600, Loss: 0.001909, Time: 5:39:23.402773
I0819 01:58:00.753177 140034352527168 train_slot.py:155] Step: 85700, Loss: 0.001790, Time: 5:39:46.941311
I0819 01:58:24.701327 140034352527168 train_slot.py:155] Step: 85800, Loss: 0.001860, Time: 5:40:10.889523
I0819 01:58:48.281734 140034352527168 train_slot.py:155] Step: 85900, Loss: 0.001853, Time: 5:40:34.469785
I0819 01:59:11.697876 140034352527168 train_slot.py:155] Step: 86000, Loss: 0.001369, Time: 5:40:57.886058
I0819 01:59:12.068871 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-86000
I0819 01:59:13.214180 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 86000
I0819 01:59:36.763661 140034352527168 train_slot.py:155] Step: 86100, Loss: 0.001391, Time: 5:41:22.951862
I0819 02:00:00.220889 140034352527168 train_slot.py:155] Step: 86200, Loss: 0.001632, Time: 5:41:46.409064
I0819 02:00:24.015897 140034352527168 train_slot.py:155] Step: 86300, Loss: 0.001530, Time: 5:42:10.203912
I0819 02:00:47.342854 140034352527168 train_slot.py:155] Step: 86400, Loss: 0.001505, Time: 5:42:33.531070
I0819 02:01:10.795330 140034352527168 train_slot.py:155] Step: 86500, Loss: 0.002283, Time: 5:42:56.983451
I0819 02:01:34.230944 140034352527168 train_slot.py:155] Step: 86600, Loss: 0.001467, Time: 5:43:20.419131
I0819 02:01:57.759212 140034352527168 train_slot.py:155] Step: 86700, Loss: 0.001587, Time: 5:43:43.947406
I0819 02:02:21.409145 140034352527168 train_slot.py:155] Step: 86800, Loss: 0.001570, Time: 5:44:07.597373
I0819 02:02:21.642975 140034352527168 train_slot.py:155] Step: 86800, Loss: 0.001746, Time: 5:44:07.831211
I0819 02:02:45.196160 140034352527168 train_slot.py:155] Step: 86900, Loss: 0.001830, Time: 5:44:31.384388
I0819 02:03:08.867224 140034352527168 train_slot.py:155] Step: 87000, Loss: 0.001824, Time: 5:44:55.055423
I0819 02:03:09.195764 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-87000
I0819 02:03:10.325136 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 87000
I0819 02:03:33.879627 140034352527168 train_slot.py:155] Step: 87100, Loss: 0.001428, Time: 5:45:20.067653
I0819 02:03:57.517850 140034352527168 train_slot.py:155] Step: 87200, Loss: 0.001742, Time: 5:45:43.706080
I0819 02:04:21.102599 140034352527168 train_slot.py:155] Step: 87300, Loss: 0.001626, Time: 5:46:07.290827
I0819 02:04:44.854442 140034352527168 train_slot.py:155] Step: 87400, Loss: 0.001909, Time: 5:46:31.042646
I0819 02:05:08.406757 140034352527168 train_slot.py:155] Step: 87500, Loss: 0.001496, Time: 5:46:54.594770
I0819 02:05:31.820925 140034352527168 train_slot.py:155] Step: 87600, Loss: 0.001597, Time: 5:47:18.009110
I0819 02:05:55.303786 140034352527168 train_slot.py:155] Step: 87700, Loss: 0.001685, Time: 5:47:41.491986
I0819 02:06:18.815174 140034352527168 train_slot.py:155] Step: 87800, Loss: 0.001487, Time: 5:48:05.003230
I0819 02:06:42.865887 140034352527168 train_slot.py:155] Step: 87900, Loss: 0.001585, Time: 5:48:29.054109
I0819 02:07:06.755208 140034352527168 train_slot.py:155] Step: 88000, Loss: 0.001664, Time: 5:48:52.943410
I0819 02:07:07.160032 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-88000
I0819 02:07:08.240998 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 88000
I0819 02:07:32.363982 140034352527168 train_slot.py:155] Step: 88100, Loss: 0.001570, Time: 5:49:18.552171
I0819 02:07:56.378605 140034352527168 train_slot.py:155] Step: 88200, Loss: 0.002155, Time: 5:49:42.566789
I0819 02:08:20.298139 140034352527168 train_slot.py:155] Step: 88300, Loss: 0.001755, Time: 5:50:06.486204
I0819 02:08:44.127807 140034352527168 train_slot.py:155] Step: 88400, Loss: 0.001267, Time: 5:50:30.316010
I0819 02:09:08.140426 140034352527168 train_slot.py:155] Step: 88500, Loss: 0.001525, Time: 5:50:54.328650
I0819 02:09:32.009857 140034352527168 train_slot.py:155] Step: 88600, Loss: 0.001473, Time: 5:51:18.197972
I0819 02:09:55.875936 140034352527168 train_slot.py:155] Step: 88700, Loss: 0.001735, Time: 5:51:42.064175
I0819 02:10:19.781123 140034352527168 train_slot.py:155] Step: 88800, Loss: 0.001459, Time: 5:52:05.969328
I0819 02:10:43.692938 140034352527168 train_slot.py:155] Step: 88900, Loss: 0.001361, Time: 5:52:29.881006
I0819 02:11:07.775909 140034352527168 train_slot.py:155] Step: 89000, Loss: 0.001579, Time: 5:52:53.964110
I0819 02:11:08.175674 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-89000
I0819 02:11:09.252112 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 89000
I0819 02:11:33.182318 140034352527168 train_slot.py:155] Step: 89100, Loss: 0.001709, Time: 5:53:19.370501
I0819 02:11:57.110090 140034352527168 train_slot.py:155] Step: 89200, Loss: 0.001746, Time: 5:53:43.298294
I0819 02:12:20.988949 140034352527168 train_slot.py:155] Step: 89300, Loss: 0.001560, Time: 5:54:07.177149
I0819 02:12:44.874490 140034352527168 train_slot.py:155] Step: 89400, Loss: 0.001892, Time: 5:54:31.062693
I0819 02:13:08.772676 140034352527168 train_slot.py:155] Step: 89500, Loss: 0.001640, Time: 5:54:54.960879
I0819 02:13:32.434837 140034352527168 train_slot.py:155] Step: 89600, Loss: 0.001466, Time: 5:55:18.622860
I0819 02:13:55.840492 140034352527168 train_slot.py:155] Step: 89700, Loss: 0.001887, Time: 5:55:42.028688
I0819 02:14:19.347124 140034352527168 train_slot.py:155] Step: 89800, Loss: 0.001511, Time: 5:56:05.535326
I0819 02:14:42.825088 140034352527168 train_slot.py:155] Step: 89900, Loss: 0.001537, Time: 5:56:29.013302
I0819 02:15:06.307170 140034352527168 train_slot.py:155] Step: 90000, Loss: 0.001690, Time: 5:56:52.495291
I0819 02:15:06.651591 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-90000
I0819 02:15:07.792485 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 90000
I0819 02:15:31.446506 140034352527168 train_slot.py:155] Step: 90100, Loss: 0.001787, Time: 5:57:17.634729
I0819 02:15:55.046777 140034352527168 train_slot.py:155] Step: 90200, Loss: 0.001566, Time: 5:57:41.234976
I0819 02:16:18.585540 140034352527168 train_slot.py:155] Step: 90300, Loss: 0.001449, Time: 5:58:04.773591
I0819 02:16:42.086510 140034352527168 train_slot.py:155] Step: 90400, Loss: 0.001225, Time: 5:58:28.274711
I0819 02:17:05.513275 140034352527168 train_slot.py:155] Step: 90500, Loss: 0.001584, Time: 5:58:51.701476
I0819 02:17:29.363554 140034352527168 train_slot.py:155] Step: 90600, Loss: 0.001592, Time: 5:59:15.551645
I0819 02:17:52.839027 140034352527168 train_slot.py:155] Step: 90700, Loss: 0.001607, Time: 5:59:39.027231
I0819 02:18:16.294701 140034352527168 train_slot.py:155] Step: 90800, Loss: 0.001806, Time: 6:00:02.482928
I0819 02:18:39.988640 140034352527168 train_slot.py:155] Step: 90900, Loss: 0.001660, Time: 6:00:26.176851
I0819 02:19:03.491461 140034352527168 train_slot.py:155] Step: 91000, Loss: 0.001594, Time: 6:00:49.679698
I0819 02:19:03.843911 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-91000
I0819 02:19:04.985464 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 91000
I0819 02:19:28.453850 140034352527168 train_slot.py:155] Step: 91100, Loss: 0.001825, Time: 6:01:14.642001
I0819 02:19:52.331940 140034352527168 train_slot.py:155] Step: 91200, Loss: 0.001478, Time: 6:01:38.520122
I0819 02:20:16.032026 140034352527168 train_slot.py:155] Step: 91300, Loss: 0.001282, Time: 6:02:02.220092
I0819 02:20:39.767365 140034352527168 train_slot.py:155] Step: 91400, Loss: 0.001269, Time: 6:02:25.955479
I0819 02:21:03.578255 140034352527168 train_slot.py:155] Step: 91500, Loss: 0.001527, Time: 6:02:49.766456
I0819 02:21:27.349330 140034352527168 train_slot.py:155] Step: 91600, Loss: 0.001842, Time: 6:03:13.537534
I0819 02:21:51.192306 140034352527168 train_slot.py:155] Step: 91700, Loss: 0.001775, Time: 6:03:37.380278
I0819 02:22:14.638054 140034352527168 train_slot.py:155] Step: 91800, Loss: 0.001510, Time: 6:04:00.826260
I0819 02:22:38.125198 140034352527168 train_slot.py:155] Step: 91900, Loss: 0.001553, Time: 6:04:24.313427
I0819 02:23:01.639997 140034352527168 train_slot.py:155] Step: 92000, Loss: 0.001771, Time: 6:04:47.828014
I0819 02:23:02.006997 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-92000
I0819 02:23:03.086429 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 92000
I0819 02:23:26.857026 140034352527168 train_slot.py:155] Step: 92100, Loss: 0.001378, Time: 6:05:13.045242
I0819 02:23:50.584952 140034352527168 train_slot.py:155] Step: 92200, Loss: 0.001724, Time: 6:05:36.773170
I0819 02:24:14.573557 140034352527168 train_slot.py:155] Step: 92300, Loss: 0.001905, Time: 6:06:00.761752
I0819 02:24:38.323578 140034352527168 train_slot.py:155] Step: 92400, Loss: 0.001675, Time: 6:06:24.511614
I0819 02:25:02.117805 140034352527168 train_slot.py:155] Step: 92500, Loss: 0.001408, Time: 6:06:48.305997
I0819 02:25:25.803457 140034352527168 train_slot.py:155] Step: 92600, Loss: 0.001486, Time: 6:07:11.991690
I0819 02:25:49.557558 140034352527168 train_slot.py:155] Step: 92700, Loss: 0.001337, Time: 6:07:35.745611
I0819 02:26:13.451753 140034352527168 train_slot.py:155] Step: 92800, Loss: 0.001703, Time: 6:07:59.639933
I0819 02:26:36.856652 140034352527168 train_slot.py:155] Step: 92900, Loss: 0.001448, Time: 6:08:23.044888
I0819 02:27:00.311224 140034352527168 train_slot.py:155] Step: 93000, Loss: 0.001463, Time: 6:08:46.499437
I0819 02:27:00.712760 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-93000
I0819 02:27:01.855326 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 93000
I0819 02:27:25.400840 140034352527168 train_slot.py:155] Step: 93100, Loss: 0.001732, Time: 6:09:11.588973
I0819 02:27:49.079466 140034352527168 train_slot.py:155] Step: 93200, Loss: 0.001616, Time: 6:09:35.267663
I0819 02:28:13.077780 140034352527168 train_slot.py:155] Step: 93300, Loss: 0.001653, Time: 6:09:59.265979
I0819 02:28:36.607056 140034352527168 train_slot.py:155] Step: 93400, Loss: 0.001309, Time: 6:10:22.795256
I0819 02:29:00.118984 140034352527168 train_slot.py:155] Step: 93500, Loss: 0.001501, Time: 6:10:46.306974
I0819 02:29:23.567672 140034352527168 train_slot.py:155] Step: 93600, Loss: 0.001489, Time: 6:11:09.755819
I0819 02:29:47.248056 140034352527168 train_slot.py:155] Step: 93700, Loss: 0.001749, Time: 6:11:33.436255
I0819 02:30:10.782136 140034352527168 train_slot.py:155] Step: 93800, Loss: 0.002387, Time: 6:11:56.970339
I0819 02:30:34.558153 140034352527168 train_slot.py:155] Step: 93900, Loss: 0.001583, Time: 6:12:20.746143
I0819 02:30:58.121418 140034352527168 train_slot.py:155] Step: 94000, Loss: 0.001447, Time: 6:12:44.309614
I0819 02:30:58.455250 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-94000
I0819 02:30:59.594040 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 94000
I0819 02:31:23.180732 140034352527168 train_slot.py:155] Step: 94100, Loss: 0.001696, Time: 6:13:09.368942
I0819 02:31:46.686845 140034352527168 train_slot.py:155] Step: 94200, Loss: 0.001660, Time: 6:13:32.875077
I0819 02:32:10.449506 140034352527168 train_slot.py:155] Step: 94300, Loss: 0.001712, Time: 6:13:56.637708
I0819 02:32:34.084625 140034352527168 train_slot.py:155] Step: 94400, Loss: 0.001593, Time: 6:14:20.272598
I0819 02:32:57.822777 140034352527168 train_slot.py:155] Step: 94500, Loss: 0.001807, Time: 6:14:44.010977
I0819 02:33:21.415970 140034352527168 train_slot.py:155] Step: 94600, Loss: 0.001629, Time: 6:15:07.604029
I0819 02:33:44.830424 140034352527168 train_slot.py:155] Step: 94700, Loss: 0.001648, Time: 6:15:31.018587
I0819 02:34:08.376266 140034352527168 train_slot.py:155] Step: 94800, Loss: 0.001730, Time: 6:15:54.564467
I0819 02:34:31.865681 140034352527168 train_slot.py:155] Step: 94900, Loss: 0.001638, Time: 6:16:18.053783
I0819 02:34:55.577890 140034352527168 train_slot.py:155] Step: 95000, Loss: 0.001406, Time: 6:16:41.765960
I0819 02:34:55.933541 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-95000
I0819 02:34:57.005210 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 95000
I0819 02:35:20.433819 140034352527168 train_slot.py:155] Step: 95100, Loss: 0.001704, Time: 6:17:06.622017
I0819 02:35:43.939662 140034352527168 train_slot.py:155] Step: 95200, Loss: 0.001955, Time: 6:17:30.127875
I0819 02:36:07.441264 140034352527168 train_slot.py:155] Step: 95300, Loss: 0.001353, Time: 6:17:53.629253
I0819 02:36:30.860739 140034352527168 train_slot.py:155] Step: 95400, Loss: 0.001410, Time: 6:18:17.048939
I0819 02:36:54.585735 140034352527168 train_slot.py:155] Step: 95500, Loss: 0.002119, Time: 6:18:40.773935
I0819 02:37:18.635627 140034352527168 train_slot.py:155] Step: 95600, Loss: 0.001615, Time: 6:19:04.823711
I0819 02:37:42.708617 140034352527168 train_slot.py:155] Step: 95700, Loss: 0.001440, Time: 6:19:28.896792
I0819 02:38:06.447979 140034352527168 train_slot.py:155] Step: 95800, Loss: 0.001487, Time: 6:19:52.636210
I0819 02:38:30.234074 140034352527168 train_slot.py:155] Step: 95900, Loss: 0.001506, Time: 6:20:16.422134
I0819 02:38:54.036190 140034352527168 train_slot.py:155] Step: 96000, Loss: 0.001473, Time: 6:20:40.224365
I0819 02:38:54.350207 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-96000
I0819 02:38:55.419060 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 96000
I0819 02:39:19.130846 140034352527168 train_slot.py:155] Step: 96100, Loss: 0.001369, Time: 6:21:05.319083
I0819 02:39:42.528071 140034352527168 train_slot.py:155] Step: 96200, Loss: 0.001625, Time: 6:21:28.716270
I0819 02:40:06.260873 140034352527168 train_slot.py:155] Step: 96300, Loss: 0.001576, Time: 6:21:52.448998
I0819 02:40:29.728641 140034352527168 train_slot.py:155] Step: 96400, Loss: 0.001536, Time: 6:22:15.916864
I0819 02:40:53.269144 140034352527168 train_slot.py:155] Step: 96500, Loss: 0.001543, Time: 6:22:39.457344
I0819 02:41:16.983346 140034352527168 train_slot.py:155] Step: 96600, Loss: 0.001435, Time: 6:23:03.171549
I0819 02:41:40.481425 140034352527168 train_slot.py:155] Step: 96700, Loss: 0.001529, Time: 6:23:26.669353
I0819 02:42:04.047408 140034352527168 train_slot.py:155] Step: 96800, Loss: 0.001431, Time: 6:23:50.235611
I0819 02:42:27.560547 140034352527168 train_slot.py:155] Step: 96900, Loss: 0.001557, Time: 6:24:13.748779
I0819 02:42:51.147464 140034352527168 train_slot.py:155] Step: 97000, Loss: 0.001573, Time: 6:24:37.335048
I0819 02:42:51.472894 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-97000
I0819 02:42:52.567136 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 97000
I0819 02:43:16.241564 140034352527168 train_slot.py:155] Step: 97100, Loss: 0.001638, Time: 6:25:02.429796
I0819 02:43:39.750040 140034352527168 train_slot.py:155] Step: 97200, Loss: 0.001455, Time: 6:25:25.938248
I0819 02:44:03.277552 140034352527168 train_slot.py:155] Step: 97300, Loss: 0.001481, Time: 6:25:49.465644
I0819 02:44:26.740051 140034352527168 train_slot.py:155] Step: 97400, Loss: 0.001814, Time: 6:26:12.928262
I0819 02:44:50.228441 140034352527168 train_slot.py:155] Step: 97500, Loss: 0.001388, Time: 6:26:36.416652
I0819 02:45:14.087580 140034352527168 train_slot.py:155] Step: 97600, Loss: 0.001348, Time: 6:27:00.275460
I0819 02:45:37.705019 140034352527168 train_slot.py:155] Step: 97700, Loss: 0.001583, Time: 6:27:23.893181
I0819 02:46:01.210176 140034352527168 train_slot.py:155] Step: 97800, Loss: 0.001511, Time: 6:27:47.398376
I0819 02:46:24.987911 140034352527168 train_slot.py:155] Step: 97900, Loss: 0.001586, Time: 6:28:11.175981
I0819 02:46:48.533108 140034352527168 train_slot.py:155] Step: 98000, Loss: 0.001853, Time: 6:28:34.721329
I0819 02:46:48.927148 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-98000
I0819 02:46:50.065587 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 98000
I0819 02:47:13.605995 140034352527168 train_slot.py:155] Step: 98100, Loss: 0.001447, Time: 6:28:59.794225
I0819 02:47:37.227412 140034352527168 train_slot.py:155] Step: 98200, Loss: 0.001418, Time: 6:29:23.415641
I0819 02:48:00.710087 140034352527168 train_slot.py:155] Step: 98300, Loss: 0.001506, Time: 6:29:46.898299
I0819 02:48:24.163586 140034352527168 train_slot.py:155] Step: 98400, Loss: 0.001567, Time: 6:30:10.351531
I0819 02:48:47.635170 140034352527168 train_slot.py:155] Step: 98500, Loss: 0.001454, Time: 6:30:33.823404
I0819 02:49:11.189112 140034352527168 train_slot.py:155] Step: 98600, Loss: 0.001384, Time: 6:30:57.377347
I0819 02:49:34.721227 140034352527168 train_slot.py:155] Step: 98700, Loss: 0.001580, Time: 6:31:20.909371
I0819 02:49:58.402352 140034352527168 train_slot.py:155] Step: 98800, Loss: 0.001407, Time: 6:31:44.590551
I0819 02:50:21.984298 140034352527168 train_slot.py:155] Step: 98900, Loss: 0.001270, Time: 6:32:08.172499
I0819 02:50:45.534344 140034352527168 train_slot.py:155] Step: 99000, Loss: 0.001654, Time: 6:32:31.722385
I0819 02:50:45.871821 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-99000
I0819 02:50:46.946064 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 99000
I0819 02:51:10.429995 140034352527168 train_slot.py:155] Step: 99100, Loss: 0.001669, Time: 6:32:56.618179
I0819 02:51:33.917005 140034352527168 train_slot.py:155] Step: 99200, Loss: 0.001567, Time: 6:33:20.105206
I0819 02:51:57.570841 140034352527168 train_slot.py:155] Step: 99300, Loss: 0.001378, Time: 6:33:43.759043
I0819 02:52:21.536567 140034352527168 train_slot.py:155] Step: 99400, Loss: 0.001650, Time: 6:34:07.724772
I0819 02:52:45.017495 140034352527168 train_slot.py:155] Step: 99500, Loss: 0.001538, Time: 6:34:31.205611
I0819 02:53:08.536463 140034352527168 train_slot.py:155] Step: 99600, Loss: 0.001158, Time: 6:34:54.724637
I0819 02:53:31.892703 140034352527168 train_slot.py:155] Step: 99700, Loss: 0.001172, Time: 6:35:18.080901
I0819 02:53:55.306133 140034352527168 train_slot.py:155] Step: 99800, Loss: 0.001864, Time: 6:35:41.494336
I0819 02:54:19.103363 140034352527168 train_slot.py:155] Step: 99900, Loss: 0.001419, Time: 6:36:05.291566
I0819 02:54:42.601466 140034352527168 train_slot.py:155] Step: 100000, Loss: 0.001590, Time: 6:36:28.789345
I0819 02:54:42.995088 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-100000
I0819 02:54:44.092500 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 100000
I0819 02:55:07.539862 140034352527168 train_slot.py:155] Step: 100100, Loss: 0.001379, Time: 6:36:53.728060
I0819 02:55:31.077419 140034352527168 train_slot.py:155] Step: 100200, Loss: 0.001563, Time: 6:37:17.265591
I0819 02:55:54.685180 140034352527168 train_slot.py:155] Step: 100300, Loss: 0.001489, Time: 6:37:40.873153
I0819 02:56:18.401467 140034352527168 train_slot.py:155] Step: 100400, Loss: 0.001923, Time: 6:38:04.589670
I0819 02:56:42.196598 140034352527168 train_slot.py:155] Step: 100500, Loss: 0.001705, Time: 6:38:28.384797
I0819 02:57:05.806235 140034352527168 train_slot.py:155] Step: 100600, Loss: 0.001485, Time: 6:38:51.994367
I0819 02:57:29.463767 140034352527168 train_slot.py:155] Step: 100700, Loss: 0.001323, Time: 6:39:15.651961
I0819 02:57:53.235151 140034352527168 train_slot.py:155] Step: 100800, Loss: 0.001212, Time: 6:39:39.423349
I0819 02:58:17.055603 140034352527168 train_slot.py:155] Step: 100900, Loss: 0.001468, Time: 6:40:03.243687
I0819 02:58:40.519516 140034352527168 train_slot.py:155] Step: 101000, Loss: 0.001281, Time: 6:40:26.707741
I0819 02:58:40.868366 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-101000
I0819 02:58:41.941868 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 101000
I0819 02:59:05.457593 140034352527168 train_slot.py:155] Step: 101100, Loss: 0.002199, Time: 6:40:51.645790
I0819 02:59:28.910767 140034352527168 train_slot.py:155] Step: 101200, Loss: 0.001254, Time: 6:41:15.098779
I0819 02:59:52.569859 140034352527168 train_slot.py:155] Step: 101300, Loss: 0.001736, Time: 6:41:38.758057
I0819 03:00:16.146501 140034352527168 train_slot.py:155] Step: 101400, Loss: 0.001800, Time: 6:42:02.334698
I0819 03:00:39.952562 140034352527168 train_slot.py:155] Step: 101500, Loss: 0.001503, Time: 6:42:26.140796
I0819 03:01:03.452039 140034352527168 train_slot.py:155] Step: 101600, Loss: 0.001310, Time: 6:42:49.640270
I0819 03:01:26.982446 140034352527168 train_slot.py:155] Step: 101700, Loss: 0.001502, Time: 6:43:13.170439
I0819 03:01:50.566622 140034352527168 train_slot.py:155] Step: 101800, Loss: 0.001429, Time: 6:43:36.754820
I0819 03:02:14.082254 140034352527168 train_slot.py:155] Step: 101900, Loss: 0.001279, Time: 6:44:00.270452
I0819 03:02:37.762989 140034352527168 train_slot.py:155] Step: 102000, Loss: 0.001276, Time: 6:44:23.951109
I0819 03:02:38.098180 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-102000
I0819 03:02:39.229523 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 102000
I0819 03:03:02.656368 140034352527168 train_slot.py:155] Step: 102100, Loss: 0.001266, Time: 6:44:48.844562
I0819 03:03:26.109501 140034352527168 train_slot.py:155] Step: 102200, Loss: 0.001768, Time: 6:45:12.297699
I0819 03:03:49.576211 140034352527168 train_slot.py:155] Step: 102300, Loss: 0.001595, Time: 6:45:35.764317
I0819 03:04:13.412415 140034352527168 train_slot.py:155] Step: 102400, Loss: 0.001773, Time: 6:45:59.600589
I0819 03:04:37.164201 140034352527168 train_slot.py:155] Step: 102500, Loss: 0.001423, Time: 6:46:23.352403
I0819 03:05:00.813312 140034352527168 train_slot.py:155] Step: 102600, Loss: 0.001144, Time: 6:46:47.001520
I0819 03:05:24.379371 140034352527168 train_slot.py:155] Step: 102700, Loss: 0.001456, Time: 6:47:10.567517
I0819 03:05:47.826068 140034352527168 train_slot.py:155] Step: 102800, Loss: 0.001544, Time: 6:47:34.014262
I0819 03:06:11.338015 140034352527168 train_slot.py:155] Step: 102900, Loss: 0.001176, Time: 6:47:57.526218
I0819 03:06:34.889099 140034352527168 train_slot.py:155] Step: 103000, Loss: 0.001476, Time: 6:48:21.077295
I0819 03:06:35.264242 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-103000
I0819 03:06:36.367235 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 103000
I0819 03:07:00.126499 140034352527168 train_slot.py:155] Step: 103100, Loss: 0.001425, Time: 6:48:46.314520
I0819 03:07:23.646143 140034352527168 train_slot.py:155] Step: 103200, Loss: 0.001448, Time: 6:49:09.834326
I0819 03:07:47.138356 140034352527168 train_slot.py:155] Step: 103300, Loss: 0.001358, Time: 6:49:33.326223
I0819 03:08:10.672056 140034352527168 train_slot.py:155] Step: 103400, Loss: 0.001462, Time: 6:49:56.860196
I0819 03:08:34.138970 140034352527168 train_slot.py:155] Step: 103500, Loss: 0.001327, Time: 6:50:20.327184
I0819 03:08:58.074319 140034352527168 train_slot.py:155] Step: 103600, Loss: 0.001698, Time: 6:50:44.262561
I0819 03:09:21.795419 140034352527168 train_slot.py:155] Step: 103700, Loss: 0.001594, Time: 6:51:07.983532
I0819 03:09:45.231078 140034352527168 train_slot.py:155] Step: 103800, Loss: 0.001670, Time: 6:51:31.419270
I0819 03:10:08.826369 140034352527168 train_slot.py:155] Step: 103900, Loss: 0.001406, Time: 6:51:55.014574
I0819 03:10:32.420031 140034352527168 train_slot.py:155] Step: 104000, Loss: 0.001269, Time: 6:52:18.607661
I0819 03:10:32.771056 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-104000
I0819 03:10:33.839298 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 104000
I0819 03:10:57.280043 140034352527168 train_slot.py:155] Step: 104100, Loss: 0.001693, Time: 6:52:43.468224
I0819 03:11:20.968553 140034352527168 train_slot.py:155] Step: 104200, Loss: 0.001385, Time: 6:53:07.156752
I0819 03:11:44.421720 140034352527168 train_slot.py:155] Step: 104300, Loss: 0.001110, Time: 6:53:30.609921
I0819 03:12:07.966359 140034352527168 train_slot.py:155] Step: 104400, Loss: 0.001221, Time: 6:53:54.154562
I0819 03:12:31.441092 140034352527168 train_slot.py:155] Step: 104500, Loss: 0.001152, Time: 6:54:17.629222
I0819 03:12:54.929218 140034352527168 train_slot.py:155] Step: 104600, Loss: 0.001542, Time: 6:54:41.117419
I0819 03:13:18.706999 140034352527168 train_slot.py:155] Step: 104700, Loss: 0.001574, Time: 6:55:04.895229
I0819 03:13:42.237797 140034352527168 train_slot.py:155] Step: 104800, Loss: 0.001136, Time: 6:55:28.425922
I0819 03:14:05.996667 140034352527168 train_slot.py:155] Step: 104900, Loss: 0.001665, Time: 6:55:52.184895
I0819 03:14:29.443656 140034352527168 train_slot.py:155] Step: 105000, Loss: 0.001332, Time: 6:56:15.631859
I0819 03:14:29.772102 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-105000
I0819 03:14:30.908643 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 105000
I0819 03:14:54.725929 140034352527168 train_slot.py:155] Step: 105100, Loss: 0.001431, Time: 6:56:40.914070
I0819 03:15:18.145157 140034352527168 train_slot.py:155] Step: 105200, Loss: 0.001268, Time: 6:57:04.333343
I0819 03:15:41.781262 140034352527168 train_slot.py:155] Step: 105300, Loss: 0.001408, Time: 6:57:27.969494
I0819 03:16:05.250953 140034352527168 train_slot.py:155] Step: 105400, Loss: 0.001641, Time: 6:57:51.439167
I0819 03:16:28.742061 140034352527168 train_slot.py:155] Step: 105500, Loss: 0.001287, Time: 6:58:14.930187
I0819 03:16:52.405393 140034352527168 train_slot.py:155] Step: 105600, Loss: 0.001569, Time: 6:58:38.593531
I0819 03:17:15.873765 140034352527168 train_slot.py:155] Step: 105700, Loss: 0.001533, Time: 6:59:02.061992
I0819 03:17:39.563619 140034352527168 train_slot.py:155] Step: 105800, Loss: 0.001367, Time: 6:59:25.751822
I0819 03:18:03.095172 140034352527168 train_slot.py:155] Step: 105900, Loss: 0.001533, Time: 6:59:49.283376
I0819 03:18:26.545429 140034352527168 train_slot.py:155] Step: 106000, Loss: 0.001650, Time: 7:00:12.733663
I0819 03:18:26.921875 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-106000
I0819 03:18:28.058962 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 106000
I0819 03:18:51.588385 140034352527168 train_slot.py:155] Step: 106100, Loss: 0.001508, Time: 7:00:37.776526
I0819 03:19:15.058352 140034352527168 train_slot.py:155] Step: 106200, Loss: 0.002142, Time: 7:01:01.246525
I0819 03:19:38.425370 140034352527168 train_slot.py:155] Step: 106300, Loss: 0.001415, Time: 7:01:24.613581
I0819 03:20:02.041517 140034352527168 train_slot.py:155] Step: 106400, Loss: 0.001618, Time: 7:01:48.229727
I0819 03:20:25.573535 140034352527168 train_slot.py:155] Step: 106500, Loss: 0.001175, Time: 7:02:11.761744
I0819 03:20:49.047631 140034352527168 train_slot.py:155] Step: 106600, Loss: 0.001425, Time: 7:02:35.235654
I0819 03:21:12.507239 140034352527168 train_slot.py:155] Step: 106700, Loss: 0.001475, Time: 7:02:58.695438
I0819 03:21:35.978663 140034352527168 train_slot.py:155] Step: 106800, Loss: 0.001531, Time: 7:03:22.166847
I0819 03:21:59.697503 140034352527168 train_slot.py:155] Step: 106900, Loss: 0.001375, Time: 7:03:45.885704
I0819 03:22:23.234184 140034352527168 train_slot.py:155] Step: 107000, Loss: 0.002299, Time: 7:04:09.422414
I0819 03:22:23.559369 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-107000
I0819 03:22:24.652066 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 107000
I0819 03:22:48.179710 140034352527168 train_slot.py:155] Step: 107100, Loss: 0.001830, Time: 7:04:34.367742
I0819 03:23:11.628051 140034352527168 train_slot.py:155] Step: 107200, Loss: 0.001549, Time: 7:04:57.816229
I0819 03:23:35.109133 140034352527168 train_slot.py:155] Step: 107300, Loss: 0.001528, Time: 7:05:21.297336
I0819 03:23:58.762996 140034352527168 train_slot.py:155] Step: 107400, Loss: 0.001533, Time: 7:05:44.950992
I0819 03:24:23.079035 140034352527168 train_slot.py:155] Step: 107500, Loss: 0.001244, Time: 7:06:09.267259
I0819 03:24:47.065747 140034352527168 train_slot.py:155] Step: 107600, Loss: 0.001359, Time: 7:06:33.253947
I0819 03:25:11.238103 140034352527168 train_slot.py:155] Step: 107700, Loss: 0.001333, Time: 7:06:57.426162
I0819 03:25:35.140998 140034352527168 train_slot.py:155] Step: 107800, Loss: 0.001242, Time: 7:07:21.329125
I0819 03:25:59.041836 140034352527168 train_slot.py:155] Step: 107900, Loss: 0.001377, Time: 7:07:45.230054
I0819 03:26:22.971938 140034352527168 train_slot.py:155] Step: 108000, Loss: 0.001306, Time: 7:08:09.159934
I0819 03:26:23.309976 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-108000
I0819 03:26:24.377068 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 108000
I0819 03:26:47.941805 140034352527168 train_slot.py:155] Step: 108100, Loss: 0.001263, Time: 7:08:34.129956
I0819 03:27:11.535756 140034352527168 train_slot.py:155] Step: 108200, Loss: 0.001048, Time: 7:08:57.723964
I0819 03:27:35.020901 140034352527168 train_slot.py:155] Step: 108300, Loss: 0.001363, Time: 7:09:21.209136
I0819 03:27:58.453098 140034352527168 train_slot.py:155] Step: 108400, Loss: 0.001454, Time: 7:09:44.641226
I0819 03:28:22.189351 140034352527168 train_slot.py:155] Step: 108500, Loss: 0.001397, Time: 7:10:08.377536
I0819 03:28:46.012533 140034352527168 train_slot.py:155] Step: 108600, Loss: 0.001371, Time: 7:10:32.200740
I0819 03:29:09.867280 140034352527168 train_slot.py:155] Step: 108700, Loss: 0.001806, Time: 7:10:56.055322
I0819 03:29:33.659316 140034352527168 train_slot.py:155] Step: 108800, Loss: 0.001144, Time: 7:11:19.847496
I0819 03:29:57.457329 140034352527168 train_slot.py:155] Step: 108900, Loss: 0.001392, Time: 7:11:43.645535
I0819 03:30:21.266523 140034352527168 train_slot.py:155] Step: 109000, Loss: 0.001357, Time: 7:12:07.454731
I0819 03:30:21.623424 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-109000
I0819 03:30:22.691519 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 109000
I0819 03:30:46.564890 140034352527168 train_slot.py:155] Step: 109100, Loss: 0.001564, Time: 7:12:32.753043
I0819 03:31:09.991185 140034352527168 train_slot.py:155] Step: 109200, Loss: 0.001458, Time: 7:12:56.179414
I0819 03:31:33.597074 140034352527168 train_slot.py:155] Step: 109300, Loss: 0.001492, Time: 7:13:19.785257
I0819 03:31:56.984381 140034352527168 train_slot.py:155] Step: 109400, Loss: 0.001354, Time: 7:13:43.172611
I0819 03:32:20.499518 140034352527168 train_slot.py:155] Step: 109500, Loss: 0.001298, Time: 7:14:06.687719
I0819 03:32:44.322199 140034352527168 train_slot.py:155] Step: 109600, Loss: 0.001007, Time: 7:14:30.510137
I0819 03:33:07.724167 140034352527168 train_slot.py:155] Step: 109700, Loss: 0.001547, Time: 7:14:53.912307
I0819 03:33:31.396319 140034352527168 train_slot.py:155] Step: 109800, Loss: 0.001237, Time: 7:15:17.584519
I0819 03:33:54.797347 140034352527168 train_slot.py:155] Step: 109900, Loss: 0.001359, Time: 7:15:40.985516
I0819 03:34:18.113868 140034352527168 train_slot.py:155] Step: 110000, Loss: 0.001672, Time: 7:16:04.302098
I0819 03:34:18.433500 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-110000
I0819 03:34:19.503265 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 110000
I0819 03:34:43.210201 140034352527168 train_slot.py:155] Step: 110100, Loss: 0.001207, Time: 7:16:29.398333
I0819 03:35:06.900827 140034352527168 train_slot.py:155] Step: 110200, Loss: 0.001344, Time: 7:16:53.089036
I0819 03:35:30.392342 140034352527168 train_slot.py:155] Step: 110300, Loss: 0.001661, Time: 7:17:16.580558
I0819 03:35:53.796967 140034352527168 train_slot.py:155] Step: 110400, Loss: 0.001485, Time: 7:17:39.984993
I0819 03:36:17.293059 140034352527168 train_slot.py:155] Step: 110500, Loss: 0.001405, Time: 7:18:03.481246
I0819 03:36:40.745142 140034352527168 train_slot.py:155] Step: 110600, Loss: 0.001158, Time: 7:18:26.933342
I0819 03:37:04.524858 140034352527168 train_slot.py:155] Step: 110700, Loss: 0.001509, Time: 7:18:50.713086
I0819 03:37:28.009260 140034352527168 train_slot.py:155] Step: 110800, Loss: 0.001322, Time: 7:19:14.197376
I0819 03:37:51.523091 140034352527168 train_slot.py:155] Step: 110900, Loss: 0.001525, Time: 7:19:37.711233
I0819 03:38:15.063578 140034352527168 train_slot.py:155] Step: 111000, Loss: 0.001407, Time: 7:20:01.251781
I0819 03:38:15.418201 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-111000
I0819 03:38:16.498820 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 111000
I0819 03:38:40.012594 140034352527168 train_slot.py:155] Step: 111100, Loss: 0.001307, Time: 7:20:26.200763
I0819 03:39:03.683573 140034352527168 train_slot.py:155] Step: 111200, Loss: 0.001372, Time: 7:20:49.871719
I0819 03:39:27.736562 140034352527168 train_slot.py:155] Step: 111300, Loss: 0.001478, Time: 7:21:13.924771
I0819 03:39:51.481482 140034352527168 train_slot.py:155] Step: 111400, Loss: 0.001508, Time: 7:21:37.669687
I0819 03:40:15.205423 140034352527168 train_slot.py:155] Step: 111500, Loss: 0.001586, Time: 7:22:01.393540
I0819 03:40:38.883247 140034352527168 train_slot.py:155] Step: 111600, Loss: 0.001416, Time: 7:22:25.071378
I0819 03:41:03.098994 140034352527168 train_slot.py:155] Step: 111700, Loss: 0.001605, Time: 7:22:49.287228
I0819 03:41:26.866482 140034352527168 train_slot.py:155] Step: 111800, Loss: 0.001489, Time: 7:23:13.054060
I0819 03:41:50.344612 140034352527168 train_slot.py:155] Step: 111900, Loss: 0.001485, Time: 7:23:36.532745
I0819 03:42:13.877441 140034352527168 train_slot.py:155] Step: 112000, Loss: 0.001364, Time: 7:24:00.065646
I0819 03:42:14.197327 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-112000
I0819 03:42:15.268262 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 112000
I0819 03:42:38.884417 140034352527168 train_slot.py:155] Step: 112100, Loss: 0.001951, Time: 7:24:25.072617
I0819 03:43:02.326146 140034352527168 train_slot.py:155] Step: 112200, Loss: 0.001525, Time: 7:24:48.514266
I0819 03:43:26.064476 140034352527168 train_slot.py:155] Step: 112300, Loss: 0.001032, Time: 7:25:12.252703
I0819 03:43:49.621368 140034352527168 train_slot.py:155] Step: 112400, Loss: 0.001341, Time: 7:25:35.809574
I0819 03:44:13.178476 140034352527168 train_slot.py:155] Step: 112500, Loss: 0.001588, Time: 7:25:59.366614
I0819 03:44:36.656720 140034352527168 train_slot.py:155] Step: 112600, Loss: 0.001338, Time: 7:26:22.844897
I0819 03:45:00.108144 140034352527168 train_slot.py:155] Step: 112700, Loss: 0.001467, Time: 7:26:46.296363
I0819 03:45:23.848656 140034352527168 train_slot.py:155] Step: 112800, Loss: 0.001082, Time: 7:27:10.036896
I0819 03:45:47.525693 140034352527168 train_slot.py:155] Step: 112900, Loss: 0.001328, Time: 7:27:33.713812
I0819 03:46:11.009362 140034352527168 train_slot.py:155] Step: 113000, Loss: 0.001790, Time: 7:27:57.197516
I0819 03:46:11.328126 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-113000
I0819 03:46:12.407927 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 113000
I0819 03:46:35.944226 140034352527168 train_slot.py:155] Step: 113100, Loss: 0.001484, Time: 7:28:22.132326
I0819 03:46:59.410133 140034352527168 train_slot.py:155] Step: 113200, Loss: 0.001421, Time: 7:28:45.598293
I0819 03:47:22.917137 140034352527168 train_slot.py:155] Step: 113300, Loss: 0.001326, Time: 7:29:09.105356
I0819 03:47:46.645190 140034352527168 train_slot.py:155] Step: 113400, Loss: 0.001451, Time: 7:29:32.833326
I0819 03:48:10.077800 140034352527168 train_slot.py:155] Step: 113500, Loss: 0.001125, Time: 7:29:56.266026
I0819 03:48:33.724325 140034352527168 train_slot.py:155] Step: 113600, Loss: 0.001330, Time: 7:30:19.912554
I0819 03:48:57.260805 140034352527168 train_slot.py:155] Step: 113700, Loss: 0.001497, Time: 7:30:43.449025
I0819 03:49:21.226668 140034352527168 train_slot.py:155] Step: 113800, Loss: 0.001690, Time: 7:31:07.414902
I0819 03:49:44.700629 140034352527168 train_slot.py:155] Step: 113900, Loss: 0.001749, Time: 7:31:30.888835
I0819 03:50:08.539073 140034352527168 train_slot.py:155] Step: 114000, Loss: 0.001441, Time: 7:31:54.727186
I0819 03:50:08.873292 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-114000
I0819 03:50:10.028486 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 114000
I0819 03:50:33.528027 140034352527168 train_slot.py:155] Step: 114100, Loss: 0.001296, Time: 7:32:19.716247
I0819 03:50:57.315062 140034352527168 train_slot.py:155] Step: 114200, Loss: 0.001368, Time: 7:32:43.503265
I0819 03:51:20.921690 140034352527168 train_slot.py:155] Step: 114300, Loss: 0.001395, Time: 7:33:07.109890
I0819 03:51:44.471769 140034352527168 train_slot.py:155] Step: 114400, Loss: 0.001258, Time: 7:33:30.659923
I0819 03:52:08.151910 140034352527168 train_slot.py:155] Step: 114500, Loss: 0.001123, Time: 7:33:54.340087
I0819 03:52:31.615605 140034352527168 train_slot.py:155] Step: 114600, Loss: 0.001132, Time: 7:34:17.803806
I0819 03:52:55.101894 140034352527168 train_slot.py:155] Step: 114700, Loss: 0.001556, Time: 7:34:41.289440
I0819 03:53:18.717085 140034352527168 train_slot.py:155] Step: 114800, Loss: 0.001317, Time: 7:35:04.905320
I0819 03:53:42.220772 140034352527168 train_slot.py:155] Step: 114900, Loss: 0.001226, Time: 7:35:28.409009
I0819 03:54:05.936332 140034352527168 train_slot.py:155] Step: 115000, Loss: 0.001229, Time: 7:35:52.124547
I0819 03:54:06.292390 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-115000
I0819 03:54:07.362468 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 115000
I0819 03:54:30.810231 140034352527168 train_slot.py:155] Step: 115100, Loss: 0.001741, Time: 7:36:16.998430
I0819 03:54:54.241059 140034352527168 train_slot.py:155] Step: 115200, Loss: 0.001419, Time: 7:36:40.429278
I0819 03:55:17.667034 140034352527168 train_slot.py:155] Step: 115300, Loss: 0.001623, Time: 7:37:03.855055
I0819 03:55:41.178891 140034352527168 train_slot.py:155] Step: 115400, Loss: 0.001304, Time: 7:37:27.367029
I0819 03:56:04.723752 140034352527168 train_slot.py:155] Step: 115500, Loss: 0.001438, Time: 7:37:50.911950
I0819 03:56:28.482581 140034352527168 train_slot.py:155] Step: 115600, Loss: 0.001657, Time: 7:38:14.670742
I0819 03:56:51.977651 140034352527168 train_slot.py:155] Step: 115700, Loss: 0.001314, Time: 7:38:38.165804
I0819 03:57:15.684292 140034352527168 train_slot.py:155] Step: 115800, Loss: 0.001508, Time: 7:39:01.872489
I0819 03:57:39.341874 140034352527168 train_slot.py:155] Step: 115900, Loss: 0.001475, Time: 7:39:25.530081
I0819 03:58:02.817073 140034352527168 train_slot.py:155] Step: 116000, Loss: 0.001226, Time: 7:39:49.004926
I0819 03:58:03.150590 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-116000
I0819 03:58:04.281739 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 116000
I0819 03:58:27.994841 140034352527168 train_slot.py:155] Step: 116100, Loss: 0.001276, Time: 7:40:14.183033
I0819 03:58:51.463254 140034352527168 train_slot.py:155] Step: 116200, Loss: 0.001114, Time: 7:40:37.651455
I0819 03:59:15.286222 140034352527168 train_slot.py:155] Step: 116300, Loss: 0.001171, Time: 7:41:01.474383
I0819 03:59:38.813020 140034352527168 train_slot.py:155] Step: 116400, Loss: 0.001531, Time: 7:41:25.001187
I0819 04:00:02.247348 140034352527168 train_slot.py:155] Step: 116500, Loss: 0.001150, Time: 7:41:48.435567
I0819 04:00:25.701427 140034352527168 train_slot.py:155] Step: 116600, Loss: 0.001075, Time: 7:42:11.889653
I0819 04:00:49.440554 140034352527168 train_slot.py:155] Step: 116700, Loss: 0.001428, Time: 7:42:35.628576
I0819 04:01:12.959202 140034352527168 train_slot.py:155] Step: 116800, Loss: 0.001078, Time: 7:42:59.147352
I0819 04:01:36.480414 140034352527168 train_slot.py:155] Step: 116900, Loss: 0.001451, Time: 7:43:22.668619
I0819 04:02:00.256589 140034352527168 train_slot.py:155] Step: 117000, Loss: 0.001501, Time: 7:43:46.444808
I0819 04:02:00.571252 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-117000
I0819 04:02:01.638107 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 117000
I0819 04:02:25.245506 140034352527168 train_slot.py:155] Step: 117100, Loss: 0.001099, Time: 7:44:11.433630
I0819 04:02:48.978599 140034352527168 train_slot.py:155] Step: 117200, Loss: 0.001278, Time: 7:44:35.166807
I0819 04:03:12.513015 140034352527168 train_slot.py:155] Step: 117300, Loss: 0.001339, Time: 7:44:58.701214
I0819 04:03:36.093338 140034352527168 train_slot.py:155] Step: 117400, Loss: 0.001439, Time: 7:45:22.281457
I0819 04:03:59.525735 140034352527168 train_slot.py:155] Step: 117500, Loss: 0.001266, Time: 7:45:45.713930
I0819 04:04:23.006691 140034352527168 train_slot.py:155] Step: 117600, Loss: 0.001318, Time: 7:46:09.194920
I0819 04:04:46.496889 140034352527168 train_slot.py:155] Step: 117700, Loss: 0.001263, Time: 7:46:32.685107
I0819 04:05:10.465073 140034352527168 train_slot.py:155] Step: 117800, Loss: 0.001120, Time: 7:46:56.653195
I0819 04:05:34.158190 140034352527168 train_slot.py:155] Step: 117900, Loss: 0.001396, Time: 7:47:20.346327
I0819 04:05:57.546240 140034352527168 train_slot.py:155] Step: 118000, Loss: 0.001187, Time: 7:47:43.734445
I0819 04:05:57.875383 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-118000
I0819 04:05:58.958575 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 118000
I0819 04:06:22.787433 140034352527168 train_slot.py:155] Step: 118100, Loss: 0.001281, Time: 7:48:08.975632
I0819 04:06:46.554640 140034352527168 train_slot.py:155] Step: 118200, Loss: 0.001259, Time: 7:48:32.742741
I0819 04:07:10.279120 140034352527168 train_slot.py:155] Step: 118300, Loss: 0.001169, Time: 7:48:56.467314
I0819 04:07:33.746523 140034352527168 train_slot.py:155] Step: 118400, Loss: 0.001673, Time: 7:49:19.934722
I0819 04:07:57.370689 140034352527168 train_slot.py:155] Step: 118500, Loss: 0.001017, Time: 7:49:43.558700
I0819 04:08:20.931742 140034352527168 train_slot.py:155] Step: 118600, Loss: 0.001927, Time: 7:50:07.119862
I0819 04:08:44.457659 140034352527168 train_slot.py:155] Step: 118700, Loss: 0.001392, Time: 7:50:30.645803
I0819 04:09:08.177614 140034352527168 train_slot.py:155] Step: 118800, Loss: 0.001505, Time: 7:50:54.365842
I0819 04:09:31.776460 140034352527168 train_slot.py:155] Step: 118900, Loss: 0.001657, Time: 7:51:17.964506
I0819 04:09:55.375017 140034352527168 train_slot.py:155] Step: 119000, Loss: 0.001612, Time: 7:51:41.563224
I0819 04:09:55.713981 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-119000
I0819 04:09:56.892342 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 119000
I0819 04:10:20.444100 140034352527168 train_slot.py:155] Step: 119100, Loss: 0.001277, Time: 7:52:06.632294
I0819 04:10:44.066874 140034352527168 train_slot.py:155] Step: 119200, Loss: 0.001164, Time: 7:52:30.255089
I0819 04:11:07.510567 140034352527168 train_slot.py:155] Step: 119300, Loss: 0.001410, Time: 7:52:53.698299
I0819 04:11:31.406122 140034352527168 train_slot.py:155] Step: 119400, Loss: 0.001120, Time: 7:53:17.594312
I0819 04:11:54.875953 140034352527168 train_slot.py:155] Step: 119500, Loss: 0.001282, Time: 7:53:41.064153
I0819 04:12:18.506192 140034352527168 train_slot.py:155] Step: 119600, Loss: 0.001594, Time: 7:54:04.694402
I0819 04:12:42.028560 140034352527168 train_slot.py:155] Step: 119700, Loss: 0.001093, Time: 7:54:28.216674
I0819 04:13:05.770314 140034352527168 train_slot.py:155] Step: 119800, Loss: 0.001565, Time: 7:54:51.958494
I0819 04:13:29.455174 140034352527168 train_slot.py:155] Step: 119900, Loss: 0.001298, Time: 7:55:15.643379
I0819 04:13:52.992096 140034352527168 train_slot.py:155] Step: 120000, Loss: 0.001223, Time: 7:55:39.180309
I0819 04:13:53.361587 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-120000
I0819 04:13:54.430408 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 120000
I0819 04:14:18.044279 140034352527168 train_slot.py:155] Step: 120100, Loss: 0.001147, Time: 7:56:04.231837
I0819 04:14:41.629695 140034352527168 train_slot.py:155] Step: 120200, Loss: 0.001279, Time: 7:56:27.817894
I0819 04:15:05.182435 140034352527168 train_slot.py:155] Step: 120300, Loss: 0.001331, Time: 7:56:51.370638
I0819 04:15:28.648703 140034352527168 train_slot.py:155] Step: 120400, Loss: 0.001545, Time: 7:57:14.836915
I0819 04:15:52.325344 140034352527168 train_slot.py:155] Step: 120500, Loss: 0.001344, Time: 7:57:38.513449
I0819 04:16:15.941772 140034352527168 train_slot.py:155] Step: 120600, Loss: 0.001366, Time: 7:58:02.129839
I0819 04:16:39.279378 140034352527168 train_slot.py:155] Step: 120700, Loss: 0.001452, Time: 7:58:25.467584
I0819 04:17:02.806975 140034352527168 train_slot.py:155] Step: 120800, Loss: 0.001282, Time: 7:58:48.995204
I0819 04:17:26.537914 140034352527168 train_slot.py:155] Step: 120900, Loss: 0.001462, Time: 7:59:12.726148
I0819 04:17:50.353465 140034352527168 train_slot.py:155] Step: 121000, Loss: 0.001214, Time: 7:59:36.541476
I0819 04:17:50.726325 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-121000
I0819 04:17:51.855704 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 121000
I0819 04:18:15.367355 140034352527168 train_slot.py:155] Step: 121100, Loss: 0.001425, Time: 8:00:01.555555
I0819 04:18:39.084649 140034352527168 train_slot.py:155] Step: 121200, Loss: 0.001334, Time: 8:00:25.272852
I0819 04:19:02.489387 140034352527168 train_slot.py:155] Step: 121300, Loss: 0.001360, Time: 8:00:48.677592
I0819 04:19:25.990728 140034352527168 train_slot.py:155] Step: 121400, Loss: 0.001634, Time: 8:01:12.178960
I0819 04:19:49.540023 140034352527168 train_slot.py:155] Step: 121500, Loss: 0.001309, Time: 8:01:35.728087
I0819 04:20:13.328110 140034352527168 train_slot.py:155] Step: 121600, Loss: 0.001179, Time: 8:01:59.516294
I0819 04:20:36.743500 140034352527168 train_slot.py:155] Step: 121700, Loss: 0.001638, Time: 8:02:22.931703
I0819 04:21:00.280790 140034352527168 train_slot.py:155] Step: 121800, Loss: 0.001215, Time: 8:02:46.469017
I0819 04:21:23.821330 140034352527168 train_slot.py:155] Step: 121900, Loss: 0.001232, Time: 8:03:10.009317
I0819 04:21:47.225429 140034352527168 train_slot.py:155] Step: 122000, Loss: 0.001346, Time: 8:03:33.413631
I0819 04:21:47.553932 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-122000
I0819 04:21:48.687273 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 122000
I0819 04:22:12.454585 140034352527168 train_slot.py:155] Step: 122100, Loss: 0.001627, Time: 8:03:58.642786
I0819 04:22:35.916789 140034352527168 train_slot.py:155] Step: 122200, Loss: 0.001215, Time: 8:04:22.104997
I0819 04:22:59.399819 140034352527168 train_slot.py:155] Step: 122300, Loss: 0.001240, Time: 8:04:45.587928
I0819 04:23:22.907239 140034352527168 train_slot.py:155] Step: 122400, Loss: 0.001484, Time: 8:05:09.095376
I0819 04:23:46.431115 140034352527168 train_slot.py:155] Step: 122500, Loss: 0.001106, Time: 8:05:32.619314
I0819 04:24:10.175100 140034352527168 train_slot.py:155] Step: 122600, Loss: 0.001957, Time: 8:05:56.363303
I0819 04:24:33.701214 140034352527168 train_slot.py:155] Step: 122700, Loss: 0.001212, Time: 8:06:19.889283
I0819 04:24:57.411820 140034352527168 train_slot.py:155] Step: 122800, Loss: 0.001295, Time: 8:06:43.600039
I0819 04:25:20.922420 140034352527168 train_slot.py:155] Step: 122900, Loss: 0.001303, Time: 8:07:07.110627
I0819 04:25:44.452288 140034352527168 train_slot.py:155] Step: 123000, Loss: 0.001211, Time: 8:07:30.640417
I0819 04:25:44.821905 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-123000
I0819 04:25:45.951548 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 123000
I0819 04:26:09.513185 140034352527168 train_slot.py:155] Step: 123100, Loss: 0.001084, Time: 8:07:55.701261
I0819 04:26:33.245725 140034352527168 train_slot.py:155] Step: 123200, Loss: 0.001071, Time: 8:08:19.433878
I0819 04:26:56.810673 140034352527168 train_slot.py:155] Step: 123300, Loss: 0.001366, Time: 8:08:42.998904
I0819 04:27:20.267416 140034352527168 train_slot.py:155] Step: 123400, Loss: 0.001377, Time: 8:09:06.455482
I0819 04:27:43.705922 140034352527168 train_slot.py:155] Step: 123500, Loss: 0.001289, Time: 8:09:29.894055
I0819 04:28:07.069307 140034352527168 train_slot.py:155] Step: 123600, Loss: 0.001129, Time: 8:09:53.257507
I0819 04:28:30.806995 140034352527168 train_slot.py:155] Step: 123700, Loss: 0.001240, Time: 8:10:16.995209
I0819 04:28:54.785144 140034352527168 train_slot.py:155] Step: 123800, Loss: 0.001211, Time: 8:10:40.973255
I0819 04:29:18.244617 140034352527168 train_slot.py:155] Step: 123900, Loss: 0.001612, Time: 8:11:04.432830
I0819 04:29:41.691589 140034352527168 train_slot.py:155] Step: 124000, Loss: 0.001261, Time: 8:11:27.879768
I0819 04:29:42.092978 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-124000
I0819 04:29:43.166907 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 124000
I0819 04:30:06.637288 140034352527168 train_slot.py:155] Step: 124100, Loss: 0.001317, Time: 8:11:52.825490
I0819 04:30:30.024075 140034352527168 train_slot.py:155] Step: 124200, Loss: 0.001741, Time: 8:12:16.212311
I0819 04:30:53.993891 140034352527168 train_slot.py:155] Step: 124300, Loss: 0.001148, Time: 8:12:40.181801
I0819 04:31:17.481025 140034352527168 train_slot.py:155] Step: 124400, Loss: 0.001234, Time: 8:13:03.669221
I0819 04:31:41.099986 140034352527168 train_slot.py:155] Step: 124500, Loss: 0.001317, Time: 8:13:27.288224
I0819 04:32:04.672764 140034352527168 train_slot.py:155] Step: 124600, Loss: 0.001132, Time: 8:13:50.860966
I0819 04:32:28.192698 140034352527168 train_slot.py:155] Step: 124700, Loss: 0.001552, Time: 8:14:14.380907
I0819 04:32:51.813593 140034352527168 train_slot.py:155] Step: 124800, Loss: 0.001114, Time: 8:14:38.001708
I0819 04:33:15.321890 140034352527168 train_slot.py:155] Step: 124900, Loss: 0.001489, Time: 8:15:01.510117
I0819 04:33:38.877202 140034352527168 train_slot.py:155] Step: 125000, Loss: 0.001275, Time: 8:15:25.065439
I0819 04:33:39.235712 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-125000
I0819 04:33:40.311072 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 125000
I0819 04:34:03.801072 140034352527168 train_slot.py:155] Step: 125100, Loss: 0.001304, Time: 8:15:49.989274
I0819 04:34:27.261500 140034352527168 train_slot.py:155] Step: 125200, Loss: 0.001078, Time: 8:16:13.449441
I0819 04:34:50.719699 140034352527168 train_slot.py:155] Step: 125300, Loss: 0.001347, Time: 8:16:36.907912
I0819 04:35:14.482773 140034352527168 train_slot.py:155] Step: 125400, Loss: 0.001336, Time: 8:17:00.671003
I0819 04:35:38.333366 140034352527168 train_slot.py:155] Step: 125500, Loss: 0.001488, Time: 8:17:24.521543
I0819 04:36:01.925162 140034352527168 train_slot.py:155] Step: 125600, Loss: 0.001375, Time: 8:17:48.113324
I0819 04:36:25.473150 140034352527168 train_slot.py:155] Step: 125700, Loss: 0.001429, Time: 8:18:11.661351
I0819 04:36:48.871850 140034352527168 train_slot.py:155] Step: 125800, Loss: 0.001398, Time: 8:18:35.060053
I0819 04:37:12.579364 140034352527168 train_slot.py:155] Step: 125900, Loss: 0.000973, Time: 8:18:58.767568
I0819 04:37:36.132760 140034352527168 train_slot.py:155] Step: 126000, Loss: 0.001268, Time: 8:19:22.320755
I0819 04:37:36.517836 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-126000
I0819 04:37:37.655185 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 126000
I0819 04:38:01.469698 140034352527168 train_slot.py:155] Step: 126100, Loss: 0.001405, Time: 8:19:47.657893
I0819 04:38:24.981288 140034352527168 train_slot.py:155] Step: 126200, Loss: 0.001421, Time: 8:20:11.169499
I0819 04:38:48.460045 140034352527168 train_slot.py:155] Step: 126300, Loss: 0.001468, Time: 8:20:34.648247
I0819 04:39:12.200405 140034352527168 train_slot.py:155] Step: 126400, Loss: 0.001134, Time: 8:20:58.388396
I0819 04:39:35.866480 140034352527168 train_slot.py:155] Step: 126500, Loss: 0.001229, Time: 8:21:22.054646
I0819 04:39:59.461471 140034352527168 train_slot.py:155] Step: 126600, Loss: 0.001221, Time: 8:21:45.649696
I0819 04:40:23.012719 140034352527168 train_slot.py:155] Step: 126700, Loss: 0.001239, Time: 8:22:09.200740
I0819 04:40:46.482957 140034352527168 train_slot.py:155] Step: 126800, Loss: 0.001386, Time: 8:22:32.671157
I0819 04:41:09.925383 140034352527168 train_slot.py:155] Step: 126900, Loss: 0.001265, Time: 8:22:56.113582
I0819 04:41:33.600606 140034352527168 train_slot.py:155] Step: 127000, Loss: 0.001239, Time: 8:23:19.788840
I0819 04:41:34.012579 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-127000
I0819 04:41:35.188751 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 127000
I0819 04:41:58.868648 140034352527168 train_slot.py:155] Step: 127100, Loss: 0.001423, Time: 8:23:45.056653
I0819 04:42:22.391889 140034352527168 train_slot.py:155] Step: 127200, Loss: 0.001238, Time: 8:24:08.580122
I0819 04:42:45.935939 140034352527168 train_slot.py:155] Step: 127300, Loss: 0.001528, Time: 8:24:32.124158
I0819 04:43:09.455986 140034352527168 train_slot.py:155] Step: 127400, Loss: 0.001558, Time: 8:24:55.644186
I0819 04:43:33.201205 140034352527168 train_slot.py:155] Step: 127500, Loss: 0.001434, Time: 8:25:19.389225
I0819 04:43:56.744644 140034352527168 train_slot.py:155] Step: 127600, Loss: 0.001652, Time: 8:25:42.932798
I0819 04:44:20.270277 140034352527168 train_slot.py:155] Step: 127700, Loss: 0.001532, Time: 8:26:06.458462
I0819 04:44:43.760517 140034352527168 train_slot.py:155] Step: 127800, Loss: 0.001306, Time: 8:26:29.948716
I0819 04:45:07.098134 140034352527168 train_slot.py:155] Step: 127900, Loss: 0.001519, Time: 8:26:53.286347
I0819 04:45:30.476788 140034352527168 train_slot.py:155] Step: 128000, Loss: 0.001182, Time: 8:27:16.664993
I0819 04:45:30.857583 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-128000
I0819 04:45:31.997694 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 128000
I0819 04:45:55.659610 140034352527168 train_slot.py:155] Step: 128100, Loss: 0.001083, Time: 8:27:41.847842
I0819 04:46:19.224753 140034352527168 train_slot.py:155] Step: 128200, Loss: 0.001414, Time: 8:28:05.412870
I0819 04:46:42.749443 140034352527168 train_slot.py:155] Step: 128300, Loss: 0.001311, Time: 8:28:28.937621
I0819 04:47:06.770707 140034352527168 train_slot.py:155] Step: 128400, Loss: 0.001462, Time: 8:28:52.958912
I0819 04:47:30.296574 140034352527168 train_slot.py:155] Step: 128500, Loss: 0.001424, Time: 8:29:16.484606
I0819 04:47:54.234136 140034352527168 train_slot.py:155] Step: 128600, Loss: 0.001179, Time: 8:29:40.422319
I0819 04:48:17.757471 140034352527168 train_slot.py:155] Step: 128700, Loss: 0.001283, Time: 8:30:03.945671
I0819 04:48:41.180053 140034352527168 train_slot.py:155] Step: 128800, Loss: 0.001183, Time: 8:30:27.368157
I0819 04:49:04.709898 140034352527168 train_slot.py:155] Step: 128900, Loss: 0.001233, Time: 8:30:50.898130
I0819 04:49:28.534355 140034352527168 train_slot.py:155] Step: 129000, Loss: 0.001410, Time: 8:31:14.722558
I0819 04:49:28.946634 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-129000
I0819 04:49:30.079974 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 129000
I0819 04:49:53.602121 140034352527168 train_slot.py:155] Step: 129100, Loss: 0.001187, Time: 8:31:39.790274
I0819 04:50:17.253826 140034352527168 train_slot.py:155] Step: 129200, Loss: 0.001615, Time: 8:32:03.441957
I0819 04:50:40.740115 140034352527168 train_slot.py:155] Step: 129300, Loss: 0.001333, Time: 8:32:26.928332
I0819 04:51:04.293743 140034352527168 train_slot.py:155] Step: 129400, Loss: 0.001358, Time: 8:32:50.481497
I0819 04:51:27.798815 140034352527168 train_slot.py:155] Step: 129500, Loss: 0.001417, Time: 8:33:13.987039
I0819 04:51:51.291750 140034352527168 train_slot.py:155] Step: 129600, Loss: 0.001650, Time: 8:33:37.479959
I0819 04:52:15.034274 140034352527168 train_slot.py:155] Step: 129700, Loss: 0.001267, Time: 8:34:01.222481
I0819 04:52:38.889517 140034352527168 train_slot.py:155] Step: 129800, Loss: 0.001587, Time: 8:34:25.077671
I0819 04:53:02.379454 140034352527168 train_slot.py:155] Step: 129900, Loss: 0.001192, Time: 8:34:48.567659
I0819 04:53:25.919931 140034352527168 train_slot.py:155] Step: 130000, Loss: 0.001409, Time: 8:35:12.108117
I0819 04:53:26.233955 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-130000
I0819 04:53:27.306122 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 130000
I0819 04:53:51.130604 140034352527168 train_slot.py:155] Step: 130100, Loss: 0.001780, Time: 8:35:37.318803
I0819 04:54:14.861707 140034352527168 train_slot.py:155] Step: 130200, Loss: 0.001147, Time: 8:36:01.049544
I0819 04:54:38.397080 140034352527168 train_slot.py:155] Step: 130300, Loss: 0.001583, Time: 8:36:24.585275
I0819 04:55:01.934527 140034352527168 train_slot.py:155] Step: 130400, Loss: 0.001272, Time: 8:36:48.122739
I0819 04:55:25.522846 140034352527168 train_slot.py:155] Step: 130500, Loss: 0.001316, Time: 8:37:11.710967
I0819 04:55:49.046122 140034352527168 train_slot.py:155] Step: 130600, Loss: 0.001396, Time: 8:37:35.234314
I0819 04:56:12.630962 140034352527168 train_slot.py:155] Step: 130700, Loss: 0.001248, Time: 8:37:58.819161
I0819 04:56:36.515645 140034352527168 train_slot.py:155] Step: 130800, Loss: 0.001459, Time: 8:38:22.703803
I0819 04:57:00.139493 140034352527168 train_slot.py:155] Step: 130900, Loss: 0.001212, Time: 8:38:46.327665
I0819 04:57:23.662943 140034352527168 train_slot.py:155] Step: 131000, Loss: 0.001145, Time: 8:39:09.851165
I0819 04:57:24.001152 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-131000
I0819 04:57:25.135491 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 131000
I0819 04:57:48.753253 140034352527168 train_slot.py:155] Step: 131100, Loss: 0.001187, Time: 8:39:34.941483
I0819 04:58:12.268085 140034352527168 train_slot.py:155] Step: 131200, Loss: 0.001197, Time: 8:39:58.455654
I0819 04:58:35.909089 140034352527168 train_slot.py:155] Step: 131300, Loss: 0.001165, Time: 8:40:22.097271
I0819 04:58:59.464527 140034352527168 train_slot.py:155] Step: 131400, Loss: 0.001355, Time: 8:40:45.652736
I0819 04:59:23.049256 140034352527168 train_slot.py:155] Step: 131500, Loss: 0.001094, Time: 8:41:09.237421
I0819 04:59:46.615368 140034352527168 train_slot.py:155] Step: 131600, Loss: 0.001420, Time: 8:41:32.803536
I0819 05:00:10.096252 140034352527168 train_slot.py:155] Step: 131700, Loss: 0.001213, Time: 8:41:56.284453
I0819 05:00:33.567044 140034352527168 train_slot.py:155] Step: 131800, Loss: 0.001182, Time: 8:42:19.755248
I0819 05:00:57.367954 140034352527168 train_slot.py:155] Step: 131900, Loss: 0.001277, Time: 8:42:43.555619
I0819 05:01:20.895122 140034352527168 train_slot.py:155] Step: 132000, Loss: 0.001521, Time: 8:43:07.083258
I0819 05:01:21.260112 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-132000
I0819 05:01:22.393037 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 132000
I0819 05:01:45.863029 140034352527168 train_slot.py:155] Step: 132100, Loss: 0.001225, Time: 8:43:32.051229
I0819 05:02:09.358392 140034352527168 train_slot.py:155] Step: 132200, Loss: 0.001224, Time: 8:43:55.546609
I0819 05:02:32.872688 140034352527168 train_slot.py:155] Step: 132300, Loss: 0.001195, Time: 8:44:19.060889
I0819 05:02:56.611993 140034352527168 train_slot.py:155] Step: 132400, Loss: 0.001347, Time: 8:44:42.800203
I0819 05:03:20.154864 140034352527168 train_slot.py:155] Step: 132500, Loss: 0.001865, Time: 8:45:06.342976
I0819 05:03:43.646147 140034352527168 train_slot.py:155] Step: 132600, Loss: 0.001208, Time: 8:45:29.834349
I0819 05:04:07.170942 140034352527168 train_slot.py:155] Step: 132700, Loss: 0.001621, Time: 8:45:53.359143
I0819 05:04:30.687423 140034352527168 train_slot.py:155] Step: 132800, Loss: 0.001411, Time: 8:46:16.875630
I0819 05:04:54.440080 140034352527168 train_slot.py:155] Step: 132900, Loss: 0.001379, Time: 8:46:40.628108
I0819 05:05:18.226973 140034352527168 train_slot.py:155] Step: 133000, Loss: 0.001254, Time: 8:47:04.415183
I0819 05:05:18.595767 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-133000
I0819 05:05:19.672371 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 133000
I0819 05:05:43.290152 140034352527168 train_slot.py:155] Step: 133100, Loss: 0.001186, Time: 8:47:29.478354
I0819 05:06:06.769906 140034352527168 train_slot.py:155] Step: 133200, Loss: 0.001436, Time: 8:47:52.957877
I0819 05:06:30.245451 140034352527168 train_slot.py:155] Step: 133300, Loss: 0.001282, Time: 8:48:16.433658
I0819 05:06:53.957145 140034352527168 train_slot.py:155] Step: 133400, Loss: 0.001389, Time: 8:48:40.145358
I0819 05:07:17.670889 140034352527168 train_slot.py:155] Step: 133500, Loss: 0.001344, Time: 8:49:03.859090
I0819 05:07:41.248467 140034352527168 train_slot.py:155] Step: 133600, Loss: 0.001446, Time: 8:49:27.436623
I0819 05:08:04.755331 140034352527168 train_slot.py:155] Step: 133700, Loss: 0.000984, Time: 8:49:50.943554
I0819 05:08:28.373621 140034352527168 train_slot.py:155] Step: 133800, Loss: 0.001521, Time: 8:50:14.561853
I0819 05:08:51.853507 140034352527168 train_slot.py:155] Step: 133900, Loss: 0.001394, Time: 8:50:38.041546
I0819 05:09:15.616569 140034352527168 train_slot.py:155] Step: 134000, Loss: 0.001437, Time: 8:51:01.804707
I0819 05:09:15.993810 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-134000
I0819 05:09:17.138971 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 134000
I0819 05:09:40.882482 140034352527168 train_slot.py:155] Step: 134100, Loss: 0.001221, Time: 8:51:27.070714
I0819 05:10:04.646457 140034352527168 train_slot.py:155] Step: 134200, Loss: 0.001165, Time: 8:51:50.834661
I0819 05:10:28.446214 140034352527168 train_slot.py:155] Step: 134300, Loss: 0.001300, Time: 8:52:14.634226
I0819 05:10:52.074341 140034352527168 train_slot.py:155] Step: 134400, Loss: 0.001186, Time: 8:52:38.262517
I0819 05:11:15.744213 140034352527168 train_slot.py:155] Step: 134500, Loss: 0.001251, Time: 8:53:01.932410
I0819 05:11:39.594855 140034352527168 train_slot.py:155] Step: 134600, Loss: 0.001119, Time: 8:53:25.783054
I0819 05:12:03.411937 140034352527168 train_slot.py:155] Step: 134700, Loss: 0.001241, Time: 8:53:49.599902
I0819 05:12:27.029846 140034352527168 train_slot.py:155] Step: 134800, Loss: 0.001344, Time: 8:54:13.218034
I0819 05:12:50.838544 140034352527168 train_slot.py:155] Step: 134900, Loss: 0.001307, Time: 8:54:37.026742
I0819 05:13:14.325987 140034352527168 train_slot.py:155] Step: 135000, Loss: 0.001431, Time: 8:55:00.514220
I0819 05:13:14.662591 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-135000
I0819 05:13:15.826977 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 135000
I0819 05:13:39.523110 140034352527168 train_slot.py:155] Step: 135100, Loss: 0.001112, Time: 8:55:25.711329
I0819 05:14:03.008228 140034352527168 train_slot.py:155] Step: 135200, Loss: 0.001298, Time: 8:55:49.196202
I0819 05:14:26.403231 140034352527168 train_slot.py:155] Step: 135300, Loss: 0.001160, Time: 8:56:12.591426
I0819 05:14:49.951901 140034352527168 train_slot.py:155] Step: 135400, Loss: 0.001375, Time: 8:56:36.140140
I0819 05:15:13.629810 140034352527168 train_slot.py:155] Step: 135500, Loss: 0.001243, Time: 8:56:59.818010
I0819 05:15:37.086592 140034352527168 train_slot.py:155] Step: 135600, Loss: 0.001180, Time: 8:57:23.274713
I0819 05:16:00.745398 140034352527168 train_slot.py:155] Step: 135700, Loss: 0.001581, Time: 8:57:46.933600
I0819 05:16:24.213480 140034352527168 train_slot.py:155] Step: 135800, Loss: 0.001245, Time: 8:58:10.401712
I0819 05:16:47.737089 140034352527168 train_slot.py:155] Step: 135900, Loss: 0.001744, Time: 8:58:33.925292
I0819 05:17:11.240660 140034352527168 train_slot.py:155] Step: 136000, Loss: 0.001098, Time: 8:58:57.428674
I0819 05:17:11.602777 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-136000
I0819 05:17:12.673189 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 136000
I0819 05:17:36.174498 140034352527168 train_slot.py:155] Step: 136100, Loss: 0.002391, Time: 8:59:22.362664
I0819 05:17:59.910025 140034352527168 train_slot.py:155] Step: 136200, Loss: 0.001189, Time: 8:59:46.098243
I0819 05:18:23.452629 140034352527168 train_slot.py:155] Step: 136300, Loss: 0.001034, Time: 9:00:09.640821
I0819 05:18:47.022871 140034352527168 train_slot.py:155] Step: 136400, Loss: 0.001162, Time: 9:00:33.210826
I0819 05:19:10.521059 140034352527168 train_slot.py:155] Step: 136500, Loss: 0.001330, Time: 9:00:56.709266
I0819 05:19:34.243937 140034352527168 train_slot.py:155] Step: 136600, Loss: 0.001156, Time: 9:01:20.432139
I0819 05:19:57.749897 140034352527168 train_slot.py:155] Step: 136700, Loss: 0.001261, Time: 9:01:43.937958
I0819 05:20:21.405493 140034352527168 train_slot.py:155] Step: 136800, Loss: 0.001163, Time: 9:02:07.593682
I0819 05:20:45.019449 140034352527168 train_slot.py:155] Step: 136900, Loss: 0.001066, Time: 9:02:31.207648
I0819 05:21:08.644748 140034352527168 train_slot.py:155] Step: 137000, Loss: 0.001103, Time: 9:02:54.832757
I0819 05:21:09.021761 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-137000
I0819 05:21:10.154117 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 137000
I0819 05:21:33.649795 140034352527168 train_slot.py:155] Step: 137100, Loss: 0.001168, Time: 9:03:19.837976
I0819 05:21:57.015054 140034352527168 train_slot.py:155] Step: 137200, Loss: 0.001649, Time: 9:03:43.203256
I0819 05:22:20.835512 140034352527168 train_slot.py:155] Step: 137300, Loss: 0.000980, Time: 9:04:07.023725
I0819 05:22:44.480656 140034352527168 train_slot.py:155] Step: 137400, Loss: 0.001140, Time: 9:04:30.668769
I0819 05:23:08.030264 140034352527168 train_slot.py:155] Step: 137500, Loss: 0.001494, Time: 9:04:54.218431
I0819 05:23:31.680287 140034352527168 train_slot.py:155] Step: 137600, Loss: 0.001358, Time: 9:05:17.868492
I0819 05:23:55.419667 140034352527168 train_slot.py:155] Step: 137700, Loss: 0.000999, Time: 9:05:41.607872
I0819 05:24:19.158677 140034352527168 train_slot.py:155] Step: 137800, Loss: 0.001189, Time: 9:06:05.346795
I0819 05:24:42.628543 140034352527168 train_slot.py:155] Step: 137900, Loss: 0.001315, Time: 9:06:28.816717
I0819 05:25:06.350114 140034352527168 train_slot.py:155] Step: 138000, Loss: 0.001296, Time: 9:06:52.538314
I0819 05:25:06.677746 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-138000
I0819 05:25:07.814568 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 138000
I0819 05:25:31.396189 140034352527168 train_slot.py:155] Step: 138100, Loss: 0.001328, Time: 9:07:17.584206
I0819 05:25:54.759473 140034352527168 train_slot.py:155] Step: 138200, Loss: 0.001170, Time: 9:07:40.947647
I0819 05:26:18.509632 140034352527168 train_slot.py:155] Step: 138300, Loss: 0.001123, Time: 9:08:04.697832
I0819 05:26:42.092069 140034352527168 train_slot.py:155] Step: 138400, Loss: 0.001177, Time: 9:08:28.280302
I0819 05:27:05.622804 140034352527168 train_slot.py:155] Step: 138500, Loss: 0.001345, Time: 9:08:51.811006
I0819 05:27:29.110293 140034352527168 train_slot.py:155] Step: 138600, Loss: 0.001109, Time: 9:09:15.298412
I0819 05:27:52.669300 140034352527168 train_slot.py:155] Step: 138700, Loss: 0.001128, Time: 9:09:38.857494
I0819 05:28:16.162240 140034352527168 train_slot.py:155] Step: 138800, Loss: 0.001341, Time: 9:10:02.350469
I0819 05:28:39.865072 140034352527168 train_slot.py:155] Step: 138900, Loss: 0.001302, Time: 9:10:26.053158
I0819 05:29:03.401656 140034352527168 train_slot.py:155] Step: 139000, Loss: 0.001184, Time: 9:10:49.589855
I0819 05:29:03.729243 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-139000
I0819 05:29:04.797711 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 139000
I0819 05:29:28.130132 140034352527168 train_slot.py:155] Step: 139100, Loss: 0.001162, Time: 9:11:14.318296
I0819 05:29:51.751455 140034352527168 train_slot.py:155] Step: 139200, Loss: 0.001087, Time: 9:11:37.939653
I0819 05:30:15.282912 140034352527168 train_slot.py:155] Step: 139300, Loss: 0.001459, Time: 9:12:01.471123
I0819 05:30:38.755681 140034352527168 train_slot.py:155] Step: 139400, Loss: 0.000934, Time: 9:12:24.943797
I0819 05:31:02.480042 140034352527168 train_slot.py:155] Step: 139500, Loss: 0.001333, Time: 9:12:48.668274
I0819 05:31:26.049727 140034352527168 train_slot.py:155] Step: 139600, Loss: 0.001336, Time: 9:13:12.237927
I0819 05:31:49.651243 140034352527168 train_slot.py:155] Step: 139700, Loss: 0.001368, Time: 9:13:35.839360
I0819 05:32:13.131164 140034352527168 train_slot.py:155] Step: 139800, Loss: 0.001565, Time: 9:13:59.319335
I0819 05:32:36.542408 140034352527168 train_slot.py:155] Step: 139900, Loss: 0.001124, Time: 9:14:22.730614
I0819 05:33:00.234358 140034352527168 train_slot.py:155] Step: 140000, Loss: 0.001003, Time: 9:14:46.422571
I0819 05:33:00.609093 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-140000
I0819 05:33:01.740853 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 140000
I0819 05:33:25.325688 140034352527168 train_slot.py:155] Step: 140100, Loss: 0.001563, Time: 9:15:11.513717
I0819 05:33:48.833664 140034352527168 train_slot.py:155] Step: 140200, Loss: 0.001361, Time: 9:15:35.021791
I0819 05:34:12.572775 140034352527168 train_slot.py:155] Step: 140300, Loss: 0.001090, Time: 9:15:58.760979
I0819 05:34:36.059827 140034352527168 train_slot.py:155] Step: 140400, Loss: 0.001301, Time: 9:16:22.248037
I0819 05:34:59.760306 140034352527168 train_slot.py:155] Step: 140500, Loss: 0.001149, Time: 9:16:45.948527
I0819 05:35:23.331920 140034352527168 train_slot.py:155] Step: 140600, Loss: 0.001280, Time: 9:17:09.520154
I0819 05:35:46.896863 140034352527168 train_slot.py:155] Step: 140700, Loss: 0.001273, Time: 9:17:33.085058
I0819 05:36:10.313596 140034352527168 train_slot.py:155] Step: 140800, Loss: 0.001201, Time: 9:17:56.501828
I0819 05:36:33.873690 140034352527168 train_slot.py:155] Step: 140900, Loss: 0.001180, Time: 9:18:20.061802
I0819 05:36:57.397416 140034352527168 train_slot.py:155] Step: 141000, Loss: 0.001477, Time: 9:18:43.585608
I0819 05:36:57.731091 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-141000
I0819 05:36:58.831398 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 141000
I0819 05:37:22.558637 140034352527168 train_slot.py:155] Step: 141100, Loss: 0.000970, Time: 9:19:08.746840
I0819 05:37:46.243090 140034352527168 train_slot.py:155] Step: 141200, Loss: 0.001155, Time: 9:19:32.431290
I0819 05:38:09.693096 140034352527168 train_slot.py:155] Step: 141300, Loss: 0.001147, Time: 9:19:55.881301
I0819 05:38:33.176458 140034352527168 train_slot.py:155] Step: 141400, Loss: 0.001219, Time: 9:20:19.364596
I0819 05:38:56.556139 140034352527168 train_slot.py:155] Step: 141500, Loss: 0.001224, Time: 9:20:42.744303
I0819 05:39:20.334862 140034352527168 train_slot.py:155] Step: 141600, Loss: 0.001308, Time: 9:21:06.523062
I0819 05:39:43.767789 140034352527168 train_slot.py:155] Step: 141700, Loss: 0.001054, Time: 9:21:29.955996
I0819 05:40:07.297922 140034352527168 train_slot.py:155] Step: 141800, Loss: 0.001254, Time: 9:21:53.485901
I0819 05:40:30.812548 140034352527168 train_slot.py:155] Step: 141900, Loss: 0.001035, Time: 9:22:17.000729
I0819 05:40:54.360530 140034352527168 train_slot.py:155] Step: 142000, Loss: 0.001203, Time: 9:22:40.548734
I0819 05:40:54.732467 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-142000
I0819 05:40:55.863983 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 142000
I0819 05:41:19.311828 140034352527168 train_slot.py:155] Step: 142100, Loss: 0.001346, Time: 9:23:05.500028
I0819 05:41:43.001805 140034352527168 train_slot.py:155] Step: 142200, Loss: 0.001306, Time: 9:23:29.190005
I0819 05:42:06.584364 140034352527168 train_slot.py:155] Step: 142300, Loss: 0.001572, Time: 9:23:52.772503
I0819 05:42:30.088401 140034352527168 train_slot.py:155] Step: 142400, Loss: 0.001153, Time: 9:24:16.276501
I0819 05:42:53.598543 140034352527168 train_slot.py:155] Step: 142500, Loss: 0.001235, Time: 9:24:39.786752
I0819 05:43:17.147356 140034352527168 train_slot.py:155] Step: 142600, Loss: 0.001222, Time: 9:25:03.335568
I0819 05:43:41.070833 140034352527168 train_slot.py:155] Step: 142700, Loss: 0.001078, Time: 9:25:27.258704
I0819 05:44:04.643158 140034352527168 train_slot.py:155] Step: 142800, Loss: 0.001117, Time: 9:25:50.831382
I0819 05:44:28.105754 140034352527168 train_slot.py:155] Step: 142900, Loss: 0.001183, Time: 9:26:14.293977
I0819 05:44:51.920585 140034352527168 train_slot.py:155] Step: 143000, Loss: 0.001121, Time: 9:26:38.108798
I0819 05:44:52.258365 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-143000
I0819 05:44:53.468109 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 143000
I0819 05:45:16.947740 140034352527168 train_slot.py:155] Step: 143100, Loss: 0.001176, Time: 9:27:03.135875
I0819 05:45:40.283824 140034352527168 train_slot.py:155] Step: 143200, Loss: 0.001436, Time: 9:27:26.472029
I0819 05:46:04.027347 140034352527168 train_slot.py:155] Step: 143300, Loss: 0.001270, Time: 9:27:50.215542
I0819 05:46:27.695307 140034352527168 train_slot.py:155] Step: 143400, Loss: 0.001205, Time: 9:28:13.883508
I0819 05:46:51.234210 140034352527168 train_slot.py:155] Step: 143500, Loss: 0.001219, Time: 9:28:37.422338
I0819 05:47:14.697265 140034352527168 train_slot.py:155] Step: 143600, Loss: 0.000987, Time: 9:29:00.885176
I0819 05:47:38.473011 140034352527168 train_slot.py:155] Step: 143700, Loss: 0.001090, Time: 9:29:24.661234
I0819 05:48:02.202258 140034352527168 train_slot.py:155] Step: 143800, Loss: 0.001029, Time: 9:29:48.390472
I0819 05:48:25.799385 140034352527168 train_slot.py:155] Step: 143900, Loss: 0.001284, Time: 9:30:11.987587
I0819 05:48:49.629625 140034352527168 train_slot.py:155] Step: 144000, Loss: 0.000984, Time: 9:30:35.817682
I0819 05:48:49.942135 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-144000
I0819 05:48:51.011633 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 144000
I0819 05:49:14.430446 140034352527168 train_slot.py:155] Step: 144100, Loss: 0.001214, Time: 9:31:00.618672
I0819 05:49:37.902582 140034352527168 train_slot.py:155] Step: 144200, Loss: 0.001277, Time: 9:31:24.090809
I0819 05:50:01.673805 140034352527168 train_slot.py:155] Step: 144300, Loss: 0.001113, Time: 9:31:47.861916
I0819 05:50:25.168768 140034352527168 train_slot.py:155] Step: 144400, Loss: 0.001241, Time: 9:32:11.356907
I0819 05:50:48.748764 140034352527168 train_slot.py:155] Step: 144500, Loss: 0.001480, Time: 9:32:34.936965
I0819 05:51:12.202471 140034352527168 train_slot.py:155] Step: 144600, Loss: 0.001544, Time: 9:32:58.390669
I0819 05:51:35.800475 140034352527168 train_slot.py:155] Step: 144700, Loss: 0.001233, Time: 9:33:21.988704
I0819 05:51:59.390080 140034352527168 train_slot.py:155] Step: 144800, Loss: 0.001118, Time: 9:33:45.578213
I0819 05:52:23.241266 140034352527168 train_slot.py:155] Step: 144900, Loss: 0.000900, Time: 9:34:09.429467
I0819 05:52:46.976410 140034352527168 train_slot.py:155] Step: 145000, Loss: 0.001204, Time: 9:34:33.164649
I0819 05:52:47.286417 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-145000
I0819 05:52:48.366289 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 145000
I0819 05:53:12.166514 140034352527168 train_slot.py:155] Step: 145100, Loss: 0.000960, Time: 9:34:58.354638
I0819 05:53:35.899663 140034352527168 train_slot.py:155] Step: 145200, Loss: 0.001173, Time: 9:35:22.087823
I0819 05:53:59.752009 140034352527168 train_slot.py:155] Step: 145300, Loss: 0.001038, Time: 9:35:45.940210
I0819 05:54:23.827628 140034352527168 train_slot.py:155] Step: 145400, Loss: 0.001346, Time: 9:36:10.015586
I0819 05:54:47.695665 140034352527168 train_slot.py:155] Step: 145500, Loss: 0.000880, Time: 9:36:33.883866
I0819 05:55:11.427636 140034352527168 train_slot.py:155] Step: 145600, Loss: 0.001198, Time: 9:36:57.615842
I0819 05:55:35.510257 140034352527168 train_slot.py:155] Step: 145700, Loss: 0.001111, Time: 9:37:21.698457
I0819 05:55:59.332717 140034352527168 train_slot.py:155] Step: 145800, Loss: 0.001395, Time: 9:37:45.520941
I0819 05:56:23.154902 140034352527168 train_slot.py:155] Step: 145900, Loss: 0.001359, Time: 9:38:09.343012
I0819 05:56:47.061570 140034352527168 train_slot.py:155] Step: 146000, Loss: 0.001257, Time: 9:38:33.249789
I0819 05:56:47.438332 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-146000
I0819 05:56:48.509158 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 146000
I0819 05:57:12.061284 140034352527168 train_slot.py:155] Step: 146100, Loss: 0.001225, Time: 9:38:58.249486
I0819 05:57:35.646718 140034352527168 train_slot.py:155] Step: 146200, Loss: 0.001206, Time: 9:39:21.834736
I0819 05:57:59.304309 140034352527168 train_slot.py:155] Step: 146300, Loss: 0.001040, Time: 9:39:45.492514
I0819 05:58:22.793647 140034352527168 train_slot.py:155] Step: 146400, Loss: 0.001223, Time: 9:40:08.981845
I0819 05:58:46.612523 140034352527168 train_slot.py:155] Step: 146500, Loss: 0.001132, Time: 9:40:32.800408
I0819 05:59:10.014251 140034352527168 train_slot.py:155] Step: 146600, Loss: 0.001052, Time: 9:40:56.202448
I0819 05:59:33.489546 140034352527168 train_slot.py:155] Step: 146700, Loss: 0.001107, Time: 9:41:19.677767
I0819 05:59:56.971039 140034352527168 train_slot.py:155] Step: 146800, Loss: 0.001074, Time: 9:41:43.159236
I0819 06:00:20.547907 140034352527168 train_slot.py:155] Step: 146900, Loss: 0.001152, Time: 9:42:06.736066
I0819 06:00:44.102662 140034352527168 train_slot.py:155] Step: 147000, Loss: 0.001335, Time: 9:42:30.290858
I0819 06:00:44.430011 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-147000
I0819 06:00:45.562931 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 147000
I0819 06:01:09.440402 140034352527168 train_slot.py:155] Step: 147100, Loss: 0.001436, Time: 9:42:55.628638
I0819 06:01:32.992286 140034352527168 train_slot.py:155] Step: 147200, Loss: 0.001181, Time: 9:43:19.180484
I0819 06:01:56.571918 140034352527168 train_slot.py:155] Step: 147300, Loss: 0.001233, Time: 9:43:42.759978
I0819 06:02:20.114906 140034352527168 train_slot.py:155] Step: 147400, Loss: 0.001168, Time: 9:44:06.303103
I0819 06:02:43.574019 140034352527168 train_slot.py:155] Step: 147500, Loss: 0.001437, Time: 9:44:29.762250
I0819 06:03:07.318064 140034352527168 train_slot.py:155] Step: 147600, Loss: 0.001335, Time: 9:44:53.506302
I0819 06:03:30.891858 140034352527168 train_slot.py:155] Step: 147700, Loss: 0.001345, Time: 9:45:17.080064
I0819 06:03:54.465886 140034352527168 train_slot.py:155] Step: 147800, Loss: 0.001442, Time: 9:45:40.654053
I0819 06:04:18.494977 140034352527168 train_slot.py:155] Step: 147900, Loss: 0.001315, Time: 9:46:04.683141
I0819 06:04:42.005378 140034352527168 train_slot.py:155] Step: 148000, Loss: 0.001328, Time: 9:46:28.193598
I0819 06:04:42.383422 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-148000
I0819 06:04:43.502309 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 148000
I0819 06:05:07.176061 140034352527168 train_slot.py:155] Step: 148100, Loss: 0.001385, Time: 9:46:53.364063
I0819 06:05:30.750170 140034352527168 train_slot.py:155] Step: 148200, Loss: 0.001361, Time: 9:47:16.938336
I0819 06:05:54.311035 140034352527168 train_slot.py:155] Step: 148300, Loss: 0.001182, Time: 9:47:40.499186
I0819 06:06:17.774878 140034352527168 train_slot.py:155] Step: 148400, Loss: 0.001105, Time: 9:48:03.963082
I0819 06:06:41.332258 140034352527168 train_slot.py:155] Step: 148500, Loss: 0.001134, Time: 9:48:27.520303
I0819 06:07:04.790118 140034352527168 train_slot.py:155] Step: 148600, Loss: 0.001273, Time: 9:48:50.978189
I0819 06:07:28.537309 140034352527168 train_slot.py:155] Step: 148700, Loss: 0.001262, Time: 9:49:14.725539
I0819 06:07:52.052156 140034352527168 train_slot.py:155] Step: 148800, Loss: 0.001099, Time: 9:49:38.240392
I0819 06:08:15.677697 140034352527168 train_slot.py:155] Step: 148900, Loss: 0.001174, Time: 9:50:01.865830
I0819 06:08:39.608809 140034352527168 train_slot.py:155] Step: 149000, Loss: 0.001229, Time: 9:50:25.797031
I0819 06:08:40.007416 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-149000
I0819 06:08:41.144712 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 149000
I0819 06:09:04.800582 140034352527168 train_slot.py:155] Step: 149100, Loss: 0.001056, Time: 9:50:50.988787
I0819 06:09:28.694132 140034352527168 train_slot.py:155] Step: 149200, Loss: 0.001416, Time: 9:51:14.882343
I0819 06:09:52.152735 140034352527168 train_slot.py:155] Step: 149300, Loss: 0.001180, Time: 9:51:38.340773
I0819 06:10:15.697487 140034352527168 train_slot.py:155] Step: 149400, Loss: 0.001327, Time: 9:52:01.885667
I0819 06:10:39.155898 140034352527168 train_slot.py:155] Step: 149500, Loss: 0.000802, Time: 9:52:25.344137
I0819 06:11:02.629756 140034352527168 train_slot.py:155] Step: 149600, Loss: 0.001154, Time: 9:52:48.817965
I0819 06:11:26.170366 140034352527168 train_slot.py:155] Step: 149700, Loss: 0.001395, Time: 9:53:12.358495
I0819 06:11:49.976452 140034352527168 train_slot.py:155] Step: 149800, Loss: 0.001202, Time: 9:53:36.164651
I0819 06:12:13.431089 140034352527168 train_slot.py:155] Step: 149900, Loss: 0.001484, Time: 9:53:59.619326
I0819 06:12:37.293065 140034352527168 train_slot.py:155] Step: 150000, Loss: 0.001258, Time: 9:54:23.481052
I0819 06:12:37.616827 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-150000
I0819 06:12:38.708911 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 150000
I0819 06:13:02.413603 140034352527168 train_slot.py:155] Step: 150100, Loss: 0.001306, Time: 9:54:48.601718
I0819 06:13:25.842994 140034352527168 train_slot.py:155] Step: 150200, Loss: 0.001297, Time: 9:55:12.031224
I0819 06:13:49.548739 140034352527168 train_slot.py:155] Step: 150300, Loss: 0.001173, Time: 9:55:35.736974
I0819 06:14:13.080099 140034352527168 train_slot.py:155] Step: 150400, Loss: 0.001160, Time: 9:55:59.268309
I0819 06:14:36.647691 140034352527168 train_slot.py:155] Step: 150500, Loss: 0.001095, Time: 9:56:22.835698
I0819 06:15:00.418083 140034352527168 train_slot.py:155] Step: 150600, Loss: 0.001197, Time: 9:56:46.606313
I0819 06:15:23.979888 140034352527168 train_slot.py:155] Step: 150700, Loss: 0.001358, Time: 9:57:10.168071
I0819 06:15:47.795766 140034352527168 train_slot.py:155] Step: 150800, Loss: 0.001167, Time: 9:57:33.983965
I0819 06:16:11.586338 140034352527168 train_slot.py:155] Step: 150900, Loss: 0.001277, Time: 9:57:57.774319
I0819 06:16:35.064487 140034352527168 train_slot.py:155] Step: 151000, Loss: 0.001251, Time: 9:58:21.252715
I0819 06:16:35.411124 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-151000
I0819 06:16:36.482299 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 151000
I0819 06:17:00.050492 140034352527168 train_slot.py:155] Step: 151100, Loss: 0.001213, Time: 9:58:46.238699
I0819 06:17:23.423254 140034352527168 train_slot.py:155] Step: 151200, Loss: 0.001130, Time: 9:59:09.611453
I0819 06:17:46.907764 140034352527168 train_slot.py:155] Step: 151300, Loss: 0.001043, Time: 9:59:33.095960
I0819 06:18:10.723170 140034352527168 train_slot.py:155] Step: 151400, Loss: 0.001407, Time: 9:59:56.911130
I0819 06:18:34.295243 140034352527168 train_slot.py:155] Step: 151500, Loss: 0.001262, Time: 10:00:20.483378
I0819 06:18:57.834505 140034352527168 train_slot.py:155] Step: 151600, Loss: 0.001419, Time: 10:00:44.022713
I0819 06:19:21.501178 140034352527168 train_slot.py:155] Step: 151700, Loss: 0.001106, Time: 10:01:07.689294
I0819 06:19:45.106949 140034352527168 train_slot.py:155] Step: 151800, Loss: 0.001131, Time: 10:01:31.295110
I0819 06:20:08.835458 140034352527168 train_slot.py:155] Step: 151900, Loss: 0.001236, Time: 10:01:55.023692
I0819 06:20:32.410346 140034352527168 train_slot.py:155] Step: 152000, Loss: 0.001548, Time: 10:02:18.598552
I0819 06:20:32.773767 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-152000
I0819 06:20:33.909662 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 152000
I0819 06:20:57.513199 140034352527168 train_slot.py:155] Step: 152100, Loss: 0.001387, Time: 10:02:43.700721
I0819 06:21:21.086823 140034352527168 train_slot.py:155] Step: 152200, Loss: 0.001095, Time: 10:03:07.275021
I0819 06:21:44.691676 140034352527168 train_slot.py:155] Step: 152300, Loss: 0.001140, Time: 10:03:30.879878
I0819 06:22:08.247792 140034352527168 train_slot.py:155] Step: 152400, Loss: 0.001187, Time: 10:03:54.436029
I0819 06:22:32.084008 140034352527168 train_slot.py:155] Step: 152500, Loss: 0.001130, Time: 10:04:18.272004
I0819 06:22:55.599454 140034352527168 train_slot.py:155] Step: 152600, Loss: 0.001057, Time: 10:04:41.787655
I0819 06:23:19.257755 140034352527168 train_slot.py:155] Step: 152700, Loss: 0.001120, Time: 10:05:05.445954
I0819 06:23:42.938690 140034352527168 train_slot.py:155] Step: 152800, Loss: 0.001339, Time: 10:05:29.126822
I0819 06:24:06.698155 140034352527168 train_slot.py:155] Step: 152900, Loss: 0.001062, Time: 10:05:52.886308
I0819 06:24:30.712371 140034352527168 train_slot.py:155] Step: 153000, Loss: 0.001247, Time: 10:06:16.900585
I0819 06:24:31.079310 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-153000
I0819 06:24:32.149212 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 153000
I0819 06:24:55.992918 140034352527168 train_slot.py:155] Step: 153100, Loss: 0.001624, Time: 10:06:42.181102
I0819 06:25:19.791840 140034352527168 train_slot.py:155] Step: 153200, Loss: 0.001235, Time: 10:07:05.979862
I0819 06:25:43.409934 140034352527168 train_slot.py:155] Step: 153300, Loss: 0.001195, Time: 10:07:29.598107
I0819 06:26:06.957643 140034352527168 train_slot.py:155] Step: 153400, Loss: 0.001329, Time: 10:07:53.145853
I0819 06:26:30.856734 140034352527168 train_slot.py:155] Step: 153500, Loss: 0.001176, Time: 10:08:17.044965
I0819 06:26:54.690011 140034352527168 train_slot.py:155] Step: 153600, Loss: 0.001051, Time: 10:08:40.878142
I0819 06:27:18.163766 140034352527168 train_slot.py:155] Step: 153700, Loss: 0.001306, Time: 10:09:04.351948
I0819 06:27:41.655339 140034352527168 train_slot.py:155] Step: 153800, Loss: 0.001242, Time: 10:09:27.843542
I0819 06:28:05.140161 140034352527168 train_slot.py:155] Step: 153900, Loss: 0.001099, Time: 10:09:51.328359
I0819 06:28:28.689063 140034352527168 train_slot.py:155] Step: 154000, Loss: 0.001085, Time: 10:10:14.877264
I0819 06:28:29.054921 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-154000
I0819 06:28:30.123802 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 154000
I0819 06:28:53.896080 140034352527168 train_slot.py:155] Step: 154100, Loss: 0.001111, Time: 10:10:40.084141
I0819 06:29:17.367136 140034352527168 train_slot.py:155] Step: 154200, Loss: 0.001307, Time: 10:11:03.555334
I0819 06:29:40.807807 140034352527168 train_slot.py:155] Step: 154300, Loss: 0.001635, Time: 10:11:26.996008
I0819 06:30:04.275686 140034352527168 train_slot.py:155] Step: 154400, Loss: 0.001177, Time: 10:11:50.463907
I0819 06:30:28.095524 140034352527168 train_slot.py:155] Step: 154500, Loss: 0.001278, Time: 10:12:14.283732
I0819 06:30:51.660742 140034352527168 train_slot.py:155] Step: 154600, Loss: 0.001320, Time: 10:12:37.848737
I0819 06:31:15.505639 140034352527168 train_slot.py:155] Step: 154700, Loss: 0.001146, Time: 10:13:01.693837
I0819 06:31:39.069302 140034352527168 train_slot.py:155] Step: 154800, Loss: 0.001086, Time: 10:13:25.257507
I0819 06:32:02.587702 140034352527168 train_slot.py:155] Step: 154900, Loss: 0.001238, Time: 10:13:48.775773
I0819 06:32:26.032112 140034352527168 train_slot.py:155] Step: 155000, Loss: 0.001233, Time: 10:14:12.220289
I0819 06:32:26.368835 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-155000
I0819 06:32:27.506453 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 155000
I0819 06:32:50.979716 140034352527168 train_slot.py:155] Step: 155100, Loss: 0.001483, Time: 10:14:37.167957
I0819 06:33:14.999764 140034352527168 train_slot.py:155] Step: 155200, Loss: 0.001194, Time: 10:15:01.187997
I0819 06:33:38.900018 140034352527168 train_slot.py:155] Step: 155300, Loss: 0.001413, Time: 10:15:25.088033
I0819 06:34:02.778917 140034352527168 train_slot.py:155] Step: 155400, Loss: 0.001101, Time: 10:15:48.967119
I0819 06:34:26.661662 140034352527168 train_slot.py:155] Step: 155500, Loss: 0.001291, Time: 10:16:12.849893
I0819 06:34:50.790451 140034352527168 train_slot.py:155] Step: 155600, Loss: 0.001144, Time: 10:16:36.978651
I0819 06:35:15.130362 140034352527168 train_slot.py:155] Step: 155700, Loss: 0.000966, Time: 10:17:01.318487
I0819 06:35:38.699780 140034352527168 train_slot.py:155] Step: 155800, Loss: 0.001087, Time: 10:17:24.887961
I0819 06:36:02.163758 140034352527168 train_slot.py:155] Step: 155900, Loss: 0.001426, Time: 10:17:48.351870
I0819 06:36:25.685514 140034352527168 train_slot.py:155] Step: 156000, Loss: 0.001175, Time: 10:18:11.873742
I0819 06:36:26.037687 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-156000
I0819 06:36:27.113524 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 156000
I0819 06:36:50.655565 140034352527168 train_slot.py:155] Step: 156100, Loss: 0.000998, Time: 10:18:36.843771
I0819 06:37:14.160885 140034352527168 train_slot.py:155] Step: 156200, Loss: 0.001063, Time: 10:19:00.349066
I0819 06:37:37.858349 140034352527168 train_slot.py:155] Step: 156300, Loss: 0.001198, Time: 10:19:24.046427
I0819 06:38:01.329709 140034352527168 train_slot.py:155] Step: 156400, Loss: 0.001514, Time: 10:19:47.517933
I0819 06:38:24.913644 140034352527168 train_slot.py:155] Step: 156500, Loss: 0.000998, Time: 10:20:11.101873
I0819 06:38:48.337520 140034352527168 train_slot.py:155] Step: 156600, Loss: 0.000923, Time: 10:20:34.525741
I0819 06:39:11.987721 140034352527168 train_slot.py:155] Step: 156700, Loss: 0.001292, Time: 10:20:58.175812
I0819 06:39:35.675671 140034352527168 train_slot.py:155] Step: 156800, Loss: 0.001077, Time: 10:21:21.863872
I0819 06:39:59.182286 140034352527168 train_slot.py:155] Step: 156900, Loss: 0.001268, Time: 10:21:45.370493
I0819 06:40:22.953519 140034352527168 train_slot.py:155] Step: 157000, Loss: 0.001005, Time: 10:22:09.141508
I0819 06:40:23.282727 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-157000
I0819 06:40:24.355816 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 157000
I0819 06:40:47.913588 140034352527168 train_slot.py:155] Step: 157100, Loss: 0.001300, Time: 10:22:34.101767
I0819 06:41:11.432730 140034352527168 train_slot.py:155] Step: 157200, Loss: 0.001225, Time: 10:22:57.620945
I0819 06:41:34.946682 140034352527168 train_slot.py:155] Step: 157300, Loss: 0.001146, Time: 10:23:21.134881
I0819 06:41:59.008823 140034352527168 train_slot.py:155] Step: 157400, Loss: 0.001016, Time: 10:23:45.196975
I0819 06:42:22.877852 140034352527168 train_slot.py:155] Step: 157500, Loss: 0.001177, Time: 10:24:09.066017
I0819 06:42:46.805565 140034352527168 train_slot.py:155] Step: 157600, Loss: 0.001074, Time: 10:24:32.993773
I0819 06:43:10.694955 140034352527168 train_slot.py:155] Step: 157700, Loss: 0.001305, Time: 10:24:56.883153
I0819 06:43:34.637436 140034352527168 train_slot.py:155] Step: 157800, Loss: 0.001348, Time: 10:25:20.825522
I0819 06:43:58.813096 140034352527168 train_slot.py:155] Step: 157900, Loss: 0.001129, Time: 10:25:45.001294
I0819 06:44:22.629304 140034352527168 train_slot.py:155] Step: 158000, Loss: 0.001185, Time: 10:26:08.817502
I0819 06:44:23.015629 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-158000
I0819 06:44:24.116659 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 158000
I0819 06:44:47.651646 140034352527168 train_slot.py:155] Step: 158100, Loss: 0.001321, Time: 10:26:33.839646
I0819 06:45:11.116177 140034352527168 train_slot.py:155] Step: 158200, Loss: 0.001536, Time: 10:26:57.304335
I0819 06:45:34.589167 140034352527168 train_slot.py:155] Step: 158300, Loss: 0.001013, Time: 10:27:20.777367
I0819 06:45:58.057964 140034352527168 train_slot.py:155] Step: 158400, Loss: 0.001135, Time: 10:27:44.246108
I0819 06:46:21.885285 140034352527168 train_slot.py:155] Step: 158500, Loss: 0.001114, Time: 10:28:08.073438
I0819 06:46:45.608088 140034352527168 train_slot.py:155] Step: 158600, Loss: 0.001155, Time: 10:28:31.796263
I0819 06:47:09.373452 140034352527168 train_slot.py:155] Step: 158700, Loss: 0.001124, Time: 10:28:55.561677
I0819 06:47:33.016118 140034352527168 train_slot.py:155] Step: 158800, Loss: 0.001177, Time: 10:29:19.204315
I0819 06:47:56.534182 140034352527168 train_slot.py:155] Step: 158900, Loss: 0.001128, Time: 10:29:42.722382
I0819 06:48:20.383762 140034352527168 train_slot.py:155] Step: 159000, Loss: 0.000910, Time: 10:30:06.571898
I0819 06:48:20.701967 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-159000
I0819 06:48:21.831886 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 159000
I0819 06:48:45.463733 140034352527168 train_slot.py:155] Step: 159100, Loss: 0.001408, Time: 10:30:31.651938
I0819 06:49:09.059841 140034352527168 train_slot.py:155] Step: 159200, Loss: 0.001024, Time: 10:30:55.247982
I0819 06:49:32.589060 140034352527168 train_slot.py:155] Step: 159300, Loss: 0.001073, Time: 10:31:18.777267
I0819 06:49:56.023358 140034352527168 train_slot.py:155] Step: 159400, Loss: 0.001200, Time: 10:31:42.211384
I0819 06:50:19.745012 140034352527168 train_slot.py:155] Step: 159500, Loss: 0.001187, Time: 10:32:05.933240
I0819 06:50:43.205899 140034352527168 train_slot.py:155] Step: 159600, Loss: 0.001281, Time: 10:32:29.394039
I0819 06:51:07.058204 140034352527168 train_slot.py:155] Step: 159700, Loss: 0.001043, Time: 10:32:53.246430
I0819 06:51:30.623786 140034352527168 train_slot.py:155] Step: 159800, Loss: 0.001070, Time: 10:33:16.811872
I0819 06:51:54.448459 140034352527168 train_slot.py:155] Step: 159900, Loss: 0.001156, Time: 10:33:40.636669
I0819 06:52:17.936944 140034352527168 train_slot.py:155] Step: 160000, Loss: 0.001253, Time: 10:34:04.125148
I0819 06:52:18.274178 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-160000
I0819 06:52:19.340948 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 160000
I0819 06:52:43.326710 140034352527168 train_slot.py:155] Step: 160100, Loss: 0.001147, Time: 10:34:29.514722
I0819 06:53:07.226455 140034352527168 train_slot.py:155] Step: 160200, Loss: 0.001100, Time: 10:34:53.414630
I0819 06:53:31.109843 140034352527168 train_slot.py:155] Step: 160300, Loss: 0.001138, Time: 10:35:17.298043
I0819 06:53:55.260477 140034352527168 train_slot.py:155] Step: 160400, Loss: 0.001212, Time: 10:35:41.448711
I0819 06:54:19.152942 140034352527168 train_slot.py:155] Step: 160500, Loss: 0.001401, Time: 10:36:05.341061
I0819 06:54:43.180191 140034352527168 train_slot.py:155] Step: 160600, Loss: 0.001080, Time: 10:36:29.368385
I0819 06:55:06.623283 140034352527168 train_slot.py:155] Step: 160700, Loss: 0.001187, Time: 10:36:52.811511
I0819 06:55:30.157091 140034352527168 train_slot.py:155] Step: 160800, Loss: 0.001258, Time: 10:37:16.345291
I0819 06:55:53.680090 140034352527168 train_slot.py:155] Step: 160900, Loss: 0.000967, Time: 10:37:39.868293
I0819 06:56:17.203717 140034352527168 train_slot.py:155] Step: 161000, Loss: 0.001150, Time: 10:38:03.391851
I0819 06:56:17.582724 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-161000
I0819 06:56:18.686810 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 161000
I0819 06:56:42.235095 140034352527168 train_slot.py:155] Step: 161100, Loss: 0.001150, Time: 10:38:28.423223
I0819 06:57:06.020859 140034352527168 train_slot.py:155] Step: 161200, Loss: 0.001315, Time: 10:38:52.209052
I0819 06:57:29.581737 140034352527168 train_slot.py:155] Step: 161300, Loss: 0.001024, Time: 10:39:15.769967
I0819 06:57:53.159016 140034352527168 train_slot.py:155] Step: 161400, Loss: 0.001312, Time: 10:39:39.347008
I0819 06:58:17.182431 140034352527168 train_slot.py:155] Step: 161500, Loss: 0.000894, Time: 10:40:03.370631
I0819 06:58:40.758030 140034352527168 train_slot.py:155] Step: 161600, Loss: 0.001501, Time: 10:40:26.946235
I0819 06:59:04.513904 140034352527168 train_slot.py:155] Step: 161700, Loss: 0.001213, Time: 10:40:50.702034
I0819 06:59:28.035611 140034352527168 train_slot.py:155] Step: 161800, Loss: 0.000914, Time: 10:41:14.223832
I0819 06:59:51.546728 140034352527168 train_slot.py:155] Step: 161900, Loss: 0.001083, Time: 10:41:37.734926
I0819 07:00:15.031207 140034352527168 train_slot.py:155] Step: 162000, Loss: 0.001263, Time: 10:42:01.219364
I0819 07:00:15.372332 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-162000
I0819 07:00:16.470309 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 162000
I0819 07:00:39.933658 140034352527168 train_slot.py:155] Step: 162100, Loss: 0.001178, Time: 10:42:26.121864
I0819 07:01:03.438717 140034352527168 train_slot.py:155] Step: 162200, Loss: 0.000873, Time: 10:42:49.626915
I0819 07:01:27.011427 140034352527168 train_slot.py:155] Step: 162300, Loss: 0.000952, Time: 10:43:13.199660
I0819 07:01:50.581982 140034352527168 train_slot.py:155] Step: 162400, Loss: 0.001019, Time: 10:43:36.770109
I0819 07:02:14.083031 140034352527168 train_slot.py:155] Step: 162500, Loss: 0.001261, Time: 10:44:00.271069
I0819 07:02:37.611578 140034352527168 train_slot.py:155] Step: 162600, Loss: 0.001139, Time: 10:44:23.799797
I0819 07:03:01.186431 140034352527168 train_slot.py:155] Step: 162700, Loss: 0.001197, Time: 10:44:47.374638
I0819 07:03:24.841803 140034352527168 train_slot.py:155] Step: 162800, Loss: 0.000953, Time: 10:45:11.030005
I0819 07:03:48.451469 140034352527168 train_slot.py:155] Step: 162900, Loss: 0.001089, Time: 10:45:34.639600
I0819 07:04:12.122747 140034352527168 train_slot.py:155] Step: 163000, Loss: 0.001112, Time: 10:45:58.310958
I0819 07:04:12.496356 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-163000
I0819 07:04:13.629681 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 163000
I0819 07:04:37.251563 140034352527168 train_slot.py:155] Step: 163100, Loss: 0.001022, Time: 10:46:23.439744
I0819 07:05:00.850115 140034352527168 train_slot.py:155] Step: 163200, Loss: 0.001087, Time: 10:46:47.038316
I0819 07:05:24.810213 140034352527168 train_slot.py:155] Step: 163300, Loss: 0.001255, Time: 10:47:10.998415
I0819 07:05:48.207211 140034352527168 train_slot.py:155] Step: 163400, Loss: 0.001086, Time: 10:47:34.395414
I0819 07:06:11.757871 140034352527168 train_slot.py:155] Step: 163500, Loss: 0.001108, Time: 10:47:57.945891
I0819 07:06:35.599876 140034352527168 train_slot.py:155] Step: 163600, Loss: 0.001620, Time: 10:48:21.788080
I0819 07:06:59.132452 140034352527168 train_slot.py:155] Step: 163700, Loss: 0.001251, Time: 10:48:45.320650
I0819 07:07:22.833034 140034352527168 train_slot.py:155] Step: 163800, Loss: 0.000934, Time: 10:49:09.021061
I0819 07:07:46.631148 140034352527168 train_slot.py:155] Step: 163900, Loss: 0.001102, Time: 10:49:32.819316
I0819 07:08:10.152284 140034352527168 train_slot.py:155] Step: 164000, Loss: 0.001192, Time: 10:49:56.340482
I0819 07:08:10.486602 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-164000
I0819 07:08:11.557117 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 164000
I0819 07:08:35.289800 140034352527168 train_slot.py:155] Step: 164100, Loss: 0.000994, Time: 10:50:21.477790
I0819 07:08:59.101851 140034352527168 train_slot.py:155] Step: 164200, Loss: 0.001070, Time: 10:50:45.290061
I0819 07:09:22.837354 140034352527168 train_slot.py:155] Step: 164300, Loss: 0.001364, Time: 10:51:09.025587
I0819 07:09:46.816100 140034352527168 train_slot.py:155] Step: 164400, Loss: 0.001040, Time: 10:51:33.004266
I0819 07:10:10.554409 140034352527168 train_slot.py:155] Step: 164500, Loss: 0.001253, Time: 10:51:56.742580
I0819 07:10:34.458207 140034352527168 train_slot.py:155] Step: 164600, Loss: 0.001304, Time: 10:52:20.646435
I0819 07:10:58.313833 140034352527168 train_slot.py:155] Step: 164700, Loss: 0.001139, Time: 10:52:44.502066
I0819 07:11:22.045666 140034352527168 train_slot.py:155] Step: 164800, Loss: 0.001133, Time: 10:53:08.233899
I0819 07:11:45.845091 140034352527168 train_slot.py:155] Step: 164900, Loss: 0.001200, Time: 10:53:32.033085
I0819 07:12:09.670686 140034352527168 train_slot.py:155] Step: 165000, Loss: 0.001167, Time: 10:53:55.858884
I0819 07:12:09.999452 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-165000
I0819 07:12:11.131064 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 165000
I0819 07:12:34.678866 140034352527168 train_slot.py:155] Step: 165100, Loss: 0.001105, Time: 10:54:20.867096
I0819 07:12:58.086957 140034352527168 train_slot.py:155] Step: 165200, Loss: 0.001059, Time: 10:54:44.275082
I0819 07:13:21.572886 140034352527168 train_slot.py:155] Step: 165300, Loss: 0.001027, Time: 10:55:07.761021
I0819 07:13:45.032820 140034352527168 train_slot.py:155] Step: 165400, Loss: 0.001068, Time: 10:55:31.221052
I0819 07:14:08.830133 140034352527168 train_slot.py:155] Step: 165500, Loss: 0.000939, Time: 10:55:55.018346
I0819 07:14:32.325237 140034352527168 train_slot.py:155] Step: 165600, Loss: 0.001237, Time: 10:56:18.513463
I0819 07:14:55.824561 140034352527168 train_slot.py:155] Step: 165700, Loss: 0.001148, Time: 10:56:42.012699
I0819 07:15:19.336009 140034352527168 train_slot.py:155] Step: 165800, Loss: 0.000986, Time: 10:57:05.524141
I0819 07:15:42.870252 140034352527168 train_slot.py:155] Step: 165900, Loss: 0.001137, Time: 10:57:29.058461
I0819 07:16:06.528448 140034352527168 train_slot.py:155] Step: 166000, Loss: 0.001203, Time: 10:57:52.716658
I0819 07:16:06.849692 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-166000
I0819 07:16:07.920727 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 166000
I0819 07:16:31.443633 140034352527168 train_slot.py:155] Step: 166100, Loss: 0.000993, Time: 10:58:17.631844
I0819 07:16:55.011035 140034352527168 train_slot.py:155] Step: 166200, Loss: 0.001293, Time: 10:58:41.199181
I0819 07:17:18.400617 140034352527168 train_slot.py:155] Step: 166300, Loss: 0.001043, Time: 10:59:04.588768
I0819 07:17:41.925525 140034352527168 train_slot.py:155] Step: 166400, Loss: 0.000971, Time: 10:59:28.113733
I0819 07:18:05.387398 140034352527168 train_slot.py:155] Step: 166500, Loss: 0.001223, Time: 10:59:51.575626
I0819 07:18:29.188021 140034352527168 train_slot.py:155] Step: 166600, Loss: 0.001309, Time: 11:00:15.376036
I0819 07:18:52.543469 140034352527168 train_slot.py:155] Step: 166700, Loss: 0.001101, Time: 11:00:38.731700
I0819 07:19:16.092347 140034352527168 train_slot.py:155] Step: 166800, Loss: 0.001008, Time: 11:01:02.280526
I0819 07:19:39.597570 140034352527168 train_slot.py:155] Step: 166900, Loss: 0.001330, Time: 11:01:25.785809
I0819 07:20:03.070498 140034352527168 train_slot.py:155] Step: 167000, Loss: 0.001273, Time: 11:01:49.258696
I0819 07:20:03.445227 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-167000
I0819 07:20:04.517422 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 167000
I0819 07:20:28.382858 140034352527168 train_slot.py:155] Step: 167100, Loss: 0.001206, Time: 11:02:14.570950
I0819 07:20:51.907692 140034352527168 train_slot.py:155] Step: 167200, Loss: 0.001046, Time: 11:02:38.095852
I0819 07:21:15.424972 140034352527168 train_slot.py:155] Step: 167300, Loss: 0.001142, Time: 11:03:01.613170
I0819 07:21:39.213740 140034352527168 train_slot.py:155] Step: 167400, Loss: 0.001250, Time: 11:03:25.401952
I0819 07:22:02.695487 140034352527168 train_slot.py:155] Step: 167500, Loss: 0.001360, Time: 11:03:48.883618
I0819 07:22:26.484642 140034352527168 train_slot.py:155] Step: 167600, Loss: 0.001103, Time: 11:04:12.672872
I0819 07:22:50.231991 140034352527168 train_slot.py:155] Step: 167700, Loss: 0.001019, Time: 11:04:36.420098
I0819 07:23:13.826748 140034352527168 train_slot.py:155] Step: 167800, Loss: 0.000962, Time: 11:05:00.014955
I0819 07:23:37.302431 140034352527168 train_slot.py:155] Step: 167900, Loss: 0.001433, Time: 11:05:23.490099
I0819 07:24:00.738305 140034352527168 train_slot.py:155] Step: 168000, Loss: 0.001125, Time: 11:05:46.926517
I0819 07:24:01.104462 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-168000
I0819 07:24:02.241989 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 168000
I0819 07:24:25.744159 140034352527168 train_slot.py:155] Step: 168100, Loss: 0.000967, Time: 11:06:11.932359
I0819 07:24:49.430053 140034352527168 train_slot.py:155] Step: 168200, Loss: 0.001215, Time: 11:06:35.618030
I0819 07:25:12.917877 140034352527168 train_slot.py:155] Step: 168300, Loss: 0.001372, Time: 11:06:59.106055
I0819 07:25:36.521388 140034352527168 train_slot.py:155] Step: 168400, Loss: 0.000997, Time: 11:07:22.709621
I0819 07:26:00.004911 140034352527168 train_slot.py:155] Step: 168500, Loss: 0.001104, Time: 11:07:46.193138
I0819 07:26:23.476309 140034352527168 train_slot.py:155] Step: 168600, Loss: 0.001373, Time: 11:08:09.664518
I0819 07:26:47.020135 140034352527168 train_slot.py:155] Step: 168700, Loss: 0.001178, Time: 11:08:33.208036
I0819 07:27:10.904830 140034352527168 train_slot.py:155] Step: 168800, Loss: 0.001064, Time: 11:08:57.092983
I0819 07:27:34.475862 140034352527168 train_slot.py:155] Step: 168900, Loss: 0.000911, Time: 11:09:20.664062
I0819 07:27:57.996518 140034352527168 train_slot.py:155] Step: 169000, Loss: 0.001134, Time: 11:09:44.184721
I0819 07:27:58.306485 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-169000
I0819 07:27:59.374315 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 169000
I0819 07:28:23.217031 140034352527168 train_slot.py:155] Step: 169100, Loss: 0.001278, Time: 11:10:09.405176
I0819 07:28:46.712386 140034352527168 train_slot.py:155] Step: 169200, Loss: 0.001215, Time: 11:10:32.900615
I0819 07:29:10.495657 140034352527168 train_slot.py:155] Step: 169300, Loss: 0.001062, Time: 11:10:56.683857
I0819 07:29:34.091690 140034352527168 train_slot.py:155] Step: 169400, Loss: 0.000971, Time: 11:11:20.279823
I0819 07:29:57.679008 140034352527168 train_slot.py:155] Step: 169500, Loss: 0.000983, Time: 11:11:43.867215
I0819 07:30:21.470549 140034352527168 train_slot.py:155] Step: 169600, Loss: 0.001168, Time: 11:12:07.658749
I0819 07:30:44.970820 140034352527168 train_slot.py:155] Step: 169700, Loss: 0.000965, Time: 11:12:31.159022
I0819 07:31:08.672607 140034352527168 train_slot.py:155] Step: 169800, Loss: 0.001233, Time: 11:12:54.860756
I0819 07:31:32.179755 140034352527168 train_slot.py:155] Step: 169900, Loss: 0.001183, Time: 11:13:18.367944
I0819 07:31:55.705269 140034352527168 train_slot.py:155] Step: 170000, Loss: 0.001067, Time: 11:13:41.893501
I0819 07:31:56.090214 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-170000
I0819 07:31:57.159282 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 170000
I0819 07:32:20.722302 140034352527168 train_slot.py:155] Step: 170100, Loss: 0.001092, Time: 11:14:06.910441
I0819 07:32:44.282995 140034352527168 train_slot.py:155] Step: 170200, Loss: 0.000995, Time: 11:14:30.471092
I0819 07:33:07.833373 140034352527168 train_slot.py:155] Step: 170300, Loss: 0.001155, Time: 11:14:54.021572
I0819 07:33:31.750365 140034352527168 train_slot.py:155] Step: 170400, Loss: 0.001102, Time: 11:15:17.938588
I0819 07:33:55.579687 140034352527168 train_slot.py:155] Step: 170500, Loss: 0.001088, Time: 11:15:41.767921
I0819 07:34:19.490918 140034352527168 train_slot.py:155] Step: 170600, Loss: 0.001094, Time: 11:16:05.679034
I0819 07:34:43.612046 140034352527168 train_slot.py:155] Step: 170700, Loss: 0.001167, Time: 11:16:29.800248
I0819 07:35:07.566594 140034352527168 train_slot.py:155] Step: 170800, Loss: 0.001262, Time: 11:16:53.754791
I0819 07:35:31.662433 140034352527168 train_slot.py:155] Step: 170900, Loss: 0.001058, Time: 11:17:17.850636
I0819 07:35:55.246379 140034352527168 train_slot.py:155] Step: 171000, Loss: 0.001243, Time: 11:17:41.434539
I0819 07:35:55.582810 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-171000
I0819 07:35:56.658619 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 171000
I0819 07:36:20.180794 140034352527168 train_slot.py:155] Step: 171100, Loss: 0.001300, Time: 11:18:06.368916
I0819 07:36:43.642053 140034352527168 train_slot.py:155] Step: 171200, Loss: 0.001199, Time: 11:18:29.830256
I0819 07:37:07.190016 140034352527168 train_slot.py:155] Step: 171300, Loss: 0.001156, Time: 11:18:53.378222
I0819 07:37:30.622188 140034352527168 train_slot.py:155] Step: 171400, Loss: 0.001290, Time: 11:19:16.810163
I0819 07:37:54.600740 140034352527168 train_slot.py:155] Step: 171500, Loss: 0.000921, Time: 11:19:40.788927
I0819 07:38:18.507925 140034352527168 train_slot.py:155] Step: 171600, Loss: 0.001214, Time: 11:20:04.696125
I0819 07:38:42.391225 140034352527168 train_slot.py:155] Step: 171700, Loss: 0.000969, Time: 11:20:28.579355
I0819 07:39:06.816304 140034352527168 train_slot.py:155] Step: 171800, Loss: 0.001077, Time: 11:20:53.004525
I0819 07:39:30.686194 140034352527168 train_slot.py:155] Step: 171900, Loss: 0.000994, Time: 11:21:16.874393
I0819 07:39:54.794042 140034352527168 train_slot.py:155] Step: 172000, Loss: 0.001126, Time: 11:21:40.982245
I0819 07:39:55.170555 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-172000
I0819 07:39:56.335438 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 172000
I0819 07:40:19.817905 140034352527168 train_slot.py:155] Step: 172100, Loss: 0.000953, Time: 11:22:06.005952
I0819 07:40:43.312584 140034352527168 train_slot.py:155] Step: 172200, Loss: 0.001043, Time: 11:22:29.500740
I0819 07:41:06.728682 140034352527168 train_slot.py:155] Step: 172300, Loss: 0.000865, Time: 11:22:52.916885
I0819 07:41:30.454524 140034352527168 train_slot.py:155] Step: 172400, Loss: 0.001134, Time: 11:23:16.642726
I0819 07:41:53.984367 140034352527168 train_slot.py:155] Step: 172500, Loss: 0.001049, Time: 11:23:40.172357
I0819 07:42:17.753107 140034352527168 train_slot.py:155] Step: 172600, Loss: 0.001193, Time: 11:24:03.941322
I0819 07:42:41.514936 140034352527168 train_slot.py:155] Step: 172700, Loss: 0.000988, Time: 11:24:27.703135
I0819 07:43:05.081980 140034352527168 train_slot.py:155] Step: 172800, Loss: 0.001004, Time: 11:24:51.270039
I0819 07:43:28.698846 140034352527168 train_slot.py:155] Step: 172900, Loss: 0.000978, Time: 11:25:14.887003
I0819 07:43:52.185859 140034352527168 train_slot.py:155] Step: 173000, Loss: 0.001147, Time: 11:25:38.374056
I0819 07:43:52.513511 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-173000
I0819 07:43:53.647008 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 173000
I0819 07:44:17.534719 140034352527168 train_slot.py:155] Step: 173100, Loss: 0.001310, Time: 11:26:03.722919
I0819 07:44:41.420715 140034352527168 train_slot.py:155] Step: 173200, Loss: 0.001093, Time: 11:26:27.608928
I0819 07:45:05.279080 140034352527168 train_slot.py:155] Step: 173300, Loss: 0.000995, Time: 11:26:51.467091
I0819 07:45:29.218433 140034352527168 train_slot.py:155] Step: 173400, Loss: 0.001307, Time: 11:27:15.406665
I0819 07:45:53.206905 140034352527168 train_slot.py:155] Step: 173500, Loss: 0.001008, Time: 11:27:39.395144
I0819 07:46:17.290293 140034352527168 train_slot.py:155] Step: 173600, Loss: 0.001333, Time: 11:28:03.478496
I0819 07:46:40.816983 140034352527168 train_slot.py:155] Step: 173700, Loss: 0.001100, Time: 11:28:27.005109
I0819 07:47:04.381430 140034352527168 train_slot.py:155] Step: 173800, Loss: 0.001072, Time: 11:28:50.569621
I0819 07:47:27.847815 140034352527168 train_slot.py:155] Step: 173900, Loss: 0.000917, Time: 11:29:14.036023
I0819 07:47:51.343554 140034352527168 train_slot.py:155] Step: 174000, Loss: 0.001130, Time: 11:29:37.531783
I0819 07:47:51.679982 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-174000
I0819 07:47:52.757322 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 174000
I0819 07:48:16.312825 140034352527168 train_slot.py:155] Step: 174100, Loss: 0.001110, Time: 11:30:02.501012
I0819 07:48:40.325298 140034352527168 train_slot.py:155] Step: 174200, Loss: 0.001031, Time: 11:30:26.513425
I0819 07:49:04.183587 140034352527168 train_slot.py:155] Step: 174300, Loss: 0.001009, Time: 11:30:50.371794
I0819 07:49:27.908016 140034352527168 train_slot.py:155] Step: 174400, Loss: 0.001324, Time: 11:31:14.096146
I0819 07:49:51.440339 140034352527168 train_slot.py:155] Step: 174500, Loss: 0.001189, Time: 11:31:37.628520
I0819 07:50:15.177661 140034352527168 train_slot.py:155] Step: 174600, Loss: 0.001167, Time: 11:32:01.365894
I0819 07:50:38.816510 140034352527168 train_slot.py:155] Step: 174700, Loss: 0.001038, Time: 11:32:25.004709
I0819 07:51:02.322328 140034352527168 train_slot.py:155] Step: 174800, Loss: 0.001021, Time: 11:32:48.510445
I0819 07:51:25.740321 140034352527168 train_slot.py:155] Step: 174900, Loss: 0.001085, Time: 11:33:11.928529
I0819 07:51:49.197731 140034352527168 train_slot.py:155] Step: 175000, Loss: 0.001276, Time: 11:33:35.385962
I0819 07:51:49.582240 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-175000
I0819 07:51:50.680449 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 175000
I0819 07:52:14.288887 140034352527168 train_slot.py:155] Step: 175100, Loss: 0.001134, Time: 11:34:00.477073
I0819 07:52:37.882923 140034352527168 train_slot.py:155] Step: 175200, Loss: 0.001157, Time: 11:34:24.070924
I0819 07:53:01.623901 140034352527168 train_slot.py:155] Step: 175300, Loss: 0.001169, Time: 11:34:47.812099
I0819 07:53:25.485463 140034352527168 train_slot.py:155] Step: 175400, Loss: 0.001314, Time: 11:35:11.673658
I0819 07:53:49.046785 140034352527168 train_slot.py:155] Step: 175500, Loss: 0.000998, Time: 11:35:35.234873
I0819 07:54:12.579949 140034352527168 train_slot.py:155] Step: 175600, Loss: 0.001212, Time: 11:35:58.768036
I0819 07:54:36.034315 140034352527168 train_slot.py:155] Step: 175700, Loss: 0.001082, Time: 11:36:22.222538
I0819 07:54:59.740066 140034352527168 train_slot.py:155] Step: 175800, Loss: 0.001258, Time: 11:36:45.928267
I0819 07:55:23.266027 140034352527168 train_slot.py:155] Step: 175900, Loss: 0.000861, Time: 11:37:09.454226
I0819 07:55:46.825081 140034352527168 train_slot.py:155] Step: 176000, Loss: 0.001170, Time: 11:37:33.013055
I0819 07:55:47.204524 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-176000
I0819 07:55:48.279094 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 176000
I0819 07:56:11.802079 140034352527168 train_slot.py:155] Step: 176100, Loss: 0.001078, Time: 11:37:57.990183
I0819 07:56:35.318961 140034352527168 train_slot.py:155] Step: 176200, Loss: 0.001333, Time: 11:38:21.507161
I0819 07:56:58.725615 140034352527168 train_slot.py:155] Step: 176300, Loss: 0.001054, Time: 11:38:44.913818
I0819 07:57:22.737922 140034352527168 train_slot.py:155] Step: 176400, Loss: 0.001053, Time: 11:39:08.926081
I0819 07:57:46.252649 140034352527168 train_slot.py:155] Step: 176500, Loss: 0.001058, Time: 11:39:32.440860
I0819 07:58:09.688771 140034352527168 train_slot.py:155] Step: 176600, Loss: 0.001010, Time: 11:39:55.876915
I0819 07:58:33.273142 140034352527168 train_slot.py:155] Step: 176700, Loss: 0.000954, Time: 11:40:19.461343
I0819 07:58:56.805902 140034352527168 train_slot.py:155] Step: 176800, Loss: 0.001608, Time: 11:40:42.994105
I0819 07:59:20.590087 140034352527168 train_slot.py:155] Step: 176900, Loss: 0.001029, Time: 11:41:06.778098
I0819 07:59:44.003773 140034352527168 train_slot.py:155] Step: 177000, Loss: 0.000908, Time: 11:41:30.191976
I0819 07:59:44.414234 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-177000
I0819 07:59:45.542054 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 177000
I0819 08:00:09.030128 140034352527168 train_slot.py:155] Step: 177100, Loss: 0.001019, Time: 11:41:55.218205
I0819 08:00:32.787403 140034352527168 train_slot.py:155] Step: 177200, Loss: 0.001060, Time: 11:42:18.975635
I0819 08:00:56.376711 140034352527168 train_slot.py:155] Step: 177300, Loss: 0.001148, Time: 11:42:42.564917
I0819 08:01:20.180404 140034352527168 train_slot.py:155] Step: 177400, Loss: 0.000976, Time: 11:43:06.368555
I0819 08:01:43.609330 140034352527168 train_slot.py:155] Step: 177500, Loss: 0.001005, Time: 11:43:29.797523
I0819 08:02:07.016148 140034352527168 train_slot.py:155] Step: 177600, Loss: 0.000994, Time: 11:43:53.204348
I0819 08:02:30.489395 140034352527168 train_slot.py:155] Step: 177700, Loss: 0.000886, Time: 11:44:16.677343
I0819 08:02:54.004312 140034352527168 train_slot.py:155] Step: 177800, Loss: 0.001240, Time: 11:44:40.192495
I0819 08:03:17.443747 140034352527168 train_slot.py:155] Step: 177900, Loss: 0.000949, Time: 11:45:03.631943
I0819 08:03:41.209313 140034352527168 train_slot.py:155] Step: 178000, Loss: 0.001111, Time: 11:45:27.397517
I0819 08:03:41.584886 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-178000
I0819 08:03:42.654103 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 178000
I0819 08:04:06.151216 140034352527168 train_slot.py:155] Step: 178100, Loss: 0.000868, Time: 11:45:52.339369
I0819 08:04:29.640293 140034352527168 train_slot.py:155] Step: 178200, Loss: 0.001014, Time: 11:46:15.828501
I0819 08:04:53.120728 140034352527168 train_slot.py:155] Step: 178300, Loss: 0.001220, Time: 11:46:39.308882
I0819 08:05:16.811541 140034352527168 train_slot.py:155] Step: 178400, Loss: 0.001025, Time: 11:47:02.999773
I0819 08:05:40.588878 140034352527168 train_slot.py:155] Step: 178500, Loss: 0.001126, Time: 11:47:26.777071
I0819 08:06:04.361387 140034352527168 train_slot.py:155] Step: 178600, Loss: 0.001278, Time: 11:47:50.549498
I0819 08:06:27.841710 140034352527168 train_slot.py:155] Step: 178700, Loss: 0.001163, Time: 11:48:14.029899
I0819 08:06:51.227777 140034352527168 train_slot.py:155] Step: 178800, Loss: 0.000931, Time: 11:48:37.416015
I0819 08:07:14.778942 140034352527168 train_slot.py:155] Step: 178900, Loss: 0.001314, Time: 11:49:00.967180
I0819 08:07:38.295500 140034352527168 train_slot.py:155] Step: 179000, Loss: 0.001011, Time: 11:49:24.483397
I0819 08:07:38.623281 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-179000
I0819 08:07:39.754137 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 179000
I0819 08:08:03.558829 140034352527168 train_slot.py:155] Step: 179100, Loss: 0.001084, Time: 11:49:49.747023
I0819 08:08:27.039717 140034352527168 train_slot.py:155] Step: 179200, Loss: 0.001027, Time: 11:50:13.227919
I0819 08:08:50.561337 140034352527168 train_slot.py:155] Step: 179300, Loss: 0.000907, Time: 11:50:36.749481
I0819 08:09:14.149019 140034352527168 train_slot.py:155] Step: 179400, Loss: 0.001083, Time: 11:51:00.337168
I0819 08:09:37.507635 140034352527168 train_slot.py:155] Step: 179500, Loss: 0.001255, Time: 11:51:23.695835
I0819 08:10:01.193779 140034352527168 train_slot.py:155] Step: 179600, Loss: 0.001146, Time: 11:51:47.381988
I0819 08:10:25.313997 140034352527168 train_slot.py:155] Step: 179700, Loss: 0.000899, Time: 11:52:11.502130
I0819 08:10:48.849889 140034352527168 train_slot.py:155] Step: 179800, Loss: 0.000825, Time: 11:52:35.038108
I0819 08:11:12.293204 140034352527168 train_slot.py:155] Step: 179900, Loss: 0.001052, Time: 11:52:58.481441
I0819 08:11:35.919141 140034352527168 train_slot.py:155] Step: 180000, Loss: 0.000889, Time: 11:53:22.107344
I0819 08:11:36.268633 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-180000
I0819 08:11:37.378117 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 180000
I0819 08:12:00.918145 140034352527168 train_slot.py:155] Step: 180100, Loss: 0.001057, Time: 11:53:47.106271
I0819 08:12:24.592759 140034352527168 train_slot.py:155] Step: 180200, Loss: 0.000964, Time: 11:54:10.780973
I0819 08:12:48.233211 140034352527168 train_slot.py:155] Step: 180300, Loss: 0.000943, Time: 11:54:34.421446
I0819 08:13:11.753620 140034352527168 train_slot.py:155] Step: 180400, Loss: 0.001015, Time: 11:54:57.941829
I0819 08:13:35.197592 140034352527168 train_slot.py:155] Step: 180500, Loss: 0.001102, Time: 11:55:21.385628
I0819 08:13:58.711971 140034352527168 train_slot.py:155] Step: 180600, Loss: 0.001129, Time: 11:55:44.900145
I0819 08:14:22.580146 140034352527168 train_slot.py:155] Step: 180700, Loss: 0.000862, Time: 11:56:08.768376
I0819 08:14:46.043489 140034352527168 train_slot.py:155] Step: 180800, Loss: 0.001021, Time: 11:56:32.231695
I0819 08:15:09.637434 140034352527168 train_slot.py:155] Step: 180900, Loss: 0.001045, Time: 11:56:55.825572
I0819 08:15:33.413129 140034352527168 train_slot.py:155] Step: 181000, Loss: 0.001045, Time: 11:57:19.601349
I0819 08:15:33.734313 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-181000
I0819 08:15:34.805449 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 181000
I0819 08:15:58.283952 140034352527168 train_slot.py:155] Step: 181100, Loss: 0.001339, Time: 11:57:44.472151
I0819 08:16:22.027335 140034352527168 train_slot.py:155] Step: 181200, Loss: 0.000999, Time: 11:58:08.215569
I0819 08:16:45.583404 140034352527168 train_slot.py:155] Step: 181300, Loss: 0.001078, Time: 11:58:31.771610
I0819 08:17:09.166351 140034352527168 train_slot.py:155] Step: 181400, Loss: 0.001066, Time: 11:58:55.354487
I0819 08:17:32.658616 140034352527168 train_slot.py:155] Step: 181500, Loss: 0.000929, Time: 11:59:18.846779
I0819 08:17:56.163348 140034352527168 train_slot.py:155] Step: 181600, Loss: 0.001077, Time: 11:59:42.351560
I0819 08:18:19.962237 140034352527168 train_slot.py:155] Step: 181700, Loss: 0.001069, Time: 12:00:06.150439
I0819 08:18:43.708484 140034352527168 train_slot.py:155] Step: 181800, Loss: 0.000735, Time: 12:00:29.896600
I0819 08:19:07.201998 140034352527168 train_slot.py:155] Step: 181900, Loss: 0.001086, Time: 12:00:53.390171
I0819 08:19:30.786323 140034352527168 train_slot.py:155] Step: 182000, Loss: 0.001117, Time: 12:01:16.974530
I0819 08:19:31.154439 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-182000
I0819 08:19:32.285101 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 182000
I0819 08:19:55.900783 140034352527168 train_slot.py:155] Step: 182100, Loss: 0.001295, Time: 12:01:42.088779
I0819 08:20:19.399563 140034352527168 train_slot.py:155] Step: 182200, Loss: 0.000970, Time: 12:02:05.587746
I0819 08:20:43.195002 140034352527168 train_slot.py:155] Step: 182300, Loss: 0.000966, Time: 12:02:29.383206
I0819 08:21:07.089046 140034352527168 train_slot.py:155] Step: 182400, Loss: 0.000996, Time: 12:02:53.277255
I0819 08:21:30.985215 140034352527168 train_slot.py:155] Step: 182500, Loss: 0.001100, Time: 12:03:17.173416
I0819 08:21:54.819440 140034352527168 train_slot.py:155] Step: 182600, Loss: 0.000980, Time: 12:03:41.007552
I0819 08:22:18.734682 140034352527168 train_slot.py:155] Step: 182700, Loss: 0.000959, Time: 12:04:04.922899
I0819 08:22:42.544198 140034352527168 train_slot.py:155] Step: 182800, Loss: 0.001083, Time: 12:04:28.732430
I0819 08:23:06.474459 140034352527168 train_slot.py:155] Step: 182900, Loss: 0.001097, Time: 12:04:52.662660
I0819 08:23:30.178505 140034352527168 train_slot.py:155] Step: 183000, Loss: 0.001117, Time: 12:05:16.366624
I0819 08:23:30.501240 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-183000
I0819 08:23:31.608588 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 183000
I0819 08:23:55.353225 140034352527168 train_slot.py:155] Step: 183100, Loss: 0.000976, Time: 12:05:41.541430
I0819 08:24:18.911579 140034352527168 train_slot.py:155] Step: 183200, Loss: 0.001204, Time: 12:06:05.099777
I0819 08:24:42.562151 140034352527168 train_slot.py:155] Step: 183300, Loss: 0.001015, Time: 12:06:28.750307
I0819 08:25:06.347032 140034352527168 train_slot.py:155] Step: 183400, Loss: 0.001058, Time: 12:06:52.535208
I0819 08:25:29.848085 140034352527168 train_slot.py:155] Step: 183500, Loss: 0.000949, Time: 12:07:16.036287
I0819 08:25:53.362179 140034352527168 train_slot.py:155] Step: 183600, Loss: 0.000862, Time: 12:07:39.550329
I0819 08:26:16.923761 140034352527168 train_slot.py:155] Step: 183700, Loss: 0.001173, Time: 12:08:03.111954
I0819 08:26:40.410398 140034352527168 train_slot.py:155] Step: 183800, Loss: 0.000924, Time: 12:08:26.598599
I0819 08:27:03.881178 140034352527168 train_slot.py:155] Step: 183900, Loss: 0.001012, Time: 12:08:50.069389
I0819 08:27:27.682735 140034352527168 train_slot.py:155] Step: 184000, Loss: 0.001020, Time: 12:09:13.870799
I0819 08:27:28.080848 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-184000
I0819 08:27:29.215337 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 184000
I0819 08:27:52.764441 140034352527168 train_slot.py:155] Step: 184100, Loss: 0.000998, Time: 12:09:38.952664
I0819 08:28:16.302987 140034352527168 train_slot.py:155] Step: 184200, Loss: 0.001239, Time: 12:10:02.491192
I0819 08:28:39.879598 140034352527168 train_slot.py:155] Step: 184300, Loss: 0.001241, Time: 12:10:26.067817
I0819 08:29:03.414190 140034352527168 train_slot.py:155] Step: 184400, Loss: 0.001077, Time: 12:10:49.602310
I0819 08:29:27.146152 140034352527168 train_slot.py:155] Step: 184500, Loss: 0.000905, Time: 12:11:13.334328
I0819 08:29:50.696299 140034352527168 train_slot.py:155] Step: 184600, Loss: 0.001067, Time: 12:11:36.884499
I0819 08:30:14.225769 140034352527168 train_slot.py:155] Step: 184700, Loss: 0.001165, Time: 12:12:00.413981
I0819 08:30:38.347287 140034352527168 train_slot.py:155] Step: 184800, Loss: 0.001153, Time: 12:12:24.535516
I0819 08:31:01.817814 140034352527168 train_slot.py:155] Step: 184900, Loss: 0.001049, Time: 12:12:48.005963
I0819 08:31:25.536072 140034352527168 train_slot.py:155] Step: 185000, Loss: 0.000960, Time: 12:13:11.724274
I0819 08:31:25.925927 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-185000
I0819 08:31:27.059767 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 185000
I0819 08:31:50.939078 140034352527168 train_slot.py:155] Step: 185100, Loss: 0.001120, Time: 12:13:37.127281
I0819 08:32:14.899346 140034352527168 train_slot.py:155] Step: 185200, Loss: 0.000984, Time: 12:14:01.087474
I0819 08:32:38.300029 140034352527168 train_slot.py:155] Step: 185300, Loss: 0.001049, Time: 12:14:24.488180
I0819 08:33:01.791718 140034352527168 train_slot.py:155] Step: 185400, Loss: 0.001153, Time: 12:14:47.979924
I0819 08:33:25.198003 140034352527168 train_slot.py:155] Step: 185500, Loss: 0.001023, Time: 12:15:11.386205
I0819 08:33:48.919227 140034352527168 train_slot.py:155] Step: 185600, Loss: 0.000962, Time: 12:15:35.107301
I0819 08:34:12.406795 140034352527168 train_slot.py:155] Step: 185700, Loss: 0.000893, Time: 12:15:58.594995
I0819 08:34:35.913015 140034352527168 train_slot.py:155] Step: 185800, Loss: 0.001049, Time: 12:16:22.101079
I0819 08:34:59.736682 140034352527168 train_slot.py:155] Step: 185900, Loss: 0.000855, Time: 12:16:45.924881
I0819 08:35:23.581501 140034352527168 train_slot.py:155] Step: 186000, Loss: 0.001092, Time: 12:17:09.769525
I0819 08:35:23.986251 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-186000
I0819 08:35:25.128155 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 186000
I0819 08:35:48.865297 140034352527168 train_slot.py:155] Step: 186100, Loss: 0.000938, Time: 12:17:35.053499
I0819 08:36:12.432975 140034352527168 train_slot.py:155] Step: 186200, Loss: 0.000934, Time: 12:17:58.621183
I0819 08:36:35.889575 140034352527168 train_slot.py:155] Step: 186300, Loss: 0.001096, Time: 12:18:22.077784
I0819 08:36:59.414500 140034352527168 train_slot.py:155] Step: 186400, Loss: 0.001027, Time: 12:18:45.602705
I0819 08:37:22.907587 140034352527168 train_slot.py:155] Step: 186500, Loss: 0.001008, Time: 12:19:09.095794
I0819 08:37:46.322134 140034352527168 train_slot.py:155] Step: 186600, Loss: 0.001093, Time: 12:19:32.510333
I0819 08:38:10.281432 140034352527168 train_slot.py:155] Step: 186700, Loss: 0.001059, Time: 12:19:56.469635
I0819 08:38:33.687604 140034352527168 train_slot.py:155] Step: 186800, Loss: 0.001019, Time: 12:20:19.875727
I0819 08:38:57.239308 140034352527168 train_slot.py:155] Step: 186900, Loss: 0.001174, Time: 12:20:43.426818
I0819 08:39:20.813842 140034352527168 train_slot.py:155] Step: 187000, Loss: 0.001046, Time: 12:21:07.002053
I0819 08:39:21.192394 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-187000
I0819 08:39:22.306168 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 187000
I0819 08:39:45.851911 140034352527168 train_slot.py:155] Step: 187100, Loss: 0.001112, Time: 12:21:32.040126
I0819 08:40:09.480905 140034352527168 train_slot.py:155] Step: 187200, Loss: 0.000950, Time: 12:21:55.669030
I0819 08:40:33.104541 140034352527168 train_slot.py:155] Step: 187300, Loss: 0.001133, Time: 12:22:19.292756
I0819 08:40:56.768474 140034352527168 train_slot.py:155] Step: 187400, Loss: 0.001184, Time: 12:22:42.956707
I0819 08:41:20.369194 140034352527168 train_slot.py:155] Step: 187500, Loss: 0.001126, Time: 12:23:06.557341
I0819 08:41:43.974963 140034352527168 train_slot.py:155] Step: 187600, Loss: 0.001241, Time: 12:23:30.163130
I0819 08:42:07.262114 140034352527168 train_slot.py:155] Step: 187700, Loss: 0.001012, Time: 12:23:53.450347
I0819 08:42:31.209650 140034352527168 train_slot.py:155] Step: 187800, Loss: 0.001120, Time: 12:24:17.397854
I0819 08:42:54.772068 140034352527168 train_slot.py:155] Step: 187900, Loss: 0.000981, Time: 12:24:40.960078
I0819 08:43:18.512440 140034352527168 train_slot.py:155] Step: 188000, Loss: 0.001139, Time: 12:25:04.700594
I0819 08:43:18.896721 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-188000
I0819 08:43:19.980198 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 188000
I0819 08:43:43.415940 140034352527168 train_slot.py:155] Step: 188100, Loss: 0.001159, Time: 12:25:29.604141
I0819 08:44:06.792648 140034352527168 train_slot.py:155] Step: 188200, Loss: 0.001444, Time: 12:25:52.980851
I0819 08:44:30.454183 140034352527168 train_slot.py:155] Step: 188300, Loss: 0.001074, Time: 12:26:16.642418
I0819 08:44:53.932200 140034352527168 train_slot.py:155] Step: 188400, Loss: 0.000873, Time: 12:26:40.120274
I0819 08:45:17.427204 140034352527168 train_slot.py:155] Step: 188500, Loss: 0.001141, Time: 12:27:03.615429
I0819 08:45:40.963407 140034352527168 train_slot.py:155] Step: 188600, Loss: 0.001218, Time: 12:27:27.151613
I0819 08:46:04.556955 140034352527168 train_slot.py:155] Step: 188700, Loss: 0.001127, Time: 12:27:50.745015
I0819 08:46:28.337853 140034352527168 train_slot.py:155] Step: 188800, Loss: 0.001017, Time: 12:28:14.526056
I0819 08:46:51.848195 140034352527168 train_slot.py:155] Step: 188900, Loss: 0.000990, Time: 12:28:38.036400
I0819 08:47:15.391534 140034352527168 train_slot.py:155] Step: 189000, Loss: 0.001119, Time: 12:29:01.579480
I0819 08:47:15.713227 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-189000
I0819 08:47:16.823503 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 189000
I0819 08:47:40.336035 140034352527168 train_slot.py:155] Step: 189100, Loss: 0.001053, Time: 12:29:26.524255
I0819 08:48:04.119473 140034352527168 train_slot.py:155] Step: 189200, Loss: 0.001065, Time: 12:29:50.307672
I0819 08:48:27.556925 140034352527168 train_slot.py:155] Step: 189300, Loss: 0.001012, Time: 12:30:13.745110
I0819 08:48:51.215987 140034352527168 train_slot.py:155] Step: 189400, Loss: 0.001091, Time: 12:30:37.404187
I0819 08:49:14.737271 140034352527168 train_slot.py:155] Step: 189500, Loss: 0.001019, Time: 12:31:00.925503
I0819 08:49:38.194343 140034352527168 train_slot.py:155] Step: 189600, Loss: 0.001041, Time: 12:31:24.382557
I0819 08:50:01.693087 140034352527168 train_slot.py:155] Step: 189700, Loss: 0.001069, Time: 12:31:47.881180
I0819 08:50:25.215811 140034352527168 train_slot.py:155] Step: 189800, Loss: 0.001176, Time: 12:32:11.404023
I0819 08:50:48.862006 140034352527168 train_slot.py:155] Step: 189900, Loss: 0.000907, Time: 12:32:35.050238
I0819 08:51:12.397901 140034352527168 train_slot.py:155] Step: 190000, Loss: 0.001116, Time: 12:32:58.586112
I0819 08:51:12.716686 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-190000
I0819 08:51:13.793385 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 190000
I0819 08:51:37.369014 140034352527168 train_slot.py:155] Step: 190100, Loss: 0.000742, Time: 12:33:23.557054
I0819 08:52:01.072583 140034352527168 train_slot.py:155] Step: 190200, Loss: 0.001185, Time: 12:33:47.260782
I0819 08:52:24.475466 140034352527168 train_slot.py:155] Step: 190300, Loss: 0.001161, Time: 12:34:10.663692
I0819 08:52:48.029830 140034352527168 train_slot.py:155] Step: 190400, Loss: 0.001208, Time: 12:34:34.218030
I0819 08:53:11.749904 140034352527168 train_slot.py:155] Step: 190500, Loss: 0.001010, Time: 12:34:57.937885
I0819 08:53:35.338697 140034352527168 train_slot.py:155] Step: 190600, Loss: 0.001055, Time: 12:35:21.526876
I0819 08:53:58.816632 140034352527168 train_slot.py:155] Step: 190700, Loss: 0.000920, Time: 12:35:45.004860
I0819 08:54:22.356510 140034352527168 train_slot.py:155] Step: 190800, Loss: 0.001176, Time: 12:36:08.544707
I0819 08:54:45.910501 140034352527168 train_slot.py:155] Step: 190900, Loss: 0.001172, Time: 12:36:32.098540
I0819 08:55:09.606390 140034352527168 train_slot.py:155] Step: 191000, Loss: 0.001086, Time: 12:36:55.794620
I0819 08:55:09.927360 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-191000
I0819 08:55:11.013887 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 191000
I0819 08:55:34.512652 140034352527168 train_slot.py:155] Step: 191100, Loss: 0.001103, Time: 12:37:20.700815
I0819 08:55:58.065979 140034352527168 train_slot.py:155] Step: 191200, Loss: 0.001053, Time: 12:37:44.254181
I0819 08:56:22.162642 140034352527168 train_slot.py:155] Step: 191300, Loss: 0.001177, Time: 12:38:08.350759
I0819 08:56:45.777931 140034352527168 train_slot.py:155] Step: 191400, Loss: 0.001230, Time: 12:38:31.966167
I0819 08:57:09.247221 140034352527168 train_slot.py:155] Step: 191500, Loss: 0.001430, Time: 12:38:55.435449
I0819 08:57:32.988649 140034352527168 train_slot.py:155] Step: 191600, Loss: 0.000932, Time: 12:39:19.176881
I0819 08:57:56.478618 140034352527168 train_slot.py:155] Step: 191700, Loss: 0.000968, Time: 12:39:42.666722
I0819 08:58:19.956682 140034352527168 train_slot.py:155] Step: 191800, Loss: 0.001170, Time: 12:40:06.144891
I0819 08:58:43.473698 140034352527168 train_slot.py:155] Step: 191900, Loss: 0.000948, Time: 12:40:29.661899
I0819 08:59:06.993243 140034352527168 train_slot.py:155] Step: 192000, Loss: 0.001070, Time: 12:40:53.181440
I0819 08:59:07.315092 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-192000
I0819 08:59:08.414767 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 192000
I0819 08:59:32.089555 140034352527168 train_slot.py:155] Step: 192100, Loss: 0.001022, Time: 12:41:18.277629
I0819 08:59:55.560043 140034352527168 train_slot.py:155] Step: 192200, Loss: 0.001144, Time: 12:41:41.748237
I0819 09:00:18.969416 140034352527168 train_slot.py:155] Step: 192300, Loss: 0.001002, Time: 12:42:05.157610
I0819 09:00:42.494885 140034352527168 train_slot.py:155] Step: 192400, Loss: 0.000987, Time: 12:42:28.683085
I0819 09:01:05.992542 140034352527168 train_slot.py:155] Step: 192500, Loss: 0.000950, Time: 12:42:52.180613
I0819 09:01:29.706279 140034352527168 train_slot.py:155] Step: 192600, Loss: 0.001103, Time: 12:43:15.894484
I0819 09:01:53.595237 140034352527168 train_slot.py:155] Step: 192700, Loss: 0.001003, Time: 12:43:39.783449
I0819 09:02:17.708175 140034352527168 train_slot.py:155] Step: 192800, Loss: 0.000985, Time: 12:44:03.896402
I0819 09:02:41.608419 140034352527168 train_slot.py:155] Step: 192900, Loss: 0.000905, Time: 12:44:27.796388
I0819 09:03:05.440145 140034352527168 train_slot.py:155] Step: 193000, Loss: 0.000817, Time: 12:44:51.628339
I0819 09:03:05.800110 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-193000
I0819 09:03:06.913239 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 193000
I0819 09:03:31.113834 140034352527168 train_slot.py:155] Step: 193100, Loss: 0.000867, Time: 12:45:17.302030
I0819 09:03:54.893164 140034352527168 train_slot.py:155] Step: 193200, Loss: 0.001160, Time: 12:45:41.081122
I0819 09:04:18.385611 140034352527168 train_slot.py:155] Step: 193300, Loss: 0.000976, Time: 12:46:04.573832
I0819 09:04:41.847472 140034352527168 train_slot.py:155] Step: 193400, Loss: 0.001067, Time: 12:46:28.035672
I0819 09:05:05.324870 140034352527168 train_slot.py:155] Step: 193500, Loss: 0.001010, Time: 12:46:51.513057
I0819 09:05:28.790394 140034352527168 train_slot.py:155] Step: 193600, Loss: 0.001197, Time: 12:47:14.978417
I0819 09:05:52.508123 140034352527168 train_slot.py:155] Step: 193700, Loss: 0.001066, Time: 12:47:38.696338
I0819 09:06:16.014550 140034352527168 train_slot.py:155] Step: 193800, Loss: 0.001141, Time: 12:48:02.202752
I0819 09:06:39.603902 140034352527168 train_slot.py:155] Step: 193900, Loss: 0.001046, Time: 12:48:25.792105
I0819 09:07:03.218680 140034352527168 train_slot.py:155] Step: 194000, Loss: 0.001040, Time: 12:48:49.406728
I0819 09:07:03.591432 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-194000
I0819 09:07:04.728773 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 194000
I0819 09:07:28.438024 140034352527168 train_slot.py:155] Step: 194100, Loss: 0.001182, Time: 12:49:14.626255
I0819 09:07:51.868262 140034352527168 train_slot.py:155] Step: 194200, Loss: 0.001034, Time: 12:49:38.056463
I0819 09:08:15.528985 140034352527168 train_slot.py:155] Step: 194300, Loss: 0.001133, Time: 12:50:01.717108
I0819 09:08:39.033167 140034352527168 train_slot.py:155] Step: 194400, Loss: 0.001052, Time: 12:50:25.221396
I0819 09:09:02.575976 140034352527168 train_slot.py:155] Step: 194500, Loss: 0.001205, Time: 12:50:48.764174
I0819 09:09:26.135571 140034352527168 train_slot.py:155] Step: 194600, Loss: 0.000941, Time: 12:51:12.323772
I0819 09:09:49.896044 140034352527168 train_slot.py:155] Step: 194700, Loss: 0.001229, Time: 12:51:36.084155
I0819 09:10:13.583772 140034352527168 train_slot.py:155] Step: 194800, Loss: 0.001100, Time: 12:51:59.771964
I0819 09:10:37.292891 140034352527168 train_slot.py:155] Step: 194900, Loss: 0.001406, Time: 12:52:23.481076
I0819 09:11:00.714141 140034352527168 train_slot.py:155] Step: 195000, Loss: 0.001142, Time: 12:52:46.902340
I0819 09:11:01.074562 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-195000
I0819 09:11:02.143093 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 195000
I0819 09:11:25.666830 140034352527168 train_slot.py:155] Step: 195100, Loss: 0.001090, Time: 12:53:11.854972
I0819 09:11:49.274184 140034352527168 train_slot.py:155] Step: 195200, Loss: 0.001139, Time: 12:53:35.462332
I0819 09:12:12.819896 140034352527168 train_slot.py:155] Step: 195300, Loss: 0.000933, Time: 12:53:59.008140
I0819 09:12:37.016884 140034352527168 train_slot.py:155] Step: 195400, Loss: 0.000990, Time: 12:54:23.205070
I0819 09:13:01.041539 140034352527168 train_slot.py:155] Step: 195500, Loss: 0.001013, Time: 12:54:47.229644
I0819 09:13:24.911774 140034352527168 train_slot.py:155] Step: 195600, Loss: 0.001077, Time: 12:55:11.099949
I0819 09:13:48.862111 140034352527168 train_slot.py:155] Step: 195700, Loss: 0.001413, Time: 12:55:35.050310
I0819 09:14:12.777596 140034352527168 train_slot.py:155] Step: 195800, Loss: 0.001361, Time: 12:55:58.965586
I0819 09:14:36.723260 140034352527168 train_slot.py:155] Step: 195900, Loss: 0.000973, Time: 12:56:22.911457
I0819 09:15:00.215351 140034352527168 train_slot.py:155] Step: 196000, Loss: 0.001145, Time: 12:56:46.403550
I0819 09:15:00.553542 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-196000
I0819 09:15:01.684804 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 196000
I0819 09:15:25.183316 140034352527168 train_slot.py:155] Step: 196100, Loss: 0.000885, Time: 12:57:11.371313
I0819 09:15:48.706648 140034352527168 train_slot.py:155] Step: 196200, Loss: 0.000872, Time: 12:57:34.894854
I0819 09:16:12.125049 140034352527168 train_slot.py:155] Step: 196300, Loss: 0.001211, Time: 12:57:58.313267
I0819 09:16:36.132732 140034352527168 train_slot.py:155] Step: 196400, Loss: 0.001093, Time: 12:58:22.320930
I0819 09:16:59.720656 140034352527168 train_slot.py:155] Step: 196500, Loss: 0.000832, Time: 12:58:45.908784
I0819 09:17:23.203029 140034352527168 train_slot.py:155] Step: 196600, Loss: 0.000926, Time: 12:59:09.391175
I0819 09:17:46.690295 140034352527168 train_slot.py:155] Step: 196700, Loss: 0.000971, Time: 12:59:32.878498
I0819 09:18:10.325330 140034352527168 train_slot.py:155] Step: 196800, Loss: 0.001152, Time: 12:59:56.513530
I0819 09:18:33.866451 140034352527168 train_slot.py:155] Step: 196900, Loss: 0.001135, Time: 13:00:20.054579
I0819 09:18:57.930519 140034352527168 train_slot.py:155] Step: 197000, Loss: 0.001009, Time: 13:00:44.118725
I0819 09:18:58.296411 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-197000
I0819 09:18:59.400871 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 197000
I0819 09:19:22.897787 140034352527168 train_slot.py:155] Step: 197100, Loss: 0.000862, Time: 13:01:09.086005
I0819 09:19:46.415465 140034352527168 train_slot.py:155] Step: 197200, Loss: 0.001054, Time: 13:01:32.603666
I0819 09:20:10.099476 140034352527168 train_slot.py:155] Step: 197300, Loss: 0.001030, Time: 13:01:56.287599
I0819 09:20:33.870716 140034352527168 train_slot.py:155] Step: 197400, Loss: 0.001069, Time: 13:02:20.058880
I0819 09:20:57.815537 140034352527168 train_slot.py:155] Step: 197500, Loss: 0.001029, Time: 13:02:44.003771
I0819 09:21:21.456467 140034352527168 train_slot.py:155] Step: 197600, Loss: 0.001049, Time: 13:03:07.644502
I0819 09:21:44.982734 140034352527168 train_slot.py:155] Step: 197700, Loss: 0.000981, Time: 13:03:31.170929
I0819 09:22:08.595763 140034352527168 train_slot.py:155] Step: 197800, Loss: 0.001338, Time: 13:03:54.783964
I0819 09:22:32.282751 140034352527168 train_slot.py:155] Step: 197900, Loss: 0.001089, Time: 13:04:18.470929
I0819 09:22:55.749967 140034352527168 train_slot.py:155] Step: 198000, Loss: 0.001045, Time: 13:04:41.938130
I0819 09:22:56.111106 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-198000
I0819 09:22:57.247501 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 198000
I0819 09:23:21.032067 140034352527168 train_slot.py:155] Step: 198100, Loss: 0.001357, Time: 13:05:07.220273
I0819 09:23:44.572134 140034352527168 train_slot.py:155] Step: 198200, Loss: 0.001043, Time: 13:05:30.760365
I0819 09:24:08.078752 140034352527168 train_slot.py:155] Step: 198300, Loss: 0.000887, Time: 13:05:54.266764
I0819 09:24:31.578091 140034352527168 train_slot.py:155] Step: 198400, Loss: 0.000933, Time: 13:06:17.766295
I0819 09:24:55.537766 140034352527168 train_slot.py:155] Step: 198500, Loss: 0.001208, Time: 13:06:41.725963
I0819 09:25:19.265756 140034352527168 train_slot.py:155] Step: 198600, Loss: 0.001051, Time: 13:07:05.453952
I0819 09:25:42.773089 140034352527168 train_slot.py:155] Step: 198700, Loss: 0.001135, Time: 13:07:28.961245
I0819 09:26:06.335754 140034352527168 train_slot.py:155] Step: 198800, Loss: 0.001072, Time: 13:07:52.523959
I0819 09:26:29.858836 140034352527168 train_slot.py:155] Step: 198900, Loss: 0.001067, Time: 13:08:16.047068
I0819 09:26:53.393630 140034352527168 train_slot.py:155] Step: 199000, Loss: 0.000996, Time: 13:08:39.581827
I0819 09:26:53.747550 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-199000
I0819 09:26:54.814711 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 199000
I0819 09:27:18.501693 140034352527168 train_slot.py:155] Step: 199100, Loss: 0.001114, Time: 13:09:04.689667
I0819 09:27:42.063198 140034352527168 train_slot.py:155] Step: 199200, Loss: 0.000964, Time: 13:09:28.251398
I0819 09:28:05.612883 140034352527168 train_slot.py:155] Step: 199300, Loss: 0.001144, Time: 13:09:51.801110
I0819 09:28:29.076614 140034352527168 train_slot.py:155] Step: 199400, Loss: 0.001042, Time: 13:10:15.264640
I0819 09:28:52.685707 140034352527168 train_slot.py:155] Step: 199500, Loss: 0.001127, Time: 13:10:38.873890
I0819 09:29:16.211365 140034352527168 train_slot.py:155] Step: 199600, Loss: 0.001045, Time: 13:11:02.399568
I0819 09:29:39.917621 140034352527168 train_slot.py:155] Step: 199700, Loss: 0.001032, Time: 13:11:26.105846
I0819 09:30:03.473425 140034352527168 train_slot.py:155] Step: 199800, Loss: 0.000773, Time: 13:11:49.661478
I0819 09:30:26.977568 140034352527168 train_slot.py:155] Step: 199900, Loss: 0.000931, Time: 13:12:13.165734
I0819 09:30:50.482261 140034352527168 train_slot.py:155] Step: 200000, Loss: 0.001068, Time: 13:12:36.670489
I0819 09:30:50.854861 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-200000
I0819 09:30:51.994102 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 200000
I0819 09:31:15.472589 140034352527168 train_slot.py:155] Step: 200100, Loss: 0.000884, Time: 13:13:01.660787
I0819 09:31:39.215705 140034352527168 train_slot.py:155] Step: 200200, Loss: 0.000915, Time: 13:13:25.403718
I0819 09:32:02.792476 140034352527168 train_slot.py:155] Step: 200300, Loss: 0.001057, Time: 13:13:48.980672
I0819 09:32:26.349918 140034352527168 train_slot.py:155] Step: 200400, Loss: 0.001066, Time: 13:14:12.538147
I0819 09:32:49.807039 140034352527168 train_slot.py:155] Step: 200500, Loss: 0.001069, Time: 13:14:35.994959
I0819 09:33:13.300288 140034352527168 train_slot.py:155] Step: 200600, Loss: 0.000832, Time: 13:14:59.488497
I0819 09:33:36.840445 140034352527168 train_slot.py:155] Step: 200700, Loss: 0.001033, Time: 13:15:23.028651
I0819 09:34:00.623797 140034352527168 train_slot.py:155] Step: 200800, Loss: 0.001244, Time: 13:15:46.812005
I0819 09:34:24.594596 140034352527168 train_slot.py:155] Step: 200900, Loss: 0.000954, Time: 13:16:10.782726
I0819 09:34:48.086498 140034352527168 train_slot.py:155] Step: 201000, Loss: 0.001051, Time: 13:16:34.274678
I0819 09:34:48.459475 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-201000
I0819 09:34:49.590863 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 201000
I0819 09:35:13.156886 140034352527168 train_slot.py:155] Step: 201100, Loss: 0.001088, Time: 13:16:59.345106
I0819 09:35:36.571432 140034352527168 train_slot.py:155] Step: 201200, Loss: 0.001028, Time: 13:17:22.759638
I0819 09:36:00.440221 140034352527168 train_slot.py:155] Step: 201300, Loss: 0.000762, Time: 13:17:46.628430
I0819 09:36:23.908100 140034352527168 train_slot.py:155] Step: 201400, Loss: 0.001009, Time: 13:18:10.096306
I0819 09:36:47.384418 140034352527168 train_slot.py:155] Step: 201500, Loss: 0.000978, Time: 13:18:33.572621
I0819 09:37:10.863236 140034352527168 train_slot.py:155] Step: 201600, Loss: 0.001116, Time: 13:18:57.051105
I0819 09:37:34.349992 140034352527168 train_slot.py:155] Step: 201700, Loss: 0.001014, Time: 13:19:20.538213
I0819 09:37:57.797625 140034352527168 train_slot.py:155] Step: 201800, Loss: 0.001095, Time: 13:19:43.985853
I0819 09:38:21.800278 140034352527168 train_slot.py:155] Step: 201900, Loss: 0.000844, Time: 13:20:07.988477
I0819 09:38:45.858438 140034352527168 train_slot.py:155] Step: 202000, Loss: 0.000939, Time: 13:20:32.046424
I0819 09:38:46.185500 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-202000
I0819 09:38:47.318828 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 202000
I0819 09:39:11.108430 140034352527168 train_slot.py:155] Step: 202100, Loss: 0.000911, Time: 13:20:57.296662
I0819 09:39:34.874565 140034352527168 train_slot.py:155] Step: 202200, Loss: 0.000815, Time: 13:21:21.062796
I0819 09:39:58.658211 140034352527168 train_slot.py:155] Step: 202300, Loss: 0.001042, Time: 13:21:44.846196
I0819 09:40:22.415363 140034352527168 train_slot.py:155] Step: 202400, Loss: 0.000807, Time: 13:22:08.603566
I0819 09:40:45.923499 140034352527168 train_slot.py:155] Step: 202500, Loss: 0.000826, Time: 13:22:32.111699
I0819 09:41:09.518223 140034352527168 train_slot.py:155] Step: 202600, Loss: 0.001169, Time: 13:22:55.706221
I0819 09:41:32.982987 140034352527168 train_slot.py:155] Step: 202700, Loss: 0.001235, Time: 13:23:19.171145
I0819 09:41:56.471720 140034352527168 train_slot.py:155] Step: 202800, Loss: 0.001076, Time: 13:23:42.659962
I0819 09:42:20.185259 140034352527168 train_slot.py:155] Step: 202900, Loss: 0.001190, Time: 13:24:06.373430
I0819 09:42:43.775199 140034352527168 train_slot.py:155] Step: 203000, Loss: 0.000948, Time: 13:24:29.963292
I0819 09:42:44.134778 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-203000
I0819 09:42:45.202777 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 203000
I0819 09:43:08.705221 140034352527168 train_slot.py:155] Step: 203100, Loss: 0.000948, Time: 13:24:54.893430
I0819 09:43:32.304491 140034352527168 train_slot.py:155] Step: 203200, Loss: 0.001372, Time: 13:25:18.492686
I0819 09:43:56.062587 140034352527168 train_slot.py:155] Step: 203300, Loss: 0.001016, Time: 13:25:42.250782
I0819 09:44:19.524664 140034352527168 train_slot.py:155] Step: 203400, Loss: 0.001145, Time: 13:26:05.712660
I0819 09:44:43.283081 140034352527168 train_slot.py:155] Step: 203500, Loss: 0.000890, Time: 13:26:29.471307
I0819 09:45:06.798939 140034352527168 train_slot.py:155] Step: 203600, Loss: 0.001039, Time: 13:26:52.987136
I0819 09:45:30.568771 140034352527168 train_slot.py:155] Step: 203700, Loss: 0.001145, Time: 13:27:16.756900
I0819 09:45:54.094959 140034352527168 train_slot.py:155] Step: 203800, Loss: 0.001110, Time: 13:27:40.283101
I0819 09:46:17.614897 140034352527168 train_slot.py:155] Step: 203900, Loss: 0.000948, Time: 13:28:03.803103
I0819 09:46:41.252711 140034352527168 train_slot.py:155] Step: 204000, Loss: 0.001013, Time: 13:28:27.440908
I0819 09:46:41.617245 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-204000
I0819 09:46:42.758327 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 204000
I0819 09:47:06.235503 140034352527168 train_slot.py:155] Step: 204100, Loss: 0.000930, Time: 13:28:52.423732
I0819 09:47:29.673069 140034352527168 train_slot.py:155] Step: 204200, Loss: 0.001280, Time: 13:29:15.861201
I0819 09:47:53.127551 140034352527168 train_slot.py:155] Step: 204300, Loss: 0.001076, Time: 13:29:39.315749
I0819 09:48:16.571990 140034352527168 train_slot.py:155] Step: 204400, Loss: 0.001008, Time: 13:30:02.760222
I0819 09:48:40.023398 140034352527168 train_slot.py:155] Step: 204500, Loss: 0.001051, Time: 13:30:26.211625
I0819 09:49:03.790750 140034352527168 train_slot.py:155] Step: 204600, Loss: 0.000878, Time: 13:30:49.978952
I0819 09:49:27.323815 140034352527168 train_slot.py:155] Step: 204700, Loss: 0.000802, Time: 13:31:13.511761
I0819 09:49:51.008572 140034352527168 train_slot.py:155] Step: 204800, Loss: 0.000963, Time: 13:31:37.196776
I0819 09:50:14.522556 140034352527168 train_slot.py:155] Step: 204900, Loss: 0.000909, Time: 13:32:00.710752
I0819 09:50:38.044012 140034352527168 train_slot.py:155] Step: 205000, Loss: 0.001014, Time: 13:32:24.232142
I0819 09:50:38.354516 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-205000
I0819 09:50:39.466640 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 205000
I0819 09:51:03.101553 140034352527168 train_slot.py:155] Step: 205100, Loss: 0.001002, Time: 13:32:49.289763
I0819 09:51:26.604645 140034352527168 train_slot.py:155] Step: 205200, Loss: 0.000830, Time: 13:33:12.792860
I0819 09:51:50.157903 140034352527168 train_slot.py:155] Step: 205300, Loss: 0.001054, Time: 13:33:36.345933
I0819 09:52:13.638679 140034352527168 train_slot.py:155] Step: 205400, Loss: 0.000909, Time: 13:33:59.826886
I0819 09:52:37.101202 140034352527168 train_slot.py:155] Step: 205500, Loss: 0.001258, Time: 13:34:23.289425
I0819 09:53:00.726195 140034352527168 train_slot.py:155] Step: 205600, Loss: 0.001004, Time: 13:34:46.914398
I0819 09:53:24.658078 140034352527168 train_slot.py:155] Step: 205700, Loss: 0.001244, Time: 13:35:10.846205
I0819 09:53:48.189900 140034352527168 train_slot.py:155] Step: 205800, Loss: 0.000964, Time: 13:35:34.377911
I0819 09:54:11.749921 140034352527168 train_slot.py:155] Step: 205900, Loss: 0.000939, Time: 13:35:57.938123
I0819 09:54:35.266370 140034352527168 train_slot.py:155] Step: 206000, Loss: 0.000919, Time: 13:36:21.454576
I0819 09:54:35.630842 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-206000
I0819 09:54:36.703780 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 206000
I0819 09:55:00.540194 140034352527168 train_slot.py:155] Step: 206100, Loss: 0.001083, Time: 13:36:46.728212
I0819 09:55:24.531409 140034352527168 train_slot.py:155] Step: 206200, Loss: 0.001143, Time: 13:37:10.719633
I0819 09:55:48.089621 140034352527168 train_slot.py:155] Step: 206300, Loss: 0.001134, Time: 13:37:34.277829
I0819 09:56:11.746593 140034352527168 train_slot.py:155] Step: 206400, Loss: 0.000907, Time: 13:37:57.934805
I0819 09:56:35.281900 140034352527168 train_slot.py:155] Step: 206500, Loss: 0.000881, Time: 13:38:21.470022
I0819 09:56:58.737941 140034352527168 train_slot.py:155] Step: 206600, Loss: 0.000976, Time: 13:38:44.926133
I0819 09:57:22.474577 140034352527168 train_slot.py:155] Step: 206700, Loss: 0.000975, Time: 13:39:08.662784
I0819 09:57:46.062202 140034352527168 train_slot.py:155] Step: 206800, Loss: 0.001093, Time: 13:39:32.250406
I0819 09:58:09.541672 140034352527168 train_slot.py:155] Step: 206900, Loss: 0.001010, Time: 13:39:55.729804
I0819 09:58:33.073643 140034352527168 train_slot.py:155] Step: 207000, Loss: 0.001262, Time: 13:40:19.261808
I0819 09:58:33.440329 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-207000
I0819 09:58:34.508336 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 207000
I0819 09:58:58.032545 140034352527168 train_slot.py:155] Step: 207100, Loss: 0.001045, Time: 13:40:44.220742
I0819 09:59:21.620048 140034352527168 train_slot.py:155] Step: 207200, Loss: 0.001066, Time: 13:41:07.808252
I0819 09:59:45.404445 140034352527168 train_slot.py:155] Step: 207300, Loss: 0.000791, Time: 13:41:31.592575
I0819 10:00:08.959421 140034352527168 train_slot.py:155] Step: 207400, Loss: 0.000849, Time: 13:41:55.147653
I0819 10:00:32.506762 140034352527168 train_slot.py:155] Step: 207500, Loss: 0.000850, Time: 13:42:18.694974
I0819 10:00:56.018454 140034352527168 train_slot.py:155] Step: 207600, Loss: 0.000907, Time: 13:42:42.206582
I0819 10:01:19.631011 140034352527168 train_slot.py:155] Step: 207700, Loss: 0.000922, Time: 13:43:05.819161
I0819 10:01:43.857952 140034352527168 train_slot.py:155] Step: 207800, Loss: 0.000883, Time: 13:43:30.046149
I0819 10:02:07.394391 140034352527168 train_slot.py:155] Step: 207900, Loss: 0.001162, Time: 13:43:53.582621
I0819 10:02:30.906257 140034352527168 train_slot.py:155] Step: 208000, Loss: 0.001163, Time: 13:44:17.094247
I0819 10:02:31.265722 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-208000
I0819 10:02:32.338940 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 208000
I0819 10:02:55.861860 140034352527168 train_slot.py:155] Step: 208100, Loss: 0.000926, Time: 13:44:42.050069
I0819 10:03:19.344378 140034352527168 train_slot.py:155] Step: 208200, Loss: 0.000880, Time: 13:45:05.532578
I0819 10:03:42.803892 140034352527168 train_slot.py:155] Step: 208300, Loss: 0.001169, Time: 13:45:28.991841
I0819 10:04:06.437121 140034352527168 train_slot.py:155] Step: 208400, Loss: 0.000968, Time: 13:45:52.625238
I0819 10:04:29.960073 140034352527168 train_slot.py:155] Step: 208500, Loss: 0.001053, Time: 13:46:16.148288
I0819 10:04:53.494184 140034352527168 train_slot.py:155] Step: 208600, Loss: 0.001053, Time: 13:46:39.682382
I0819 10:05:17.043206 140034352527168 train_slot.py:155] Step: 208700, Loss: 0.000985, Time: 13:47:03.231240
I0819 10:05:40.725416 140034352527168 train_slot.py:155] Step: 208800, Loss: 0.001236, Time: 13:47:26.913601
I0819 10:06:04.401053 140034352527168 train_slot.py:155] Step: 208900, Loss: 0.001043, Time: 13:47:50.589257
I0819 10:06:28.103610 140034352527168 train_slot.py:155] Step: 209000, Loss: 0.001057, Time: 13:48:14.291834
I0819 10:06:28.482474 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-209000
I0819 10:06:29.587756 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 209000
I0819 10:06:53.154304 140034352527168 train_slot.py:155] Step: 209100, Loss: 0.000968, Time: 13:48:39.341872
I0819 10:07:16.636759 140034352527168 train_slot.py:155] Step: 209200, Loss: 0.000865, Time: 13:49:02.824962
I0819 10:07:40.161809 140034352527168 train_slot.py:155] Step: 209300, Loss: 0.001054, Time: 13:49:26.350009
I0819 10:08:03.621012 140034352527168 train_slot.py:155] Step: 209400, Loss: 0.000886, Time: 13:49:49.809032
I0819 10:08:27.790845 140034352527168 train_slot.py:155] Step: 209500, Loss: 0.001118, Time: 13:50:13.979021
I0819 10:08:51.564781 140034352527168 train_slot.py:155] Step: 209600, Loss: 0.001156, Time: 13:50:37.752983
I0819 10:09:15.303430 140034352527168 train_slot.py:155] Step: 209700, Loss: 0.001062, Time: 13:51:01.491630
I0819 10:09:39.143914 140034352527168 train_slot.py:155] Step: 209800, Loss: 0.000839, Time: 13:51:25.332140
I0819 10:10:02.985964 140034352527168 train_slot.py:155] Step: 209900, Loss: 0.001129, Time: 13:51:49.173958
I0819 10:10:26.915502 140034352527168 train_slot.py:155] Step: 210000, Loss: 0.000801, Time: 13:52:13.103725
I0819 10:10:27.247681 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-210000
I0819 10:10:28.382680 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 210000
I0819 10:10:51.913211 140034352527168 train_slot.py:155] Step: 210100, Loss: 0.000956, Time: 13:52:38.101440
I0819 10:11:15.530217 140034352527168 train_slot.py:155] Step: 210200, Loss: 0.000950, Time: 13:53:01.718421
I0819 10:11:39.054653 140034352527168 train_slot.py:155] Step: 210300, Loss: 0.000955, Time: 13:53:25.242812
I0819 10:12:02.481867 140034352527168 train_slot.py:155] Step: 210400, Loss: 0.000987, Time: 13:53:48.670065
I0819 10:12:26.192119 140034352527168 train_slot.py:155] Step: 210500, Loss: 0.000920, Time: 13:54:12.380346
I0819 10:12:50.305913 140034352527168 train_slot.py:155] Step: 210600, Loss: 0.001253, Time: 13:54:36.494126
I0819 10:13:13.794604 140034352527168 train_slot.py:155] Step: 210700, Loss: 0.000974, Time: 13:54:59.982738
I0819 10:13:37.273699 140034352527168 train_slot.py:155] Step: 210800, Loss: 0.000986, Time: 13:55:23.461900
I0819 10:14:00.819218 140034352527168 train_slot.py:155] Step: 210900, Loss: 0.000955, Time: 13:55:47.007390
I0819 10:14:24.319768 140034352527168 train_slot.py:155] Step: 211000, Loss: 0.001058, Time: 13:56:10.508001
I0819 10:14:24.662927 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-211000
I0819 10:14:25.803112 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 211000
I0819 10:14:49.552953 140034352527168 train_slot.py:155] Step: 211100, Loss: 0.001156, Time: 13:56:35.741163
I0819 10:15:13.257582 140034352527168 train_slot.py:155] Step: 211200, Loss: 0.001114, Time: 13:56:59.445744
I0819 10:15:36.840594 140034352527168 train_slot.py:155] Step: 211300, Loss: 0.000854, Time: 13:57:23.028815
I0819 10:16:00.338130 140034352527168 train_slot.py:155] Step: 211400, Loss: 0.000941, Time: 13:57:46.526331
I0819 10:16:23.865646 140034352527168 train_slot.py:155] Step: 211500, Loss: 0.001098, Time: 13:58:10.053847
I0819 10:16:47.595567 140034352527168 train_slot.py:155] Step: 211600, Loss: 0.001021, Time: 13:58:33.783500
I0819 10:17:11.115226 140034352527168 train_slot.py:155] Step: 211700, Loss: 0.001004, Time: 13:58:57.303423
I0819 10:17:34.715878 140034352527168 train_slot.py:155] Step: 211800, Loss: 0.001068, Time: 13:59:20.904074
I0819 10:17:58.234131 140034352527168 train_slot.py:155] Step: 211900, Loss: 0.000850, Time: 13:59:44.422240
I0819 10:18:21.767057 140034352527168 train_slot.py:155] Step: 212000, Loss: 0.000848, Time: 14:00:07.955234
I0819 10:18:22.096015 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-212000
I0819 10:18:23.248341 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 212000
I0819 10:18:46.683151 140034352527168 train_slot.py:155] Step: 212100, Loss: 0.000864, Time: 14:00:32.871351
I0819 10:19:10.360645 140034352527168 train_slot.py:155] Step: 212200, Loss: 0.001087, Time: 14:00:56.548876
I0819 10:19:33.819378 140034352527168 train_slot.py:155] Step: 212300, Loss: 0.000968, Time: 14:01:20.007380
I0819 10:19:57.377932 140034352527168 train_slot.py:155] Step: 212400, Loss: 0.000927, Time: 14:01:43.566170
I0819 10:20:20.895974 140034352527168 train_slot.py:155] Step: 212500, Loss: 0.000976, Time: 14:02:07.084205
I0819 10:20:44.424616 140034352527168 train_slot.py:155] Step: 212600, Loss: 0.000761, Time: 14:02:30.612679
I0819 10:21:08.155155 140034352527168 train_slot.py:155] Step: 212700, Loss: 0.000915, Time: 14:02:54.343213
I0819 10:21:31.699989 140034352527168 train_slot.py:155] Step: 212800, Loss: 0.001075, Time: 14:03:17.888125
I0819 10:21:55.160034 140034352527168 train_slot.py:155] Step: 212900, Loss: 0.000732, Time: 14:03:41.348243
I0819 10:22:18.722401 140034352527168 train_slot.py:155] Step: 213000, Loss: 0.001156, Time: 14:04:04.910100
I0819 10:22:19.107465 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-213000
I0819 10:22:20.211897 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 213000
I0819 10:22:43.732167 140034352527168 train_slot.py:155] Step: 213100, Loss: 0.001058, Time: 14:04:29.920265
I0819 10:23:07.221385 140034352527168 train_slot.py:155] Step: 213200, Loss: 0.001017, Time: 14:04:53.409585
I0819 10:23:31.171651 140034352527168 train_slot.py:155] Step: 213300, Loss: 0.000965, Time: 14:05:17.359831
I0819 10:23:55.350418 140034352527168 train_slot.py:155] Step: 213400, Loss: 0.000924, Time: 14:05:41.538617
I0819 10:24:18.904917 140034352527168 train_slot.py:155] Step: 213500, Loss: 0.000897, Time: 14:06:05.093110
I0819 10:24:42.795587 140034352527168 train_slot.py:155] Step: 213600, Loss: 0.000820, Time: 14:06:28.983663
I0819 10:25:06.569906 140034352527168 train_slot.py:155] Step: 213700, Loss: 0.001124, Time: 14:06:52.758106
I0819 10:25:30.540909 140034352527168 train_slot.py:155] Step: 213800, Loss: 0.000727, Time: 14:07:16.729139
I0819 10:25:54.272870 140034352527168 train_slot.py:155] Step: 213900, Loss: 0.001019, Time: 14:07:40.460972
I0819 10:26:18.050063 140034352527168 train_slot.py:155] Step: 214000, Loss: 0.001213, Time: 14:08:04.238233
I0819 10:26:18.390908 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-214000
I0819 10:26:19.460998 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 214000
I0819 10:26:43.303155 140034352527168 train_slot.py:155] Step: 214100, Loss: 0.000969, Time: 14:08:29.491384
I0819 10:27:07.113889 140034352527168 train_slot.py:155] Step: 214200, Loss: 0.000968, Time: 14:08:53.302089
I0819 10:27:31.107837 140034352527168 train_slot.py:155] Step: 214300, Loss: 0.001116, Time: 14:09:17.295876
I0819 10:27:54.621812 140034352527168 train_slot.py:155] Step: 214400, Loss: 0.001005, Time: 14:09:40.810039
I0819 10:28:18.190339 140034352527168 train_slot.py:155] Step: 214500, Loss: 0.000911, Time: 14:10:04.378565
I0819 10:28:42.027018 140034352527168 train_slot.py:155] Step: 214600, Loss: 0.001046, Time: 14:10:28.215245
I0819 10:29:05.581145 140034352527168 train_slot.py:155] Step: 214700, Loss: 0.000909, Time: 14:10:51.769305
I0819 10:29:29.301461 140034352527168 train_slot.py:155] Step: 214800, Loss: 0.000935, Time: 14:11:15.489601
I0819 10:29:53.114378 140034352527168 train_slot.py:155] Step: 214900, Loss: 0.000930, Time: 14:11:39.302607
I0819 10:30:16.834786 140034352527168 train_slot.py:155] Step: 215000, Loss: 0.001048, Time: 14:12:03.022987
I0819 10:30:17.246529 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-215000
I0819 10:30:18.386614 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 215000
I0819 10:30:42.012034 140034352527168 train_slot.py:155] Step: 215100, Loss: 0.001242, Time: 14:12:28.200183
I0819 10:31:05.532039 140034352527168 train_slot.py:155] Step: 215200, Loss: 0.000860, Time: 14:12:51.720235
I0819 10:31:28.922098 140034352527168 train_slot.py:155] Step: 215300, Loss: 0.001215, Time: 14:13:15.110300
I0819 10:31:52.622694 140034352527168 train_slot.py:155] Step: 215400, Loss: 0.000975, Time: 14:13:38.810927
I0819 10:32:16.283481 140034352527168 train_slot.py:155] Step: 215500, Loss: 0.000953, Time: 14:14:02.471601
I0819 10:32:39.940219 140034352527168 train_slot.py:155] Step: 215600, Loss: 0.001214, Time: 14:14:26.128450
I0819 10:33:03.769357 140034352527168 train_slot.py:155] Step: 215700, Loss: 0.000864, Time: 14:14:49.957548
I0819 10:33:27.462093 140034352527168 train_slot.py:155] Step: 215800, Loss: 0.001222, Time: 14:15:13.650294
I0819 10:33:51.450476 140034352527168 train_slot.py:155] Step: 215900, Loss: 0.001166, Time: 14:15:37.638522
I0819 10:34:15.431451 140034352527168 train_slot.py:155] Step: 216000, Loss: 0.000887, Time: 14:16:01.619641
I0819 10:34:15.801566 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-216000
I0819 10:34:16.942022 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 216000
I0819 10:34:40.938289 140034352527168 train_slot.py:155] Step: 216100, Loss: 0.001012, Time: 14:16:27.126490
I0819 10:35:04.705145 140034352527168 train_slot.py:155] Step: 216200, Loss: 0.001158, Time: 14:16:50.893362
I0819 10:35:28.471013 140034352527168 train_slot.py:155] Step: 216300, Loss: 0.001185, Time: 14:17:14.658998
I0819 10:35:52.204318 140034352527168 train_slot.py:155] Step: 216400, Loss: 0.000820, Time: 14:17:38.392518
I0819 10:36:16.201744 140034352527168 train_slot.py:155] Step: 216500, Loss: 0.000969, Time: 14:18:02.389955
I0819 10:36:39.683912 140034352527168 train_slot.py:155] Step: 216600, Loss: 0.000829, Time: 14:18:25.871999
I0819 10:37:03.236943 140034352527168 train_slot.py:155] Step: 216700, Loss: 0.001021, Time: 14:18:49.425103
I0819 10:37:26.698006 140034352527168 train_slot.py:155] Step: 216800, Loss: 0.001170, Time: 14:19:12.886233
I0819 10:37:50.213349 140034352527168 train_slot.py:155] Step: 216900, Loss: 0.000998, Time: 14:19:36.401385
I0819 10:38:13.935136 140034352527168 train_slot.py:155] Step: 217000, Loss: 0.000926, Time: 14:20:00.123291
I0819 10:38:14.307687 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-217000
I0819 10:38:15.389188 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 217000
I0819 10:38:38.981744 140034352527168 train_slot.py:155] Step: 217100, Loss: 0.000721, Time: 14:20:25.169970
I0819 10:39:02.529493 140034352527168 train_slot.py:155] Step: 217200, Loss: 0.001138, Time: 14:20:48.717722
I0819 10:39:26.086486 140034352527168 train_slot.py:155] Step: 217300, Loss: 0.001171, Time: 14:21:12.274647
I0819 10:39:49.897680 140034352527168 train_slot.py:155] Step: 217400, Loss: 0.001047, Time: 14:21:36.085880
I0819 10:40:13.523869 140034352527168 train_slot.py:155] Step: 217500, Loss: 0.000860, Time: 14:21:59.712067
I0819 10:40:37.124351 140034352527168 train_slot.py:155] Step: 217600, Loss: 0.001041, Time: 14:22:23.312462
I0819 10:41:00.622554 140034352527168 train_slot.py:155] Step: 217700, Loss: 0.000836, Time: 14:22:46.810768
I0819 10:41:24.113925 140034352527168 train_slot.py:155] Step: 217800, Loss: 0.001042, Time: 14:23:10.302120
I0819 10:41:47.694159 140034352527168 train_slot.py:155] Step: 217900, Loss: 0.000925, Time: 14:23:33.882389
I0819 10:42:11.174411 140034352527168 train_slot.py:155] Step: 218000, Loss: 0.000932, Time: 14:23:57.362567
I0819 10:42:11.517005 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-218000
I0819 10:42:12.601639 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 218000
I0819 10:42:36.389513 140034352527168 train_slot.py:155] Step: 218100, Loss: 0.000903, Time: 14:24:22.577702
I0819 10:42:59.930345 140034352527168 train_slot.py:155] Step: 218200, Loss: 0.001019, Time: 14:24:46.118546
I0819 10:43:23.804344 140034352527168 train_slot.py:155] Step: 218300, Loss: 0.000782, Time: 14:25:09.992473
I0819 10:43:47.328624 140034352527168 train_slot.py:155] Step: 218400, Loss: 0.000920, Time: 14:25:33.516624
I0819 10:44:10.900557 140034352527168 train_slot.py:155] Step: 218500, Loss: 0.000966, Time: 14:25:57.088762
I0819 10:44:34.363632 140034352527168 train_slot.py:155] Step: 218600, Loss: 0.001071, Time: 14:26:20.551832
I0819 10:44:58.288412 140034352527168 train_slot.py:155] Step: 218700, Loss: 0.001012, Time: 14:26:44.476612
I0819 10:45:21.879357 140034352527168 train_slot.py:155] Step: 218800, Loss: 0.000867, Time: 14:27:08.067419
I0819 10:45:45.479905 140034352527168 train_slot.py:155] Step: 218900, Loss: 0.000958, Time: 14:27:31.668078
I0819 10:46:09.030777 140034352527168 train_slot.py:155] Step: 219000, Loss: 0.001233, Time: 14:27:55.218977
I0819 10:46:09.433996 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-219000
I0819 10:46:10.517197 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 219000
I0819 10:46:34.059261 140034352527168 train_slot.py:155] Step: 219100, Loss: 0.000908, Time: 14:28:20.247458
I0819 10:46:57.688035 140034352527168 train_slot.py:155] Step: 219200, Loss: 0.001067, Time: 14:28:43.876178
I0819 10:47:21.163200 140034352527168 train_slot.py:155] Step: 219300, Loss: 0.000932, Time: 14:29:07.351308
I0819 10:47:44.620795 140034352527168 train_slot.py:155] Step: 219400, Loss: 0.000940, Time: 14:29:30.809001
I0819 10:48:08.173424 140034352527168 train_slot.py:155] Step: 219500, Loss: 0.000994, Time: 14:29:54.361625
I0819 10:48:31.675253 140034352527168 train_slot.py:155] Step: 219600, Loss: 0.000992, Time: 14:30:17.863256
I0819 10:48:55.206647 140034352527168 train_slot.py:155] Step: 219700, Loss: 0.001109, Time: 14:30:41.394849
I0819 10:49:19.038087 140034352527168 train_slot.py:155] Step: 219800, Loss: 0.000801, Time: 14:31:05.226282
I0819 10:49:42.625144 140034352527168 train_slot.py:155] Step: 219900, Loss: 0.000893, Time: 14:31:28.813348
I0819 10:50:06.165981 140034352527168 train_slot.py:155] Step: 220000, Loss: 0.001022, Time: 14:31:52.354204
I0819 10:50:06.512811 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-220000
I0819 10:50:07.699438 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 220000
I0819 10:50:31.252504 140034352527168 train_slot.py:155] Step: 220100, Loss: 0.000925, Time: 14:32:17.440587
I0819 10:50:54.821079 140034352527168 train_slot.py:155] Step: 220200, Loss: 0.001058, Time: 14:32:41.009284
I0819 10:51:18.478136 140034352527168 train_slot.py:155] Step: 220300, Loss: 0.000945, Time: 14:33:04.666347
I0819 10:51:42.039333 140034352527168 train_slot.py:155] Step: 220400, Loss: 0.001131, Time: 14:33:28.227545
I0819 10:52:06.053612 140034352527168 train_slot.py:155] Step: 220500, Loss: 0.001143, Time: 14:33:52.241573
I0819 10:52:29.706618 140034352527168 train_slot.py:155] Step: 220600, Loss: 0.001172, Time: 14:34:15.894846
I0819 10:52:53.423818 140034352527168 train_slot.py:155] Step: 220700, Loss: 0.000884, Time: 14:34:39.612038
I0819 10:53:17.150434 140034352527168 train_slot.py:155] Step: 220800, Loss: 0.000908, Time: 14:35:03.338425
I0819 10:53:40.588916 140034352527168 train_slot.py:155] Step: 220900, Loss: 0.000989, Time: 14:35:26.777111
I0819 10:54:04.350073 140034352527168 train_slot.py:155] Step: 221000, Loss: 0.001132, Time: 14:35:50.538281
I0819 10:54:04.729842 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-221000
I0819 10:54:05.840862 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 221000
I0819 10:54:29.764389 140034352527168 train_slot.py:155] Step: 221100, Loss: 0.001100, Time: 14:36:15.952589
I0819 10:54:53.258036 140034352527168 train_slot.py:155] Step: 221200, Loss: 0.000965, Time: 14:36:39.446164
I0819 10:55:16.772494 140034352527168 train_slot.py:155] Step: 221300, Loss: 0.000977, Time: 14:37:02.960693
I0819 10:55:40.502744 140034352527168 train_slot.py:155] Step: 221400, Loss: 0.001000, Time: 14:37:26.690944
I0819 10:56:04.066000 140034352527168 train_slot.py:155] Step: 221500, Loss: 0.000902, Time: 14:37:50.254203
I0819 10:56:27.625221 140034352527168 train_slot.py:155] Step: 221600, Loss: 0.001190, Time: 14:38:13.813331
I0819 10:56:51.152904 140034352527168 train_slot.py:155] Step: 221700, Loss: 0.000993, Time: 14:38:37.341087
I0819 10:57:14.565220 140034352527168 train_slot.py:155] Step: 221800, Loss: 0.000868, Time: 14:39:00.753455
I0819 10:57:38.181496 140034352527168 train_slot.py:155] Step: 221900, Loss: 0.001165, Time: 14:39:24.369700
I0819 10:58:01.632217 140034352527168 train_slot.py:155] Step: 222000, Loss: 0.000840, Time: 14:39:47.820419
I0819 10:58:01.999588 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-222000
I0819 10:58:03.128328 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 222000
I0819 10:58:26.897897 140034352527168 train_slot.py:155] Step: 222100, Loss: 0.000955, Time: 14:40:13.086028
I0819 10:58:50.412238 140034352527168 train_slot.py:155] Step: 222200, Loss: 0.001014, Time: 14:40:36.600467
I0819 10:59:14.136831 140034352527168 train_slot.py:155] Step: 222300, Loss: 0.001166, Time: 14:41:00.325031
I0819 10:59:37.756629 140034352527168 train_slot.py:155] Step: 222400, Loss: 0.000970, Time: 14:41:23.944834
I0819 11:00:01.438570 140034352527168 train_slot.py:155] Step: 222500, Loss: 0.000842, Time: 14:41:47.626564
I0819 11:00:24.986573 140034352527168 train_slot.py:155] Step: 222600, Loss: 0.001097, Time: 14:42:11.174808
I0819 11:00:48.460083 140034352527168 train_slot.py:155] Step: 222700, Loss: 0.000789, Time: 14:42:34.648265
I0819 11:01:12.234311 140034352527168 train_slot.py:155] Step: 222800, Loss: 0.001542, Time: 14:42:58.422550
I0819 11:01:35.550059 140034352527168 train_slot.py:155] Step: 222900, Loss: 0.000806, Time: 14:43:21.738260
I0819 11:01:59.302287 140034352527168 train_slot.py:155] Step: 223000, Loss: 0.000960, Time: 14:43:45.490485
I0819 11:01:59.672510 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-223000
I0819 11:02:00.823886 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 223000
I0819 11:02:24.383333 140034352527168 train_slot.py:155] Step: 223100, Loss: 0.001051, Time: 14:44:10.571389
I0819 11:02:47.929330 140034352527168 train_slot.py:155] Step: 223200, Loss: 0.001065, Time: 14:44:34.117552
I0819 11:03:11.455794 140034352527168 train_slot.py:155] Step: 223300, Loss: 0.000758, Time: 14:44:57.644025
I0819 11:03:35.134879 140034352527168 train_slot.py:155] Step: 223400, Loss: 0.000775, Time: 14:45:21.322999
I0819 11:03:58.682063 140034352527168 train_slot.py:155] Step: 223500, Loss: 0.001257, Time: 14:45:44.870188
I0819 11:04:22.326352 140034352527168 train_slot.py:155] Step: 223600, Loss: 0.001059, Time: 14:46:08.514553
I0819 11:04:45.985404 140034352527168 train_slot.py:155] Step: 223700, Loss: 0.000785, Time: 14:46:32.173602
I0819 11:05:09.457775 140034352527168 train_slot.py:155] Step: 223800, Loss: 0.000966, Time: 14:46:55.645897
I0819 11:05:33.050962 140034352527168 train_slot.py:155] Step: 223900, Loss: 0.000985, Time: 14:47:19.239193
I0819 11:05:56.514472 140034352527168 train_slot.py:155] Step: 224000, Loss: 0.001099, Time: 14:47:42.702707
I0819 11:05:56.897866 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-224000
I0819 11:05:58.026867 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 224000
I0819 11:06:21.767018 140034352527168 train_slot.py:155] Step: 224100, Loss: 0.000834, Time: 14:48:07.955163
I0819 11:06:45.287561 140034352527168 train_slot.py:155] Step: 224200, Loss: 0.001238, Time: 14:48:31.475577
I0819 11:07:08.845672 140034352527168 train_slot.py:155] Step: 224300, Loss: 0.000888, Time: 14:48:55.033732
I0819 11:07:32.654410 140034352527168 train_slot.py:155] Step: 224400, Loss: 0.000808, Time: 14:49:18.842606
I0819 11:07:56.193344 140034352527168 train_slot.py:155] Step: 224500, Loss: 0.001247, Time: 14:49:42.381546
I0819 11:08:19.941323 140034352527168 train_slot.py:155] Step: 224600, Loss: 0.000972, Time: 14:50:06.129434
I0819 11:08:43.560168 140034352527168 train_slot.py:155] Step: 224700, Loss: 0.001093, Time: 14:50:29.748375
I0819 11:09:07.051300 140034352527168 train_slot.py:155] Step: 224800, Loss: 0.000965, Time: 14:50:53.239500
I0819 11:09:30.529311 140034352527168 train_slot.py:155] Step: 224900, Loss: 0.000984, Time: 14:51:16.717469
I0819 11:09:53.985182 140034352527168 train_slot.py:155] Step: 225000, Loss: 0.000810, Time: 14:51:40.173370
I0819 11:09:54.333832 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-225000
I0819 11:09:55.440028 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 225000
I0819 11:10:18.942119 140034352527168 train_slot.py:155] Step: 225100, Loss: 0.001105, Time: 14:52:05.130350
I0819 11:10:42.652685 140034352527168 train_slot.py:155] Step: 225200, Loss: 0.000947, Time: 14:52:28.840887
I0819 11:11:06.158455 140034352527168 train_slot.py:155] Step: 225300, Loss: 0.000892, Time: 14:52:52.346658
I0819 11:11:29.719617 140034352527168 train_slot.py:155] Step: 225400, Loss: 0.000968, Time: 14:53:15.907607
I0819 11:11:53.500557 140034352527168 train_slot.py:155] Step: 225500, Loss: 0.000838, Time: 14:53:39.688763
I0819 11:12:17.233081 140034352527168 train_slot.py:155] Step: 225600, Loss: 0.001057, Time: 14:54:03.421280
I0819 11:12:40.910354 140034352527168 train_slot.py:155] Step: 225700, Loss: 0.001075, Time: 14:54:27.098565
I0819 11:13:04.697225 140034352527168 train_slot.py:155] Step: 225800, Loss: 0.001085, Time: 14:54:50.885192
I0819 11:13:28.531982 140034352527168 train_slot.py:155] Step: 225900, Loss: 0.001051, Time: 14:55:14.720140
I0819 11:13:52.076361 140034352527168 train_slot.py:155] Step: 226000, Loss: 0.000936, Time: 14:55:38.264565
I0819 11:13:52.455941 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-226000
I0819 11:13:53.589535 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 226000
I0819 11:14:17.218904 140034352527168 train_slot.py:155] Step: 226100, Loss: 0.000983, Time: 14:56:03.407132
I0819 11:14:40.822168 140034352527168 train_slot.py:155] Step: 226200, Loss: 0.000896, Time: 14:56:27.010400
I0819 11:15:04.570108 140034352527168 train_slot.py:155] Step: 226300, Loss: 0.000804, Time: 14:56:50.758214
I0819 11:15:28.064530 140034352527168 train_slot.py:155] Step: 226400, Loss: 0.000954, Time: 14:57:14.252751
I0819 11:15:51.563353 140034352527168 train_slot.py:155] Step: 226500, Loss: 0.000764, Time: 14:57:37.751510
I0819 11:16:15.085550 140034352527168 train_slot.py:155] Step: 226600, Loss: 0.000843, Time: 14:58:01.273760
I0819 11:16:38.509119 140034352527168 train_slot.py:155] Step: 226700, Loss: 0.001028, Time: 14:58:24.697320
I0819 11:17:02.227665 140034352527168 train_slot.py:155] Step: 226800, Loss: 0.000896, Time: 14:58:48.415791
I0819 11:17:25.676372 140034352527168 train_slot.py:155] Step: 226900, Loss: 0.001017, Time: 14:59:11.864576
I0819 11:17:49.706142 140034352527168 train_slot.py:155] Step: 227000, Loss: 0.000974, Time: 14:59:35.893744
I0819 11:17:50.046102 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-227000
I0819 11:17:51.119636 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 227000
I0819 11:18:14.633472 140034352527168 train_slot.py:155] Step: 227100, Loss: 0.000903, Time: 15:00:00.821671
I0819 11:18:38.063057 140034352527168 train_slot.py:155] Step: 227200, Loss: 0.000858, Time: 15:00:24.251254
I0819 11:19:01.553093 140034352527168 train_slot.py:155] Step: 227300, Loss: 0.000848, Time: 15:00:47.741291
I0819 11:19:25.220375 140034352527168 train_slot.py:155] Step: 227400, Loss: 0.000935, Time: 15:01:11.408592
I0819 11:19:48.686978 140034352527168 train_slot.py:155] Step: 227500, Loss: 0.001045, Time: 15:01:34.875090
I0819 11:20:12.202326 140034352527168 train_slot.py:155] Step: 227600, Loss: 0.000835, Time: 15:01:58.390535
I0819 11:20:35.642857 140034352527168 train_slot.py:155] Step: 227700, Loss: 0.001074, Time: 15:02:21.831057
I0819 11:20:59.335266 140034352527168 train_slot.py:155] Step: 227800, Loss: 0.001031, Time: 15:02:45.523463
I0819 11:21:23.014694 140034352527168 train_slot.py:155] Step: 227900, Loss: 0.000936, Time: 15:03:09.202902
I0819 11:21:46.476574 140034352527168 train_slot.py:155] Step: 228000, Loss: 0.000864, Time: 15:03:32.664215
I0819 11:21:46.848507 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-228000
I0819 11:21:47.981901 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 228000
I0819 11:22:11.716467 140034352527168 train_slot.py:155] Step: 228100, Loss: 0.000954, Time: 15:03:57.904668
I0819 11:22:35.264596 140034352527168 train_slot.py:155] Step: 228200, Loss: 0.001001, Time: 15:04:21.452796
I0819 11:22:58.726102 140034352527168 train_slot.py:155] Step: 228300, Loss: 0.000983, Time: 15:04:44.914311
I0819 11:23:22.412176 140034352527168 train_slot.py:155] Step: 228400, Loss: 0.001043, Time: 15:05:08.600378
I0819 11:23:45.927389 140034352527168 train_slot.py:155] Step: 228500, Loss: 0.001041, Time: 15:05:32.115405
I0819 11:24:09.478825 140034352527168 train_slot.py:155] Step: 228600, Loss: 0.000955, Time: 15:05:55.667035
I0819 11:24:33.016766 140034352527168 train_slot.py:155] Step: 228700, Loss: 0.001036, Time: 15:06:19.204971
I0819 11:24:56.563800 140034352527168 train_slot.py:155] Step: 228800, Loss: 0.000741, Time: 15:06:42.751784
I0819 11:25:20.082957 140034352527168 train_slot.py:155] Step: 228900, Loss: 0.000927, Time: 15:07:06.271191
I0819 11:25:43.745763 140034352527168 train_slot.py:155] Step: 229000, Loss: 0.001229, Time: 15:07:29.933960
I0819 11:25:44.082211 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-229000
I0819 11:25:45.215458 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 229000
I0819 11:26:08.720347 140034352527168 train_slot.py:155] Step: 229100, Loss: 0.001151, Time: 15:07:54.908347
I0819 11:26:32.213290 140034352527168 train_slot.py:155] Step: 229200, Loss: 0.000734, Time: 15:08:18.401490
I0819 11:26:55.695160 140034352527168 train_slot.py:155] Step: 229300, Loss: 0.000883, Time: 15:08:41.883345
I0819 11:27:19.247019 140034352527168 train_slot.py:155] Step: 229400, Loss: 0.001002, Time: 15:09:05.435245
I0819 11:27:42.927840 140034352527168 train_slot.py:155] Step: 229500, Loss: 0.000924, Time: 15:09:29.116045
I0819 11:28:06.390901 140034352527168 train_slot.py:155] Step: 229600, Loss: 0.000931, Time: 15:09:52.578905
I0819 11:28:29.952760 140034352527168 train_slot.py:155] Step: 229700, Loss: 0.000887, Time: 15:10:16.140929
I0819 11:28:53.479873 140034352527168 train_slot.py:155] Step: 229800, Loss: 0.000996, Time: 15:10:39.668077
I0819 11:29:17.045874 140034352527168 train_slot.py:155] Step: 229900, Loss: 0.000981, Time: 15:11:03.234064
I0819 11:29:40.474438 140034352527168 train_slot.py:155] Step: 230000, Loss: 0.000702, Time: 15:11:26.662466
I0819 11:29:40.843129 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-230000
I0819 11:29:41.911595 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 230000
I0819 11:30:05.671772 140034352527168 train_slot.py:155] Step: 230100, Loss: 0.001105, Time: 15:11:51.859975
I0819 11:30:29.145990 140034352527168 train_slot.py:155] Step: 230200, Loss: 0.001247, Time: 15:12:15.334189
I0819 11:30:52.748755 140034352527168 train_slot.py:155] Step: 230300, Loss: 0.000960, Time: 15:12:38.936766
I0819 11:31:16.184114 140034352527168 train_slot.py:155] Step: 230400, Loss: 0.000984, Time: 15:13:02.372325
I0819 11:31:39.801802 140034352527168 train_slot.py:155] Step: 230500, Loss: 0.000826, Time: 15:13:25.990005
I0819 11:32:03.592186 140034352527168 train_slot.py:155] Step: 230600, Loss: 0.001016, Time: 15:13:49.780384
I0819 11:32:27.139083 140034352527168 train_slot.py:155] Step: 230700, Loss: 0.000986, Time: 15:14:13.327289
I0819 11:32:51.018903 140034352527168 train_slot.py:155] Step: 230800, Loss: 0.001071, Time: 15:14:37.207110
I0819 11:33:14.796154 140034352527168 train_slot.py:155] Step: 230900, Loss: 0.001074, Time: 15:15:00.984367
I0819 11:33:38.585836 140034352527168 train_slot.py:155] Step: 231000, Loss: 0.000980, Time: 15:15:24.773939
I0819 11:33:38.951102 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-231000
I0819 11:33:40.070173 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 231000
I0819 11:34:03.899389 140034352527168 train_slot.py:155] Step: 231100, Loss: 0.000710, Time: 15:15:50.087566
I0819 11:34:27.667723 140034352527168 train_slot.py:155] Step: 231200, Loss: 0.000811, Time: 15:16:13.855922
I0819 11:34:51.241039 140034352527168 train_slot.py:155] Step: 231300, Loss: 0.001063, Time: 15:16:37.429169
I0819 11:35:14.855125 140034352527168 train_slot.py:155] Step: 231400, Loss: 0.000833, Time: 15:17:01.043292
I0819 11:35:38.381118 140034352527168 train_slot.py:155] Step: 231500, Loss: 0.000970, Time: 15:17:24.569328
I0819 11:36:01.878443 140034352527168 train_slot.py:155] Step: 231600, Loss: 0.000932, Time: 15:17:48.066593
I0819 11:36:25.786768 140034352527168 train_slot.py:155] Step: 231700, Loss: 0.000921, Time: 15:18:11.974964
I0819 11:36:49.387331 140034352527168 train_slot.py:155] Step: 231800, Loss: 0.000879, Time: 15:18:35.575547
I0819 11:37:12.893170 140034352527168 train_slot.py:155] Step: 231900, Loss: 0.000976, Time: 15:18:59.081404
I0819 11:37:36.429500 140034352527168 train_slot.py:155] Step: 232000, Loss: 0.000918, Time: 15:19:22.617613
I0819 11:37:36.812669 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-232000
I0819 11:37:37.944825 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 232000
I0819 11:38:01.467174 140034352527168 train_slot.py:155] Step: 232100, Loss: 0.000947, Time: 15:19:47.655381
I0819 11:38:25.514823 140034352527168 train_slot.py:155] Step: 232200, Loss: 0.000914, Time: 15:20:11.703043
I0819 11:38:49.072451 140034352527168 train_slot.py:155] Step: 232300, Loss: 0.000958, Time: 15:20:35.260669
I0819 11:39:12.798368 140034352527168 train_slot.py:155] Step: 232400, Loss: 0.001054, Time: 15:20:58.986437
I0819 11:39:36.504055 140034352527168 train_slot.py:155] Step: 232500, Loss: 0.000836, Time: 15:21:22.692075
I0819 11:40:00.301630 140034352527168 train_slot.py:155] Step: 232600, Loss: 0.000765, Time: 15:21:46.489835
I0819 11:40:24.326101 140034352527168 train_slot.py:155] Step: 232700, Loss: 0.000955, Time: 15:22:10.514299
I0819 11:40:48.074493 140034352527168 train_slot.py:155] Step: 232800, Loss: 0.001056, Time: 15:22:34.262687
I0819 11:41:11.715484 140034352527168 train_slot.py:155] Step: 232900, Loss: 0.000773, Time: 15:22:57.903617
I0819 11:41:35.205732 140034352527168 train_slot.py:155] Step: 233000, Loss: 0.000945, Time: 15:23:21.393939
I0819 11:41:35.576690 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-233000
I0819 11:41:36.720112 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 233000
I0819 11:42:00.259329 140034352527168 train_slot.py:155] Step: 233100, Loss: 0.000893, Time: 15:23:46.447542
I0819 11:42:23.812676 140034352527168 train_slot.py:155] Step: 233200, Loss: 0.000955, Time: 15:24:10.000896
I0819 11:42:47.609590 140034352527168 train_slot.py:155] Step: 233300, Loss: 0.001243, Time: 15:24:33.797797
I0819 11:43:11.439159 140034352527168 train_slot.py:155] Step: 233400, Loss: 0.000861, Time: 15:24:57.627162
I0819 11:43:35.250297 140034352527168 train_slot.py:155] Step: 233500, Loss: 0.001094, Time: 15:25:21.438498
I0819 11:43:59.105426 140034352527168 train_slot.py:155] Step: 233600, Loss: 0.001060, Time: 15:25:45.293631
I0819 11:44:22.862502 140034352527168 train_slot.py:155] Step: 233700, Loss: 0.001047, Time: 15:26:09.050730
I0819 11:44:46.570679 140034352527168 train_slot.py:155] Step: 233800, Loss: 0.000978, Time: 15:26:32.758832
I0819 11:45:10.423112 140034352527168 train_slot.py:155] Step: 233900, Loss: 0.000896, Time: 15:26:56.611215
I0819 11:45:33.855358 140034352527168 train_slot.py:155] Step: 234000, Loss: 0.000967, Time: 15:27:20.043588
I0819 11:45:34.164303 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-234000
I0819 11:45:35.232893 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 234000
I0819 11:45:58.815926 140034352527168 train_slot.py:155] Step: 234100, Loss: 0.000945, Time: 15:27:45.004125
I0819 11:46:22.354578 140034352527168 train_slot.py:155] Step: 234200, Loss: 0.000939, Time: 15:28:08.542703
I0819 11:46:45.881816 140034352527168 train_slot.py:155] Step: 234300, Loss: 0.000965, Time: 15:28:32.070012
I0819 11:47:09.567828 140034352527168 train_slot.py:155] Step: 234400, Loss: 0.000898, Time: 15:28:55.756057
I0819 11:47:09.801352 140034352527168 train_slot.py:155] Step: 234400, Loss: 0.001233, Time: 15:28:55.989580
I0819 11:47:33.264995 140034352527168 train_slot.py:155] Step: 234500, Loss: 0.001122, Time: 15:29:19.453196
I0819 11:47:57.001892 140034352527168 train_slot.py:155] Step: 234600, Loss: 0.000939, Time: 15:29:43.190025
I0819 11:48:20.770007 140034352527168 train_slot.py:155] Step: 234700, Loss: 0.000997, Time: 15:30:06.958234
I0819 11:48:44.314221 140034352527168 train_slot.py:155] Step: 234800, Loss: 0.000795, Time: 15:30:30.502454
I0819 11:49:07.876582 140034352527168 train_slot.py:155] Step: 234900, Loss: 0.000828, Time: 15:30:54.064712
I0819 11:49:31.637617 140034352527168 train_slot.py:155] Step: 235000, Loss: 0.000854, Time: 15:31:17.825675
I0819 11:49:32.028859 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-235000
I0819 11:49:33.118674 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 235000
I0819 11:49:56.637560 140034352527168 train_slot.py:155] Step: 235100, Loss: 0.000943, Time: 15:31:42.825725
I0819 11:50:20.134463 140034352527168 train_slot.py:155] Step: 235200, Loss: 0.001102, Time: 15:32:06.322663
I0819 11:50:43.644553 140034352527168 train_slot.py:155] Step: 235300, Loss: 0.001008, Time: 15:32:29.832751
I0819 11:51:07.108155 140034352527168 train_slot.py:155] Step: 235400, Loss: 0.000865, Time: 15:32:53.296372
I0819 11:51:30.870485 140034352527168 train_slot.py:155] Step: 235500, Loss: 0.000863, Time: 15:33:17.058611
I0819 11:51:54.449649 140034352527168 train_slot.py:155] Step: 235600, Loss: 0.000972, Time: 15:33:40.637844
I0819 11:52:17.942216 140034352527168 train_slot.py:155] Step: 235700, Loss: 0.000860, Time: 15:34:04.130411
I0819 11:52:41.391927 140034352527168 train_slot.py:155] Step: 235800, Loss: 0.000869, Time: 15:34:27.580067
I0819 11:53:04.846475 140034352527168 train_slot.py:155] Step: 235900, Loss: 0.001102, Time: 15:34:51.034688
I0819 11:53:28.629586 140034352527168 train_slot.py:155] Step: 236000, Loss: 0.000825, Time: 15:35:14.817749
I0819 11:53:29.018692 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-236000
I0819 11:53:30.113672 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 236000
I0819 11:53:53.832375 140034352527168 train_slot.py:155] Step: 236100, Loss: 0.000938, Time: 15:35:40.020569
I0819 11:54:17.410447 140034352527168 train_slot.py:155] Step: 236200, Loss: 0.000902, Time: 15:36:03.598683
I0819 11:54:41.262377 140034352527168 train_slot.py:155] Step: 236300, Loss: 0.000932, Time: 15:36:27.450503
I0819 11:55:04.776081 140034352527168 train_slot.py:155] Step: 236400, Loss: 0.000934, Time: 15:36:50.964302
I0819 11:55:28.278791 140034352527168 train_slot.py:155] Step: 236500, Loss: 0.001003, Time: 15:37:14.467020
I0819 11:55:52.199757 140034352527168 train_slot.py:155] Step: 236600, Loss: 0.000953, Time: 15:37:38.387958
I0819 11:56:16.146499 140034352527168 train_slot.py:155] Step: 236700, Loss: 0.000852, Time: 15:38:02.334671
I0819 11:56:40.058367 140034352527168 train_slot.py:155] Step: 236800, Loss: 0.000895, Time: 15:38:26.246423
I0819 11:57:03.941015 140034352527168 train_slot.py:155] Step: 236900, Loss: 0.000963, Time: 15:38:50.129245
I0819 11:57:27.805269 140034352527168 train_slot.py:155] Step: 237000, Loss: 0.000909, Time: 15:39:13.993452
I0819 11:57:28.142000 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-237000
I0819 11:57:29.210376 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 237000
I0819 11:57:53.206255 140034352527168 train_slot.py:155] Step: 237100, Loss: 0.001046, Time: 15:39:39.394488
I0819 11:58:16.862504 140034352527168 train_slot.py:155] Step: 237200, Loss: 0.000865, Time: 15:40:03.050467
I0819 11:58:41.065154 140034352527168 train_slot.py:155] Step: 237300, Loss: 0.000958, Time: 15:40:27.253361
I0819 11:59:04.760101 140034352527168 train_slot.py:155] Step: 237400, Loss: 0.000903, Time: 15:40:50.948301
I0819 11:59:28.611466 140034352527168 train_slot.py:155] Step: 237500, Loss: 0.001066, Time: 15:41:14.799667
I0819 11:59:52.384828 140034352527168 train_slot.py:155] Step: 237600, Loss: 0.000968, Time: 15:41:38.572929
I0819 12:00:16.599072 140034352527168 train_slot.py:155] Step: 237700, Loss: 0.000849, Time: 15:42:02.787294
I0819 12:00:40.602267 140034352527168 train_slot.py:155] Step: 237800, Loss: 0.000925, Time: 15:42:26.790479
I0819 12:01:04.503673 140034352527168 train_slot.py:155] Step: 237900, Loss: 0.001204, Time: 15:42:50.691904
I0819 12:01:28.281951 140034352527168 train_slot.py:155] Step: 238000, Loss: 0.000749, Time: 15:43:14.469540
I0819 12:01:28.657355 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-238000
I0819 12:01:29.728753 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 238000
I0819 12:01:53.624473 140034352527168 train_slot.py:155] Step: 238100, Loss: 0.000877, Time: 15:43:39.812669
I0819 12:02:17.913964 140034352527168 train_slot.py:155] Step: 238200, Loss: 0.000848, Time: 15:44:04.102184
I0819 12:02:41.920921 140034352527168 train_slot.py:155] Step: 238300, Loss: 0.000900, Time: 15:44:28.109156
I0819 12:03:05.845331 140034352527168 train_slot.py:155] Step: 238400, Loss: 0.000888, Time: 15:44:52.033461
I0819 12:03:29.452470 140034352527168 train_slot.py:155] Step: 238500, Loss: 0.001145, Time: 15:45:15.640670
I0819 12:03:53.182656 140034352527168 train_slot.py:155] Step: 238600, Loss: 0.000861, Time: 15:45:39.370865
I0819 12:04:17.144343 140034352527168 train_slot.py:155] Step: 238700, Loss: 0.000981, Time: 15:46:03.332341
I0819 12:04:41.107442 140034352527168 train_slot.py:155] Step: 238800, Loss: 0.000918, Time: 15:46:27.295455
I0819 12:05:05.373842 140034352527168 train_slot.py:155] Step: 238900, Loss: 0.001073, Time: 15:46:51.561912
I0819 12:05:29.713254 140034352527168 train_slot.py:155] Step: 239000, Loss: 0.000791, Time: 15:47:15.901451
I0819 12:05:30.080295 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-239000
I0819 12:05:31.216767 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 239000
I0819 12:05:55.250222 140034352527168 train_slot.py:155] Step: 239100, Loss: 0.000972, Time: 15:47:41.438451
I0819 12:06:18.878048 140034352527168 train_slot.py:155] Step: 239200, Loss: 0.000978, Time: 15:48:05.066207
I0819 12:06:42.656577 140034352527168 train_slot.py:155] Step: 239300, Loss: 0.001028, Time: 15:48:28.844770
I0819 12:07:06.069230 140034352527168 train_slot.py:155] Step: 239400, Loss: 0.001029, Time: 15:48:52.257441
I0819 12:07:29.568140 140034352527168 train_slot.py:155] Step: 239500, Loss: 0.001091, Time: 15:49:15.756273
I0819 12:07:52.954065 140034352527168 train_slot.py:155] Step: 239600, Loss: 0.000920, Time: 15:49:39.142060
I0819 12:08:16.437642 140034352527168 train_slot.py:155] Step: 239700, Loss: 0.000773, Time: 15:50:02.625844
I0819 12:08:40.139776 140034352527168 train_slot.py:155] Step: 239800, Loss: 0.000910, Time: 15:50:26.327989
I0819 12:09:03.632410 140034352527168 train_slot.py:155] Step: 239900, Loss: 0.000876, Time: 15:50:49.820484
I0819 12:09:27.224338 140034352527168 train_slot.py:155] Step: 240000, Loss: 0.000754, Time: 15:51:13.412532
I0819 12:09:27.539720 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-240000
I0819 12:09:28.614454 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 240000
I0819 12:09:52.403585 140034352527168 train_slot.py:155] Step: 240100, Loss: 0.000913, Time: 15:51:38.591770
I0819 12:10:15.845474 140034352527168 train_slot.py:155] Step: 240200, Loss: 0.000955, Time: 15:52:02.033673
I0819 12:10:39.322185 140034352527168 train_slot.py:155] Step: 240300, Loss: 0.001118, Time: 15:52:25.510317
I0819 12:11:03.075009 140034352527168 train_slot.py:155] Step: 240400, Loss: 0.001124, Time: 15:52:49.263214
I0819 12:11:26.617537 140034352527168 train_slot.py:155] Step: 240500, Loss: 0.001113, Time: 15:53:12.805737
I0819 12:11:50.130753 140034352527168 train_slot.py:155] Step: 240600, Loss: 0.000831, Time: 15:53:36.318852
I0819 12:12:13.688479 140034352527168 train_slot.py:155] Step: 240700, Loss: 0.001005, Time: 15:53:59.876637
I0819 12:12:37.190277 140034352527168 train_slot.py:155] Step: 240800, Loss: 0.000905, Time: 15:54:23.378484
I0819 12:13:00.951423 140034352527168 train_slot.py:155] Step: 240900, Loss: 0.000917, Time: 15:54:47.139623
I0819 12:13:24.780009 140034352527168 train_slot.py:155] Step: 241000, Loss: 0.001074, Time: 15:55:10.967957
I0819 12:13:25.145829 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-241000
I0819 12:13:26.276236 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 241000
I0819 12:13:50.074013 140034352527168 train_slot.py:155] Step: 241100, Loss: 0.000939, Time: 15:55:36.262207
I0819 12:14:13.963699 140034352527168 train_slot.py:155] Step: 241200, Loss: 0.000924, Time: 15:56:00.151931
I0819 12:14:37.721906 140034352527168 train_slot.py:155] Step: 241300, Loss: 0.001153, Time: 15:56:23.910107
I0819 12:15:01.503895 140034352527168 train_slot.py:155] Step: 241400, Loss: 0.000996, Time: 15:56:47.692055
I0819 12:15:25.413242 140034352527168 train_slot.py:155] Step: 241500, Loss: 0.000913, Time: 15:57:11.601426
I0819 12:15:48.976779 140034352527168 train_slot.py:155] Step: 241600, Loss: 0.000766, Time: 15:57:35.165000
I0819 12:16:12.521691 140034352527168 train_slot.py:155] Step: 241700, Loss: 0.000950, Time: 15:57:58.709851
I0819 12:16:35.930319 140034352527168 train_slot.py:155] Step: 241800, Loss: 0.000887, Time: 15:58:22.118524
I0819 12:16:59.428380 140034352527168 train_slot.py:155] Step: 241900, Loss: 0.000957, Time: 15:58:45.616560
I0819 12:17:23.151294 140034352527168 train_slot.py:155] Step: 242000, Loss: 0.000871, Time: 15:59:09.339498
I0819 12:17:23.531191 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-242000
I0819 12:17:24.663578 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 242000
I0819 12:17:48.207467 140034352527168 train_slot.py:155] Step: 242100, Loss: 0.001015, Time: 15:59:34.395594
I0819 12:18:11.720528 140034352527168 train_slot.py:155] Step: 242200, Loss: 0.000964, Time: 15:59:57.908762
I0819 12:18:35.303724 140034352527168 train_slot.py:155] Step: 242300, Loss: 0.001091, Time: 16:00:21.491924
I0819 12:18:58.807669 140034352527168 train_slot.py:155] Step: 242400, Loss: 0.001008, Time: 16:00:44.995874
I0819 12:19:22.359874 140034352527168 train_slot.py:155] Step: 242500, Loss: 0.000811, Time: 16:01:08.547874
I0819 12:19:46.320338 140034352527168 train_slot.py:155] Step: 242600, Loss: 0.000798, Time: 16:01:32.508540
I0819 12:20:10.082180 140034352527168 train_slot.py:155] Step: 242700, Loss: 0.000855, Time: 16:01:56.270401
I0819 12:20:33.686369 140034352527168 train_slot.py:155] Step: 242800, Loss: 0.001005, Time: 16:02:19.874487
I0819 12:20:57.177050 140034352527168 train_slot.py:155] Step: 242900, Loss: 0.001096, Time: 16:02:43.365278
I0819 12:21:21.160213 140034352527168 train_slot.py:155] Step: 243000, Loss: 0.000889, Time: 16:03:07.348419
I0819 12:21:21.527035 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-243000
I0819 12:21:22.599820 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 243000
I0819 12:21:46.429820 140034352527168 train_slot.py:155] Step: 243100, Loss: 0.000926, Time: 16:03:32.618032
I0819 12:22:10.003998 140034352527168 train_slot.py:155] Step: 243200, Loss: 0.000931, Time: 16:03:56.192129
I0819 12:22:33.486699 140034352527168 train_slot.py:155] Step: 243300, Loss: 0.000933, Time: 16:04:19.674899
I0819 12:22:56.976862 140034352527168 train_slot.py:155] Step: 243400, Loss: 0.000983, Time: 16:04:43.165050
I0819 12:23:20.456017 140034352527168 train_slot.py:155] Step: 243500, Loss: 0.000876, Time: 16:05:06.644212
I0819 12:23:44.261841 140034352527168 train_slot.py:155] Step: 243600, Loss: 0.001125, Time: 16:05:30.449955
I0819 12:24:07.775340 140034352527168 train_slot.py:155] Step: 243700, Loss: 0.000887, Time: 16:05:53.963550
I0819 12:24:31.345972 140034352527168 train_slot.py:155] Step: 243800, Loss: 0.000907, Time: 16:06:17.534168
I0819 12:24:54.866565 140034352527168 train_slot.py:155] Step: 243900, Loss: 0.000887, Time: 16:06:41.054685
I0819 12:25:18.445886 140034352527168 train_slot.py:155] Step: 244000, Loss: 0.000938, Time: 16:07:04.634105
I0819 12:25:18.794529 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-244000
I0819 12:25:19.862379 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 244000
I0819 12:25:43.430889 140034352527168 train_slot.py:155] Step: 244100, Loss: 0.000879, Time: 16:07:29.619117
I0819 12:26:07.161289 140034352527168 train_slot.py:155] Step: 244200, Loss: 0.001008, Time: 16:07:53.349455
I0819 12:26:30.770533 140034352527168 train_slot.py:155] Step: 244300, Loss: 0.001046, Time: 16:08:16.958585
I0819 12:26:54.353265 140034352527168 train_slot.py:155] Step: 244400, Loss: 0.000953, Time: 16:08:40.541447
I0819 12:27:17.807272 140034352527168 train_slot.py:155] Step: 244500, Loss: 0.000948, Time: 16:09:03.995488
I0819 12:27:41.393933 140034352527168 train_slot.py:155] Step: 244600, Loss: 0.000975, Time: 16:09:27.582136
I0819 12:28:04.980173 140034352527168 train_slot.py:155] Step: 244700, Loss: 0.001003, Time: 16:09:51.167771
I0819 12:28:28.635398 140034352527168 train_slot.py:155] Step: 244800, Loss: 0.000931, Time: 16:10:14.823602
I0819 12:28:52.256073 140034352527168 train_slot.py:155] Step: 244900, Loss: 0.000941, Time: 16:10:38.444282
I0819 12:29:15.830791 140034352527168 train_slot.py:155] Step: 245000, Loss: 0.000977, Time: 16:11:02.018851
I0819 12:29:16.196453 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-245000
I0819 12:29:17.326782 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 245000
I0819 12:29:40.982342 140034352527168 train_slot.py:155] Step: 245100, Loss: 0.000946, Time: 16:11:27.170489
I0819 12:30:04.784001 140034352527168 train_slot.py:155] Step: 245200, Loss: 0.000981, Time: 16:11:50.972235
I0819 12:30:28.608531 140034352527168 train_slot.py:155] Step: 245300, Loss: 0.000830, Time: 16:12:14.796770
I0819 12:30:52.102539 140034352527168 train_slot.py:155] Step: 245400, Loss: 0.000933, Time: 16:12:38.290035
I0819 12:31:15.698204 140034352527168 train_slot.py:155] Step: 245500, Loss: 0.000773, Time: 16:13:01.886398
I0819 12:31:39.250309 140034352527168 train_slot.py:155] Step: 245600, Loss: 0.000742, Time: 16:13:25.438508
I0819 12:32:03.016995 140034352527168 train_slot.py:155] Step: 245700, Loss: 0.000954, Time: 16:13:49.205192
I0819 12:32:26.790980 140034352527168 train_slot.py:155] Step: 245800, Loss: 0.001067, Time: 16:14:12.978994
I0819 12:32:50.203307 140034352527168 train_slot.py:155] Step: 245900, Loss: 0.000804, Time: 16:14:36.391512
I0819 12:33:13.735067 140034352527168 train_slot.py:155] Step: 246000, Loss: 0.000886, Time: 16:14:59.923273
I0819 12:33:14.107424 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-246000
I0819 12:33:15.176390 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 246000
I0819 12:33:38.766778 140034352527168 train_slot.py:155] Step: 246100, Loss: 0.001116, Time: 16:15:24.954900
I0819 12:34:02.379746 140034352527168 train_slot.py:155] Step: 246200, Loss: 0.000882, Time: 16:15:48.567963
I0819 12:34:25.986679 140034352527168 train_slot.py:155] Step: 246300, Loss: 0.000973, Time: 16:16:12.174879
I0819 12:34:49.528352 140034352527168 train_slot.py:155] Step: 246400, Loss: 0.001277, Time: 16:16:35.716558
I0819 12:35:13.158065 140034352527168 train_slot.py:155] Step: 246500, Loss: 0.000952, Time: 16:16:59.346032
I0819 12:35:36.645683 140034352527168 train_slot.py:155] Step: 246600, Loss: 0.000935, Time: 16:17:22.833888
I0819 12:36:00.160134 140034352527168 train_slot.py:155] Step: 246700, Loss: 0.000928, Time: 16:17:46.348355
I0819 12:36:23.698178 140034352527168 train_slot.py:155] Step: 246800, Loss: 0.000767, Time: 16:18:09.885739
I0819 12:36:47.589742 140034352527168 train_slot.py:155] Step: 246900, Loss: 0.000928, Time: 16:18:33.777925
I0819 12:37:11.251160 140034352527168 train_slot.py:155] Step: 247000, Loss: 0.000775, Time: 16:18:57.439366
I0819 12:37:11.595505 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-247000
I0819 12:37:12.704302 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 247000
I0819 12:37:36.486899 140034352527168 train_slot.py:155] Step: 247100, Loss: 0.000983, Time: 16:19:22.674939
I0819 12:37:59.885994 140034352527168 train_slot.py:155] Step: 247200, Loss: 0.000933, Time: 16:19:46.074150
I0819 12:38:23.275594 140034352527168 train_slot.py:155] Step: 247300, Loss: 0.001052, Time: 16:20:09.463797
I0819 12:38:47.195115 140034352527168 train_slot.py:155] Step: 247400, Loss: 0.000787, Time: 16:20:33.383314
I0819 12:39:10.622661 140034352527168 train_slot.py:155] Step: 247500, Loss: 0.000765, Time: 16:20:56.810701
I0819 12:39:34.114567 140034352527168 train_slot.py:155] Step: 247600, Loss: 0.000915, Time: 16:21:20.302769
I0819 12:39:57.557961 140034352527168 train_slot.py:155] Step: 247700, Loss: 0.000717, Time: 16:21:43.746169
I0819 12:40:21.098425 140034352527168 train_slot.py:155] Step: 247800, Loss: 0.001067, Time: 16:22:07.286633
I0819 12:40:44.592034 140034352527168 train_slot.py:155] Step: 247900, Loss: 0.000778, Time: 16:22:30.779623
I0819 12:41:08.342399 140034352527168 train_slot.py:155] Step: 248000, Loss: 0.000864, Time: 16:22:54.530567
I0819 12:41:08.708876 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-248000
I0819 12:41:09.776923 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 248000
I0819 12:41:33.355432 140034352527168 train_slot.py:155] Step: 248100, Loss: 0.001084, Time: 16:23:19.543628
I0819 12:41:56.883727 140034352527168 train_slot.py:155] Step: 248200, Loss: 0.000823, Time: 16:23:43.071858
I0819 12:42:20.332338 140034352527168 train_slot.py:155] Step: 248300, Loss: 0.000917, Time: 16:24:06.520522
I0819 12:42:43.716946 140034352527168 train_slot.py:155] Step: 248400, Loss: 0.000834, Time: 16:24:29.905144
I0819 12:43:07.440825 140034352527168 train_slot.py:155] Step: 248500, Loss: 0.001116, Time: 16:24:53.629058
I0819 12:43:30.888080 140034352527168 train_slot.py:155] Step: 248600, Loss: 0.001285, Time: 16:25:17.076209
I0819 12:43:54.499323 140034352527168 train_slot.py:155] Step: 248700, Loss: 0.000900, Time: 16:25:40.687505
I0819 12:44:18.042761 140034352527168 train_slot.py:155] Step: 248800, Loss: 0.000883, Time: 16:26:04.230962
I0819 12:44:41.614516 140034352527168 train_slot.py:155] Step: 248900, Loss: 0.000935, Time: 16:26:27.802714
I0819 12:45:05.001768 140034352527168 train_slot.py:155] Step: 249000, Loss: 0.000934, Time: 16:26:51.189829
I0819 12:45:05.393946 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-249000
I0819 12:45:06.507693 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 249000
I0819 12:45:30.217388 140034352527168 train_slot.py:155] Step: 249100, Loss: 0.000933, Time: 16:27:16.405605
I0819 12:45:53.752090 140034352527168 train_slot.py:155] Step: 249200, Loss: 0.000970, Time: 16:27:39.940293
I0819 12:46:17.313761 140034352527168 train_slot.py:155] Step: 249300, Loss: 0.001019, Time: 16:28:03.501846
I0819 12:46:41.035401 140034352527168 train_slot.py:155] Step: 249400, Loss: 0.000893, Time: 16:28:27.223396
I0819 12:47:04.740051 140034352527168 train_slot.py:155] Step: 249500, Loss: 0.000909, Time: 16:28:50.928201
I0819 12:47:28.426186 140034352527168 train_slot.py:155] Step: 249600, Loss: 0.000853, Time: 16:29:14.614391
I0819 12:47:51.885325 140034352527168 train_slot.py:155] Step: 249700, Loss: 0.000906, Time: 16:29:38.073558
I0819 12:48:15.606638 140034352527168 train_slot.py:155] Step: 249800, Loss: 0.000897, Time: 16:30:01.794842
I0819 12:48:39.105964 140034352527168 train_slot.py:155] Step: 249900, Loss: 0.000728, Time: 16:30:25.294165
I0819 12:49:02.688921 140034352527168 train_slot.py:155] Step: 250000, Loss: 0.001016, Time: 16:30:48.876912
I0819 12:49:03.048647 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-250000
I0819 12:49:04.166107 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 250000
I0819 12:49:28.070898 140034352527168 train_slot.py:155] Step: 250100, Loss: 0.000963, Time: 16:31:14.259122
I0819 12:49:51.503016 140034352527168 train_slot.py:155] Step: 250200, Loss: 0.001016, Time: 16:31:37.691225
I0819 12:50:14.982253 140034352527168 train_slot.py:155] Step: 250300, Loss: 0.000849, Time: 16:32:01.170475
I0819 12:50:38.646377 140034352527168 train_slot.py:155] Step: 250400, Loss: 0.000845, Time: 16:32:24.834576
I0819 12:51:02.276858 140034352527168 train_slot.py:155] Step: 250500, Loss: 0.000955, Time: 16:32:48.464808
I0819 12:51:25.791548 140034352527168 train_slot.py:155] Step: 250600, Loss: 0.001083, Time: 16:33:11.979746
I0819 12:51:49.575929 140034352527168 train_slot.py:155] Step: 250700, Loss: 0.001008, Time: 16:33:35.764132
I0819 12:52:13.087753 140034352527168 train_slot.py:155] Step: 250800, Loss: 0.001137, Time: 16:33:59.275988
I0819 12:52:36.609450 140034352527168 train_slot.py:155] Step: 250900, Loss: 0.000938, Time: 16:34:22.797495
I0819 12:53:00.461302 140034352527168 train_slot.py:155] Step: 251000, Loss: 0.000831, Time: 16:34:46.649509
I0819 12:53:00.817066 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-251000
I0819 12:53:01.887249 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 251000
I0819 12:53:25.627374 140034352527168 train_slot.py:155] Step: 251100, Loss: 0.001031, Time: 16:35:11.815566
I0819 12:53:49.591641 140034352527168 train_slot.py:155] Step: 251200, Loss: 0.001058, Time: 16:35:35.779766
I0819 12:54:13.216192 140034352527168 train_slot.py:155] Step: 251300, Loss: 0.000869, Time: 16:35:59.404247
I0819 12:54:36.951386 140034352527168 train_slot.py:155] Step: 251400, Loss: 0.000829, Time: 16:36:23.139574
I0819 12:55:00.691882 140034352527168 train_slot.py:155] Step: 251500, Loss: 0.000934, Time: 16:36:46.880099
I0819 12:55:24.690197 140034352527168 train_slot.py:155] Step: 251600, Loss: 0.000811, Time: 16:37:10.878395
I0819 12:55:48.436635 140034352527168 train_slot.py:155] Step: 251700, Loss: 0.000831, Time: 16:37:34.624834
I0819 12:56:12.298569 140034352527168 train_slot.py:155] Step: 251800, Loss: 0.000753, Time: 16:37:58.486636
I0819 12:56:35.803028 140034352527168 train_slot.py:155] Step: 251900, Loss: 0.000804, Time: 16:38:21.991259
I0819 12:56:59.591613 140034352527168 train_slot.py:155] Step: 252000, Loss: 0.000977, Time: 16:38:45.779845
I0819 12:56:59.945951 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-252000
I0819 12:57:01.050943 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 252000
I0819 12:57:24.663378 140034352527168 train_slot.py:155] Step: 252100, Loss: 0.000876, Time: 16:39:10.851574
I0819 12:57:48.295052 140034352527168 train_slot.py:155] Step: 252200, Loss: 0.001005, Time: 16:39:34.483250
I0819 12:58:12.074777 140034352527168 train_slot.py:155] Step: 252300, Loss: 0.000823, Time: 16:39:58.262880
I0819 12:58:35.650135 140034352527168 train_slot.py:155] Step: 252400, Loss: 0.000806, Time: 16:40:21.838379
I0819 12:58:59.170231 140034352527168 train_slot.py:155] Step: 252500, Loss: 0.000842, Time: 16:40:45.358434
I0819 12:59:22.744733 140034352527168 train_slot.py:155] Step: 252600, Loss: 0.000978, Time: 16:41:08.932961
I0819 12:59:46.266286 140034352527168 train_slot.py:155] Step: 252700, Loss: 0.000760, Time: 16:41:32.454512
I0819 13:00:09.795838 140034352527168 train_slot.py:155] Step: 252800, Loss: 0.000870, Time: 16:41:55.984040
I0819 13:00:33.539364 140034352527168 train_slot.py:155] Step: 252900, Loss: 0.000825, Time: 16:42:19.727575
I0819 13:00:57.143082 140034352527168 train_slot.py:155] Step: 253000, Loss: 0.000930, Time: 16:42:43.331280
I0819 13:00:57.481003 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-253000
I0819 13:00:58.555757 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 253000
I0819 13:01:22.378898 140034352527168 train_slot.py:155] Step: 253100, Loss: 0.000944, Time: 16:43:08.567043
I0819 13:01:46.190331 140034352527168 train_slot.py:155] Step: 253200, Loss: 0.000888, Time: 16:43:32.378543
I0819 13:02:09.690126 140034352527168 train_slot.py:155] Step: 253300, Loss: 0.001098, Time: 16:43:55.878324
I0819 13:02:33.499135 140034352527168 train_slot.py:155] Step: 253400, Loss: 0.000941, Time: 16:44:19.687340
I0819 13:02:57.062839 140034352527168 train_slot.py:155] Step: 253500, Loss: 0.000924, Time: 16:44:43.251043
I0819 13:03:20.912550 140034352527168 train_slot.py:155] Step: 253600, Loss: 0.000848, Time: 16:45:07.100677
I0819 13:03:44.584429 140034352527168 train_slot.py:155] Step: 253700, Loss: 0.001161, Time: 16:45:30.772631
I0819 13:04:08.142838 140034352527168 train_slot.py:155] Step: 253800, Loss: 0.001017, Time: 16:45:54.331037
I0819 13:04:31.957039 140034352527168 train_slot.py:155] Step: 253900, Loss: 0.000944, Time: 16:46:18.145174
I0819 13:04:55.627576 140034352527168 train_slot.py:155] Step: 254000, Loss: 0.001016, Time: 16:46:41.815737
I0819 13:04:56.004074 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-254000
I0819 13:04:57.132879 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 254000
I0819 13:05:20.797338 140034352527168 train_slot.py:155] Step: 254100, Loss: 0.001029, Time: 16:47:06.985545
I0819 13:05:44.155455 140034352527168 train_slot.py:155] Step: 254200, Loss: 0.001010, Time: 16:47:30.343660
I0819 13:06:07.609528 140034352527168 train_slot.py:155] Step: 254300, Loss: 0.001057, Time: 16:47:53.797581
I0819 13:06:31.091818 140034352527168 train_slot.py:155] Step: 254400, Loss: 0.000965, Time: 16:48:17.280044
I0819 13:06:54.842096 140034352527168 train_slot.py:155] Step: 254500, Loss: 0.001054, Time: 16:48:41.030303
I0819 13:07:18.377054 140034352527168 train_slot.py:155] Step: 254600, Loss: 0.000816, Time: 16:49:04.565256
I0819 13:07:41.879660 140034352527168 train_slot.py:155] Step: 254700, Loss: 0.000962, Time: 16:49:28.067862
I0819 13:08:05.668197 140034352527168 train_slot.py:155] Step: 254800, Loss: 0.000934, Time: 16:49:51.856425
I0819 13:08:29.310131 140034352527168 train_slot.py:155] Step: 254900, Loss: 0.000931, Time: 16:50:15.498093
I0819 13:08:53.260153 140034352527168 train_slot.py:155] Step: 255000, Loss: 0.000911, Time: 16:50:39.448354
I0819 13:08:53.585302 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-255000
I0819 13:08:54.736166 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 255000
I0819 13:09:18.278226 140034352527168 train_slot.py:155] Step: 255100, Loss: 0.001020, Time: 16:51:04.466433
I0819 13:09:41.887130 140034352527168 train_slot.py:155] Step: 255200, Loss: 0.000873, Time: 16:51:28.075351
I0819 13:10:05.317248 140034352527168 train_slot.py:155] Step: 255300, Loss: 0.001086, Time: 16:51:51.505224
I0819 13:10:28.782021 140034352527168 train_slot.py:155] Step: 255400, Loss: 0.001048, Time: 16:52:14.970260
I0819 13:10:52.224178 140034352527168 train_slot.py:155] Step: 255500, Loss: 0.000863, Time: 16:52:38.412412
I0819 13:11:15.913168 140034352527168 train_slot.py:155] Step: 255600, Loss: 0.001032, Time: 16:53:02.101386
I0819 13:11:39.443295 140034352527168 train_slot.py:155] Step: 255700, Loss: 0.000941, Time: 16:53:25.631529
I0819 13:12:02.972184 140034352527168 train_slot.py:155] Step: 255800, Loss: 0.000927, Time: 16:53:49.160307
I0819 13:12:26.483839 140034352527168 train_slot.py:155] Step: 255900, Loss: 0.000869, Time: 16:54:12.672056
I0819 13:12:50.166874 140034352527168 train_slot.py:155] Step: 256000, Loss: 0.001149, Time: 16:54:36.355105
I0819 13:12:50.488988 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-256000
I0819 13:12:51.621719 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 256000
I0819 13:13:15.492331 140034352527168 train_slot.py:155] Step: 256100, Loss: 0.000805, Time: 16:55:01.680538
I0819 13:13:38.985759 140034352527168 train_slot.py:155] Step: 256200, Loss: 0.000863, Time: 16:55:25.173895
I0819 13:14:02.751345 140034352527168 train_slot.py:155] Step: 256300, Loss: 0.000770, Time: 16:55:48.939510
I0819 13:14:26.272632 140034352527168 train_slot.py:155] Step: 256400, Loss: 0.000771, Time: 16:56:12.460834
I0819 13:14:49.832740 140034352527168 train_slot.py:155] Step: 256500, Loss: 0.001072, Time: 16:56:36.020959
I0819 13:15:13.557572 140034352527168 train_slot.py:155] Step: 256600, Loss: 0.000931, Time: 16:56:59.745804
I0819 13:15:37.342513 140034352527168 train_slot.py:155] Step: 256700, Loss: 0.000969, Time: 16:57:23.530527
I0819 13:16:00.907064 140034352527168 train_slot.py:155] Step: 256800, Loss: 0.000882, Time: 16:57:47.095255
I0819 13:16:24.502304 140034352527168 train_slot.py:155] Step: 256900, Loss: 0.001113, Time: 16:58:10.690498
I0819 13:16:48.016307 140034352527168 train_slot.py:155] Step: 257000, Loss: 0.001356, Time: 16:58:34.204531
I0819 13:16:48.337103 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-257000
I0819 13:16:49.404714 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 257000
I0819 13:17:12.894536 140034352527168 train_slot.py:155] Step: 257100, Loss: 0.001028, Time: 16:58:59.082591
I0819 13:17:36.641693 140034352527168 train_slot.py:155] Step: 257200, Loss: 0.001041, Time: 16:59:22.829869
I0819 13:18:00.146813 140034352527168 train_slot.py:155] Step: 257300, Loss: 0.001172, Time: 16:59:46.335048
I0819 13:18:23.624211 140034352527168 train_slot.py:155] Step: 257400, Loss: 0.000881, Time: 17:00:09.812408
I0819 13:18:47.065298 140034352527168 train_slot.py:155] Step: 257500, Loss: 0.000954, Time: 17:00:33.253497
I0819 13:19:10.818963 140034352527168 train_slot.py:155] Step: 257600, Loss: 0.000903, Time: 17:00:57.007107
I0819 13:19:34.459148 140034352527168 train_slot.py:155] Step: 257700, Loss: 0.000839, Time: 17:01:20.647355
I0819 13:19:58.255004 140034352527168 train_slot.py:155] Step: 257800, Loss: 0.001060, Time: 17:01:44.443161
I0819 13:20:21.765464 140034352527168 train_slot.py:155] Step: 257900, Loss: 0.000947, Time: 17:02:07.953665
I0819 13:20:45.225598 140034352527168 train_slot.py:155] Step: 258000, Loss: 0.000902, Time: 17:02:31.413735
I0819 13:20:45.545471 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-258000
I0819 13:20:46.627495 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 258000
I0819 13:21:10.277450 140034352527168 train_slot.py:155] Step: 258100, Loss: 0.001003, Time: 17:02:56.465614
I0819 13:21:33.682839 140034352527168 train_slot.py:155] Step: 258200, Loss: 0.001000, Time: 17:03:19.871037
I0819 13:21:57.428463 140034352527168 train_slot.py:155] Step: 258300, Loss: 0.000855, Time: 17:03:43.616663
I0819 13:22:20.919012 140034352527168 train_slot.py:155] Step: 258400, Loss: 0.000792, Time: 17:04:07.107244
I0819 13:22:44.482585 140034352527168 train_slot.py:155] Step: 258500, Loss: 0.000874, Time: 17:04:30.670745
I0819 13:23:08.031436 140034352527168 train_slot.py:155] Step: 258600, Loss: 0.001017, Time: 17:04:54.219622
I0819 13:23:31.681879 140034352527168 train_slot.py:155] Step: 258700, Loss: 0.001067, Time: 17:05:17.870115
I0819 13:23:55.563237 140034352527168 train_slot.py:155] Step: 258800, Loss: 0.000875, Time: 17:05:41.751441
I0819 13:24:19.412423 140034352527168 train_slot.py:155] Step: 258900, Loss: 0.000826, Time: 17:06:05.600656
I0819 13:24:43.314667 140034352527168 train_slot.py:155] Step: 259000, Loss: 0.001228, Time: 17:06:29.502860
I0819 13:24:43.638105 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-259000
I0819 13:24:44.710408 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 259000
I0819 13:25:08.643122 140034352527168 train_slot.py:155] Step: 259100, Loss: 0.000827, Time: 17:06:54.831173
I0819 13:25:32.489783 140034352527168 train_slot.py:155] Step: 259200, Loss: 0.000826, Time: 17:07:18.677941
I0819 13:25:56.626793 140034352527168 train_slot.py:155] Step: 259300, Loss: 0.000984, Time: 17:07:42.815025
I0819 13:26:20.491189 140034352527168 train_slot.py:155] Step: 259400, Loss: 0.001018, Time: 17:08:06.679383
I0819 13:26:43.973957 140034352527168 train_slot.py:155] Step: 259500, Loss: 0.000900, Time: 17:08:30.162185
I0819 13:27:07.427245 140034352527168 train_slot.py:155] Step: 259600, Loss: 0.000924, Time: 17:08:53.615210
I0819 13:27:31.095259 140034352527168 train_slot.py:155] Step: 259700, Loss: 0.000810, Time: 17:09:17.283482
I0819 13:27:54.603668 140034352527168 train_slot.py:155] Step: 259800, Loss: 0.000965, Time: 17:09:40.791895
I0819 13:28:18.334009 140034352527168 train_slot.py:155] Step: 259900, Loss: 0.000765, Time: 17:10:04.522210
I0819 13:28:42.136057 140034352527168 train_slot.py:155] Step: 260000, Loss: 0.000864, Time: 17:10:28.324266
I0819 13:28:42.493681 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-260000
I0819 13:28:43.566009 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 260000
I0819 13:29:07.164528 140034352527168 train_slot.py:155] Step: 260100, Loss: 0.001111, Time: 17:10:53.352540
I0819 13:29:30.716840 140034352527168 train_slot.py:155] Step: 260200, Loss: 0.000807, Time: 17:11:16.904947
I0819 13:29:54.234065 140034352527168 train_slot.py:155] Step: 260300, Loss: 0.000891, Time: 17:11:40.422269
I0819 13:30:18.140731 140034352527168 train_slot.py:155] Step: 260400, Loss: 0.001010, Time: 17:12:04.328938
I0819 13:30:41.700680 140034352527168 train_slot.py:155] Step: 260500, Loss: 0.000929, Time: 17:12:27.888891
I0819 13:31:05.230738 140034352527168 train_slot.py:155] Step: 260600, Loss: 0.000911, Time: 17:12:51.418792
I0819 13:31:28.781786 140034352527168 train_slot.py:155] Step: 260700, Loss: 0.000984, Time: 17:13:14.969987
I0819 13:31:52.162806 140034352527168 train_slot.py:155] Step: 260800, Loss: 0.000947, Time: 17:13:38.351009
I0819 13:32:15.619831 140034352527168 train_slot.py:155] Step: 260900, Loss: 0.001056, Time: 17:14:01.808037
I0819 13:32:39.407598 140034352527168 train_slot.py:155] Step: 261000, Loss: 0.001177, Time: 17:14:25.595805
I0819 13:32:39.759002 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-261000
I0819 13:32:40.826730 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 261000
I0819 13:33:04.367441 140034352527168 train_slot.py:155] Step: 261100, Loss: 0.000922, Time: 17:14:50.555604
I0819 13:33:27.868452 140034352527168 train_slot.py:155] Step: 261200, Loss: 0.000910, Time: 17:15:14.056641
I0819 13:33:51.342315 140034352527168 train_slot.py:155] Step: 261300, Loss: 0.000765, Time: 17:15:37.530514
I0819 13:34:14.839882 140034352527168 train_slot.py:155] Step: 261400, Loss: 0.000870, Time: 17:16:01.028084
I0819 13:34:38.632838 140034352527168 train_slot.py:155] Step: 261500, Loss: 0.000901, Time: 17:16:24.821073
I0819 13:35:02.178331 140034352527168 train_slot.py:155] Step: 261600, Loss: 0.000884, Time: 17:16:48.366351
I0819 13:35:25.670590 140034352527168 train_slot.py:155] Step: 261700, Loss: 0.000891, Time: 17:17:11.858762
I0819 13:35:49.111051 140034352527168 train_slot.py:155] Step: 261800, Loss: 0.000828, Time: 17:17:35.299246
I0819 13:36:12.680624 140034352527168 train_slot.py:155] Step: 261900, Loss: 0.000745, Time: 17:17:58.868860
I0819 13:36:36.231724 140034352527168 train_slot.py:155] Step: 262000, Loss: 0.000817, Time: 17:18:22.419924
I0819 13:36:36.601570 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-262000
I0819 13:36:37.668432 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 262000
I0819 13:37:01.388165 140034352527168 train_slot.py:155] Step: 262100, Loss: 0.000874, Time: 17:18:47.576220
I0819 13:37:24.789452 140034352527168 train_slot.py:155] Step: 262200, Loss: 0.000989, Time: 17:19:10.977677
I0819 13:37:48.270066 140034352527168 train_slot.py:155] Step: 262300, Loss: 0.001146, Time: 17:19:34.458244
I0819 13:38:12.107981 140034352527168 train_slot.py:155] Step: 262400, Loss: 0.000812, Time: 17:19:58.296190
I0819 13:38:35.945031 140034352527168 train_slot.py:155] Step: 262500, Loss: 0.000982, Time: 17:20:22.133223
I0819 13:38:59.909491 140034352527168 train_slot.py:155] Step: 262600, Loss: 0.000826, Time: 17:20:46.097606
I0819 13:39:23.356374 140034352527168 train_slot.py:155] Step: 262700, Loss: 0.000821, Time: 17:21:09.544595
I0819 13:39:47.021713 140034352527168 train_slot.py:155] Step: 262800, Loss: 0.000861, Time: 17:21:33.209917
I0819 13:40:10.504003 140034352527168 train_slot.py:155] Step: 262900, Loss: 0.001124, Time: 17:21:56.692198
I0819 13:40:34.009428 140034352527168 train_slot.py:155] Step: 263000, Loss: 0.000828, Time: 17:22:20.197625
I0819 13:40:34.381504 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-263000
I0819 13:40:35.450516 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 263000
I0819 13:40:58.941846 140034352527168 train_slot.py:155] Step: 263100, Loss: 0.000776, Time: 17:22:45.129910
I0819 13:41:22.661845 140034352527168 train_slot.py:155] Step: 263200, Loss: 0.001052, Time: 17:23:08.850046
I0819 13:41:46.243504 140034352527168 train_slot.py:155] Step: 263300, Loss: 0.000758, Time: 17:23:32.431703
I0819 13:42:09.749318 140034352527168 train_slot.py:155] Step: 263400, Loss: 0.000876, Time: 17:23:55.937550
I0819 13:42:33.244221 140034352527168 train_slot.py:155] Step: 263500, Loss: 0.000795, Time: 17:24:19.432429
I0819 13:42:56.608196 140034352527168 train_slot.py:155] Step: 263600, Loss: 0.000912, Time: 17:24:42.796424
I0819 13:43:20.330392 140034352527168 train_slot.py:155] Step: 263700, Loss: 0.001079, Time: 17:25:06.518592
I0819 13:43:43.839602 140034352527168 train_slot.py:155] Step: 263800, Loss: 0.000814, Time: 17:25:30.027609
I0819 13:44:07.417920 140034352527168 train_slot.py:155] Step: 263900, Loss: 0.000823, Time: 17:25:53.606152
I0819 13:44:30.894399 140034352527168 train_slot.py:155] Step: 264000, Loss: 0.000975, Time: 17:26:17.082631
I0819 13:44:31.250997 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-264000
I0819 13:44:32.321058 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 264000
I0819 13:44:55.759858 140034352527168 train_slot.py:155] Step: 264100, Loss: 0.000977, Time: 17:26:41.947883
I0819 13:45:19.414460 140034352527168 train_slot.py:155] Step: 264200, Loss: 0.001102, Time: 17:27:05.602659
I0819 13:45:42.925114 140034352527168 train_slot.py:155] Step: 264300, Loss: 0.000872, Time: 17:27:29.113340
I0819 13:46:06.472054 140034352527168 train_slot.py:155] Step: 264400, Loss: 0.000861, Time: 17:27:52.660286
I0819 13:46:30.084567 140034352527168 train_slot.py:155] Step: 264500, Loss: 0.000962, Time: 17:28:16.272770
I0819 13:46:53.604532 140034352527168 train_slot.py:155] Step: 264600, Loss: 0.000931, Time: 17:28:39.792727
I0819 13:47:17.121420 140034352527168 train_slot.py:155] Step: 264700, Loss: 0.000763, Time: 17:29:03.309623
I0819 13:47:40.891651 140034352527168 train_slot.py:155] Step: 264800, Loss: 0.000829, Time: 17:29:27.079685
I0819 13:48:04.399289 140034352527168 train_slot.py:155] Step: 264900, Loss: 0.001070, Time: 17:29:50.587162
I0819 13:48:28.183340 140034352527168 train_slot.py:155] Step: 265000, Loss: 0.000948, Time: 17:30:14.371539
I0819 13:48:28.517913 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-265000
I0819 13:48:29.628081 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 265000
I0819 13:48:53.133062 140034352527168 train_slot.py:155] Step: 265100, Loss: 0.001105, Time: 17:30:39.321261
I0819 13:49:17.008093 140034352527168 train_slot.py:155] Step: 265200, Loss: 0.000796, Time: 17:31:03.196333
I0819 13:49:40.951261 140034352527168 train_slot.py:155] Step: 265300, Loss: 0.001017, Time: 17:31:27.139390
I0819 13:50:04.525868 140034352527168 train_slot.py:155] Step: 265400, Loss: 0.000932, Time: 17:31:50.713997
I0819 13:50:27.966208 140034352527168 train_slot.py:155] Step: 265500, Loss: 0.000970, Time: 17:32:14.154405
I0819 13:50:51.583386 140034352527168 train_slot.py:155] Step: 265600, Loss: 0.000898, Time: 17:32:37.771591
I0819 13:51:15.169650 140034352527168 train_slot.py:155] Step: 265700, Loss: 0.000809, Time: 17:33:01.357857
I0819 13:51:38.678919 140034352527168 train_slot.py:155] Step: 265800, Loss: 0.000896, Time: 17:33:24.867056
I0819 13:52:02.471534 140034352527168 train_slot.py:155] Step: 265900, Loss: 0.000988, Time: 17:33:48.659095
I0819 13:52:25.989280 140034352527168 train_slot.py:155] Step: 266000, Loss: 0.000962, Time: 17:34:12.177473
I0819 13:52:26.363722 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-266000
I0819 13:52:27.429185 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 266000
I0819 13:52:50.863550 140034352527168 train_slot.py:155] Step: 266100, Loss: 0.000981, Time: 17:34:37.051705
I0819 13:53:14.419863 140034352527168 train_slot.py:155] Step: 266200, Loss: 0.000931, Time: 17:35:00.608037
I0819 13:53:38.165433 140034352527168 train_slot.py:155] Step: 266300, Loss: 0.000797, Time: 17:35:24.353635
I0819 13:54:01.844671 140034352527168 train_slot.py:155] Step: 266400, Loss: 0.000865, Time: 17:35:48.032874
I0819 13:54:25.415018 140034352527168 train_slot.py:155] Step: 266500, Loss: 0.000917, Time: 17:36:11.603253
I0819 13:54:48.906705 140034352527168 train_slot.py:155] Step: 266600, Loss: 0.000967, Time: 17:36:35.094845
I0819 13:55:12.343966 140034352527168 train_slot.py:155] Step: 266700, Loss: 0.000888, Time: 17:36:58.532199
I0819 13:55:35.744368 140034352527168 train_slot.py:155] Step: 266800, Loss: 0.000821, Time: 17:37:21.932571
I0819 13:55:59.254981 140034352527168 train_slot.py:155] Step: 266900, Loss: 0.000883, Time: 17:37:45.443189
I0819 13:56:22.990217 140034352527168 train_slot.py:155] Step: 267000, Loss: 0.000796, Time: 17:38:09.178354
I0819 13:56:23.307478 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-267000
I0819 13:56:24.439418 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 267000
I0819 13:56:47.923359 140034352527168 train_slot.py:155] Step: 267100, Loss: 0.000782, Time: 17:38:34.111517
I0819 13:57:11.598569 140034352527168 train_slot.py:155] Step: 267200, Loss: 0.000765, Time: 17:38:57.786801
I0819 13:57:35.149119 140034352527168 train_slot.py:155] Step: 267300, Loss: 0.000968, Time: 17:39:21.337316
I0819 13:57:58.686031 140034352527168 train_slot.py:155] Step: 267400, Loss: 0.001083, Time: 17:39:44.874230
I0819 13:58:22.438746 140034352527168 train_slot.py:155] Step: 267500, Loss: 0.000743, Time: 17:40:08.626763
I0819 13:58:46.024740 140034352527168 train_slot.py:155] Step: 267600, Loss: 0.000939, Time: 17:40:32.212971
I0819 13:59:09.529927 140034352527168 train_slot.py:155] Step: 267700, Loss: 0.000896, Time: 17:40:55.718147
I0819 13:59:33.083466 140034352527168 train_slot.py:155] Step: 267800, Loss: 0.000838, Time: 17:41:19.271667
I0819 13:59:56.661134 140034352527168 train_slot.py:155] Step: 267900, Loss: 0.000978, Time: 17:41:42.849259
I0819 14:00:20.328411 140034352527168 train_slot.py:155] Step: 268000, Loss: 0.000850, Time: 17:42:06.516613
I0819 14:00:20.701816 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-268000
I0819 14:00:21.774644 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 268000
I0819 14:00:45.224902 140034352527168 train_slot.py:155] Step: 268100, Loss: 0.000989, Time: 17:42:31.413089
I0819 14:01:08.797007 140034352527168 train_slot.py:155] Step: 268200, Loss: 0.000856, Time: 17:42:54.985215
I0819 14:01:32.396175 140034352527168 train_slot.py:155] Step: 268300, Loss: 0.000701, Time: 17:43:18.584389
I0819 14:01:56.020762 140034352527168 train_slot.py:155] Step: 268400, Loss: 0.000889, Time: 17:43:42.208873
I0819 14:02:19.738549 140034352527168 train_slot.py:155] Step: 268500, Loss: 0.000768, Time: 17:44:05.926775
I0819 14:02:43.513328 140034352527168 train_slot.py:155] Step: 268600, Loss: 0.000777, Time: 17:44:29.701520
I0819 14:03:06.962711 140034352527168 train_slot.py:155] Step: 268700, Loss: 0.000933, Time: 17:44:53.150914
I0819 14:03:30.498957 140034352527168 train_slot.py:155] Step: 268800, Loss: 0.001020, Time: 17:45:16.687117
I0819 14:03:30.726017 140034352527168 train_slot.py:155] Step: 268800, Loss: 0.001219, Time: 17:45:16.914258
I0819 14:03:54.234923 140034352527168 train_slot.py:155] Step: 268900, Loss: 0.000832, Time: 17:45:40.423153
I0819 14:04:17.693751 140034352527168 train_slot.py:155] Step: 269000, Loss: 0.000819, Time: 17:46:03.881976
I0819 14:04:18.060896 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-269000
I0819 14:04:19.165455 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 269000
I0819 14:04:42.851927 140034352527168 train_slot.py:155] Step: 269100, Loss: 0.001002, Time: 17:46:29.040131
I0819 14:05:06.373613 140034352527168 train_slot.py:155] Step: 269200, Loss: 0.000815, Time: 17:46:52.561743
I0819 14:05:29.909651 140034352527168 train_slot.py:155] Step: 269300, Loss: 0.000957, Time: 17:47:16.097842
I0819 14:05:53.372310 140034352527168 train_slot.py:155] Step: 269400, Loss: 0.000887, Time: 17:47:39.560533
I0819 14:06:16.826480 140034352527168 train_slot.py:155] Step: 269500, Loss: 0.000852, Time: 17:48:03.014674
I0819 14:06:40.332897 140034352527168 train_slot.py:155] Step: 269600, Loss: 0.001036, Time: 17:48:26.521121
I0819 14:07:04.031944 140034352527168 train_slot.py:155] Step: 269700, Loss: 0.000772, Time: 17:48:50.220012
I0819 14:07:27.556973 140034352527168 train_slot.py:155] Step: 269800, Loss: 0.000992, Time: 17:49:13.745171
I0819 14:07:51.256659 140034352527168 train_slot.py:155] Step: 269900, Loss: 0.001016, Time: 17:49:37.444858
I0819 14:08:14.696784 140034352527168 train_slot.py:155] Step: 270000, Loss: 0.001004, Time: 17:50:00.885013
I0819 14:08:15.069486 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-270000
I0819 14:08:16.144136 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 270000
I0819 14:08:39.569429 140034352527168 train_slot.py:155] Step: 270100, Loss: 0.000841, Time: 17:50:25.757657
I0819 14:09:03.254033 140034352527168 train_slot.py:155] Step: 270200, Loss: 0.001039, Time: 17:50:49.442234
I0819 14:09:26.977654 140034352527168 train_slot.py:155] Step: 270300, Loss: 0.000892, Time: 17:51:13.165855
I0819 14:09:50.728640 140034352527168 train_slot.py:155] Step: 270400, Loss: 0.000933, Time: 17:51:36.916836
I0819 14:10:14.247353 140034352527168 train_slot.py:155] Step: 270500, Loss: 0.000801, Time: 17:52:00.435514
I0819 14:10:37.668486 140034352527168 train_slot.py:155] Step: 270600, Loss: 0.000891, Time: 17:52:23.856719
I0819 14:11:01.131217 140034352527168 train_slot.py:155] Step: 270700, Loss: 0.001015, Time: 17:52:47.319343
I0819 14:11:24.879955 140034352527168 train_slot.py:155] Step: 270800, Loss: 0.000789, Time: 17:53:11.068187
I0819 14:11:48.405784 140034352527168 train_slot.py:155] Step: 270900, Loss: 0.000707, Time: 17:53:34.593994
I0819 14:12:12.000950 140034352527168 train_slot.py:155] Step: 271000, Loss: 0.000763, Time: 17:53:58.189184
I0819 14:12:12.327450 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-271000
I0819 14:12:13.425267 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 271000
I0819 14:12:36.935965 140034352527168 train_slot.py:155] Step: 271100, Loss: 0.001012, Time: 17:54:23.124111
I0819 14:13:00.377410 140034352527168 train_slot.py:155] Step: 271200, Loss: 0.000918, Time: 17:54:46.565628
I0819 14:13:24.065714 140034352527168 train_slot.py:155] Step: 271300, Loss: 0.000802, Time: 17:55:10.253915
I0819 14:13:47.536993 140034352527168 train_slot.py:155] Step: 271400, Loss: 0.001305, Time: 17:55:33.725228
I0819 14:14:11.101404 140034352527168 train_slot.py:155] Step: 271500, Loss: 0.000759, Time: 17:55:57.289376
I0819 14:14:34.630966 140034352527168 train_slot.py:155] Step: 271600, Loss: 0.000837, Time: 17:56:20.819175
I0819 14:14:58.051965 140034352527168 train_slot.py:155] Step: 271700, Loss: 0.000842, Time: 17:56:44.240199
I0819 14:15:22.041451 140034352527168 train_slot.py:155] Step: 271800, Loss: 0.001005, Time: 17:57:08.229665
I0819 14:15:45.771901 140034352527168 train_slot.py:155] Step: 271900, Loss: 0.000921, Time: 17:57:31.959921
I0819 14:16:09.236415 140034352527168 train_slot.py:155] Step: 272000, Loss: 0.001067, Time: 17:57:55.424646
I0819 14:16:09.609687 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-272000
I0819 14:16:10.698094 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 272000
I0819 14:16:34.242779 140034352527168 train_slot.py:155] Step: 272100, Loss: 0.000933, Time: 17:58:20.430996
I0819 14:16:57.806231 140034352527168 train_slot.py:155] Step: 272200, Loss: 0.000984, Time: 17:58:43.994431
I0819 14:17:21.268141 140034352527168 train_slot.py:155] Step: 272300, Loss: 0.000923, Time: 17:59:07.456371
I0819 14:17:44.907929 140034352527168 train_slot.py:155] Step: 272400, Loss: 0.000873, Time: 17:59:31.095914
I0819 14:18:08.337961 140034352527168 train_slot.py:155] Step: 272500, Loss: 0.000920, Time: 17:59:54.526201
I0819 14:18:31.768504 140034352527168 train_slot.py:155] Step: 272600, Loss: 0.000852, Time: 18:00:17.956694
I0819 14:18:55.296849 140034352527168 train_slot.py:155] Step: 272700, Loss: 0.000899, Time: 18:00:41.485074
I0819 14:19:18.753145 140034352527168 train_slot.py:155] Step: 272800, Loss: 0.000905, Time: 18:01:04.941374
I0819 14:19:42.443161 140034352527168 train_slot.py:155] Step: 272900, Loss: 0.000861, Time: 18:01:28.631283
I0819 14:20:05.994147 140034352527168 train_slot.py:155] Step: 273000, Loss: 0.000973, Time: 18:01:52.182334
I0819 14:20:06.367280 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-273000
I0819 14:20:07.440289 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 273000
I0819 14:20:30.992058 140034352527168 train_slot.py:155] Step: 273100, Loss: 0.001096, Time: 18:02:17.180260
I0819 14:20:54.336101 140034352527168 train_slot.py:155] Step: 273200, Loss: 0.000794, Time: 18:02:40.524300
I0819 14:21:17.848520 140034352527168 train_slot.py:155] Step: 273300, Loss: 0.000825, Time: 18:03:04.036727
I0819 14:21:41.258840 140034352527168 train_slot.py:155] Step: 273400, Loss: 0.000972, Time: 18:03:27.446968
I0819 14:22:04.981150 140034352527168 train_slot.py:155] Step: 273500, Loss: 0.000974, Time: 18:03:51.169322
I0819 14:22:28.425069 140034352527168 train_slot.py:155] Step: 273600, Loss: 0.000990, Time: 18:04:14.613271
I0819 14:22:51.978330 140034352527168 train_slot.py:155] Step: 273700, Loss: 0.001008, Time: 18:04:38.166463
I0819 14:23:15.987609 140034352527168 train_slot.py:155] Step: 273800, Loss: 0.000972, Time: 18:05:02.175762
I0819 14:23:39.499981 140034352527168 train_slot.py:155] Step: 273900, Loss: 0.000789, Time: 18:05:25.688192
I0819 14:24:03.309913 140034352527168 train_slot.py:155] Step: 274000, Loss: 0.000767, Time: 18:05:49.498141
I0819 14:24:03.679792 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-274000
I0819 14:24:04.753705 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 274000
I0819 14:24:28.170604 140034352527168 train_slot.py:155] Step: 274100, Loss: 0.000788, Time: 18:06:14.358833
I0819 14:24:51.500931 140034352527168 train_slot.py:155] Step: 274200, Loss: 0.001028, Time: 18:06:37.689152
I0819 14:25:15.237307 140034352527168 train_slot.py:155] Step: 274300, Loss: 0.000869, Time: 18:07:01.425510
I0819 14:25:38.718586 140034352527168 train_slot.py:155] Step: 274400, Loss: 0.000966, Time: 18:07:24.906820
I0819 14:26:02.150781 140034352527168 train_slot.py:155] Step: 274500, Loss: 0.000852, Time: 18:07:48.338777
I0819 14:26:25.767938 140034352527168 train_slot.py:155] Step: 274600, Loss: 0.000860, Time: 18:08:11.956091
I0819 14:26:49.352713 140034352527168 train_slot.py:155] Step: 274700, Loss: 0.000912, Time: 18:08:35.540914
I0819 14:27:12.885725 140034352527168 train_slot.py:155] Step: 274800, Loss: 0.000971, Time: 18:08:59.073926
I0819 14:27:36.482407 140034352527168 train_slot.py:155] Step: 274900, Loss: 0.000918, Time: 18:09:22.670640
I0819 14:28:00.063435 140034352527168 train_slot.py:155] Step: 275000, Loss: 0.000842, Time: 18:09:46.251462
I0819 14:28:00.432026 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-275000
I0819 14:28:01.572055 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 275000
I0819 14:28:25.368291 140034352527168 train_slot.py:155] Step: 275100, Loss: 0.000829, Time: 18:10:11.556489
I0819 14:28:48.911976 140034352527168 train_slot.py:155] Step: 275200, Loss: 0.000974, Time: 18:10:35.100186
I0819 14:29:12.400372 140034352527168 train_slot.py:155] Step: 275300, Loss: 0.001191, Time: 18:10:58.588567
I0819 14:29:35.815531 140034352527168 train_slot.py:155] Step: 275400, Loss: 0.000869, Time: 18:11:22.003644
I0819 14:29:59.301756 140034352527168 train_slot.py:155] Step: 275500, Loss: 0.000808, Time: 18:11:45.489892
I0819 14:30:23.004543 140034352527168 train_slot.py:155] Step: 275600, Loss: 0.000781, Time: 18:12:09.192739
I0819 14:30:46.746071 140034352527168 train_slot.py:155] Step: 275700, Loss: 0.000900, Time: 18:12:32.934274
I0819 14:31:10.205044 140034352527168 train_slot.py:155] Step: 275800, Loss: 0.000902, Time: 18:12:56.393270
I0819 14:31:33.788902 140034352527168 train_slot.py:155] Step: 275900, Loss: 0.000923, Time: 18:13:19.977100
I0819 14:31:57.479516 140034352527168 train_slot.py:155] Step: 276000, Loss: 0.000872, Time: 18:13:43.667538
I0819 14:31:57.833218 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-276000
I0819 14:31:58.989180 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 276000
I0819 14:32:22.663705 140034352527168 train_slot.py:155] Step: 276100, Loss: 0.000731, Time: 18:14:08.851929
I0819 14:32:46.830740 140034352527168 train_slot.py:155] Step: 276200, Loss: 0.000824, Time: 18:14:33.018941
I0819 14:33:10.523330 140034352527168 train_slot.py:155] Step: 276300, Loss: 0.000872, Time: 18:14:56.711554
I0819 14:33:34.398971 140034352527168 train_slot.py:155] Step: 276400, Loss: 0.000939, Time: 18:15:20.587173
I0819 14:33:58.087623 140034352527168 train_slot.py:155] Step: 276500, Loss: 0.000950, Time: 18:15:44.275562
I0819 14:34:21.622391 140034352527168 train_slot.py:155] Step: 276600, Loss: 0.000926, Time: 18:16:07.810634
I0819 14:34:46.337597 140034352527168 train_slot.py:155] Step: 276700, Loss: 0.000867, Time: 18:16:32.525802
I0819 14:35:11.184587 140034352527168 train_slot.py:155] Step: 276800, Loss: 0.000846, Time: 18:16:57.372813
I0819 14:35:34.758679 140034352527168 train_slot.py:155] Step: 276900, Loss: 0.000729, Time: 18:17:20.946890
I0819 14:35:58.665310 140034352527168 train_slot.py:155] Step: 277000, Loss: 0.000893, Time: 18:17:44.853340
I0819 14:35:59.035258 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-277000
I0819 14:36:00.116900 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 277000
I0819 14:36:24.210741 140034352527168 train_slot.py:155] Step: 277100, Loss: 0.000957, Time: 18:18:10.398916
I0819 14:36:48.027342 140034352527168 train_slot.py:155] Step: 277200, Loss: 0.000974, Time: 18:18:34.215550
I0819 14:37:12.264043 140034352527168 train_slot.py:155] Step: 277300, Loss: 0.000767, Time: 18:18:58.452258
I0819 14:37:36.228593 140034352527168 train_slot.py:155] Step: 277400, Loss: 0.000795, Time: 18:19:22.416624
I0819 14:37:59.992128 140034352527168 train_slot.py:155] Step: 277500, Loss: 0.000855, Time: 18:19:46.180321
I0819 14:38:23.815332 140034352527168 train_slot.py:155] Step: 277600, Loss: 0.000804, Time: 18:20:10.003532
I0819 14:38:47.618674 140034352527168 train_slot.py:155] Step: 277700, Loss: 0.000863, Time: 18:20:33.806885
I0819 14:39:11.782181 140034352527168 train_slot.py:155] Step: 277800, Loss: 0.000896, Time: 18:20:57.970377
I0819 14:39:35.658773 140034352527168 train_slot.py:155] Step: 277900, Loss: 0.000697, Time: 18:21:21.846916
I0819 14:39:59.449383 140034352527168 train_slot.py:155] Step: 278000, Loss: 0.000973, Time: 18:21:45.637591
I0819 14:39:59.862267 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-278000
I0819 14:40:01.002933 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 278000
I0819 14:40:24.837897 140034352527168 train_slot.py:155] Step: 278100, Loss: 0.000861, Time: 18:22:11.026123
I0819 14:40:48.686797 140034352527168 train_slot.py:155] Step: 278200, Loss: 0.000851, Time: 18:22:34.875006
I0819 14:41:12.616127 140034352527168 train_slot.py:155] Step: 278300, Loss: 0.001044, Time: 18:22:58.804345
I0819 14:41:36.730074 140034352527168 train_slot.py:155] Step: 278400, Loss: 0.000890, Time: 18:23:22.918118
I0819 14:42:00.622384 140034352527168 train_slot.py:155] Step: 278500, Loss: 0.001056, Time: 18:23:46.810569
I0819 14:42:24.486696 140034352527168 train_slot.py:155] Step: 278600, Loss: 0.000795, Time: 18:24:10.674905
I0819 14:42:48.336944 140034352527168 train_slot.py:155] Step: 278700, Loss: 0.000858, Time: 18:24:34.525142
I0819 14:43:12.218437 140034352527168 train_slot.py:155] Step: 278800, Loss: 0.001004, Time: 18:24:58.406460
I0819 14:43:36.272448 140034352527168 train_slot.py:155] Step: 278900, Loss: 0.000931, Time: 18:25:22.460631
I0819 14:44:00.177953 140034352527168 train_slot.py:155] Step: 279000, Loss: 0.000771, Time: 18:25:46.366194
I0819 14:44:00.563607 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-279000
I0819 14:44:01.833338 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 279000
I0819 14:44:25.671243 140034352527168 train_slot.py:155] Step: 279100, Loss: 0.000742, Time: 18:26:11.859480
I0819 14:44:49.704195 140034352527168 train_slot.py:155] Step: 279200, Loss: 0.000802, Time: 18:26:35.892431
I0819 14:45:13.470922 140034352527168 train_slot.py:155] Step: 279300, Loss: 0.000828, Time: 18:26:59.659164
I0819 14:45:37.404357 140034352527168 train_slot.py:155] Step: 279400, Loss: 0.000942, Time: 18:27:23.592570
I0819 14:46:01.444542 140034352527168 train_slot.py:155] Step: 279500, Loss: 0.001039, Time: 18:27:47.632748
I0819 14:46:25.306381 140034352527168 train_slot.py:155] Step: 279600, Loss: 0.000790, Time: 18:28:11.494517
I0819 14:46:49.112725 140034352527168 train_slot.py:155] Step: 279700, Loss: 0.001090, Time: 18:28:35.300932
I0819 14:47:12.960161 140034352527168 train_slot.py:155] Step: 279800, Loss: 0.000899, Time: 18:28:59.148365
I0819 14:47:36.484995 140034352527168 train_slot.py:155] Step: 279900, Loss: 0.000863, Time: 18:29:22.673201
I0819 14:48:00.326706 140034352527168 train_slot.py:155] Step: 280000, Loss: 0.001038, Time: 18:29:46.514860
I0819 14:48:00.730593 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-280000
I0819 14:48:01.818108 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 280000
I0819 14:48:25.357600 140034352527168 train_slot.py:155] Step: 280100, Loss: 0.000748, Time: 18:30:11.545814
I0819 14:48:49.195134 140034352527168 train_slot.py:155] Step: 280200, Loss: 0.000782, Time: 18:30:35.383224
I0819 14:49:12.789500 140034352527168 train_slot.py:155] Step: 280300, Loss: 0.000772, Time: 18:30:58.977703
I0819 14:49:36.308614 140034352527168 train_slot.py:155] Step: 280400, Loss: 0.001018, Time: 18:31:22.496802
I0819 14:50:00.289964 140034352527168 train_slot.py:155] Step: 280500, Loss: 0.000838, Time: 18:31:46.478165
I0819 14:50:23.738822 140034352527168 train_slot.py:155] Step: 280600, Loss: 0.001033, Time: 18:32:09.927030
I0819 14:50:47.337803 140034352527168 train_slot.py:155] Step: 280700, Loss: 0.000921, Time: 18:32:33.525831
I0819 14:51:10.950056 140034352527168 train_slot.py:155] Step: 280800, Loss: 0.001032, Time: 18:32:57.138219
I0819 14:51:34.611197 140034352527168 train_slot.py:155] Step: 280900, Loss: 0.001037, Time: 18:33:20.799409
I0819 14:51:58.056128 140034352527168 train_slot.py:155] Step: 281000, Loss: 0.000802, Time: 18:33:44.244130
I0819 14:51:58.420722 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-281000
I0819 14:51:59.488588 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 281000
I0819 14:52:23.228563 140034352527168 train_slot.py:155] Step: 281100, Loss: 0.000957, Time: 18:34:09.416789
I0819 14:52:46.859482 140034352527168 train_slot.py:155] Step: 281200, Loss: 0.000782, Time: 18:34:33.047685
I0819 14:53:10.390380 140034352527168 train_slot.py:155] Step: 281300, Loss: 0.000876, Time: 18:34:56.578586
I0819 14:53:33.934429 140034352527168 train_slot.py:155] Step: 281400, Loss: 0.000967, Time: 18:35:20.122636
I0819 14:53:57.672506 140034352527168 train_slot.py:155] Step: 281500, Loss: 0.001007, Time: 18:35:43.860710
I0819 14:54:21.631401 140034352527168 train_slot.py:155] Step: 281600, Loss: 0.000811, Time: 18:36:07.819636
I0819 14:54:45.107562 140034352527168 train_slot.py:155] Step: 281700, Loss: 0.000851, Time: 18:36:31.295758
I0819 14:55:08.562338 140034352527168 train_slot.py:155] Step: 281800, Loss: 0.000841, Time: 18:36:54.750543
I0819 14:55:32.693114 140034352527168 train_slot.py:155] Step: 281900, Loss: 0.000785, Time: 18:37:18.881335
I0819 14:55:56.220884 140034352527168 train_slot.py:155] Step: 282000, Loss: 0.000810, Time: 18:37:42.408399
I0819 14:55:56.596593 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-282000
I0819 14:55:57.730449 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 282000
I0819 14:56:21.555760 140034352527168 train_slot.py:155] Step: 282100, Loss: 0.000809, Time: 18:38:07.743947
I0819 14:56:45.153773 140034352527168 train_slot.py:155] Step: 282200, Loss: 0.000947, Time: 18:38:31.341971
I0819 14:57:08.753276 140034352527168 train_slot.py:155] Step: 282300, Loss: 0.000971, Time: 18:38:54.941477
I0819 14:57:32.323735 140034352527168 train_slot.py:155] Step: 282400, Loss: 0.001035, Time: 18:39:18.511756
I0819 14:57:55.944287 140034352527168 train_slot.py:155] Step: 282500, Loss: 0.000824, Time: 18:39:42.132509
I0819 14:58:19.383710 140034352527168 train_slot.py:155] Step: 282600, Loss: 0.001171, Time: 18:40:05.571908
I0819 14:58:43.193367 140034352527168 train_slot.py:155] Step: 282700, Loss: 0.000721, Time: 18:40:29.381572
I0819 14:59:06.804070 140034352527168 train_slot.py:155] Step: 282800, Loss: 0.000870, Time: 18:40:52.991655
I0819 14:59:30.347449 140034352527168 train_slot.py:155] Step: 282900, Loss: 0.000979, Time: 18:41:16.535655
I0819 14:59:53.757281 140034352527168 train_slot.py:155] Step: 283000, Loss: 0.000805, Time: 18:41:39.945482
I0819 14:59:54.134802 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-283000
I0819 14:59:55.210244 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 283000
I0819 15:00:18.825696 140034352527168 train_slot.py:155] Step: 283100, Loss: 0.000769, Time: 18:42:05.013791
I0819 15:00:42.564623 140034352527168 train_slot.py:155] Step: 283200, Loss: 0.000928, Time: 18:42:28.752654
I0819 15:01:06.342309 140034352527168 train_slot.py:155] Step: 283300, Loss: 0.000831, Time: 18:42:52.530514
I0819 15:01:29.929656 140034352527168 train_slot.py:155] Step: 283400, Loss: 0.000763, Time: 18:43:16.117896
I0819 15:01:53.469280 140034352527168 train_slot.py:155] Step: 283500, Loss: 0.000789, Time: 18:43:39.657300
I0819 15:02:17.024228 140034352527168 train_slot.py:155] Step: 283600, Loss: 0.000807, Time: 18:44:03.212380
I0819 15:02:40.538639 140034352527168 train_slot.py:155] Step: 283700, Loss: 0.000916, Time: 18:44:26.726840
I0819 15:03:04.302007 140034352527168 train_slot.py:155] Step: 283800, Loss: 0.001009, Time: 18:44:50.490245
I0819 15:03:27.913105 140034352527168 train_slot.py:155] Step: 283900, Loss: 0.000822, Time: 18:45:14.101264
I0819 15:03:51.714948 140034352527168 train_slot.py:155] Step: 284000, Loss: 0.000908, Time: 18:45:37.903157
I0819 15:03:52.062645 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-284000
I0819 15:03:53.169178 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 284000
I0819 15:04:16.739452 140034352527168 train_slot.py:155] Step: 284100, Loss: 0.000826, Time: 18:46:02.927654
I0819 15:04:40.202679 140034352527168 train_slot.py:155] Step: 284200, Loss: 0.000916, Time: 18:46:26.390730
I0819 15:05:04.001615 140034352527168 train_slot.py:155] Step: 284300, Loss: 0.001031, Time: 18:46:50.189200
I0819 15:05:27.628997 140034352527168 train_slot.py:155] Step: 284400, Loss: 0.000906, Time: 18:47:13.817225
I0819 15:05:51.195706 140034352527168 train_slot.py:155] Step: 284500, Loss: 0.000718, Time: 18:47:37.383907
I0819 15:06:15.003413 140034352527168 train_slot.py:155] Step: 284600, Loss: 0.000993, Time: 18:48:01.191642
I0819 15:06:38.484862 140034352527168 train_slot.py:155] Step: 284700, Loss: 0.001002, Time: 18:48:24.673064
I0819 15:07:02.091496 140034352527168 train_slot.py:155] Step: 284800, Loss: 0.000919, Time: 18:48:48.279706
I0819 15:07:25.931080 140034352527168 train_slot.py:155] Step: 284900, Loss: 0.000957, Time: 18:49:12.119278
I0819 15:07:49.484954 140034352527168 train_slot.py:155] Step: 285000, Loss: 0.000792, Time: 18:49:35.673153
I0819 15:07:49.808411 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-285000
I0819 15:07:50.928769 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 285000
I0819 15:08:14.444463 140034352527168 train_slot.py:155] Step: 285100, Loss: 0.001037, Time: 18:50:00.632475
I0819 15:08:38.201544 140034352527168 train_slot.py:155] Step: 285200, Loss: 0.000788, Time: 18:50:24.389765
I0819 15:09:01.645070 140034352527168 train_slot.py:155] Step: 285300, Loss: 0.000846, Time: 18:50:47.833269
I0819 15:09:25.265131 140034352527168 train_slot.py:155] Step: 285400, Loss: 0.000814, Time: 18:51:11.453360
I0819 15:09:48.766098 140034352527168 train_slot.py:155] Step: 285500, Loss: 0.000829, Time: 18:51:34.954301
I0819 15:10:12.225853 140034352527168 train_slot.py:155] Step: 285600, Loss: 0.000945, Time: 18:51:58.414059
I0819 15:10:35.819360 140034352527168 train_slot.py:155] Step: 285700, Loss: 0.000899, Time: 18:52:22.007507
I0819 15:10:59.371786 140034352527168 train_slot.py:155] Step: 285800, Loss: 0.000911, Time: 18:52:45.560013
I0819 15:11:23.138024 140034352527168 train_slot.py:155] Step: 285900, Loss: 0.000875, Time: 18:53:09.326150
I0819 15:11:46.631389 140034352527168 train_slot.py:155] Step: 286000, Loss: 0.001092, Time: 18:53:32.819549
I0819 15:11:46.949270 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-286000
I0819 15:11:48.013763 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 286000
I0819 15:12:11.643437 140034352527168 train_slot.py:155] Step: 286100, Loss: 0.000908, Time: 18:53:57.831639
I0819 15:12:35.087552 140034352527168 train_slot.py:155] Step: 286200, Loss: 0.000929, Time: 18:54:21.275750
I0819 15:12:58.500210 140034352527168 train_slot.py:155] Step: 286300, Loss: 0.001011, Time: 18:54:44.688411
I0819 15:13:22.209212 140034352527168 train_slot.py:155] Step: 286400, Loss: 0.000840, Time: 18:55:08.397414
I0819 15:13:45.975817 140034352527168 train_slot.py:155] Step: 286500, Loss: 0.000964, Time: 18:55:32.164018
I0819 15:14:09.415987 140034352527168 train_slot.py:155] Step: 286600, Loss: 0.000779, Time: 18:55:55.604189
I0819 15:14:32.937639 140034352527168 train_slot.py:155] Step: 286700, Loss: 0.000898, Time: 18:56:19.125838
I0819 15:14:56.410076 140034352527168 train_slot.py:155] Step: 286800, Loss: 0.000661, Time: 18:56:42.598194
I0819 15:15:19.834243 140034352527168 train_slot.py:155] Step: 286900, Loss: 0.000850, Time: 18:57:06.022445
I0819 15:15:43.588817 140034352527168 train_slot.py:155] Step: 287000, Loss: 0.000836, Time: 18:57:29.777022
I0819 15:15:43.942675 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-287000
I0819 15:15:45.012291 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 287000
I0819 15:16:08.484221 140034352527168 train_slot.py:155] Step: 287100, Loss: 0.000847, Time: 18:57:54.672420
I0819 15:16:32.272522 140034352527168 train_slot.py:155] Step: 287200, Loss: 0.000774, Time: 18:58:18.460754
I0819 15:16:55.816412 140034352527168 train_slot.py:155] Step: 287300, Loss: 0.000902, Time: 18:58:42.004613
I0819 15:17:19.274513 140034352527168 train_slot.py:155] Step: 287400, Loss: 0.000740, Time: 18:59:05.462745
I0819 15:17:42.842109 140034352527168 train_slot.py:155] Step: 287500, Loss: 0.000913, Time: 18:59:29.030171
I0819 15:18:06.548944 140034352527168 train_slot.py:155] Step: 287600, Loss: 0.000821, Time: 18:59:52.737152
I0819 15:18:30.118303 140034352527168 train_slot.py:155] Step: 287700, Loss: 0.000817, Time: 19:00:16.306473
I0819 15:18:53.629997 140034352527168 train_slot.py:155] Step: 287800, Loss: 0.000820, Time: 19:00:39.818197
I0819 15:19:17.286254 140034352527168 train_slot.py:155] Step: 287900, Loss: 0.000749, Time: 19:01:03.474386
I0819 15:19:40.878186 140034352527168 train_slot.py:155] Step: 288000, Loss: 0.000805, Time: 19:01:27.066406
I0819 15:19:41.230678 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-288000
I0819 15:19:42.298934 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 288000
I0819 15:20:06.056917 140034352527168 train_slot.py:155] Step: 288100, Loss: 0.000852, Time: 19:01:52.245147
I0819 15:20:29.516437 140034352527168 train_slot.py:155] Step: 288200, Loss: 0.000861, Time: 19:02:15.704643
I0819 15:20:53.098310 140034352527168 train_slot.py:155] Step: 288300, Loss: 0.000957, Time: 19:02:39.286306
I0819 15:21:16.665924 140034352527168 train_slot.py:155] Step: 288400, Loss: 0.000771, Time: 19:03:02.854095
I0819 15:21:40.223814 140034352527168 train_slot.py:155] Step: 288500, Loss: 0.000839, Time: 19:03:26.412021
I0819 15:22:03.722368 140034352527168 train_slot.py:155] Step: 288600, Loss: 0.000888, Time: 19:03:49.910579
I0819 15:22:27.487895 140034352527168 train_slot.py:155] Step: 288700, Loss: 0.001107, Time: 19:04:13.676126
I0819 15:22:50.956871 140034352527168 train_slot.py:155] Step: 288800, Loss: 0.000754, Time: 19:04:37.145069
I0819 15:23:14.414578 140034352527168 train_slot.py:155] Step: 288900, Loss: 0.001186, Time: 19:05:00.602777
I0819 15:23:37.820959 140034352527168 train_slot.py:155] Step: 289000, Loss: 0.000750, Time: 19:05:24.009162
I0819 15:23:38.220601 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-289000
I0819 15:23:39.289122 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 289000
I0819 15:24:02.824226 140034352527168 train_slot.py:155] Step: 289100, Loss: 0.001277, Time: 19:05:49.012372
I0819 15:24:26.519626 140034352527168 train_slot.py:155] Step: 289200, Loss: 0.000715, Time: 19:06:12.707747
I0819 15:24:50.273684 140034352527168 train_slot.py:155] Step: 289300, Loss: 0.000792, Time: 19:06:36.461886
I0819 15:25:13.774895 140034352527168 train_slot.py:155] Step: 289400, Loss: 0.000816, Time: 19:06:59.963096
I0819 15:25:37.584672 140034352527168 train_slot.py:155] Step: 289500, Loss: 0.000876, Time: 19:07:23.772809
I0819 15:26:01.313033 140034352527168 train_slot.py:155] Step: 289600, Loss: 0.000783, Time: 19:07:47.501259
I0819 15:26:25.043394 140034352527168 train_slot.py:155] Step: 289700, Loss: 0.000909, Time: 19:08:11.231601
I0819 15:26:48.554418 140034352527168 train_slot.py:155] Step: 289800, Loss: 0.000828, Time: 19:08:34.742621
I0819 15:27:12.186713 140034352527168 train_slot.py:155] Step: 289900, Loss: 0.000799, Time: 19:08:58.374745
I0819 15:27:35.773029 140034352527168 train_slot.py:155] Step: 290000, Loss: 0.000869, Time: 19:09:21.961228
I0819 15:27:36.093179 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-290000
I0819 15:27:37.228632 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 290000
I0819 15:28:00.723761 140034352527168 train_slot.py:155] Step: 290100, Loss: 0.000799, Time: 19:09:46.911927
I0819 15:28:24.215550 140034352527168 train_slot.py:155] Step: 290200, Loss: 0.000856, Time: 19:10:10.403751
I0819 15:28:48.349373 140034352527168 train_slot.py:155] Step: 290300, Loss: 0.000960, Time: 19:10:34.537555
I0819 15:29:12.394890 140034352527168 train_slot.py:155] Step: 290400, Loss: 0.001120, Time: 19:10:58.582882
I0819 15:29:36.475114 140034352527168 train_slot.py:155] Step: 290500, Loss: 0.000868, Time: 19:11:22.663313
I0819 15:30:00.296476 140034352527168 train_slot.py:155] Step: 290600, Loss: 0.001028, Time: 19:11:46.484706
I0819 15:30:24.156751 140034352527168 train_slot.py:155] Step: 290700, Loss: 0.000776, Time: 19:12:10.344980
I0819 15:30:48.279047 140034352527168 train_slot.py:155] Step: 290800, Loss: 0.000906, Time: 19:12:34.467247
I0819 15:31:12.350718 140034352527168 train_slot.py:155] Step: 290900, Loss: 0.000795, Time: 19:12:58.538918
I0819 15:31:36.034990 140034352527168 train_slot.py:155] Step: 291000, Loss: 0.000895, Time: 19:13:22.223030
I0819 15:31:36.398069 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-291000
I0819 15:31:37.470402 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 291000
I0819 15:32:00.963515 140034352527168 train_slot.py:155] Step: 291100, Loss: 0.000844, Time: 19:13:47.151744
I0819 15:32:24.448801 140034352527168 train_slot.py:155] Step: 291200, Loss: 0.000707, Time: 19:14:10.636997
I0819 15:32:47.966092 140034352527168 train_slot.py:155] Step: 291300, Loss: 0.000844, Time: 19:14:34.154295
I0819 15:33:11.727734 140034352527168 train_slot.py:155] Step: 291400, Loss: 0.000943, Time: 19:14:57.915937
I0819 15:33:35.228919 140034352527168 train_slot.py:155] Step: 291500, Loss: 0.000683, Time: 19:15:21.417048
I0819 15:33:58.845304 140034352527168 train_slot.py:155] Step: 291600, Loss: 0.000868, Time: 19:15:45.033482
I0819 15:34:22.459212 140034352527168 train_slot.py:155] Step: 291700, Loss: 0.000747, Time: 19:16:08.647423
I0819 15:34:46.085366 140034352527168 train_slot.py:155] Step: 291800, Loss: 0.000851, Time: 19:16:32.273563
I0819 15:35:09.739882 140034352527168 train_slot.py:155] Step: 291900, Loss: 0.000799, Time: 19:16:55.928102
I0819 15:35:33.384991 140034352527168 train_slot.py:155] Step: 292000, Loss: 0.000742, Time: 19:17:19.572965
I0819 15:35:33.738641 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-292000
I0819 15:35:34.806102 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 292000
I0819 15:35:58.408925 140034352527168 train_slot.py:155] Step: 292100, Loss: 0.000731, Time: 19:17:44.597082
I0819 15:36:22.232472 140034352527168 train_slot.py:155] Step: 292200, Loss: 0.000813, Time: 19:18:08.420669
I0819 15:36:45.830357 140034352527168 train_slot.py:155] Step: 292300, Loss: 0.000854, Time: 19:18:32.018563
I0819 15:37:09.422153 140034352527168 train_slot.py:155] Step: 292400, Loss: 0.000983, Time: 19:18:55.610130
I0819 15:37:33.141542 140034352527168 train_slot.py:155] Step: 292500, Loss: 0.000768, Time: 19:19:19.329742
I0819 15:37:56.785133 140034352527168 train_slot.py:155] Step: 292600, Loss: 0.000809, Time: 19:19:42.973330
I0819 15:38:20.608648 140034352527168 train_slot.py:155] Step: 292700, Loss: 0.000974, Time: 19:20:06.796843
I0819 15:38:44.238159 140034352527168 train_slot.py:155] Step: 292800, Loss: 0.000934, Time: 19:20:30.426388
I0819 15:39:07.801401 140034352527168 train_slot.py:155] Step: 292900, Loss: 0.000760, Time: 19:20:53.989600
I0819 15:39:31.740694 140034352527168 train_slot.py:155] Step: 293000, Loss: 0.000995, Time: 19:21:17.928890
I0819 15:39:32.110738 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-293000
I0819 15:39:33.177878 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 293000
I0819 15:39:57.259342 140034352527168 train_slot.py:155] Step: 293100, Loss: 0.000901, Time: 19:21:43.447546
I0819 15:40:21.424361 140034352527168 train_slot.py:155] Step: 293200, Loss: 0.000818, Time: 19:22:07.612371
I0819 15:40:45.449890 140034352527168 train_slot.py:155] Step: 293300, Loss: 0.000875, Time: 19:22:31.638096
I0819 15:41:09.468039 140034352527168 train_slot.py:155] Step: 293400, Loss: 0.000871, Time: 19:22:55.656236
I0819 15:41:33.567059 140034352527168 train_slot.py:155] Step: 293500, Loss: 0.000819, Time: 19:23:19.755163
I0819 15:41:57.186086 140034352527168 train_slot.py:155] Step: 293600, Loss: 0.001009, Time: 19:23:43.374279
I0819 15:42:20.836082 140034352527168 train_slot.py:155] Step: 293700, Loss: 0.000927, Time: 19:24:07.024287
I0819 15:42:44.602552 140034352527168 train_slot.py:155] Step: 293800, Loss: 0.001006, Time: 19:24:30.790694
I0819 15:43:08.381113 140034352527168 train_slot.py:155] Step: 293900, Loss: 0.000797, Time: 19:24:54.569223
I0819 15:43:31.758830 140034352527168 train_slot.py:155] Step: 294000, Loss: 0.000743, Time: 19:25:17.947006
I0819 15:43:32.129152 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-294000
I0819 15:43:33.267725 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 294000
I0819 15:43:57.047194 140034352527168 train_slot.py:155] Step: 294100, Loss: 0.000925, Time: 19:25:43.235389
I0819 15:44:20.561557 140034352527168 train_slot.py:155] Step: 294200, Loss: 0.000708, Time: 19:26:06.749761
I0819 15:44:44.089262 140034352527168 train_slot.py:155] Step: 294300, Loss: 0.000806, Time: 19:26:30.277301
I0819 15:45:07.656230 140034352527168 train_slot.py:155] Step: 294400, Loss: 0.000774, Time: 19:26:53.844430
I0819 15:45:31.233969 140034352527168 train_slot.py:155] Step: 294500, Loss: 0.000878, Time: 19:27:17.422107
I0819 15:45:55.029751 140034352527168 train_slot.py:155] Step: 294600, Loss: 0.000853, Time: 19:27:41.217968
I0819 15:46:18.613579 140034352527168 train_slot.py:155] Step: 294700, Loss: 0.001010, Time: 19:28:04.801563
I0819 15:46:42.106447 140034352527168 train_slot.py:155] Step: 294800, Loss: 0.000861, Time: 19:28:28.294643
I0819 15:47:05.607537 140034352527168 train_slot.py:155] Step: 294900, Loss: 0.001035, Time: 19:28:51.795686
I0819 15:47:29.125608 140034352527168 train_slot.py:155] Step: 295000, Loss: 0.000831, Time: 19:29:15.313807
I0819 15:47:29.492287 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-295000
I0819 15:47:30.559088 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 295000
I0819 15:47:54.134579 140034352527168 train_slot.py:155] Step: 295100, Loss: 0.000837, Time: 19:29:40.322779
I0819 15:48:17.915203 140034352527168 train_slot.py:155] Step: 295200, Loss: 0.000915, Time: 19:30:04.103341
I0819 15:48:41.345282 140034352527168 train_slot.py:155] Step: 295300, Loss: 0.000837, Time: 19:30:27.533484
I0819 15:49:05.341274 140034352527168 train_slot.py:155] Step: 295400, Loss: 0.000866, Time: 19:30:51.529416
I0819 15:49:28.921703 140034352527168 train_slot.py:155] Step: 295500, Loss: 0.000966, Time: 19:31:15.109913
I0819 15:49:52.472695 140034352527168 train_slot.py:155] Step: 295600, Loss: 0.000942, Time: 19:31:38.660910
I0819 15:50:16.219198 140034352527168 train_slot.py:155] Step: 295700, Loss: 0.000871, Time: 19:32:02.407239
I0819 15:50:39.665038 140034352527168 train_slot.py:155] Step: 295800, Loss: 0.000655, Time: 19:32:25.853237
I0819 15:51:03.372610 140034352527168 train_slot.py:155] Step: 295900, Loss: 0.000709, Time: 19:32:49.560830
I0819 15:51:26.939245 140034352527168 train_slot.py:155] Step: 296000, Loss: 0.001051, Time: 19:33:13.127455
I0819 15:51:27.284960 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-296000
I0819 15:51:28.356510 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 296000
I0819 15:51:51.963844 140034352527168 train_slot.py:155] Step: 296100, Loss: 0.000968, Time: 19:33:38.152051
I0819 15:52:15.560825 140034352527168 train_slot.py:155] Step: 296200, Loss: 0.001004, Time: 19:34:01.748980
I0819 15:52:39.302199 140034352527168 train_slot.py:155] Step: 296300, Loss: 0.000906, Time: 19:34:25.490391
I0819 15:53:02.835381 140034352527168 train_slot.py:155] Step: 296400, Loss: 0.000926, Time: 19:34:49.023579
I0819 15:53:26.382045 140034352527168 train_slot.py:155] Step: 296500, Loss: 0.000747, Time: 19:35:12.570244
I0819 15:53:49.917315 140034352527168 train_slot.py:155] Step: 296600, Loss: 0.000887, Time: 19:35:36.105475
I0819 15:54:13.393619 140034352527168 train_slot.py:155] Step: 296700, Loss: 0.001041, Time: 19:35:59.581777
I0819 15:54:37.165602 140034352527168 train_slot.py:155] Step: 296800, Loss: 0.000916, Time: 19:36:23.353805
I0819 15:55:00.659606 140034352527168 train_slot.py:155] Step: 296900, Loss: 0.000899, Time: 19:36:46.847806
I0819 15:55:24.344745 140034352527168 train_slot.py:155] Step: 297000, Loss: 0.000888, Time: 19:37:10.532979
I0819 15:55:24.714449 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-297000
I0819 15:55:25.852634 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 297000
I0819 15:55:49.352720 140034352527168 train_slot.py:155] Step: 297100, Loss: 0.000887, Time: 19:37:35.540951
I0819 15:56:12.788001 140034352527168 train_slot.py:155] Step: 297200, Loss: 0.000890, Time: 19:37:58.976204
I0819 15:56:36.478184 140034352527168 train_slot.py:155] Step: 297300, Loss: 0.000818, Time: 19:38:22.666388
I0819 15:57:00.059188 140034352527168 train_slot.py:155] Step: 297400, Loss: 0.000815, Time: 19:38:46.247391
I0819 15:57:23.537814 140034352527168 train_slot.py:155] Step: 297500, Loss: 0.000892, Time: 19:39:09.725962
I0819 15:57:47.048328 140034352527168 train_slot.py:155] Step: 297600, Loss: 0.000817, Time: 19:39:33.236559
I0819 15:58:10.843570 140034352527168 train_slot.py:155] Step: 297700, Loss: 0.000862, Time: 19:39:57.031776
I0819 15:58:34.326342 140034352527168 train_slot.py:155] Step: 297800, Loss: 0.000760, Time: 19:40:20.514576
I0819 15:58:58.074382 140034352527168 train_slot.py:155] Step: 297900, Loss: 0.000869, Time: 19:40:44.262587
I0819 15:59:21.717061 140034352527168 train_slot.py:155] Step: 298000, Loss: 0.000828, Time: 19:41:07.905200
I0819 15:59:22.049767 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-298000
I0819 15:59:23.187467 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 298000
I0819 15:59:46.641767 140034352527168 train_slot.py:155] Step: 298100, Loss: 0.000917, Time: 19:41:32.830001
I0819 15:59:46.882765 140034352527168 train_slot.py:155] Step: 298100, Loss: 0.001000, Time: 19:41:33.070999
I0819 16:00:10.459783 140034352527168 train_slot.py:155] Step: 298200, Loss: 0.000785, Time: 19:41:56.647957
I0819 16:00:34.002079 140034352527168 train_slot.py:155] Step: 298300, Loss: 0.000773, Time: 19:42:20.190283
I0819 16:00:57.839681 140034352527168 train_slot.py:155] Step: 298400, Loss: 0.000718, Time: 19:42:44.027820
I0819 16:01:21.383331 140034352527168 train_slot.py:155] Step: 298500, Loss: 0.000927, Time: 19:43:07.571484
I0819 16:01:45.027131 140034352527168 train_slot.py:155] Step: 298600, Loss: 0.000829, Time: 19:43:31.215336
I0819 16:02:08.422637 140034352527168 train_slot.py:155] Step: 298700, Loss: 0.000834, Time: 19:43:54.610835
I0819 16:02:31.932484 140034352527168 train_slot.py:155] Step: 298800, Loss: 0.001116, Time: 19:44:18.120709
I0819 16:02:55.376109 140034352527168 train_slot.py:155] Step: 298900, Loss: 0.000871, Time: 19:44:41.564307
I0819 16:03:19.177047 140034352527168 train_slot.py:155] Step: 299000, Loss: 0.000856, Time: 19:45:05.365181
I0819 16:03:19.511956 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-299000
I0819 16:03:20.588900 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 299000
I0819 16:03:44.295963 140034352527168 train_slot.py:155] Step: 299100, Loss: 0.000811, Time: 19:45:30.484117
I0819 16:04:08.163000 140034352527168 train_slot.py:155] Step: 299200, Loss: 0.000853, Time: 19:45:54.351207
I0819 16:04:32.045298 140034352527168 train_slot.py:155] Step: 299300, Loss: 0.000892, Time: 19:46:18.233523
I0819 16:04:56.318460 140034352527168 train_slot.py:155] Step: 299400, Loss: 0.000759, Time: 19:46:42.506589
I0819 16:05:20.421864 140034352527168 train_slot.py:155] Step: 299500, Loss: 0.000816, Time: 19:47:06.610056
I0819 16:05:44.836515 140034352527168 train_slot.py:155] Step: 299600, Loss: 0.000932, Time: 19:47:31.024732
I0819 16:06:08.884135 140034352527168 train_slot.py:155] Step: 299700, Loss: 0.000847, Time: 19:47:55.072336
I0819 16:06:33.202938 140034352527168 train_slot.py:155] Step: 299800, Loss: 0.000764, Time: 19:48:19.391131
I0819 16:06:56.804314 140034352527168 train_slot.py:155] Step: 299900, Loss: 0.000955, Time: 19:48:42.992533
I0819 16:07:20.314201 140034352527168 train_slot.py:155] Step: 300000, Loss: 0.000852, Time: 19:49:06.502418
I0819 16:07:20.643562 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-300000
I0819 16:07:21.789236 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 300000
I0819 16:07:45.541321 140034352527168 train_slot.py:155] Step: 300100, Loss: 0.000774, Time: 19:49:31.729550
I0819 16:08:09.017222 140034352527168 train_slot.py:155] Step: 300200, Loss: 0.000780, Time: 19:49:55.205356
I0819 16:08:32.661026 140034352527168 train_slot.py:155] Step: 300300, Loss: 0.000707, Time: 19:50:18.849230
I0819 16:08:56.215597 140034352527168 train_slot.py:155] Step: 300400, Loss: 0.000860, Time: 19:50:42.403793
I0819 16:09:19.713157 140034352527168 train_slot.py:155] Step: 300500, Loss: 0.001070, Time: 19:51:05.901371
I0819 16:09:43.410551 140034352527168 train_slot.py:155] Step: 300600, Loss: 0.000900, Time: 19:51:29.598689
I0819 16:10:06.902468 140034352527168 train_slot.py:155] Step: 300700, Loss: 0.001015, Time: 19:51:53.090700
I0819 16:10:30.368726 140034352527168 train_slot.py:155] Step: 300800, Loss: 0.000816, Time: 19:52:16.556925
I0819 16:10:53.930399 140034352527168 train_slot.py:155] Step: 300900, Loss: 0.000899, Time: 19:52:40.118588
I0819 16:11:17.467031 140034352527168 train_slot.py:155] Step: 301000, Loss: 0.000828, Time: 19:53:03.655228
I0819 16:11:17.798199 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-301000
I0819 16:11:18.923151 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 301000
I0819 16:11:42.674290 140034352527168 train_slot.py:155] Step: 301100, Loss: 0.000865, Time: 19:53:28.862387
I0819 16:12:06.444935 140034352527168 train_slot.py:155] Step: 301200, Loss: 0.000826, Time: 19:53:52.633044
I0819 16:12:30.196293 140034352527168 train_slot.py:155] Step: 301300, Loss: 0.000855, Time: 19:54:16.384495
I0819 16:12:53.807164 140034352527168 train_slot.py:155] Step: 301400, Loss: 0.000825, Time: 19:54:39.995310
I0819 16:13:17.424704 140034352527168 train_slot.py:155] Step: 301500, Loss: 0.001018, Time: 19:55:03.612925
I0819 16:13:40.911786 140034352527168 train_slot.py:155] Step: 301600, Loss: 0.000800, Time: 19:55:27.099999
I0819 16:14:04.628756 140034352527168 train_slot.py:155] Step: 301700, Loss: 0.000673, Time: 19:55:50.816954
I0819 16:14:28.186873 140034352527168 train_slot.py:155] Step: 301800, Loss: 0.001016, Time: 19:56:14.374862
I0819 16:14:51.654452 140034352527168 train_slot.py:155] Step: 301900, Loss: 0.000992, Time: 19:56:37.842679
I0819 16:15:15.250726 140034352527168 train_slot.py:155] Step: 302000, Loss: 0.000783, Time: 19:57:01.438884
I0819 16:15:15.596611 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-302000
I0819 16:15:16.663005 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 302000
I0819 16:15:40.276458 140034352527168 train_slot.py:155] Step: 302100, Loss: 0.000901, Time: 19:57:26.464684
I0819 16:16:04.146063 140034352527168 train_slot.py:155] Step: 302200, Loss: 0.000755, Time: 19:57:50.334202
I0819 16:16:28.191755 140034352527168 train_slot.py:155] Step: 302300, Loss: 0.000779, Time: 19:58:14.379953
I0819 16:16:51.937852 140034352527168 train_slot.py:155] Step: 302400, Loss: 0.000999, Time: 19:58:38.126084
I0819 16:17:15.827103 140034352527168 train_slot.py:155] Step: 302500, Loss: 0.000951, Time: 19:59:02.015299
I0819 16:17:39.527687 140034352527168 train_slot.py:155] Step: 302600, Loss: 0.000821, Time: 19:59:25.715895
I0819 16:18:03.776871 140034352527168 train_slot.py:155] Step: 302700, Loss: 0.001044, Time: 19:59:49.964996
I0819 16:18:28.862320 140034352527168 train_slot.py:155] Step: 302800, Loss: 0.000782, Time: 20:00:15.050537
I0819 16:18:52.696592 140034352527168 train_slot.py:155] Step: 302900, Loss: 0.000814, Time: 20:00:38.884770
I0819 16:19:16.545147 140034352527168 train_slot.py:155] Step: 303000, Loss: 0.001203, Time: 20:01:02.733374
I0819 16:19:16.970449 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-303000
I0819 16:19:18.081997 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 303000
I0819 16:19:41.943477 140034352527168 train_slot.py:155] Step: 303100, Loss: 0.000823, Time: 20:01:28.131685
I0819 16:20:05.791929 140034352527168 train_slot.py:155] Step: 303200, Loss: 0.000814, Time: 20:01:51.980127
I0819 16:20:29.842533 140034352527168 train_slot.py:155] Step: 303300, Loss: 0.000839, Time: 20:02:16.030646
I0819 16:20:53.956674 140034352527168 train_slot.py:155] Step: 303400, Loss: 0.000900, Time: 20:02:40.144820
I0819 16:21:17.787421 140034352527168 train_slot.py:155] Step: 303500, Loss: 0.000895, Time: 20:03:03.975623
I0819 16:21:41.903400 140034352527168 train_slot.py:155] Step: 303600, Loss: 0.000892, Time: 20:03:28.091629
I0819 16:22:05.767924 140034352527168 train_slot.py:155] Step: 303700, Loss: 0.000876, Time: 20:03:51.956094
I0819 16:22:29.887537 140034352527168 train_slot.py:155] Step: 303800, Loss: 0.000801, Time: 20:04:16.075539
I0819 16:22:53.986464 140034352527168 train_slot.py:155] Step: 303900, Loss: 0.000851, Time: 20:04:40.174674
I0819 16:23:17.887509 140034352527168 train_slot.py:155] Step: 304000, Loss: 0.000834, Time: 20:05:04.075707
I0819 16:23:18.286252 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-304000
I0819 16:23:19.477837 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 304000
I0819 16:23:43.661930 140034352527168 train_slot.py:155] Step: 304100, Loss: 0.000962, Time: 20:05:29.850126
I0819 16:24:07.573733 140034352527168 train_slot.py:155] Step: 304200, Loss: 0.000836, Time: 20:05:53.761962
I0819 16:24:31.428604 140034352527168 train_slot.py:155] Step: 304300, Loss: 0.000849, Time: 20:06:17.616477
I0819 16:24:55.673413 140034352527168 train_slot.py:155] Step: 304400, Loss: 0.000721, Time: 20:06:41.861600
I0819 16:25:19.494173 140034352527168 train_slot.py:155] Step: 304500, Loss: 0.000996, Time: 20:07:05.682371
I0819 16:25:43.440627 140034352527168 train_slot.py:155] Step: 304600, Loss: 0.000991, Time: 20:07:29.628752
I0819 16:26:07.356710 140034352527168 train_slot.py:155] Step: 304700, Loss: 0.000858, Time: 20:07:53.544911
I0819 16:26:31.284789 140034352527168 train_slot.py:155] Step: 304800, Loss: 0.001080, Time: 20:08:17.472978
I0819 16:26:55.326203 140034352527168 train_slot.py:155] Step: 304900, Loss: 0.000849, Time: 20:08:41.514222
I0819 16:27:19.231138 140034352527168 train_slot.py:155] Step: 305000, Loss: 0.000873, Time: 20:09:05.419306
I0819 16:27:19.615236 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-305000
I0819 16:27:20.683551 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 305000
I0819 16:27:44.731627 140034352527168 train_slot.py:155] Step: 305100, Loss: 0.000789, Time: 20:09:30.919831
I0819 16:28:08.589220 140034352527168 train_slot.py:155] Step: 305200, Loss: 0.000976, Time: 20:09:54.777455
I0819 16:28:32.664169 140034352527168 train_slot.py:155] Step: 305300, Loss: 0.000906, Time: 20:10:18.852374
I0819 16:28:56.337519 140034352527168 train_slot.py:155] Step: 305400, Loss: 0.000785, Time: 20:10:42.525734
I0819 16:29:20.030253 140034352527168 train_slot.py:155] Step: 305500, Loss: 0.000856, Time: 20:11:06.218471
I0819 16:29:43.398683 140034352527168 train_slot.py:155] Step: 305600, Loss: 0.000842, Time: 20:11:29.586892
I0819 16:30:06.962669 140034352527168 train_slot.py:155] Step: 305700, Loss: 0.000855, Time: 20:11:53.150884
I0819 16:30:30.479459 140034352527168 train_slot.py:155] Step: 305800, Loss: 0.000871, Time: 20:12:16.667437
I0819 16:30:54.046780 140034352527168 train_slot.py:155] Step: 305900, Loss: 0.001117, Time: 20:12:40.234980
I0819 16:31:17.772629 140034352527168 train_slot.py:155] Step: 306000, Loss: 0.000789, Time: 20:13:03.960864
I0819 16:31:18.094802 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-306000
I0819 16:31:19.222704 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 306000
I0819 16:31:42.740614 140034352527168 train_slot.py:155] Step: 306100, Loss: 0.000849, Time: 20:13:28.928816
I0819 16:32:06.221897 140034352527168 train_slot.py:155] Step: 306200, Loss: 0.000849, Time: 20:13:52.410107
I0819 16:32:29.804899 140034352527168 train_slot.py:155] Step: 306300, Loss: 0.000799, Time: 20:14:15.992356
I0819 16:32:53.525970 140034352527168 train_slot.py:155] Step: 306400, Loss: 0.000876, Time: 20:14:39.714178
I0819 16:33:17.230963 140034352527168 train_slot.py:155] Step: 306500, Loss: 0.000931, Time: 20:15:03.419154
I0819 16:33:40.904525 140034352527168 train_slot.py:155] Step: 306600, Loss: 0.000877, Time: 20:15:27.092721
I0819 16:34:04.449537 140034352527168 train_slot.py:155] Step: 306700, Loss: 0.000842, Time: 20:15:50.637542
I0819 16:34:28.008627 140034352527168 train_slot.py:155] Step: 306800, Loss: 0.001018, Time: 20:16:14.196766
I0819 16:34:51.510866 140034352527168 train_slot.py:155] Step: 306900, Loss: 0.000708, Time: 20:16:37.699095
I0819 16:35:14.921519 140034352527168 train_slot.py:155] Step: 307000, Loss: 0.000906, Time: 20:17:01.109721
I0819 16:35:15.238075 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-307000
I0819 16:35:16.306772 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 307000
I0819 16:35:40.071867 140034352527168 train_slot.py:155] Step: 307100, Loss: 0.000995, Time: 20:17:26.260065
I0819 16:36:03.586657 140034352527168 train_slot.py:155] Step: 307200, Loss: 0.000956, Time: 20:17:49.774887
I0819 16:36:27.072195 140034352527168 train_slot.py:155] Step: 307300, Loss: 0.001171, Time: 20:18:13.260422
I0819 16:36:50.480928 140034352527168 train_slot.py:155] Step: 307400, Loss: 0.000957, Time: 20:18:36.669124
I0819 16:37:14.061398 140034352527168 train_slot.py:155] Step: 307500, Loss: 0.000682, Time: 20:19:00.249597
I0819 16:37:37.624535 140034352527168 train_slot.py:155] Step: 307600, Loss: 0.000715, Time: 20:19:23.812402
I0819 16:38:01.330410 140034352527168 train_slot.py:155] Step: 307700, Loss: 0.000918, Time: 20:19:47.518643
I0819 16:38:24.809937 140034352527168 train_slot.py:155] Step: 307800, Loss: 0.000902, Time: 20:20:10.998143
I0819 16:38:48.358659 140034352527168 train_slot.py:155] Step: 307900, Loss: 0.000760, Time: 20:20:34.546856
I0819 16:39:12.117501 140034352527168 train_slot.py:155] Step: 308000, Loss: 0.000999, Time: 20:20:58.305699
I0819 16:39:12.439251 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-308000
I0819 16:39:13.508512 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 308000
I0819 16:39:36.917060 140034352527168 train_slot.py:155] Step: 308100, Loss: 0.000873, Time: 20:21:23.105271
I0819 16:40:00.700393 140034352527168 train_slot.py:155] Step: 308200, Loss: 0.000805, Time: 20:21:46.888604
I0819 16:40:24.245267 140034352527168 train_slot.py:155] Step: 308300, Loss: 0.000964, Time: 20:22:10.433333
I0819 16:40:47.931804 140034352527168 train_slot.py:155] Step: 308400, Loss: 0.000927, Time: 20:22:34.120016
I0819 16:41:11.373373 140034352527168 train_slot.py:155] Step: 308500, Loss: 0.000803, Time: 20:22:57.561499
I0819 16:41:34.881559 140034352527168 train_slot.py:155] Step: 308600, Loss: 0.000647, Time: 20:23:21.069767
I0819 16:41:58.618100 140034352527168 train_slot.py:155] Step: 308700, Loss: 0.000830, Time: 20:23:44.806319
I0819 16:42:22.115003 140034352527168 train_slot.py:155] Step: 308800, Loss: 0.000832, Time: 20:24:08.303107
I0819 16:42:45.631474 140034352527168 train_slot.py:155] Step: 308900, Loss: 0.000848, Time: 20:24:31.819685
I0819 16:43:09.196994 140034352527168 train_slot.py:155] Step: 309000, Loss: 0.000832, Time: 20:24:55.385225
I0819 16:43:09.574922 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-309000
I0819 16:43:10.701573 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 309000
I0819 16:43:34.267275 140034352527168 train_slot.py:155] Step: 309100, Loss: 0.000854, Time: 20:25:20.455295
I0819 16:43:57.782557 140034352527168 train_slot.py:155] Step: 309200, Loss: 0.000817, Time: 20:25:43.970622
I0819 16:44:21.686431 140034352527168 train_slot.py:155] Step: 309300, Loss: 0.000812, Time: 20:26:07.874631
I0819 16:44:45.175906 140034352527168 train_slot.py:155] Step: 309400, Loss: 0.000834, Time: 20:26:31.364123
I0819 16:45:08.705125 140034352527168 train_slot.py:155] Step: 309500, Loss: 0.000932, Time: 20:26:54.893262
I0819 16:45:32.273534 140034352527168 train_slot.py:155] Step: 309600, Loss: 0.000898, Time: 20:27:18.461754
I0819 16:45:55.822449 140034352527168 train_slot.py:155] Step: 309700, Loss: 0.000874, Time: 20:27:42.010656
I0819 16:46:19.537390 140034352527168 train_slot.py:155] Step: 309800, Loss: 0.000767, Time: 20:28:05.725631
I0819 16:46:43.089349 140034352527168 train_slot.py:155] Step: 309900, Loss: 0.000926, Time: 20:28:29.277560
I0819 16:47:06.840574 140034352527168 train_slot.py:155] Step: 310000, Loss: 0.000719, Time: 20:28:53.028446
I0819 16:47:07.160463 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-310000
I0819 16:47:08.262547 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 310000
I0819 16:47:31.666898 140034352527168 train_slot.py:155] Step: 310100, Loss: 0.000761, Time: 20:29:17.855105
I0819 16:47:55.113526 140034352527168 train_slot.py:155] Step: 310200, Loss: 0.001433, Time: 20:29:41.301741
I0819 16:48:18.605443 140034352527168 train_slot.py:155] Step: 310300, Loss: 0.000843, Time: 20:30:04.793642
I0819 16:48:42.382174 140034352527168 train_slot.py:155] Step: 310400, Loss: 0.000847, Time: 20:30:28.570378
I0819 16:49:05.955010 140034352527168 train_slot.py:155] Step: 310500, Loss: 0.000759, Time: 20:30:52.143135
I0819 16:49:29.433539 140034352527168 train_slot.py:155] Step: 310600, Loss: 0.000863, Time: 20:31:15.621736
I0819 16:49:53.078338 140034352527168 train_slot.py:155] Step: 310700, Loss: 0.000789, Time: 20:31:39.266557
I0819 16:50:16.492377 140034352527168 train_slot.py:155] Step: 310800, Loss: 0.000908, Time: 20:32:02.680506
I0819 16:50:40.362017 140034352527168 train_slot.py:155] Step: 310900, Loss: 0.000856, Time: 20:32:26.550229
I0819 16:51:03.852753 140034352527168 train_slot.py:155] Step: 311000, Loss: 0.000939, Time: 20:32:50.040951
I0819 16:51:04.246651 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-311000
I0819 16:51:05.334366 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 311000
I0819 16:51:29.189647 140034352527168 train_slot.py:155] Step: 311100, Loss: 0.000879, Time: 20:33:15.377844
I0819 16:51:52.892036 140034352527168 train_slot.py:155] Step: 311200, Loss: 0.000902, Time: 20:33:39.080267
I0819 16:52:16.691510 140034352527168 train_slot.py:155] Step: 311300, Loss: 0.000859, Time: 20:34:02.879654
I0819 16:52:40.341045 140034352527168 train_slot.py:155] Step: 311400, Loss: 0.000815, Time: 20:34:26.529246
I0819 16:53:04.576524 140034352527168 train_slot.py:155] Step: 311500, Loss: 0.000815, Time: 20:34:50.764741
I0819 16:53:29.480959 140034352527168 train_slot.py:155] Step: 311600, Loss: 0.000770, Time: 20:35:15.669153
I0819 16:53:53.384213 140034352527168 train_slot.py:155] Step: 311700, Loss: 0.000900, Time: 20:35:39.572108
I0819 16:54:17.230874 140034352527168 train_slot.py:155] Step: 311800, Loss: 0.000864, Time: 20:36:03.419053
I0819 16:54:41.220373 140034352527168 train_slot.py:155] Step: 311900, Loss: 0.000892, Time: 20:36:27.408573
I0819 16:55:05.402982 140034352527168 train_slot.py:155] Step: 312000, Loss: 0.000973, Time: 20:36:51.591190
I0819 16:55:05.795114 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-312000
I0819 16:55:06.967797 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 312000
I0819 16:55:30.953034 140034352527168 train_slot.py:155] Step: 312100, Loss: 0.001115, Time: 20:37:17.141105
I0819 16:55:54.818471 140034352527168 train_slot.py:155] Step: 312200, Loss: 0.001014, Time: 20:37:41.006675
I0819 16:56:18.692646 140034352527168 train_slot.py:155] Step: 312300, Loss: 0.000941, Time: 20:38:04.880873
I0819 16:56:42.735378 140034352527168 train_slot.py:155] Step: 312400, Loss: 0.001103, Time: 20:38:28.923596
I0819 16:57:06.913519 140034352527168 train_slot.py:155] Step: 312500, Loss: 0.000751, Time: 20:38:53.101665
I0819 16:57:30.779605 140034352527168 train_slot.py:155] Step: 312600, Loss: 0.000855, Time: 20:39:16.967639
I0819 16:57:54.622886 140034352527168 train_slot.py:155] Step: 312700, Loss: 0.000954, Time: 20:39:40.811070
I0819 16:58:18.422280 140034352527168 train_slot.py:155] Step: 312800, Loss: 0.000945, Time: 20:40:04.610486
I0819 16:58:42.014433 140034352527168 train_slot.py:155] Step: 312900, Loss: 0.000838, Time: 20:40:28.202667
I0819 16:59:05.530460 140034352527168 train_slot.py:155] Step: 313000, Loss: 0.000809, Time: 20:40:51.718624
I0819 16:59:05.856511 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-313000
I0819 16:59:06.987617 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 313000
I0819 16:59:31.044381 140034352527168 train_slot.py:155] Step: 313100, Loss: 0.000956, Time: 20:41:17.232575
I0819 16:59:54.510309 140034352527168 train_slot.py:155] Step: 313200, Loss: 0.000846, Time: 20:41:40.698517
I0819 17:00:17.974761 140034352527168 train_slot.py:155] Step: 313300, Loss: 0.000743, Time: 20:42:04.162995
I0819 17:00:41.539069 140034352527168 train_slot.py:155] Step: 313400, Loss: 0.000946, Time: 20:42:27.727276
I0819 17:01:05.022328 140034352527168 train_slot.py:155] Step: 313500, Loss: 0.000777, Time: 20:42:51.210564
I0819 17:01:28.784265 140034352527168 train_slot.py:155] Step: 313600, Loss: 0.000986, Time: 20:43:14.972501
I0819 17:01:52.551204 140034352527168 train_slot.py:155] Step: 313700, Loss: 0.000904, Time: 20:43:38.739415
I0819 17:02:16.242465 140034352527168 train_slot.py:155] Step: 313800, Loss: 0.000870, Time: 20:44:02.430699
I0819 17:02:40.078898 140034352527168 train_slot.py:155] Step: 313900, Loss: 0.000944, Time: 20:44:26.266888
I0819 17:03:03.875410 140034352527168 train_slot.py:155] Step: 314000, Loss: 0.000747, Time: 20:44:50.063611
I0819 17:03:04.221397 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-314000
I0819 17:03:05.366131 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 314000
I0819 17:03:29.143065 140034352527168 train_slot.py:155] Step: 314100, Loss: 0.000748, Time: 20:45:15.331272
I0819 17:03:53.266079 140034352527168 train_slot.py:155] Step: 314200, Loss: 0.000860, Time: 20:45:39.454149
I0819 17:04:16.705799 140034352527168 train_slot.py:155] Step: 314300, Loss: 0.000713, Time: 20:46:02.893739
I0819 17:04:40.543386 140034352527168 train_slot.py:155] Step: 314400, Loss: 0.000829, Time: 20:46:26.731579
I0819 17:05:04.016466 140034352527168 train_slot.py:155] Step: 314500, Loss: 0.001033, Time: 20:46:50.204670
I0819 17:05:27.482279 140034352527168 train_slot.py:155] Step: 314600, Loss: 0.000781, Time: 20:47:13.670487
I0819 17:05:51.125982 140034352527168 train_slot.py:155] Step: 314700, Loss: 0.000864, Time: 20:47:37.314210
I0819 17:06:14.843972 140034352527168 train_slot.py:155] Step: 314800, Loss: 0.000797, Time: 20:48:01.031985
I0819 17:06:38.390516 140034352527168 train_slot.py:155] Step: 314900, Loss: 0.000776, Time: 20:48:24.578723
I0819 17:07:01.932692 140034352527168 train_slot.py:155] Step: 315000, Loss: 0.000679, Time: 20:48:48.120903
I0819 17:07:02.293868 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-315000
I0819 17:07:03.366454 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 315000
I0819 17:07:26.994301 140034352527168 train_slot.py:155] Step: 315100, Loss: 0.000808, Time: 20:49:13.182504
I0819 17:07:50.461273 140034352527168 train_slot.py:155] Step: 315200, Loss: 0.000839, Time: 20:49:36.649267
I0819 17:08:14.233150 140034352527168 train_slot.py:155] Step: 315300, Loss: 0.000899, Time: 20:50:00.421322
I0819 17:08:37.800811 140034352527168 train_slot.py:155] Step: 315400, Loss: 0.000793, Time: 20:50:23.989013
I0819 17:09:01.446929 140034352527168 train_slot.py:155] Step: 315500, Loss: 0.000751, Time: 20:50:47.635145
I0819 17:09:25.182164 140034352527168 train_slot.py:155] Step: 315600, Loss: 0.001012, Time: 20:51:11.370266
I0819 17:09:48.648811 140034352527168 train_slot.py:155] Step: 315700, Loss: 0.000937, Time: 20:51:34.837041
I0819 17:10:12.363692 140034352527168 train_slot.py:155] Step: 315800, Loss: 0.000972, Time: 20:51:58.551892
I0819 17:10:35.960945 140034352527168 train_slot.py:155] Step: 315900, Loss: 0.000692, Time: 20:52:22.149146
I0819 17:10:59.480510 140034352527168 train_slot.py:155] Step: 316000, Loss: 0.000818, Time: 20:52:45.668448
I0819 17:10:59.883625 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-316000
I0819 17:11:01.035071 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 316000
I0819 17:11:24.579759 140034352527168 train_slot.py:155] Step: 316100, Loss: 0.000764, Time: 20:53:10.767955
I0819 17:11:48.029832 140034352527168 train_slot.py:155] Step: 316200, Loss: 0.000726, Time: 20:53:34.218063
I0819 17:12:11.862056 140034352527168 train_slot.py:155] Step: 316300, Loss: 0.000703, Time: 20:53:58.050257
I0819 17:12:35.355694 140034352527168 train_slot.py:155] Step: 316400, Loss: 0.000991, Time: 20:54:21.543897
I0819 17:12:58.875326 140034352527168 train_slot.py:155] Step: 316500, Loss: 0.000868, Time: 20:54:45.063309
I0819 17:13:22.393758 140034352527168 train_slot.py:155] Step: 316600, Loss: 0.000922, Time: 20:55:08.581922
I0819 17:13:45.969399 140034352527168 train_slot.py:155] Step: 316700, Loss: 0.000779, Time: 20:55:32.157625
I0819 17:14:09.446830 140034352527168 train_slot.py:155] Step: 316800, Loss: 0.000757, Time: 20:55:55.635061
I0819 17:14:33.197972 140034352527168 train_slot.py:155] Step: 316900, Loss: 0.000943, Time: 20:56:19.386169
I0819 17:14:56.825055 140034352527168 train_slot.py:155] Step: 317000, Loss: 0.000784, Time: 20:56:43.013274
I0819 17:14:57.211854 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-317000
I0819 17:14:58.351343 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 317000
I0819 17:15:21.890501 140034352527168 train_slot.py:155] Step: 317100, Loss: 0.000836, Time: 20:57:08.078634
I0819 17:15:45.329798 140034352527168 train_slot.py:155] Step: 317200, Loss: 0.000831, Time: 20:57:31.518018
I0819 17:16:08.759465 140034352527168 train_slot.py:155] Step: 317300, Loss: 0.000951, Time: 20:57:54.947675
I0819 17:16:32.739302 140034352527168 train_slot.py:155] Step: 317400, Loss: 0.000740, Time: 20:58:18.927520
I0819 17:16:56.367996 140034352527168 train_slot.py:155] Step: 317500, Loss: 0.000682, Time: 20:58:42.556149
I0819 17:17:19.872351 140034352527168 train_slot.py:155] Step: 317600, Loss: 0.001049, Time: 20:59:06.060550
I0819 17:17:20.107806 140034352527168 train_slot.py:155] Step: 317600, Loss: 0.001009, Time: 20:59:06.296024
I0819 17:17:43.587311 140034352527168 train_slot.py:155] Step: 317700, Loss: 0.000954, Time: 20:59:29.775524
I0819 17:18:07.082339 140034352527168 train_slot.py:155] Step: 317800, Loss: 0.000937, Time: 20:59:53.270532
I0819 17:18:30.599519 140034352527168 train_slot.py:155] Step: 317900, Loss: 0.000854, Time: 21:00:16.787750
I0819 17:18:54.226762 140034352527168 train_slot.py:155] Step: 318000, Loss: 0.000806, Time: 21:00:40.414962
I0819 17:18:54.668139 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-318000
I0819 17:18:55.810072 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 318000
I0819 17:19:19.357568 140034352527168 train_slot.py:155] Step: 318100, Loss: 0.000762, Time: 21:01:05.545725
I0819 17:19:43.101169 140034352527168 train_slot.py:155] Step: 318200, Loss: 0.000643, Time: 21:01:29.289367
I0819 17:20:06.599237 140034352527168 train_slot.py:155] Step: 318300, Loss: 0.000817, Time: 21:01:52.787420
I0819 17:20:30.048146 140034352527168 train_slot.py:155] Step: 318400, Loss: 0.000920, Time: 21:02:16.236387
I0819 17:20:53.914976 140034352527168 train_slot.py:155] Step: 318500, Loss: 0.000804, Time: 21:02:40.103195
I0819 17:21:17.352184 140034352527168 train_slot.py:155] Step: 318600, Loss: 0.000698, Time: 21:03:03.540129
I0819 17:21:40.845053 140034352527168 train_slot.py:155] Step: 318700, Loss: 0.000752, Time: 21:03:27.033283
I0819 17:22:04.385833 140034352527168 train_slot.py:155] Step: 318800, Loss: 0.000872, Time: 21:03:50.574052
I0819 17:22:27.868027 140034352527168 train_slot.py:155] Step: 318900, Loss: 0.000870, Time: 21:04:14.056257
I0819 17:22:51.511876 140034352527168 train_slot.py:155] Step: 319000, Loss: 0.000711, Time: 21:04:37.700072
I0819 17:22:51.914860 140034352527168 train_slot.py:163] Saved checkpoint: /mnt/home/test_user01/pr_slot_attention/checkp/checkpoint.ckpt-319000
I0819 17:22:53.058874 140034352527168 train_slot.py:166] Save graph /mnt/home/test_user01/pr_slot_attention/graphcheckp at iteration 319000
I0819 17:23:16.550282 140034352527168 train_slot.py:155] Step: 319100, Loss: 0.000746, Time: 21:05:02.738440
I0819 17:23:40.000103 140034352527168 train_slot.py:155] Step: 319200, Loss: 0.000725, Time: 21:05:26.188283
I0819 17:24:03.486330 140034352527168 train_slot.py:155] Step: 319300, Loss: 0.000793, Time: 21:05:49.674530
