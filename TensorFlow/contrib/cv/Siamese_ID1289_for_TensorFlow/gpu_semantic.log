WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO - SA-Siam-Semantic - Running command 'main'
INFO - SA-Siam-Semantic - Started run with ID "7"
INFO - root - nvidia-ml-py is not installed, automatically select gpu is disabled!
WARNING:tensorflow:From ../train_siamese_model.py:103: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - tensorflow - From ../train_siamese_model.py:103: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

INFO - root - preproces -- siamese_fc_color
WARNING:tensorflow:From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING - tensorflow - From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING:tensorflow:From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING - tensorflow - From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING - tensorflow - From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From ../datasets/transforms.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From ../datasets/transforms.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From ../datasets/transforms.py:51: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From ../datasets/transforms.py:51: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.

WARNING - tensorflow - From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.

WARNING:tensorflow:From ../datasets/dataloader.py:100: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING - tensorflow - From ../datasets/dataloader.py:100: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - embedding init method -- None
WARNING:tensorflow:From ../embeddings/sa_siam.py:208: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING - tensorflow - From ../embeddings/sa_siam.py:208: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO - root - Building Semantic branch of SA-Siam..
WARNING:tensorflow:From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING - tensorflow - From /home/user/anaconda3/envs/ysp4/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
INFO - root - For layer conv4 ...
INFO - root - .. Crop as [0, 7, 15, 22]
INFO - root - .. Max_map.shape = (?, 384, 9)
INFO - root - .. Max_map_fc1.shape = (?, 384, 9)
INFO - root - .. Max_map_fc2.shape = (?, 384, 1)
INFO - root - .. att_map.shape = (?, 1, 1, 384)
INFO - root - For layer conv5 ...
INFO - root - .. Crop as [0, 7, 13, 20]
INFO - root - .. Max_map.shape = (?, 256, 9)
INFO - root - .. Max_map_fc1.shape = (?, 256, 9)
INFO - root - .. Max_map_fc2.shape = (?, 256, 1)
INFO - root - .. att_map.shape = (?, 1, 1, 256)
INFO - root - Keep conv4 .. is_appearance=False shape=[None, 8, 8, 128]
INFO - root - Keep conv5 .. is_appearance=False shape=[None, 6, 6, 128]
INFO - root - Max_feat_size=8
INFO - root - Building Semantic branch of SA-Siam..
INFO - root - Keep conv4 .. is_appearance=False shape=[None, 22, 22, 128]
INFO - root - Keep conv5 .. is_appearance=False shape=[None, 20, 20, 128]
INFO - root - Max_feat_size=22
WARNING:tensorflow:From ../siamese_model.py:122: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING - tensorflow - From ../siamese_model.py:122: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From ../siamese_model.py:124: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING - tensorflow - From ../siamese_model.py:124: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From ../utils/train_utils.py:49: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING - tensorflow - From ../utils/train_utils.py:49: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../siamese_model.py:160: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING - tensorflow - From ../siamese_model.py:160: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From ../siamese_model.py:162: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING - tensorflow - From ../siamese_model.py:162: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING:tensorflow:From ../siamese_model.py:166: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING - tensorflow - From ../siamese_model.py:166: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From ../siamese_model.py:169: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

WARNING - tensorflow - From ../siamese_model.py:169: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

WARNING:tensorflow:From ../siamese_model.py:172: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING - tensorflow - From ../siamese_model.py:172: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From ../siamese_model.py:178: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING - tensorflow - From ../siamese_model.py:178: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From ../metrics/track_metrics.py:116: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - tensorflow - From ../metrics/track_metrics.py:116: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From ../metrics/track_metrics.py:117: The name tf.mod is deprecated. Please use tf.math.mod instead.

WARNING - tensorflow - From ../metrics/track_metrics.py:117: The name tf.mod is deprecated. Please use tf.math.mod instead.

WARNING:tensorflow:From ../siamese_model.py:189: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING - tensorflow - From ../siamese_model.py:189: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

INFO - root - preproces -- None
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - Building Semantic branch of SA-Siam..
INFO - root - For layer conv4 ...
INFO - root - .. Crop as [0, 8, 16, 24]
INFO - root - .. Max_map.shape = (?, 384, 9)
INFO - root - .. Max_map_fc1.shape = (?, 384, 9)
INFO - root - .. Max_map_fc2.shape = (?, 384, 1)
INFO - root - .. att_map.shape = (?, 1, 1, 384)
INFO - root - For layer conv5 ...
INFO - root - .. Crop as [0, 8, 14, 22]
INFO - root - .. Max_map.shape = (?, 256, 9)
INFO - root - .. Max_map_fc1.shape = (?, 256, 9)
INFO - root - .. Max_map_fc2.shape = (?, 256, 1)
INFO - root - .. att_map.shape = (?, 1, 1, 256)
INFO - root - Keep conv4 .. is_appearance=False shape=[None, 8, 8, 128]
INFO - root - Keep conv5 .. is_appearance=False shape=[None, 6, 6, 128]
INFO - root - Max_feat_size=8
INFO - root - Building Semantic branch of SA-Siam..
INFO - root - Keep conv4 .. is_appearance=False shape=[None, 24, 24, 128]
INFO - root - Keep conv5 .. is_appearance=False shape=[None, 22, 22, 128]
INFO - root - Max_feat_size=24
WARNING:tensorflow:From ../train_siamese_model.py:59: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING - tensorflow - From ../train_siamese_model.py:59: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

WARNING:tensorflow:From ../train_siamese_model.py:81: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING - tensorflow - From ../train_siamese_model.py:81: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

INFO - root - Trainable variables:
WARNING:tensorflow:From ../train_siamese_model.py:118: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING - tensorflow - From ../train_siamese_model.py:118: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc1_conv4/weights:0' shape=(9, 9) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc1_conv4/biases:0' shape=(9,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc2_conv4/weights:0' shape=(9, 1) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc2_conv4/biases:0' shape=(1,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc1_conv5/weights:0' shape=(9, 9) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc1_conv5/biases:0' shape=(9,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc2_conv5/weights:0' shape=(9, 1) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/att_fc2_conv5/biases:0' shape=(1,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/c1x1_conv4/weights:0' shape=(1, 1, 384, 128) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/c1x1_conv4/biases:0' shape=(128,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/c1x1_conv5/weights:0' shape=(1, 1, 256, 128) dtype=float32_ref>
INFO - root - -- <tf.Variable 'sa_siam/semantic_net/c1x1_conv5/biases:0' shape=(128,) dtype=float32_ref>
INFO - root - -- <tf.Variable 'detection/biases:0' shape=(1,) dtype=float32_ref>
WARNING:tensorflow:From ../train_siamese_model.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING - tensorflow - From ../train_siamese_model.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../train_siamese_model.py:133: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING - tensorflow - From ../train_siamese_model.py:133: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From ../train_siamese_model.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING - tensorflow - From ../train_siamese_model.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From ../train_siamese_model.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING - tensorflow - From ../train_siamese_model.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From ../train_siamese_model.py:139: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING - tensorflow - From ../train_siamese_model.py:139: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From ../train_siamese_model.py:140: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING - tensorflow - From ../train_siamese_model.py:140: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From ../train_siamese_model.py:143: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING - tensorflow - From ../train_siamese_model.py:143: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From ../train_siamese_model.py:144: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING - tensorflow - From ../train_siamese_model.py:144: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../train_siamese_model.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING - tensorflow - From ../train_siamese_model.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-02-24 19:13:00.701780: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2022-02-24 19:13:00.745357: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2022-02-24 19:13:00.749905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5597e938ff60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-02-24 19:13:00.749931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-02-24 19:13:00.754599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2022-02-24 19:13:01.027587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5597e93ab2a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-02-24 19:13:01.027654: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2022-02-24 19:13:01.030089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:04:00.0
2022-02-24 19:13:01.031006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2022-02-24 19:13:01.038315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2022-02-24 19:13:01.052920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2022-02-24 19:13:01.057311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2022-02-24 19:13:01.064620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2022-02-24 19:13:01.071591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2022-02-24 19:13:01.095265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-24 19:13:01.098551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2022-02-24 19:13:01.099929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2022-02-24 19:13:01.102655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-02-24 19:13:01.102680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2022-02-24 19:13:01.102690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2022-02-24 19:13:01.106639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5408 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
INFO - root - Load object model from ./data/caffenet.npy
INFO - root - Loading: sa_siam/semantic_net/conv3 weights
INFO - root - Loading: sa_siam/semantic_net/conv3 biases
INFO - root - Loading: sa_siam/semantic_net/conv2 b1 weights
INFO - root - Loading: sa_siam/semantic_net/conv2 b2 weights
INFO - root - Loading: sa_siam/semantic_net/conv2 b1 biases
INFO - root - Loading: sa_siam/semantic_net/conv2 b2 biases
INFO - root - Loading: sa_siam/semantic_net/conv1 weights
INFO - root - Loading: sa_siam/semantic_net/conv1 biases
INFO - root - Loading: sa_siam/semantic_net/conv5 b1 weights
INFO - root - Loading: sa_siam/semantic_net/conv5 b2 weights
INFO - root - Loading: sa_siam/semantic_net/conv5 b1 biases
INFO - root - Loading: sa_siam/semantic_net/conv5 b2 biases
INFO - root - Loading: sa_siam/semantic_net/conv4 b1 weights
INFO - root - Loading: sa_siam/semantic_net/conv4 b2 weights
INFO - root - Loading: sa_siam/semantic_net/conv4 b1 biases
INFO - root - Loading: sa_siam/semantic_net/conv4 b2 biases
INFO - root - Train for 199500 steps
2022-02-24 19:13:09.541530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2022-02-24 19:13:10.384445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
INFO - root - 2022-02-24 19:13:13.494403: step 0, total loss = 17.52, batch loss = 17.19 (1.7 examples/sec; 4.733 sec/batch; 262h:16m:37s remains)
INFO - root - 2022-02-24 19:13:15.487782: step 10, total loss = 2.28, batch loss = 1.95 (246.0 examples/sec; 0.033 sec/batch; 1h:48m:07s remains)
INFO - root - 2022-02-24 19:13:15.746015: step 20, total loss = 2.24, batch loss = 1.92 (336.9 examples/sec; 0.024 sec/batch; 1h:18m:57s remains)
INFO - root - 2022-02-24 19:13:16.230751: step 30, total loss = 2.19, batch loss = 1.87 (148.9 examples/sec; 0.054 sec/batch; 2h:58m:39s remains)
INFO - root - 2022-02-24 19:13:16.736483: step 40, total loss = 3.33, batch loss = 3.00 (142.8 examples/sec; 0.056 sec/batch; 3h:06m:13s remains)
INFO - root - 2022-02-24 19:13:17.219083: step 50, total loss = 2.10, batch loss = 1.78 (185.2 examples/sec; 0.043 sec/batch; 2h:23m:35s remains)
INFO - root - 2022-02-24 19:13:17.775034: step 60, total loss = 1.86, batch loss = 1.54 (177.5 examples/sec; 0.045 sec/batch; 2h:29m:46s remains)
INFO - root - 2022-02-24 19:13:18.217443: step 70, total loss = 1.87, batch loss = 1.54 (152.0 examples/sec; 0.053 sec/batch; 2h:54m:59s remains)
INFO - root - 2022-02-24 19:13:18.615610: step 80, total loss = 2.47, batch loss = 2.14 (269.3 examples/sec; 0.030 sec/batch; 1h:38m:43s remains)
INFO - root - 2022-02-24 19:13:19.013102: step 90, total loss = 1.67, batch loss = 1.35 (347.8 examples/sec; 0.023 sec/batch; 1h:16m:27s remains)
INFO - root - 2022-02-24 19:13:19.544824: step 100, total loss = 2.60, batch loss = 2.28 (329.6 examples/sec; 0.024 sec/batch; 1h:20m:40s remains)
INFO - root - 2022-02-24 19:13:20.260522: step 110, total loss = 2.23, batch loss = 1.90 (177.1 examples/sec; 0.045 sec/batch; 2h:30m:04s remains)
INFO - root - 2022-02-24 19:13:20.689930: step 120, total loss = 1.79, batch loss = 1.46 (333.9 examples/sec; 0.024 sec/batch; 1h:19m:36s remains)
INFO - root - 2022-02-24 19:13:21.316784: step 130, total loss = 1.22, batch loss = 0.89 (128.5 examples/sec; 0.062 sec/batch; 3h:26m:55s remains)
INFO - root - 2022-02-24 19:13:21.715273: step 140, total loss = 1.53, batch loss = 1.20 (161.9 examples/sec; 0.049 sec/batch; 2h:44m:09s remains)
INFO - root - 2022-02-24 19:13:22.198272: step 150, total loss = 1.84, batch loss = 1.51 (132.7 examples/sec; 0.060 sec/batch; 3h:20m:21s remains)
INFO - root - 2022-02-24 19:13:22.525876: step 160, total loss = 1.61, batch loss = 1.28 (335.8 examples/sec; 0.024 sec/batch; 1h:19m:09s remains)
INFO - root - 2022-02-24 19:13:22.880604: step 170, total loss = 1.28, batch loss = 0.95 (327.8 examples/sec; 0.024 sec/batch; 1h:21m:05s remains)
INFO - root - 2022-02-24 19:13:23.353642: step 180, total loss = 1.26, batch loss = 0.94 (178.4 examples/sec; 0.045 sec/batch; 2h:28m:56s remains)
INFO - root - 2022-02-24 19:13:23.905956: step 190, total loss = 1.46, batch loss = 1.13 (127.8 examples/sec; 0.063 sec/batch; 3h:27m:58s remains)
INFO - root - 2022-02-24 19:13:24.359141: step 200, total loss = 1.67, batch loss = 1.34 (114.6 examples/sec; 0.070 sec/batch; 3h:51m:46s remains)
INFO - root - 2022-02-24 19:13:24.912792: step 210, total loss = 1.66, batch loss = 1.33 (337.2 examples/sec; 0.024 sec/batch; 1h:18m:48s remains)
INFO - root - 2022-02-24 19:13:25.265690: step 220, total loss = 1.42, batch loss = 1.09 (121.7 examples/sec; 0.066 sec/batch; 3h:38m:20s remains)
INFO - root - 2022-02-24 19:13:25.860612: step 230, total loss = 1.61, batch loss = 1.29 (162.5 examples/sec; 0.049 sec/batch; 2h:43m:28s remains)
INFO - root - 2022-02-24 19:13:26.418333: step 240, total loss = 1.49, batch loss = 1.16 (168.1 examples/sec; 0.048 sec/batch; 2h:38m:04s remains)
INFO - root - 2022-02-24 19:13:27.044767: step 250, total loss = 1.39, batch loss = 1.07 (171.2 examples/sec; 0.047 sec/batch; 2h:35m:13s remains)
INFO - root - 2022-02-24 19:13:27.595299: step 260, total loss = 1.41, batch loss = 1.09 (131.3 examples/sec; 0.061 sec/batch; 3h:22m:22s remains)
INFO - root - 2022-02-24 19:13:28.078657: step 270, total loss = 1.98, batch loss = 1.65 (149.9 examples/sec; 0.053 sec/batch; 2h:57m:11s remains)
INFO - root - 2022-02-24 19:13:28.590162: step 280, total loss = 1.47, batch loss = 1.15 (166.1 examples/sec; 0.048 sec/batch; 2h:39m:54s remains)
INFO - root - 2022-02-24 19:13:29.063288: step 290, total loss = 1.41, batch loss = 1.09 (218.6 examples/sec; 0.037 sec/batch; 2h:01m:29s remains)
INFO - root - 2022-02-24 19:13:29.459588: step 300, total loss = 1.21, batch loss = 0.89 (179.1 examples/sec; 0.045 sec/batch; 2h:28m:18s remains)
INFO - root - 2022-02-24 19:13:29.966081: step 310, total loss = 1.07, batch loss = 0.75 (190.4 examples/sec; 0.042 sec/batch; 2h:19m:28s remains)
INFO - root - 2022-02-24 19:13:30.487718: step 320, total loss = 1.20, batch loss = 0.88 (118.0 examples/sec; 0.068 sec/batch; 3h:44m:59s remains)
INFO - root - 2022-02-24 19:13:30.969873: step 330, total loss = 1.25, batch loss = 0.92 (319.4 examples/sec; 0.025 sec/batch; 1h:23m:08s remains)
INFO - root - 2022-02-24 19:13:31.383493: step 340, total loss = 1.08, batch loss = 0.75 (119.3 examples/sec; 0.067 sec/batch; 3h:42m:32s remains)
INFO - root - 2022-02-24 19:13:31.835892: step 350, total loss = 1.07, batch loss = 0.74 (314.4 examples/sec; 0.025 sec/batch; 1h:24m:27s remains)
INFO - root - 2022-02-24 19:13:32.384073: step 360, total loss = 1.05, batch loss = 0.72 (180.4 examples/sec; 0.044 sec/batch; 2h:27m:13s remains)
INFO - root - 2022-02-24 19:13:33.106228: step 370, total loss = 1.25, batch loss = 0.93 (264.9 examples/sec; 0.030 sec/batch; 1h:40m:13s remains)
INFO - root - 2022-02-24 19:13:33.464892: step 380, total loss = 1.06, batch loss = 0.74 (166.6 examples/sec; 0.048 sec/batch; 2h:39m:18s remains)
INFO - root - 2022-02-24 19:13:33.809790: step 390, total loss = 1.02, batch loss = 0.69 (323.1 examples/sec; 0.025 sec/batch; 1h:22m:09s remains)
INFO - root - 2022-02-24 19:13:34.247116: step 400, total loss = 1.28, batch loss = 0.96 (133.1 examples/sec; 0.060 sec/batch; 3h:19m:29s remains)
INFO - root - 2022-02-24 19:13:34.868169: step 410, total loss = 1.25, batch loss = 0.93 (205.2 examples/sec; 0.039 sec/batch; 2h:09m:20s remains)
INFO - root - 2022-02-24 19:13:35.308075: step 420, total loss = 1.15, batch loss = 0.83 (263.9 examples/sec; 0.030 sec/batch; 1h:40m:34s remains)
INFO - root - 2022-02-24 19:13:35.822172: step 430, total loss = 1.30, batch loss = 0.98 (150.6 examples/sec; 0.053 sec/batch; 2h:56m:15s remains)
INFO - root - 2022-02-24 19:13:36.184004: step 440, total loss = 1.09, batch loss = 0.77 (116.3 examples/sec; 0.069 sec/batch; 3h:48m:16s remains)
INFO - root - 2022-02-24 19:13:36.574061: step 450, total loss = 1.05, batch loss = 0.72 (166.5 examples/sec; 0.048 sec/batch; 2h:39m:22s remains)
INFO - root - 2022-02-24 19:13:36.965766: step 460, total loss = 1.64, batch loss = 1.31 (116.3 examples/sec; 0.069 sec/batch; 3h:48m:06s remains)
INFO - root - 2022-02-24 19:13:37.463975: step 470, total loss = 1.12, batch loss = 0.80 (74.2 examples/sec; 0.108 sec/batch; 5h:57m:41s remains)
INFO - root - 2022-02-24 19:13:37.965784: step 480, total loss = 1.18, batch loss = 0.85 (70.0 examples/sec; 0.114 sec/batch; 6h:19m:19s remains)
INFO - root - 2022-02-24 19:13:38.401489: step 490, total loss = 1.45, batch loss = 1.13 (103.0 examples/sec; 0.078 sec/batch; 4h:17m:38s remains)
INFO - root - 2022-02-24 19:13:38.917856: step 500, total loss = 1.10, batch loss = 0.77 (286.5 examples/sec; 0.028 sec/batch; 1h:32m:36s remains)
INFO - root - 2022-02-24 19:13:39.532143: step 510, total loss = 1.02, batch loss = 0.70 (120.0 examples/sec; 0.067 sec/batch; 3h:41m:04s remains)
INFO - root - 2022-02-24 19:13:40.065284: step 520, total loss = 1.68, batch loss = 1.36 (257.2 examples/sec; 0.031 sec/batch; 1h:43m:08s remains)
INFO - root - 2022-02-24 19:13:40.503281: step 530, total loss = 1.00, batch loss = 0.68 (189.3 examples/sec; 0.042 sec/batch; 2h:20m:09s remains)
INFO - root - 2022-02-24 19:13:40.807610: step 540, total loss = 1.54, batch loss = 1.22 (271.4 examples/sec; 0.029 sec/batch; 1h:37m:43s remains)
INFO - root - 2022-02-24 19:13:41.355506: step 550, total loss = 1.08, batch loss = 0.76 (200.6 examples/sec; 0.040 sec/batch; 2h:12m:16s remains)
INFO - root - 2022-02-24 19:13:41.847471: step 560, total loss = 1.20, batch loss = 0.88 (184.0 examples/sec; 0.043 sec/batch; 2h:24m:10s remains)
INFO - root - 2022-02-24 19:13:42.323490: step 570, total loss = 0.93, batch loss = 0.60 (209.8 examples/sec; 0.038 sec/batch; 2h:06m:27s remains)
INFO - root - 2022-02-24 19:13:42.729075: step 580, total loss = 1.02, batch loss = 0.69 (206.6 examples/sec; 0.039 sec/batch; 2h:08m:20s remains)
INFO - root - 2022-02-24 19:13:43.148515: step 590, total loss = 1.01, batch loss = 0.69 (252.6 examples/sec; 0.032 sec/batch; 1h:44m:59s remains)
INFO - root - 2022-02-24 19:13:43.708484: step 600, total loss = 1.07, batch loss = 0.75 (165.3 examples/sec; 0.048 sec/batch; 2h:40m:27s remains)
INFO - root - 2022-02-24 19:13:44.531295: step 610, total loss = 1.15, batch loss = 0.82 (333.4 examples/sec; 0.024 sec/batch; 1h:19m:32s remains)
INFO - root - 2022-02-24 19:13:44.929329: step 620, total loss = 1.03, batch loss = 0.71 (348.3 examples/sec; 0.023 sec/batch; 1h:16m:07s remains)
INFO - root - 2022-02-24 19:13:45.376564: step 630, total loss = 1.10, batch loss = 0.78 (187.4 examples/sec; 0.043 sec/batch; 2h:21m:31s remains)
INFO - root - 2022-02-24 19:13:45.758218: step 640, total loss = 1.25, batch loss = 0.93 (152.0 examples/sec; 0.053 sec/batch; 2h:54m:28s remains)
INFO - root - 2022-02-24 19:13:46.145483: step 650, total loss = 1.33, batch loss = 1.01 (178.7 examples/sec; 0.045 sec/batch; 2h:28m:21s remains)
INFO - root - 2022-02-24 19:13:46.668264: step 660, total loss = 1.24, batch loss = 0.92 (219.0 examples/sec; 0.037 sec/batch; 2h:01m:02s remains)
INFO - root - 2022-02-24 19:13:47.108531: step 670, total loss = 1.20, batch loss = 0.88 (178.7 examples/sec; 0.045 sec/batch; 2h:28m:23s remains)
INFO - root - 2022-02-24 19:13:47.546969: step 680, total loss = 1.94, batch loss = 1.62 (150.8 examples/sec; 0.053 sec/batch; 2h:55m:44s remains)
INFO - root - 2022-02-24 19:13:47.939402: step 690, total loss = 1.26, batch loss = 0.94 (140.0 examples/sec; 0.057 sec/batch; 3h:09m:20s remains)
INFO - root - 2022-02-24 19:13:48.478605: step 700, total loss = 0.93, batch loss = 0.60 (102.9 examples/sec; 0.078 sec/batch; 4h:17m:34s remains)
INFO - root - 2022-02-24 19:13:49.032492: step 710, total loss = 1.09, batch loss = 0.77 (134.4 examples/sec; 0.060 sec/batch; 3h:17m:12s remains)
INFO - root - 2022-02-24 19:13:49.428410: step 720, total loss = 0.97, batch loss = 0.65 (203.5 examples/sec; 0.039 sec/batch; 2h:10m:15s remains)
INFO - root - 2022-02-24 19:13:49.876538: step 730, total loss = 0.94, batch loss = 0.62 (148.8 examples/sec; 0.054 sec/batch; 2h:58m:05s remains)
INFO - root - 2022-02-24 19:13:50.305607: step 740, total loss = 0.81, batch loss = 0.49 (254.4 examples/sec; 0.031 sec/batch; 1h:44m:09s remains)
INFO - root - 2022-02-24 19:13:50.786199: step 750, total loss = 1.07, batch loss = 0.75 (126.4 examples/sec; 0.063 sec/batch; 3h:29m:41s remains)
INFO - root - 2022-02-24 19:13:51.295593: step 760, total loss = 0.93, batch loss = 0.61 (271.3 examples/sec; 0.029 sec/batch; 1h:37m:39s remains)
INFO - root - 2022-02-24 19:13:51.741994: step 770, total loss = 0.92, batch loss = 0.60 (177.7 examples/sec; 0.045 sec/batch; 2h:29m:09s remains)
INFO - root - 2022-02-24 19:13:52.088595: step 780, total loss = 1.12, batch loss = 0.80 (299.0 examples/sec; 0.027 sec/batch; 1h:28m:36s remains)
INFO - root - 2022-02-24 19:13:52.442961: step 790, total loss = 0.94, batch loss = 0.62 (172.5 examples/sec; 0.046 sec/batch; 2h:33m:34s remains)
INFO - root - 2022-02-24 19:13:53.004571: step 800, total loss = 1.04, batch loss = 0.71 (236.6 examples/sec; 0.034 sec/batch; 1h:51m:58s remains)
INFO - root - 2022-02-24 19:13:53.443001: step 810, total loss = 1.07, batch loss = 0.75 (300.4 examples/sec; 0.027 sec/batch; 1h:28m:11s remains)
INFO - root - 2022-02-24 19:13:54.103699: step 820, total loss = 0.98, batch loss = 0.66 (29.2 examples/sec; 0.274 sec/batch; 15h:07m:03s remains)
INFO - root - 2022-02-24 19:13:54.505382: step 830, total loss = 0.92, batch loss = 0.59 (153.0 examples/sec; 0.052 sec/batch; 2h:53m:11s remains)
INFO - root - 2022-02-24 19:13:54.998402: step 840, total loss = 0.80, batch loss = 0.48 (96.2 examples/sec; 0.083 sec/batch; 4h:35m:26s remains)
INFO - root - 2022-02-24 19:13:55.458172: step 850, total loss = 1.03, batch loss = 0.71 (214.6 examples/sec; 0.037 sec/batch; 2h:03m:24s remains)
INFO - root - 2022-02-24 19:13:55.974254: step 860, total loss = 0.89, batch loss = 0.57 (201.5 examples/sec; 0.040 sec/batch; 2h:11m:26s remains)
INFO - root - 2022-02-24 19:13:56.421391: step 870, total loss = 0.96, batch loss = 0.64 (179.5 examples/sec; 0.045 sec/batch; 2h:27m:30s remains)
INFO - root - 2022-02-24 19:13:56.887337: step 880, total loss = 0.76, batch loss = 0.44 (145.3 examples/sec; 0.055 sec/batch; 3h:02m:17s remains)
INFO - root - 2022-02-24 19:13:57.383101: step 890, total loss = 0.92, batch loss = 0.60 (99.5 examples/sec; 0.080 sec/batch; 4h:26m:05s remains)
INFO - root - 2022-02-24 19:13:57.870317: step 900, total loss = 1.00, batch loss = 0.68 (344.3 examples/sec; 0.023 sec/batch; 1h:16m:54s remains)
INFO - root - 2022-02-24 19:13:58.413219: step 910, total loss = 0.76, batch loss = 0.43 (179.8 examples/sec; 0.045 sec/batch; 2h:27m:17s remains)
INFO - root - 2022-02-24 19:13:58.802024: step 920, total loss = 1.04, batch loss = 0.72 (114.9 examples/sec; 0.070 sec/batch; 3h:50m:22s remains)
INFO - root - 2022-02-24 19:13:59.271435: step 930, total loss = 0.89, batch loss = 0.57 (151.8 examples/sec; 0.053 sec/batch; 2h:54m:26s remains)
INFO - root - 2022-02-24 19:13:59.793870: step 940, total loss = 1.28, batch loss = 0.96 (225.2 examples/sec; 0.036 sec/batch; 1h:57m:33s remains)
INFO - root - 2022-02-24 19:14:00.257347: step 950, total loss = 0.84, batch loss = 0.52 (225.6 examples/sec; 0.035 sec/batch; 1h:57m:19s remains)
INFO - root - 2022-02-24 19:14:00.670768: step 960, total loss = 1.18, batch loss = 0.86 (287.4 examples/sec; 0.028 sec/batch; 1h:32m:06s remains)
INFO - root - 2022-02-24 19:14:01.051404: step 970, total loss = 1.38, batch loss = 1.06 (318.9 examples/sec; 0.025 sec/batch; 1h:23m:00s remains)
INFO - root - 2022-02-24 19:14:01.374939: step 980, total loss = 1.02, batch loss = 0.70 (164.0 examples/sec; 0.049 sec/batch; 2h:41m:23s remains)
INFO - root - 2022-02-24 19:14:01.863563: step 990, total loss = 1.06, batch loss = 0.74 (161.8 examples/sec; 0.049 sec/batch; 2h:43m:36s remains)
INFO - root - 2022-02-24 19:14:02.382921: step 1000, total loss = 1.16, batch loss = 0.84 (193.6 examples/sec; 0.041 sec/batch; 2h:16m:44s remains)
INFO - root - 2022-02-24 19:14:02.916847: step 1010, total loss = 1.34, batch loss = 1.02 (225.7 examples/sec; 0.035 sec/batch; 1h:57m:14s remains)
INFO - root - 2022-02-24 19:14:03.368454: step 1020, total loss = 0.83, batch loss = 0.51 (201.1 examples/sec; 0.040 sec/batch; 2h:11m:37s remains)
INFO - root - 2022-02-24 19:14:03.780874: step 1030, total loss = 0.81, batch loss = 0.49 (243.3 examples/sec; 0.033 sec/batch; 1h:48m:47s remains)
INFO - root - 2022-02-24 19:14:04.487710: step 1040, total loss = 0.88, batch loss = 0.56 (302.7 examples/sec; 0.026 sec/batch; 1h:27m:25s remains)
INFO - root - 2022-02-24 19:14:05.067262: step 1050, total loss = 0.81, batch loss = 0.49 (127.2 examples/sec; 0.063 sec/batch; 3h:28m:02s remains)
INFO - root - 2022-02-24 19:14:05.491958: step 1060, total loss = 1.18, batch loss = 0.86 (149.0 examples/sec; 0.054 sec/batch; 2h:57m:37s remains)
INFO - root - 2022-02-24 19:14:05.908316: step 1070, total loss = 1.16, batch loss = 0.84 (317.6 examples/sec; 0.025 sec/batch; 1h:23m:18s remains)
INFO - root - 2022-02-24 19:14:06.458944: step 1080, total loss = 1.27, batch loss = 0.95 (166.6 examples/sec; 0.048 sec/batch; 2h:38m:47s remains)
INFO - root - 2022-02-24 19:14:06.999753: step 1090, total loss = 0.82, batch loss = 0.50 (254.7 examples/sec; 0.031 sec/batch; 1h:43m:52s remains)
INFO - root - 2022-02-24 19:14:07.437778: step 1100, total loss = 0.93, batch loss = 0.61 (268.5 examples/sec; 0.030 sec/batch; 1h:38m:30s remains)
INFO - root - 2022-02-24 19:14:07.986888: step 1110, total loss = 0.84, batch loss = 0.52 (251.8 examples/sec; 0.032 sec/batch; 1h:45m:03s remains)
INFO - root - 2022-02-24 19:14:08.496144: step 1120, total loss = 1.18, batch loss = 0.86 (93.7 examples/sec; 0.085 sec/batch; 4h:42m:10s remains)
INFO - root - 2022-02-24 19:14:09.409407: step 1130, total loss = 0.86, batch loss = 0.54 (17.4 examples/sec; 0.459 sec/batch; 25h:17m:55s remains)
INFO - root - 2022-02-24 19:14:09.877137: step 1140, total loss = 0.88, batch loss = 0.57 (96.9 examples/sec; 0.083 sec/batch; 4h:32m:58s remains)
INFO - root - 2022-02-24 19:14:10.342673: step 1150, total loss = 1.01, batch loss = 0.69 (125.1 examples/sec; 0.064 sec/batch; 3h:31m:25s remains)
INFO - root - 2022-02-24 19:14:10.776165: step 1160, total loss = 0.96, batch loss = 0.64 (149.3 examples/sec; 0.054 sec/batch; 2h:57m:07s remains)
INFO - root - 2022-02-24 19:14:11.176527: step 1170, total loss = 1.08, batch loss = 0.76 (162.4 examples/sec; 0.049 sec/batch; 2h:42m:51s remains)
INFO - root - 2022-02-24 19:14:11.654320: step 1180, total loss = 0.99, batch loss = 0.67 (323.6 examples/sec; 0.025 sec/batch; 1h:21m:42s remains)
INFO - root - 2022-02-24 19:14:12.147569: step 1190, total loss = 1.17, batch loss = 0.85 (314.6 examples/sec; 0.025 sec/batch; 1h:24m:03s remains)
INFO - root - 2022-02-24 19:14:12.535536: step 1200, total loss = 0.85, batch loss = 0.53 (241.1 examples/sec; 0.033 sec/batch; 1h:49m:40s remains)
INFO - root - 2022-02-24 19:14:13.002964: step 1210, total loss = 0.88, batch loss = 0.56 (168.8 examples/sec; 0.047 sec/batch; 2h:36m:37s remains)
INFO - root - 2022-02-24 19:14:13.428878: step 1220, total loss = 0.84, batch loss = 0.52 (209.7 examples/sec; 0.038 sec/batch; 2h:06m:03s remains)
INFO - root - 2022-02-24 19:14:13.950603: step 1230, total loss = 0.87, batch loss = 0.55 (118.6 examples/sec; 0.067 sec/batch; 3h:42m:59s remains)
INFO - root - 2022-02-24 19:14:14.585964: step 1240, total loss = 0.90, batch loss = 0.58 (230.2 examples/sec; 0.035 sec/batch; 1h:54m:49s remains)
INFO - root - 2022-02-24 19:14:14.974644: step 1250, total loss = 0.80, batch loss = 0.48 (226.3 examples/sec; 0.035 sec/batch; 1h:56m:48s remains)
INFO - root - 2022-02-24 19:14:15.333465: step 1260, total loss = 0.84, batch loss = 0.52 (287.1 examples/sec; 0.028 sec/batch; 1h:32m:04s remains)
INFO - root - 2022-02-24 19:14:15.725593: step 1270, total loss = 0.75, batch loss = 0.44 (273.6 examples/sec; 0.029 sec/batch; 1h:36m:36s remains)
INFO - root - 2022-02-24 19:14:16.185669: step 1280, total loss = 0.88, batch loss = 0.56 (98.7 examples/sec; 0.081 sec/batch; 4h:27m:42s remains)
INFO - root - 2022-02-24 19:14:16.713081: step 1290, total loss = 0.74, batch loss = 0.42 (208.1 examples/sec; 0.038 sec/batch; 2h:07m:01s remains)
INFO - root - 2022-02-24 19:14:17.126435: step 1300, total loss = 0.82, batch loss = 0.50 (157.9 examples/sec; 0.051 sec/batch; 2h:47m:22s remains)
INFO - root - 2022-02-24 19:14:17.675239: step 1310, total loss = 0.80, batch loss = 0.48 (218.3 examples/sec; 0.037 sec/batch; 2h:01m:03s remains)
INFO - root - 2022-02-24 19:14:18.270929: step 1320, total loss = 1.25, batch loss = 0.93 (323.5 examples/sec; 0.025 sec/batch; 1h:21m:40s remains)
INFO - root - 2022-02-24 19:14:18.815898: step 1330, total loss = 0.74, batch loss = 0.42 (226.3 examples/sec; 0.035 sec/batch; 1h:56m:44s remains)
INFO - root - 2022-02-24 19:14:19.882173: step 1340, total loss = 0.77, batch loss = 0.45 (171.0 examples/sec; 0.047 sec/batch; 2h:34m:31s remains)
INFO - root - 2022-02-24 19:14:20.359717: step 1350, total loss = 0.75, batch loss = 0.43 (121.7 examples/sec; 0.066 sec/batch; 3h:37m:08s remains)
INFO - root - 2022-02-24 19:14:20.780623: step 1360, total loss = 0.78, batch loss = 0.46 (228.6 examples/sec; 0.035 sec/batch; 1h:55m:34s remains)
INFO - root - 2022-02-24 19:14:21.290941: step 1370, total loss = 0.85, batch loss = 0.53 (129.1 examples/sec; 0.062 sec/batch; 3h:24m:35s remains)
INFO - root - 2022-02-24 19:14:21.752180: step 1380, total loss = 0.81, batch loss = 0.49 (166.6 examples/sec; 0.048 sec/batch; 2h:38m:35s remains)
INFO - root - 2022-02-24 19:14:22.276754: step 1390, total loss = 1.02, batch loss = 0.70 (307.2 examples/sec; 0.026 sec/batch; 1h:25m:59s remains)
INFO - root - 2022-02-24 19:14:22.662009: step 1400, total loss = 0.93, batch loss = 0.61 (303.4 examples/sec; 0.026 sec/batch; 1h:27m:04s remains)
INFO - root - 2022-02-24 19:14:23.299112: step 1410, total loss = 0.90, batch loss = 0.58 (185.3 examples/sec; 0.043 sec/batch; 2h:22m:29s remains)
INFO - root - 2022-02-24 19:14:23.786644: step 1420, total loss = 0.86, batch loss = 0.54 (172.8 examples/sec; 0.046 sec/batch; 2h:32m:52s remains)
INFO - root - 2022-02-24 19:14:24.301978: step 1430, total loss = 0.89, batch loss = 0.57 (189.3 examples/sec; 0.042 sec/batch; 2h:19m:32s remains)
INFO - root - 2022-02-24 19:14:24.900814: step 1440, total loss = 1.10, batch loss = 0.78 (129.7 examples/sec; 0.062 sec/batch; 3h:23m:34s remains)
INFO - root - 2022-02-24 19:14:25.464406: step 1450, total loss = 0.96, batch loss = 0.64 (298.0 examples/sec; 0.027 sec/batch; 1h:28m:37s remains)
INFO - root - 2022-02-24 19:14:25.872335: step 1460, total loss = 0.81, batch loss = 0.49 (240.6 examples/sec; 0.033 sec/batch; 1h:49m:44s remains)
INFO - root - 2022-02-24 19:14:26.415848: step 1470, total loss = 0.76, batch loss = 0.44 (180.1 examples/sec; 0.044 sec/batch; 2h:26m:34s remains)
INFO - root - 2022-02-24 19:14:26.873464: step 1480, total loss = 1.04, batch loss = 0.72 (112.8 examples/sec; 0.071 sec/batch; 3h:53m:58s remains)
INFO - root - 2022-02-24 19:14:27.309447: step 1490, total loss = 0.91, batch loss = 0.59 (164.5 examples/sec; 0.049 sec/batch; 2h:40m:27s remains)
INFO - root - 2022-02-24 19:14:27.809862: step 1500, total loss = 0.97, batch loss = 0.65 (142.8 examples/sec; 0.056 sec/batch; 3h:04m:54s remains)
INFO - root - 2022-02-24 19:14:28.392466: step 1510, total loss = 0.77, batch loss = 0.45 (301.3 examples/sec; 0.027 sec/batch; 1h:27m:37s remains)
INFO - root - 2022-02-24 19:14:28.815378: step 1520, total loss = 0.99, batch loss = 0.67 (217.7 examples/sec; 0.037 sec/batch; 2h:01m:15s remains)
INFO - root - 2022-02-24 19:14:29.222397: step 1530, total loss = 0.75, batch loss = 0.43 (180.1 examples/sec; 0.044 sec/batch; 2h:26m:36s remains)
INFO - root - 2022-02-24 19:14:29.694696: step 1540, total loss = 0.82, batch loss = 0.50 (81.6 examples/sec; 0.098 sec/batch; 5h:23m:17s remains)
INFO - root - 2022-02-24 19:14:30.152045: step 1550, total loss = 0.76, batch loss = 0.44 (357.0 examples/sec; 0.022 sec/batch; 1h:13m:55s remains)
INFO - root - 2022-02-24 19:14:30.688439: step 1560, total loss = 0.80, batch loss = 0.48 (150.2 examples/sec; 0.053 sec/batch; 2h:55m:39s remains)
INFO - root - 2022-02-24 19:14:31.154728: step 1570, total loss = 0.67, batch loss = 0.35 (269.7 examples/sec; 0.030 sec/batch; 1h:37m:51s remains)
INFO - root - 2022-02-24 19:14:31.529676: step 1580, total loss = 0.92, batch loss = 0.60 (353.3 examples/sec; 0.023 sec/batch; 1h:14m:42s remains)
INFO - root - 2022-02-24 19:14:31.903786: step 1590, total loss = 0.93, batch loss = 0.61 (177.0 examples/sec; 0.045 sec/batch; 2h:29m:07s remains)
INFO - root - 2022-02-24 19:14:32.415228: step 1600, total loss = 0.88, batch loss = 0.56 (73.2 examples/sec; 0.109 sec/batch; 6h:00m:32s remains)
INFO - root - 2022-02-24 19:14:33.003857: step 1610, total loss = 0.74, batch loss = 0.43 (120.4 examples/sec; 0.066 sec/batch; 3h:39m:06s remains)
INFO - root - 2022-02-24 19:14:33.396161: step 1620, total loss = 0.75, batch loss = 0.43 (159.0 examples/sec; 0.050 sec/batch; 2h:45m:55s remains)
INFO - root - 2022-02-24 19:14:33.783629: step 1630, total loss = 0.86, batch loss = 0.54 (257.2 examples/sec; 0.031 sec/batch; 1h:42m:35s remains)
INFO - root - 2022-02-24 19:14:34.212692: step 1640, total loss = 0.73, batch loss = 0.42 (193.7 examples/sec; 0.041 sec/batch; 2h:16m:10s remains)
INFO - root - 2022-02-24 19:14:34.766832: step 1650, total loss = 0.89, batch loss = 0.58 (248.9 examples/sec; 0.032 sec/batch; 1h:46m:00s remains)
INFO - root - 2022-02-24 19:14:35.292989: step 1660, total loss = 0.79, batch loss = 0.47 (282.9 examples/sec; 0.028 sec/batch; 1h:33m:13s remains)
INFO - root - 2022-02-24 19:14:35.777544: step 1670, total loss = 0.83, batch loss = 0.52 (153.7 examples/sec; 0.052 sec/batch; 2h:51m:37s remains)
INFO - root - 2022-02-24 19:14:36.348036: step 1680, total loss = 1.04, batch loss = 0.72 (145.1 examples/sec; 0.055 sec/batch; 3h:01m:45s remains)
INFO - root - 2022-02-24 19:14:37.028854: step 1690, total loss = 0.85, batch loss = 0.54 (252.8 examples/sec; 0.032 sec/batch; 1h:44m:20s remains)
INFO - root - 2022-02-24 19:14:37.671695: step 1700, total loss = 1.07, batch loss = 0.75 (56.7 examples/sec; 0.141 sec/batch; 7h:45m:18s remains)
INFO - root - 2022-02-24 19:14:38.294704: step 1710, total loss = 0.80, batch loss = 0.49 (192.5 examples/sec; 0.042 sec/batch; 2h:16m:58s remains)
INFO - root - 2022-02-24 19:14:38.884125: step 1720, total loss = 0.93, batch loss = 0.61 (122.6 examples/sec; 0.065 sec/batch; 3h:35m:07s remains)
INFO - root - 2022-02-24 19:14:39.467001: step 1730, total loss = 0.74, batch loss = 0.43 (150.5 examples/sec; 0.053 sec/batch; 2h:55m:10s remains)
INFO - root - 2022-02-24 19:14:40.334774: step 1740, total loss = 0.78, batch loss = 0.47 (288.3 examples/sec; 0.028 sec/batch; 1h:31m:27s remains)
INFO - root - 2022-02-24 19:14:40.818133: step 1750, total loss = 0.70, batch loss = 0.38 (123.4 examples/sec; 0.065 sec/batch; 3h:33m:35s remains)
INFO - root - 2022-02-24 19:14:41.320881: step 1760, total loss = 0.88, batch loss = 0.56 (296.3 examples/sec; 0.027 sec/batch; 1h:28m:58s remains)
INFO - root - 2022-02-24 19:14:41.816962: step 1770, total loss = 0.71, batch loss = 0.40 (175.7 examples/sec; 0.046 sec/batch; 2h:30m:03s remains)
INFO - root - 2022-02-24 19:14:42.254778: step 1780, total loss = 0.88, batch loss = 0.56 (206.4 examples/sec; 0.039 sec/batch; 2h:07m:43s remains)
INFO - root - 2022-02-24 19:14:42.636130: step 1790, total loss = 0.88, batch loss = 0.57 (322.8 examples/sec; 0.025 sec/batch; 1h:21m:39s remains)
INFO - root - 2022-02-24 19:14:43.146453: step 1800, total loss = 0.80, batch loss = 0.48 (139.5 examples/sec; 0.057 sec/batch; 3h:08m:53s remains)
INFO - root - 2022-02-24 19:14:43.768302: step 1810, total loss = 0.64, batch loss = 0.32 (224.6 examples/sec; 0.036 sec/batch; 1h:57m:20s remains)
INFO - root - 2022-02-24 19:14:44.260240: step 1820, total loss = 0.74, batch loss = 0.43 (245.7 examples/sec; 0.033 sec/batch; 1h:47m:16s remains)
INFO - root - 2022-02-24 19:14:44.673679: step 1830, total loss = 0.72, batch loss = 0.40 (142.8 examples/sec; 0.056 sec/batch; 3h:04m:32s remains)
INFO - root - 2022-02-24 19:14:45.081033: step 1840, total loss = 0.86, batch loss = 0.54 (281.1 examples/sec; 0.028 sec/batch; 1h:33m:44s remains)
INFO - root - 2022-02-24 19:14:45.603313: step 1850, total loss = 0.98, batch loss = 0.66 (250.9 examples/sec; 0.032 sec/batch; 1h:45m:03s remains)
INFO - root - 2022-02-24 19:14:46.054800: step 1860, total loss = 0.74, batch loss = 0.42 (274.7 examples/sec; 0.029 sec/batch; 1h:35m:56s remains)
INFO - root - 2022-02-24 19:14:46.460372: step 1870, total loss = 1.16, batch loss = 0.84 (321.1 examples/sec; 0.025 sec/batch; 1h:22m:03s remains)
INFO - root - 2022-02-24 19:14:46.820606: step 1880, total loss = 0.98, batch loss = 0.67 (248.3 examples/sec; 0.032 sec/batch; 1h:46m:06s remains)
INFO - root - 2022-02-24 19:14:47.312570: step 1890, total loss = 0.82, batch loss = 0.51 (76.3 examples/sec; 0.105 sec/batch; 5h:45m:21s remains)
INFO - root - 2022-02-24 19:14:47.781389: step 1900, total loss = 0.86, batch loss = 0.54 (329.7 examples/sec; 0.024 sec/batch; 1h:19m:54s remains)
INFO - root - 2022-02-24 19:14:48.329806: step 1910, total loss = 0.77, batch loss = 0.45 (210.2 examples/sec; 0.038 sec/batch; 2h:05m:18s remains)
INFO - root - 2022-02-24 19:14:48.728904: step 1920, total loss = 0.94, batch loss = 0.62 (332.4 examples/sec; 0.024 sec/batch; 1h:19m:15s remains)
INFO - root - 2022-02-24 19:14:49.185122: step 1930, total loss = 0.61, batch loss = 0.29 (158.1 examples/sec; 0.051 sec/batch; 2h:46m:34s remains)
INFO - root - 2022-02-24 19:14:49.704407: step 1940, total loss = 1.04, batch loss = 0.73 (101.2 examples/sec; 0.079 sec/batch; 4h:20m:10s remains)
INFO - root - 2022-02-24 19:14:50.220023: step 1950, total loss = 0.79, batch loss = 0.47 (178.8 examples/sec; 0.045 sec/batch; 2h:27m:19s remains)
INFO - root - 2022-02-24 19:14:50.684837: step 1960, total loss = 1.00, batch loss = 0.69 (124.7 examples/sec; 0.064 sec/batch; 3h:31m:12s remains)
INFO - root - 2022-02-24 19:14:51.017538: step 1970, total loss = 1.03, batch loss = 0.71 (265.2 examples/sec; 0.030 sec/batch; 1h:39m:18s remains)
INFO - root - 2022-02-24 19:14:51.432048: step 1980, total loss = 0.98, batch loss = 0.66 (117.0 examples/sec; 0.068 sec/batch; 3h:45m:04s remains)
INFO - root - 2022-02-24 19:14:51.949854: step 1990, total loss = 0.91, batch loss = 0.59 (159.7 examples/sec; 0.050 sec/batch; 2h:44m:51s remains)
INFO - root - 2022-02-24 19:14:52.464251: step 2000, total loss = 0.80, batch loss = 0.48 (173.2 examples/sec; 0.046 sec/batch; 2h:32m:02s remains)
INFO - root - 2022-02-24 19:14:53.005334: step 2010, total loss = 0.86, batch loss = 0.54 (155.8 examples/sec; 0.051 sec/batch; 2h:49m:03s remains)
INFO - root - 2022-02-24 19:14:53.383047: step 2020, total loss = 0.97, batch loss = 0.65 (293.2 examples/sec; 0.027 sec/batch; 1h:29m:48s remains)
INFO - root - 2022-02-24 19:14:53.800348: step 2030, total loss = 0.66, batch loss = 0.34 (176.6 examples/sec; 0.045 sec/batch; 2h:29m:04s remains)
INFO - root - 2022-02-24 19:14:54.429677: step 2040, total loss = 0.89, batch loss = 0.58 (231.5 examples/sec; 0.035 sec/batch; 1h:53m:42s remains)
INFO - root - 2022-02-24 19:14:54.897622: step 2050, total loss = 0.93, batch loss = 0.61 (131.8 examples/sec; 0.061 sec/batch; 3h:19m:42s remains)
INFO - root - 2022-02-24 19:14:55.850929: step 2060, total loss = 0.88, batch loss = 0.56 (103.1 examples/sec; 0.078 sec/batch; 4h:15m:24s remains)
INFO - root - 2022-02-24 19:14:56.374702: step 2070, total loss = 0.88, batch loss = 0.57 (93.1 examples/sec; 0.086 sec/batch; 4h:42m:42s remains)
INFO - root - 2022-02-24 19:14:56.927397: step 2080, total loss = 0.69, batch loss = 0.37 (213.1 examples/sec; 0.038 sec/batch; 2h:03m:31s remains)
INFO - root - 2022-02-24 19:14:57.373240: step 2090, total loss = 0.79, batch loss = 0.47 (274.9 examples/sec; 0.029 sec/batch; 1h:35m:45s remains)
INFO - root - 2022-02-24 19:14:57.886965: step 2100, total loss = 0.92, batch loss = 0.61 (168.7 examples/sec; 0.047 sec/batch; 2h:36m:01s remains)
INFO - root - 2022-02-24 19:14:59.120685: step 2110, total loss = 0.79, batch loss = 0.48 (356.7 examples/sec; 0.022 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 19:14:59.379572: step 2120, total loss = 0.73, batch loss = 0.41 (313.4 examples/sec; 0.026 sec/batch; 1h:23m:59s remains)
INFO - root - 2022-02-24 19:14:59.619545: step 2130, total loss = 0.62, batch loss = 0.30 (328.9 examples/sec; 0.024 sec/batch; 1h:20m:01s remains)
INFO - root - 2022-02-24 19:14:59.981986: step 2140, total loss = 0.83, batch loss = 0.51 (177.0 examples/sec; 0.045 sec/batch; 2h:28m:39s remains)
INFO - root - 2022-02-24 19:15:00.753330: step 2150, total loss = 0.75, batch loss = 0.44 (217.2 examples/sec; 0.037 sec/batch; 2h:01m:07s remains)
INFO - root - 2022-02-24 19:15:01.148278: step 2160, total loss = 0.85, batch loss = 0.53 (358.6 examples/sec; 0.022 sec/batch; 1h:13m:22s remains)
INFO - root - 2022-02-24 19:15:01.609129: step 2170, total loss = 0.72, batch loss = 0.40 (262.9 examples/sec; 0.030 sec/batch; 1h:40m:04s remains)
INFO - root - 2022-02-24 19:15:02.027143: step 2180, total loss = 0.91, batch loss = 0.60 (182.1 examples/sec; 0.044 sec/batch; 2h:24m:28s remains)
INFO - root - 2022-02-24 19:15:02.481592: step 2190, total loss = 0.77, batch loss = 0.46 (224.5 examples/sec; 0.036 sec/batch; 1h:57m:12s remains)
INFO - root - 2022-02-24 19:15:02.982760: step 2200, total loss = 1.01, batch loss = 0.69 (333.6 examples/sec; 0.024 sec/batch; 1h:18m:51s remains)
INFO - root - 2022-02-24 19:15:03.497773: step 2210, total loss = 0.56, batch loss = 0.24 (348.7 examples/sec; 0.023 sec/batch; 1h:15m:25s remains)
INFO - root - 2022-02-24 19:15:03.976030: step 2220, total loss = 0.85, batch loss = 0.53 (191.2 examples/sec; 0.042 sec/batch; 2h:17m:34s remains)
INFO - root - 2022-02-24 19:15:04.346040: step 2230, total loss = 0.73, batch loss = 0.42 (222.0 examples/sec; 0.036 sec/batch; 1h:58m:29s remains)
INFO - root - 2022-02-24 19:15:04.851537: step 2240, total loss = 0.72, batch loss = 0.40 (142.8 examples/sec; 0.056 sec/batch; 3h:04m:07s remains)
INFO - root - 2022-02-24 19:15:05.261154: step 2250, total loss = 0.73, batch loss = 0.42 (144.9 examples/sec; 0.055 sec/batch; 3h:01m:29s remains)
INFO - root - 2022-02-24 19:15:05.730990: step 2260, total loss = 0.73, batch loss = 0.42 (98.0 examples/sec; 0.082 sec/batch; 4h:28m:28s remains)
INFO - root - 2022-02-24 19:15:06.248944: step 2270, total loss = 0.83, batch loss = 0.52 (179.3 examples/sec; 0.045 sec/batch; 2h:26m:41s remains)
INFO - root - 2022-02-24 19:15:06.637605: step 2280, total loss = 0.99, batch loss = 0.67 (273.8 examples/sec; 0.029 sec/batch; 1h:36m:02s remains)
INFO - root - 2022-02-24 19:15:07.057438: step 2290, total loss = 0.75, batch loss = 0.43 (205.4 examples/sec; 0.039 sec/batch; 2h:08m:02s remains)
INFO - root - 2022-02-24 19:15:07.484248: step 2300, total loss = 0.65, batch loss = 0.33 (138.4 examples/sec; 0.058 sec/batch; 3h:10m:00s remains)
INFO - root - 2022-02-24 19:15:08.036418: step 2310, total loss = 0.79, batch loss = 0.48 (211.2 examples/sec; 0.038 sec/batch; 2h:04m:27s remains)
INFO - root - 2022-02-24 19:15:08.421976: step 2320, total loss = 0.81, batch loss = 0.49 (264.0 examples/sec; 0.030 sec/batch; 1h:39m:35s remains)
INFO - root - 2022-02-24 19:15:08.871050: step 2330, total loss = 0.71, batch loss = 0.39 (125.6 examples/sec; 0.064 sec/batch; 3h:29m:21s remains)
INFO - root - 2022-02-24 19:15:09.227201: step 2340, total loss = 0.75, batch loss = 0.43 (141.9 examples/sec; 0.056 sec/batch; 3h:05m:14s remains)
INFO - root - 2022-02-24 19:15:09.565149: step 2350, total loss = 0.79, batch loss = 0.48 (277.3 examples/sec; 0.029 sec/batch; 1h:34m:48s remains)
INFO - root - 2022-02-24 19:15:10.050303: step 2360, total loss = 0.77, batch loss = 0.46 (139.8 examples/sec; 0.057 sec/batch; 3h:08m:05s remains)
INFO - root - 2022-02-24 19:15:10.533938: step 2370, total loss = 0.92, batch loss = 0.61 (229.9 examples/sec; 0.035 sec/batch; 1h:54m:18s remains)
INFO - root - 2022-02-24 19:15:11.015388: step 2380, total loss = 0.75, batch loss = 0.43 (239.7 examples/sec; 0.033 sec/batch; 1h:49m:39s remains)
INFO - root - 2022-02-24 19:15:11.373278: step 2390, total loss = 0.78, batch loss = 0.46 (194.2 examples/sec; 0.041 sec/batch; 2h:15m:18s remains)
INFO - root - 2022-02-24 19:15:11.770130: step 2400, total loss = 0.75, batch loss = 0.43 (245.4 examples/sec; 0.033 sec/batch; 1h:47m:05s remains)
INFO - root - 2022-02-24 19:15:12.345791: step 2410, total loss = 0.75, batch loss = 0.44 (267.9 examples/sec; 0.030 sec/batch; 1h:38m:04s remains)
INFO - root - 2022-02-24 19:15:12.805973: step 2420, total loss = 0.66, batch loss = 0.35 (242.6 examples/sec; 0.033 sec/batch; 1h:48m:19s remains)
INFO - root - 2022-02-24 19:15:13.322772: step 2430, total loss = 1.02, batch loss = 0.70 (172.5 examples/sec; 0.046 sec/batch; 2h:32m:18s remains)
INFO - root - 2022-02-24 19:15:13.755285: step 2440, total loss = 0.77, batch loss = 0.45 (134.0 examples/sec; 0.060 sec/batch; 3h:16m:08s remains)
INFO - root - 2022-02-24 19:15:14.607860: step 2450, total loss = 1.01, batch loss = 0.70 (241.4 examples/sec; 0.033 sec/batch; 1h:48m:50s remains)
INFO - root - 2022-02-24 19:15:15.226447: step 2460, total loss = 0.90, batch loss = 0.59 (72.0 examples/sec; 0.111 sec/batch; 6h:04m:50s remains)
INFO - root - 2022-02-24 19:15:15.776138: step 2470, total loss = 0.70, batch loss = 0.39 (163.1 examples/sec; 0.049 sec/batch; 2h:41m:06s remains)
INFO - root - 2022-02-24 19:15:16.750523: step 2480, total loss = 0.83, batch loss = 0.52 (116.2 examples/sec; 0.069 sec/batch; 3h:46m:04s remains)
INFO - root - 2022-02-24 19:15:17.313614: step 2490, total loss = 0.84, batch loss = 0.52 (247.4 examples/sec; 0.032 sec/batch; 1h:46m:10s remains)
INFO - root - 2022-02-24 19:15:17.819380: step 2500, total loss = 0.95, batch loss = 0.64 (206.4 examples/sec; 0.039 sec/batch; 2h:07m:15s remains)
INFO - root - 2022-02-24 19:15:18.346732: step 2510, total loss = 0.84, batch loss = 0.53 (201.3 examples/sec; 0.040 sec/batch; 2h:10m:26s remains)
INFO - root - 2022-02-24 19:15:18.814195: step 2520, total loss = 0.76, batch loss = 0.45 (333.0 examples/sec; 0.024 sec/batch; 1h:18m:52s remains)
INFO - root - 2022-02-24 19:15:19.249416: step 2530, total loss = 0.70, batch loss = 0.39 (144.9 examples/sec; 0.055 sec/batch; 3h:01m:12s remains)
INFO - root - 2022-02-24 19:15:19.721125: step 2540, total loss = 1.14, batch loss = 0.83 (166.0 examples/sec; 0.048 sec/batch; 2h:38m:13s remains)
INFO - root - 2022-02-24 19:15:20.116662: step 2550, total loss = 0.70, batch loss = 0.38 (192.2 examples/sec; 0.042 sec/batch; 2h:16m:36s remains)
INFO - root - 2022-02-24 19:15:20.560387: step 2560, total loss = 0.85, batch loss = 0.54 (215.5 examples/sec; 0.037 sec/batch; 2h:01m:49s remains)
INFO - root - 2022-02-24 19:15:21.198084: step 2570, total loss = 0.83, batch loss = 0.52 (95.7 examples/sec; 0.084 sec/batch; 4h:34m:25s remains)
INFO - root - 2022-02-24 19:15:21.818086: step 2580, total loss = 0.71, batch loss = 0.40 (84.7 examples/sec; 0.094 sec/batch; 5h:09m:57s remains)
INFO - root - 2022-02-24 19:15:22.124669: step 2590, total loss = 0.80, batch loss = 0.48 (273.0 examples/sec; 0.029 sec/batch; 1h:36m:09s remains)
INFO - root - 2022-02-24 19:15:22.534784: step 2600, total loss = 0.68, batch loss = 0.37 (228.9 examples/sec; 0.035 sec/batch; 1h:54m:42s remains)
INFO - root - 2022-02-24 19:15:22.997630: step 2610, total loss = 0.88, batch loss = 0.57 (220.7 examples/sec; 0.036 sec/batch; 1h:58m:57s remains)
INFO - root - 2022-02-24 19:15:23.503270: step 2620, total loss = 0.74, batch loss = 0.43 (136.5 examples/sec; 0.059 sec/batch; 3h:12m:20s remains)
INFO - root - 2022-02-24 19:15:23.976939: step 2630, total loss = 0.86, batch loss = 0.54 (123.8 examples/sec; 0.065 sec/batch; 3h:31m:57s remains)
INFO - root - 2022-02-24 19:15:24.339683: step 2640, total loss = 0.64, batch loss = 0.33 (307.2 examples/sec; 0.026 sec/batch; 1h:25m:27s remains)
INFO - root - 2022-02-24 19:15:24.746962: step 2650, total loss = 0.78, batch loss = 0.47 (141.3 examples/sec; 0.057 sec/batch; 3h:05m:44s remains)
INFO - root - 2022-02-24 19:15:25.196978: step 2660, total loss = 0.79, batch loss = 0.48 (328.1 examples/sec; 0.024 sec/batch; 1h:19m:58s remains)
INFO - root - 2022-02-24 19:15:25.638076: step 2670, total loss = 0.70, batch loss = 0.39 (241.8 examples/sec; 0.033 sec/batch; 1h:48m:33s remains)
INFO - root - 2022-02-24 19:15:26.188476: step 2680, total loss = 0.93, batch loss = 0.62 (157.5 examples/sec; 0.051 sec/batch; 2h:46m:34s remains)
INFO - root - 2022-02-24 19:15:26.606312: step 2690, total loss = 0.90, batch loss = 0.59 (302.0 examples/sec; 0.026 sec/batch; 1h:26m:53s remains)
INFO - root - 2022-02-24 19:15:26.948876: step 2700, total loss = 0.74, batch loss = 0.43 (242.3 examples/sec; 0.033 sec/batch; 1h:48m:18s remains)
INFO - root - 2022-02-24 19:15:27.440830: step 2710, total loss = 0.76, batch loss = 0.45 (228.7 examples/sec; 0.035 sec/batch; 1h:54m:42s remains)
INFO - root - 2022-02-24 19:15:27.977653: step 2720, total loss = 0.78, batch loss = 0.46 (141.8 examples/sec; 0.056 sec/batch; 3h:05m:05s remains)
INFO - root - 2022-02-24 19:15:28.452890: step 2730, total loss = 0.82, batch loss = 0.50 (173.9 examples/sec; 0.046 sec/batch; 2h:30m:51s remains)
INFO - root - 2022-02-24 19:15:28.932649: step 2740, total loss = 0.77, batch loss = 0.46 (123.1 examples/sec; 0.065 sec/batch; 3h:33m:03s remains)
INFO - root - 2022-02-24 19:15:29.311253: step 2750, total loss = 0.77, batch loss = 0.45 (159.6 examples/sec; 0.050 sec/batch; 2h:44m:22s remains)
INFO - root - 2022-02-24 19:15:29.729873: step 2760, total loss = 0.82, batch loss = 0.51 (112.1 examples/sec; 0.071 sec/batch; 3h:54m:00s remains)
INFO - root - 2022-02-24 19:15:30.167986: step 2770, total loss = 0.75, batch loss = 0.44 (167.8 examples/sec; 0.048 sec/batch; 2h:36m:17s remains)
INFO - root - 2022-02-24 19:15:30.666805: step 2780, total loss = 0.80, batch loss = 0.48 (332.7 examples/sec; 0.024 sec/batch; 1h:18m:50s remains)
INFO - root - 2022-02-24 19:15:31.154362: step 2790, total loss = 0.86, batch loss = 0.55 (146.4 examples/sec; 0.055 sec/batch; 2h:59m:06s remains)
INFO - root - 2022-02-24 19:15:31.776221: step 2800, total loss = 0.81, batch loss = 0.49 (152.5 examples/sec; 0.052 sec/batch; 2h:51m:58s remains)
INFO - root - 2022-02-24 19:15:32.252034: step 2810, total loss = 0.75, batch loss = 0.43 (219.7 examples/sec; 0.036 sec/batch; 1h:59m:23s remains)
INFO - root - 2022-02-24 19:15:32.745774: step 2820, total loss = 0.69, batch loss = 0.38 (104.9 examples/sec; 0.076 sec/batch; 4h:09m:55s remains)
INFO - root - 2022-02-24 19:15:33.225899: step 2830, total loss = 0.75, batch loss = 0.43 (78.7 examples/sec; 0.102 sec/batch; 5h:33m:03s remains)
INFO - root - 2022-02-24 19:15:33.851441: step 2840, total loss = 0.75, batch loss = 0.44 (72.3 examples/sec; 0.111 sec/batch; 6h:02m:54s remains)
INFO - root - 2022-02-24 19:15:34.448229: step 2850, total loss = 0.70, batch loss = 0.38 (93.6 examples/sec; 0.085 sec/batch; 4h:40m:08s remains)
INFO - root - 2022-02-24 19:15:35.076812: step 2860, total loss = 1.20, batch loss = 0.89 (143.5 examples/sec; 0.056 sec/batch; 3h:02m:39s remains)
INFO - root - 2022-02-24 19:15:35.764043: step 2870, total loss = 0.75, batch loss = 0.44 (238.2 examples/sec; 0.034 sec/batch; 1h:50m:04s remains)
INFO - root - 2022-02-24 19:15:36.605074: step 2880, total loss = 0.85, batch loss = 0.54 (139.0 examples/sec; 0.058 sec/batch; 3h:08m:36s remains)
INFO - root - 2022-02-24 19:15:37.034368: step 2890, total loss = 0.71, batch loss = 0.40 (116.2 examples/sec; 0.069 sec/batch; 3h:45m:31s remains)
INFO - root - 2022-02-24 19:15:37.573152: step 2900, total loss = 0.78, batch loss = 0.47 (146.6 examples/sec; 0.055 sec/batch; 2h:58m:45s remains)
INFO - root - 2022-02-24 19:15:38.149962: step 2910, total loss = 0.91, batch loss = 0.60 (311.4 examples/sec; 0.026 sec/batch; 1h:24m:09s remains)
INFO - root - 2022-02-24 19:15:38.563390: step 2920, total loss = 0.74, batch loss = 0.43 (276.2 examples/sec; 0.029 sec/batch; 1h:34m:54s remains)
INFO - root - 2022-02-24 19:15:38.975049: step 2930, total loss = 0.65, batch loss = 0.33 (209.7 examples/sec; 0.038 sec/batch; 2h:04m:58s remains)
INFO - root - 2022-02-24 19:15:39.354870: step 2940, total loss = 0.72, batch loss = 0.41 (147.5 examples/sec; 0.054 sec/batch; 2h:57m:39s remains)
INFO - root - 2022-02-24 19:15:39.883073: step 2950, total loss = 0.77, batch loss = 0.46 (211.7 examples/sec; 0.038 sec/batch; 2h:03m:47s remains)
INFO - root - 2022-02-24 19:15:40.375359: step 2960, total loss = 0.77, batch loss = 0.46 (315.5 examples/sec; 0.025 sec/batch; 1h:23m:03s remains)
INFO - root - 2022-02-24 19:15:40.774326: step 2970, total loss = 0.75, batch loss = 0.44 (252.7 examples/sec; 0.032 sec/batch; 1h:43m:41s remains)
INFO - root - 2022-02-24 19:15:41.155811: step 2980, total loss = 0.77, batch loss = 0.46 (290.0 examples/sec; 0.028 sec/batch; 1h:30m:22s remains)
INFO - root - 2022-02-24 19:15:41.624411: step 2990, total loss = 0.68, batch loss = 0.37 (213.0 examples/sec; 0.038 sec/batch; 2h:03m:01s remains)
INFO - root - 2022-02-24 19:15:42.255715: step 3000, total loss = 0.73, batch loss = 0.42 (163.3 examples/sec; 0.049 sec/batch; 2h:40m:25s remains)
INFO - root - 2022-02-24 19:15:42.708593: step 3010, total loss = 0.61, batch loss = 0.30 (229.9 examples/sec; 0.035 sec/batch; 1h:53m:56s remains)
INFO - root - 2022-02-24 19:15:43.046038: step 3020, total loss = 0.73, batch loss = 0.42 (269.2 examples/sec; 0.030 sec/batch; 1h:37m:19s remains)
INFO - root - 2022-02-24 19:15:43.504425: step 3030, total loss = 0.89, batch loss = 0.58 (200.9 examples/sec; 0.040 sec/batch; 2h:10m:23s remains)
INFO - root - 2022-02-24 19:15:43.906333: step 3040, total loss = 0.76, batch loss = 0.44 (264.8 examples/sec; 0.030 sec/batch; 1h:38m:54s remains)
INFO - root - 2022-02-24 19:15:44.451830: step 3050, total loss = 0.62, batch loss = 0.31 (120.3 examples/sec; 0.066 sec/batch; 3h:37m:39s remains)
INFO - root - 2022-02-24 19:15:44.879188: step 3060, total loss = 0.85, batch loss = 0.53 (342.1 examples/sec; 0.023 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 19:15:45.300955: step 3070, total loss = 0.81, batch loss = 0.50 (170.5 examples/sec; 0.047 sec/batch; 2h:33m:38s remains)
INFO - root - 2022-02-24 19:15:45.721183: step 3080, total loss = 0.70, batch loss = 0.39 (247.2 examples/sec; 0.032 sec/batch; 1h:45m:57s remains)
INFO - root - 2022-02-24 19:15:46.202961: step 3090, total loss = 0.69, batch loss = 0.38 (231.6 examples/sec; 0.035 sec/batch; 1h:53m:03s remains)
INFO - root - 2022-02-24 19:15:46.736604: step 3100, total loss = 0.80, batch loss = 0.49 (138.4 examples/sec; 0.058 sec/batch; 3h:09m:08s remains)
INFO - root - 2022-02-24 19:15:47.170228: step 3110, total loss = 0.72, batch loss = 0.41 (243.5 examples/sec; 0.033 sec/batch; 1h:47m:33s remains)
INFO - root - 2022-02-24 19:15:47.542148: step 3120, total loss = 0.92, batch loss = 0.61 (328.5 examples/sec; 0.024 sec/batch; 1h:19m:42s remains)
INFO - root - 2022-02-24 19:15:47.969108: step 3130, total loss = 0.85, batch loss = 0.54 (347.0 examples/sec; 0.023 sec/batch; 1h:15m:27s remains)
INFO - root - 2022-02-24 19:15:48.381417: step 3140, total loss = 0.64, batch loss = 0.33 (214.7 examples/sec; 0.037 sec/batch; 2h:01m:58s remains)
INFO - root - 2022-02-24 19:15:48.899482: step 3150, total loss = 0.68, batch loss = 0.37 (174.7 examples/sec; 0.046 sec/batch; 2h:29m:50s remains)
INFO - root - 2022-02-24 19:15:49.344181: step 3160, total loss = 0.59, batch loss = 0.28 (319.9 examples/sec; 0.025 sec/batch; 1h:21m:50s remains)
INFO - root - 2022-02-24 19:15:49.752531: step 3170, total loss = 0.75, batch loss = 0.44 (195.4 examples/sec; 0.041 sec/batch; 2h:13m:58s remains)
INFO - root - 2022-02-24 19:15:50.214772: step 3180, total loss = 0.86, batch loss = 0.55 (137.3 examples/sec; 0.058 sec/batch; 3h:10m:36s remains)
INFO - root - 2022-02-24 19:15:50.837815: step 3190, total loss = 0.61, batch loss = 0.30 (103.6 examples/sec; 0.077 sec/batch; 4h:12m:32s remains)
INFO - root - 2022-02-24 19:15:51.276947: step 3200, total loss = 0.82, batch loss = 0.51 (154.7 examples/sec; 0.052 sec/batch; 2h:49m:08s remains)
INFO - root - 2022-02-24 19:15:52.216219: step 3210, total loss = 0.81, batch loss = 0.49 (202.4 examples/sec; 0.040 sec/batch; 2h:09m:17s remains)
INFO - root - 2022-02-24 19:15:52.736310: step 3220, total loss = 0.81, batch loss = 0.49 (285.2 examples/sec; 0.028 sec/batch; 1h:31m:45s remains)
INFO - root - 2022-02-24 19:15:53.232845: step 3230, total loss = 0.62, batch loss = 0.31 (231.3 examples/sec; 0.035 sec/batch; 1h:53m:08s remains)
INFO - root - 2022-02-24 19:15:53.643402: step 3240, total loss = 0.91, batch loss = 0.60 (324.8 examples/sec; 0.025 sec/batch; 1h:20m:34s remains)
INFO - root - 2022-02-24 19:15:54.183939: step 3250, total loss = 0.74, batch loss = 0.43 (133.5 examples/sec; 0.060 sec/batch; 3h:15m:56s remains)
INFO - root - 2022-02-24 19:15:54.708066: step 3260, total loss = 0.70, batch loss = 0.39 (65.7 examples/sec; 0.122 sec/batch; 6h:37m:59s remains)
INFO - root - 2022-02-24 19:15:55.265609: step 3270, total loss = 0.85, batch loss = 0.54 (292.8 examples/sec; 0.027 sec/batch; 1h:29m:21s remains)
INFO - root - 2022-02-24 19:15:55.791705: step 3280, total loss = 0.77, batch loss = 0.46 (75.9 examples/sec; 0.105 sec/batch; 5h:44m:54s remains)
INFO - root - 2022-02-24 19:15:56.286155: step 3290, total loss = 0.69, batch loss = 0.38 (161.5 examples/sec; 0.050 sec/batch; 2h:41m:58s remains)
INFO - root - 2022-02-24 19:15:56.719559: step 3300, total loss = 0.79, batch loss = 0.48 (100.8 examples/sec; 0.079 sec/batch; 4h:19m:28s remains)
INFO - root - 2022-02-24 19:15:57.779307: step 3310, total loss = 0.62, batch loss = 0.31 (110.9 examples/sec; 0.072 sec/batch; 3h:55m:54s remains)
INFO - root - 2022-02-24 19:15:58.288433: step 3320, total loss = 0.67, batch loss = 0.36 (194.5 examples/sec; 0.041 sec/batch; 2h:14m:28s remains)
INFO - root - 2022-02-24 19:15:58.618552: step 3330, total loss = 0.64, batch loss = 0.33 (194.6 examples/sec; 0.041 sec/batch; 2h:14m:25s remains)
INFO - root - 2022-02-24 19:15:59.044627: step 3340, total loss = 0.63, batch loss = 0.31 (140.4 examples/sec; 0.057 sec/batch; 3h:06m:13s remains)
INFO - root - 2022-02-24 19:15:59.431989: step 3350, total loss = 0.65, batch loss = 0.34 (201.1 examples/sec; 0.040 sec/batch; 2h:10m:01s remains)
INFO - root - 2022-02-24 19:15:59.981767: step 3360, total loss = 0.61, batch loss = 0.30 (190.5 examples/sec; 0.042 sec/batch; 2h:17m:16s remains)
INFO - root - 2022-02-24 19:16:00.475750: step 3370, total loss = 0.57, batch loss = 0.26 (324.4 examples/sec; 0.025 sec/batch; 1h:20m:37s remains)
INFO - root - 2022-02-24 19:16:00.939797: step 3380, total loss = 0.79, batch loss = 0.48 (258.7 examples/sec; 0.031 sec/batch; 1h:41m:05s remains)
INFO - root - 2022-02-24 19:16:01.330713: step 3390, total loss = 0.81, batch loss = 0.50 (137.2 examples/sec; 0.058 sec/batch; 3h:10m:36s remains)
INFO - root - 2022-02-24 19:16:01.775859: step 3400, total loss = 0.83, batch loss = 0.52 (359.8 examples/sec; 0.022 sec/batch; 1h:12m:40s remains)
INFO - root - 2022-02-24 19:16:02.343349: step 3410, total loss = 0.87, batch loss = 0.56 (346.4 examples/sec; 0.023 sec/batch; 1h:15m:28s remains)
INFO - root - 2022-02-24 19:16:02.771518: step 3420, total loss = 0.82, batch loss = 0.51 (175.9 examples/sec; 0.045 sec/batch; 2h:28m:39s remains)
INFO - root - 2022-02-24 19:16:03.258314: step 3430, total loss = 0.76, batch loss = 0.44 (130.2 examples/sec; 0.061 sec/batch; 3h:20m:49s remains)
INFO - root - 2022-02-24 19:16:03.689939: step 3440, total loss = 0.83, batch loss = 0.52 (166.7 examples/sec; 0.048 sec/batch; 2h:36m:47s remains)
INFO - root - 2022-02-24 19:16:04.102843: step 3450, total loss = 0.67, batch loss = 0.36 (310.8 examples/sec; 0.026 sec/batch; 1h:24m:05s remains)
INFO - root - 2022-02-24 19:16:04.561790: step 3460, total loss = 0.72, batch loss = 0.41 (137.7 examples/sec; 0.058 sec/batch; 3h:09m:48s remains)
INFO - root - 2022-02-24 19:16:05.050648: step 3470, total loss = 0.79, batch loss = 0.48 (184.4 examples/sec; 0.043 sec/batch; 2h:21m:44s remains)
INFO - root - 2022-02-24 19:16:05.527763: step 3480, total loss = 0.72, batch loss = 0.41 (341.5 examples/sec; 0.023 sec/batch; 1h:16m:31s remains)
INFO - root - 2022-02-24 19:16:05.932525: step 3490, total loss = 0.85, batch loss = 0.54 (243.7 examples/sec; 0.033 sec/batch; 1h:47m:13s remains)
INFO - root - 2022-02-24 19:16:06.332931: step 3500, total loss = 0.79, batch loss = 0.48 (363.9 examples/sec; 0.022 sec/batch; 1h:11m:49s remains)
INFO - root - 2022-02-24 19:16:06.783175: step 3510, total loss = 0.76, batch loss = 0.45 (241.9 examples/sec; 0.033 sec/batch; 1h:48m:02s remains)
INFO - root - 2022-02-24 19:16:07.380342: step 3520, total loss = 0.68, batch loss = 0.36 (96.8 examples/sec; 0.083 sec/batch; 4h:30m:00s remains)
INFO - root - 2022-02-24 19:16:07.914042: step 3530, total loss = 0.55, batch loss = 0.24 (191.1 examples/sec; 0.042 sec/batch; 2h:16m:42s remains)
INFO - root - 2022-02-24 19:16:08.390600: step 3540, total loss = 0.68, batch loss = 0.37 (193.0 examples/sec; 0.041 sec/batch; 2h:15m:23s remains)
INFO - root - 2022-02-24 19:16:08.811919: step 3550, total loss = 0.74, batch loss = 0.43 (164.1 examples/sec; 0.049 sec/batch; 2h:39m:14s remains)
INFO - root - 2022-02-24 19:16:09.270247: step 3560, total loss = 0.88, batch loss = 0.56 (265.3 examples/sec; 0.030 sec/batch; 1h:38m:27s remains)
INFO - root - 2022-02-24 19:16:09.771416: step 3570, total loss = 0.83, batch loss = 0.51 (173.4 examples/sec; 0.046 sec/batch; 2h:30m:39s remains)
INFO - root - 2022-02-24 19:16:10.145884: step 3580, total loss = 0.61, batch loss = 0.30 (191.7 examples/sec; 0.042 sec/batch; 2h:16m:17s remains)
INFO - root - 2022-02-24 19:16:10.483354: step 3590, total loss = 0.71, batch loss = 0.40 (329.7 examples/sec; 0.024 sec/batch; 1h:19m:13s remains)
INFO - root - 2022-02-24 19:16:10.949998: step 3600, total loss = 0.63, batch loss = 0.32 (110.3 examples/sec; 0.073 sec/batch; 3h:56m:54s remains)
INFO - root - 2022-02-24 19:16:11.740338: step 3610, total loss = 0.68, batch loss = 0.37 (172.5 examples/sec; 0.046 sec/batch; 2h:31m:23s remains)
INFO - root - 2022-02-24 19:16:12.274226: step 3620, total loss = 0.76, batch loss = 0.45 (117.1 examples/sec; 0.068 sec/batch; 3h:43m:03s remains)
INFO - root - 2022-02-24 19:16:13.267769: step 3630, total loss = 0.92, batch loss = 0.61 (214.6 examples/sec; 0.037 sec/batch; 2h:01m:41s remains)
INFO - root - 2022-02-24 19:16:13.667520: step 3640, total loss = 0.70, batch loss = 0.39 (126.6 examples/sec; 0.063 sec/batch; 3h:26m:15s remains)
INFO - root - 2022-02-24 19:16:14.141965: step 3650, total loss = 0.70, batch loss = 0.39 (114.9 examples/sec; 0.070 sec/batch; 3h:47m:19s remains)
INFO - root - 2022-02-24 19:16:14.679988: step 3660, total loss = 0.67, batch loss = 0.36 (281.8 examples/sec; 0.028 sec/batch; 1h:32m:40s remains)
INFO - root - 2022-02-24 19:16:15.146275: step 3670, total loss = 0.77, batch loss = 0.46 (146.7 examples/sec; 0.055 sec/batch; 2h:57m:56s remains)
INFO - root - 2022-02-24 19:16:15.789182: step 3680, total loss = 0.89, batch loss = 0.58 (127.6 examples/sec; 0.063 sec/batch; 3h:24m:40s remains)
INFO - root - 2022-02-24 19:16:16.242670: step 3690, total loss = 0.71, batch loss = 0.40 (255.9 examples/sec; 0.031 sec/batch; 1h:42m:02s remains)
INFO - root - 2022-02-24 19:16:16.671066: step 3700, total loss = 0.74, batch loss = 0.43 (172.9 examples/sec; 0.046 sec/batch; 2h:30m:58s remains)
INFO - root - 2022-02-24 19:16:17.180086: step 3710, total loss = 0.76, batch loss = 0.45 (143.5 examples/sec; 0.056 sec/batch; 3h:01m:58s remains)
INFO - root - 2022-02-24 19:16:17.676177: step 3720, total loss = 0.84, batch loss = 0.53 (160.3 examples/sec; 0.050 sec/batch; 2h:42m:48s remains)
INFO - root - 2022-02-24 19:16:18.620609: step 3730, total loss = 0.62, batch loss = 0.31 (103.1 examples/sec; 0.078 sec/batch; 4h:13m:08s remains)
INFO - root - 2022-02-24 19:16:19.023323: step 3740, total loss = 0.87, batch loss = 0.56 (154.6 examples/sec; 0.052 sec/batch; 2h:48m:49s remains)
INFO - root - 2022-02-24 19:16:19.548268: step 3750, total loss = 0.71, batch loss = 0.39 (96.6 examples/sec; 0.083 sec/batch; 4h:30m:17s remains)
INFO - root - 2022-02-24 19:16:20.077194: step 3760, total loss = 0.75, batch loss = 0.44 (195.6 examples/sec; 0.041 sec/batch; 2h:13m:26s remains)
INFO - root - 2022-02-24 19:16:20.600197: step 3770, total loss = 0.62, batch loss = 0.31 (292.3 examples/sec; 0.027 sec/batch; 1h:29m:17s remains)
INFO - root - 2022-02-24 19:16:21.046103: step 3780, total loss = 0.78, batch loss = 0.47 (285.2 examples/sec; 0.028 sec/batch; 1h:31m:30s remains)
INFO - root - 2022-02-24 19:16:21.506798: step 3790, total loss = 0.55, batch loss = 0.24 (276.5 examples/sec; 0.029 sec/batch; 1h:34m:23s remains)
INFO - root - 2022-02-24 19:16:22.030844: step 3800, total loss = 0.67, batch loss = 0.36 (229.9 examples/sec; 0.035 sec/batch; 1h:53m:29s remains)
INFO - root - 2022-02-24 19:16:22.663679: step 3810, total loss = 0.62, batch loss = 0.31 (284.6 examples/sec; 0.028 sec/batch; 1h:31m:39s remains)
INFO - root - 2022-02-24 19:16:23.097483: step 3820, total loss = 0.77, batch loss = 0.46 (98.3 examples/sec; 0.081 sec/batch; 4h:25m:23s remains)
INFO - root - 2022-02-24 19:16:23.572282: step 3830, total loss = 0.57, batch loss = 0.26 (181.4 examples/sec; 0.044 sec/batch; 2h:23m:49s remains)
INFO - root - 2022-02-24 19:16:24.175904: step 3840, total loss = 0.72, batch loss = 0.41 (177.6 examples/sec; 0.045 sec/batch; 2h:26m:54s remains)
INFO - root - 2022-02-24 19:16:24.623865: step 3850, total loss = 0.70, batch loss = 0.39 (154.6 examples/sec; 0.052 sec/batch; 2h:48m:44s remains)
INFO - root - 2022-02-24 19:16:24.985220: step 3860, total loss = 0.64, batch loss = 0.33 (308.7 examples/sec; 0.026 sec/batch; 1h:24m:30s remains)
INFO - root - 2022-02-24 19:16:25.276123: step 3870, total loss = 0.77, batch loss = 0.46 (349.2 examples/sec; 0.023 sec/batch; 1h:14m:41s remains)
INFO - root - 2022-02-24 19:16:25.666542: step 3880, total loss = 0.76, batch loss = 0.45 (146.0 examples/sec; 0.055 sec/batch; 2h:58m:42s remains)
INFO - root - 2022-02-24 19:16:26.176968: step 3890, total loss = 0.84, batch loss = 0.53 (159.4 examples/sec; 0.050 sec/batch; 2h:43m:39s remains)
INFO - root - 2022-02-24 19:16:26.613324: step 3900, total loss = 0.72, batch loss = 0.41 (167.3 examples/sec; 0.048 sec/batch; 2h:35m:52s remains)
INFO - root - 2022-02-24 19:16:27.141604: step 3910, total loss = 0.71, batch loss = 0.40 (173.8 examples/sec; 0.046 sec/batch; 2h:30m:05s remains)
INFO - root - 2022-02-24 19:16:27.537768: step 3920, total loss = 0.65, batch loss = 0.34 (314.4 examples/sec; 0.025 sec/batch; 1h:22m:56s remains)
INFO - root - 2022-02-24 19:16:27.956313: step 3930, total loss = 0.79, batch loss = 0.48 (285.4 examples/sec; 0.028 sec/batch; 1h:31m:22s remains)
INFO - root - 2022-02-24 19:16:28.467934: step 3940, total loss = 0.73, batch loss = 0.42 (233.9 examples/sec; 0.034 sec/batch; 1h:51m:27s remains)
INFO - root - 2022-02-24 19:16:28.966051: step 3950, total loss = 0.81, batch loss = 0.50 (178.0 examples/sec; 0.045 sec/batch; 2h:26m:31s remains)
INFO - root - 2022-02-24 19:16:29.414404: step 3960, total loss = 0.78, batch loss = 0.47 (324.7 examples/sec; 0.025 sec/batch; 1h:20m:17s remains)
INFO - root - 2022-02-24 19:16:29.807576: step 3970, total loss = 0.66, batch loss = 0.35 (233.5 examples/sec; 0.034 sec/batch; 1h:51m:39s remains)
INFO - root - 2022-02-24 19:16:30.276084: step 3980, total loss = 0.68, batch loss = 0.37 (239.9 examples/sec; 0.033 sec/batch; 1h:48m:40s remains)
INFO - root - 2022-02-24 19:16:30.906822: step 3990, total loss = 0.66, batch loss = 0.35 (257.0 examples/sec; 0.031 sec/batch; 1h:41m:26s remains)
INFO - root - 2022-02-24 19:16:31.567802: step 4000, total loss = 0.91, batch loss = 0.60 (80.0 examples/sec; 0.100 sec/batch; 5h:25m:58s remains)
INFO - root - 2022-02-24 19:16:32.191925: step 4010, total loss = 0.90, batch loss = 0.59 (290.8 examples/sec; 0.028 sec/batch; 1h:29m:37s remains)
INFO - root - 2022-02-24 19:16:32.664406: step 4020, total loss = 0.61, batch loss = 0.30 (288.4 examples/sec; 0.028 sec/batch; 1h:30m:23s remains)
INFO - root - 2022-02-24 19:16:33.186785: step 4030, total loss = 0.69, batch loss = 0.38 (170.0 examples/sec; 0.047 sec/batch; 2h:33m:16s remains)
INFO - root - 2022-02-24 19:16:34.135470: step 4040, total loss = 0.83, batch loss = 0.52 (142.0 examples/sec; 0.056 sec/batch; 3h:03m:29s remains)
INFO - root - 2022-02-24 19:16:34.526705: step 4050, total loss = 0.78, batch loss = 0.47 (160.2 examples/sec; 0.050 sec/batch; 2h:42m:38s remains)
INFO - root - 2022-02-24 19:16:34.968164: step 4060, total loss = 0.59, batch loss = 0.28 (115.8 examples/sec; 0.069 sec/batch; 3h:45m:06s remains)
INFO - root - 2022-02-24 19:16:35.504757: step 4070, total loss = 0.64, batch loss = 0.33 (80.0 examples/sec; 0.100 sec/batch; 5h:25m:53s remains)
INFO - root - 2022-02-24 19:16:36.005396: step 4080, total loss = 0.63, batch loss = 0.32 (308.9 examples/sec; 0.026 sec/batch; 1h:24m:20s remains)
INFO - root - 2022-02-24 19:16:36.399532: step 4090, total loss = 0.62, batch loss = 0.32 (184.5 examples/sec; 0.043 sec/batch; 2h:21m:11s remains)
INFO - root - 2022-02-24 19:16:36.824052: step 4100, total loss = 0.63, batch loss = 0.32 (129.8 examples/sec; 0.062 sec/batch; 3h:20m:44s remains)
INFO - root - 2022-02-24 19:16:37.361945: step 4110, total loss = 0.66, batch loss = 0.35 (181.3 examples/sec; 0.044 sec/batch; 2h:23m:42s remains)
INFO - root - 2022-02-24 19:16:37.853389: step 4120, total loss = 0.71, batch loss = 0.40 (265.3 examples/sec; 0.030 sec/batch; 1h:38m:10s remains)
INFO - root - 2022-02-24 19:16:38.312299: step 4130, total loss = 0.70, batch loss = 0.39 (186.8 examples/sec; 0.043 sec/batch; 2h:19m:28s remains)
INFO - root - 2022-02-24 19:16:38.947489: step 4140, total loss = 0.69, batch loss = 0.38 (184.9 examples/sec; 0.043 sec/batch; 2h:20m:52s remains)
INFO - root - 2022-02-24 19:16:39.504348: step 4150, total loss = 0.73, batch loss = 0.42 (95.5 examples/sec; 0.084 sec/batch; 4h:32m:45s remains)
INFO - root - 2022-02-24 19:16:40.133743: step 4160, total loss = 0.83, batch loss = 0.52 (211.0 examples/sec; 0.038 sec/batch; 2h:03m:27s remains)
INFO - root - 2022-02-24 19:16:40.458421: step 4170, total loss = 1.03, batch loss = 0.72 (322.7 examples/sec; 0.025 sec/batch; 1h:20m:43s remains)
INFO - root - 2022-02-24 19:16:40.827275: step 4180, total loss = 0.80, batch loss = 0.49 (179.2 examples/sec; 0.045 sec/batch; 2h:25m:18s remains)
INFO - root - 2022-02-24 19:16:41.171672: step 4190, total loss = 0.84, batch loss = 0.53 (148.7 examples/sec; 0.054 sec/batch; 2h:55m:10s remains)
INFO - root - 2022-02-24 19:16:41.632628: step 4200, total loss = 0.85, batch loss = 0.54 (154.6 examples/sec; 0.052 sec/batch; 2h:48m:29s remains)
INFO - root - 2022-02-24 19:16:42.144523: step 4210, total loss = 0.65, batch loss = 0.34 (212.3 examples/sec; 0.038 sec/batch; 2h:02m:38s remains)
INFO - root - 2022-02-24 19:16:42.622117: step 4220, total loss = 0.98, batch loss = 0.67 (177.3 examples/sec; 0.045 sec/batch; 2h:26m:51s remains)
INFO - root - 2022-02-24 19:16:42.967962: step 4230, total loss = 0.61, batch loss = 0.30 (180.1 examples/sec; 0.044 sec/batch; 2h:24m:32s remains)
INFO - root - 2022-02-24 19:16:43.438163: step 4240, total loss = 0.75, batch loss = 0.44 (93.2 examples/sec; 0.086 sec/batch; 4h:39m:22s remains)
INFO - root - 2022-02-24 19:16:43.881949: step 4250, total loss = 0.64, batch loss = 0.33 (227.1 examples/sec; 0.035 sec/batch; 1h:54m:36s remains)
INFO - root - 2022-02-24 19:16:44.333119: step 4260, total loss = 0.68, batch loss = 0.38 (130.3 examples/sec; 0.061 sec/batch; 3h:19m:50s remains)
INFO - root - 2022-02-24 19:16:44.842114: step 4270, total loss = 0.76, batch loss = 0.45 (131.2 examples/sec; 0.061 sec/batch; 3h:18m:27s remains)
INFO - root - 2022-02-24 19:16:45.218354: step 4280, total loss = 0.55, batch loss = 0.24 (351.8 examples/sec; 0.023 sec/batch; 1h:13m:59s remains)
INFO - root - 2022-02-24 19:16:45.621244: step 4290, total loss = 0.89, batch loss = 0.58 (217.6 examples/sec; 0.037 sec/batch; 1h:59m:35s remains)
INFO - root - 2022-02-24 19:16:46.094741: step 4300, total loss = 0.79, batch loss = 0.48 (103.3 examples/sec; 0.077 sec/batch; 4h:11m:56s remains)
INFO - root - 2022-02-24 19:16:46.716180: step 4310, total loss = 0.76, batch loss = 0.45 (125.8 examples/sec; 0.064 sec/batch; 3h:26m:57s remains)
INFO - root - 2022-02-24 19:16:47.065462: step 4320, total loss = 0.59, batch loss = 0.28 (160.4 examples/sec; 0.050 sec/batch; 2h:42m:13s remains)
INFO - root - 2022-02-24 19:16:47.504253: step 4330, total loss = 0.68, batch loss = 0.37 (131.4 examples/sec; 0.061 sec/batch; 3h:17m:58s remains)
INFO - root - 2022-02-24 19:16:47.992015: step 4340, total loss = 0.76, batch loss = 0.45 (196.8 examples/sec; 0.041 sec/batch; 2h:12m:11s remains)
INFO - root - 2022-02-24 19:16:48.398199: step 4350, total loss = 0.84, batch loss = 0.53 (261.9 examples/sec; 0.031 sec/batch; 1h:39m:21s remains)
INFO - root - 2022-02-24 19:16:48.887772: step 4360, total loss = 0.75, batch loss = 0.44 (188.9 examples/sec; 0.042 sec/batch; 2h:17m:42s remains)
INFO - root - 2022-02-24 19:16:49.388183: step 4370, total loss = 0.71, batch loss = 0.41 (213.5 examples/sec; 0.037 sec/batch; 2h:01m:50s remains)
INFO - root - 2022-02-24 19:16:49.840534: step 4380, total loss = 0.72, batch loss = 0.41 (225.9 examples/sec; 0.035 sec/batch; 1h:55m:10s remains)
INFO - root - 2022-02-24 19:16:50.360204: step 4390, total loss = 0.68, batch loss = 0.37 (158.2 examples/sec; 0.051 sec/batch; 2h:44m:25s remains)
INFO - root - 2022-02-24 19:16:50.835328: step 4400, total loss = 0.70, batch loss = 0.39 (135.2 examples/sec; 0.059 sec/batch; 3h:12m:25s remains)
INFO - root - 2022-02-24 19:16:51.519364: step 4410, total loss = 0.73, batch loss = 0.42 (177.0 examples/sec; 0.045 sec/batch; 2h:26m:57s remains)
INFO - root - 2022-02-24 19:16:52.156328: step 4420, total loss = 0.75, batch loss = 0.44 (122.0 examples/sec; 0.066 sec/batch; 3h:33m:13s remains)
INFO - root - 2022-02-24 19:16:52.638000: step 4430, total loss = 0.58, batch loss = 0.27 (137.0 examples/sec; 0.058 sec/batch; 3h:09m:52s remains)
INFO - root - 2022-02-24 19:16:53.100697: step 4440, total loss = 0.76, batch loss = 0.46 (244.3 examples/sec; 0.033 sec/batch; 1h:46m:26s remains)
INFO - root - 2022-02-24 19:16:53.965748: step 4450, total loss = 0.80, batch loss = 0.49 (188.7 examples/sec; 0.042 sec/batch; 2h:17m:50s remains)
INFO - root - 2022-02-24 19:16:54.556279: step 4460, total loss = 0.69, batch loss = 0.38 (115.1 examples/sec; 0.070 sec/batch; 3h:46m:01s remains)
INFO - root - 2022-02-24 19:16:55.323595: step 4470, total loss = 0.66, batch loss = 0.35 (299.4 examples/sec; 0.027 sec/batch; 1h:26m:50s remains)
INFO - root - 2022-02-24 19:16:55.723948: step 4480, total loss = 0.71, batch loss = 0.40 (210.1 examples/sec; 0.038 sec/batch; 2h:03m:46s remains)
INFO - root - 2022-02-24 19:16:56.212512: step 4490, total loss = 0.76, batch loss = 0.45 (142.6 examples/sec; 0.056 sec/batch; 3h:02m:17s remains)
INFO - root - 2022-02-24 19:16:56.725434: step 4500, total loss = 0.75, batch loss = 0.44 (282.8 examples/sec; 0.028 sec/batch; 1h:31m:57s remains)
INFO - root - 2022-02-24 19:16:57.327525: step 4510, total loss = 0.78, batch loss = 0.48 (214.2 examples/sec; 0.037 sec/batch; 2h:01m:23s remains)
INFO - root - 2022-02-24 19:16:57.749676: step 4520, total loss = 0.67, batch loss = 0.36 (125.9 examples/sec; 0.064 sec/batch; 3h:26m:29s remains)
INFO - root - 2022-02-24 19:16:58.105588: step 4530, total loss = 0.69, batch loss = 0.38 (283.8 examples/sec; 0.028 sec/batch; 1h:31m:35s remains)
INFO - root - 2022-02-24 19:16:58.867835: step 4540, total loss = 0.67, batch loss = 0.36 (138.6 examples/sec; 0.058 sec/batch; 3h:07m:30s remains)
INFO - root - 2022-02-24 19:16:59.322602: step 4550, total loss = 0.70, batch loss = 0.39 (169.2 examples/sec; 0.047 sec/batch; 2h:33m:37s remains)
INFO - root - 2022-02-24 19:16:59.732348: step 4560, total loss = 0.66, batch loss = 0.35 (324.0 examples/sec; 0.025 sec/batch; 1h:20m:12s remains)
INFO - root - 2022-02-24 19:17:00.125452: step 4570, total loss = 0.59, batch loss = 0.28 (208.1 examples/sec; 0.038 sec/batch; 2h:04m:55s remains)
INFO - root - 2022-02-24 19:17:00.561773: step 4580, total loss = 0.80, batch loss = 0.49 (211.3 examples/sec; 0.038 sec/batch; 2h:03m:00s remains)
INFO - root - 2022-02-24 19:17:00.953258: step 4590, total loss = 0.71, batch loss = 0.40 (348.2 examples/sec; 0.023 sec/batch; 1h:14m:38s remains)
INFO - root - 2022-02-24 19:17:01.460858: step 4600, total loss = 0.72, batch loss = 0.41 (145.3 examples/sec; 0.055 sec/batch; 2h:58m:48s remains)
INFO - root - 2022-02-24 19:17:02.025648: step 4610, total loss = 0.63, batch loss = 0.32 (205.3 examples/sec; 0.039 sec/batch; 2h:06m:34s remains)
INFO - root - 2022-02-24 19:17:02.385022: step 4620, total loss = 0.71, batch loss = 0.40 (272.8 examples/sec; 0.029 sec/batch; 1h:35m:15s remains)
INFO - root - 2022-02-24 19:17:02.799568: step 4630, total loss = 0.59, batch loss = 0.28 (101.5 examples/sec; 0.079 sec/batch; 4h:15m:58s remains)
INFO - root - 2022-02-24 19:17:03.192237: step 4640, total loss = 0.80, batch loss = 0.50 (278.2 examples/sec; 0.029 sec/batch; 1h:33m:23s remains)
INFO - root - 2022-02-24 19:17:03.620852: step 4650, total loss = 0.79, batch loss = 0.48 (253.2 examples/sec; 0.032 sec/batch; 1h:42m:36s remains)
INFO - root - 2022-02-24 19:17:04.128005: step 4660, total loss = 0.73, batch loss = 0.42 (164.4 examples/sec; 0.049 sec/batch; 2h:38m:01s remains)
INFO - root - 2022-02-24 19:17:04.552329: step 4670, total loss = 0.65, batch loss = 0.34 (357.5 examples/sec; 0.022 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 19:17:04.950364: step 4680, total loss = 0.71, batch loss = 0.40 (202.5 examples/sec; 0.040 sec/batch; 2h:08m:16s remains)
INFO - root - 2022-02-24 19:17:05.415066: step 4690, total loss = 0.70, batch loss = 0.40 (122.0 examples/sec; 0.066 sec/batch; 3h:32m:53s remains)
INFO - root - 2022-02-24 19:17:05.928516: step 4700, total loss = 0.64, batch loss = 0.33 (257.0 examples/sec; 0.031 sec/batch; 1h:41m:04s remains)
INFO - root - 2022-02-24 19:17:06.428224: step 4710, total loss = 0.78, batch loss = 0.47 (336.5 examples/sec; 0.024 sec/batch; 1h:17m:10s remains)
INFO - root - 2022-02-24 19:17:06.820211: step 4720, total loss = 0.60, batch loss = 0.29 (128.8 examples/sec; 0.062 sec/batch; 3h:21m:33s remains)
INFO - root - 2022-02-24 19:17:07.290077: step 4730, total loss = 0.66, batch loss = 0.36 (160.4 examples/sec; 0.050 sec/batch; 2h:41m:51s remains)
INFO - root - 2022-02-24 19:17:07.789846: step 4740, total loss = 0.61, batch loss = 0.30 (92.2 examples/sec; 0.087 sec/batch; 4h:41m:41s remains)
INFO - root - 2022-02-24 19:17:08.216859: step 4750, total loss = 0.67, batch loss = 0.36 (84.3 examples/sec; 0.095 sec/batch; 5h:07m:52s remains)
INFO - root - 2022-02-24 19:17:08.588710: step 4760, total loss = 0.78, batch loss = 0.47 (300.5 examples/sec; 0.027 sec/batch; 1h:26m:25s remains)
INFO - root - 2022-02-24 19:17:09.015260: step 4770, total loss = 0.62, batch loss = 0.31 (78.6 examples/sec; 0.102 sec/batch; 5h:30m:26s remains)
INFO - root - 2022-02-24 19:17:09.401722: step 4780, total loss = 0.73, batch loss = 0.42 (175.2 examples/sec; 0.046 sec/batch; 2h:28m:10s remains)
INFO - root - 2022-02-24 19:17:09.882616: step 4790, total loss = 0.67, batch loss = 0.37 (209.5 examples/sec; 0.038 sec/batch; 2h:03m:54s remains)
INFO - root - 2022-02-24 19:17:10.412005: step 4800, total loss = 0.63, batch loss = 0.33 (107.1 examples/sec; 0.075 sec/batch; 4h:02m:20s remains)
INFO - root - 2022-02-24 19:17:10.884646: step 4810, total loss = 0.62, batch loss = 0.32 (305.0 examples/sec; 0.026 sec/batch; 1h:25m:07s remains)
INFO - root - 2022-02-24 19:17:11.266093: step 4820, total loss = 0.82, batch loss = 0.51 (310.6 examples/sec; 0.026 sec/batch; 1h:23m:34s remains)
INFO - root - 2022-02-24 19:17:11.705819: step 4830, total loss = 0.63, batch loss = 0.32 (128.4 examples/sec; 0.062 sec/batch; 3h:22m:09s remains)
INFO - root - 2022-02-24 19:17:12.156467: step 4840, total loss = 0.78, batch loss = 0.47 (363.7 examples/sec; 0.022 sec/batch; 1h:11m:21s remains)
INFO - root - 2022-02-24 19:17:12.608426: step 4850, total loss = 0.74, batch loss = 0.43 (213.6 examples/sec; 0.037 sec/batch; 2h:01m:30s remains)
INFO - root - 2022-02-24 19:17:13.008843: step 4860, total loss = 0.64, batch loss = 0.33 (250.7 examples/sec; 0.032 sec/batch; 1h:43m:32s remains)
INFO - root - 2022-02-24 19:17:13.402966: step 4870, total loss = 0.61, batch loss = 0.31 (317.8 examples/sec; 0.025 sec/batch; 1h:21m:39s remains)
INFO - root - 2022-02-24 19:17:13.748735: step 4880, total loss = 0.63, batch loss = 0.32 (220.1 examples/sec; 0.036 sec/batch; 1h:57m:54s remains)
INFO - root - 2022-02-24 19:17:14.238965: step 4890, total loss = 0.62, batch loss = 0.31 (304.1 examples/sec; 0.026 sec/batch; 1h:25m:20s remains)
INFO - root - 2022-02-24 19:17:14.698582: step 4900, total loss = 0.78, batch loss = 0.47 (155.2 examples/sec; 0.052 sec/batch; 2h:47m:10s remains)
INFO - root - 2022-02-24 19:17:15.172299: step 4910, total loss = 0.71, batch loss = 0.40 (298.6 examples/sec; 0.027 sec/batch; 1h:26m:53s remains)
INFO - root - 2022-02-24 19:17:15.557701: step 4920, total loss = 0.71, batch loss = 0.40 (276.0 examples/sec; 0.029 sec/batch; 1h:34m:00s remains)
INFO - root - 2022-02-24 19:17:15.990425: step 4930, total loss = 0.75, batch loss = 0.45 (178.9 examples/sec; 0.045 sec/batch; 2h:24m:58s remains)
INFO - root - 2022-02-24 19:17:16.459072: step 4940, total loss = 0.73, batch loss = 0.42 (190.7 examples/sec; 0.042 sec/batch; 2h:16m:02s remains)
INFO - root - 2022-02-24 19:17:16.911264: step 4950, total loss = 0.71, batch loss = 0.40 (264.7 examples/sec; 0.030 sec/batch; 1h:37m:59s remains)
INFO - root - 2022-02-24 19:17:17.298245: step 4960, total loss = 1.01, batch loss = 0.70 (166.5 examples/sec; 0.048 sec/batch; 2h:35m:44s remains)
INFO - root - 2022-02-24 19:17:17.683604: step 4970, total loss = 0.82, batch loss = 0.52 (190.6 examples/sec; 0.042 sec/batch; 2h:16m:03s remains)
INFO - root - 2022-02-24 19:17:18.118657: step 4980, total loss = 0.70, batch loss = 0.39 (135.8 examples/sec; 0.059 sec/batch; 3h:10m:57s remains)
INFO - root - 2022-02-24 19:17:18.539555: step 4990, total loss = 0.71, batch loss = 0.41 (248.1 examples/sec; 0.032 sec/batch; 1h:44m:32s remains)
INFO - root - 2022-02-24 19:17:19.133722: step 5000, total loss = 0.82, batch loss = 0.51 (211.6 examples/sec; 0.038 sec/batch; 2h:02m:35s remains)
INFO - root - 2022-02-24 19:17:19.735175: step 5010, total loss = 0.86, batch loss = 0.56 (259.8 examples/sec; 0.031 sec/batch; 1h:39m:49s remains)
INFO - root - 2022-02-24 19:17:20.183915: step 5020, total loss = 0.64, batch loss = 0.34 (184.6 examples/sec; 0.043 sec/batch; 2h:20m:30s remains)
INFO - root - 2022-02-24 19:17:20.583668: step 5030, total loss = 0.73, batch loss = 0.42 (332.9 examples/sec; 0.024 sec/batch; 1h:17m:53s remains)
INFO - root - 2022-02-24 19:17:21.066204: step 5040, total loss = 0.75, batch loss = 0.44 (129.6 examples/sec; 0.062 sec/batch; 3h:20m:07s remains)
INFO - root - 2022-02-24 19:17:21.574402: step 5050, total loss = 0.62, batch loss = 0.31 (302.6 examples/sec; 0.026 sec/batch; 1h:25m:40s remains)
INFO - root - 2022-02-24 19:17:21.954060: step 5060, total loss = 0.78, batch loss = 0.47 (252.2 examples/sec; 0.032 sec/batch; 1h:42m:47s remains)
INFO - root - 2022-02-24 19:17:22.334895: step 5070, total loss = 0.79, batch loss = 0.48 (277.2 examples/sec; 0.029 sec/batch; 1h:33m:30s remains)
INFO - root - 2022-02-24 19:17:22.746525: step 5080, total loss = 0.66, batch loss = 0.35 (120.7 examples/sec; 0.066 sec/batch; 3h:34m:48s remains)
INFO - root - 2022-02-24 19:17:23.222536: step 5090, total loss = 0.84, batch loss = 0.53 (120.6 examples/sec; 0.066 sec/batch; 3h:34m:56s remains)
INFO - root - 2022-02-24 19:17:23.722088: step 5100, total loss = 0.69, batch loss = 0.38 (153.3 examples/sec; 0.052 sec/batch; 2h:49m:05s remains)
INFO - root - 2022-02-24 19:17:24.227135: step 5110, total loss = 0.67, batch loss = 0.36 (192.0 examples/sec; 0.042 sec/batch; 2h:14m:59s remains)
INFO - root - 2022-02-24 19:17:24.616641: step 5120, total loss = 0.70, batch loss = 0.39 (309.9 examples/sec; 0.026 sec/batch; 1h:23m:38s remains)
INFO - root - 2022-02-24 19:17:25.083682: step 5130, total loss = 0.72, batch loss = 0.41 (103.0 examples/sec; 0.078 sec/batch; 4h:11m:41s remains)
INFO - root - 2022-02-24 19:17:25.546469: step 5140, total loss = 0.64, batch loss = 0.33 (122.1 examples/sec; 0.066 sec/batch; 3h:32m:19s remains)
INFO - root - 2022-02-24 19:17:26.084402: step 5150, total loss = 0.71, batch loss = 0.40 (100.3 examples/sec; 0.080 sec/batch; 4h:18m:15s remains)
INFO - root - 2022-02-24 19:17:26.551950: step 5160, total loss = 0.68, batch loss = 0.38 (273.7 examples/sec; 0.029 sec/batch; 1h:34m:39s remains)
INFO - root - 2022-02-24 19:17:26.983771: step 5170, total loss = 0.74, batch loss = 0.44 (142.3 examples/sec; 0.056 sec/batch; 3h:02m:06s remains)
INFO - root - 2022-02-24 19:17:27.419368: step 5180, total loss = 0.71, batch loss = 0.40 (273.7 examples/sec; 0.029 sec/batch; 1h:34m:38s remains)
INFO - root - 2022-02-24 19:17:27.961281: step 5190, total loss = 0.65, batch loss = 0.34 (128.8 examples/sec; 0.062 sec/batch; 3h:21m:10s remains)
INFO - root - 2022-02-24 19:17:28.473191: step 5200, total loss = 0.70, batch loss = 0.39 (251.5 examples/sec; 0.032 sec/batch; 1h:43m:00s remains)
INFO - root - 2022-02-24 19:17:29.053677: step 5210, total loss = 0.77, batch loss = 0.46 (313.1 examples/sec; 0.026 sec/batch; 1h:22m:43s remains)
INFO - root - 2022-02-24 19:17:29.976591: step 5220, total loss = 0.74, batch loss = 0.43 (141.5 examples/sec; 0.057 sec/batch; 3h:03m:04s remains)
INFO - root - 2022-02-24 19:17:30.452372: step 5230, total loss = 0.68, batch loss = 0.37 (335.5 examples/sec; 0.024 sec/batch; 1h:17m:12s remains)
INFO - root - 2022-02-24 19:17:30.872382: step 5240, total loss = 0.70, batch loss = 0.40 (150.0 examples/sec; 0.053 sec/batch; 2h:52m:37s remains)
INFO - root - 2022-02-24 19:17:31.306042: step 5250, total loss = 0.80, batch loss = 0.49 (141.9 examples/sec; 0.056 sec/batch; 3h:02m:34s remains)
INFO - root - 2022-02-24 19:17:31.738484: step 5260, total loss = 0.63, batch loss = 0.33 (230.3 examples/sec; 0.035 sec/batch; 1h:52m:28s remains)
INFO - root - 2022-02-24 19:17:32.249306: step 5270, total loss = 0.65, batch loss = 0.34 (227.6 examples/sec; 0.035 sec/batch; 1h:53m:45s remains)
INFO - root - 2022-02-24 19:17:32.693134: step 5280, total loss = 0.73, batch loss = 0.42 (171.9 examples/sec; 0.047 sec/batch; 2h:30m:38s remains)
INFO - root - 2022-02-24 19:17:33.294793: step 5290, total loss = 0.77, batch loss = 0.46 (213.7 examples/sec; 0.037 sec/batch; 2h:01m:11s remains)
INFO - root - 2022-02-24 19:17:33.967998: step 5300, total loss = 0.74, batch loss = 0.43 (174.3 examples/sec; 0.046 sec/batch; 2h:28m:31s remains)
INFO - root - 2022-02-24 19:17:34.877975: step 5310, total loss = 0.65, batch loss = 0.35 (130.4 examples/sec; 0.061 sec/batch; 3h:18m:37s remains)
INFO - root - 2022-02-24 19:17:35.392619: step 5320, total loss = 0.73, batch loss = 0.43 (205.5 examples/sec; 0.039 sec/batch; 2h:05m:59s remains)
INFO - root - 2022-02-24 19:17:35.892661: step 5330, total loss = 0.63, batch loss = 0.32 (342.8 examples/sec; 0.023 sec/batch; 1h:15m:31s remains)
INFO - root - 2022-02-24 19:17:36.307798: step 5340, total loss = 0.72, batch loss = 0.41 (298.2 examples/sec; 0.027 sec/batch; 1h:26m:48s remains)
INFO - root - 2022-02-24 19:17:36.878924: step 5350, total loss = 0.62, batch loss = 0.31 (115.4 examples/sec; 0.069 sec/batch; 3h:44m:15s remains)
INFO - root - 2022-02-24 19:17:37.464009: step 5360, total loss = 0.69, batch loss = 0.38 (87.7 examples/sec; 0.091 sec/batch; 4h:55m:16s remains)
INFO - root - 2022-02-24 19:17:37.980823: step 5370, total loss = 0.70, batch loss = 0.39 (246.2 examples/sec; 0.033 sec/batch; 1h:45m:09s remains)
INFO - root - 2022-02-24 19:17:38.427256: step 5380, total loss = 0.80, batch loss = 0.50 (180.8 examples/sec; 0.044 sec/batch; 2h:23m:10s remains)
INFO - root - 2022-02-24 19:17:38.888704: step 5390, total loss = 0.79, batch loss = 0.48 (248.0 examples/sec; 0.032 sec/batch; 1h:44m:20s remains)
INFO - root - 2022-02-24 19:17:39.635341: step 5400, total loss = 0.70, batch loss = 0.40 (167.2 examples/sec; 0.048 sec/batch; 2h:34m:47s remains)
INFO - root - 2022-02-24 19:17:40.098584: step 5410, total loss = 0.77, batch loss = 0.46 (116.9 examples/sec; 0.068 sec/batch; 3h:41m:21s remains)
INFO - root - 2022-02-24 19:17:40.538945: step 5420, total loss = 0.67, batch loss = 0.37 (143.2 examples/sec; 0.056 sec/batch; 3h:00m:43s remains)
INFO - root - 2022-02-24 19:17:40.928472: step 5430, total loss = 0.56, batch loss = 0.25 (172.7 examples/sec; 0.046 sec/batch; 2h:29m:51s remains)
INFO - root - 2022-02-24 19:17:41.435556: step 5440, total loss = 0.71, batch loss = 0.41 (115.2 examples/sec; 0.069 sec/batch; 3h:44m:33s remains)
INFO - root - 2022-02-24 19:17:41.858314: step 5450, total loss = 0.72, batch loss = 0.41 (257.0 examples/sec; 0.031 sec/batch; 1h:40m:39s remains)
INFO - root - 2022-02-24 19:17:42.285746: step 5460, total loss = 0.79, batch loss = 0.48 (125.9 examples/sec; 0.064 sec/batch; 3h:25m:25s remains)
INFO - root - 2022-02-24 19:17:42.633374: step 5470, total loss = 0.62, batch loss = 0.32 (280.2 examples/sec; 0.029 sec/batch; 1h:32m:19s remains)
INFO - root - 2022-02-24 19:17:42.934636: step 5480, total loss = 0.56, batch loss = 0.25 (311.6 examples/sec; 0.026 sec/batch; 1h:23m:01s remains)
INFO - root - 2022-02-24 19:17:43.402348: step 5490, total loss = 0.67, batch loss = 0.36 (200.6 examples/sec; 0.040 sec/batch; 2h:08m:56s remains)
INFO - root - 2022-02-24 19:17:43.916457: step 5500, total loss = 0.62, batch loss = 0.31 (135.4 examples/sec; 0.059 sec/batch; 3h:10m:58s remains)
INFO - root - 2022-02-24 19:17:44.517285: step 5510, total loss = 0.71, batch loss = 0.41 (84.1 examples/sec; 0.095 sec/batch; 5h:07m:34s remains)
INFO - root - 2022-02-24 19:17:44.889409: step 5520, total loss = 0.91, batch loss = 0.60 (160.1 examples/sec; 0.050 sec/batch; 2h:41m:30s remains)
INFO - root - 2022-02-24 19:17:45.297886: step 5530, total loss = 0.63, batch loss = 0.32 (226.1 examples/sec; 0.035 sec/batch; 1h:54m:23s remains)
INFO - root - 2022-02-24 19:17:45.803327: step 5540, total loss = 0.74, batch loss = 0.44 (301.9 examples/sec; 0.027 sec/batch; 1h:25m:40s remains)
INFO - root - 2022-02-24 19:17:46.360495: step 5550, total loss = 0.62, batch loss = 0.32 (238.2 examples/sec; 0.034 sec/batch; 1h:48m:34s remains)
INFO - root - 2022-02-24 19:17:46.690236: step 5560, total loss = 0.94, batch loss = 0.63 (192.8 examples/sec; 0.041 sec/batch; 2h:14m:05s remains)
INFO - root - 2022-02-24 19:17:47.098581: step 5570, total loss = 0.64, batch loss = 0.33 (161.6 examples/sec; 0.050 sec/batch; 2h:40m:02s remains)
INFO - root - 2022-02-24 19:17:47.517754: step 5580, total loss = 0.81, batch loss = 0.51 (110.6 examples/sec; 0.072 sec/batch; 3h:53m:44s remains)
INFO - root - 2022-02-24 19:17:47.929376: step 5590, total loss = 0.65, batch loss = 0.35 (176.3 examples/sec; 0.045 sec/batch; 2h:26m:39s remains)
INFO - root - 2022-02-24 19:17:48.486501: step 5600, total loss = 0.69, batch loss = 0.38 (62.7 examples/sec; 0.128 sec/batch; 6h:52m:06s remains)
INFO - root - 2022-02-24 19:17:48.940718: step 5610, total loss = 0.71, batch loss = 0.40 (195.5 examples/sec; 0.041 sec/batch; 2h:12m:13s remains)
INFO - root - 2022-02-24 19:17:49.327405: step 5620, total loss = 0.70, batch loss = 0.39 (286.2 examples/sec; 0.028 sec/batch; 1h:30m:18s remains)
INFO - root - 2022-02-24 19:17:49.781982: step 5630, total loss = 0.61, batch loss = 0.30 (146.7 examples/sec; 0.055 sec/batch; 2h:56m:15s remains)
INFO - root - 2022-02-24 19:17:50.237871: step 5640, total loss = 0.68, batch loss = 0.37 (152.8 examples/sec; 0.052 sec/batch; 2h:49m:08s remains)
INFO - root - 2022-02-24 19:17:50.714464: step 5650, total loss = 0.79, batch loss = 0.48 (237.7 examples/sec; 0.034 sec/batch; 1h:48m:42s remains)
INFO - root - 2022-02-24 19:17:51.223385: step 5660, total loss = 0.77, batch loss = 0.47 (185.2 examples/sec; 0.043 sec/batch; 2h:19m:34s remains)
INFO - root - 2022-02-24 19:17:51.632553: step 5670, total loss = 0.79, batch loss = 0.48 (89.4 examples/sec; 0.089 sec/batch; 4h:48m:56s remains)
INFO - root - 2022-02-24 19:17:52.008735: step 5680, total loss = 0.63, batch loss = 0.32 (166.9 examples/sec; 0.048 sec/batch; 2h:34m:52s remains)
INFO - root - 2022-02-24 19:17:52.497275: step 5690, total loss = 0.60, batch loss = 0.30 (162.3 examples/sec; 0.049 sec/batch; 2h:39m:14s remains)
INFO - root - 2022-02-24 19:17:52.946934: step 5700, total loss = 0.65, batch loss = 0.34 (381.9 examples/sec; 0.021 sec/batch; 1h:07m:39s remains)
INFO - root - 2022-02-24 19:17:53.508860: step 5710, total loss = 0.79, batch loss = 0.48 (287.0 examples/sec; 0.028 sec/batch; 1h:30m:00s remains)
INFO - root - 2022-02-24 19:17:53.937065: step 5720, total loss = 0.64, batch loss = 0.33 (278.4 examples/sec; 0.029 sec/batch; 1h:32m:48s remains)
INFO - root - 2022-02-24 19:17:54.309681: step 5730, total loss = 0.53, batch loss = 0.22 (258.1 examples/sec; 0.031 sec/batch; 1h:40m:05s remains)
INFO - root - 2022-02-24 19:17:54.855956: step 5740, total loss = 0.69, batch loss = 0.38 (93.2 examples/sec; 0.086 sec/batch; 4h:37m:19s remains)
INFO - root - 2022-02-24 19:17:55.263925: step 5750, total loss = 0.74, batch loss = 0.43 (230.8 examples/sec; 0.035 sec/batch; 1h:51m:55s remains)
INFO - root - 2022-02-24 19:17:55.623614: step 5760, total loss = 0.65, batch loss = 0.34 (380.4 examples/sec; 0.021 sec/batch; 1h:07m:54s remains)
INFO - root - 2022-02-24 19:17:56.011264: step 5770, total loss = 0.79, batch loss = 0.48 (163.9 examples/sec; 0.049 sec/batch; 2h:37m:34s remains)
INFO - root - 2022-02-24 19:17:56.464172: step 5780, total loss = 0.89, batch loss = 0.59 (158.7 examples/sec; 0.050 sec/batch; 2h:42m:45s remains)
INFO - root - 2022-02-24 19:17:56.944126: step 5790, total loss = 0.66, batch loss = 0.35 (382.0 examples/sec; 0.021 sec/batch; 1h:07m:36s remains)
INFO - root - 2022-02-24 19:17:57.315429: step 5800, total loss = 0.67, batch loss = 0.37 (265.3 examples/sec; 0.030 sec/batch; 1h:37m:20s remains)
INFO - root - 2022-02-24 19:17:57.774238: step 5810, total loss = 0.57, batch loss = 0.27 (222.1 examples/sec; 0.036 sec/batch; 1h:56m:16s remains)
INFO - root - 2022-02-24 19:17:58.139911: step 5820, total loss = 0.62, batch loss = 0.31 (182.2 examples/sec; 0.044 sec/batch; 2h:21m:44s remains)
INFO - root - 2022-02-24 19:17:58.534842: step 5830, total loss = 0.70, batch loss = 0.39 (221.4 examples/sec; 0.036 sec/batch; 1h:56m:39s remains)
INFO - root - 2022-02-24 19:17:58.958789: step 5840, total loss = 0.69, batch loss = 0.39 (340.2 examples/sec; 0.024 sec/batch; 1h:15m:54s remains)
INFO - root - 2022-02-24 19:17:59.426694: step 5850, total loss = 0.70, batch loss = 0.39 (169.1 examples/sec; 0.047 sec/batch; 2h:32m:40s remains)
INFO - root - 2022-02-24 19:17:59.859786: step 5860, total loss = 0.59, batch loss = 0.29 (265.4 examples/sec; 0.030 sec/batch; 1h:37m:17s remains)
INFO - root - 2022-02-24 19:18:00.243456: step 5870, total loss = 0.65, batch loss = 0.34 (296.9 examples/sec; 0.027 sec/batch; 1h:26m:57s remains)
INFO - root - 2022-02-24 19:18:00.684959: step 5880, total loss = 0.77, batch loss = 0.46 (150.0 examples/sec; 0.053 sec/batch; 2h:52m:08s remains)
INFO - root - 2022-02-24 19:18:01.128377: step 5890, total loss = 0.62, batch loss = 0.31 (179.9 examples/sec; 0.044 sec/batch; 2h:23m:28s remains)
INFO - root - 2022-02-24 19:18:01.590167: step 5900, total loss = 0.82, batch loss = 0.52 (168.5 examples/sec; 0.047 sec/batch; 2h:33m:09s remains)
INFO - root - 2022-02-24 19:18:02.181691: step 5910, total loss = 0.68, batch loss = 0.38 (262.0 examples/sec; 0.031 sec/batch; 1h:38m:31s remains)
INFO - root - 2022-02-24 19:18:02.628231: step 5920, total loss = 0.65, batch loss = 0.34 (289.2 examples/sec; 0.028 sec/batch; 1h:29m:15s remains)
INFO - root - 2022-02-24 19:18:03.088829: step 5930, total loss = 0.55, batch loss = 0.24 (279.0 examples/sec; 0.029 sec/batch; 1h:32m:30s remains)
INFO - root - 2022-02-24 19:18:03.533649: step 5940, total loss = 0.73, batch loss = 0.42 (107.7 examples/sec; 0.074 sec/batch; 3h:59m:40s remains)
INFO - root - 2022-02-24 19:18:04.100318: step 5950, total loss = 0.75, batch loss = 0.45 (139.6 examples/sec; 0.057 sec/batch; 3h:04m:49s remains)
INFO - root - 2022-02-24 19:18:04.539432: step 5960, total loss = 0.73, batch loss = 0.42 (176.5 examples/sec; 0.045 sec/batch; 2h:26m:10s remains)
INFO - root - 2022-02-24 19:18:04.939516: step 5970, total loss = 0.76, batch loss = 0.45 (347.5 examples/sec; 0.023 sec/batch; 1h:14m:15s remains)
INFO - root - 2022-02-24 19:18:05.378912: step 5980, total loss = 0.70, batch loss = 0.40 (294.3 examples/sec; 0.027 sec/batch; 1h:27m:39s remains)
INFO - root - 2022-02-24 19:18:05.838542: step 5990, total loss = 0.66, batch loss = 0.35 (184.5 examples/sec; 0.043 sec/batch; 2h:19m:51s remains)
INFO - root - 2022-02-24 19:18:06.414483: step 6000, total loss = 0.64, batch loss = 0.33 (155.9 examples/sec; 0.051 sec/batch; 2h:45m:29s remains)
INFO - root - 2022-02-24 19:18:06.942249: step 6010, total loss = 0.83, batch loss = 0.53 (153.7 examples/sec; 0.052 sec/batch; 2h:47m:51s remains)
INFO - root - 2022-02-24 19:18:07.403091: step 6020, total loss = 0.67, batch loss = 0.36 (101.4 examples/sec; 0.079 sec/batch; 4h:14m:22s remains)
INFO - root - 2022-02-24 19:18:07.892230: step 6030, total loss = 0.67, batch loss = 0.37 (149.3 examples/sec; 0.054 sec/batch; 2h:52m:47s remains)
INFO - root - 2022-02-24 19:18:08.441356: step 6040, total loss = 0.64, batch loss = 0.34 (187.0 examples/sec; 0.043 sec/batch; 2h:17m:58s remains)
INFO - root - 2022-02-24 19:18:08.880554: step 6050, total loss = 0.68, batch loss = 0.37 (271.1 examples/sec; 0.030 sec/batch; 1h:35m:07s remains)
INFO - root - 2022-02-24 19:18:09.396708: step 6060, total loss = 0.75, batch loss = 0.45 (109.4 examples/sec; 0.073 sec/batch; 3h:55m:50s remains)
INFO - root - 2022-02-24 19:18:10.273415: step 6070, total loss = 0.70, batch loss = 0.40 (117.3 examples/sec; 0.068 sec/batch; 3h:39m:55s remains)
INFO - root - 2022-02-24 19:18:10.671587: step 6080, total loss = 0.74, batch loss = 0.43 (195.5 examples/sec; 0.041 sec/batch; 2h:11m:53s remains)
INFO - root - 2022-02-24 19:18:11.112733: step 6090, total loss = 0.60, batch loss = 0.30 (125.9 examples/sec; 0.064 sec/batch; 3h:24m:50s remains)
INFO - root - 2022-02-24 19:18:11.680216: step 6100, total loss = 0.67, batch loss = 0.37 (194.0 examples/sec; 0.041 sec/batch; 2h:12m:54s remains)
INFO - root - 2022-02-24 19:18:12.236772: step 6110, total loss = 0.77, batch loss = 0.47 (161.5 examples/sec; 0.050 sec/batch; 2h:39m:42s remains)
INFO - root - 2022-02-24 19:18:12.777756: step 6120, total loss = 0.84, batch loss = 0.54 (121.0 examples/sec; 0.066 sec/batch; 3h:33m:09s remains)
INFO - root - 2022-02-24 19:18:13.240801: step 6130, total loss = 0.68, batch loss = 0.38 (280.8 examples/sec; 0.028 sec/batch; 1h:31m:48s remains)
INFO - root - 2022-02-24 19:18:13.679240: step 6140, total loss = 0.87, batch loss = 0.57 (188.3 examples/sec; 0.042 sec/batch; 2h:16m:56s remains)
INFO - root - 2022-02-24 19:18:14.081315: step 6150, total loss = 0.69, batch loss = 0.39 (101.2 examples/sec; 0.079 sec/batch; 4h:14m:41s remains)
INFO - root - 2022-02-24 19:18:14.592806: step 6160, total loss = 0.66, batch loss = 0.35 (90.3 examples/sec; 0.089 sec/batch; 4h:45m:35s remains)
INFO - root - 2022-02-24 19:18:15.067274: step 6170, total loss = 0.61, batch loss = 0.31 (220.9 examples/sec; 0.036 sec/batch; 1h:56m:41s remains)
INFO - root - 2022-02-24 19:18:15.493780: step 6180, total loss = 0.55, batch loss = 0.24 (108.3 examples/sec; 0.074 sec/batch; 3h:58m:01s remains)
INFO - root - 2022-02-24 19:18:16.222690: step 6190, total loss = 0.61, batch loss = 0.31 (296.7 examples/sec; 0.027 sec/batch; 1h:26m:53s remains)
INFO - root - 2022-02-24 19:18:16.723239: step 6200, total loss = 0.61, batch loss = 0.30 (158.6 examples/sec; 0.050 sec/batch; 2h:42m:30s remains)
INFO - root - 2022-02-24 19:18:17.348967: step 6210, total loss = 0.64, batch loss = 0.34 (316.1 examples/sec; 0.025 sec/batch; 1h:21m:32s remains)
INFO - root - 2022-02-24 19:18:17.774411: step 6220, total loss = 0.69, batch loss = 0.38 (353.5 examples/sec; 0.023 sec/batch; 1h:12m:53s remains)
INFO - root - 2022-02-24 19:18:18.303676: step 6230, total loss = 0.64, batch loss = 0.33 (146.2 examples/sec; 0.055 sec/batch; 2h:56m:17s remains)
INFO - root - 2022-02-24 19:18:18.882636: step 6240, total loss = 0.69, batch loss = 0.39 (66.8 examples/sec; 0.120 sec/batch; 6h:25m:53s remains)
INFO - root - 2022-02-24 19:18:19.343689: step 6250, total loss = 0.83, batch loss = 0.53 (198.0 examples/sec; 0.040 sec/batch; 2h:10m:06s remains)
INFO - root - 2022-02-24 19:18:20.148842: step 6260, total loss = 0.78, batch loss = 0.47 (164.6 examples/sec; 0.049 sec/batch; 2h:36m:32s remains)
INFO - root - 2022-02-24 19:18:20.596461: step 6270, total loss = 0.66, batch loss = 0.36 (135.0 examples/sec; 0.059 sec/batch; 3h:10m:52s remains)
INFO - root - 2022-02-24 19:18:20.982555: step 6280, total loss = 0.59, batch loss = 0.29 (154.5 examples/sec; 0.052 sec/batch; 2h:46m:42s remains)
INFO - root - 2022-02-24 19:18:21.547744: step 6290, total loss = 0.61, batch loss = 0.31 (100.4 examples/sec; 0.080 sec/batch; 4h:16m:36s remains)
INFO - root - 2022-02-24 19:18:21.989033: step 6300, total loss = 0.69, batch loss = 0.39 (145.1 examples/sec; 0.055 sec/batch; 2h:57m:32s remains)
INFO - root - 2022-02-24 19:18:22.464817: step 6310, total loss = 0.79, batch loss = 0.49 (158.7 examples/sec; 0.050 sec/batch; 2h:42m:21s remains)
INFO - root - 2022-02-24 19:18:23.024367: step 6320, total loss = 0.68, batch loss = 0.37 (93.0 examples/sec; 0.086 sec/batch; 4h:37m:02s remains)
INFO - root - 2022-02-24 19:18:23.384463: step 6330, total loss = 0.68, batch loss = 0.37 (187.5 examples/sec; 0.043 sec/batch; 2h:17m:20s remains)
INFO - root - 2022-02-24 19:18:23.827980: step 6340, total loss = 0.77, batch loss = 0.47 (273.0 examples/sec; 0.029 sec/batch; 1h:34m:21s remains)
INFO - root - 2022-02-24 19:18:24.422292: step 6350, total loss = 0.79, batch loss = 0.48 (275.4 examples/sec; 0.029 sec/batch; 1h:33m:30s remains)
INFO - root - 2022-02-24 19:18:24.828874: step 6360, total loss = 0.73, batch loss = 0.43 (182.2 examples/sec; 0.044 sec/batch; 2h:21m:21s remains)
INFO - root - 2022-02-24 19:18:25.266365: step 6370, total loss = 0.81, batch loss = 0.50 (145.0 examples/sec; 0.055 sec/batch; 2h:57m:38s remains)
INFO - root - 2022-02-24 19:18:25.806865: step 6380, total loss = 0.61, batch loss = 0.30 (114.5 examples/sec; 0.070 sec/batch; 3h:44m:54s remains)
INFO - root - 2022-02-24 19:18:26.257223: step 6390, total loss = 0.72, batch loss = 0.41 (319.2 examples/sec; 0.025 sec/batch; 1h:20m:40s remains)
INFO - root - 2022-02-24 19:18:26.616618: step 6400, total loss = 0.82, batch loss = 0.51 (161.9 examples/sec; 0.049 sec/batch; 2h:39m:01s remains)
INFO - root - 2022-02-24 19:18:27.054423: step 6410, total loss = 0.62, batch loss = 0.32 (107.9 examples/sec; 0.074 sec/batch; 3h:58m:41s remains)
INFO - root - 2022-02-24 19:18:27.504857: step 6420, total loss = 0.66, batch loss = 0.35 (105.3 examples/sec; 0.076 sec/batch; 4h:04m:30s remains)
INFO - root - 2022-02-24 19:18:28.009756: step 6430, total loss = 0.69, batch loss = 0.38 (341.8 examples/sec; 0.023 sec/batch; 1h:15m:18s remains)
INFO - root - 2022-02-24 19:18:28.505246: step 6440, total loss = 0.59, batch loss = 0.28 (189.6 examples/sec; 0.042 sec/batch; 2h:15m:44s remains)
INFO - root - 2022-02-24 19:18:28.878995: step 6450, total loss = 0.68, batch loss = 0.38 (337.8 examples/sec; 0.024 sec/batch; 1h:16m:12s remains)
INFO - root - 2022-02-24 19:18:29.326803: step 6460, total loss = 0.71, batch loss = 0.40 (285.8 examples/sec; 0.028 sec/batch; 1h:30m:03s remains)
INFO - root - 2022-02-24 19:18:29.787463: step 6470, total loss = 0.78, batch loss = 0.48 (198.3 examples/sec; 0.040 sec/batch; 2h:09m:47s remains)
INFO - root - 2022-02-24 19:18:30.414835: step 6480, total loss = 0.66, batch loss = 0.35 (88.1 examples/sec; 0.091 sec/batch; 4h:52m:07s remains)
INFO - root - 2022-02-24 19:18:30.830052: step 6490, total loss = 0.60, batch loss = 0.29 (109.6 examples/sec; 0.073 sec/batch; 3h:54m:42s remains)
INFO - root - 2022-02-24 19:18:31.208654: step 6500, total loss = 0.65, batch loss = 0.35 (140.8 examples/sec; 0.057 sec/batch; 3h:02m:47s remains)
INFO - root - 2022-02-24 19:18:31.595336: step 6510, total loss = 0.65, batch loss = 0.34 (204.5 examples/sec; 0.039 sec/batch; 2h:05m:49s remains)
INFO - root - 2022-02-24 19:18:32.026033: step 6520, total loss = 0.70, batch loss = 0.39 (300.7 examples/sec; 0.027 sec/batch; 1h:25m:33s remains)
INFO - root - 2022-02-24 19:18:32.588885: step 6530, total loss = 0.66, batch loss = 0.36 (217.7 examples/sec; 0.037 sec/batch; 1h:58m:10s remains)
INFO - root - 2022-02-24 19:18:33.023653: step 6540, total loss = 0.73, batch loss = 0.42 (312.5 examples/sec; 0.026 sec/batch; 1h:22m:19s remains)
INFO - root - 2022-02-24 19:18:33.464786: step 6550, total loss = 0.87, batch loss = 0.56 (243.7 examples/sec; 0.033 sec/batch; 1h:45m:33s remains)
INFO - root - 2022-02-24 19:18:33.856188: step 6560, total loss = 0.63, batch loss = 0.33 (266.1 examples/sec; 0.030 sec/batch; 1h:36m:39s remains)
INFO - root - 2022-02-24 19:18:34.322468: step 6570, total loss = 0.63, batch loss = 0.32 (224.7 examples/sec; 0.036 sec/batch; 1h:54m:30s remains)
INFO - root - 2022-02-24 19:18:34.834129: step 6580, total loss = 0.74, batch loss = 0.44 (110.9 examples/sec; 0.072 sec/batch; 3h:51m:54s remains)
INFO - root - 2022-02-24 19:18:35.264871: step 6590, total loss = 0.63, batch loss = 0.33 (120.2 examples/sec; 0.067 sec/batch; 3h:33m:54s remains)
INFO - root - 2022-02-24 19:18:35.777429: step 6600, total loss = 0.70, batch loss = 0.40 (240.7 examples/sec; 0.033 sec/batch; 1h:46m:52s remains)
INFO - root - 2022-02-24 19:18:36.285661: step 6610, total loss = 0.75, batch loss = 0.44 (142.9 examples/sec; 0.056 sec/batch; 3h:00m:02s remains)
INFO - root - 2022-02-24 19:18:36.843179: step 6620, total loss = 0.61, batch loss = 0.30 (127.9 examples/sec; 0.063 sec/batch; 3h:21m:08s remains)
INFO - root - 2022-02-24 19:18:37.286154: step 6630, total loss = 0.65, batch loss = 0.34 (106.6 examples/sec; 0.075 sec/batch; 4h:01m:11s remains)
INFO - root - 2022-02-24 19:18:37.728199: step 6640, total loss = 0.72, batch loss = 0.41 (268.4 examples/sec; 0.030 sec/batch; 1h:35m:48s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-6649 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-6649 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:18:38.657946: step 6650, total loss = 0.76, batch loss = 0.45 (292.3 examples/sec; 0.027 sec/batch; 1h:27m:58s remains)
INFO - root - 2022-02-24 19:18:38.890927: step 6660, total loss = 0.63, batch loss = 0.32 (344.1 examples/sec; 0.023 sec/batch; 1h:14m:43s remains)
INFO - root - 2022-02-24 19:18:39.202293: step 6670, total loss = 0.62, batch loss = 0.31 (97.5 examples/sec; 0.082 sec/batch; 4h:23m:38s remains)
INFO - root - 2022-02-24 19:18:39.650396: step 6680, total loss = 0.65, batch loss = 0.34 (258.2 examples/sec; 0.031 sec/batch; 1h:39m:33s remains)
INFO - root - 2022-02-24 19:18:40.099304: step 6690, total loss = 0.61, batch loss = 0.30 (268.0 examples/sec; 0.030 sec/batch; 1h:35m:56s remains)
INFO - root - 2022-02-24 19:18:40.482739: step 6700, total loss = 0.68, batch loss = 0.38 (255.0 examples/sec; 0.031 sec/batch; 1h:40m:49s remains)
INFO - root - 2022-02-24 19:18:41.044938: step 6710, total loss = 0.78, batch loss = 0.48 (201.6 examples/sec; 0.040 sec/batch; 2h:07m:32s remains)
INFO - root - 2022-02-24 19:18:41.524432: step 6720, total loss = 0.79, batch loss = 0.48 (108.3 examples/sec; 0.074 sec/batch; 3h:57m:20s remains)
INFO - root - 2022-02-24 19:18:41.975215: step 6730, total loss = 0.67, batch loss = 0.36 (158.2 examples/sec; 0.051 sec/batch; 2h:42m:26s remains)
INFO - root - 2022-02-24 19:18:42.361889: step 6740, total loss = 0.63, batch loss = 0.33 (148.5 examples/sec; 0.054 sec/batch; 2h:53m:03s remains)
INFO - root - 2022-02-24 19:18:42.693267: step 6750, total loss = 0.65, batch loss = 0.35 (268.0 examples/sec; 0.030 sec/batch; 1h:35m:54s remains)
INFO - root - 2022-02-24 19:18:43.125935: step 6760, total loss = 0.76, batch loss = 0.46 (163.3 examples/sec; 0.049 sec/batch; 2h:37m:21s remains)
INFO - root - 2022-02-24 19:18:43.602485: step 6770, total loss = 0.67, batch loss = 0.37 (166.6 examples/sec; 0.048 sec/batch; 2h:34m:16s remains)
INFO - root - 2022-02-24 19:18:44.124586: step 6780, total loss = 0.66, batch loss = 0.36 (265.9 examples/sec; 0.030 sec/batch; 1h:36m:38s remains)
INFO - root - 2022-02-24 19:18:44.520642: step 6790, total loss = 0.62, batch loss = 0.31 (253.5 examples/sec; 0.032 sec/batch; 1h:41m:22s remains)
INFO - root - 2022-02-24 19:18:45.026947: step 6800, total loss = 0.81, batch loss = 0.51 (93.1 examples/sec; 0.086 sec/batch; 4h:36m:04s remains)
INFO - root - 2022-02-24 19:18:46.259055: step 6810, total loss = 0.62, batch loss = 0.32 (123.5 examples/sec; 0.065 sec/batch; 3h:28m:05s remains)
INFO - root - 2022-02-24 19:18:46.797049: step 6820, total loss = 0.67, batch loss = 0.37 (294.6 examples/sec; 0.027 sec/batch; 1h:27m:12s remains)
INFO - root - 2022-02-24 19:18:47.307690: step 6830, total loss = 0.63, batch loss = 0.33 (157.6 examples/sec; 0.051 sec/batch; 2h:42m:59s remains)
INFO - root - 2022-02-24 19:18:47.741464: step 6840, total loss = 0.63, batch loss = 0.33 (321.1 examples/sec; 0.025 sec/batch; 1h:20m:00s remains)
INFO - root - 2022-02-24 19:18:48.320554: step 6850, total loss = 0.74, batch loss = 0.44 (161.8 examples/sec; 0.049 sec/batch; 2h:38m:47s remains)
INFO - root - 2022-02-24 19:18:48.863296: step 6860, total loss = 0.76, batch loss = 0.45 (287.5 examples/sec; 0.028 sec/batch; 1h:29m:20s remains)
INFO - root - 2022-02-24 19:18:49.458146: step 6870, total loss = 0.67, batch loss = 0.37 (125.4 examples/sec; 0.064 sec/batch; 3h:24m:46s remains)
INFO - root - 2022-02-24 19:18:49.852015: step 6880, total loss = 0.66, batch loss = 0.35 (200.0 examples/sec; 0.040 sec/batch; 2h:08m:25s remains)
INFO - root - 2022-02-24 19:18:50.347225: step 6890, total loss = 0.68, batch loss = 0.38 (283.1 examples/sec; 0.028 sec/batch; 1h:30m:43s remains)
INFO - root - 2022-02-24 19:18:51.153888: step 6900, total loss = 0.73, batch loss = 0.43 (249.6 examples/sec; 0.032 sec/batch; 1h:42m:53s remains)
INFO - root - 2022-02-24 19:18:51.631587: step 6910, total loss = 0.60, batch loss = 0.29 (280.9 examples/sec; 0.028 sec/batch; 1h:31m:24s remains)
INFO - root - 2022-02-24 19:18:52.047226: step 6920, total loss = 0.67, batch loss = 0.36 (330.2 examples/sec; 0.024 sec/batch; 1h:17m:45s remains)
INFO - root - 2022-02-24 19:18:52.507062: step 6930, total loss = 0.63, batch loss = 0.32 (189.4 examples/sec; 0.042 sec/batch; 2h:15m:33s remains)
INFO - root - 2022-02-24 19:18:52.971856: step 6940, total loss = 0.67, batch loss = 0.36 (169.2 examples/sec; 0.047 sec/batch; 2h:31m:46s remains)
INFO - root - 2022-02-24 19:18:53.410998: step 6950, total loss = 0.64, batch loss = 0.33 (190.5 examples/sec; 0.042 sec/batch; 2h:14m:45s remains)
INFO - root - 2022-02-24 19:18:53.918004: step 6960, total loss = 0.72, batch loss = 0.41 (253.8 examples/sec; 0.032 sec/batch; 1h:41m:09s remains)
INFO - root - 2022-02-24 19:18:54.395811: step 6970, total loss = 0.71, batch loss = 0.40 (192.0 examples/sec; 0.042 sec/batch; 2h:13m:42s remains)
INFO - root - 2022-02-24 19:18:54.778088: step 6980, total loss = 0.64, batch loss = 0.33 (214.0 examples/sec; 0.037 sec/batch; 1h:59m:56s remains)
INFO - root - 2022-02-24 19:18:55.258354: step 6990, total loss = 0.66, batch loss = 0.36 (102.9 examples/sec; 0.078 sec/batch; 4h:09m:30s remains)
INFO - root - 2022-02-24 19:18:55.827783: step 7000, total loss = 0.72, batch loss = 0.42 (189.3 examples/sec; 0.042 sec/batch; 2h:15m:34s remains)
INFO - root - 2022-02-24 19:18:56.892693: step 7010, total loss = 0.76, batch loss = 0.46 (170.3 examples/sec; 0.047 sec/batch; 2h:30m:40s remains)
INFO - root - 2022-02-24 19:18:57.644668: step 7020, total loss = 0.70, batch loss = 0.39 (90.8 examples/sec; 0.088 sec/batch; 4h:42m:29s remains)
INFO - root - 2022-02-24 19:18:58.385335: step 7030, total loss = 0.92, batch loss = 0.62 (333.5 examples/sec; 0.024 sec/batch; 1h:16m:56s remains)
INFO - root - 2022-02-24 19:18:58.971216: step 7040, total loss = 0.76, batch loss = 0.46 (174.1 examples/sec; 0.046 sec/batch; 2h:27m:25s remains)
INFO - root - 2022-02-24 19:18:59.481154: step 7050, total loss = 0.67, batch loss = 0.36 (157.9 examples/sec; 0.051 sec/batch; 2h:42m:30s remains)
INFO - root - 2022-02-24 19:19:00.098385: step 7060, total loss = 0.67, batch loss = 0.36 (184.8 examples/sec; 0.043 sec/batch; 2h:18m:51s remains)
INFO - root - 2022-02-24 19:19:00.618220: step 7070, total loss = 0.62, batch loss = 0.32 (187.5 examples/sec; 0.043 sec/batch; 2h:16m:52s remains)
INFO - root - 2022-02-24 19:19:01.537805: step 7080, total loss = 0.80, batch loss = 0.50 (57.4 examples/sec; 0.139 sec/batch; 7h:26m:56s remains)
INFO - root - 2022-02-24 19:19:02.273833: step 7090, total loss = 0.69, batch loss = 0.39 (77.0 examples/sec; 0.104 sec/batch; 5h:33m:22s remains)
INFO - root - 2022-02-24 19:19:02.961607: step 7100, total loss = 0.68, batch loss = 0.38 (123.9 examples/sec; 0.065 sec/batch; 3h:26m:58s remains)
INFO - root - 2022-02-24 19:19:03.645574: step 7110, total loss = 0.65, batch loss = 0.35 (168.0 examples/sec; 0.048 sec/batch; 2h:32m:41s remains)
INFO - root - 2022-02-24 19:19:04.239178: step 7120, total loss = 0.64, batch loss = 0.34 (254.5 examples/sec; 0.031 sec/batch; 1h:40m:46s remains)
INFO - root - 2022-02-24 19:19:04.841755: step 7130, total loss = 0.72, batch loss = 0.42 (190.1 examples/sec; 0.042 sec/batch; 2h:14m:56s remains)
INFO - root - 2022-02-24 19:19:05.471566: step 7140, total loss = 0.72, batch loss = 0.41 (116.3 examples/sec; 0.069 sec/batch; 3h:40m:33s remains)
INFO - root - 2022-02-24 19:19:05.905398: step 7150, total loss = 0.81, batch loss = 0.50 (225.2 examples/sec; 0.036 sec/batch; 1h:53m:54s remains)
INFO - root - 2022-02-24 19:19:06.798729: step 7160, total loss = 0.67, batch loss = 0.37 (56.3 examples/sec; 0.142 sec/batch; 7h:35m:18s remains)
INFO - root - 2022-02-24 19:19:07.392043: step 7170, total loss = 0.70, batch loss = 0.40 (187.5 examples/sec; 0.043 sec/batch; 2h:16m:46s remains)
INFO - root - 2022-02-24 19:19:08.296382: step 7180, total loss = 0.59, batch loss = 0.29 (145.7 examples/sec; 0.055 sec/batch; 2h:56m:00s remains)
INFO - root - 2022-02-24 19:19:08.797975: step 7190, total loss = 0.67, batch loss = 0.37 (179.1 examples/sec; 0.045 sec/batch; 2h:23m:10s remains)
INFO - root - 2022-02-24 19:19:09.357230: step 7200, total loss = 0.66, batch loss = 0.36 (62.5 examples/sec; 0.128 sec/batch; 6h:50m:12s remains)
INFO - root - 2022-02-24 19:19:09.874761: step 7210, total loss = 0.69, batch loss = 0.39 (328.3 examples/sec; 0.024 sec/batch; 1h:18m:05s remains)
INFO - root - 2022-02-24 19:19:10.398219: step 7220, total loss = 0.77, batch loss = 0.46 (287.3 examples/sec; 0.028 sec/batch; 1h:29m:13s remains)
INFO - root - 2022-02-24 19:19:10.759677: step 7230, total loss = 0.55, batch loss = 0.24 (134.4 examples/sec; 0.060 sec/batch; 3h:10m:47s remains)
INFO - root - 2022-02-24 19:19:11.182596: step 7240, total loss = 0.57, batch loss = 0.27 (322.1 examples/sec; 0.025 sec/batch; 1h:19m:34s remains)
INFO - root - 2022-02-24 19:19:11.607344: step 7250, total loss = 0.73, batch loss = 0.42 (277.8 examples/sec; 0.029 sec/batch; 1h:32m:16s remains)
INFO - root - 2022-02-24 19:19:12.156897: step 7260, total loss = 0.64, batch loss = 0.34 (155.0 examples/sec; 0.052 sec/batch; 2h:45m:23s remains)
INFO - root - 2022-02-24 19:19:12.545275: step 7270, total loss = 0.57, batch loss = 0.27 (263.6 examples/sec; 0.030 sec/batch; 1h:37m:14s remains)
INFO - root - 2022-02-24 19:19:12.898203: step 7280, total loss = 0.80, batch loss = 0.50 (334.4 examples/sec; 0.024 sec/batch; 1h:16m:38s remains)
INFO - root - 2022-02-24 19:19:13.310454: step 7290, total loss = 0.76, batch loss = 0.46 (144.1 examples/sec; 0.056 sec/batch; 2h:57m:51s remains)
INFO - root - 2022-02-24 19:19:13.675280: step 7300, total loss = 0.79, batch loss = 0.48 (142.7 examples/sec; 0.056 sec/batch; 2h:59m:32s remains)
INFO - root - 2022-02-24 19:19:14.204410: step 7310, total loss = 0.83, batch loss = 0.53 (316.0 examples/sec; 0.025 sec/batch; 1h:21m:05s remains)
INFO - root - 2022-02-24 19:19:14.659602: step 7320, total loss = 0.61, batch loss = 0.30 (193.4 examples/sec; 0.041 sec/batch; 2h:12m:30s remains)
INFO - root - 2022-02-24 19:19:15.016314: step 7330, total loss = 0.61, batch loss = 0.31 (338.3 examples/sec; 0.024 sec/batch; 1h:15m:44s remains)
INFO - root - 2022-02-24 19:19:15.408847: step 7340, total loss = 0.83, batch loss = 0.53 (132.9 examples/sec; 0.060 sec/batch; 3h:12m:46s remains)
INFO - root - 2022-02-24 19:19:15.817595: step 7350, total loss = 0.66, batch loss = 0.36 (328.5 examples/sec; 0.024 sec/batch; 1h:17m:58s remains)
INFO - root - 2022-02-24 19:19:16.343061: step 7360, total loss = 0.68, batch loss = 0.37 (62.6 examples/sec; 0.128 sec/batch; 6h:48m:56s remains)
INFO - root - 2022-02-24 19:19:16.842873: step 7370, total loss = 0.68, batch loss = 0.38 (145.3 examples/sec; 0.055 sec/batch; 2h:56m:19s remains)
INFO - root - 2022-02-24 19:19:17.221004: step 7380, total loss = 0.66, batch loss = 0.36 (249.7 examples/sec; 0.032 sec/batch; 1h:42m:35s remains)
INFO - root - 2022-02-24 19:19:17.644243: step 7390, total loss = 0.59, batch loss = 0.29 (170.0 examples/sec; 0.047 sec/batch; 2h:30m:39s remains)
INFO - root - 2022-02-24 19:19:18.050262: step 7400, total loss = 0.66, batch loss = 0.35 (182.1 examples/sec; 0.044 sec/batch; 2h:20m:37s remains)
INFO - root - 2022-02-24 19:19:18.630890: step 7410, total loss = 0.64, batch loss = 0.33 (227.7 examples/sec; 0.035 sec/batch; 1h:52m:27s remains)
INFO - root - 2022-02-24 19:19:19.086208: step 7420, total loss = 0.64, batch loss = 0.34 (229.9 examples/sec; 0.035 sec/batch; 1h:51m:25s remains)
INFO - root - 2022-02-24 19:19:19.573325: step 7430, total loss = 0.59, batch loss = 0.29 (166.1 examples/sec; 0.048 sec/batch; 2h:34m:10s remains)
INFO - root - 2022-02-24 19:19:19.954831: step 7440, total loss = 0.61, batch loss = 0.31 (316.4 examples/sec; 0.025 sec/batch; 1h:20m:56s remains)
INFO - root - 2022-02-24 19:19:20.376326: step 7450, total loss = 0.64, batch loss = 0.33 (257.3 examples/sec; 0.031 sec/batch; 1h:39m:30s remains)
INFO - root - 2022-02-24 19:19:20.837986: step 7460, total loss = 0.55, batch loss = 0.25 (147.6 examples/sec; 0.054 sec/batch; 2h:53m:32s remains)
INFO - root - 2022-02-24 19:19:21.345595: step 7470, total loss = 0.65, batch loss = 0.34 (276.6 examples/sec; 0.029 sec/batch; 1h:32m:34s remains)
INFO - root - 2022-02-24 19:19:21.776984: step 7480, total loss = 0.68, batch loss = 0.38 (154.6 examples/sec; 0.052 sec/batch; 2h:45m:37s remains)
INFO - root - 2022-02-24 19:19:22.171444: step 7490, total loss = 0.56, batch loss = 0.26 (312.5 examples/sec; 0.026 sec/batch; 1h:21m:55s remains)
INFO - root - 2022-02-24 19:19:22.669185: step 7500, total loss = 0.65, batch loss = 0.35 (127.0 examples/sec; 0.063 sec/batch; 3h:21m:32s remains)
INFO - root - 2022-02-24 19:19:23.171587: step 7510, total loss = 0.64, batch loss = 0.34 (220.1 examples/sec; 0.036 sec/batch; 1h:56m:17s remains)
INFO - root - 2022-02-24 19:19:23.652641: step 7520, total loss = 0.59, batch loss = 0.29 (113.0 examples/sec; 0.071 sec/batch; 3h:46m:32s remains)
INFO - root - 2022-02-24 19:19:24.030189: step 7530, total loss = 0.75, batch loss = 0.45 (203.9 examples/sec; 0.039 sec/batch; 2h:05m:30s remains)
INFO - root - 2022-02-24 19:19:24.440294: step 7540, total loss = 0.55, batch loss = 0.25 (145.5 examples/sec; 0.055 sec/batch; 2h:55m:53s remains)
INFO - root - 2022-02-24 19:19:24.794000: step 7550, total loss = 0.74, batch loss = 0.44 (199.7 examples/sec; 0.040 sec/batch; 2h:08m:10s remains)
INFO - root - 2022-02-24 19:19:25.310499: step 7560, total loss = 0.64, batch loss = 0.34 (118.8 examples/sec; 0.067 sec/batch; 3h:35m:26s remains)
INFO - root - 2022-02-24 19:19:25.955333: step 7570, total loss = 0.75, batch loss = 0.45 (252.4 examples/sec; 0.032 sec/batch; 1h:41m:24s remains)
INFO - root - 2022-02-24 19:19:26.412976: step 7580, total loss = 0.63, batch loss = 0.33 (180.2 examples/sec; 0.044 sec/batch; 2h:22m:00s remains)
INFO - root - 2022-02-24 19:19:27.002916: step 7590, total loss = 0.72, batch loss = 0.41 (270.2 examples/sec; 0.030 sec/batch; 1h:34m:43s remains)
INFO - root - 2022-02-24 19:19:27.466881: step 7600, total loss = 0.63, batch loss = 0.32 (184.6 examples/sec; 0.043 sec/batch; 2h:18m:34s remains)
INFO - root - 2022-02-24 19:19:28.023213: step 7610, total loss = 0.60, batch loss = 0.30 (254.8 examples/sec; 0.031 sec/batch; 1h:40m:24s remains)
INFO - root - 2022-02-24 19:19:28.551571: step 7620, total loss = 0.59, batch loss = 0.29 (332.5 examples/sec; 0.024 sec/batch; 1h:16m:57s remains)
INFO - root - 2022-02-24 19:19:29.064870: step 7630, total loss = 0.57, batch loss = 0.27 (301.4 examples/sec; 0.027 sec/batch; 1h:24m:53s remains)
INFO - root - 2022-02-24 19:19:29.618101: step 7640, total loss = 0.71, batch loss = 0.40 (226.9 examples/sec; 0.035 sec/batch; 1h:52m:44s remains)
INFO - root - 2022-02-24 19:19:30.201272: step 7650, total loss = 0.72, batch loss = 0.42 (219.3 examples/sec; 0.036 sec/batch; 1h:56m:39s remains)
INFO - root - 2022-02-24 19:19:30.770803: step 7660, total loss = 0.63, batch loss = 0.33 (170.9 examples/sec; 0.047 sec/batch; 2h:29m:39s remains)
INFO - root - 2022-02-24 19:19:31.147728: step 7670, total loss = 0.63, batch loss = 0.33 (240.9 examples/sec; 0.033 sec/batch; 1h:46m:09s remains)
INFO - root - 2022-02-24 19:19:31.808686: step 7680, total loss = 0.63, batch loss = 0.33 (162.2 examples/sec; 0.049 sec/batch; 2h:37m:38s remains)
INFO - root - 2022-02-24 19:19:32.261943: step 7690, total loss = 0.62, batch loss = 0.32 (219.2 examples/sec; 0.037 sec/batch; 1h:56m:41s remains)
INFO - root - 2022-02-24 19:19:32.770592: step 7700, total loss = 0.64, batch loss = 0.33 (296.0 examples/sec; 0.027 sec/batch; 1h:26m:24s remains)
INFO - root - 2022-02-24 19:19:33.287854: step 7710, total loss = 0.58, batch loss = 0.28 (195.4 examples/sec; 0.041 sec/batch; 2h:10m:54s remains)
INFO - root - 2022-02-24 19:19:33.806263: step 7720, total loss = 0.61, batch loss = 0.31 (137.3 examples/sec; 0.058 sec/batch; 3h:06m:14s remains)
INFO - root - 2022-02-24 19:19:34.286491: step 7730, total loss = 0.63, batch loss = 0.33 (110.2 examples/sec; 0.073 sec/batch; 3h:52m:06s remains)
INFO - root - 2022-02-24 19:19:34.706070: step 7740, total loss = 0.65, batch loss = 0.35 (157.7 examples/sec; 0.051 sec/batch; 2h:42m:10s remains)
INFO - root - 2022-02-24 19:19:35.219631: step 7750, total loss = 0.58, batch loss = 0.27 (131.6 examples/sec; 0.061 sec/batch; 3h:14m:20s remains)
INFO - root - 2022-02-24 19:19:35.638290: step 7760, total loss = 0.69, batch loss = 0.39 (227.9 examples/sec; 0.035 sec/batch; 1h:52m:11s remains)
INFO - root - 2022-02-24 19:19:36.188331: step 7770, total loss = 0.73, batch loss = 0.43 (107.1 examples/sec; 0.075 sec/batch; 3h:58m:43s remains)
INFO - root - 2022-02-24 19:19:36.672218: step 7780, total loss = 0.72, batch loss = 0.42 (261.9 examples/sec; 0.031 sec/batch; 1h:37m:35s remains)
INFO - root - 2022-02-24 19:19:37.473497: step 7790, total loss = 0.62, batch loss = 0.31 (285.0 examples/sec; 0.028 sec/batch; 1h:29m:41s remains)
INFO - root - 2022-02-24 19:19:37.896820: step 7800, total loss = 0.71, batch loss = 0.41 (183.0 examples/sec; 0.044 sec/batch; 2h:19m:40s remains)
INFO - root - 2022-02-24 19:19:38.379398: step 7810, total loss = 0.76, batch loss = 0.45 (201.7 examples/sec; 0.040 sec/batch; 2h:06m:44s remains)
INFO - root - 2022-02-24 19:19:38.768102: step 7820, total loss = 0.67, batch loss = 0.37 (208.6 examples/sec; 0.038 sec/batch; 2h:02m:30s remains)
INFO - root - 2022-02-24 19:19:39.215268: step 7830, total loss = 0.61, batch loss = 0.31 (162.7 examples/sec; 0.049 sec/batch; 2h:37m:06s remains)
INFO - root - 2022-02-24 19:19:39.748360: step 7840, total loss = 0.70, batch loss = 0.40 (219.0 examples/sec; 0.037 sec/batch; 1h:56m:39s remains)
INFO - root - 2022-02-24 19:19:40.263831: step 7850, total loss = 0.57, batch loss = 0.27 (303.5 examples/sec; 0.026 sec/batch; 1h:24m:12s remains)
INFO - root - 2022-02-24 19:19:40.750244: step 7860, total loss = 0.64, batch loss = 0.34 (118.2 examples/sec; 0.068 sec/batch; 3h:36m:15s remains)
INFO - root - 2022-02-24 19:19:41.101981: step 7870, total loss = 0.80, batch loss = 0.50 (354.9 examples/sec; 0.023 sec/batch; 1h:11m:59s remains)
INFO - root - 2022-02-24 19:19:41.700166: step 7880, total loss = 0.81, batch loss = 0.51 (154.6 examples/sec; 0.052 sec/batch; 2h:45m:17s remains)
INFO - root - 2022-02-24 19:19:42.514299: step 7890, total loss = 0.62, batch loss = 0.31 (265.3 examples/sec; 0.030 sec/batch; 1h:36m:18s remains)
INFO - root - 2022-02-24 19:19:42.873723: step 7900, total loss = 0.69, batch loss = 0.38 (210.1 examples/sec; 0.038 sec/batch; 2h:01m:36s remains)
INFO - root - 2022-02-24 19:19:43.373097: step 7910, total loss = 0.87, batch loss = 0.57 (337.2 examples/sec; 0.024 sec/batch; 1h:15m:44s remains)
INFO - root - 2022-02-24 19:19:43.828798: step 7920, total loss = 0.66, batch loss = 0.36 (195.9 examples/sec; 0.041 sec/batch; 2h:10m:23s remains)
INFO - root - 2022-02-24 19:19:44.296331: step 7930, total loss = 0.57, batch loss = 0.26 (190.0 examples/sec; 0.042 sec/batch; 2h:14m:26s remains)
INFO - root - 2022-02-24 19:19:44.790778: step 7940, total loss = 0.62, batch loss = 0.31 (292.7 examples/sec; 0.027 sec/batch; 1h:27m:15s remains)
INFO - root - 2022-02-24 19:19:45.138611: step 7950, total loss = 0.70, batch loss = 0.39 (105.4 examples/sec; 0.076 sec/batch; 4h:02m:19s remains)
INFO - root - 2022-02-24 19:19:45.493782: step 7960, total loss = 0.65, batch loss = 0.35 (280.6 examples/sec; 0.029 sec/batch; 1h:31m:01s remains)
INFO - root - 2022-02-24 19:19:45.987605: step 7970, total loss = 0.65, batch loss = 0.35 (210.8 examples/sec; 0.038 sec/batch; 2h:01m:09s remains)
INFO - root - 2022-02-24 19:19:46.408502: step 7980, total loss = 0.57, batch loss = 0.27 (171.3 examples/sec; 0.047 sec/batch; 2h:29m:03s remains)
INFO - root - 2022-02-24 19:19:46.970661: step 7990, total loss = 0.62, batch loss = 0.32 (138.5 examples/sec; 0.058 sec/batch; 3h:04m:19s remains)
INFO - root - 2022-02-24 19:19:47.396219: step 8000, total loss = 0.65, batch loss = 0.35 (151.7 examples/sec; 0.053 sec/batch; 2h:48m:20s remains)
INFO - root - 2022-02-24 19:19:47.843674: step 8010, total loss = 0.84, batch loss = 0.54 (218.6 examples/sec; 0.037 sec/batch; 1h:56m:49s remains)
INFO - root - 2022-02-24 19:19:48.378995: step 8020, total loss = 0.70, batch loss = 0.39 (95.7 examples/sec; 0.084 sec/batch; 4h:26m:43s remains)
INFO - root - 2022-02-24 19:19:48.838713: step 8030, total loss = 0.62, batch loss = 0.32 (157.8 examples/sec; 0.051 sec/batch; 2h:41m:47s remains)
INFO - root - 2022-02-24 19:19:49.253085: step 8040, total loss = 0.62, batch loss = 0.31 (148.7 examples/sec; 0.054 sec/batch; 2h:51m:41s remains)
INFO - root - 2022-02-24 19:19:49.658063: step 8050, total loss = 0.74, batch loss = 0.43 (275.1 examples/sec; 0.029 sec/batch; 1h:32m:46s remains)
INFO - root - 2022-02-24 19:19:50.066422: step 8060, total loss = 0.64, batch loss = 0.34 (319.9 examples/sec; 0.025 sec/batch; 1h:19m:46s remains)
INFO - root - 2022-02-24 19:19:50.552142: step 8070, total loss = 0.76, batch loss = 0.46 (269.2 examples/sec; 0.030 sec/batch; 1h:34m:48s remains)
INFO - root - 2022-02-24 19:19:51.053525: step 8080, total loss = 0.72, batch loss = 0.42 (132.6 examples/sec; 0.060 sec/batch; 3h:12m:30s remains)
INFO - root - 2022-02-24 19:19:51.482309: step 8090, total loss = 0.64, batch loss = 0.34 (251.2 examples/sec; 0.032 sec/batch; 1h:41m:36s remains)
INFO - root - 2022-02-24 19:19:51.899731: step 8100, total loss = 0.59, batch loss = 0.29 (185.4 examples/sec; 0.043 sec/batch; 2h:17m:37s remains)
INFO - root - 2022-02-24 19:19:52.504652: step 8110, total loss = 0.58, batch loss = 0.27 (162.9 examples/sec; 0.049 sec/batch; 2h:36m:37s remains)
INFO - root - 2022-02-24 19:19:52.992894: step 8120, total loss = 0.58, batch loss = 0.28 (336.0 examples/sec; 0.024 sec/batch; 1h:15m:56s remains)
INFO - root - 2022-02-24 19:19:53.559979: step 8130, total loss = 0.58, batch loss = 0.28 (171.1 examples/sec; 0.047 sec/batch; 2h:29m:08s remains)
INFO - root - 2022-02-24 19:19:53.923558: step 8140, total loss = 0.60, batch loss = 0.30 (210.0 examples/sec; 0.038 sec/batch; 2h:01m:31s remains)
INFO - root - 2022-02-24 19:19:54.255761: step 8150, total loss = 0.70, batch loss = 0.40 (301.5 examples/sec; 0.027 sec/batch; 1h:24m:37s remains)
INFO - root - 2022-02-24 19:19:54.746992: step 8160, total loss = 0.71, batch loss = 0.41 (130.6 examples/sec; 0.061 sec/batch; 3h:15m:23s remains)
INFO - root - 2022-02-24 19:19:55.217103: step 8170, total loss = 0.68, batch loss = 0.37 (120.1 examples/sec; 0.067 sec/batch; 3h:32m:28s remains)
INFO - root - 2022-02-24 19:19:55.638044: step 8180, total loss = 0.67, batch loss = 0.37 (336.4 examples/sec; 0.024 sec/batch; 1h:15m:50s remains)
INFO - root - 2022-02-24 19:19:56.009447: step 8190, total loss = 0.73, batch loss = 0.42 (216.0 examples/sec; 0.037 sec/batch; 1h:58m:04s remains)
INFO - root - 2022-02-24 19:19:56.435873: step 8200, total loss = 0.73, batch loss = 0.43 (194.7 examples/sec; 0.041 sec/batch; 2h:11m:01s remains)
INFO - root - 2022-02-24 19:19:56.918327: step 8210, total loss = 0.59, batch loss = 0.29 (126.6 examples/sec; 0.063 sec/batch; 3h:21m:28s remains)
INFO - root - 2022-02-24 19:19:57.468815: step 8220, total loss = 0.70, batch loss = 0.40 (123.8 examples/sec; 0.065 sec/batch; 3h:25m:57s remains)
INFO - root - 2022-02-24 19:19:57.925928: step 8230, total loss = 0.67, batch loss = 0.37 (293.5 examples/sec; 0.027 sec/batch; 1h:26m:53s remains)
INFO - root - 2022-02-24 19:19:58.308507: step 8240, total loss = 0.80, batch loss = 0.50 (230.3 examples/sec; 0.035 sec/batch; 1h:50m:44s remains)
INFO - root - 2022-02-24 19:19:58.706427: step 8250, total loss = 0.65, batch loss = 0.34 (323.9 examples/sec; 0.025 sec/batch; 1h:18m:43s remains)
INFO - root - 2022-02-24 19:19:59.034003: step 8260, total loss = 0.61, batch loss = 0.31 (229.4 examples/sec; 0.035 sec/batch; 1h:51m:08s remains)
INFO - root - 2022-02-24 19:19:59.507221: step 8270, total loss = 0.61, batch loss = 0.31 (123.8 examples/sec; 0.065 sec/batch; 3h:25m:56s remains)
INFO - root - 2022-02-24 19:20:00.028315: step 8280, total loss = 0.65, batch loss = 0.34 (223.9 examples/sec; 0.036 sec/batch; 1h:53m:53s remains)
INFO - root - 2022-02-24 19:20:00.454724: step 8290, total loss = 0.60, batch loss = 0.30 (187.3 examples/sec; 0.043 sec/batch; 2h:16m:04s remains)
INFO - root - 2022-02-24 19:20:00.808340: step 8300, total loss = 0.69, batch loss = 0.38 (176.1 examples/sec; 0.045 sec/batch; 2h:24m:47s remains)
INFO - root - 2022-02-24 19:20:01.395865: step 8310, total loss = 0.64, batch loss = 0.34 (150.6 examples/sec; 0.053 sec/batch; 2h:49m:16s remains)
INFO - root - 2022-02-24 19:20:01.857878: step 8320, total loss = 0.73, batch loss = 0.43 (173.1 examples/sec; 0.046 sec/batch; 2h:27m:13s remains)
INFO - root - 2022-02-24 19:20:02.680139: step 8330, total loss = 0.67, batch loss = 0.37 (139.5 examples/sec; 0.057 sec/batch; 3h:02m:41s remains)
INFO - root - 2022-02-24 19:20:03.173253: step 8340, total loss = 0.67, batch loss = 0.37 (234.4 examples/sec; 0.034 sec/batch; 1h:48m:45s remains)
INFO - root - 2022-02-24 19:20:03.613524: step 8350, total loss = 0.59, batch loss = 0.29 (155.0 examples/sec; 0.052 sec/batch; 2h:44m:26s remains)
INFO - root - 2022-02-24 19:20:04.133944: step 8360, total loss = 0.59, batch loss = 0.29 (297.5 examples/sec; 0.027 sec/batch; 1h:25m:39s remains)
INFO - root - 2022-02-24 19:20:04.661212: step 8370, total loss = 0.77, batch loss = 0.47 (223.5 examples/sec; 0.036 sec/batch; 1h:54m:02s remains)
INFO - root - 2022-02-24 19:20:05.081353: step 8380, total loss = 0.61, batch loss = 0.31 (172.8 examples/sec; 0.046 sec/batch; 2h:27m:28s remains)
INFO - root - 2022-02-24 19:20:05.467853: step 8390, total loss = 0.66, batch loss = 0.36 (117.9 examples/sec; 0.068 sec/batch; 3h:36m:03s remains)
INFO - root - 2022-02-24 19:20:05.912937: step 8400, total loss = 0.64, batch loss = 0.34 (137.8 examples/sec; 0.058 sec/batch; 3h:04m:54s remains)
INFO - root - 2022-02-24 19:20:06.497179: step 8410, total loss = 0.64, batch loss = 0.34 (143.0 examples/sec; 0.056 sec/batch; 2h:58m:08s remains)
INFO - root - 2022-02-24 19:20:06.916899: step 8420, total loss = 0.63, batch loss = 0.33 (312.1 examples/sec; 0.026 sec/batch; 1h:21m:38s remains)
INFO - root - 2022-02-24 19:20:07.745043: step 8430, total loss = 0.67, batch loss = 0.37 (109.0 examples/sec; 0.073 sec/batch; 3h:53m:42s remains)
INFO - root - 2022-02-24 19:20:08.189192: step 8440, total loss = 0.61, batch loss = 0.30 (145.0 examples/sec; 0.055 sec/batch; 2h:55m:42s remains)
INFO - root - 2022-02-24 19:20:08.536718: step 8450, total loss = 0.71, batch loss = 0.41 (290.8 examples/sec; 0.028 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 19:20:09.013189: step 8460, total loss = 0.58, batch loss = 0.28 (221.7 examples/sec; 0.036 sec/batch; 1h:54m:53s remains)
INFO - root - 2022-02-24 19:20:09.589095: step 8470, total loss = 0.53, batch loss = 0.23 (147.3 examples/sec; 0.054 sec/batch; 2h:52m:56s remains)
INFO - root - 2022-02-24 19:20:10.090006: step 8480, total loss = 0.62, batch loss = 0.32 (129.2 examples/sec; 0.062 sec/batch; 3h:17m:11s remains)
INFO - root - 2022-02-24 19:20:10.465766: step 8490, total loss = 0.55, batch loss = 0.25 (189.8 examples/sec; 0.042 sec/batch; 2h:14m:12s remains)
INFO - root - 2022-02-24 19:20:10.908044: step 8500, total loss = 0.72, batch loss = 0.42 (241.8 examples/sec; 0.033 sec/batch; 1h:45m:18s remains)
INFO - root - 2022-02-24 19:20:11.486430: step 8510, total loss = 0.66, batch loss = 0.36 (187.9 examples/sec; 0.043 sec/batch; 2h:15m:31s remains)
INFO - root - 2022-02-24 19:20:11.993540: step 8520, total loss = 0.63, batch loss = 0.32 (250.8 examples/sec; 0.032 sec/batch; 1h:41m:31s remains)
INFO - root - 2022-02-24 19:20:12.552657: step 8530, total loss = 0.54, batch loss = 0.23 (148.6 examples/sec; 0.054 sec/batch; 2h:51m:19s remains)
INFO - root - 2022-02-24 19:20:13.144432: step 8540, total loss = 0.63, batch loss = 0.33 (178.8 examples/sec; 0.045 sec/batch; 2h:22m:23s remains)
INFO - root - 2022-02-24 19:20:13.537143: step 8550, total loss = 0.72, batch loss = 0.42 (283.0 examples/sec; 0.028 sec/batch; 1h:29m:58s remains)
INFO - root - 2022-02-24 19:20:14.013346: step 8560, total loss = 0.65, batch loss = 0.35 (234.4 examples/sec; 0.034 sec/batch; 1h:48m:35s remains)
INFO - root - 2022-02-24 19:20:14.477278: step 8570, total loss = 0.73, batch loss = 0.43 (175.9 examples/sec; 0.045 sec/batch; 2h:24m:42s remains)
INFO - root - 2022-02-24 19:20:14.934755: step 8580, total loss = 0.60, batch loss = 0.30 (134.7 examples/sec; 0.059 sec/batch; 3h:09m:02s remains)
INFO - root - 2022-02-24 19:20:15.437297: step 8590, total loss = 0.63, batch loss = 0.33 (138.8 examples/sec; 0.058 sec/batch; 3h:03m:22s remains)
INFO - root - 2022-02-24 19:20:15.961159: step 8600, total loss = 0.66, batch loss = 0.36 (197.0 examples/sec; 0.041 sec/batch; 2h:09m:10s remains)
INFO - root - 2022-02-24 19:20:17.141338: step 8610, total loss = 0.87, batch loss = 0.57 (347.9 examples/sec; 0.023 sec/batch; 1h:13m:09s remains)
INFO - root - 2022-02-24 19:20:17.382298: step 8620, total loss = 0.76, batch loss = 0.46 (318.7 examples/sec; 0.025 sec/batch; 1h:19m:51s remains)
INFO - root - 2022-02-24 19:20:17.925675: step 8630, total loss = 0.73, batch loss = 0.43 (26.6 examples/sec; 0.301 sec/batch; 15h:58m:29s remains)
INFO - root - 2022-02-24 19:20:18.362003: step 8640, total loss = 0.61, batch loss = 0.31 (205.9 examples/sec; 0.039 sec/batch; 2h:03m:36s remains)
INFO - root - 2022-02-24 19:20:18.847529: step 8650, total loss = 0.66, batch loss = 0.35 (124.1 examples/sec; 0.064 sec/batch; 3h:25m:01s remains)
INFO - root - 2022-02-24 19:20:19.319639: step 8660, total loss = 0.60, batch loss = 0.30 (270.9 examples/sec; 0.030 sec/batch; 1h:33m:55s remains)
INFO - root - 2022-02-24 19:20:19.759009: step 8670, total loss = 0.61, batch loss = 0.31 (313.1 examples/sec; 0.026 sec/batch; 1h:21m:15s remains)
INFO - root - 2022-02-24 19:20:20.153862: step 8680, total loss = 0.71, batch loss = 0.41 (293.7 examples/sec; 0.027 sec/batch; 1h:26m:36s remains)
INFO - root - 2022-02-24 19:20:20.622774: step 8690, total loss = 0.63, batch loss = 0.33 (130.7 examples/sec; 0.061 sec/batch; 3h:14m:34s remains)
INFO - root - 2022-02-24 19:20:21.049283: step 8700, total loss = 0.64, batch loss = 0.34 (171.1 examples/sec; 0.047 sec/batch; 2h:28m:41s remains)
INFO - root - 2022-02-24 19:20:21.487086: step 8710, total loss = 0.63, batch loss = 0.33 (249.9 examples/sec; 0.032 sec/batch; 1h:41m:47s remains)
INFO - root - 2022-02-24 19:20:21.886900: step 8720, total loss = 0.66, batch loss = 0.36 (155.2 examples/sec; 0.052 sec/batch; 2h:43m:56s remains)
INFO - root - 2022-02-24 19:20:22.276168: step 8730, total loss = 0.64, batch loss = 0.34 (246.0 examples/sec; 0.033 sec/batch; 1h:43m:24s remains)
INFO - root - 2022-02-24 19:20:22.809271: step 8740, total loss = 0.66, batch loss = 0.36 (124.9 examples/sec; 0.064 sec/batch; 3h:23m:39s remains)
INFO - root - 2022-02-24 19:20:23.255862: step 8750, total loss = 0.60, batch loss = 0.30 (263.9 examples/sec; 0.030 sec/batch; 1h:36m:21s remains)
INFO - root - 2022-02-24 19:20:23.689581: step 8760, total loss = 0.54, batch loss = 0.24 (198.6 examples/sec; 0.040 sec/batch; 2h:08m:01s remains)
INFO - root - 2022-02-24 19:20:24.055835: step 8770, total loss = 0.61, batch loss = 0.31 (300.4 examples/sec; 0.027 sec/batch; 1h:24m:39s remains)
INFO - root - 2022-02-24 19:20:24.466046: step 8780, total loss = 0.68, batch loss = 0.38 (236.3 examples/sec; 0.034 sec/batch; 1h:47m:37s remains)
INFO - root - 2022-02-24 19:20:24.953495: step 8790, total loss = 0.62, batch loss = 0.32 (105.5 examples/sec; 0.076 sec/batch; 4h:00m:59s remains)
INFO - root - 2022-02-24 19:20:25.436336: step 8800, total loss = 0.65, batch loss = 0.35 (266.3 examples/sec; 0.030 sec/batch; 1h:35m:29s remains)
INFO - root - 2022-02-24 19:20:26.003677: step 8810, total loss = 0.63, batch loss = 0.33 (207.6 examples/sec; 0.039 sec/batch; 2h:02m:28s remains)
INFO - root - 2022-02-24 19:20:26.430134: step 8820, total loss = 0.72, batch loss = 0.42 (182.6 examples/sec; 0.044 sec/batch; 2h:19m:15s remains)
INFO - root - 2022-02-24 19:20:26.805241: step 8830, total loss = 0.60, batch loss = 0.30 (242.6 examples/sec; 0.033 sec/batch; 1h:44m:47s remains)
INFO - root - 2022-02-24 19:20:27.312029: step 8840, total loss = 0.71, batch loss = 0.41 (300.2 examples/sec; 0.027 sec/batch; 1h:24m:41s remains)
INFO - root - 2022-02-24 19:20:27.760415: step 8850, total loss = 0.75, batch loss = 0.44 (138.1 examples/sec; 0.058 sec/batch; 3h:04m:00s remains)
INFO - root - 2022-02-24 19:20:28.190819: step 8860, total loss = 0.61, batch loss = 0.31 (264.5 examples/sec; 0.030 sec/batch; 1h:36m:06s remains)
INFO - root - 2022-02-24 19:20:28.600837: step 8870, total loss = 0.58, batch loss = 0.28 (211.2 examples/sec; 0.038 sec/batch; 2h:00m:20s remains)
INFO - root - 2022-02-24 19:20:28.911931: step 8880, total loss = 0.63, batch loss = 0.33 (327.2 examples/sec; 0.024 sec/batch; 1h:17m:41s remains)
INFO - root - 2022-02-24 19:20:29.379444: step 8890, total loss = 0.59, batch loss = 0.29 (290.8 examples/sec; 0.028 sec/batch; 1h:27m:23s remains)
INFO - root - 2022-02-24 19:20:29.860016: step 8900, total loss = 0.75, batch loss = 0.44 (177.9 examples/sec; 0.045 sec/batch; 2h:22m:52s remains)
INFO - root - 2022-02-24 19:20:30.459287: step 8910, total loss = 0.62, batch loss = 0.32 (166.7 examples/sec; 0.048 sec/batch; 2h:32m:28s remains)
INFO - root - 2022-02-24 19:20:30.883795: step 8920, total loss = 0.74, batch loss = 0.43 (250.5 examples/sec; 0.032 sec/batch; 1h:41m:25s remains)
INFO - root - 2022-02-24 19:20:31.350396: step 8930, total loss = 0.64, batch loss = 0.34 (160.1 examples/sec; 0.050 sec/batch; 2h:38m:42s remains)
INFO - root - 2022-02-24 19:20:31.755036: step 8940, total loss = 0.62, batch loss = 0.32 (274.4 examples/sec; 0.029 sec/batch; 1h:32m:35s remains)
INFO - root - 2022-02-24 19:20:32.298488: step 8950, total loss = 0.61, batch loss = 0.31 (125.7 examples/sec; 0.064 sec/batch; 3h:22m:12s remains)
INFO - root - 2022-02-24 19:20:33.409737: step 8960, total loss = 0.69, batch loss = 0.39 (17.5 examples/sec; 0.456 sec/batch; 24h:07m:46s remains)
INFO - root - 2022-02-24 19:20:33.967131: step 8970, total loss = 0.59, batch loss = 0.29 (102.7 examples/sec; 0.078 sec/batch; 4h:07m:18s remains)
INFO - root - 2022-02-24 19:20:34.560609: step 8980, total loss = 0.67, batch loss = 0.37 (132.9 examples/sec; 0.060 sec/batch; 3h:11m:06s remains)
INFO - root - 2022-02-24 19:20:34.916868: step 8990, total loss = 0.68, batch loss = 0.38 (255.7 examples/sec; 0.031 sec/batch; 1h:39m:19s remains)
INFO - root - 2022-02-24 19:20:35.362651: step 9000, total loss = 0.73, batch loss = 0.43 (132.7 examples/sec; 0.060 sec/batch; 3h:11m:22s remains)
INFO - root - 2022-02-24 19:20:35.808066: step 9010, total loss = 0.66, batch loss = 0.36 (229.5 examples/sec; 0.035 sec/batch; 1h:50m:39s remains)
INFO - root - 2022-02-24 19:20:36.313428: step 9020, total loss = 0.63, batch loss = 0.33 (160.9 examples/sec; 0.050 sec/batch; 2h:37m:51s remains)
INFO - root - 2022-02-24 19:20:36.929697: step 9030, total loss = 0.63, batch loss = 0.33 (135.0 examples/sec; 0.059 sec/batch; 3h:08m:05s remains)
INFO - root - 2022-02-24 19:20:37.451338: step 9040, total loss = 0.56, batch loss = 0.25 (154.2 examples/sec; 0.052 sec/batch; 2h:44m:39s remains)
INFO - root - 2022-02-24 19:20:37.865207: step 9050, total loss = 0.66, batch loss = 0.36 (168.2 examples/sec; 0.048 sec/batch; 2h:30m:56s remains)
INFO - root - 2022-02-24 19:20:38.355379: step 9060, total loss = 0.56, batch loss = 0.25 (185.6 examples/sec; 0.043 sec/batch; 2h:16m:50s remains)
INFO - root - 2022-02-24 19:20:39.063448: step 9070, total loss = 0.69, batch loss = 0.39 (228.0 examples/sec; 0.035 sec/batch; 1h:51m:23s remains)
INFO - root - 2022-02-24 19:20:39.537023: step 9080, total loss = 0.77, batch loss = 0.47 (278.5 examples/sec; 0.029 sec/batch; 1h:31m:09s remains)
INFO - root - 2022-02-24 19:20:39.918128: step 9090, total loss = 0.69, batch loss = 0.39 (259.2 examples/sec; 0.031 sec/batch; 1h:37m:57s remains)
INFO - root - 2022-02-24 19:20:40.277411: step 9100, total loss = 0.70, batch loss = 0.40 (256.6 examples/sec; 0.031 sec/batch; 1h:38m:57s remains)
INFO - root - 2022-02-24 19:20:40.792659: step 9110, total loss = 0.61, batch loss = 0.31 (212.9 examples/sec; 0.038 sec/batch; 1h:59m:14s remains)
INFO - root - 2022-02-24 19:20:41.257210: step 9120, total loss = 0.76, batch loss = 0.46 (211.8 examples/sec; 0.038 sec/batch; 1h:59m:50s remains)
INFO - root - 2022-02-24 19:20:41.767744: step 9130, total loss = 0.68, batch loss = 0.38 (242.9 examples/sec; 0.033 sec/batch; 1h:44m:29s remains)
INFO - root - 2022-02-24 19:20:42.180963: step 9140, total loss = 0.63, batch loss = 0.33 (175.5 examples/sec; 0.046 sec/batch; 2h:24m:37s remains)
INFO - root - 2022-02-24 19:20:42.614685: step 9150, total loss = 0.65, batch loss = 0.35 (156.5 examples/sec; 0.051 sec/batch; 2h:42m:10s remains)
INFO - root - 2022-02-24 19:20:43.139225: step 9160, total loss = 0.73, batch loss = 0.43 (86.7 examples/sec; 0.092 sec/batch; 4h:52m:42s remains)
INFO - root - 2022-02-24 19:20:43.622024: step 9170, total loss = 0.86, batch loss = 0.56 (171.8 examples/sec; 0.047 sec/batch; 2h:27m:41s remains)
INFO - root - 2022-02-24 19:20:44.208758: step 9180, total loss = 0.64, batch loss = 0.34 (133.1 examples/sec; 0.060 sec/batch; 3h:10m:36s remains)
INFO - root - 2022-02-24 19:20:44.631072: step 9190, total loss = 0.73, batch loss = 0.43 (304.0 examples/sec; 0.026 sec/batch; 1h:23m:28s remains)
INFO - root - 2022-02-24 19:20:45.173562: step 9200, total loss = 0.76, batch loss = 0.45 (111.3 examples/sec; 0.072 sec/batch; 3h:48m:04s remains)
INFO - root - 2022-02-24 19:20:45.695383: step 9210, total loss = 0.70, batch loss = 0.40 (100.4 examples/sec; 0.080 sec/batch; 4h:12m:46s remains)
INFO - root - 2022-02-24 19:20:46.143107: step 9220, total loss = 0.74, batch loss = 0.44 (132.2 examples/sec; 0.061 sec/batch; 3h:11m:55s remains)
INFO - root - 2022-02-24 19:20:46.605196: step 9230, total loss = 0.66, batch loss = 0.36 (218.4 examples/sec; 0.037 sec/batch; 1h:56m:11s remains)
INFO - root - 2022-02-24 19:20:46.972336: step 9240, total loss = 0.62, batch loss = 0.32 (311.3 examples/sec; 0.026 sec/batch; 1h:21m:29s remains)
INFO - root - 2022-02-24 19:20:47.337973: step 9250, total loss = 0.67, batch loss = 0.37 (185.4 examples/sec; 0.043 sec/batch; 2h:16m:50s remains)
INFO - root - 2022-02-24 19:20:47.822765: step 9260, total loss = 0.69, batch loss = 0.39 (333.5 examples/sec; 0.024 sec/batch; 1h:16m:03s remains)
INFO - root - 2022-02-24 19:20:48.344315: step 9270, total loss = 0.65, batch loss = 0.35 (127.2 examples/sec; 0.063 sec/batch; 3h:19m:24s remains)
INFO - root - 2022-02-24 19:20:48.766655: step 9280, total loss = 0.61, batch loss = 0.31 (181.3 examples/sec; 0.044 sec/batch; 2h:19m:55s remains)
INFO - root - 2022-02-24 19:20:49.208747: step 9290, total loss = 0.75, batch loss = 0.45 (225.8 examples/sec; 0.035 sec/batch; 1h:52m:18s remains)
INFO - root - 2022-02-24 19:20:49.617929: step 9300, total loss = 0.63, batch loss = 0.33 (154.8 examples/sec; 0.052 sec/batch; 2h:43m:51s remains)
INFO - root - 2022-02-24 19:20:50.149477: step 9310, total loss = 0.56, batch loss = 0.26 (317.2 examples/sec; 0.025 sec/batch; 1h:19m:57s remains)
INFO - root - 2022-02-24 19:20:50.657515: step 9320, total loss = 0.61, batch loss = 0.31 (126.9 examples/sec; 0.063 sec/batch; 3h:19m:51s remains)
INFO - root - 2022-02-24 19:20:50.999333: step 9330, total loss = 0.82, batch loss = 0.52 (328.8 examples/sec; 0.024 sec/batch; 1h:17m:07s remains)
INFO - root - 2022-02-24 19:20:51.347303: step 9340, total loss = 0.62, batch loss = 0.32 (222.4 examples/sec; 0.036 sec/batch; 1h:53m:59s remains)
INFO - root - 2022-02-24 19:20:51.747689: step 9350, total loss = 0.74, batch loss = 0.44 (161.2 examples/sec; 0.050 sec/batch; 2h:37m:18s remains)
INFO - root - 2022-02-24 19:20:52.268783: step 9360, total loss = 0.79, batch loss = 0.49 (111.3 examples/sec; 0.072 sec/batch; 3h:47m:43s remains)
INFO - root - 2022-02-24 19:20:52.741777: step 9370, total loss = 0.79, batch loss = 0.49 (293.6 examples/sec; 0.027 sec/batch; 1h:26m:20s remains)
INFO - root - 2022-02-24 19:20:53.118831: step 9380, total loss = 0.78, batch loss = 0.48 (161.1 examples/sec; 0.050 sec/batch; 2h:37m:18s remains)
INFO - root - 2022-02-24 19:20:53.480000: step 9390, total loss = 0.69, batch loss = 0.39 (161.7 examples/sec; 0.049 sec/batch; 2h:36m:47s remains)
INFO - root - 2022-02-24 19:20:53.896057: step 9400, total loss = 0.70, batch loss = 0.40 (174.0 examples/sec; 0.046 sec/batch; 2h:25m:38s remains)
INFO - root - 2022-02-24 19:20:54.539073: step 9410, total loss = 0.68, batch loss = 0.38 (163.1 examples/sec; 0.049 sec/batch; 2h:35m:25s remains)
INFO - root - 2022-02-24 19:20:55.001905: step 9420, total loss = 0.76, batch loss = 0.46 (176.2 examples/sec; 0.045 sec/batch; 2h:23m:50s remains)
INFO - root - 2022-02-24 19:20:55.484719: step 9430, total loss = 0.65, batch loss = 0.35 (304.5 examples/sec; 0.026 sec/batch; 1h:23m:13s remains)
INFO - root - 2022-02-24 19:20:55.855264: step 9440, total loss = 0.63, batch loss = 0.33 (121.0 examples/sec; 0.066 sec/batch; 3h:29m:28s remains)
INFO - root - 2022-02-24 19:20:56.203518: step 9450, total loss = 0.63, batch loss = 0.33 (341.9 examples/sec; 0.023 sec/batch; 1h:14m:07s remains)
INFO - root - 2022-02-24 19:20:56.524659: step 9460, total loss = 0.71, batch loss = 0.41 (265.0 examples/sec; 0.030 sec/batch; 1h:35m:37s remains)
INFO - root - 2022-02-24 19:20:57.104476: step 9470, total loss = 0.69, batch loss = 0.38 (82.8 examples/sec; 0.097 sec/batch; 5h:06m:01s remains)
INFO - root - 2022-02-24 19:20:57.576994: step 9480, total loss = 0.57, batch loss = 0.27 (257.3 examples/sec; 0.031 sec/batch; 1h:38m:28s remains)
INFO - root - 2022-02-24 19:20:58.096642: step 9490, total loss = 0.79, batch loss = 0.49 (134.3 examples/sec; 0.060 sec/batch; 3h:08m:40s remains)
INFO - root - 2022-02-24 19:20:58.544319: step 9500, total loss = 0.59, batch loss = 0.29 (243.6 examples/sec; 0.033 sec/batch; 1h:43m:59s remains)
INFO - root - 2022-02-24 19:20:59.531076: step 9510, total loss = 0.56, batch loss = 0.26 (280.6 examples/sec; 0.029 sec/batch; 1h:30m:15s remains)
INFO - root - 2022-02-24 19:21:00.017357: step 9520, total loss = 0.64, batch loss = 0.34 (259.7 examples/sec; 0.031 sec/batch; 1h:37m:33s remains)
INFO - root - 2022-02-24 19:21:00.524731: step 9530, total loss = 0.63, batch loss = 0.33 (188.9 examples/sec; 0.042 sec/batch; 2h:14m:03s remains)
INFO - root - 2022-02-24 19:21:00.912138: step 9540, total loss = 0.60, batch loss = 0.30 (219.5 examples/sec; 0.036 sec/batch; 1h:55m:23s remains)
INFO - root - 2022-02-24 19:21:01.546088: step 9550, total loss = 0.60, batch loss = 0.30 (64.0 examples/sec; 0.125 sec/batch; 6h:35m:31s remains)
INFO - root - 2022-02-24 19:21:02.158589: step 9560, total loss = 0.63, batch loss = 0.33 (119.0 examples/sec; 0.067 sec/batch; 3h:32m:49s remains)
INFO - root - 2022-02-24 19:21:02.641158: step 9570, total loss = 0.57, batch loss = 0.27 (168.1 examples/sec; 0.048 sec/batch; 2h:30m:37s remains)
INFO - root - 2022-02-24 19:21:03.036718: step 9580, total loss = 0.64, batch loss = 0.34 (178.8 examples/sec; 0.045 sec/batch; 2h:21m:37s remains)
INFO - root - 2022-02-24 19:21:03.407143: step 9590, total loss = 0.70, batch loss = 0.40 (163.6 examples/sec; 0.049 sec/batch; 2h:34m:46s remains)
INFO - root - 2022-02-24 19:21:03.955549: step 9600, total loss = 0.65, batch loss = 0.35 (119.6 examples/sec; 0.067 sec/batch; 3h:31m:46s remains)
INFO - root - 2022-02-24 19:21:04.923911: step 9610, total loss = 0.60, batch loss = 0.30 (167.2 examples/sec; 0.048 sec/batch; 2h:31m:26s remains)
INFO - root - 2022-02-24 19:21:05.426362: step 9620, total loss = 0.64, batch loss = 0.34 (149.8 examples/sec; 0.053 sec/batch; 2h:49m:03s remains)
INFO - root - 2022-02-24 19:21:05.883591: step 9630, total loss = 0.66, batch loss = 0.36 (167.2 examples/sec; 0.048 sec/batch; 2h:31m:25s remains)
INFO - root - 2022-02-24 19:21:06.231556: step 9640, total loss = 0.72, batch loss = 0.42 (306.2 examples/sec; 0.026 sec/batch; 1h:22m:40s remains)
INFO - root - 2022-02-24 19:21:06.695913: step 9650, total loss = 0.62, batch loss = 0.32 (118.0 examples/sec; 0.068 sec/batch; 3h:34m:32s remains)
INFO - root - 2022-02-24 19:21:07.190233: step 9660, total loss = 0.62, batch loss = 0.32 (212.7 examples/sec; 0.038 sec/batch; 1h:59m:01s remains)
INFO - root - 2022-02-24 19:21:07.567758: step 9670, total loss = 0.60, batch loss = 0.30 (156.4 examples/sec; 0.051 sec/batch; 2h:41m:47s remains)
INFO - root - 2022-02-24 19:21:07.969562: step 9680, total loss = 0.56, batch loss = 0.26 (95.9 examples/sec; 0.083 sec/batch; 4h:24m:02s remains)
INFO - root - 2022-02-24 19:21:08.352039: step 9690, total loss = 0.56, batch loss = 0.26 (305.7 examples/sec; 0.026 sec/batch; 1h:22m:46s remains)
INFO - root - 2022-02-24 19:21:08.759647: step 9700, total loss = 0.61, batch loss = 0.31 (120.9 examples/sec; 0.066 sec/batch; 3h:29m:24s remains)
INFO - root - 2022-02-24 19:21:09.588669: step 9710, total loss = 0.61, batch loss = 0.31 (111.4 examples/sec; 0.072 sec/batch; 3h:47m:12s remains)
INFO - root - 2022-02-24 19:21:10.043823: step 9720, total loss = 0.58, batch loss = 0.28 (195.5 examples/sec; 0.041 sec/batch; 2h:09m:25s remains)
INFO - root - 2022-02-24 19:21:10.392661: step 9730, total loss = 0.65, batch loss = 0.35 (154.8 examples/sec; 0.052 sec/batch; 2h:43m:28s remains)
INFO - root - 2022-02-24 19:21:10.747041: step 9740, total loss = 0.68, batch loss = 0.38 (247.5 examples/sec; 0.032 sec/batch; 1h:42m:12s remains)
INFO - root - 2022-02-24 19:21:11.156693: step 9750, total loss = 0.69, batch loss = 0.39 (198.5 examples/sec; 0.040 sec/batch; 2h:07m:27s remains)
INFO - root - 2022-02-24 19:21:11.676596: step 9760, total loss = 0.70, batch loss = 0.40 (149.3 examples/sec; 0.054 sec/batch; 2h:49m:24s remains)
INFO - root - 2022-02-24 19:21:12.105240: step 9770, total loss = 0.61, batch loss = 0.31 (86.5 examples/sec; 0.093 sec/batch; 4h:52m:36s remains)
INFO - root - 2022-02-24 19:21:12.494515: step 9780, total loss = 0.68, batch loss = 0.38 (325.5 examples/sec; 0.025 sec/batch; 1h:17m:42s remains)
INFO - root - 2022-02-24 19:21:12.931645: step 9790, total loss = 0.69, batch loss = 0.39 (133.0 examples/sec; 0.060 sec/batch; 3h:10m:10s remains)
INFO - root - 2022-02-24 19:21:13.311165: step 9800, total loss = 0.82, batch loss = 0.52 (285.4 examples/sec; 0.028 sec/batch; 1h:28m:37s remains)
INFO - root - 2022-02-24 19:21:13.893339: step 9810, total loss = 0.65, batch loss = 0.35 (145.6 examples/sec; 0.055 sec/batch; 2h:53m:45s remains)
INFO - root - 2022-02-24 19:21:14.368629: step 9820, total loss = 0.57, batch loss = 0.27 (193.0 examples/sec; 0.041 sec/batch; 2h:11m:01s remains)
INFO - root - 2022-02-24 19:21:14.839293: step 9830, total loss = 0.58, batch loss = 0.28 (295.0 examples/sec; 0.027 sec/batch; 1h:25m:42s remains)
INFO - root - 2022-02-24 19:21:15.207681: step 9840, total loss = 0.82, batch loss = 0.52 (127.5 examples/sec; 0.063 sec/batch; 3h:18m:21s remains)
INFO - root - 2022-02-24 19:21:15.575040: step 9850, total loss = 0.80, batch loss = 0.50 (350.5 examples/sec; 0.023 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 19:21:16.024442: step 9860, total loss = 0.62, batch loss = 0.32 (109.3 examples/sec; 0.073 sec/batch; 3h:51m:26s remains)
INFO - root - 2022-02-24 19:21:16.464338: step 9870, total loss = 0.69, batch loss = 0.39 (122.8 examples/sec; 0.065 sec/batch; 3h:25m:56s remains)
INFO - root - 2022-02-24 19:21:16.899081: step 9880, total loss = 0.67, batch loss = 0.37 (295.4 examples/sec; 0.027 sec/batch; 1h:25m:35s remains)
INFO - root - 2022-02-24 19:21:17.290608: step 9890, total loss = 0.74, batch loss = 0.44 (163.9 examples/sec; 0.049 sec/batch; 2h:34m:12s remains)
INFO - root - 2022-02-24 19:21:17.682178: step 9900, total loss = 0.65, batch loss = 0.35 (152.7 examples/sec; 0.052 sec/batch; 2h:45m:31s remains)
INFO - root - 2022-02-24 19:21:18.152651: step 9910, total loss = 0.66, batch loss = 0.36 (192.7 examples/sec; 0.042 sec/batch; 2h:11m:12s remains)
INFO - root - 2022-02-24 19:21:18.701579: step 9920, total loss = 0.65, batch loss = 0.34 (125.8 examples/sec; 0.064 sec/batch; 3h:21m:00s remains)
INFO - root - 2022-02-24 19:21:19.198444: step 9930, total loss = 0.70, batch loss = 0.40 (90.2 examples/sec; 0.089 sec/batch; 4h:40m:09s remains)
INFO - root - 2022-02-24 19:21:19.576400: step 9940, total loss = 0.61, batch loss = 0.31 (154.3 examples/sec; 0.052 sec/batch; 2h:43m:49s remains)
INFO - root - 2022-02-24 19:21:19.957578: step 9950, total loss = 0.72, batch loss = 0.42 (163.6 examples/sec; 0.049 sec/batch; 2h:34m:30s remains)
INFO - root - 2022-02-24 19:21:20.324734: step 9960, total loss = 0.60, batch loss = 0.30 (136.5 examples/sec; 0.059 sec/batch; 3h:05m:10s remains)
INFO - root - 2022-02-24 19:21:20.769889: step 9970, total loss = 0.59, batch loss = 0.29 (158.5 examples/sec; 0.050 sec/batch; 2h:39m:27s remains)
INFO - root - 2022-02-24 19:21:21.314062: step 9980, total loss = 0.61, batch loss = 0.31 (199.4 examples/sec; 0.040 sec/batch; 2h:06m:42s remains)
INFO - root - 2022-02-24 19:21:21.732179: step 9990, total loss = 0.61, batch loss = 0.31 (157.6 examples/sec; 0.051 sec/batch; 2h:40m:20s remains)
INFO - root - 2022-02-24 19:21:22.059857: step 10000, total loss = 0.72, batch loss = 0.42 (320.5 examples/sec; 0.025 sec/batch; 1h:18m:49s remains)
INFO - root - 2022-02-24 19:21:22.516704: step 10010, total loss = 0.76, batch loss = 0.46 (314.4 examples/sec; 0.025 sec/batch; 1h:20m:21s remains)
INFO - root - 2022-02-24 19:21:23.033623: step 10020, total loss = 0.73, batch loss = 0.43 (120.5 examples/sec; 0.066 sec/batch; 3h:29m:34s remains)
INFO - root - 2022-02-24 19:21:23.460263: step 10030, total loss = 0.58, batch loss = 0.28 (168.3 examples/sec; 0.048 sec/batch; 2h:30m:08s remains)
INFO - root - 2022-02-24 19:21:23.845628: step 10040, total loss = 0.56, batch loss = 0.26 (300.4 examples/sec; 0.027 sec/batch; 1h:24m:05s remains)
INFO - root - 2022-02-24 19:21:24.807317: step 10050, total loss = 0.57, batch loss = 0.27 (121.8 examples/sec; 0.066 sec/batch; 3h:27m:19s remains)
INFO - root - 2022-02-24 19:21:25.349126: step 10060, total loss = 0.65, batch loss = 0.35 (152.9 examples/sec; 0.052 sec/batch; 2h:45m:09s remains)
INFO - root - 2022-02-24 19:21:25.848277: step 10070, total loss = 0.58, batch loss = 0.28 (122.7 examples/sec; 0.065 sec/batch; 3h:25m:52s remains)
INFO - root - 2022-02-24 19:21:26.279891: step 10080, total loss = 0.63, batch loss = 0.33 (205.5 examples/sec; 0.039 sec/batch; 2h:02m:53s remains)
INFO - root - 2022-02-24 19:21:26.773843: step 10090, total loss = 0.61, batch loss = 0.31 (231.8 examples/sec; 0.035 sec/batch; 1h:48m:56s remains)
INFO - root - 2022-02-24 19:21:27.344453: step 10100, total loss = 0.60, batch loss = 0.30 (242.5 examples/sec; 0.033 sec/batch; 1h:44m:08s remains)
INFO - root - 2022-02-24 19:21:27.974559: step 10110, total loss = 0.60, batch loss = 0.30 (243.5 examples/sec; 0.033 sec/batch; 1h:43m:42s remains)
INFO - root - 2022-02-24 19:21:28.464459: step 10120, total loss = 0.55, batch loss = 0.25 (286.8 examples/sec; 0.028 sec/batch; 1h:28m:02s remains)
INFO - root - 2022-02-24 19:21:28.960352: step 10130, total loss = 0.75, batch loss = 0.45 (190.4 examples/sec; 0.042 sec/batch; 2h:12m:38s remains)
INFO - root - 2022-02-24 19:21:29.492063: step 10140, total loss = 0.70, batch loss = 0.40 (312.1 examples/sec; 0.026 sec/batch; 1h:20m:53s remains)
INFO - root - 2022-02-24 19:21:30.472398: step 10150, total loss = 0.60, batch loss = 0.30 (239.6 examples/sec; 0.033 sec/batch; 1h:45m:22s remains)
INFO - root - 2022-02-24 19:21:31.031934: step 10160, total loss = 0.55, batch loss = 0.25 (116.8 examples/sec; 0.069 sec/batch; 3h:36m:13s remains)
INFO - root - 2022-02-24 19:21:31.424259: step 10170, total loss = 0.73, batch loss = 0.43 (234.4 examples/sec; 0.034 sec/batch; 1h:47m:42s remains)
INFO - root - 2022-02-24 19:21:31.852567: step 10180, total loss = 0.60, batch loss = 0.30 (139.9 examples/sec; 0.057 sec/batch; 3h:00m:23s remains)
INFO - root - 2022-02-24 19:21:32.434979: step 10190, total loss = 0.66, batch loss = 0.36 (136.1 examples/sec; 0.059 sec/batch; 3h:05m:28s remains)
INFO - root - 2022-02-24 19:21:32.891665: step 10200, total loss = 0.74, batch loss = 0.45 (204.0 examples/sec; 0.039 sec/batch; 2h:03m:44s remains)
INFO - root - 2022-02-24 19:21:33.354940: step 10210, total loss = 0.60, batch loss = 0.30 (185.3 examples/sec; 0.043 sec/batch; 2h:16m:10s remains)
INFO - root - 2022-02-24 19:21:33.689075: step 10220, total loss = 0.74, batch loss = 0.44 (304.5 examples/sec; 0.026 sec/batch; 1h:22m:53s remains)
INFO - root - 2022-02-24 19:21:34.133106: step 10230, total loss = 0.58, batch loss = 0.28 (179.0 examples/sec; 0.045 sec/batch; 2h:20m:57s remains)
INFO - root - 2022-02-24 19:21:34.661519: step 10240, total loss = 0.65, batch loss = 0.35 (239.5 examples/sec; 0.033 sec/batch; 1h:45m:21s remains)
INFO - root - 2022-02-24 19:21:35.149772: step 10250, total loss = 0.74, batch loss = 0.44 (117.5 examples/sec; 0.068 sec/batch; 3h:34m:49s remains)
INFO - root - 2022-02-24 19:21:35.534488: step 10260, total loss = 0.60, batch loss = 0.30 (133.3 examples/sec; 0.060 sec/batch; 3h:09m:20s remains)
INFO - root - 2022-02-24 19:21:35.981713: step 10270, total loss = 0.62, batch loss = 0.32 (117.3 examples/sec; 0.068 sec/batch; 3h:35m:00s remains)
INFO - root - 2022-02-24 19:21:36.297872: step 10280, total loss = 0.72, batch loss = 0.42 (302.0 examples/sec; 0.026 sec/batch; 1h:23m:32s remains)
INFO - root - 2022-02-24 19:21:36.672036: step 10290, total loss = 0.61, batch loss = 0.31 (348.6 examples/sec; 0.023 sec/batch; 1h:12m:22s remains)
INFO - root - 2022-02-24 19:21:37.186784: step 10300, total loss = 0.80, batch loss = 0.50 (84.2 examples/sec; 0.095 sec/batch; 4h:59m:43s remains)
INFO - root - 2022-02-24 19:21:37.631043: step 10310, total loss = 0.62, batch loss = 0.32 (255.2 examples/sec; 0.031 sec/batch; 1h:38m:49s remains)
INFO - root - 2022-02-24 19:21:38.093969: step 10320, total loss = 0.65, batch loss = 0.35 (127.6 examples/sec; 0.063 sec/batch; 3h:17m:39s remains)
INFO - root - 2022-02-24 19:21:38.488167: step 10330, total loss = 0.63, batch loss = 0.33 (245.6 examples/sec; 0.033 sec/batch; 1h:42m:43s remains)
INFO - root - 2022-02-24 19:21:38.971368: step 10340, total loss = 0.51, batch loss = 0.21 (138.5 examples/sec; 0.058 sec/batch; 3h:02m:05s remains)
INFO - root - 2022-02-24 19:21:39.417882: step 10350, total loss = 0.65, batch loss = 0.35 (131.3 examples/sec; 0.061 sec/batch; 3h:12m:05s remains)
INFO - root - 2022-02-24 19:21:39.940883: step 10360, total loss = 0.59, batch loss = 0.29 (187.2 examples/sec; 0.043 sec/batch; 2h:14m:42s remains)
INFO - root - 2022-02-24 19:21:40.267029: step 10370, total loss = 0.58, batch loss = 0.28 (156.9 examples/sec; 0.051 sec/batch; 2h:40m:45s remains)
INFO - root - 2022-02-24 19:21:40.646852: step 10380, total loss = 0.87, batch loss = 0.57 (147.8 examples/sec; 0.054 sec/batch; 2h:50m:34s remains)
INFO - root - 2022-02-24 19:21:41.050463: step 10390, total loss = 0.72, batch loss = 0.42 (267.5 examples/sec; 0.030 sec/batch; 1h:34m:14s remains)
INFO - root - 2022-02-24 19:21:41.448253: step 10400, total loss = 0.63, batch loss = 0.33 (159.4 examples/sec; 0.050 sec/batch; 2h:38m:10s remains)
INFO - root - 2022-02-24 19:21:41.980012: step 10410, total loss = 0.56, batch loss = 0.26 (261.1 examples/sec; 0.031 sec/batch; 1h:36m:33s remains)
INFO - root - 2022-02-24 19:21:42.364831: step 10420, total loss = 0.71, batch loss = 0.41 (257.0 examples/sec; 0.031 sec/batch; 1h:38m:06s remains)
INFO - root - 2022-02-24 19:21:42.750539: step 10430, total loss = 0.68, batch loss = 0.38 (197.9 examples/sec; 0.040 sec/batch; 2h:07m:22s remains)
INFO - root - 2022-02-24 19:21:43.252234: step 10440, total loss = 0.53, batch loss = 0.23 (140.7 examples/sec; 0.057 sec/batch; 2h:59m:09s remains)
INFO - root - 2022-02-24 19:21:43.657329: step 10450, total loss = 0.60, batch loss = 0.30 (244.0 examples/sec; 0.033 sec/batch; 1h:43m:19s remains)
INFO - root - 2022-02-24 19:21:44.072160: step 10460, total loss = 0.58, batch loss = 0.28 (272.1 examples/sec; 0.029 sec/batch; 1h:32m:37s remains)
INFO - root - 2022-02-24 19:21:44.424880: step 10470, total loss = 0.78, batch loss = 0.48 (254.3 examples/sec; 0.031 sec/batch; 1h:39m:06s remains)
INFO - root - 2022-02-24 19:21:44.877208: step 10480, total loss = 0.65, batch loss = 0.35 (195.8 examples/sec; 0.041 sec/batch; 2h:08m:42s remains)
INFO - root - 2022-02-24 19:21:45.314214: step 10490, total loss = 0.60, batch loss = 0.31 (108.4 examples/sec; 0.074 sec/batch; 3h:52m:35s remains)
INFO - root - 2022-02-24 19:21:45.720919: step 10500, total loss = 0.57, batch loss = 0.27 (104.3 examples/sec; 0.077 sec/batch; 4h:01m:36s remains)
INFO - root - 2022-02-24 19:21:46.186917: step 10510, total loss = 0.57, batch loss = 0.27 (202.0 examples/sec; 0.040 sec/batch; 2h:04m:45s remains)
INFO - root - 2022-02-24 19:21:46.556623: step 10520, total loss = 0.65, batch loss = 0.35 (115.2 examples/sec; 0.069 sec/batch; 3h:38m:39s remains)
INFO - root - 2022-02-24 19:21:46.955299: step 10530, total loss = 0.66, batch loss = 0.36 (160.7 examples/sec; 0.050 sec/batch; 2h:36m:49s remains)
INFO - root - 2022-02-24 19:21:47.283018: step 10540, total loss = 0.64, batch loss = 0.34 (276.2 examples/sec; 0.029 sec/batch; 1h:31m:13s remains)
INFO - root - 2022-02-24 19:21:47.683203: step 10550, total loss = 0.56, batch loss = 0.26 (226.6 examples/sec; 0.035 sec/batch; 1h:51m:10s remains)
INFO - root - 2022-02-24 19:21:48.190150: step 10560, total loss = 0.72, batch loss = 0.42 (178.7 examples/sec; 0.045 sec/batch; 2h:20m:59s remains)
INFO - root - 2022-02-24 19:21:48.604351: step 10570, total loss = 0.67, batch loss = 0.37 (165.0 examples/sec; 0.048 sec/batch; 2h:32m:37s remains)
INFO - root - 2022-02-24 19:21:48.978746: step 10580, total loss = 0.61, batch loss = 0.31 (272.0 examples/sec; 0.029 sec/batch; 1h:32m:36s remains)
INFO - root - 2022-02-24 19:21:49.377236: step 10590, total loss = 0.61, batch loss = 0.31 (347.3 examples/sec; 0.023 sec/batch; 1h:12m:31s remains)
INFO - root - 2022-02-24 19:21:49.877358: step 10600, total loss = 0.64, batch loss = 0.34 (268.1 examples/sec; 0.030 sec/batch; 1h:33m:56s remains)
INFO - root - 2022-02-24 19:21:50.437158: step 10610, total loss = 0.62, batch loss = 0.32 (172.6 examples/sec; 0.046 sec/batch; 2h:25m:56s remains)
INFO - root - 2022-02-24 19:21:50.895811: step 10620, total loss = 0.77, batch loss = 0.47 (226.8 examples/sec; 0.035 sec/batch; 1h:51m:02s remains)
INFO - root - 2022-02-24 19:21:51.400232: step 10630, total loss = 0.58, batch loss = 0.28 (113.9 examples/sec; 0.070 sec/batch; 3h:41m:01s remains)
INFO - root - 2022-02-24 19:21:52.108415: step 10640, total loss = 0.74, batch loss = 0.44 (99.3 examples/sec; 0.081 sec/batch; 4h:13m:34s remains)
INFO - root - 2022-02-24 19:21:52.724879: step 10650, total loss = 0.70, batch loss = 0.40 (186.1 examples/sec; 0.043 sec/batch; 2h:15m:18s remains)
INFO - root - 2022-02-24 19:21:53.282942: step 10660, total loss = 0.59, batch loss = 0.29 (327.1 examples/sec; 0.024 sec/batch; 1h:16m:57s remains)
INFO - root - 2022-02-24 19:21:53.834047: step 10670, total loss = 0.59, batch loss = 0.29 (91.1 examples/sec; 0.088 sec/batch; 4h:36m:17s remains)
INFO - root - 2022-02-24 19:21:54.460094: step 10680, total loss = 0.61, batch loss = 0.31 (257.3 examples/sec; 0.031 sec/batch; 1h:37m:51s remains)
INFO - root - 2022-02-24 19:21:55.463868: step 10690, total loss = 0.62, batch loss = 0.32 (147.4 examples/sec; 0.054 sec/batch; 2h:50m:44s remains)
INFO - root - 2022-02-24 19:21:55.878266: step 10700, total loss = 0.64, batch loss = 0.34 (230.1 examples/sec; 0.035 sec/batch; 1h:49m:23s remains)
INFO - root - 2022-02-24 19:21:56.354109: step 10710, total loss = 0.66, batch loss = 0.36 (159.2 examples/sec; 0.050 sec/batch; 2h:38m:05s remains)
INFO - root - 2022-02-24 19:21:56.869913: step 10720, total loss = 0.70, batch loss = 0.40 (221.9 examples/sec; 0.036 sec/batch; 1h:53m:25s remains)
INFO - root - 2022-02-24 19:21:57.300762: step 10730, total loss = 0.68, batch loss = 0.38 (279.5 examples/sec; 0.029 sec/batch; 1h:30m:02s remains)
INFO - root - 2022-02-24 19:21:57.789899: step 10740, total loss = 0.60, batch loss = 0.31 (304.4 examples/sec; 0.026 sec/batch; 1h:22m:41s remains)
INFO - root - 2022-02-24 19:21:58.198073: step 10750, total loss = 0.68, batch loss = 0.38 (295.5 examples/sec; 0.027 sec/batch; 1h:25m:10s remains)
INFO - root - 2022-02-24 19:21:58.543025: step 10760, total loss = 0.59, batch loss = 0.29 (294.1 examples/sec; 0.027 sec/batch; 1h:25m:33s remains)
INFO - root - 2022-02-24 19:21:58.961182: step 10770, total loss = 0.58, batch loss = 0.28 (212.9 examples/sec; 0.038 sec/batch; 1h:58m:11s remains)
INFO - root - 2022-02-24 19:21:59.534719: step 10780, total loss = 0.66, batch loss = 0.36 (94.5 examples/sec; 0.085 sec/batch; 4h:26m:09s remains)
INFO - root - 2022-02-24 19:22:00.003514: step 10790, total loss = 0.66, batch loss = 0.36 (212.7 examples/sec; 0.038 sec/batch; 1h:58m:19s remains)
INFO - root - 2022-02-24 19:22:00.464617: step 10800, total loss = 0.56, batch loss = 0.26 (297.2 examples/sec; 0.027 sec/batch; 1h:24m:38s remains)
INFO - root - 2022-02-24 19:22:01.406772: step 10810, total loss = 0.66, batch loss = 0.36 (333.9 examples/sec; 0.024 sec/batch; 1h:15m:20s remains)
INFO - root - 2022-02-24 19:22:01.630917: step 10820, total loss = 0.81, batch loss = 0.51 (356.8 examples/sec; 0.022 sec/batch; 1h:10m:30s remains)
INFO - root - 2022-02-24 19:22:01.950003: step 10830, total loss = 0.74, batch loss = 0.44 (264.2 examples/sec; 0.030 sec/batch; 1h:35m:12s remains)
INFO - root - 2022-02-24 19:22:02.357867: step 10840, total loss = 0.64, batch loss = 0.34 (217.7 examples/sec; 0.037 sec/batch; 1h:55m:31s remains)
INFO - root - 2022-02-24 19:22:02.706803: step 10850, total loss = 0.53, batch loss = 0.23 (311.3 examples/sec; 0.026 sec/batch; 1h:20m:47s remains)
INFO - root - 2022-02-24 19:22:03.216204: step 10860, total loss = 0.68, batch loss = 0.38 (175.7 examples/sec; 0.046 sec/batch; 2h:23m:09s remains)
INFO - root - 2022-02-24 19:22:03.713369: step 10870, total loss = 0.58, batch loss = 0.28 (88.5 examples/sec; 0.090 sec/batch; 4h:44m:13s remains)
INFO - root - 2022-02-24 19:22:04.322780: step 10880, total loss = 0.83, batch loss = 0.53 (337.8 examples/sec; 0.024 sec/batch; 1h:14m:27s remains)
INFO - root - 2022-02-24 19:22:04.698730: step 10890, total loss = 0.66, batch loss = 0.36 (226.9 examples/sec; 0.035 sec/batch; 1h:50m:48s remains)
INFO - root - 2022-02-24 19:22:05.164589: step 10900, total loss = 0.64, batch loss = 0.35 (364.4 examples/sec; 0.022 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 19:22:05.658896: step 10910, total loss = 0.68, batch loss = 0.38 (276.8 examples/sec; 0.029 sec/batch; 1h:30m:51s remains)
INFO - root - 2022-02-24 19:22:06.204125: step 10920, total loss = 0.67, batch loss = 0.37 (251.6 examples/sec; 0.032 sec/batch; 1h:39m:56s remains)
INFO - root - 2022-02-24 19:22:06.519890: step 10930, total loss = 0.67, batch loss = 0.37 (204.4 examples/sec; 0.039 sec/batch; 2h:02m:59s remains)
INFO - root - 2022-02-24 19:22:06.899224: step 10940, total loss = 0.57, batch loss = 0.27 (144.2 examples/sec; 0.055 sec/batch; 2h:54m:21s remains)
INFO - root - 2022-02-24 19:22:07.303615: step 10950, total loss = 0.63, batch loss = 0.33 (318.6 examples/sec; 0.025 sec/batch; 1h:18m:53s remains)
INFO - root - 2022-02-24 19:22:07.748562: step 10960, total loss = 0.62, batch loss = 0.32 (137.3 examples/sec; 0.058 sec/batch; 3h:03m:06s remains)
INFO - root - 2022-02-24 19:22:08.273595: step 10970, total loss = 0.60, batch loss = 0.30 (106.6 examples/sec; 0.075 sec/batch; 3h:55m:45s remains)
INFO - root - 2022-02-24 19:22:08.725198: step 10980, total loss = 0.64, batch loss = 0.35 (139.5 examples/sec; 0.057 sec/batch; 3h:00m:08s remains)
INFO - root - 2022-02-24 19:22:09.166877: step 10990, total loss = 0.57, batch loss = 0.27 (143.5 examples/sec; 0.056 sec/batch; 2h:55m:07s remains)
INFO - root - 2022-02-24 19:22:09.551684: step 11000, total loss = 0.86, batch loss = 0.56 (249.7 examples/sec; 0.032 sec/batch; 1h:40m:38s remains)
INFO - root - 2022-02-24 19:22:10.085930: step 11010, total loss = 0.79, batch loss = 0.49 (224.2 examples/sec; 0.036 sec/batch; 1h:52m:05s remains)
INFO - root - 2022-02-24 19:22:10.648178: step 11020, total loss = 0.70, batch loss = 0.40 (135.8 examples/sec; 0.059 sec/batch; 3h:05m:01s remains)
INFO - root - 2022-02-24 19:22:11.041716: step 11030, total loss = 0.59, batch loss = 0.29 (194.8 examples/sec; 0.041 sec/batch; 2h:09m:00s remains)
INFO - root - 2022-02-24 19:22:11.392254: step 11040, total loss = 0.69, batch loss = 0.39 (251.8 examples/sec; 0.032 sec/batch; 1h:39m:47s remains)
INFO - root - 2022-02-24 19:22:11.790764: step 11050, total loss = 0.64, batch loss = 0.34 (290.5 examples/sec; 0.028 sec/batch; 1h:26m:29s remains)
INFO - root - 2022-02-24 19:22:12.309133: step 11060, total loss = 0.63, batch loss = 0.33 (103.3 examples/sec; 0.077 sec/batch; 4h:03m:10s remains)
INFO - root - 2022-02-24 19:22:12.855751: step 11070, total loss = 0.63, batch loss = 0.33 (94.3 examples/sec; 0.085 sec/batch; 4h:26m:31s remains)
INFO - root - 2022-02-24 19:22:13.314796: step 11080, total loss = 0.78, batch loss = 0.48 (157.5 examples/sec; 0.051 sec/batch; 2h:39m:33s remains)
INFO - root - 2022-02-24 19:22:13.874922: step 11090, total loss = 0.81, batch loss = 0.51 (63.8 examples/sec; 0.125 sec/batch; 6h:33m:36s remains)
INFO - root - 2022-02-24 19:22:14.397612: step 11100, total loss = 0.64, batch loss = 0.34 (131.4 examples/sec; 0.061 sec/batch; 3h:11m:14s remains)
INFO - root - 2022-02-24 19:22:15.593429: step 11110, total loss = 0.68, batch loss = 0.39 (165.9 examples/sec; 0.048 sec/batch; 2h:31m:25s remains)
INFO - root - 2022-02-24 19:22:15.955219: step 11120, total loss = 0.69, batch loss = 0.40 (200.9 examples/sec; 0.040 sec/batch; 2h:05m:01s remains)
INFO - root - 2022-02-24 19:22:16.403216: step 11130, total loss = 0.58, batch loss = 0.28 (104.9 examples/sec; 0.076 sec/batch; 3h:59m:20s remains)
INFO - root - 2022-02-24 19:22:16.934292: step 11140, total loss = 0.69, batch loss = 0.39 (165.6 examples/sec; 0.048 sec/batch; 2h:31m:38s remains)
INFO - root - 2022-02-24 19:22:17.370350: step 11150, total loss = 0.67, batch loss = 0.37 (260.5 examples/sec; 0.031 sec/batch; 1h:36m:24s remains)
INFO - root - 2022-02-24 19:22:17.845308: step 11160, total loss = 0.63, batch loss = 0.33 (152.3 examples/sec; 0.053 sec/batch; 2h:44m:53s remains)
INFO - root - 2022-02-24 19:22:18.274253: step 11170, total loss = 0.62, batch loss = 0.32 (139.2 examples/sec; 0.057 sec/batch; 3h:00m:25s remains)
INFO - root - 2022-02-24 19:22:18.749999: step 11180, total loss = 0.66, batch loss = 0.36 (132.0 examples/sec; 0.061 sec/batch; 3h:10m:16s remains)
INFO - root - 2022-02-24 19:22:19.299060: step 11190, total loss = 0.81, batch loss = 0.51 (92.9 examples/sec; 0.086 sec/batch; 4h:30m:16s remains)
INFO - root - 2022-02-24 19:22:19.696508: step 11200, total loss = 0.58, batch loss = 0.28 (292.8 examples/sec; 0.027 sec/batch; 1h:25m:44s remains)
INFO - root - 2022-02-24 19:22:20.390978: step 11210, total loss = 0.58, batch loss = 0.29 (126.8 examples/sec; 0.063 sec/batch; 3h:18m:00s remains)
INFO - root - 2022-02-24 19:22:20.851733: step 11220, total loss = 0.76, batch loss = 0.46 (340.3 examples/sec; 0.024 sec/batch; 1h:13m:45s remains)
INFO - root - 2022-02-24 19:22:21.343270: step 11230, total loss = 0.72, batch loss = 0.42 (119.7 examples/sec; 0.067 sec/batch; 3h:29m:44s remains)
INFO - root - 2022-02-24 19:22:21.706973: step 11240, total loss = 0.70, batch loss = 0.40 (205.6 examples/sec; 0.039 sec/batch; 2h:02m:03s remains)
INFO - root - 2022-02-24 19:22:22.184024: step 11250, total loss = 0.66, batch loss = 0.37 (212.9 examples/sec; 0.038 sec/batch; 1h:57m:55s remains)
INFO - root - 2022-02-24 19:22:22.575048: step 11260, total loss = 0.77, batch loss = 0.47 (203.6 examples/sec; 0.039 sec/batch; 2h:03m:17s remains)
INFO - root - 2022-02-24 19:22:22.966680: step 11270, total loss = 0.57, batch loss = 0.27 (253.3 examples/sec; 0.032 sec/batch; 1h:39m:05s remains)
INFO - root - 2022-02-24 19:22:23.517391: step 11280, total loss = 0.63, batch loss = 0.33 (129.1 examples/sec; 0.062 sec/batch; 3h:14m:27s remains)
INFO - root - 2022-02-24 19:22:23.939265: step 11290, total loss = 0.59, batch loss = 0.29 (217.7 examples/sec; 0.037 sec/batch; 1h:55m:16s remains)
INFO - root - 2022-02-24 19:22:24.339008: step 11300, total loss = 0.62, batch loss = 0.33 (125.2 examples/sec; 0.064 sec/batch; 3h:20m:23s remains)
INFO - root - 2022-02-24 19:22:24.731692: step 11310, total loss = 0.64, batch loss = 0.34 (179.2 examples/sec; 0.045 sec/batch; 2h:20m:00s remains)
INFO - root - 2022-02-24 19:22:25.075184: step 11320, total loss = 0.60, batch loss = 0.30 (368.9 examples/sec; 0.022 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 19:22:25.471308: step 11330, total loss = 0.65, batch loss = 0.35 (90.8 examples/sec; 0.088 sec/batch; 4h:36m:14s remains)
INFO - root - 2022-02-24 19:22:25.975533: step 11340, total loss = 0.64, batch loss = 0.34 (279.9 examples/sec; 0.029 sec/batch; 1h:29m:38s remains)
INFO - root - 2022-02-24 19:22:26.330907: step 11350, total loss = 0.59, batch loss = 0.29 (272.2 examples/sec; 0.029 sec/batch; 1h:32m:08s remains)
INFO - root - 2022-02-24 19:22:26.724823: step 11360, total loss = 0.66, batch loss = 0.36 (274.7 examples/sec; 0.029 sec/batch; 1h:31m:19s remains)
INFO - root - 2022-02-24 19:22:27.082127: step 11370, total loss = 0.59, batch loss = 0.29 (329.9 examples/sec; 0.024 sec/batch; 1h:16m:02s remains)
INFO - root - 2022-02-24 19:22:27.646519: step 11380, total loss = 0.70, batch loss = 0.40 (93.1 examples/sec; 0.086 sec/batch; 4h:29m:17s remains)
INFO - root - 2022-02-24 19:22:28.101477: step 11390, total loss = 0.74, batch loss = 0.44 (156.4 examples/sec; 0.051 sec/batch; 2h:40m:20s remains)
INFO - root - 2022-02-24 19:22:28.575021: step 11400, total loss = 0.72, batch loss = 0.42 (328.6 examples/sec; 0.024 sec/batch; 1h:16m:19s remains)
INFO - root - 2022-02-24 19:22:29.072085: step 11410, total loss = 0.62, batch loss = 0.32 (270.0 examples/sec; 0.030 sec/batch; 1h:32m:53s remains)
INFO - root - 2022-02-24 19:22:29.472758: step 11420, total loss = 0.70, batch loss = 0.40 (307.9 examples/sec; 0.026 sec/batch; 1h:21m:27s remains)
INFO - root - 2022-02-24 19:22:29.980143: step 11430, total loss = 0.70, batch loss = 0.40 (147.0 examples/sec; 0.054 sec/batch; 2h:50m:33s remains)
INFO - root - 2022-02-24 19:22:30.550835: step 11440, total loss = 0.70, batch loss = 0.40 (106.5 examples/sec; 0.075 sec/batch; 3h:55m:32s remains)
INFO - root - 2022-02-24 19:22:30.988539: step 11450, total loss = 0.64, batch loss = 0.34 (152.2 examples/sec; 0.053 sec/batch; 2h:44m:43s remains)
INFO - root - 2022-02-24 19:22:31.358806: step 11460, total loss = 0.70, batch loss = 0.40 (227.4 examples/sec; 0.035 sec/batch; 1h:50m:14s remains)
INFO - root - 2022-02-24 19:22:31.706937: step 11470, total loss = 0.56, batch loss = 0.26 (206.7 examples/sec; 0.039 sec/batch; 2h:01m:18s remains)
INFO - root - 2022-02-24 19:22:32.229186: step 11480, total loss = 0.63, batch loss = 0.33 (84.6 examples/sec; 0.095 sec/batch; 4h:56m:21s remains)
INFO - root - 2022-02-24 19:22:32.681973: step 11490, total loss = 0.68, batch loss = 0.38 (181.4 examples/sec; 0.044 sec/batch; 2h:18m:09s remains)
INFO - root - 2022-02-24 19:22:33.325110: step 11500, total loss = 0.62, batch loss = 0.32 (96.2 examples/sec; 0.083 sec/batch; 4h:20m:32s remains)
INFO - root - 2022-02-24 19:22:34.208858: step 11510, total loss = 0.68, batch loss = 0.39 (358.8 examples/sec; 0.022 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 19:22:34.789619: step 11520, total loss = 0.81, batch loss = 0.51 (246.1 examples/sec; 0.033 sec/batch; 1h:41m:51s remains)
INFO - root - 2022-02-24 19:22:35.803336: step 11530, total loss = 0.65, batch loss = 0.35 (197.5 examples/sec; 0.041 sec/batch; 2h:06m:52s remains)
INFO - root - 2022-02-24 19:22:36.259713: step 11540, total loss = 0.68, batch loss = 0.38 (133.3 examples/sec; 0.060 sec/batch; 3h:07m:59s remains)
INFO - root - 2022-02-24 19:22:36.757459: step 11550, total loss = 0.61, batch loss = 0.31 (294.9 examples/sec; 0.027 sec/batch; 1h:24m:58s remains)
INFO - root - 2022-02-24 19:22:37.178553: step 11560, total loss = 0.67, batch loss = 0.37 (152.0 examples/sec; 0.053 sec/batch; 2h:44m:50s remains)
INFO - root - 2022-02-24 19:22:37.628107: step 11570, total loss = 0.62, batch loss = 0.32 (194.6 examples/sec; 0.041 sec/batch; 2h:08m:46s remains)
INFO - root - 2022-02-24 19:22:37.977970: step 11580, total loss = 0.60, batch loss = 0.31 (230.4 examples/sec; 0.035 sec/batch; 1h:48m:45s remains)
INFO - root - 2022-02-24 19:22:38.329158: step 11590, total loss = 0.59, batch loss = 0.29 (164.1 examples/sec; 0.049 sec/batch; 2h:32m:40s remains)
INFO - root - 2022-02-24 19:22:38.834058: step 11600, total loss = 0.59, batch loss = 0.30 (121.0 examples/sec; 0.066 sec/batch; 3h:27m:04s remains)
INFO - root - 2022-02-24 19:22:39.516520: step 11610, total loss = 0.63, batch loss = 0.33 (80.6 examples/sec; 0.099 sec/batch; 5h:10m:43s remains)
INFO - root - 2022-02-24 19:22:39.935594: step 11620, total loss = 0.65, batch loss = 0.35 (74.2 examples/sec; 0.108 sec/batch; 5h:37m:29s remains)
INFO - root - 2022-02-24 19:22:40.237736: step 11630, total loss = 0.60, batch loss = 0.30 (328.9 examples/sec; 0.024 sec/batch; 1h:16m:09s remains)
INFO - root - 2022-02-24 19:22:40.567277: step 11640, total loss = 0.72, batch loss = 0.42 (153.0 examples/sec; 0.052 sec/batch; 2h:43m:40s remains)
INFO - root - 2022-02-24 19:22:41.085939: step 11650, total loss = 0.66, batch loss = 0.37 (326.4 examples/sec; 0.025 sec/batch; 1h:16m:43s remains)
INFO - root - 2022-02-24 19:22:41.471950: step 11660, total loss = 0.61, batch loss = 0.31 (268.4 examples/sec; 0.030 sec/batch; 1h:33m:19s remains)
INFO - root - 2022-02-24 19:22:42.019804: step 11670, total loss = 0.60, batch loss = 0.30 (79.6 examples/sec; 0.100 sec/batch; 5h:14m:27s remains)
INFO - root - 2022-02-24 19:22:42.470449: step 11680, total loss = 0.58, batch loss = 0.28 (123.1 examples/sec; 0.065 sec/batch; 3h:23m:24s remains)
INFO - root - 2022-02-24 19:22:42.876638: step 11690, total loss = 0.58, batch loss = 0.28 (114.0 examples/sec; 0.070 sec/batch; 3h:39m:41s remains)
INFO - root - 2022-02-24 19:22:43.363425: step 11700, total loss = 0.67, batch loss = 0.37 (147.5 examples/sec; 0.054 sec/batch; 2h:49m:45s remains)
INFO - root - 2022-02-24 19:22:43.862492: step 11710, total loss = 0.72, batch loss = 0.42 (198.9 examples/sec; 0.040 sec/batch; 2h:05m:53s remains)
INFO - root - 2022-02-24 19:22:44.272816: step 11720, total loss = 0.55, batch loss = 0.25 (212.1 examples/sec; 0.038 sec/batch; 1h:58m:03s remains)
INFO - root - 2022-02-24 19:22:44.658456: step 11730, total loss = 0.70, batch loss = 0.40 (279.5 examples/sec; 0.029 sec/batch; 1h:29m:34s remains)
INFO - root - 2022-02-24 19:22:45.009894: step 11740, total loss = 0.68, batch loss = 0.38 (395.7 examples/sec; 0.020 sec/batch; 1h:03m:16s remains)
INFO - root - 2022-02-24 19:22:45.400933: step 11750, total loss = 0.59, batch loss = 0.30 (370.2 examples/sec; 0.022 sec/batch; 1h:07m:36s remains)
INFO - root - 2022-02-24 19:22:45.941149: step 11760, total loss = 0.68, batch loss = 0.38 (247.8 examples/sec; 0.032 sec/batch; 1h:41m:01s remains)
INFO - root - 2022-02-24 19:22:46.344919: step 11770, total loss = 0.56, batch loss = 0.26 (142.7 examples/sec; 0.056 sec/batch; 2h:55m:20s remains)
INFO - root - 2022-02-24 19:22:46.728423: step 11780, total loss = 0.71, batch loss = 0.41 (278.6 examples/sec; 0.029 sec/batch; 1h:29m:50s remains)
INFO - root - 2022-02-24 19:22:47.093848: step 11790, total loss = 0.57, batch loss = 0.28 (159.6 examples/sec; 0.050 sec/batch; 2h:36m:46s remains)
INFO - root - 2022-02-24 19:22:47.609663: step 11800, total loss = 0.66, batch loss = 0.36 (133.9 examples/sec; 0.060 sec/batch; 3h:06m:58s remains)
INFO - root - 2022-02-24 19:22:48.164960: step 11810, total loss = 0.69, batch loss = 0.39 (210.5 examples/sec; 0.038 sec/batch; 1h:58m:52s remains)
INFO - root - 2022-02-24 19:22:48.525035: step 11820, total loss = 0.72, batch loss = 0.42 (360.2 examples/sec; 0.022 sec/batch; 1h:09m:28s remains)
INFO - root - 2022-02-24 19:22:48.928472: step 11830, total loss = 0.65, batch loss = 0.35 (312.2 examples/sec; 0.026 sec/batch; 1h:20m:09s remains)
INFO - root - 2022-02-24 19:22:49.287048: step 11840, total loss = 0.61, batch loss = 0.31 (292.8 examples/sec; 0.027 sec/batch; 1h:25m:27s remains)
INFO - root - 2022-02-24 19:22:49.812017: step 11850, total loss = 0.60, batch loss = 0.30 (105.8 examples/sec; 0.076 sec/batch; 3h:56m:29s remains)
INFO - root - 2022-02-24 19:22:50.314510: step 11860, total loss = 0.70, batch loss = 0.40 (123.2 examples/sec; 0.065 sec/batch; 3h:23m:07s remains)
INFO - root - 2022-02-24 19:22:51.095478: step 11870, total loss = 0.67, batch loss = 0.37 (20.5 examples/sec; 0.389 sec/batch; 20h:17m:58s remains)
INFO - root - 2022-02-24 19:22:51.670195: step 11880, total loss = 0.58, batch loss = 0.28 (178.2 examples/sec; 0.045 sec/batch; 2h:20m:20s remains)
INFO - root - 2022-02-24 19:22:52.350014: step 11890, total loss = 0.67, batch loss = 0.37 (96.2 examples/sec; 0.083 sec/batch; 4h:20m:08s remains)
INFO - root - 2022-02-24 19:22:52.769607: step 11900, total loss = 0.69, batch loss = 0.39 (270.9 examples/sec; 0.030 sec/batch; 1h:32m:20s remains)
INFO - root - 2022-02-24 19:22:53.188019: step 11910, total loss = 0.64, batch loss = 0.35 (279.2 examples/sec; 0.029 sec/batch; 1h:29m:34s remains)
INFO - root - 2022-02-24 19:22:53.667460: step 11920, total loss = 0.68, batch loss = 0.38 (278.9 examples/sec; 0.029 sec/batch; 1h:29m:41s remains)
INFO - root - 2022-02-24 19:22:54.137337: step 11930, total loss = 0.75, batch loss = 0.46 (153.5 examples/sec; 0.052 sec/batch; 2h:42m:55s remains)
INFO - root - 2022-02-24 19:22:54.660821: step 11940, total loss = 0.60, batch loss = 0.31 (270.7 examples/sec; 0.030 sec/batch; 1h:32m:23s remains)
INFO - root - 2022-02-24 19:22:55.246830: step 11950, total loss = 0.77, batch loss = 0.48 (152.7 examples/sec; 0.052 sec/batch; 2h:43m:47s remains)
INFO - root - 2022-02-24 19:22:55.651431: step 11960, total loss = 0.75, batch loss = 0.45 (175.4 examples/sec; 0.046 sec/batch; 2h:22m:34s remains)
INFO - root - 2022-02-24 19:22:56.610119: step 11970, total loss = 0.57, batch loss = 0.27 (165.1 examples/sec; 0.048 sec/batch; 2h:31m:28s remains)
INFO - root - 2022-02-24 19:22:57.058259: step 11980, total loss = 0.62, batch loss = 0.32 (125.7 examples/sec; 0.064 sec/batch; 3h:18m:55s remains)
INFO - root - 2022-02-24 19:22:57.519926: step 11990, total loss = 0.61, batch loss = 0.31 (151.9 examples/sec; 0.053 sec/batch; 2h:44m:33s remains)
INFO - root - 2022-02-24 19:22:57.844966: step 12000, total loss = 0.55, batch loss = 0.26 (169.9 examples/sec; 0.047 sec/batch; 2h:27m:10s remains)
INFO - root - 2022-02-24 19:22:58.239926: step 12010, total loss = 0.56, batch loss = 0.27 (295.6 examples/sec; 0.027 sec/batch; 1h:24m:34s remains)
INFO - root - 2022-02-24 19:22:58.681131: step 12020, total loss = 0.70, batch loss = 0.40 (132.6 examples/sec; 0.060 sec/batch; 3h:08m:33s remains)
INFO - root - 2022-02-24 19:22:59.141698: step 12030, total loss = 0.61, batch loss = 0.31 (221.5 examples/sec; 0.036 sec/batch; 1h:52m:51s remains)
INFO - root - 2022-02-24 19:22:59.628995: step 12040, total loss = 0.56, batch loss = 0.26 (313.1 examples/sec; 0.026 sec/batch; 1h:19m:49s remains)
INFO - root - 2022-02-24 19:23:00.089942: step 12050, total loss = 0.77, batch loss = 0.48 (309.6 examples/sec; 0.026 sec/batch; 1h:20m:43s remains)
INFO - root - 2022-02-24 19:23:00.479727: step 12060, total loss = 0.69, batch loss = 0.39 (197.0 examples/sec; 0.041 sec/batch; 2h:06m:53s remains)
INFO - root - 2022-02-24 19:23:00.921417: step 12070, total loss = 0.56, batch loss = 0.26 (139.7 examples/sec; 0.057 sec/batch; 2h:58m:54s remains)
INFO - root - 2022-02-24 19:23:01.415561: step 12080, total loss = 0.74, batch loss = 0.44 (204.3 examples/sec; 0.039 sec/batch; 2h:02m:20s remains)
INFO - root - 2022-02-24 19:23:01.829043: step 12090, total loss = 0.60, batch loss = 0.30 (198.3 examples/sec; 0.040 sec/batch; 2h:06m:02s remains)
INFO - root - 2022-02-24 19:23:02.263936: step 12100, total loss = 0.56, batch loss = 0.26 (220.5 examples/sec; 0.036 sec/batch; 1h:53m:17s remains)
INFO - root - 2022-02-24 19:23:02.683018: step 12110, total loss = 0.77, batch loss = 0.47 (119.7 examples/sec; 0.067 sec/batch; 3h:28m:42s remains)
INFO - root - 2022-02-24 19:23:03.045095: step 12120, total loss = 0.67, batch loss = 0.38 (167.0 examples/sec; 0.048 sec/batch; 2h:29m:34s remains)
INFO - root - 2022-02-24 19:23:03.577382: step 12130, total loss = 0.51, batch loss = 0.21 (236.0 examples/sec; 0.034 sec/batch; 1h:45m:52s remains)
INFO - root - 2022-02-24 19:23:04.074383: step 12140, total loss = 0.61, batch loss = 0.31 (182.2 examples/sec; 0.044 sec/batch; 2h:17m:05s remains)
INFO - root - 2022-02-24 19:23:04.523212: step 12150, total loss = 0.65, batch loss = 0.35 (212.0 examples/sec; 0.038 sec/batch; 1h:57m:48s remains)
INFO - root - 2022-02-24 19:23:04.884436: step 12160, total loss = 0.51, batch loss = 0.22 (152.7 examples/sec; 0.052 sec/batch; 2h:43m:37s remains)
INFO - root - 2022-02-24 19:23:05.292836: step 12170, total loss = 0.62, batch loss = 0.33 (222.3 examples/sec; 0.036 sec/batch; 1h:52m:22s remains)
INFO - root - 2022-02-24 19:23:05.790556: step 12180, total loss = 0.59, batch loss = 0.30 (71.0 examples/sec; 0.113 sec/batch; 5h:51m:55s remains)
INFO - root - 2022-02-24 19:23:06.315894: step 12190, total loss = 0.61, batch loss = 0.31 (117.0 examples/sec; 0.068 sec/batch; 3h:33m:26s remains)
INFO - root - 2022-02-24 19:23:06.781818: step 12200, total loss = 0.56, batch loss = 0.26 (252.2 examples/sec; 0.032 sec/batch; 1h:39m:01s remains)
INFO - root - 2022-02-24 19:23:07.218792: step 12210, total loss = 0.68, batch loss = 0.39 (309.2 examples/sec; 0.026 sec/batch; 1h:20m:46s remains)
INFO - root - 2022-02-24 19:23:07.670479: step 12220, total loss = 0.59, batch loss = 0.29 (271.2 examples/sec; 0.030 sec/batch; 1h:32m:04s remains)
INFO - root - 2022-02-24 19:23:08.163573: step 12230, total loss = 0.62, batch loss = 0.33 (166.9 examples/sec; 0.048 sec/batch; 2h:29m:34s remains)
INFO - root - 2022-02-24 19:23:08.639074: step 12240, total loss = 0.58, batch loss = 0.29 (258.3 examples/sec; 0.031 sec/batch; 1h:36m:38s remains)
INFO - root - 2022-02-24 19:23:09.035817: step 12250, total loss = 0.65, batch loss = 0.35 (250.2 examples/sec; 0.032 sec/batch; 1h:39m:46s remains)
INFO - root - 2022-02-24 19:23:09.431076: step 12260, total loss = 0.67, batch loss = 0.37 (156.8 examples/sec; 0.051 sec/batch; 2h:39m:12s remains)
INFO - root - 2022-02-24 19:23:09.850685: step 12270, total loss = 0.65, batch loss = 0.35 (288.3 examples/sec; 0.028 sec/batch; 1h:26m:35s remains)
INFO - root - 2022-02-24 19:23:10.588665: step 12280, total loss = 0.75, batch loss = 0.45 (133.6 examples/sec; 0.060 sec/batch; 3h:06m:50s remains)
INFO - root - 2022-02-24 19:23:11.115155: step 12290, total loss = 0.59, batch loss = 0.30 (228.2 examples/sec; 0.035 sec/batch; 1h:49m:24s remains)
INFO - root - 2022-02-24 19:23:12.904103: step 12300, total loss = 0.72, batch loss = 0.43 (351.7 examples/sec; 0.023 sec/batch; 1h:10m:57s remains)
INFO - root - 2022-02-24 19:23:13.295176: step 12310, total loss = 0.70, batch loss = 0.40 (324.1 examples/sec; 0.025 sec/batch; 1h:17m:00s remains)
INFO - root - 2022-02-24 19:23:13.927092: step 12320, total loss = 0.67, batch loss = 0.37 (265.3 examples/sec; 0.030 sec/batch; 1h:34m:03s remains)
INFO - root - 2022-02-24 19:23:14.310834: step 12330, total loss = 0.61, batch loss = 0.31 (137.3 examples/sec; 0.058 sec/batch; 3h:01m:42s remains)
INFO - root - 2022-02-24 19:23:14.821240: step 12340, total loss = 0.66, batch loss = 0.36 (212.5 examples/sec; 0.038 sec/batch; 1h:57m:26s remains)
INFO - root - 2022-02-24 19:23:15.467219: step 12350, total loss = 0.56, batch loss = 0.26 (351.4 examples/sec; 0.023 sec/batch; 1h:11m:01s remains)
INFO - root - 2022-02-24 19:23:16.154250: step 12360, total loss = 0.70, batch loss = 0.40 (57.8 examples/sec; 0.138 sec/batch; 7h:11m:57s remains)
INFO - root - 2022-02-24 19:23:16.682820: step 12370, total loss = 0.67, batch loss = 0.38 (199.5 examples/sec; 0.040 sec/batch; 2h:05m:05s remains)
INFO - root - 2022-02-24 19:23:17.196419: step 12380, total loss = 0.62, batch loss = 0.32 (239.2 examples/sec; 0.033 sec/batch; 1h:44m:17s remains)
INFO - root - 2022-02-24 19:23:18.200401: step 12390, total loss = 0.64, batch loss = 0.34 (231.0 examples/sec; 0.035 sec/batch; 1h:48m:01s remains)
INFO - root - 2022-02-24 19:23:18.670232: step 12400, total loss = 0.70, batch loss = 0.40 (118.0 examples/sec; 0.068 sec/batch; 3h:31m:27s remains)
INFO - root - 2022-02-24 19:23:19.588280: step 12410, total loss = 0.68, batch loss = 0.38 (305.7 examples/sec; 0.026 sec/batch; 1h:21m:36s remains)
INFO - root - 2022-02-24 19:23:19.830973: step 12420, total loss = 0.64, batch loss = 0.34 (313.4 examples/sec; 0.026 sec/batch; 1h:19m:36s remains)
INFO - root - 2022-02-24 19:23:20.072575: step 12430, total loss = 0.61, batch loss = 0.31 (347.0 examples/sec; 0.023 sec/batch; 1h:11m:52s remains)
INFO - root - 2022-02-24 19:23:20.408236: step 12440, total loss = 0.77, batch loss = 0.47 (122.5 examples/sec; 0.065 sec/batch; 3h:23m:31s remains)
INFO - root - 2022-02-24 19:23:20.914885: step 12450, total loss = 0.61, batch loss = 0.31 (247.1 examples/sec; 0.032 sec/batch; 1h:40m:55s remains)
INFO - root - 2022-02-24 19:23:21.309428: step 12460, total loss = 0.66, batch loss = 0.36 (148.3 examples/sec; 0.054 sec/batch; 2h:48m:10s remains)
INFO - root - 2022-02-24 19:23:21.695538: step 12470, total loss = 0.62, batch loss = 0.32 (162.2 examples/sec; 0.049 sec/batch; 2h:33m:42s remains)
INFO - root - 2022-02-24 19:23:22.153377: step 12480, total loss = 0.59, batch loss = 0.30 (135.9 examples/sec; 0.059 sec/batch; 3h:03m:25s remains)
INFO - root - 2022-02-24 19:23:22.623133: step 12490, total loss = 0.73, batch loss = 0.43 (182.6 examples/sec; 0.044 sec/batch; 2h:16m:33s remains)
INFO - root - 2022-02-24 19:23:23.025155: step 12500, total loss = 0.56, batch loss = 0.26 (208.5 examples/sec; 0.038 sec/batch; 1h:59m:36s remains)
INFO - root - 2022-02-24 19:23:23.713794: step 12510, total loss = 0.71, batch loss = 0.41 (164.7 examples/sec; 0.049 sec/batch; 2h:31m:25s remains)
INFO - root - 2022-02-24 19:23:24.143119: step 12520, total loss = 0.66, batch loss = 0.36 (341.9 examples/sec; 0.023 sec/batch; 1h:12m:55s remains)
INFO - root - 2022-02-24 19:23:24.585945: step 12530, total loss = 0.64, batch loss = 0.35 (295.9 examples/sec; 0.027 sec/batch; 1h:24m:15s remains)
INFO - root - 2022-02-24 19:23:25.053855: step 12540, total loss = 0.54, batch loss = 0.24 (146.2 examples/sec; 0.055 sec/batch; 2h:50m:30s remains)
INFO - root - 2022-02-24 19:23:25.365333: step 12550, total loss = 0.63, batch loss = 0.33 (219.4 examples/sec; 0.036 sec/batch; 1h:53m:38s remains)
INFO - root - 2022-02-24 19:23:25.751435: step 12560, total loss = 0.57, batch loss = 0.28 (283.1 examples/sec; 0.028 sec/batch; 1h:28m:02s remains)
INFO - root - 2022-02-24 19:23:26.146816: step 12570, total loss = 0.65, batch loss = 0.36 (208.6 examples/sec; 0.038 sec/batch; 1h:59m:29s remains)
INFO - root - 2022-02-24 19:23:26.597911: step 12580, total loss = 0.69, batch loss = 0.39 (284.3 examples/sec; 0.028 sec/batch; 1h:27m:39s remains)
INFO - root - 2022-02-24 19:23:27.092676: step 12590, total loss = 0.67, batch loss = 0.38 (250.3 examples/sec; 0.032 sec/batch; 1h:39m:34s remains)
INFO - root - 2022-02-24 19:23:27.490584: step 12600, total loss = 0.62, batch loss = 0.32 (219.4 examples/sec; 0.036 sec/batch; 1h:53m:35s remains)
INFO - root - 2022-02-24 19:23:28.043383: step 12610, total loss = 0.70, batch loss = 0.40 (305.3 examples/sec; 0.026 sec/batch; 1h:21m:37s remains)
INFO - root - 2022-02-24 19:23:28.691889: step 12620, total loss = 0.56, batch loss = 0.26 (301.3 examples/sec; 0.027 sec/batch; 1h:22m:42s remains)
INFO - root - 2022-02-24 19:23:29.271817: step 12630, total loss = 0.62, batch loss = 0.32 (320.5 examples/sec; 0.025 sec/batch; 1h:17m:44s remains)
INFO - root - 2022-02-24 19:23:29.777376: step 12640, total loss = 0.59, batch loss = 0.29 (254.1 examples/sec; 0.031 sec/batch; 1h:38m:03s remains)
INFO - root - 2022-02-24 19:23:30.235537: step 12650, total loss = 0.68, batch loss = 0.38 (168.4 examples/sec; 0.048 sec/batch; 2h:27m:57s remains)
INFO - root - 2022-02-24 19:23:30.662805: step 12660, total loss = 0.70, batch loss = 0.40 (217.8 examples/sec; 0.037 sec/batch; 1h:54m:24s remains)
INFO - root - 2022-02-24 19:23:31.094180: step 12670, total loss = 0.62, batch loss = 0.33 (210.5 examples/sec; 0.038 sec/batch; 1h:58m:19s remains)
INFO - root - 2022-02-24 19:23:31.492840: step 12680, total loss = 0.60, batch loss = 0.30 (246.5 examples/sec; 0.032 sec/batch; 1h:41m:03s remains)
INFO - root - 2022-02-24 19:23:32.063044: step 12690, total loss = 0.71, batch loss = 0.41 (113.1 examples/sec; 0.071 sec/batch; 3h:40m:09s remains)
INFO - root - 2022-02-24 19:23:32.482936: step 12700, total loss = 0.68, batch loss = 0.38 (131.5 examples/sec; 0.061 sec/batch; 3h:09m:24s remains)
INFO - root - 2022-02-24 19:23:32.964173: step 12710, total loss = 0.64, batch loss = 0.35 (121.2 examples/sec; 0.066 sec/batch; 3h:25m:29s remains)
INFO - root - 2022-02-24 19:23:33.345174: step 12720, total loss = 0.58, batch loss = 0.29 (357.3 examples/sec; 0.022 sec/batch; 1h:09m:41s remains)
INFO - root - 2022-02-24 19:23:33.742610: step 12730, total loss = 0.70, batch loss = 0.40 (126.4 examples/sec; 0.063 sec/batch; 3h:16m:56s remains)
INFO - root - 2022-02-24 19:23:34.225873: step 12740, total loss = 0.78, batch loss = 0.49 (142.2 examples/sec; 0.056 sec/batch; 2h:55m:10s remains)
INFO - root - 2022-02-24 19:23:34.620990: step 12750, total loss = 0.70, batch loss = 0.40 (218.3 examples/sec; 0.037 sec/batch; 1h:54m:02s remains)
INFO - root - 2022-02-24 19:23:34.981034: step 12760, total loss = 0.72, batch loss = 0.42 (263.5 examples/sec; 0.030 sec/batch; 1h:34m:29s remains)
INFO - root - 2022-02-24 19:23:35.397985: step 12770, total loss = 0.72, batch loss = 0.42 (159.5 examples/sec; 0.050 sec/batch; 2h:36m:05s remains)
INFO - root - 2022-02-24 19:23:35.844375: step 12780, total loss = 0.56, batch loss = 0.26 (117.1 examples/sec; 0.068 sec/batch; 3h:32m:40s remains)
INFO - root - 2022-02-24 19:23:36.283016: step 12790, total loss = 0.71, batch loss = 0.41 (288.0 examples/sec; 0.028 sec/batch; 1h:26m:26s remains)
INFO - root - 2022-02-24 19:23:36.733282: step 12800, total loss = 0.55, batch loss = 0.25 (285.7 examples/sec; 0.028 sec/batch; 1h:27m:08s remains)
INFO - root - 2022-02-24 19:23:37.147141: step 12810, total loss = 0.64, batch loss = 0.34 (263.5 examples/sec; 0.030 sec/batch; 1h:34m:27s remains)
INFO - root - 2022-02-24 19:23:37.530207: step 12820, total loss = 0.59, batch loss = 0.29 (184.0 examples/sec; 0.043 sec/batch; 2h:15m:17s remains)
INFO - root - 2022-02-24 19:23:37.927814: step 12830, total loss = 0.73, batch loss = 0.43 (113.0 examples/sec; 0.071 sec/batch; 3h:40m:18s remains)
INFO - root - 2022-02-24 19:23:38.451519: step 12840, total loss = 0.63, batch loss = 0.34 (239.4 examples/sec; 0.033 sec/batch; 1h:43m:57s remains)
INFO - root - 2022-02-24 19:23:38.918526: step 12850, total loss = 0.58, batch loss = 0.29 (224.7 examples/sec; 0.036 sec/batch; 1h:50m:46s remains)
INFO - root - 2022-02-24 19:23:39.400961: step 12860, total loss = 0.58, batch loss = 0.29 (266.4 examples/sec; 0.030 sec/batch; 1h:33m:25s remains)
INFO - root - 2022-02-24 19:23:39.819989: step 12870, total loss = 0.63, batch loss = 0.33 (164.4 examples/sec; 0.049 sec/batch; 2h:31m:19s remains)
INFO - root - 2022-02-24 19:23:40.333944: step 12880, total loss = 0.66, batch loss = 0.36 (271.0 examples/sec; 0.030 sec/batch; 1h:31m:48s remains)
INFO - root - 2022-02-24 19:23:41.032293: step 12890, total loss = 0.57, batch loss = 0.27 (95.0 examples/sec; 0.084 sec/batch; 4h:21m:46s remains)
INFO - root - 2022-02-24 19:23:41.662723: step 12900, total loss = 0.68, batch loss = 0.38 (144.5 examples/sec; 0.055 sec/batch; 2h:52m:12s remains)
INFO - root - 2022-02-24 19:23:42.317122: step 12910, total loss = 0.53, batch loss = 0.23 (81.5 examples/sec; 0.098 sec/batch; 5h:05m:08s remains)
INFO - root - 2022-02-24 19:23:42.766689: step 12920, total loss = 0.72, batch loss = 0.42 (189.3 examples/sec; 0.042 sec/batch; 2h:11m:25s remains)
INFO - root - 2022-02-24 19:23:43.237859: step 12930, total loss = 0.66, batch loss = 0.36 (99.6 examples/sec; 0.080 sec/batch; 4h:09m:52s remains)
INFO - root - 2022-02-24 19:23:44.056210: step 12940, total loss = 0.59, batch loss = 0.29 (281.7 examples/sec; 0.028 sec/batch; 1h:28m:17s remains)
INFO - root - 2022-02-24 19:23:44.455250: step 12950, total loss = 0.64, batch loss = 0.34 (286.2 examples/sec; 0.028 sec/batch; 1h:26m:54s remains)
INFO - root - 2022-02-24 19:23:44.830459: step 12960, total loss = 0.55, batch loss = 0.26 (192.3 examples/sec; 0.042 sec/batch; 2h:09m:20s remains)
INFO - root - 2022-02-24 19:23:45.280738: step 12970, total loss = 0.61, batch loss = 0.31 (129.9 examples/sec; 0.062 sec/batch; 3h:11m:25s remains)
INFO - root - 2022-02-24 19:23:45.789910: step 12980, total loss = 0.73, batch loss = 0.44 (133.8 examples/sec; 0.060 sec/batch; 3h:05m:48s remains)
INFO - root - 2022-02-24 19:23:46.242514: step 12990, total loss = 0.72, batch loss = 0.43 (134.4 examples/sec; 0.060 sec/batch; 3h:05m:00s remains)
INFO - root - 2022-02-24 19:23:46.577976: step 13000, total loss = 0.82, batch loss = 0.52 (340.4 examples/sec; 0.024 sec/batch; 1h:13m:02s remains)
INFO - root - 2022-02-24 19:23:47.115344: step 13010, total loss = 0.67, batch loss = 0.38 (141.0 examples/sec; 0.057 sec/batch; 2h:56m:21s remains)
INFO - root - 2022-02-24 19:23:47.604235: step 13020, total loss = 0.64, batch loss = 0.35 (291.3 examples/sec; 0.027 sec/batch; 1h:25m:20s remains)
INFO - root - 2022-02-24 19:23:48.052392: step 13030, total loss = 0.57, batch loss = 0.27 (200.1 examples/sec; 0.040 sec/batch; 2h:04m:13s remains)
INFO - root - 2022-02-24 19:23:48.878960: step 13040, total loss = 0.56, batch loss = 0.26 (226.5 examples/sec; 0.035 sec/batch; 1h:49m:46s remains)
INFO - root - 2022-02-24 19:23:49.273526: step 13050, total loss = 0.64, batch loss = 0.34 (325.3 examples/sec; 0.025 sec/batch; 1h:16m:24s remains)
INFO - root - 2022-02-24 19:23:49.683666: step 13060, total loss = 0.66, batch loss = 0.37 (283.9 examples/sec; 0.028 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 19:23:50.073968: step 13070, total loss = 0.69, batch loss = 0.40 (236.9 examples/sec; 0.034 sec/batch; 1h:44m:54s remains)
INFO - root - 2022-02-24 19:23:50.550569: step 13080, total loss = 0.66, batch loss = 0.36 (220.1 examples/sec; 0.036 sec/batch; 1h:52m:55s remains)
INFO - root - 2022-02-24 19:23:50.967916: step 13090, total loss = 0.62, batch loss = 0.33 (166.0 examples/sec; 0.048 sec/batch; 2h:29m:44s remains)
INFO - root - 2022-02-24 19:23:51.508064: step 13100, total loss = 0.65, batch loss = 0.35 (168.5 examples/sec; 0.047 sec/batch; 2h:27m:28s remains)
INFO - root - 2022-02-24 19:23:51.923627: step 13110, total loss = 0.71, batch loss = 0.41 (319.1 examples/sec; 0.025 sec/batch; 1h:17m:53s remains)
INFO - root - 2022-02-24 19:23:52.314627: step 13120, total loss = 0.53, batch loss = 0.23 (277.9 examples/sec; 0.029 sec/batch; 1h:29m:24s remains)
INFO - root - 2022-02-24 19:23:52.657343: step 13130, total loss = 0.60, batch loss = 0.30 (211.6 examples/sec; 0.038 sec/batch; 1h:57m:24s remains)
INFO - root - 2022-02-24 19:23:53.180781: step 13140, total loss = 0.65, batch loss = 0.35 (242.5 examples/sec; 0.033 sec/batch; 1h:42m:28s remains)
INFO - root - 2022-02-24 19:23:53.758631: step 13150, total loss = 0.64, batch loss = 0.35 (323.8 examples/sec; 0.025 sec/batch; 1h:16m:44s remains)
INFO - root - 2022-02-24 19:23:54.130997: step 13160, total loss = 0.78, batch loss = 0.49 (245.9 examples/sec; 0.033 sec/batch; 1h:41m:01s remains)
INFO - root - 2022-02-24 19:23:54.534549: step 13170, total loss = 0.68, batch loss = 0.38 (175.5 examples/sec; 0.046 sec/batch; 2h:21m:32s remains)
INFO - root - 2022-02-24 19:23:54.907538: step 13180, total loss = 0.59, batch loss = 0.29 (101.7 examples/sec; 0.079 sec/batch; 4h:04m:10s remains)
INFO - root - 2022-02-24 19:23:55.406211: step 13190, total loss = 0.70, batch loss = 0.41 (316.9 examples/sec; 0.025 sec/batch; 1h:18m:24s remains)
INFO - root - 2022-02-24 19:23:55.872284: step 13200, total loss = 0.53, batch loss = 0.24 (75.6 examples/sec; 0.106 sec/batch; 5h:28m:34s remains)
INFO - root - 2022-02-24 19:23:56.372289: step 13210, total loss = 0.72, batch loss = 0.43 (364.2 examples/sec; 0.022 sec/batch; 1h:08m:12s remains)
INFO - root - 2022-02-24 19:23:56.757228: step 13220, total loss = 0.64, batch loss = 0.34 (256.1 examples/sec; 0.031 sec/batch; 1h:36m:59s remains)
INFO - root - 2022-02-24 19:23:57.184704: step 13230, total loss = 0.74, batch loss = 0.45 (91.9 examples/sec; 0.087 sec/batch; 4h:30m:07s remains)
INFO - root - 2022-02-24 19:23:57.551444: step 13240, total loss = 0.79, batch loss = 0.49 (221.6 examples/sec; 0.036 sec/batch; 1h:52m:04s remains)
INFO - root - 2022-02-24 19:23:57.977354: step 13250, total loss = 0.70, batch loss = 0.41 (198.8 examples/sec; 0.040 sec/batch; 2h:04m:53s remains)
INFO - root - 2022-02-24 19:23:58.714169: step 13260, total loss = 0.64, batch loss = 0.34 (26.3 examples/sec; 0.304 sec/batch; 15h:43m:57s remains)
INFO - root - 2022-02-24 19:23:59.055973: step 13270, total loss = 0.60, batch loss = 0.30 (281.4 examples/sec; 0.028 sec/batch; 1h:28m:15s remains)
INFO - root - 2022-02-24 19:23:59.483675: step 13280, total loss = 0.75, batch loss = 0.46 (365.3 examples/sec; 0.022 sec/batch; 1h:07m:58s remains)
INFO - root - 2022-02-24 19:23:59.924051: step 13290, total loss = 0.62, batch loss = 0.32 (174.8 examples/sec; 0.046 sec/batch; 2h:22m:04s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-13299 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-13299 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:24:01.027581: step 13300, total loss = 0.67, batch loss = 0.37 (297.6 examples/sec; 0.027 sec/batch; 1h:23m:24s remains)
INFO - root - 2022-02-24 19:24:01.771910: step 13310, total loss = 0.70, batch loss = 0.41 (327.8 examples/sec; 0.024 sec/batch; 1h:15m:43s remains)
INFO - root - 2022-02-24 19:24:01.995586: step 13320, total loss = 0.75, batch loss = 0.46 (373.6 examples/sec; 0.021 sec/batch; 1h:06m:26s remains)
INFO - root - 2022-02-24 19:24:02.292190: step 13330, total loss = 0.56, batch loss = 0.26 (109.4 examples/sec; 0.073 sec/batch; 3h:46m:59s remains)
INFO - root - 2022-02-24 19:24:02.710627: step 13340, total loss = 0.94, batch loss = 0.64 (345.7 examples/sec; 0.023 sec/batch; 1h:11m:48s remains)
INFO - root - 2022-02-24 19:24:03.113661: step 13350, total loss = 0.62, batch loss = 0.32 (238.9 examples/sec; 0.033 sec/batch; 1h:43m:54s remains)
INFO - root - 2022-02-24 19:24:03.993915: step 13360, total loss = 0.73, batch loss = 0.43 (128.0 examples/sec; 0.062 sec/batch; 3h:13m:49s remains)
INFO - root - 2022-02-24 19:24:04.471417: step 13370, total loss = 0.67, batch loss = 0.37 (104.8 examples/sec; 0.076 sec/batch; 3h:56m:47s remains)
INFO - root - 2022-02-24 19:24:04.941979: step 13380, total loss = 0.76, batch loss = 0.46 (266.5 examples/sec; 0.030 sec/batch; 1h:33m:07s remains)
INFO - root - 2022-02-24 19:24:05.302558: step 13390, total loss = 0.71, batch loss = 0.41 (246.4 examples/sec; 0.032 sec/batch; 1h:40m:42s remains)
INFO - root - 2022-02-24 19:24:05.687915: step 13400, total loss = 0.53, batch loss = 0.23 (243.3 examples/sec; 0.033 sec/batch; 1h:42m:00s remains)
INFO - root - 2022-02-24 19:24:06.220410: step 13410, total loss = 0.60, batch loss = 0.30 (87.0 examples/sec; 0.092 sec/batch; 4h:45m:17s remains)
INFO - root - 2022-02-24 19:24:06.735943: step 13420, total loss = 0.68, batch loss = 0.39 (247.1 examples/sec; 0.032 sec/batch; 1h:40m:25s remains)
INFO - root - 2022-02-24 19:24:07.250175: step 13430, total loss = 0.65, batch loss = 0.35 (185.1 examples/sec; 0.043 sec/batch; 2h:14m:00s remains)
INFO - root - 2022-02-24 19:24:07.595091: step 13440, total loss = 0.57, batch loss = 0.27 (180.9 examples/sec; 0.044 sec/batch; 2h:17m:07s remains)
INFO - root - 2022-02-24 19:24:08.017633: step 13450, total loss = 0.60, batch loss = 0.31 (150.4 examples/sec; 0.053 sec/batch; 2h:44m:53s remains)
INFO - root - 2022-02-24 19:24:08.397331: step 13460, total loss = 0.64, batch loss = 0.34 (354.0 examples/sec; 0.023 sec/batch; 1h:10m:04s remains)
INFO - root - 2022-02-24 19:24:08.798588: step 13470, total loss = 0.76, batch loss = 0.46 (265.6 examples/sec; 0.030 sec/batch; 1h:33m:23s remains)
INFO - root - 2022-02-24 19:24:09.308366: step 13480, total loss = 0.60, batch loss = 0.30 (223.4 examples/sec; 0.036 sec/batch; 1h:51m:00s remains)
INFO - root - 2022-02-24 19:24:09.645876: step 13490, total loss = 0.72, batch loss = 0.43 (306.8 examples/sec; 0.026 sec/batch; 1h:20m:49s remains)
INFO - root - 2022-02-24 19:24:10.056071: step 13500, total loss = 0.74, batch loss = 0.44 (200.0 examples/sec; 0.040 sec/batch; 2h:03m:59s remains)
INFO - root - 2022-02-24 19:24:10.541803: step 13510, total loss = 0.71, batch loss = 0.42 (319.4 examples/sec; 0.025 sec/batch; 1h:17m:38s remains)
INFO - root - 2022-02-24 19:24:11.097980: step 13520, total loss = 0.59, batch loss = 0.30 (196.1 examples/sec; 0.041 sec/batch; 2h:06m:28s remains)
INFO - root - 2022-02-24 19:24:11.549281: step 13530, total loss = 0.72, batch loss = 0.43 (175.2 examples/sec; 0.046 sec/batch; 2h:21m:29s remains)
INFO - root - 2022-02-24 19:24:11.937035: step 13540, total loss = 0.58, batch loss = 0.28 (268.4 examples/sec; 0.030 sec/batch; 1h:32m:23s remains)
INFO - root - 2022-02-24 19:24:12.246706: step 13550, total loss = 0.61, batch loss = 0.32 (337.8 examples/sec; 0.024 sec/batch; 1h:13m:24s remains)
INFO - root - 2022-02-24 19:24:12.659282: step 13560, total loss = 0.78, batch loss = 0.48 (310.4 examples/sec; 0.026 sec/batch; 1h:19m:52s remains)
INFO - root - 2022-02-24 19:24:13.132568: step 13570, total loss = 0.83, batch loss = 0.54 (154.8 examples/sec; 0.052 sec/batch; 2h:40m:11s remains)
INFO - root - 2022-02-24 19:24:13.647370: step 13580, total loss = 0.72, batch loss = 0.42 (140.1 examples/sec; 0.057 sec/batch; 2h:56m:56s remains)
INFO - root - 2022-02-24 19:24:14.157538: step 13590, total loss = 0.53, batch loss = 0.23 (204.3 examples/sec; 0.039 sec/batch; 2h:01m:18s remains)
INFO - root - 2022-02-24 19:24:14.522498: step 13600, total loss = 0.58, batch loss = 0.28 (231.2 examples/sec; 0.035 sec/batch; 1h:47m:13s remains)
INFO - root - 2022-02-24 19:24:14.954294: step 13610, total loss = 0.52, batch loss = 0.22 (175.1 examples/sec; 0.046 sec/batch; 2h:21m:34s remains)
INFO - root - 2022-02-24 19:24:15.416490: step 13620, total loss = 0.70, batch loss = 0.40 (254.6 examples/sec; 0.031 sec/batch; 1h:37m:21s remains)
INFO - root - 2022-02-24 19:24:15.964454: step 13630, total loss = 0.65, batch loss = 0.35 (94.6 examples/sec; 0.085 sec/batch; 4h:21m:52s remains)
INFO - root - 2022-02-24 19:24:16.364127: step 13640, total loss = 0.55, batch loss = 0.26 (194.4 examples/sec; 0.041 sec/batch; 2h:07m:28s remains)
INFO - root - 2022-02-24 19:24:16.743523: step 13650, total loss = 0.58, batch loss = 0.29 (373.6 examples/sec; 0.021 sec/batch; 1h:06m:19s remains)
INFO - root - 2022-02-24 19:24:17.197581: step 13660, total loss = 0.65, batch loss = 0.35 (187.0 examples/sec; 0.043 sec/batch; 2h:12m:30s remains)
INFO - root - 2022-02-24 19:24:18.258108: step 13670, total loss = 0.54, batch loss = 0.25 (99.6 examples/sec; 0.080 sec/batch; 4h:08m:53s remains)
INFO - root - 2022-02-24 19:24:18.770803: step 13680, total loss = 0.80, batch loss = 0.51 (88.9 examples/sec; 0.090 sec/batch; 4h:38m:33s remains)
INFO - root - 2022-02-24 19:24:19.697736: step 13690, total loss = 0.62, batch loss = 0.33 (236.9 examples/sec; 0.034 sec/batch; 1h:44m:34s remains)
INFO - root - 2022-02-24 19:24:20.154234: step 13700, total loss = 0.63, batch loss = 0.34 (172.5 examples/sec; 0.046 sec/batch; 2h:23m:38s remains)
INFO - root - 2022-02-24 19:24:20.701225: step 13710, total loss = 0.58, batch loss = 0.29 (183.8 examples/sec; 0.044 sec/batch; 2h:14m:46s remains)
INFO - root - 2022-02-24 19:24:21.089055: step 13720, total loss = 0.78, batch loss = 0.49 (259.6 examples/sec; 0.031 sec/batch; 1h:35m:25s remains)
INFO - root - 2022-02-24 19:24:21.446877: step 13730, total loss = 0.64, batch loss = 0.35 (307.6 examples/sec; 0.026 sec/batch; 1h:20m:31s remains)
INFO - root - 2022-02-24 19:24:21.949301: step 13740, total loss = 0.66, batch loss = 0.37 (270.2 examples/sec; 0.030 sec/batch; 1h:31m:39s remains)
INFO - root - 2022-02-24 19:24:22.492197: step 13750, total loss = 0.74, batch loss = 0.45 (125.5 examples/sec; 0.064 sec/batch; 3h:17m:18s remains)
INFO - root - 2022-02-24 19:24:22.900926: step 13760, total loss = 0.70, batch loss = 0.40 (235.3 examples/sec; 0.034 sec/batch; 1h:45m:15s remains)
INFO - root - 2022-02-24 19:24:23.371019: step 13770, total loss = 0.72, batch loss = 0.43 (295.5 examples/sec; 0.027 sec/batch; 1h:23m:48s remains)
INFO - root - 2022-02-24 19:24:23.801461: step 13780, total loss = 0.64, batch loss = 0.35 (114.1 examples/sec; 0.070 sec/batch; 3h:37m:02s remains)
INFO - root - 2022-02-24 19:24:24.284089: step 13790, total loss = 0.63, batch loss = 0.33 (143.0 examples/sec; 0.056 sec/batch; 2h:53m:10s remains)
INFO - root - 2022-02-24 19:24:24.725835: step 13800, total loss = 0.69, batch loss = 0.39 (104.3 examples/sec; 0.077 sec/batch; 3h:57m:20s remains)
INFO - root - 2022-02-24 19:24:25.331842: step 13810, total loss = 0.61, batch loss = 0.32 (252.8 examples/sec; 0.032 sec/batch; 1h:37m:56s remains)
INFO - root - 2022-02-24 19:24:25.735902: step 13820, total loss = 0.56, batch loss = 0.26 (108.7 examples/sec; 0.074 sec/batch; 3h:47m:49s remains)
INFO - root - 2022-02-24 19:24:26.111798: step 13830, total loss = 0.60, batch loss = 0.30 (194.3 examples/sec; 0.041 sec/batch; 2h:07m:26s remains)
INFO - root - 2022-02-24 19:24:26.577041: step 13840, total loss = 0.71, batch loss = 0.42 (125.0 examples/sec; 0.064 sec/batch; 3h:18m:06s remains)
INFO - root - 2022-02-24 19:24:27.085072: step 13850, total loss = 0.65, batch loss = 0.35 (208.9 examples/sec; 0.038 sec/batch; 1h:58m:30s remains)
INFO - root - 2022-02-24 19:24:27.438110: step 13860, total loss = 0.59, batch loss = 0.30 (254.6 examples/sec; 0.031 sec/batch; 1h:37m:12s remains)
INFO - root - 2022-02-24 19:24:27.851501: step 13870, total loss = 0.58, batch loss = 0.29 (317.5 examples/sec; 0.025 sec/batch; 1h:17m:56s remains)
INFO - root - 2022-02-24 19:24:28.269214: step 13880, total loss = 0.60, batch loss = 0.30 (179.3 examples/sec; 0.045 sec/batch; 2h:18m:01s remains)
INFO - root - 2022-02-24 19:24:28.681889: step 13890, total loss = 0.53, batch loss = 0.24 (225.2 examples/sec; 0.036 sec/batch; 1h:49m:54s remains)
INFO - root - 2022-02-24 19:24:29.164333: step 13900, total loss = 0.56, batch loss = 0.26 (83.7 examples/sec; 0.096 sec/batch; 4h:55m:42s remains)
INFO - root - 2022-02-24 19:24:29.651354: step 13910, total loss = 0.64, batch loss = 0.34 (224.6 examples/sec; 0.036 sec/batch; 1h:50m:11s remains)
INFO - root - 2022-02-24 19:24:30.096549: step 13920, total loss = 0.54, batch loss = 0.25 (191.8 examples/sec; 0.042 sec/batch; 2h:09m:00s remains)
INFO - root - 2022-02-24 19:24:30.526057: step 13930, total loss = 0.74, batch loss = 0.44 (231.5 examples/sec; 0.035 sec/batch; 1h:46m:54s remains)
INFO - root - 2022-02-24 19:24:30.966216: step 13940, total loss = 0.60, batch loss = 0.30 (315.2 examples/sec; 0.025 sec/batch; 1h:18m:30s remains)
INFO - root - 2022-02-24 19:24:31.412722: step 13950, total loss = 0.58, batch loss = 0.28 (323.6 examples/sec; 0.025 sec/batch; 1h:16m:26s remains)
INFO - root - 2022-02-24 19:24:31.800477: step 13960, total loss = 0.56, batch loss = 0.26 (178.8 examples/sec; 0.045 sec/batch; 2h:18m:19s remains)
INFO - root - 2022-02-24 19:24:32.159692: step 13970, total loss = 0.67, batch loss = 0.37 (235.6 examples/sec; 0.034 sec/batch; 1h:44m:59s remains)
INFO - root - 2022-02-24 19:24:32.522290: step 13980, total loss = 0.67, batch loss = 0.38 (249.4 examples/sec; 0.032 sec/batch; 1h:39m:09s remains)
INFO - root - 2022-02-24 19:24:32.949108: step 13990, total loss = 0.53, batch loss = 0.24 (133.3 examples/sec; 0.060 sec/batch; 3h:05m:36s remains)
INFO - root - 2022-02-24 19:24:33.508753: step 14000, total loss = 0.59, batch loss = 0.30 (75.7 examples/sec; 0.106 sec/batch; 5h:26m:43s remains)
INFO - root - 2022-02-24 19:24:34.031878: step 14010, total loss = 0.70, batch loss = 0.41 (316.1 examples/sec; 0.025 sec/batch; 1h:18m:14s remains)
INFO - root - 2022-02-24 19:24:34.495416: step 14020, total loss = 0.55, batch loss = 0.25 (187.7 examples/sec; 0.043 sec/batch; 2h:11m:46s remains)
INFO - root - 2022-02-24 19:24:34.908071: step 14030, total loss = 0.74, batch loss = 0.44 (128.0 examples/sec; 0.062 sec/batch; 3h:13m:11s remains)
INFO - root - 2022-02-24 19:24:35.386722: step 14040, total loss = 0.71, batch loss = 0.42 (180.0 examples/sec; 0.044 sec/batch; 2h:17m:21s remains)
INFO - root - 2022-02-24 19:24:35.792954: step 14050, total loss = 0.62, batch loss = 0.33 (274.5 examples/sec; 0.029 sec/batch; 1h:30m:05s remains)
INFO - root - 2022-02-24 19:24:36.225042: step 14060, total loss = 0.74, batch loss = 0.45 (297.4 examples/sec; 0.027 sec/batch; 1h:23m:08s remains)
INFO - root - 2022-02-24 19:24:36.652267: step 14070, total loss = 0.64, batch loss = 0.34 (201.8 examples/sec; 0.040 sec/batch; 2h:02m:30s remains)
INFO - root - 2022-02-24 19:24:37.078166: step 14080, total loss = 0.59, batch loss = 0.30 (248.7 examples/sec; 0.032 sec/batch; 1h:39m:23s remains)
INFO - root - 2022-02-24 19:24:37.547010: step 14090, total loss = 0.61, batch loss = 0.31 (74.1 examples/sec; 0.108 sec/batch; 5h:33m:43s remains)
INFO - root - 2022-02-24 19:24:37.970737: step 14100, total loss = 0.64, batch loss = 0.35 (128.7 examples/sec; 0.062 sec/batch; 3h:12m:01s remains)
INFO - root - 2022-02-24 19:24:38.519346: step 14110, total loss = 0.65, batch loss = 0.35 (211.6 examples/sec; 0.038 sec/batch; 1h:56m:47s remains)
INFO - root - 2022-02-24 19:24:38.905551: step 14120, total loss = 0.52, batch loss = 0.22 (285.2 examples/sec; 0.028 sec/batch; 1h:26m:40s remains)
INFO - root - 2022-02-24 19:24:39.354636: step 14130, total loss = 0.74, batch loss = 0.45 (258.0 examples/sec; 0.031 sec/batch; 1h:35m:47s remains)
INFO - root - 2022-02-24 19:24:39.785280: step 14140, total loss = 0.58, batch loss = 0.29 (159.7 examples/sec; 0.050 sec/batch; 2h:34m:46s remains)
INFO - root - 2022-02-24 19:24:40.269143: step 14150, total loss = 0.53, batch loss = 0.23 (188.3 examples/sec; 0.042 sec/batch; 2h:11m:14s remains)
INFO - root - 2022-02-24 19:24:40.726926: step 14160, total loss = 0.69, batch loss = 0.40 (269.7 examples/sec; 0.030 sec/batch; 1h:31m:37s remains)
INFO - root - 2022-02-24 19:24:41.119213: step 14170, total loss = 0.50, batch loss = 0.20 (232.5 examples/sec; 0.034 sec/batch; 1h:46m:17s remains)
INFO - root - 2022-02-24 19:24:41.484272: step 14180, total loss = 0.57, batch loss = 0.27 (139.4 examples/sec; 0.057 sec/batch; 2h:57m:14s remains)
INFO - root - 2022-02-24 19:24:41.917876: step 14190, total loss = 0.69, batch loss = 0.39 (118.5 examples/sec; 0.068 sec/batch; 3h:28m:34s remains)
INFO - root - 2022-02-24 19:24:42.390081: step 14200, total loss = 0.57, batch loss = 0.27 (233.5 examples/sec; 0.034 sec/batch; 1h:45m:49s remains)
INFO - root - 2022-02-24 19:24:42.985532: step 14210, total loss = 0.68, batch loss = 0.39 (149.9 examples/sec; 0.053 sec/batch; 2h:44m:47s remains)
INFO - root - 2022-02-24 19:24:43.378859: step 14220, total loss = 0.76, batch loss = 0.47 (337.1 examples/sec; 0.024 sec/batch; 1h:13m:16s remains)
INFO - root - 2022-02-24 19:24:43.777640: step 14230, total loss = 0.55, batch loss = 0.26 (197.7 examples/sec; 0.040 sec/batch; 2h:04m:56s remains)
INFO - root - 2022-02-24 19:24:44.153304: step 14240, total loss = 0.64, batch loss = 0.35 (218.8 examples/sec; 0.037 sec/batch; 1h:52m:54s remains)
INFO - root - 2022-02-24 19:24:44.654236: step 14250, total loss = 0.66, batch loss = 0.36 (176.2 examples/sec; 0.045 sec/batch; 2h:20m:09s remains)
INFO - root - 2022-02-24 19:24:45.080951: step 14260, total loss = 0.51, batch loss = 0.21 (277.7 examples/sec; 0.029 sec/batch; 1h:28m:55s remains)
INFO - root - 2022-02-24 19:24:45.529775: step 14270, total loss = 0.71, batch loss = 0.41 (255.6 examples/sec; 0.031 sec/batch; 1h:36m:36s remains)
INFO - root - 2022-02-24 19:24:45.942527: step 14280, total loss = 0.70, batch loss = 0.40 (193.6 examples/sec; 0.041 sec/batch; 2h:07m:32s remains)
INFO - root - 2022-02-24 19:24:46.302103: step 14290, total loss = 0.58, batch loss = 0.29 (348.7 examples/sec; 0.023 sec/batch; 1h:10m:49s remains)
INFO - root - 2022-02-24 19:24:46.744031: step 14300, total loss = 0.62, batch loss = 0.32 (254.1 examples/sec; 0.031 sec/batch; 1h:37m:11s remains)
INFO - root - 2022-02-24 19:24:47.316812: step 14310, total loss = 0.73, batch loss = 0.43 (213.0 examples/sec; 0.038 sec/batch; 1h:55m:56s remains)
INFO - root - 2022-02-24 19:24:47.812007: step 14320, total loss = 0.63, batch loss = 0.34 (136.4 examples/sec; 0.059 sec/batch; 3h:00m:57s remains)
INFO - root - 2022-02-24 19:24:48.231105: step 14330, total loss = 0.69, batch loss = 0.39 (333.9 examples/sec; 0.024 sec/batch; 1h:13m:56s remains)
INFO - root - 2022-02-24 19:24:48.745507: step 14340, total loss = 0.61, batch loss = 0.32 (299.6 examples/sec; 0.027 sec/batch; 1h:22m:24s remains)
INFO - root - 2022-02-24 19:24:49.733803: step 14350, total loss = 0.66, batch loss = 0.36 (100.4 examples/sec; 0.080 sec/batch; 4h:05m:54s remains)
INFO - root - 2022-02-24 19:24:50.232725: step 14360, total loss = 0.69, batch loss = 0.39 (182.9 examples/sec; 0.044 sec/batch; 2h:14m:58s remains)
INFO - root - 2022-02-24 19:24:50.653531: step 14370, total loss = 0.53, batch loss = 0.23 (136.0 examples/sec; 0.059 sec/batch; 3h:01m:27s remains)
INFO - root - 2022-02-24 19:24:51.109157: step 14380, total loss = 0.74, batch loss = 0.44 (279.7 examples/sec; 0.029 sec/batch; 1h:28m:15s remains)
INFO - root - 2022-02-24 19:24:51.676034: step 14390, total loss = 0.62, batch loss = 0.32 (90.5 examples/sec; 0.088 sec/batch; 4h:32m:34s remains)
INFO - root - 2022-02-24 19:24:52.224444: step 14400, total loss = 0.59, batch loss = 0.30 (176.9 examples/sec; 0.045 sec/batch; 2h:19m:29s remains)
INFO - root - 2022-02-24 19:24:52.781387: step 14410, total loss = 0.76, batch loss = 0.47 (154.5 examples/sec; 0.052 sec/batch; 2h:39m:43s remains)
INFO - root - 2022-02-24 19:24:53.164549: step 14420, total loss = 0.61, batch loss = 0.31 (243.8 examples/sec; 0.033 sec/batch; 1h:41m:14s remains)
INFO - root - 2022-02-24 19:24:53.671240: step 14430, total loss = 0.71, batch loss = 0.42 (164.3 examples/sec; 0.049 sec/batch; 2h:30m:10s remains)
INFO - root - 2022-02-24 19:24:54.111762: step 14440, total loss = 0.70, batch loss = 0.41 (215.2 examples/sec; 0.037 sec/batch; 1h:54m:39s remains)
INFO - root - 2022-02-24 19:24:54.547563: step 14450, total loss = 0.70, batch loss = 0.40 (313.3 examples/sec; 0.026 sec/batch; 1h:18m:44s remains)
INFO - root - 2022-02-24 19:24:55.105812: step 14460, total loss = 0.68, batch loss = 0.39 (295.0 examples/sec; 0.027 sec/batch; 1h:23m:38s remains)
INFO - root - 2022-02-24 19:24:55.438832: step 14470, total loss = 0.62, batch loss = 0.33 (248.9 examples/sec; 0.032 sec/batch; 1h:39m:06s remains)
INFO - root - 2022-02-24 19:24:55.924642: step 14480, total loss = 0.68, batch loss = 0.39 (303.1 examples/sec; 0.026 sec/batch; 1h:21m:23s remains)
INFO - root - 2022-02-24 19:24:56.447775: step 14490, total loss = 0.71, batch loss = 0.41 (151.0 examples/sec; 0.053 sec/batch; 2h:43m:24s remains)
INFO - root - 2022-02-24 19:24:56.895214: step 14500, total loss = 0.60, batch loss = 0.31 (284.2 examples/sec; 0.028 sec/batch; 1h:26m:48s remains)
INFO - root - 2022-02-24 19:24:57.412768: step 14510, total loss = 0.62, batch loss = 0.33 (207.0 examples/sec; 0.039 sec/batch; 1h:59m:07s remains)
INFO - root - 2022-02-24 19:24:57.970282: step 14520, total loss = 0.66, batch loss = 0.37 (180.7 examples/sec; 0.044 sec/batch; 2h:16m:30s remains)
INFO - root - 2022-02-24 19:24:58.486306: step 14530, total loss = 0.67, batch loss = 0.37 (142.0 examples/sec; 0.056 sec/batch; 2h:53m:41s remains)
INFO - root - 2022-02-24 19:24:58.961256: step 14540, total loss = 0.63, batch loss = 0.33 (316.6 examples/sec; 0.025 sec/batch; 1h:17m:53s remains)
INFO - root - 2022-02-24 19:24:59.423207: step 14550, total loss = 0.61, batch loss = 0.32 (123.7 examples/sec; 0.065 sec/batch; 3h:19m:20s remains)
INFO - root - 2022-02-24 19:25:00.076582: step 14560, total loss = 0.58, batch loss = 0.28 (154.6 examples/sec; 0.052 sec/batch; 2h:39m:29s remains)
INFO - root - 2022-02-24 19:25:00.512752: step 14570, total loss = 0.60, batch loss = 0.31 (110.4 examples/sec; 0.072 sec/batch; 3h:43m:21s remains)
INFO - root - 2022-02-24 19:25:00.967667: step 14580, total loss = 0.62, batch loss = 0.33 (167.7 examples/sec; 0.048 sec/batch; 2h:27m:04s remains)
INFO - root - 2022-02-24 19:25:01.325448: step 14590, total loss = 0.72, batch loss = 0.42 (272.6 examples/sec; 0.029 sec/batch; 1h:30m:26s remains)
INFO - root - 2022-02-24 19:25:01.720153: step 14600, total loss = 0.66, batch loss = 0.36 (297.0 examples/sec; 0.027 sec/batch; 1h:23m:00s remains)
INFO - root - 2022-02-24 19:25:02.230396: step 14610, total loss = 0.64, batch loss = 0.34 (349.7 examples/sec; 0.023 sec/batch; 1h:10m:30s remains)
INFO - root - 2022-02-24 19:25:02.691344: step 14620, total loss = 0.68, batch loss = 0.38 (282.3 examples/sec; 0.028 sec/batch; 1h:27m:19s remains)
INFO - root - 2022-02-24 19:25:03.235015: step 14630, total loss = 0.68, batch loss = 0.39 (171.3 examples/sec; 0.047 sec/batch; 2h:23m:52s remains)
INFO - root - 2022-02-24 19:25:03.581361: step 14640, total loss = 0.64, batch loss = 0.34 (192.7 examples/sec; 0.042 sec/batch; 2h:07m:53s remains)
INFO - root - 2022-02-24 19:25:03.946148: step 14650, total loss = 0.60, batch loss = 0.31 (146.8 examples/sec; 0.054 sec/batch; 2h:47m:52s remains)
INFO - root - 2022-02-24 19:25:04.358905: step 14660, total loss = 0.57, batch loss = 0.28 (266.7 examples/sec; 0.030 sec/batch; 1h:32m:24s remains)
INFO - root - 2022-02-24 19:25:04.870764: step 14670, total loss = 0.64, batch loss = 0.34 (350.1 examples/sec; 0.023 sec/batch; 1h:10m:22s remains)
INFO - root - 2022-02-24 19:25:05.324480: step 14680, total loss = 0.55, batch loss = 0.26 (157.1 examples/sec; 0.051 sec/batch; 2h:36m:50s remains)
INFO - root - 2022-02-24 19:25:05.683255: step 14690, total loss = 0.61, batch loss = 0.32 (153.2 examples/sec; 0.052 sec/batch; 2h:40m:47s remains)
INFO - root - 2022-02-24 19:25:06.124874: step 14700, total loss = 0.60, batch loss = 0.30 (304.8 examples/sec; 0.026 sec/batch; 1h:20m:50s remains)
INFO - root - 2022-02-24 19:25:06.759964: step 14710, total loss = 0.63, batch loss = 0.33 (163.8 examples/sec; 0.049 sec/batch; 2h:30m:23s remains)
INFO - root - 2022-02-24 19:25:07.185487: step 14720, total loss = 0.67, batch loss = 0.37 (301.0 examples/sec; 0.027 sec/batch; 1h:21m:50s remains)
INFO - root - 2022-02-24 19:25:07.663586: step 14730, total loss = 0.67, batch loss = 0.38 (92.4 examples/sec; 0.087 sec/batch; 4h:26m:39s remains)
INFO - root - 2022-02-24 19:25:08.276414: step 14740, total loss = 0.60, batch loss = 0.31 (329.1 examples/sec; 0.024 sec/batch; 1h:14m:51s remains)
INFO - root - 2022-02-24 19:25:08.814922: step 14750, total loss = 0.64, batch loss = 0.35 (220.2 examples/sec; 0.036 sec/batch; 1h:51m:52s remains)
INFO - root - 2022-02-24 19:25:09.142213: step 14760, total loss = 0.60, batch loss = 0.30 (351.8 examples/sec; 0.023 sec/batch; 1h:10m:01s remains)
INFO - root - 2022-02-24 19:25:09.521226: step 14770, total loss = 0.67, batch loss = 0.38 (269.7 examples/sec; 0.030 sec/batch; 1h:31m:20s remains)
INFO - root - 2022-02-24 19:25:10.444353: step 14780, total loss = 0.55, batch loss = 0.26 (16.3 examples/sec; 0.491 sec/batch; 25h:11m:46s remains)
INFO - root - 2022-02-24 19:25:11.008086: step 14790, total loss = 0.59, batch loss = 0.30 (85.3 examples/sec; 0.094 sec/batch; 4h:48m:47s remains)
INFO - root - 2022-02-24 19:25:11.433465: step 14800, total loss = 0.72, batch loss = 0.43 (220.2 examples/sec; 0.036 sec/batch; 1h:51m:49s remains)
INFO - root - 2022-02-24 19:25:11.906454: step 14810, total loss = 0.61, batch loss = 0.32 (338.5 examples/sec; 0.024 sec/batch; 1h:12m:45s remains)
INFO - root - 2022-02-24 19:25:12.272180: step 14820, total loss = 0.64, batch loss = 0.35 (333.0 examples/sec; 0.024 sec/batch; 1h:13m:57s remains)
INFO - root - 2022-02-24 19:25:12.717964: step 14830, total loss = 0.59, batch loss = 0.30 (166.2 examples/sec; 0.048 sec/batch; 2h:28m:09s remains)
INFO - root - 2022-02-24 19:25:13.228218: step 14840, total loss = 0.64, batch loss = 0.34 (125.1 examples/sec; 0.064 sec/batch; 3h:16m:45s remains)
INFO - root - 2022-02-24 19:25:13.683469: step 14850, total loss = 0.60, batch loss = 0.31 (242.5 examples/sec; 0.033 sec/batch; 1h:41m:30s remains)
INFO - root - 2022-02-24 19:25:14.095468: step 14860, total loss = 0.64, batch loss = 0.35 (195.2 examples/sec; 0.041 sec/batch; 2h:06m:06s remains)
INFO - root - 2022-02-24 19:25:14.499400: step 14870, total loss = 0.72, batch loss = 0.42 (232.6 examples/sec; 0.034 sec/batch; 1h:45m:50s remains)
INFO - root - 2022-02-24 19:25:14.864819: step 14880, total loss = 0.58, batch loss = 0.29 (270.0 examples/sec; 0.030 sec/batch; 1h:31m:09s remains)
INFO - root - 2022-02-24 19:25:15.503119: step 14890, total loss = 0.67, batch loss = 0.38 (99.7 examples/sec; 0.080 sec/batch; 4h:06m:50s remains)
INFO - root - 2022-02-24 19:25:16.022775: step 14900, total loss = 0.58, batch loss = 0.29 (204.7 examples/sec; 0.039 sec/batch; 2h:00m:15s remains)
INFO - root - 2022-02-24 19:25:16.537883: step 14910, total loss = 0.64, batch loss = 0.35 (265.0 examples/sec; 0.030 sec/batch; 1h:32m:51s remains)
INFO - root - 2022-02-24 19:25:16.929443: step 14920, total loss = 0.59, batch loss = 0.29 (198.6 examples/sec; 0.040 sec/batch; 2h:03m:56s remains)
INFO - root - 2022-02-24 19:25:17.326482: step 14930, total loss = 0.88, batch loss = 0.58 (376.7 examples/sec; 0.021 sec/batch; 1h:05m:19s remains)
INFO - root - 2022-02-24 19:25:17.813490: step 14940, total loss = 0.68, batch loss = 0.38 (191.3 examples/sec; 0.042 sec/batch; 2h:08m:39s remains)
INFO - root - 2022-02-24 19:25:18.268342: step 14950, total loss = 0.62, batch loss = 0.33 (121.3 examples/sec; 0.066 sec/batch; 3h:22m:56s remains)
INFO - root - 2022-02-24 19:25:18.676779: step 14960, total loss = 0.56, batch loss = 0.27 (263.5 examples/sec; 0.030 sec/batch; 1h:33m:22s remains)
INFO - root - 2022-02-24 19:25:19.055739: step 14970, total loss = 0.63, batch loss = 0.34 (296.7 examples/sec; 0.027 sec/batch; 1h:22m:55s remains)
INFO - root - 2022-02-24 19:25:19.385646: step 14980, total loss = 0.61, batch loss = 0.32 (296.7 examples/sec; 0.027 sec/batch; 1h:22m:54s remains)
INFO - root - 2022-02-24 19:25:19.887083: step 14990, total loss = 0.63, batch loss = 0.33 (182.7 examples/sec; 0.044 sec/batch; 2h:14m:40s remains)
INFO - root - 2022-02-24 19:25:20.384923: step 15000, total loss = 0.81, batch loss = 0.51 (294.6 examples/sec; 0.027 sec/batch; 1h:23m:29s remains)
INFO - root - 2022-02-24 19:25:20.866463: step 15010, total loss = 0.57, batch loss = 0.27 (296.5 examples/sec; 0.027 sec/batch; 1h:22m:58s remains)
INFO - root - 2022-02-24 19:25:21.260452: step 15020, total loss = 0.64, batch loss = 0.35 (195.1 examples/sec; 0.041 sec/batch; 2h:06m:05s remains)
INFO - root - 2022-02-24 19:25:21.632083: step 15030, total loss = 0.65, batch loss = 0.35 (173.1 examples/sec; 0.046 sec/batch; 2h:22m:03s remains)
INFO - root - 2022-02-24 19:25:22.095337: step 15040, total loss = 0.53, batch loss = 0.23 (237.6 examples/sec; 0.034 sec/batch; 1h:43m:31s remains)
INFO - root - 2022-02-24 19:25:22.578936: step 15050, total loss = 0.77, batch loss = 0.47 (195.1 examples/sec; 0.041 sec/batch; 2h:06m:03s remains)
INFO - root - 2022-02-24 19:25:22.990205: step 15060, total loss = 0.54, batch loss = 0.25 (173.1 examples/sec; 0.046 sec/batch; 2h:22m:05s remains)
INFO - root - 2022-02-24 19:25:23.345213: step 15070, total loss = 0.60, batch loss = 0.31 (318.8 examples/sec; 0.025 sec/batch; 1h:17m:08s remains)
INFO - root - 2022-02-24 19:25:23.693145: step 15080, total loss = 0.61, batch loss = 0.31 (259.7 examples/sec; 0.031 sec/batch; 1h:34m:40s remains)
INFO - root - 2022-02-24 19:25:24.156274: step 15090, total loss = 0.67, batch loss = 0.37 (98.5 examples/sec; 0.081 sec/batch; 4h:09m:38s remains)
INFO - root - 2022-02-24 19:25:24.688334: step 15100, total loss = 0.61, batch loss = 0.31 (291.3 examples/sec; 0.027 sec/batch; 1h:24m:23s remains)
INFO - root - 2022-02-24 19:25:25.149233: step 15110, total loss = 0.70, batch loss = 0.40 (243.8 examples/sec; 0.033 sec/batch; 1h:40m:50s remains)
INFO - root - 2022-02-24 19:25:25.565408: step 15120, total loss = 0.63, batch loss = 0.33 (199.0 examples/sec; 0.040 sec/batch; 2h:03m:31s remains)
INFO - root - 2022-02-24 19:25:25.933371: step 15130, total loss = 0.63, batch loss = 0.33 (179.2 examples/sec; 0.045 sec/batch; 2h:17m:12s remains)
INFO - root - 2022-02-24 19:25:26.373986: step 15140, total loss = 0.54, batch loss = 0.24 (102.9 examples/sec; 0.078 sec/batch; 3h:58m:56s remains)
INFO - root - 2022-02-24 19:25:26.866736: step 15150, total loss = 0.57, batch loss = 0.28 (154.4 examples/sec; 0.052 sec/batch; 2h:39m:11s remains)
INFO - root - 2022-02-24 19:25:27.300961: step 15160, total loss = 0.62, batch loss = 0.33 (174.4 examples/sec; 0.046 sec/batch; 2h:20m:54s remains)
INFO - root - 2022-02-24 19:25:27.709075: step 15170, total loss = 0.58, batch loss = 0.29 (323.6 examples/sec; 0.025 sec/batch; 1h:15m:56s remains)
INFO - root - 2022-02-24 19:25:28.122957: step 15180, total loss = 0.68, batch loss = 0.39 (215.7 examples/sec; 0.037 sec/batch; 1h:53m:57s remains)
INFO - root - 2022-02-24 19:25:28.660801: step 15190, total loss = 0.68, batch loss = 0.39 (115.8 examples/sec; 0.069 sec/batch; 3h:32m:16s remains)
INFO - root - 2022-02-24 19:25:29.211232: step 15200, total loss = 0.59, batch loss = 0.30 (338.1 examples/sec; 0.024 sec/batch; 1h:12m:40s remains)
INFO - root - 2022-02-24 19:25:29.831337: step 15210, total loss = 0.63, batch loss = 0.34 (138.9 examples/sec; 0.058 sec/batch; 2h:56m:56s remains)
INFO - root - 2022-02-24 19:25:30.701148: step 15220, total loss = 0.62, batch loss = 0.32 (15.9 examples/sec; 0.503 sec/batch; 25h:43m:51s remains)
INFO - root - 2022-02-24 19:25:31.059363: step 15230, total loss = 0.59, batch loss = 0.29 (285.4 examples/sec; 0.028 sec/batch; 1h:26m:04s remains)
INFO - root - 2022-02-24 19:25:31.589488: step 15240, total loss = 0.60, batch loss = 0.31 (99.7 examples/sec; 0.080 sec/batch; 4h:06m:27s remains)
INFO - root - 2022-02-24 19:25:32.121362: step 15250, total loss = 0.67, batch loss = 0.37 (192.7 examples/sec; 0.042 sec/batch; 2h:07m:27s remains)
INFO - root - 2022-02-24 19:25:32.500608: step 15260, total loss = 0.67, batch loss = 0.37 (267.5 examples/sec; 0.030 sec/batch; 1h:31m:49s remains)
INFO - root - 2022-02-24 19:25:32.867959: step 15270, total loss = 0.61, batch loss = 0.31 (180.4 examples/sec; 0.044 sec/batch; 2h:16m:07s remains)
INFO - root - 2022-02-24 19:25:33.228369: step 15280, total loss = 0.59, batch loss = 0.30 (317.7 examples/sec; 0.025 sec/batch; 1h:17m:19s remains)
INFO - root - 2022-02-24 19:25:33.719542: step 15290, total loss = 0.58, batch loss = 0.28 (365.1 examples/sec; 0.022 sec/batch; 1h:07m:16s remains)
INFO - root - 2022-02-24 19:25:34.189438: step 15300, total loss = 0.56, batch loss = 0.26 (352.6 examples/sec; 0.023 sec/batch; 1h:09m:39s remains)
INFO - root - 2022-02-24 19:25:34.731820: step 15310, total loss = 0.60, batch loss = 0.31 (214.7 examples/sec; 0.037 sec/batch; 1h:54m:24s remains)
INFO - root - 2022-02-24 19:25:35.125835: step 15320, total loss = 0.61, batch loss = 0.31 (293.0 examples/sec; 0.027 sec/batch; 1h:23m:48s remains)
INFO - root - 2022-02-24 19:25:35.780242: step 15330, total loss = 0.55, batch loss = 0.26 (338.9 examples/sec; 0.024 sec/batch; 1h:12m:27s remains)
INFO - root - 2022-02-24 19:25:36.238303: step 15340, total loss = 0.71, batch loss = 0.42 (191.7 examples/sec; 0.042 sec/batch; 2h:08m:07s remains)
INFO - root - 2022-02-24 19:25:36.656991: step 15350, total loss = 0.61, batch loss = 0.32 (202.0 examples/sec; 0.040 sec/batch; 2h:01m:34s remains)
INFO - root - 2022-02-24 19:25:37.149255: step 15360, total loss = 0.61, batch loss = 0.32 (175.8 examples/sec; 0.046 sec/batch; 2h:19m:39s remains)
INFO - root - 2022-02-24 19:25:37.536614: step 15370, total loss = 0.64, batch loss = 0.34 (119.8 examples/sec; 0.067 sec/batch; 3h:24m:54s remains)
INFO - root - 2022-02-24 19:25:37.888842: step 15380, total loss = 0.66, batch loss = 0.36 (134.2 examples/sec; 0.060 sec/batch; 3h:02m:53s remains)
INFO - root - 2022-02-24 19:25:38.362818: step 15390, total loss = 0.66, batch loss = 0.37 (229.9 examples/sec; 0.035 sec/batch; 1h:46m:47s remains)
INFO - root - 2022-02-24 19:25:38.739661: step 15400, total loss = 0.62, batch loss = 0.32 (159.2 examples/sec; 0.050 sec/batch; 2h:34m:13s remains)
INFO - root - 2022-02-24 19:25:39.265503: step 15410, total loss = 0.66, batch loss = 0.36 (285.9 examples/sec; 0.028 sec/batch; 1h:25m:51s remains)
INFO - root - 2022-02-24 19:25:39.634104: step 15420, total loss = 0.64, batch loss = 0.35 (213.4 examples/sec; 0.037 sec/batch; 1h:54m:59s remains)
INFO - root - 2022-02-24 19:25:40.049907: step 15430, total loss = 0.76, batch loss = 0.46 (197.6 examples/sec; 0.040 sec/batch; 2h:04m:13s remains)
INFO - root - 2022-02-24 19:25:40.611744: step 15440, total loss = 0.75, batch loss = 0.45 (92.1 examples/sec; 0.087 sec/batch; 4h:26m:29s remains)
INFO - root - 2022-02-24 19:25:41.119681: step 15450, total loss = 0.72, batch loss = 0.42 (93.0 examples/sec; 0.086 sec/batch; 4h:23m:53s remains)
INFO - root - 2022-02-24 19:25:41.508746: step 15460, total loss = 0.65, batch loss = 0.35 (254.2 examples/sec; 0.031 sec/batch; 1h:36m:32s remains)
INFO - root - 2022-02-24 19:25:41.874977: step 15470, total loss = 0.63, batch loss = 0.34 (329.1 examples/sec; 0.024 sec/batch; 1h:14m:33s remains)
INFO - root - 2022-02-24 19:25:42.235087: step 15480, total loss = 0.60, batch loss = 0.31 (301.6 examples/sec; 0.027 sec/batch; 1h:21m:20s remains)
INFO - root - 2022-02-24 19:25:42.722566: step 15490, total loss = 0.62, batch loss = 0.32 (119.8 examples/sec; 0.067 sec/batch; 3h:24m:50s remains)
INFO - root - 2022-02-24 19:25:43.216501: step 15500, total loss = 0.63, batch loss = 0.33 (211.7 examples/sec; 0.038 sec/batch; 1h:55m:52s remains)
INFO - root - 2022-02-24 19:25:43.701906: step 15510, total loss = 0.58, batch loss = 0.29 (188.6 examples/sec; 0.042 sec/batch; 2h:10m:03s remains)
INFO - root - 2022-02-24 19:25:44.090832: step 15520, total loss = 0.62, batch loss = 0.33 (130.0 examples/sec; 0.062 sec/batch; 3h:08m:44s remains)
INFO - root - 2022-02-24 19:25:44.534769: step 15530, total loss = 0.53, batch loss = 0.23 (92.6 examples/sec; 0.086 sec/batch; 4h:24m:57s remains)
INFO - root - 2022-02-24 19:25:44.967541: step 15540, total loss = 0.58, batch loss = 0.29 (170.4 examples/sec; 0.047 sec/batch; 2h:23m:56s remains)
INFO - root - 2022-02-24 19:25:45.528299: step 15550, total loss = 0.57, batch loss = 0.28 (189.9 examples/sec; 0.042 sec/batch; 2h:09m:10s remains)
INFO - root - 2022-02-24 19:25:45.886084: step 15560, total loss = 0.62, batch loss = 0.33 (280.9 examples/sec; 0.028 sec/batch; 1h:27m:18s remains)
INFO - root - 2022-02-24 19:25:46.277556: step 15570, total loss = 0.66, batch loss = 0.36 (365.3 examples/sec; 0.022 sec/batch; 1h:07m:08s remains)
INFO - root - 2022-02-24 19:25:46.615162: step 15580, total loss = 0.69, batch loss = 0.39 (323.4 examples/sec; 0.025 sec/batch; 1h:15m:49s remains)
INFO - root - 2022-02-24 19:25:47.034503: step 15590, total loss = 0.52, batch loss = 0.23 (355.1 examples/sec; 0.023 sec/batch; 1h:09m:03s remains)
INFO - root - 2022-02-24 19:25:47.517247: step 15600, total loss = 0.64, batch loss = 0.34 (229.0 examples/sec; 0.035 sec/batch; 1h:47m:04s remains)
INFO - root - 2022-02-24 19:25:48.015477: step 15610, total loss = 0.54, batch loss = 0.24 (184.7 examples/sec; 0.043 sec/batch; 2h:12m:45s remains)
INFO - root - 2022-02-24 19:25:48.454505: step 15620, total loss = 0.55, batch loss = 0.25 (180.8 examples/sec; 0.044 sec/batch; 2h:15m:34s remains)
INFO - root - 2022-02-24 19:25:48.808709: step 15630, total loss = 0.67, batch loss = 0.37 (176.0 examples/sec; 0.045 sec/batch; 2h:19m:15s remains)
INFO - root - 2022-02-24 19:25:49.412585: step 15640, total loss = 0.68, batch loss = 0.38 (77.6 examples/sec; 0.103 sec/batch; 5h:15m:53s remains)
INFO - root - 2022-02-24 19:25:49.901919: step 15650, total loss = 0.56, batch loss = 0.26 (96.3 examples/sec; 0.083 sec/batch; 4h:14m:38s remains)
INFO - root - 2022-02-24 19:25:50.906145: step 15660, total loss = 0.56, batch loss = 0.27 (125.7 examples/sec; 0.064 sec/batch; 3h:14m:59s remains)
INFO - root - 2022-02-24 19:25:51.263002: step 15670, total loss = 0.57, batch loss = 0.27 (154.5 examples/sec; 0.052 sec/batch; 2h:38m:38s remains)
INFO - root - 2022-02-24 19:25:51.643202: step 15680, total loss = 0.66, batch loss = 0.37 (212.0 examples/sec; 0.038 sec/batch; 1h:55m:36s remains)
INFO - root - 2022-02-24 19:25:52.210090: step 15690, total loss = 0.62, batch loss = 0.33 (141.2 examples/sec; 0.057 sec/batch; 2h:53m:34s remains)
INFO - root - 2022-02-24 19:25:52.610800: step 15700, total loss = 0.59, batch loss = 0.30 (243.6 examples/sec; 0.033 sec/batch; 1h:40m:35s remains)
INFO - root - 2022-02-24 19:25:53.060757: step 15710, total loss = 0.67, batch loss = 0.38 (350.5 examples/sec; 0.023 sec/batch; 1h:09m:54s remains)
INFO - root - 2022-02-24 19:25:53.509790: step 15720, total loss = 0.53, batch loss = 0.24 (122.2 examples/sec; 0.065 sec/batch; 3h:20m:31s remains)
INFO - root - 2022-02-24 19:25:54.223836: step 15730, total loss = 0.71, batch loss = 0.41 (163.3 examples/sec; 0.049 sec/batch; 2h:30m:03s remains)
INFO - root - 2022-02-24 19:25:54.711362: step 15740, total loss = 0.54, batch loss = 0.25 (201.5 examples/sec; 0.040 sec/batch; 2h:01m:35s remains)
INFO - root - 2022-02-24 19:25:55.209802: step 15750, total loss = 0.68, batch loss = 0.38 (141.9 examples/sec; 0.056 sec/batch; 2h:52m:36s remains)
INFO - root - 2022-02-24 19:25:55.950250: step 15760, total loss = 0.64, batch loss = 0.35 (125.0 examples/sec; 0.064 sec/batch; 3h:15m:55s remains)
INFO - root - 2022-02-24 19:25:56.351117: step 15770, total loss = 0.64, batch loss = 0.34 (169.2 examples/sec; 0.047 sec/batch; 2h:24m:44s remains)
INFO - root - 2022-02-24 19:25:56.851490: step 15780, total loss = 0.73, batch loss = 0.43 (213.0 examples/sec; 0.038 sec/batch; 1h:55m:00s remains)
INFO - root - 2022-02-24 19:25:57.251463: step 15790, total loss = 0.65, batch loss = 0.36 (74.5 examples/sec; 0.107 sec/batch; 5h:28m:44s remains)
INFO - root - 2022-02-24 19:25:57.578701: step 15800, total loss = 0.65, batch loss = 0.36 (343.5 examples/sec; 0.023 sec/batch; 1h:11m:18s remains)
INFO - root - 2022-02-24 19:25:58.076798: step 15810, total loss = 0.64, batch loss = 0.35 (173.6 examples/sec; 0.046 sec/batch; 2h:21m:03s remains)
INFO - root - 2022-02-24 19:25:58.528716: step 15820, total loss = 0.59, batch loss = 0.30 (181.7 examples/sec; 0.044 sec/batch; 2h:14m:46s remains)
INFO - root - 2022-02-24 19:25:58.906120: step 15830, total loss = 0.57, batch loss = 0.27 (150.4 examples/sec; 0.053 sec/batch; 2h:42m:50s remains)
INFO - root - 2022-02-24 19:25:59.504958: step 15840, total loss = 0.62, batch loss = 0.33 (166.0 examples/sec; 0.048 sec/batch; 2h:27m:32s remains)
INFO - root - 2022-02-24 19:25:59.888719: step 15850, total loss = 0.54, batch loss = 0.24 (224.2 examples/sec; 0.036 sec/batch; 1h:49m:14s remains)
INFO - root - 2022-02-24 19:26:00.236554: step 15860, total loss = 0.54, batch loss = 0.25 (202.2 examples/sec; 0.040 sec/batch; 2h:01m:05s remains)
INFO - root - 2022-02-24 19:26:00.693260: step 15870, total loss = 0.60, batch loss = 0.31 (262.6 examples/sec; 0.030 sec/batch; 1h:33m:14s remains)
INFO - root - 2022-02-24 19:26:01.090149: step 15880, total loss = 0.59, batch loss = 0.30 (264.0 examples/sec; 0.030 sec/batch; 1h:32m:44s remains)
INFO - root - 2022-02-24 19:26:01.517420: step 15890, total loss = 0.57, batch loss = 0.27 (156.4 examples/sec; 0.051 sec/batch; 2h:36m:31s remains)
INFO - root - 2022-02-24 19:26:01.834262: step 15900, total loss = 0.68, batch loss = 0.39 (191.3 examples/sec; 0.042 sec/batch; 2h:07m:56s remains)
INFO - root - 2022-02-24 19:26:02.271534: step 15910, total loss = 0.57, batch loss = 0.27 (279.0 examples/sec; 0.029 sec/batch; 1h:27m:43s remains)
INFO - root - 2022-02-24 19:26:02.653424: step 15920, total loss = 0.65, batch loss = 0.36 (168.3 examples/sec; 0.048 sec/batch; 2h:25m:28s remains)
INFO - root - 2022-02-24 19:26:03.165655: step 15930, total loss = 0.53, batch loss = 0.24 (104.5 examples/sec; 0.077 sec/batch; 3h:54m:11s remains)
INFO - root - 2022-02-24 19:26:03.532939: step 15940, total loss = 0.59, batch loss = 0.30 (156.1 examples/sec; 0.051 sec/batch; 2h:36m:49s remains)
INFO - root - 2022-02-24 19:26:03.918995: step 15950, total loss = 0.60, batch loss = 0.31 (292.4 examples/sec; 0.027 sec/batch; 1h:23m:42s remains)
INFO - root - 2022-02-24 19:26:04.318470: step 15960, total loss = 0.55, batch loss = 0.26 (328.8 examples/sec; 0.024 sec/batch; 1h:14m:25s remains)
INFO - root - 2022-02-24 19:26:04.763181: step 15970, total loss = 0.72, batch loss = 0.42 (313.7 examples/sec; 0.026 sec/batch; 1h:18m:00s remains)
INFO - root - 2022-02-24 19:26:05.277086: step 15980, total loss = 0.59, batch loss = 0.29 (220.6 examples/sec; 0.036 sec/batch; 1h:50m:56s remains)
INFO - root - 2022-02-24 19:26:05.654086: step 15990, total loss = 0.64, batch loss = 0.35 (321.4 examples/sec; 0.025 sec/batch; 1h:16m:08s remains)
INFO - root - 2022-02-24 19:26:06.122208: step 16000, total loss = 0.79, batch loss = 0.49 (152.6 examples/sec; 0.052 sec/batch; 2h:40m:20s remains)
INFO - root - 2022-02-24 19:26:06.646126: step 16010, total loss = 0.65, batch loss = 0.36 (102.3 examples/sec; 0.078 sec/batch; 3h:59m:14s remains)
INFO - root - 2022-02-24 19:26:07.167566: step 16020, total loss = 0.62, batch loss = 0.32 (171.1 examples/sec; 0.047 sec/batch; 2h:22m:59s remains)
INFO - root - 2022-02-24 19:26:07.546047: step 16030, total loss = 0.54, batch loss = 0.25 (276.4 examples/sec; 0.029 sec/batch; 1h:28m:29s remains)
INFO - root - 2022-02-24 19:26:07.947124: step 16040, total loss = 0.64, batch loss = 0.34 (249.4 examples/sec; 0.032 sec/batch; 1h:38m:05s remains)
INFO - root - 2022-02-24 19:26:08.312301: step 16050, total loss = 0.75, batch loss = 0.46 (229.9 examples/sec; 0.035 sec/batch; 1h:46m:23s remains)
INFO - root - 2022-02-24 19:26:08.744851: step 16060, total loss = 0.68, batch loss = 0.39 (322.8 examples/sec; 0.025 sec/batch; 1h:15m:46s remains)
INFO - root - 2022-02-24 19:26:09.224334: step 16070, total loss = 0.64, batch loss = 0.35 (343.8 examples/sec; 0.023 sec/batch; 1h:11m:08s remains)
INFO - root - 2022-02-24 19:26:09.574024: step 16080, total loss = 0.56, batch loss = 0.26 (303.7 examples/sec; 0.026 sec/batch; 1h:20m:32s remains)
INFO - root - 2022-02-24 19:26:09.954085: step 16090, total loss = 0.68, batch loss = 0.39 (189.5 examples/sec; 0.042 sec/batch; 2h:09m:04s remains)
INFO - root - 2022-02-24 19:26:10.444309: step 16100, total loss = 0.60, batch loss = 0.30 (187.4 examples/sec; 0.043 sec/batch; 2h:10m:28s remains)
INFO - root - 2022-02-24 19:26:11.045911: step 16110, total loss = 0.64, batch loss = 0.35 (171.1 examples/sec; 0.047 sec/batch; 2h:22m:54s remains)
INFO - root - 2022-02-24 19:26:11.445576: step 16120, total loss = 0.59, batch loss = 0.29 (242.8 examples/sec; 0.033 sec/batch; 1h:40m:42s remains)
INFO - root - 2022-02-24 19:26:11.848001: step 16130, total loss = 0.61, batch loss = 0.32 (167.3 examples/sec; 0.048 sec/batch; 2h:26m:06s remains)
INFO - root - 2022-02-24 19:26:12.219159: step 16140, total loss = 0.60, batch loss = 0.31 (218.5 examples/sec; 0.037 sec/batch; 1h:51m:54s remains)
INFO - root - 2022-02-24 19:26:12.634165: step 16150, total loss = 0.63, batch loss = 0.33 (136.0 examples/sec; 0.059 sec/batch; 2h:59m:42s remains)
INFO - root - 2022-02-24 19:26:13.118046: step 16160, total loss = 0.55, batch loss = 0.26 (208.4 examples/sec; 0.038 sec/batch; 1h:57m:16s remains)
INFO - root - 2022-02-24 19:26:13.475283: step 16170, total loss = 0.52, batch loss = 0.23 (335.1 examples/sec; 0.024 sec/batch; 1h:12m:56s remains)
INFO - root - 2022-02-24 19:26:13.985753: step 16180, total loss = 0.60, batch loss = 0.31 (105.5 examples/sec; 0.076 sec/batch; 3h:51m:46s remains)
INFO - root - 2022-02-24 19:26:14.471896: step 16190, total loss = 0.64, batch loss = 0.34 (136.5 examples/sec; 0.059 sec/batch; 2h:59m:05s remains)
INFO - root - 2022-02-24 19:26:14.829946: step 16200, total loss = 0.57, batch loss = 0.28 (224.1 examples/sec; 0.036 sec/batch; 1h:49m:02s remains)
INFO - root - 2022-02-24 19:26:15.319450: step 16210, total loss = 0.68, batch loss = 0.39 (180.8 examples/sec; 0.044 sec/batch; 2h:15m:09s remains)
INFO - root - 2022-02-24 19:26:16.197072: step 16220, total loss = 0.73, batch loss = 0.44 (19.8 examples/sec; 0.405 sec/batch; 20h:35m:52s remains)
INFO - root - 2022-02-24 19:26:16.636829: step 16230, total loss = 0.66, batch loss = 0.36 (196.1 examples/sec; 0.041 sec/batch; 2h:04m:34s remains)
INFO - root - 2022-02-24 19:26:17.090772: step 16240, total loss = 0.56, batch loss = 0.27 (281.2 examples/sec; 0.028 sec/batch; 1h:26m:54s remains)
INFO - root - 2022-02-24 19:26:17.402501: step 16250, total loss = 0.70, batch loss = 0.41 (338.2 examples/sec; 0.024 sec/batch; 1h:12m:14s remains)
INFO - root - 2022-02-24 19:26:17.889255: step 16260, total loss = 0.77, batch loss = 0.48 (211.3 examples/sec; 0.038 sec/batch; 1h:55m:38s remains)
INFO - root - 2022-02-24 19:26:18.296957: step 16270, total loss = 0.70, batch loss = 0.41 (289.4 examples/sec; 0.028 sec/batch; 1h:24m:25s remains)
INFO - root - 2022-02-24 19:26:18.772650: step 16280, total loss = 0.64, batch loss = 0.35 (167.9 examples/sec; 0.048 sec/batch; 2h:25m:29s remains)
INFO - root - 2022-02-24 19:26:19.251949: step 16290, total loss = 0.56, batch loss = 0.26 (115.0 examples/sec; 0.070 sec/batch; 3h:32m:29s remains)
INFO - root - 2022-02-24 19:26:19.784606: step 16300, total loss = 0.67, batch loss = 0.38 (193.3 examples/sec; 0.041 sec/batch; 2h:06m:20s remains)
INFO - root - 2022-02-24 19:26:20.270894: step 16310, total loss = 0.64, batch loss = 0.34 (200.0 examples/sec; 0.040 sec/batch; 2h:02m:07s remains)
INFO - root - 2022-02-24 19:26:20.868559: step 16320, total loss = 0.57, batch loss = 0.28 (123.4 examples/sec; 0.065 sec/batch; 3h:17m:52s remains)
INFO - root - 2022-02-24 19:26:21.708340: step 16330, total loss = 0.63, batch loss = 0.34 (152.4 examples/sec; 0.052 sec/batch; 2h:40m:15s remains)
INFO - root - 2022-02-24 19:26:22.206996: step 16340, total loss = 0.74, batch loss = 0.44 (311.9 examples/sec; 0.026 sec/batch; 1h:18m:18s remains)
INFO - root - 2022-02-24 19:26:22.665325: step 16350, total loss = 0.60, batch loss = 0.30 (146.7 examples/sec; 0.055 sec/batch; 2h:46m:27s remains)
INFO - root - 2022-02-24 19:26:23.134619: step 16360, total loss = 0.59, batch loss = 0.30 (180.8 examples/sec; 0.044 sec/batch; 2h:15m:05s remains)
INFO - root - 2022-02-24 19:26:23.631578: step 16370, total loss = 0.52, batch loss = 0.22 (105.8 examples/sec; 0.076 sec/batch; 3h:50m:49s remains)
INFO - root - 2022-02-24 19:26:24.022041: step 16380, total loss = 0.55, batch loss = 0.25 (143.1 examples/sec; 0.056 sec/batch; 2h:50m:38s remains)
INFO - root - 2022-02-24 19:26:24.464052: step 16390, total loss = 0.60, batch loss = 0.31 (184.1 examples/sec; 0.043 sec/batch; 2h:12m:38s remains)
INFO - root - 2022-02-24 19:26:24.888238: step 16400, total loss = 0.53, batch loss = 0.24 (95.7 examples/sec; 0.084 sec/batch; 4h:15m:13s remains)
INFO - root - 2022-02-24 19:26:25.420456: step 16410, total loss = 0.63, batch loss = 0.33 (184.2 examples/sec; 0.043 sec/batch; 2h:12m:33s remains)
INFO - root - 2022-02-24 19:26:25.794902: step 16420, total loss = 0.82, batch loss = 0.52 (328.5 examples/sec; 0.024 sec/batch; 1h:14m:19s remains)
INFO - root - 2022-02-24 19:26:26.199867: step 16430, total loss = 0.68, batch loss = 0.39 (175.2 examples/sec; 0.046 sec/batch; 2h:19m:17s remains)
INFO - root - 2022-02-24 19:26:26.699411: step 16440, total loss = 0.68, batch loss = 0.38 (119.3 examples/sec; 0.067 sec/batch; 3h:24m:36s remains)
INFO - root - 2022-02-24 19:26:27.236560: step 16450, total loss = 0.62, batch loss = 0.32 (99.4 examples/sec; 0.081 sec/batch; 4h:05m:37s remains)
INFO - root - 2022-02-24 19:26:27.613297: step 16460, total loss = 0.62, batch loss = 0.33 (301.7 examples/sec; 0.027 sec/batch; 1h:20m:53s remains)
INFO - root - 2022-02-24 19:26:28.074245: step 16470, total loss = 0.68, batch loss = 0.38 (195.8 examples/sec; 0.041 sec/batch; 2h:04m:36s remains)
INFO - root - 2022-02-24 19:26:28.468309: step 16480, total loss = 0.53, batch loss = 0.24 (169.7 examples/sec; 0.047 sec/batch; 2h:23m:50s remains)
INFO - root - 2022-02-24 19:26:28.964769: step 16490, total loss = 0.51, batch loss = 0.22 (97.6 examples/sec; 0.082 sec/batch; 4h:10m:05s remains)
INFO - root - 2022-02-24 19:26:29.444826: step 16500, total loss = 0.61, batch loss = 0.31 (215.8 examples/sec; 0.037 sec/batch; 1h:53m:02s remains)
INFO - root - 2022-02-24 19:26:29.918251: step 16510, total loss = 0.74, batch loss = 0.44 (332.1 examples/sec; 0.024 sec/batch; 1h:13m:28s remains)
INFO - root - 2022-02-24 19:26:30.350757: step 16520, total loss = 0.54, batch loss = 0.24 (138.6 examples/sec; 0.058 sec/batch; 2h:56m:02s remains)
INFO - root - 2022-02-24 19:26:30.773877: step 16530, total loss = 0.59, batch loss = 0.29 (197.0 examples/sec; 0.041 sec/batch; 2h:03m:50s remains)
INFO - root - 2022-02-24 19:26:31.316824: step 16540, total loss = 0.68, batch loss = 0.39 (132.4 examples/sec; 0.060 sec/batch; 3h:04m:17s remains)
INFO - root - 2022-02-24 19:26:31.919990: step 16550, total loss = 0.50, batch loss = 0.21 (176.6 examples/sec; 0.045 sec/batch; 2h:18m:06s remains)
INFO - root - 2022-02-24 19:26:32.360155: step 16560, total loss = 0.67, batch loss = 0.37 (201.7 examples/sec; 0.040 sec/batch; 2h:00m:54s remains)
INFO - root - 2022-02-24 19:26:32.749701: step 16570, total loss = 0.58, batch loss = 0.29 (264.0 examples/sec; 0.030 sec/batch; 1h:32m:22s remains)
INFO - root - 2022-02-24 19:26:33.105207: step 16580, total loss = 0.61, batch loss = 0.32 (352.5 examples/sec; 0.023 sec/batch; 1h:09m:11s remains)
INFO - root - 2022-02-24 19:26:33.437525: step 16590, total loss = 0.69, batch loss = 0.39 (291.7 examples/sec; 0.027 sec/batch; 1h:23m:36s remains)
INFO - root - 2022-02-24 19:26:33.964490: step 16600, total loss = 0.57, batch loss = 0.27 (94.2 examples/sec; 0.085 sec/batch; 4h:18m:50s remains)
INFO - root - 2022-02-24 19:26:34.462821: step 16610, total loss = 0.62, batch loss = 0.33 (189.2 examples/sec; 0.042 sec/batch; 2h:08m:54s remains)
INFO - root - 2022-02-24 19:26:34.860916: step 16620, total loss = 0.62, batch loss = 0.33 (310.9 examples/sec; 0.026 sec/batch; 1h:18m:26s remains)
INFO - root - 2022-02-24 19:26:35.216111: step 16630, total loss = 0.58, batch loss = 0.28 (299.3 examples/sec; 0.027 sec/batch; 1h:21m:27s remains)
INFO - root - 2022-02-24 19:26:35.617634: step 16640, total loss = 0.69, batch loss = 0.40 (340.6 examples/sec; 0.023 sec/batch; 1h:11m:34s remains)
INFO - root - 2022-02-24 19:26:36.105358: step 16650, total loss = 0.58, batch loss = 0.29 (178.1 examples/sec; 0.045 sec/batch; 2h:16m:55s remains)
INFO - root - 2022-02-24 19:26:36.589589: step 16660, total loss = 0.60, batch loss = 0.31 (206.7 examples/sec; 0.039 sec/batch; 1h:57m:55s remains)
INFO - root - 2022-02-24 19:26:37.072989: step 16670, total loss = 0.58, batch loss = 0.29 (161.6 examples/sec; 0.049 sec/batch; 2h:30m:48s remains)
INFO - root - 2022-02-24 19:26:37.393204: step 16680, total loss = 0.51, batch loss = 0.21 (273.7 examples/sec; 0.029 sec/batch; 1h:29m:04s remains)
INFO - root - 2022-02-24 19:26:37.759973: step 16690, total loss = 0.77, batch loss = 0.48 (214.5 examples/sec; 0.037 sec/batch; 1h:53m:37s remains)
INFO - root - 2022-02-24 19:26:38.145776: step 16700, total loss = 0.68, batch loss = 0.39 (265.3 examples/sec; 0.030 sec/batch; 1h:31m:52s remains)
INFO - root - 2022-02-24 19:26:38.712065: step 16710, total loss = 0.68, batch loss = 0.39 (97.8 examples/sec; 0.082 sec/batch; 4h:09m:18s remains)
INFO - root - 2022-02-24 19:26:39.128133: step 16720, total loss = 0.67, batch loss = 0.38 (159.0 examples/sec; 0.050 sec/batch; 2h:33m:14s remains)
INFO - root - 2022-02-24 19:26:39.662026: step 16730, total loss = 0.55, batch loss = 0.26 (211.7 examples/sec; 0.038 sec/batch; 1h:55m:06s remains)
INFO - root - 2022-02-24 19:26:40.016688: step 16740, total loss = 0.60, batch loss = 0.31 (182.4 examples/sec; 0.044 sec/batch; 2h:13m:34s remains)
INFO - root - 2022-02-24 19:26:40.463756: step 16750, total loss = 0.74, batch loss = 0.45 (188.8 examples/sec; 0.042 sec/batch; 2h:09m:04s remains)
INFO - root - 2022-02-24 19:26:41.050574: step 16760, total loss = 0.63, batch loss = 0.33 (129.4 examples/sec; 0.062 sec/batch; 3h:08m:20s remains)
INFO - root - 2022-02-24 19:26:41.631571: step 16770, total loss = 0.64, batch loss = 0.35 (258.7 examples/sec; 0.031 sec/batch; 1h:34m:10s remains)
INFO - root - 2022-02-24 19:26:42.652805: step 16780, total loss = 0.56, batch loss = 0.26 (323.7 examples/sec; 0.025 sec/batch; 1h:15m:15s remains)
INFO - root - 2022-02-24 19:26:43.208952: step 16790, total loss = 0.77, batch loss = 0.48 (114.9 examples/sec; 0.070 sec/batch; 3h:31m:59s remains)
INFO - root - 2022-02-24 19:26:43.652738: step 16800, total loss = 0.57, batch loss = 0.28 (303.1 examples/sec; 0.026 sec/batch; 1h:20m:22s remains)
INFO - root - 2022-02-24 19:26:44.633533: step 16810, total loss = 0.62, batch loss = 0.33 (363.8 examples/sec; 0.022 sec/batch; 1h:06m:57s remains)
INFO - root - 2022-02-24 19:26:44.862145: step 16820, total loss = 0.58, batch loss = 0.29 (354.7 examples/sec; 0.023 sec/batch; 1h:08m:39s remains)
INFO - root - 2022-02-24 19:26:45.095377: step 16830, total loss = 0.61, batch loss = 0.32 (356.6 examples/sec; 0.022 sec/batch; 1h:08m:17s remains)
INFO - root - 2022-02-24 19:26:45.618035: step 16840, total loss = 0.75, batch loss = 0.46 (256.1 examples/sec; 0.031 sec/batch; 1h:35m:05s remains)
INFO - root - 2022-02-24 19:26:46.050550: step 16850, total loss = 0.65, batch loss = 0.36 (264.5 examples/sec; 0.030 sec/batch; 1h:32m:05s remains)
INFO - root - 2022-02-24 19:26:46.499869: step 16860, total loss = 0.62, batch loss = 0.32 (394.2 examples/sec; 0.020 sec/batch; 1h:01m:47s remains)
INFO - root - 2022-02-24 19:26:46.919451: step 16870, total loss = 0.68, batch loss = 0.39 (326.6 examples/sec; 0.024 sec/batch; 1h:14m:33s remains)
INFO - root - 2022-02-24 19:26:47.356317: step 16880, total loss = 0.71, batch loss = 0.42 (159.9 examples/sec; 0.050 sec/batch; 2h:32m:18s remains)
INFO - root - 2022-02-24 19:26:48.161080: step 16890, total loss = 0.61, batch loss = 0.32 (195.6 examples/sec; 0.041 sec/batch; 2h:04m:28s remains)
INFO - root - 2022-02-24 19:26:48.557504: step 16900, total loss = 0.57, batch loss = 0.28 (248.3 examples/sec; 0.032 sec/batch; 1h:38m:04s remains)
INFO - root - 2022-02-24 19:26:48.977190: step 16910, total loss = 0.54, batch loss = 0.25 (130.4 examples/sec; 0.061 sec/batch; 3h:06m:40s remains)
INFO - root - 2022-02-24 19:26:49.570303: step 16920, total loss = 0.62, batch loss = 0.32 (200.2 examples/sec; 0.040 sec/batch; 2h:01m:35s remains)
INFO - root - 2022-02-24 19:26:50.043519: step 16930, total loss = 0.63, batch loss = 0.34 (185.6 examples/sec; 0.043 sec/batch; 2h:11m:08s remains)
INFO - root - 2022-02-24 19:26:50.453285: step 16940, total loss = 0.75, batch loss = 0.46 (248.8 examples/sec; 0.032 sec/batch; 1h:37m:51s remains)
INFO - root - 2022-02-24 19:26:50.868577: step 16950, total loss = 0.72, batch loss = 0.43 (142.7 examples/sec; 0.056 sec/batch; 2h:50m:35s remains)
INFO - root - 2022-02-24 19:26:51.303905: step 16960, total loss = 0.57, batch loss = 0.27 (115.5 examples/sec; 0.069 sec/batch; 3h:30m:40s remains)
INFO - root - 2022-02-24 19:26:51.806711: step 16970, total loss = 0.69, batch loss = 0.39 (172.4 examples/sec; 0.046 sec/batch; 2h:21m:10s remains)
INFO - root - 2022-02-24 19:26:52.188167: step 16980, total loss = 0.64, batch loss = 0.35 (253.3 examples/sec; 0.032 sec/batch; 1h:36m:05s remains)
INFO - root - 2022-02-24 19:26:52.666187: step 16990, total loss = 0.62, batch loss = 0.32 (155.1 examples/sec; 0.052 sec/batch; 2h:36m:53s remains)
INFO - root - 2022-02-24 19:26:53.095706: step 17000, total loss = 0.72, batch loss = 0.42 (285.8 examples/sec; 0.028 sec/batch; 1h:25m:09s remains)
INFO - root - 2022-02-24 19:26:53.618229: step 17010, total loss = 0.59, batch loss = 0.29 (184.6 examples/sec; 0.043 sec/batch; 2h:11m:48s remains)
INFO - root - 2022-02-24 19:26:54.151139: step 17020, total loss = 0.59, batch loss = 0.29 (141.6 examples/sec; 0.057 sec/batch; 2h:51m:51s remains)
INFO - root - 2022-02-24 19:26:54.551211: step 17030, total loss = 0.54, batch loss = 0.25 (299.1 examples/sec; 0.027 sec/batch; 1h:21m:19s remains)
INFO - root - 2022-02-24 19:26:54.952072: step 17040, total loss = 0.66, batch loss = 0.37 (164.9 examples/sec; 0.049 sec/batch; 2h:27m:30s remains)
INFO - root - 2022-02-24 19:26:55.367665: step 17050, total loss = 0.64, batch loss = 0.35 (235.5 examples/sec; 0.034 sec/batch; 1h:43m:18s remains)
INFO - root - 2022-02-24 19:26:55.888769: step 17060, total loss = 0.58, batch loss = 0.29 (328.8 examples/sec; 0.024 sec/batch; 1h:13m:59s remains)
INFO - root - 2022-02-24 19:26:56.302385: step 17070, total loss = 0.62, batch loss = 0.32 (173.2 examples/sec; 0.046 sec/batch; 2h:20m:24s remains)
INFO - root - 2022-02-24 19:26:56.712401: step 17080, total loss = 0.55, batch loss = 0.26 (170.0 examples/sec; 0.047 sec/batch; 2h:23m:06s remains)
INFO - root - 2022-02-24 19:26:57.109871: step 17090, total loss = 0.64, batch loss = 0.35 (185.7 examples/sec; 0.043 sec/batch; 2h:10m:58s remains)
INFO - root - 2022-02-24 19:26:57.670710: step 17100, total loss = 0.56, batch loss = 0.26 (108.1 examples/sec; 0.074 sec/batch; 3h:44m:59s remains)
INFO - root - 2022-02-24 19:26:58.219507: step 17110, total loss = 0.61, batch loss = 0.32 (203.8 examples/sec; 0.039 sec/batch; 1h:59m:18s remains)
INFO - root - 2022-02-24 19:26:58.627736: step 17120, total loss = 0.63, batch loss = 0.34 (197.9 examples/sec; 0.040 sec/batch; 2h:02m:52s remains)
INFO - root - 2022-02-24 19:26:58.981549: step 17130, total loss = 0.62, batch loss = 0.33 (359.3 examples/sec; 0.022 sec/batch; 1h:07m:40s remains)
INFO - root - 2022-02-24 19:26:59.358772: step 17140, total loss = 0.55, batch loss = 0.26 (224.0 examples/sec; 0.036 sec/batch; 1h:48m:33s remains)
INFO - root - 2022-02-24 19:26:59.751146: step 17150, total loss = 0.62, batch loss = 0.33 (109.8 examples/sec; 0.073 sec/batch; 3h:41m:23s remains)
INFO - root - 2022-02-24 19:27:00.266913: step 17160, total loss = 0.68, batch loss = 0.39 (241.7 examples/sec; 0.033 sec/batch; 1h:40m:34s remains)
INFO - root - 2022-02-24 19:27:00.739311: step 17170, total loss = 0.56, batch loss = 0.27 (256.5 examples/sec; 0.031 sec/batch; 1h:34m:46s remains)
INFO - root - 2022-02-24 19:27:01.312445: step 17180, total loss = 0.63, batch loss = 0.33 (322.0 examples/sec; 0.025 sec/batch; 1h:15m:29s remains)
INFO - root - 2022-02-24 19:27:01.747292: step 17190, total loss = 0.58, batch loss = 0.29 (208.3 examples/sec; 0.038 sec/batch; 1h:56m:41s remains)
INFO - root - 2022-02-24 19:27:02.322487: step 17200, total loss = 0.67, batch loss = 0.38 (315.1 examples/sec; 0.025 sec/batch; 1h:17m:08s remains)
INFO - root - 2022-02-24 19:27:03.381923: step 17210, total loss = 0.60, batch loss = 0.31 (192.3 examples/sec; 0.042 sec/batch; 2h:06m:22s remains)
INFO - root - 2022-02-24 19:27:03.813541: step 17220, total loss = 0.56, batch loss = 0.26 (190.1 examples/sec; 0.042 sec/batch; 2h:07m:50s remains)
INFO - root - 2022-02-24 19:27:04.274538: step 17230, total loss = 0.61, batch loss = 0.31 (111.6 examples/sec; 0.072 sec/batch; 3h:37m:42s remains)
INFO - root - 2022-02-24 19:27:04.657226: step 17240, total loss = 0.69, batch loss = 0.40 (264.1 examples/sec; 0.030 sec/batch; 1h:32m:01s remains)
INFO - root - 2022-02-24 19:27:05.147493: step 17250, total loss = 0.68, batch loss = 0.39 (190.2 examples/sec; 0.042 sec/batch; 2h:07m:45s remains)
INFO - root - 2022-02-24 19:27:05.643904: step 17260, total loss = 0.61, batch loss = 0.31 (157.3 examples/sec; 0.051 sec/batch; 2h:34m:25s remains)
INFO - root - 2022-02-24 19:27:06.016930: step 17270, total loss = 0.59, batch loss = 0.29 (331.9 examples/sec; 0.024 sec/batch; 1h:13m:12s remains)
INFO - root - 2022-02-24 19:27:06.517402: step 17280, total loss = 0.69, batch loss = 0.40 (215.6 examples/sec; 0.037 sec/batch; 1h:52m:40s remains)
INFO - root - 2022-02-24 19:27:06.938169: step 17290, total loss = 0.62, batch loss = 0.33 (293.7 examples/sec; 0.027 sec/batch; 1h:22m:43s remains)
INFO - root - 2022-02-24 19:27:07.302375: step 17300, total loss = 0.64, batch loss = 0.35 (350.3 examples/sec; 0.023 sec/batch; 1h:09m:21s remains)
INFO - root - 2022-02-24 19:27:08.055042: step 17310, total loss = 0.58, batch loss = 0.28 (135.9 examples/sec; 0.059 sec/batch; 2h:58m:47s remains)
INFO - root - 2022-02-24 19:27:08.492130: step 17320, total loss = 0.61, batch loss = 0.31 (254.7 examples/sec; 0.031 sec/batch; 1h:35m:21s remains)
INFO - root - 2022-02-24 19:27:08.921751: step 17330, total loss = 0.61, batch loss = 0.32 (98.8 examples/sec; 0.081 sec/batch; 4h:05m:48s remains)
INFO - root - 2022-02-24 19:27:09.449181: step 17340, total loss = 0.74, batch loss = 0.45 (135.5 examples/sec; 0.059 sec/batch; 2h:59m:15s remains)
INFO - root - 2022-02-24 19:27:09.905378: step 17350, total loss = 0.53, batch loss = 0.24 (126.8 examples/sec; 0.063 sec/batch; 3h:11m:31s remains)
INFO - root - 2022-02-24 19:27:10.323945: step 17360, total loss = 0.57, batch loss = 0.28 (232.4 examples/sec; 0.034 sec/batch; 1h:44m:29s remains)
INFO - root - 2022-02-24 19:27:10.793523: step 17370, total loss = 0.54, batch loss = 0.25 (277.1 examples/sec; 0.029 sec/batch; 1h:27m:37s remains)
INFO - root - 2022-02-24 19:27:11.235088: step 17380, total loss = 0.72, batch loss = 0.43 (118.9 examples/sec; 0.067 sec/batch; 3h:24m:13s remains)
INFO - root - 2022-02-24 19:27:11.625200: step 17390, total loss = 0.52, batch loss = 0.23 (263.5 examples/sec; 0.030 sec/batch; 1h:32m:08s remains)
INFO - root - 2022-02-24 19:27:12.049146: step 17400, total loss = 0.62, batch loss = 0.33 (251.2 examples/sec; 0.032 sec/batch; 1h:36m:40s remains)
INFO - root - 2022-02-24 19:27:12.673915: step 17410, total loss = 0.67, batch loss = 0.38 (382.2 examples/sec; 0.021 sec/batch; 1h:03m:30s remains)
INFO - root - 2022-02-24 19:27:13.042092: step 17420, total loss = 0.60, batch loss = 0.31 (322.6 examples/sec; 0.025 sec/batch; 1h:15m:14s remains)
INFO - root - 2022-02-24 19:27:13.338539: step 17430, total loss = 0.63, batch loss = 0.34 (273.6 examples/sec; 0.029 sec/batch; 1h:28m:44s remains)
INFO - root - 2022-02-24 19:27:13.678990: step 17440, total loss = 0.60, batch loss = 0.31 (192.8 examples/sec; 0.041 sec/batch; 2h:05m:54s remains)
INFO - root - 2022-02-24 19:27:14.029276: step 17450, total loss = 0.67, batch loss = 0.38 (206.6 examples/sec; 0.039 sec/batch; 1h:57m:29s remains)
INFO - root - 2022-02-24 19:27:14.373699: step 17460, total loss = 0.67, batch loss = 0.38 (237.8 examples/sec; 0.034 sec/batch; 1h:42m:05s remains)
INFO - root - 2022-02-24 19:27:14.847507: step 17470, total loss = 0.48, batch loss = 0.19 (203.0 examples/sec; 0.039 sec/batch; 1h:59m:33s remains)
INFO - root - 2022-02-24 19:27:15.243793: step 17480, total loss = 0.68, batch loss = 0.39 (179.7 examples/sec; 0.045 sec/batch; 2h:15m:03s remains)
INFO - root - 2022-02-24 19:27:15.526021: step 17490, total loss = 0.73, batch loss = 0.43 (325.6 examples/sec; 0.025 sec/batch; 1h:14m:31s remains)
INFO - root - 2022-02-24 19:27:15.864065: step 17500, total loss = 0.76, batch loss = 0.47 (209.1 examples/sec; 0.038 sec/batch; 1h:56m:03s remains)
INFO - root - 2022-02-24 19:27:16.409244: step 17510, total loss = 0.62, batch loss = 0.33 (167.1 examples/sec; 0.048 sec/batch; 2h:25m:13s remains)
INFO - root - 2022-02-24 19:27:16.874952: step 17520, total loss = 0.82, batch loss = 0.53 (340.6 examples/sec; 0.023 sec/batch; 1h:11m:14s remains)
INFO - root - 2022-02-24 19:27:17.291162: step 17530, total loss = 0.56, batch loss = 0.27 (151.3 examples/sec; 0.053 sec/batch; 2h:40m:24s remains)
INFO - root - 2022-02-24 19:27:17.693123: step 17540, total loss = 0.57, batch loss = 0.28 (208.1 examples/sec; 0.038 sec/batch; 1h:56m:34s remains)
INFO - root - 2022-02-24 19:27:18.085171: step 17550, total loss = 0.72, batch loss = 0.43 (270.0 examples/sec; 0.030 sec/batch; 1h:29m:50s remains)
INFO - root - 2022-02-24 19:27:18.631162: step 17560, total loss = 0.56, batch loss = 0.27 (194.6 examples/sec; 0.041 sec/batch; 2h:04m:39s remains)
INFO - root - 2022-02-24 19:27:19.087064: step 17570, total loss = 0.66, batch loss = 0.37 (329.2 examples/sec; 0.024 sec/batch; 1h:13m:41s remains)
INFO - root - 2022-02-24 19:27:19.512764: step 17580, total loss = 0.54, batch loss = 0.25 (183.5 examples/sec; 0.044 sec/batch; 2h:12m:11s remains)
INFO - root - 2022-02-24 19:27:19.960814: step 17590, total loss = 0.72, batch loss = 0.42 (159.8 examples/sec; 0.050 sec/batch; 2h:31m:48s remains)
INFO - root - 2022-02-24 19:27:20.456566: step 17600, total loss = 0.62, batch loss = 0.32 (297.5 examples/sec; 0.027 sec/batch; 1h:21m:31s remains)
INFO - root - 2022-02-24 19:27:21.047023: step 17610, total loss = 0.62, batch loss = 0.33 (103.1 examples/sec; 0.078 sec/batch; 3h:55m:13s remains)
INFO - root - 2022-02-24 19:27:21.583228: step 17620, total loss = 0.63, batch loss = 0.34 (129.5 examples/sec; 0.062 sec/batch; 3h:07m:14s remains)
INFO - root - 2022-02-24 19:27:22.066613: step 17630, total loss = 0.65, batch loss = 0.35 (279.6 examples/sec; 0.029 sec/batch; 1h:26m:43s remains)
INFO - root - 2022-02-24 19:27:23.154064: step 17640, total loss = 0.58, batch loss = 0.28 (104.5 examples/sec; 0.077 sec/batch; 3h:52m:02s remains)
INFO - root - 2022-02-24 19:27:23.618244: step 17650, total loss = 0.56, batch loss = 0.27 (192.7 examples/sec; 0.042 sec/batch; 2h:05m:47s remains)
INFO - root - 2022-02-24 19:27:24.059686: step 17660, total loss = 0.60, batch loss = 0.31 (244.7 examples/sec; 0.033 sec/batch; 1h:39m:05s remains)
INFO - root - 2022-02-24 19:27:24.491828: step 17670, total loss = 0.63, batch loss = 0.34 (198.1 examples/sec; 0.040 sec/batch; 2h:02m:22s remains)
INFO - root - 2022-02-24 19:27:24.846014: step 17680, total loss = 0.69, batch loss = 0.40 (304.0 examples/sec; 0.026 sec/batch; 1h:19m:43s remains)
INFO - root - 2022-02-24 19:27:25.276610: step 17690, total loss = 0.64, batch loss = 0.35 (122.9 examples/sec; 0.065 sec/batch; 3h:17m:14s remains)
INFO - root - 2022-02-24 19:27:25.720655: step 17700, total loss = 0.79, batch loss = 0.49 (130.9 examples/sec; 0.061 sec/batch; 3h:05m:11s remains)
INFO - root - 2022-02-24 19:27:26.275851: step 17710, total loss = 0.57, batch loss = 0.28 (222.8 examples/sec; 0.036 sec/batch; 1h:48m:46s remains)
INFO - root - 2022-02-24 19:27:26.710761: step 17720, total loss = 0.65, batch loss = 0.36 (200.0 examples/sec; 0.040 sec/batch; 2h:01m:12s remains)
INFO - root - 2022-02-24 19:27:27.130876: step 17730, total loss = 0.63, batch loss = 0.34 (276.7 examples/sec; 0.029 sec/batch; 1h:27m:35s remains)
INFO - root - 2022-02-24 19:27:27.535545: step 17740, total loss = 0.56, batch loss = 0.27 (224.6 examples/sec; 0.036 sec/batch; 1h:47m:53s remains)
INFO - root - 2022-02-24 19:27:28.233511: step 17750, total loss = 0.62, batch loss = 0.33 (131.8 examples/sec; 0.061 sec/batch; 3h:03m:54s remains)
INFO - root - 2022-02-24 19:27:28.697754: step 17760, total loss = 0.56, batch loss = 0.27 (239.7 examples/sec; 0.033 sec/batch; 1h:41m:06s remains)
INFO - root - 2022-02-24 19:27:29.043000: step 17770, total loss = 0.55, batch loss = 0.26 (241.6 examples/sec; 0.033 sec/batch; 1h:40m:16s remains)
INFO - root - 2022-02-24 19:27:29.496331: step 17780, total loss = 0.57, batch loss = 0.28 (314.3 examples/sec; 0.025 sec/batch; 1h:17m:04s remains)
INFO - root - 2022-02-24 19:27:29.809470: step 17790, total loss = 0.61, batch loss = 0.32 (264.4 examples/sec; 0.030 sec/batch; 1h:31m:38s remains)
INFO - root - 2022-02-24 19:27:30.238231: step 17800, total loss = 0.62, batch loss = 0.33 (288.2 examples/sec; 0.028 sec/batch; 1h:24m:03s remains)
INFO - root - 2022-02-24 19:27:30.666765: step 17810, total loss = 0.62, batch loss = 0.32 (186.9 examples/sec; 0.043 sec/batch; 2h:09m:37s remains)
INFO - root - 2022-02-24 19:27:31.135607: step 17820, total loss = 0.62, batch loss = 0.33 (196.0 examples/sec; 0.041 sec/batch; 2h:03m:36s remains)
INFO - root - 2022-02-24 19:27:31.521909: step 17830, total loss = 0.61, batch loss = 0.32 (301.4 examples/sec; 0.027 sec/batch; 1h:20m:22s remains)
INFO - root - 2022-02-24 19:27:31.856384: step 17840, total loss = 0.58, batch loss = 0.28 (308.5 examples/sec; 0.026 sec/batch; 1h:18m:30s remains)
INFO - root - 2022-02-24 19:27:32.277188: step 17850, total loss = 0.54, batch loss = 0.25 (106.1 examples/sec; 0.075 sec/batch; 3h:48m:17s remains)
INFO - root - 2022-02-24 19:27:32.672762: step 17860, total loss = 0.67, batch loss = 0.38 (241.6 examples/sec; 0.033 sec/batch; 1h:40m:14s remains)
INFO - root - 2022-02-24 19:27:33.271799: step 17870, total loss = 0.52, batch loss = 0.22 (118.7 examples/sec; 0.067 sec/batch; 3h:23m:56s remains)
INFO - root - 2022-02-24 19:27:33.656713: step 17880, total loss = 0.64, batch loss = 0.35 (167.5 examples/sec; 0.048 sec/batch; 2h:24m:34s remains)
INFO - root - 2022-02-24 19:27:33.982168: step 17890, total loss = 0.70, batch loss = 0.41 (217.5 examples/sec; 0.037 sec/batch; 1h:51m:20s remains)
INFO - root - 2022-02-24 19:27:34.418160: step 17900, total loss = 0.64, batch loss = 0.35 (200.7 examples/sec; 0.040 sec/batch; 2h:00m:38s remains)
INFO - root - 2022-02-24 19:27:34.917134: step 17910, total loss = 0.65, batch loss = 0.36 (175.6 examples/sec; 0.046 sec/batch; 2h:17m:54s remains)
INFO - root - 2022-02-24 19:27:35.414604: step 17920, total loss = 0.57, batch loss = 0.28 (148.5 examples/sec; 0.054 sec/batch; 2h:43m:04s remains)
INFO - root - 2022-02-24 19:27:35.860679: step 17930, total loss = 0.61, batch loss = 0.32 (219.1 examples/sec; 0.037 sec/batch; 1h:50m:28s remains)
INFO - root - 2022-02-24 19:27:36.151672: step 17940, total loss = 0.61, batch loss = 0.31 (138.3 examples/sec; 0.058 sec/batch; 2h:55m:00s remains)
INFO - root - 2022-02-24 19:27:36.565099: step 17950, total loss = 0.62, batch loss = 0.33 (106.9 examples/sec; 0.075 sec/batch; 3h:46m:21s remains)
INFO - root - 2022-02-24 19:27:36.988223: step 17960, total loss = 0.62, batch loss = 0.33 (319.8 examples/sec; 0.025 sec/batch; 1h:15m:41s remains)
INFO - root - 2022-02-24 19:27:37.460987: step 17970, total loss = 0.54, batch loss = 0.24 (155.8 examples/sec; 0.051 sec/batch; 2h:35m:20s remains)
INFO - root - 2022-02-24 19:27:38.003682: step 17980, total loss = 0.62, batch loss = 0.33 (204.3 examples/sec; 0.039 sec/batch; 1h:58m:27s remains)
INFO - root - 2022-02-24 19:27:38.436590: step 17990, total loss = 0.59, batch loss = 0.30 (209.7 examples/sec; 0.038 sec/batch; 1h:55m:25s remains)
INFO - root - 2022-02-24 19:27:38.810497: step 18000, total loss = 0.61, batch loss = 0.32 (273.0 examples/sec; 0.029 sec/batch; 1h:28m:38s remains)
INFO - root - 2022-02-24 19:27:39.300533: step 18010, total loss = 0.62, batch loss = 0.33 (315.5 examples/sec; 0.025 sec/batch; 1h:16m:41s remains)
INFO - root - 2022-02-24 19:27:39.820047: step 18020, total loss = 0.59, batch loss = 0.30 (345.1 examples/sec; 0.023 sec/batch; 1h:10m:06s remains)
INFO - root - 2022-02-24 19:27:40.358538: step 18030, total loss = 0.54, batch loss = 0.25 (53.8 examples/sec; 0.149 sec/batch; 7h:29m:54s remains)
INFO - root - 2022-02-24 19:27:40.817293: step 18040, total loss = 0.61, batch loss = 0.31 (145.3 examples/sec; 0.055 sec/batch; 2h:46m:28s remains)
INFO - root - 2022-02-24 19:27:41.488790: step 18050, total loss = 0.60, batch loss = 0.31 (305.4 examples/sec; 0.026 sec/batch; 1h:19m:12s remains)
INFO - root - 2022-02-24 19:27:42.060223: step 18060, total loss = 0.58, batch loss = 0.29 (216.9 examples/sec; 0.037 sec/batch; 1h:51m:31s remains)
INFO - root - 2022-02-24 19:27:42.703640: step 18070, total loss = 0.57, batch loss = 0.28 (204.1 examples/sec; 0.039 sec/batch; 1h:58m:30s remains)
INFO - root - 2022-02-24 19:27:43.744000: step 18080, total loss = 0.58, batch loss = 0.29 (252.8 examples/sec; 0.032 sec/batch; 1h:35m:40s remains)
INFO - root - 2022-02-24 19:27:44.198026: step 18090, total loss = 0.66, batch loss = 0.36 (308.6 examples/sec; 0.026 sec/batch; 1h:18m:22s remains)
INFO - root - 2022-02-24 19:27:44.650737: step 18100, total loss = 0.50, batch loss = 0.21 (187.0 examples/sec; 0.043 sec/batch; 2h:09m:20s remains)
INFO - root - 2022-02-24 19:27:45.109405: step 18110, total loss = 0.68, batch loss = 0.39 (272.2 examples/sec; 0.029 sec/batch; 1h:28m:51s remains)
INFO - root - 2022-02-24 19:27:45.524442: step 18120, total loss = 0.61, batch loss = 0.32 (237.3 examples/sec; 0.034 sec/batch; 1h:41m:53s remains)
INFO - root - 2022-02-24 19:27:45.892549: step 18130, total loss = 0.56, batch loss = 0.27 (355.0 examples/sec; 0.023 sec/batch; 1h:08m:07s remains)
INFO - root - 2022-02-24 19:27:46.359617: step 18140, total loss = 0.55, batch loss = 0.25 (271.1 examples/sec; 0.030 sec/batch; 1h:29m:12s remains)
INFO - root - 2022-02-24 19:27:46.986356: step 18150, total loss = 0.60, batch loss = 0.30 (205.7 examples/sec; 0.039 sec/batch; 1h:57m:33s remains)
INFO - root - 2022-02-24 19:27:47.361462: step 18160, total loss = 0.51, batch loss = 0.22 (148.6 examples/sec; 0.054 sec/batch; 2h:42m:39s remains)
INFO - root - 2022-02-24 19:27:47.742080: step 18170, total loss = 0.64, batch loss = 0.34 (197.3 examples/sec; 0.041 sec/batch; 2h:02m:31s remains)
INFO - root - 2022-02-24 19:27:48.236060: step 18180, total loss = 0.71, batch loss = 0.41 (104.4 examples/sec; 0.077 sec/batch; 3h:51m:35s remains)
INFO - root - 2022-02-24 19:27:48.734693: step 18190, total loss = 0.52, batch loss = 0.23 (101.0 examples/sec; 0.079 sec/batch; 3h:59m:19s remains)
INFO - root - 2022-02-24 19:27:49.186827: step 18200, total loss = 0.71, batch loss = 0.42 (173.5 examples/sec; 0.046 sec/batch; 2h:19m:20s remains)
INFO - root - 2022-02-24 19:27:49.686822: step 18210, total loss = 0.66, batch loss = 0.37 (225.4 examples/sec; 0.035 sec/batch; 1h:47m:13s remains)
INFO - root - 2022-02-24 19:27:50.030674: step 18220, total loss = 0.61, batch loss = 0.31 (264.3 examples/sec; 0.030 sec/batch; 1h:31m:26s remains)
INFO - root - 2022-02-24 19:27:50.558153: step 18230, total loss = 0.60, batch loss = 0.31 (125.2 examples/sec; 0.064 sec/batch; 3h:13m:00s remains)
INFO - root - 2022-02-24 19:27:51.040362: step 18240, total loss = 0.65, batch loss = 0.36 (117.6 examples/sec; 0.068 sec/batch; 3h:25m:31s remains)
INFO - root - 2022-02-24 19:27:51.394529: step 18250, total loss = 0.51, batch loss = 0.22 (146.6 examples/sec; 0.055 sec/batch; 2h:44m:48s remains)
INFO - root - 2022-02-24 19:27:51.738126: step 18260, total loss = 0.64, batch loss = 0.35 (139.7 examples/sec; 0.057 sec/batch; 2h:52m:58s remains)
INFO - root - 2022-02-24 19:27:52.149953: step 18270, total loss = 0.56, batch loss = 0.27 (300.4 examples/sec; 0.027 sec/batch; 1h:20m:25s remains)
INFO - root - 2022-02-24 19:27:52.686216: step 18280, total loss = 0.70, batch loss = 0.41 (108.9 examples/sec; 0.073 sec/batch; 3h:41m:47s remains)
INFO - root - 2022-02-24 19:27:53.132679: step 18290, total loss = 0.61, batch loss = 0.32 (352.9 examples/sec; 0.023 sec/batch; 1h:08m:27s remains)
INFO - root - 2022-02-24 19:27:53.597541: step 18300, total loss = 0.68, batch loss = 0.39 (135.1 examples/sec; 0.059 sec/batch; 2h:58m:48s remains)
INFO - root - 2022-02-24 19:27:54.166020: step 18310, total loss = 0.70, batch loss = 0.41 (210.3 examples/sec; 0.038 sec/batch; 1h:54m:51s remains)
INFO - root - 2022-02-24 19:27:54.603407: step 18320, total loss = 0.62, batch loss = 0.33 (192.1 examples/sec; 0.042 sec/batch; 2h:05m:45s remains)
INFO - root - 2022-02-24 19:27:54.964196: step 18330, total loss = 0.55, batch loss = 0.26 (155.4 examples/sec; 0.051 sec/batch; 2h:35m:28s remains)
INFO - root - 2022-02-24 19:27:55.498980: step 18340, total loss = 0.65, batch loss = 0.36 (325.7 examples/sec; 0.025 sec/batch; 1h:14m:09s remains)
INFO - root - 2022-02-24 19:27:55.895710: step 18350, total loss = 0.69, batch loss = 0.39 (321.7 examples/sec; 0.025 sec/batch; 1h:15m:04s remains)
INFO - root - 2022-02-24 19:27:56.283289: step 18360, total loss = 0.77, batch loss = 0.48 (348.8 examples/sec; 0.023 sec/batch; 1h:09m:13s remains)
INFO - root - 2022-02-24 19:27:56.600017: step 18370, total loss = 0.59, batch loss = 0.29 (210.5 examples/sec; 0.038 sec/batch; 1h:54m:43s remains)
INFO - root - 2022-02-24 19:27:57.064681: step 18380, total loss = 0.53, batch loss = 0.24 (84.6 examples/sec; 0.095 sec/batch; 4h:45m:19s remains)
INFO - root - 2022-02-24 19:27:57.575280: step 18390, total loss = 0.58, batch loss = 0.28 (265.9 examples/sec; 0.030 sec/batch; 1h:30m:49s remains)
INFO - root - 2022-02-24 19:27:57.933565: step 18400, total loss = 0.64, batch loss = 0.35 (308.3 examples/sec; 0.026 sec/batch; 1h:18m:19s remains)
INFO - root - 2022-02-24 19:27:58.518252: step 18410, total loss = 0.57, batch loss = 0.28 (108.1 examples/sec; 0.074 sec/batch; 3h:43m:21s remains)
INFO - root - 2022-02-24 19:27:58.930079: step 18420, total loss = 0.57, batch loss = 0.28 (207.6 examples/sec; 0.039 sec/batch; 1h:56m:18s remains)
INFO - root - 2022-02-24 19:27:59.461377: step 18430, total loss = 0.61, batch loss = 0.32 (364.3 examples/sec; 0.022 sec/batch; 1h:06m:16s remains)
INFO - root - 2022-02-24 19:27:59.926785: step 18440, total loss = 0.65, batch loss = 0.36 (130.4 examples/sec; 0.061 sec/batch; 3h:05m:06s remains)
INFO - root - 2022-02-24 19:28:00.356610: step 18450, total loss = 0.57, batch loss = 0.28 (177.7 examples/sec; 0.045 sec/batch; 2h:15m:52s remains)
INFO - root - 2022-02-24 19:28:00.939971: step 18460, total loss = 0.59, batch loss = 0.30 (95.4 examples/sec; 0.084 sec/batch; 4h:12m:58s remains)
INFO - root - 2022-02-24 19:28:01.412096: step 18470, total loss = 0.67, batch loss = 0.38 (132.0 examples/sec; 0.061 sec/batch; 3h:02m:53s remains)
INFO - root - 2022-02-24 19:28:01.960360: step 18480, total loss = 0.69, batch loss = 0.40 (321.7 examples/sec; 0.025 sec/batch; 1h:15m:01s remains)
INFO - root - 2022-02-24 19:28:02.405140: step 18490, total loss = 0.63, batch loss = 0.34 (115.4 examples/sec; 0.069 sec/batch; 3h:29m:10s remains)
INFO - root - 2022-02-24 19:28:02.836948: step 18500, total loss = 0.67, batch loss = 0.38 (332.6 examples/sec; 0.024 sec/batch; 1h:12m:33s remains)
INFO - root - 2022-02-24 19:28:03.844176: step 18510, total loss = 0.56, batch loss = 0.27 (107.1 examples/sec; 0.075 sec/batch; 3h:45m:14s remains)
INFO - root - 2022-02-24 19:28:04.379209: step 18520, total loss = 0.63, batch loss = 0.34 (99.4 examples/sec; 0.081 sec/batch; 4h:02m:48s remains)
INFO - root - 2022-02-24 19:28:04.905741: step 18530, total loss = 0.50, batch loss = 0.21 (98.9 examples/sec; 0.081 sec/batch; 4h:03m:59s remains)
INFO - root - 2022-02-24 19:28:05.303170: step 18540, total loss = 0.63, batch loss = 0.34 (164.0 examples/sec; 0.049 sec/batch; 2h:27m:05s remains)
INFO - root - 2022-02-24 19:28:05.748452: step 18550, total loss = 0.52, batch loss = 0.23 (121.6 examples/sec; 0.066 sec/batch; 3h:18m:21s remains)
INFO - root - 2022-02-24 19:28:06.269385: step 18560, total loss = 0.59, batch loss = 0.30 (206.1 examples/sec; 0.039 sec/batch; 1h:57m:02s remains)
INFO - root - 2022-02-24 19:28:06.738300: step 18570, total loss = 0.60, batch loss = 0.31 (149.7 examples/sec; 0.053 sec/batch; 2h:41m:05s remains)
INFO - root - 2022-02-24 19:28:07.187374: step 18580, total loss = 0.68, batch loss = 0.39 (291.3 examples/sec; 0.027 sec/batch; 1h:22m:49s remains)
INFO - root - 2022-02-24 19:28:07.592926: step 18590, total loss = 0.51, batch loss = 0.22 (181.8 examples/sec; 0.044 sec/batch; 2h:12m:39s remains)
INFO - root - 2022-02-24 19:28:08.087206: step 18600, total loss = 0.59, batch loss = 0.30 (100.3 examples/sec; 0.080 sec/batch; 4h:00m:30s remains)
INFO - root - 2022-02-24 19:28:08.587683: step 18610, total loss = 0.65, batch loss = 0.35 (249.5 examples/sec; 0.032 sec/batch; 1h:36m:39s remains)
INFO - root - 2022-02-24 19:28:09.066329: step 18620, total loss = 0.68, batch loss = 0.39 (163.4 examples/sec; 0.049 sec/batch; 2h:27m:36s remains)
INFO - root - 2022-02-24 19:28:09.552894: step 18630, total loss = 0.58, batch loss = 0.29 (344.6 examples/sec; 0.023 sec/batch; 1h:09m:59s remains)
INFO - root - 2022-02-24 19:28:09.895134: step 18640, total loss = 0.55, batch loss = 0.26 (351.6 examples/sec; 0.023 sec/batch; 1h:08m:34s remains)
INFO - root - 2022-02-24 19:28:10.296802: step 18650, total loss = 0.66, batch loss = 0.37 (148.4 examples/sec; 0.054 sec/batch; 2h:42m:29s remains)
INFO - root - 2022-02-24 19:28:10.755826: step 18660, total loss = 0.63, batch loss = 0.34 (90.3 examples/sec; 0.089 sec/batch; 4h:27m:01s remains)
INFO - root - 2022-02-24 19:28:11.220740: step 18670, total loss = 0.63, batch loss = 0.34 (137.0 examples/sec; 0.058 sec/batch; 2h:56m:01s remains)
INFO - root - 2022-02-24 19:28:11.556893: step 18680, total loss = 0.67, batch loss = 0.37 (300.9 examples/sec; 0.027 sec/batch; 1h:20m:07s remains)
INFO - root - 2022-02-24 19:28:11.903408: step 18690, total loss = 0.56, batch loss = 0.27 (260.9 examples/sec; 0.031 sec/batch; 1h:32m:23s remains)
INFO - root - 2022-02-24 19:28:12.257617: step 18700, total loss = 0.57, batch loss = 0.28 (200.1 examples/sec; 0.040 sec/batch; 2h:00m:29s remains)
INFO - root - 2022-02-24 19:28:12.769915: step 18710, total loss = 0.69, batch loss = 0.40 (156.9 examples/sec; 0.051 sec/batch; 2h:33m:36s remains)
INFO - root - 2022-02-24 19:28:13.161297: step 18720, total loss = 0.55, batch loss = 0.26 (351.1 examples/sec; 0.023 sec/batch; 1h:08m:39s remains)
INFO - root - 2022-02-24 19:28:13.490053: step 18730, total loss = 0.57, batch loss = 0.28 (322.8 examples/sec; 0.025 sec/batch; 1h:14m:39s remains)
INFO - root - 2022-02-24 19:28:13.879348: step 18740, total loss = 0.74, batch loss = 0.45 (111.3 examples/sec; 0.072 sec/batch; 3h:36m:26s remains)
INFO - root - 2022-02-24 19:28:14.254457: step 18750, total loss = 0.57, batch loss = 0.28 (171.1 examples/sec; 0.047 sec/batch; 2h:20m:48s remains)
INFO - root - 2022-02-24 19:28:14.658314: step 18760, total loss = 0.70, batch loss = 0.41 (238.3 examples/sec; 0.034 sec/batch; 1h:41m:06s remains)
INFO - root - 2022-02-24 19:28:15.080213: step 18770, total loss = 0.59, batch loss = 0.29 (145.2 examples/sec; 0.055 sec/batch; 2h:45m:56s remains)
INFO - root - 2022-02-24 19:28:15.559425: step 18780, total loss = 0.59, batch loss = 0.29 (317.2 examples/sec; 0.025 sec/batch; 1h:15m:58s remains)
INFO - root - 2022-02-24 19:28:15.980261: step 18790, total loss = 0.58, batch loss = 0.29 (315.4 examples/sec; 0.025 sec/batch; 1h:16m:23s remains)
INFO - root - 2022-02-24 19:28:16.332472: step 18800, total loss = 0.58, batch loss = 0.28 (330.4 examples/sec; 0.024 sec/batch; 1h:12m:54s remains)
INFO - root - 2022-02-24 19:28:16.770981: step 18810, total loss = 0.59, batch loss = 0.30 (160.5 examples/sec; 0.050 sec/batch; 2h:30m:03s remains)
INFO - root - 2022-02-24 19:28:17.202295: step 18820, total loss = 0.79, batch loss = 0.50 (322.3 examples/sec; 0.025 sec/batch; 1h:14m:45s remains)
INFO - root - 2022-02-24 19:28:17.747905: step 18830, total loss = 0.68, batch loss = 0.38 (213.7 examples/sec; 0.037 sec/batch; 1h:52m:42s remains)
INFO - root - 2022-02-24 19:28:18.101636: step 18840, total loss = 0.59, batch loss = 0.30 (253.7 examples/sec; 0.032 sec/batch; 1h:34m:57s remains)
INFO - root - 2022-02-24 19:28:18.507793: step 18850, total loss = 0.54, batch loss = 0.25 (133.8 examples/sec; 0.060 sec/batch; 2h:59m:58s remains)
INFO - root - 2022-02-24 19:28:18.915625: step 18860, total loss = 0.57, batch loss = 0.28 (180.5 examples/sec; 0.044 sec/batch; 2h:13m:26s remains)
INFO - root - 2022-02-24 19:28:19.396946: step 18870, total loss = 0.71, batch loss = 0.42 (284.3 examples/sec; 0.028 sec/batch; 1h:24m:43s remains)
INFO - root - 2022-02-24 19:28:19.929882: step 18880, total loss = 0.63, batch loss = 0.34 (335.7 examples/sec; 0.024 sec/batch; 1h:11m:43s remains)
INFO - root - 2022-02-24 19:28:20.269154: step 18890, total loss = 0.54, batch loss = 0.25 (266.3 examples/sec; 0.030 sec/batch; 1h:30m:25s remains)
INFO - root - 2022-02-24 19:28:20.649186: step 18900, total loss = 0.67, batch loss = 0.37 (305.0 examples/sec; 0.026 sec/batch; 1h:18m:57s remains)
INFO - root - 2022-02-24 19:28:21.130769: step 18910, total loss = 0.55, batch loss = 0.26 (314.8 examples/sec; 0.025 sec/batch; 1h:16m:28s remains)
INFO - root - 2022-02-24 19:28:21.620437: step 18920, total loss = 0.74, batch loss = 0.45 (145.7 examples/sec; 0.055 sec/batch; 2h:45m:12s remains)
INFO - root - 2022-02-24 19:28:22.014512: step 18930, total loss = 0.61, batch loss = 0.32 (307.5 examples/sec; 0.026 sec/batch; 1h:18m:17s remains)
INFO - root - 2022-02-24 19:28:22.419555: step 18940, total loss = 0.55, batch loss = 0.26 (174.9 examples/sec; 0.046 sec/batch; 2h:17m:37s remains)
INFO - root - 2022-02-24 19:28:22.796719: step 18950, total loss = 0.62, batch loss = 0.33 (372.5 examples/sec; 0.021 sec/batch; 1h:04m:37s remains)
INFO - root - 2022-02-24 19:28:23.272018: step 18960, total loss = 0.71, batch loss = 0.42 (86.8 examples/sec; 0.092 sec/batch; 4h:37m:27s remains)
INFO - root - 2022-02-24 19:28:23.831774: step 18970, total loss = 0.64, batch loss = 0.35 (215.1 examples/sec; 0.037 sec/batch; 1h:51m:54s remains)
INFO - root - 2022-02-24 19:28:24.736712: step 18980, total loss = 0.56, batch loss = 0.26 (304.8 examples/sec; 0.026 sec/batch; 1h:18m:58s remains)
INFO - root - 2022-02-24 19:28:25.146852: step 18990, total loss = 0.58, batch loss = 0.28 (283.1 examples/sec; 0.028 sec/batch; 1h:25m:01s remains)
INFO - root - 2022-02-24 19:28:25.672969: step 19000, total loss = 0.71, batch loss = 0.42 (142.8 examples/sec; 0.056 sec/batch; 2h:48m:30s remains)
INFO - root - 2022-02-24 19:28:26.151413: step 19010, total loss = 0.59, batch loss = 0.30 (334.1 examples/sec; 0.024 sec/batch; 1h:12m:01s remains)
INFO - root - 2022-02-24 19:28:26.565908: step 19020, total loss = 0.62, batch loss = 0.32 (245.2 examples/sec; 0.033 sec/batch; 1h:38m:09s remains)
INFO - root - 2022-02-24 19:28:27.096899: step 19030, total loss = 0.52, batch loss = 0.23 (263.4 examples/sec; 0.030 sec/batch; 1h:31m:22s remains)
INFO - root - 2022-02-24 19:28:27.606538: step 19040, total loss = 0.59, batch loss = 0.30 (88.7 examples/sec; 0.090 sec/batch; 4h:31m:24s remains)
INFO - root - 2022-02-24 19:28:28.010091: step 19050, total loss = 0.56, batch loss = 0.27 (303.2 examples/sec; 0.026 sec/batch; 1h:19m:20s remains)
INFO - root - 2022-02-24 19:28:28.412287: step 19060, total loss = 0.68, batch loss = 0.38 (168.4 examples/sec; 0.048 sec/batch; 2h:22m:52s remains)
INFO - root - 2022-02-24 19:28:28.862980: step 19070, total loss = 0.55, batch loss = 0.26 (171.6 examples/sec; 0.047 sec/batch; 2h:20m:12s remains)
INFO - root - 2022-02-24 19:28:29.741852: step 19080, total loss = 0.56, batch loss = 0.27 (186.8 examples/sec; 0.043 sec/batch; 2h:08m:48s remains)
INFO - root - 2022-02-24 19:28:30.084541: step 19090, total loss = 0.58, batch loss = 0.29 (170.0 examples/sec; 0.047 sec/batch; 2h:21m:29s remains)
INFO - root - 2022-02-24 19:28:30.462974: step 19100, total loss = 0.64, batch loss = 0.35 (339.5 examples/sec; 0.024 sec/batch; 1h:10m:50s remains)
INFO - root - 2022-02-24 19:28:30.852455: step 19110, total loss = 0.65, batch loss = 0.36 (331.4 examples/sec; 0.024 sec/batch; 1h:12m:34s remains)
INFO - root - 2022-02-24 19:28:31.475602: step 19120, total loss = 0.61, batch loss = 0.32 (209.2 examples/sec; 0.038 sec/batch; 1h:54m:56s remains)
INFO - root - 2022-02-24 19:28:32.196523: step 19130, total loss = 0.62, batch loss = 0.33 (178.2 examples/sec; 0.045 sec/batch; 2h:14m:58s remains)
INFO - root - 2022-02-24 19:28:32.830286: step 19140, total loss = 0.67, batch loss = 0.38 (155.1 examples/sec; 0.052 sec/batch; 2h:35m:05s remains)
INFO - root - 2022-02-24 19:28:33.491459: step 19150, total loss = 0.68, batch loss = 0.39 (336.9 examples/sec; 0.024 sec/batch; 1h:11m:22s remains)
INFO - root - 2022-02-24 19:28:34.067844: step 19160, total loss = 0.51, batch loss = 0.22 (43.9 examples/sec; 0.182 sec/batch; 9h:07m:20s remains)
INFO - root - 2022-02-24 19:28:34.779562: step 19170, total loss = 0.66, batch loss = 0.36 (100.8 examples/sec; 0.079 sec/batch; 3h:58m:31s remains)
INFO - root - 2022-02-24 19:28:35.445310: step 19180, total loss = 0.62, batch loss = 0.33 (98.6 examples/sec; 0.081 sec/batch; 4h:03m:50s remains)
INFO - root - 2022-02-24 19:28:35.979981: step 19190, total loss = 0.59, batch loss = 0.30 (103.6 examples/sec; 0.077 sec/batch; 3h:51m:59s remains)
INFO - root - 2022-02-24 19:28:36.506956: step 19200, total loss = 0.56, batch loss = 0.27 (81.0 examples/sec; 0.099 sec/batch; 4h:56m:41s remains)
INFO - root - 2022-02-24 19:28:37.188778: step 19210, total loss = 0.59, batch loss = 0.30 (111.8 examples/sec; 0.072 sec/batch; 3h:35m:06s remains)
INFO - root - 2022-02-24 19:28:37.776744: step 19220, total loss = 0.61, batch loss = 0.32 (318.3 examples/sec; 0.025 sec/batch; 1h:15m:30s remains)
INFO - root - 2022-02-24 19:28:38.363311: step 19230, total loss = 0.56, batch loss = 0.27 (309.7 examples/sec; 0.026 sec/batch; 1h:17m:36s remains)
INFO - root - 2022-02-24 19:28:39.146052: step 19240, total loss = 0.63, batch loss = 0.34 (53.0 examples/sec; 0.151 sec/batch; 7h:33m:36s remains)
INFO - root - 2022-02-24 19:28:39.569444: step 19250, total loss = 0.64, batch loss = 0.35 (199.1 examples/sec; 0.040 sec/batch; 2h:00m:43s remains)
INFO - root - 2022-02-24 19:28:40.205456: step 19260, total loss = 0.78, batch loss = 0.49 (124.2 examples/sec; 0.064 sec/batch; 3h:13m:26s remains)
INFO - root - 2022-02-24 19:28:40.669257: step 19270, total loss = 0.62, batch loss = 0.33 (237.8 examples/sec; 0.034 sec/batch; 1h:41m:03s remains)
INFO - root - 2022-02-24 19:28:41.318396: step 19280, total loss = 0.63, batch loss = 0.34 (126.2 examples/sec; 0.063 sec/batch; 3h:10m:22s remains)
INFO - root - 2022-02-24 19:28:41.935104: step 19290, total loss = 0.68, batch loss = 0.38 (217.4 examples/sec; 0.037 sec/batch; 1h:50m:32s remains)
INFO - root - 2022-02-24 19:28:42.515468: step 19300, total loss = 0.72, batch loss = 0.43 (319.4 examples/sec; 0.025 sec/batch; 1h:15m:14s remains)
INFO - root - 2022-02-24 19:28:43.206379: step 19310, total loss = 0.59, batch loss = 0.30 (83.2 examples/sec; 0.096 sec/batch; 4h:48m:44s remains)
INFO - root - 2022-02-24 19:28:43.670270: step 19320, total loss = 0.71, batch loss = 0.41 (240.4 examples/sec; 0.033 sec/batch; 1h:39m:55s remains)
INFO - root - 2022-02-24 19:28:44.052890: step 19330, total loss = 0.53, batch loss = 0.24 (289.3 examples/sec; 0.028 sec/batch; 1h:23m:02s remains)
INFO - root - 2022-02-24 19:28:44.482801: step 19340, total loss = 0.72, batch loss = 0.42 (326.7 examples/sec; 0.024 sec/batch; 1h:13m:31s remains)
INFO - root - 2022-02-24 19:28:44.856272: step 19350, total loss = 0.69, batch loss = 0.40 (120.3 examples/sec; 0.067 sec/batch; 3h:19m:40s remains)
INFO - root - 2022-02-24 19:28:45.305994: step 19360, total loss = 0.58, batch loss = 0.29 (184.1 examples/sec; 0.043 sec/batch; 2h:10m:26s remains)
INFO - root - 2022-02-24 19:28:45.774553: step 19370, total loss = 0.59, batch loss = 0.30 (193.1 examples/sec; 0.041 sec/batch; 2h:04m:20s remains)
INFO - root - 2022-02-24 19:28:46.161481: step 19380, total loss = 0.61, batch loss = 0.32 (281.5 examples/sec; 0.028 sec/batch; 1h:25m:18s remains)
INFO - root - 2022-02-24 19:28:46.588673: step 19390, total loss = 0.71, batch loss = 0.42 (272.3 examples/sec; 0.029 sec/batch; 1h:28m:11s remains)
INFO - root - 2022-02-24 19:28:46.999521: step 19400, total loss = 0.58, batch loss = 0.29 (181.9 examples/sec; 0.044 sec/batch; 2h:12m:00s remains)
INFO - root - 2022-02-24 19:28:47.562572: step 19410, total loss = 0.63, batch loss = 0.34 (124.8 examples/sec; 0.064 sec/batch; 3h:12m:21s remains)
INFO - root - 2022-02-24 19:28:48.016344: step 19420, total loss = 0.64, batch loss = 0.35 (236.0 examples/sec; 0.034 sec/batch; 1h:41m:45s remains)
INFO - root - 2022-02-24 19:28:48.363796: step 19430, total loss = 0.54, batch loss = 0.25 (351.3 examples/sec; 0.023 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 19:28:48.762367: step 19440, total loss = 0.55, batch loss = 0.26 (238.2 examples/sec; 0.034 sec/batch; 1h:40m:46s remains)
INFO - root - 2022-02-24 19:28:49.167373: step 19450, total loss = 0.66, batch loss = 0.37 (226.0 examples/sec; 0.035 sec/batch; 1h:46m:14s remains)
INFO - root - 2022-02-24 19:28:49.694528: step 19460, total loss = 0.59, batch loss = 0.30 (195.1 examples/sec; 0.041 sec/batch; 2h:03m:01s remains)
INFO - root - 2022-02-24 19:28:50.164256: step 19470, total loss = 0.62, batch loss = 0.33 (228.4 examples/sec; 0.035 sec/batch; 1h:45m:04s remains)
INFO - root - 2022-02-24 19:28:50.635367: step 19480, total loss = 0.64, batch loss = 0.35 (206.8 examples/sec; 0.039 sec/batch; 1h:56m:03s remains)
INFO - root - 2022-02-24 19:28:51.042669: step 19490, total loss = 0.58, batch loss = 0.29 (167.0 examples/sec; 0.048 sec/batch; 2h:23m:43s remains)
INFO - root - 2022-02-24 19:28:51.405494: step 19500, total loss = 0.61, batch loss = 0.32 (188.4 examples/sec; 0.042 sec/batch; 2h:07m:23s remains)
INFO - root - 2022-02-24 19:28:51.840076: step 19510, total loss = 0.63, batch loss = 0.34 (213.2 examples/sec; 0.038 sec/batch; 1h:52m:32s remains)
INFO - root - 2022-02-24 19:28:52.228996: step 19520, total loss = 0.72, batch loss = 0.43 (215.3 examples/sec; 0.037 sec/batch; 1h:51m:26s remains)
INFO - root - 2022-02-24 19:28:52.725799: step 19530, total loss = 0.73, batch loss = 0.44 (185.6 examples/sec; 0.043 sec/batch; 2h:09m:15s remains)
INFO - root - 2022-02-24 19:28:53.064062: step 19540, total loss = 0.57, batch loss = 0.28 (255.3 examples/sec; 0.031 sec/batch; 1h:33m:58s remains)
INFO - root - 2022-02-24 19:28:53.565391: step 19550, total loss = 0.56, batch loss = 0.27 (137.7 examples/sec; 0.058 sec/batch; 2h:54m:14s remains)
INFO - root - 2022-02-24 19:28:54.008160: step 19560, total loss = 0.61, batch loss = 0.32 (141.5 examples/sec; 0.057 sec/batch; 2h:49m:32s remains)
INFO - root - 2022-02-24 19:28:54.567027: step 19570, total loss = 0.66, batch loss = 0.37 (321.9 examples/sec; 0.025 sec/batch; 1h:14m:32s remains)
INFO - root - 2022-02-24 19:28:54.941531: step 19580, total loss = 0.56, batch loss = 0.27 (290.2 examples/sec; 0.028 sec/batch; 1h:22m:39s remains)
INFO - root - 2022-02-24 19:28:55.300824: step 19590, total loss = 0.70, batch loss = 0.40 (164.4 examples/sec; 0.049 sec/batch; 2h:25m:54s remains)
INFO - root - 2022-02-24 19:28:55.663881: step 19600, total loss = 0.63, batch loss = 0.34 (180.1 examples/sec; 0.044 sec/batch; 2h:13m:09s remains)
INFO - root - 2022-02-24 19:28:56.187283: step 19610, total loss = 0.61, batch loss = 0.32 (244.1 examples/sec; 0.033 sec/batch; 1h:38m:16s remains)
INFO - root - 2022-02-24 19:28:56.591305: step 19620, total loss = 0.64, batch loss = 0.35 (163.1 examples/sec; 0.049 sec/batch; 2h:27m:00s remains)
INFO - root - 2022-02-24 19:28:57.106922: step 19630, total loss = 0.59, batch loss = 0.30 (339.0 examples/sec; 0.024 sec/batch; 1h:10m:44s remains)
INFO - root - 2022-02-24 19:28:57.509226: step 19640, total loss = 0.61, batch loss = 0.31 (187.5 examples/sec; 0.043 sec/batch; 2h:07m:55s remains)
INFO - root - 2022-02-24 19:28:57.867001: step 19650, total loss = 0.62, batch loss = 0.33 (366.7 examples/sec; 0.022 sec/batch; 1h:05m:23s remains)
INFO - root - 2022-02-24 19:28:58.262489: step 19660, total loss = 0.60, batch loss = 0.31 (162.0 examples/sec; 0.049 sec/batch; 2h:27m:58s remains)
INFO - root - 2022-02-24 19:28:58.754151: step 19670, total loss = 0.52, batch loss = 0.22 (101.7 examples/sec; 0.079 sec/batch; 3h:55m:41s remains)
INFO - root - 2022-02-24 19:28:59.186516: step 19680, total loss = 0.66, batch loss = 0.37 (241.2 examples/sec; 0.033 sec/batch; 1h:39m:24s remains)
INFO - root - 2022-02-24 19:28:59.747773: step 19690, total loss = 0.60, batch loss = 0.31 (220.3 examples/sec; 0.036 sec/batch; 1h:48m:48s remains)
INFO - root - 2022-02-24 19:29:00.136127: step 19700, total loss = 0.61, batch loss = 0.32 (121.6 examples/sec; 0.066 sec/batch; 3h:17m:07s remains)
INFO - root - 2022-02-24 19:29:00.617339: step 19710, total loss = 0.60, batch loss = 0.30 (352.4 examples/sec; 0.023 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 19:29:01.079477: step 19720, total loss = 0.55, batch loss = 0.26 (321.8 examples/sec; 0.025 sec/batch; 1h:14m:29s remains)
INFO - root - 2022-02-24 19:29:01.540628: step 19730, total loss = 0.70, batch loss = 0.41 (207.4 examples/sec; 0.039 sec/batch; 1h:55m:33s remains)
INFO - root - 2022-02-24 19:29:01.957258: step 19740, total loss = 0.52, batch loss = 0.23 (165.5 examples/sec; 0.048 sec/batch; 2h:24m:51s remains)
INFO - root - 2022-02-24 19:29:02.332105: step 19750, total loss = 0.48, batch loss = 0.19 (246.3 examples/sec; 0.032 sec/batch; 1h:37m:18s remains)
INFO - root - 2022-02-24 19:29:02.822149: step 19760, total loss = 0.60, batch loss = 0.31 (126.7 examples/sec; 0.063 sec/batch; 3h:09m:11s remains)
INFO - root - 2022-02-24 19:29:03.463306: step 19770, total loss = 0.61, batch loss = 0.32 (181.5 examples/sec; 0.044 sec/batch; 2h:11m:59s remains)
INFO - root - 2022-02-24 19:29:04.009711: step 19780, total loss = 0.61, batch loss = 0.32 (279.7 examples/sec; 0.029 sec/batch; 1h:25m:39s remains)
INFO - root - 2022-02-24 19:29:04.979469: step 19790, total loss = 0.73, batch loss = 0.44 (186.9 examples/sec; 0.043 sec/batch; 2h:08m:11s remains)
INFO - root - 2022-02-24 19:29:05.426268: step 19800, total loss = 0.61, batch loss = 0.32 (292.3 examples/sec; 0.027 sec/batch; 1h:21m:58s remains)
INFO - root - 2022-02-24 19:29:06.047785: step 19810, total loss = 0.67, batch loss = 0.38 (190.8 examples/sec; 0.042 sec/batch; 2h:05m:33s remains)
INFO - root - 2022-02-24 19:29:06.558673: step 19820, total loss = 0.52, batch loss = 0.22 (294.8 examples/sec; 0.027 sec/batch; 1h:21m:15s remains)
INFO - root - 2022-02-24 19:29:07.086926: step 19830, total loss = 0.64, batch loss = 0.35 (118.4 examples/sec; 0.068 sec/batch; 3h:22m:16s remains)
INFO - root - 2022-02-24 19:29:07.630987: step 19840, total loss = 0.78, batch loss = 0.49 (94.0 examples/sec; 0.085 sec/batch; 4h:14m:52s remains)
INFO - root - 2022-02-24 19:29:08.199934: step 19850, total loss = 0.77, batch loss = 0.48 (148.2 examples/sec; 0.054 sec/batch; 2h:41m:38s remains)
INFO - root - 2022-02-24 19:29:08.690568: step 19860, total loss = 0.73, batch loss = 0.44 (263.6 examples/sec; 0.030 sec/batch; 1h:30m:52s remains)
INFO - root - 2022-02-24 19:29:09.038884: step 19870, total loss = 0.58, batch loss = 0.29 (299.9 examples/sec; 0.027 sec/batch; 1h:19m:51s remains)
INFO - root - 2022-02-24 19:29:09.446452: step 19880, total loss = 0.80, batch loss = 0.51 (178.3 examples/sec; 0.045 sec/batch; 2h:14m:21s remains)
INFO - root - 2022-02-24 19:29:10.398100: step 19890, total loss = 0.53, batch loss = 0.24 (170.8 examples/sec; 0.047 sec/batch; 2h:20m:10s remains)
INFO - root - 2022-02-24 19:29:10.804904: step 19900, total loss = 0.60, batch loss = 0.31 (379.5 examples/sec; 0.021 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 19:29:11.240781: step 19910, total loss = 0.72, batch loss = 0.43 (262.4 examples/sec; 0.030 sec/batch; 1h:31m:14s remains)
INFO - root - 2022-02-24 19:29:11.705529: step 19920, total loss = 0.59, batch loss = 0.30 (120.0 examples/sec; 0.067 sec/batch; 3h:19m:28s remains)
INFO - root - 2022-02-24 19:29:12.158831: step 19930, total loss = 0.62, batch loss = 0.33 (228.9 examples/sec; 0.035 sec/batch; 1h:44m:36s remains)
INFO - root - 2022-02-24 19:29:12.593953: step 19940, total loss = 0.69, batch loss = 0.40 (283.0 examples/sec; 0.028 sec/batch; 1h:24m:36s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-19949 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-19949 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:29:13.379585: step 19950, total loss = 0.65, batch loss = 0.36 (296.5 examples/sec; 0.027 sec/batch; 1h:20m:44s remains)
INFO - root - 2022-02-24 19:29:13.626127: step 19960, total loss = 0.55, batch loss = 0.26 (317.6 examples/sec; 0.025 sec/batch; 1h:15m:22s remains)
INFO - root - 2022-02-24 19:29:13.975856: step 19970, total loss = 0.65, batch loss = 0.35 (246.3 examples/sec; 0.032 sec/batch; 1h:37m:11s remains)
INFO - root - 2022-02-24 19:29:14.405477: step 19980, total loss = 0.61, batch loss = 0.31 (166.0 examples/sec; 0.048 sec/batch; 2h:24m:09s remains)
INFO - root - 2022-02-24 19:29:14.866484: step 19990, total loss = 0.65, batch loss = 0.36 (303.4 examples/sec; 0.026 sec/batch; 1h:18m:52s remains)
INFO - root - 2022-02-24 19:29:15.376064: step 20000, total loss = 0.63, batch loss = 0.34 (120.9 examples/sec; 0.066 sec/batch; 3h:17m:56s remains)
INFO - root - 2022-02-24 19:29:15.790709: step 20010, total loss = 0.75, batch loss = 0.45 (194.3 examples/sec; 0.041 sec/batch; 2h:03m:11s remains)
INFO - root - 2022-02-24 19:29:16.137280: step 20020, total loss = 0.71, batch loss = 0.42 (217.4 examples/sec; 0.037 sec/batch; 1h:50m:03s remains)
INFO - root - 2022-02-24 19:29:16.613427: step 20030, total loss = 0.68, batch loss = 0.39 (144.4 examples/sec; 0.055 sec/batch; 2h:45m:42s remains)
INFO - root - 2022-02-24 19:29:17.046856: step 20040, total loss = 0.75, batch loss = 0.46 (132.0 examples/sec; 0.061 sec/batch; 3h:01m:18s remains)
INFO - root - 2022-02-24 19:29:17.474865: step 20050, total loss = 0.75, batch loss = 0.45 (249.8 examples/sec; 0.032 sec/batch; 1h:35m:46s remains)
INFO - root - 2022-02-24 19:29:17.860368: step 20060, total loss = 0.60, batch loss = 0.30 (206.1 examples/sec; 0.039 sec/batch; 1h:56m:05s remains)
INFO - root - 2022-02-24 19:29:18.208114: step 20070, total loss = 0.71, batch loss = 0.42 (358.5 examples/sec; 0.022 sec/batch; 1h:06m:44s remains)
INFO - root - 2022-02-24 19:29:18.562729: step 20080, total loss = 0.68, batch loss = 0.39 (237.6 examples/sec; 0.034 sec/batch; 1h:40m:42s remains)
INFO - root - 2022-02-24 19:29:19.014529: step 20090, total loss = 0.51, batch loss = 0.22 (130.4 examples/sec; 0.061 sec/batch; 3h:03m:23s remains)
INFO - root - 2022-02-24 19:29:19.504495: step 20100, total loss = 0.48, batch loss = 0.19 (242.5 examples/sec; 0.033 sec/batch; 1h:38m:38s remains)
INFO - root - 2022-02-24 19:29:19.904057: step 20110, total loss = 0.59, batch loss = 0.30 (208.9 examples/sec; 0.038 sec/batch; 1h:54m:28s remains)
INFO - root - 2022-02-24 19:29:20.208245: step 20120, total loss = 0.75, batch loss = 0.46 (285.7 examples/sec; 0.028 sec/batch; 1h:23m:42s remains)
INFO - root - 2022-02-24 19:29:20.604753: step 20130, total loss = 0.67, batch loss = 0.38 (292.2 examples/sec; 0.027 sec/batch; 1h:21m:50s remains)
INFO - root - 2022-02-24 19:29:21.109457: step 20140, total loss = 0.62, batch loss = 0.33 (144.9 examples/sec; 0.055 sec/batch; 2h:45m:02s remains)
INFO - root - 2022-02-24 19:29:21.497765: step 20150, total loss = 0.54, batch loss = 0.25 (183.8 examples/sec; 0.044 sec/batch; 2h:10m:05s remains)
INFO - root - 2022-02-24 19:29:21.867404: step 20160, total loss = 0.73, batch loss = 0.44 (149.6 examples/sec; 0.053 sec/batch; 2h:39m:47s remains)
INFO - root - 2022-02-24 19:29:22.213480: step 20170, total loss = 0.73, batch loss = 0.44 (181.9 examples/sec; 0.044 sec/batch; 2h:11m:25s remains)
INFO - root - 2022-02-24 19:29:22.656734: step 20180, total loss = 0.61, batch loss = 0.32 (234.4 examples/sec; 0.034 sec/batch; 1h:42m:00s remains)
INFO - root - 2022-02-24 19:29:23.174033: step 20190, total loss = 0.67, batch loss = 0.38 (223.1 examples/sec; 0.036 sec/batch; 1h:47m:08s remains)
INFO - root - 2022-02-24 19:29:23.567436: step 20200, total loss = 0.67, batch loss = 0.38 (128.1 examples/sec; 0.062 sec/batch; 3h:06m:35s remains)
INFO - root - 2022-02-24 19:29:24.018403: step 20210, total loss = 0.68, batch loss = 0.39 (107.6 examples/sec; 0.074 sec/batch; 3h:42m:04s remains)
INFO - root - 2022-02-24 19:29:24.456252: step 20220, total loss = 0.70, batch loss = 0.41 (261.7 examples/sec; 0.031 sec/batch; 1h:31m:21s remains)
INFO - root - 2022-02-24 19:29:24.949899: step 20230, total loss = 0.63, batch loss = 0.34 (150.0 examples/sec; 0.053 sec/batch; 2h:39m:20s remains)
INFO - root - 2022-02-24 19:29:25.903446: step 20240, total loss = 0.66, batch loss = 0.36 (180.2 examples/sec; 0.044 sec/batch; 2h:12m:38s remains)
INFO - root - 2022-02-24 19:29:26.314574: step 20250, total loss = 0.65, batch loss = 0.36 (207.5 examples/sec; 0.039 sec/batch; 1h:55m:11s remains)
INFO - root - 2022-02-24 19:29:26.652043: step 20260, total loss = 0.61, batch loss = 0.32 (293.3 examples/sec; 0.027 sec/batch; 1h:21m:28s remains)
INFO - root - 2022-02-24 19:29:26.922312: step 20270, total loss = 0.60, batch loss = 0.31 (290.9 examples/sec; 0.027 sec/batch; 1h:22m:08s remains)
INFO - root - 2022-02-24 19:29:27.454615: step 20280, total loss = 0.69, batch loss = 0.39 (198.5 examples/sec; 0.040 sec/batch; 2h:00m:23s remains)
INFO - root - 2022-02-24 19:29:27.853053: step 20290, total loss = 0.68, batch loss = 0.39 (145.8 examples/sec; 0.055 sec/batch; 2h:43m:51s remains)
INFO - root - 2022-02-24 19:29:28.338429: step 20300, total loss = 0.64, batch loss = 0.35 (195.5 examples/sec; 0.041 sec/batch; 2h:02m:11s remains)
INFO - root - 2022-02-24 19:29:28.813707: step 20310, total loss = 0.65, batch loss = 0.36 (309.9 examples/sec; 0.026 sec/batch; 1h:17m:06s remains)
INFO - root - 2022-02-24 19:29:29.291785: step 20320, total loss = 0.65, batch loss = 0.36 (160.6 examples/sec; 0.050 sec/batch; 2h:28m:46s remains)
INFO - root - 2022-02-24 19:29:29.831008: step 20330, total loss = 0.67, batch loss = 0.38 (83.3 examples/sec; 0.096 sec/batch; 4h:46m:38s remains)
INFO - root - 2022-02-24 19:29:30.238262: step 20340, total loss = 0.53, batch loss = 0.24 (306.2 examples/sec; 0.026 sec/batch; 1h:18m:01s remains)
INFO - root - 2022-02-24 19:29:31.176909: step 20350, total loss = 0.68, batch loss = 0.39 (97.2 examples/sec; 0.082 sec/batch; 4h:05m:40s remains)
INFO - root - 2022-02-24 19:29:31.616601: step 20360, total loss = 0.56, batch loss = 0.27 (108.8 examples/sec; 0.074 sec/batch; 3h:39m:28s remains)
INFO - root - 2022-02-24 19:29:31.960755: step 20370, total loss = 0.62, batch loss = 0.33 (243.4 examples/sec; 0.033 sec/batch; 1h:38m:08s remains)
INFO - root - 2022-02-24 19:29:32.410163: step 20380, total loss = 0.61, batch loss = 0.32 (202.2 examples/sec; 0.040 sec/batch; 1h:58m:08s remains)
INFO - root - 2022-02-24 19:29:32.912287: step 20390, total loss = 0.60, batch loss = 0.31 (135.5 examples/sec; 0.059 sec/batch; 2h:56m:16s remains)
INFO - root - 2022-02-24 19:29:33.384246: step 20400, total loss = 0.53, batch loss = 0.24 (127.0 examples/sec; 0.063 sec/batch; 3h:08m:02s remains)
INFO - root - 2022-02-24 19:29:33.845980: step 20410, total loss = 0.53, batch loss = 0.24 (313.4 examples/sec; 0.026 sec/batch; 1h:16m:11s remains)
INFO - root - 2022-02-24 19:29:34.256675: step 20420, total loss = 0.68, batch loss = 0.39 (311.3 examples/sec; 0.026 sec/batch; 1h:16m:42s remains)
INFO - root - 2022-02-24 19:29:34.675982: step 20430, total loss = 0.68, batch loss = 0.39 (228.7 examples/sec; 0.035 sec/batch; 1h:44m:25s remains)
INFO - root - 2022-02-24 19:29:35.154479: step 20440, total loss = 0.61, batch loss = 0.32 (135.9 examples/sec; 0.059 sec/batch; 2h:55m:44s remains)
INFO - root - 2022-02-24 19:29:35.857300: step 20450, total loss = 0.53, batch loss = 0.24 (185.9 examples/sec; 0.043 sec/batch; 2h:08m:27s remains)
INFO - root - 2022-02-24 19:29:36.243638: step 20460, total loss = 0.58, batch loss = 0.29 (173.0 examples/sec; 0.046 sec/batch; 2h:18m:00s remains)
INFO - root - 2022-02-24 19:29:36.743604: step 20470, total loss = 0.49, batch loss = 0.20 (147.6 examples/sec; 0.054 sec/batch; 2h:41m:44s remains)
INFO - root - 2022-02-24 19:29:37.227895: step 20480, total loss = 0.58, batch loss = 0.29 (202.1 examples/sec; 0.040 sec/batch; 1h:58m:07s remains)
INFO - root - 2022-02-24 19:29:37.602618: step 20490, total loss = 0.57, batch loss = 0.28 (300.0 examples/sec; 0.027 sec/batch; 1h:19m:33s remains)
INFO - root - 2022-02-24 19:29:38.246623: step 20500, total loss = 0.63, batch loss = 0.34 (164.1 examples/sec; 0.049 sec/batch; 2h:25m:26s remains)
INFO - root - 2022-02-24 19:29:38.745967: step 20510, total loss = 0.67, batch loss = 0.38 (215.4 examples/sec; 0.037 sec/batch; 1h:50m:49s remains)
INFO - root - 2022-02-24 19:29:39.218454: step 20520, total loss = 0.64, batch loss = 0.35 (213.5 examples/sec; 0.037 sec/batch; 1h:51m:45s remains)
INFO - root - 2022-02-24 19:29:39.635118: step 20530, total loss = 0.54, batch loss = 0.25 (235.3 examples/sec; 0.034 sec/batch; 1h:41m:23s remains)
INFO - root - 2022-02-24 19:29:40.066069: step 20540, total loss = 0.63, batch loss = 0.33 (311.7 examples/sec; 0.026 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 19:29:40.423355: step 20550, total loss = 0.63, batch loss = 0.34 (262.3 examples/sec; 0.031 sec/batch; 1h:30m:58s remains)
INFO - root - 2022-02-24 19:29:40.870519: step 20560, total loss = 0.59, batch loss = 0.30 (158.1 examples/sec; 0.051 sec/batch; 2h:30m:52s remains)
INFO - root - 2022-02-24 19:29:41.279882: step 20570, total loss = 0.65, batch loss = 0.36 (151.2 examples/sec; 0.053 sec/batch; 2h:37m:50s remains)
INFO - root - 2022-02-24 19:29:41.819534: step 20580, total loss = 0.55, batch loss = 0.26 (116.5 examples/sec; 0.069 sec/batch; 3h:24m:43s remains)
INFO - root - 2022-02-24 19:29:42.229136: step 20590, total loss = 0.59, batch loss = 0.30 (233.4 examples/sec; 0.034 sec/batch; 1h:42m:11s remains)
INFO - root - 2022-02-24 19:29:42.547113: step 20600, total loss = 0.57, batch loss = 0.28 (216.6 examples/sec; 0.037 sec/batch; 1h:50m:07s remains)
INFO - root - 2022-02-24 19:29:43.019801: step 20610, total loss = 0.58, batch loss = 0.29 (143.7 examples/sec; 0.056 sec/batch; 2h:45m:58s remains)
INFO - root - 2022-02-24 19:29:43.585489: step 20620, total loss = 0.52, batch loss = 0.23 (132.6 examples/sec; 0.060 sec/batch; 2h:59m:51s remains)
INFO - root - 2022-02-24 19:29:44.001782: step 20630, total loss = 0.61, batch loss = 0.31 (228.9 examples/sec; 0.035 sec/batch; 1h:44m:10s remains)
INFO - root - 2022-02-24 19:29:44.392925: step 20640, total loss = 0.66, batch loss = 0.37 (195.6 examples/sec; 0.041 sec/batch; 2h:01m:56s remains)
INFO - root - 2022-02-24 19:29:44.801704: step 20650, total loss = 0.59, batch loss = 0.30 (199.1 examples/sec; 0.040 sec/batch; 1h:59m:44s remains)
INFO - root - 2022-02-24 19:29:45.174998: step 20660, total loss = 0.60, batch loss = 0.31 (110.9 examples/sec; 0.072 sec/batch; 3h:35m:00s remains)
INFO - root - 2022-02-24 19:29:45.545780: step 20670, total loss = 0.56, batch loss = 0.27 (167.3 examples/sec; 0.048 sec/batch; 2h:22m:33s remains)
INFO - root - 2022-02-24 19:29:45.974101: step 20680, total loss = 0.55, batch loss = 0.26 (101.5 examples/sec; 0.079 sec/batch; 3h:54m:59s remains)
INFO - root - 2022-02-24 19:29:46.425262: step 20690, total loss = 0.60, batch loss = 0.31 (175.8 examples/sec; 0.045 sec/batch; 2h:15m:35s remains)
INFO - root - 2022-02-24 19:29:46.906031: step 20700, total loss = 0.62, batch loss = 0.32 (100.8 examples/sec; 0.079 sec/batch; 3h:56m:36s remains)
INFO - root - 2022-02-24 19:29:47.430068: step 20710, total loss = 0.60, batch loss = 0.31 (257.7 examples/sec; 0.031 sec/batch; 1h:32m:29s remains)
INFO - root - 2022-02-24 19:29:47.815653: step 20720, total loss = 0.85, batch loss = 0.56 (143.2 examples/sec; 0.056 sec/batch; 2h:46m:27s remains)
INFO - root - 2022-02-24 19:29:48.310249: step 20730, total loss = 0.63, batch loss = 0.34 (320.9 examples/sec; 0.025 sec/batch; 1h:14m:17s remains)
INFO - root - 2022-02-24 19:29:48.774904: step 20740, total loss = 0.60, batch loss = 0.31 (234.9 examples/sec; 0.034 sec/batch; 1h:41m:28s remains)
INFO - root - 2022-02-24 19:29:49.172780: step 20750, total loss = 0.53, batch loss = 0.24 (127.8 examples/sec; 0.063 sec/batch; 3h:06m:28s remains)
INFO - root - 2022-02-24 19:29:49.564284: step 20760, total loss = 0.57, batch loss = 0.28 (275.8 examples/sec; 0.029 sec/batch; 1h:26m:25s remains)
INFO - root - 2022-02-24 19:29:49.955545: step 20770, total loss = 0.62, batch loss = 0.33 (209.5 examples/sec; 0.038 sec/batch; 1h:53m:45s remains)
INFO - root - 2022-02-24 19:29:50.371372: step 20780, total loss = 0.59, batch loss = 0.30 (120.8 examples/sec; 0.066 sec/batch; 3h:17m:12s remains)
INFO - root - 2022-02-24 19:29:50.913539: step 20790, total loss = 0.64, batch loss = 0.35 (143.6 examples/sec; 0.056 sec/batch; 2h:45m:56s remains)
INFO - root - 2022-02-24 19:29:51.300384: step 20800, total loss = 0.55, batch loss = 0.26 (364.6 examples/sec; 0.022 sec/batch; 1h:05m:21s remains)
INFO - root - 2022-02-24 19:29:51.758080: step 20810, total loss = 0.60, batch loss = 0.31 (283.1 examples/sec; 0.028 sec/batch; 1h:24m:09s remains)
INFO - root - 2022-02-24 19:29:52.148801: step 20820, total loss = 0.56, batch loss = 0.27 (259.8 examples/sec; 0.031 sec/batch; 1h:31m:42s remains)
INFO - root - 2022-02-24 19:29:52.552251: step 20830, total loss = 0.72, batch loss = 0.42 (137.6 examples/sec; 0.058 sec/batch; 2h:53m:08s remains)
INFO - root - 2022-02-24 19:29:52.950787: step 20840, total loss = 0.54, batch loss = 0.25 (319.6 examples/sec; 0.025 sec/batch; 1h:14m:32s remains)
INFO - root - 2022-02-24 19:29:53.411647: step 20850, total loss = 0.59, batch loss = 0.30 (123.1 examples/sec; 0.065 sec/batch; 3h:13m:29s remains)
INFO - root - 2022-02-24 19:29:53.784633: step 20860, total loss = 0.57, batch loss = 0.28 (260.3 examples/sec; 0.031 sec/batch; 1h:31m:30s remains)
INFO - root - 2022-02-24 19:29:54.166388: step 20870, total loss = 0.77, batch loss = 0.48 (293.2 examples/sec; 0.027 sec/batch; 1h:21m:13s remains)
INFO - root - 2022-02-24 19:29:54.484046: step 20880, total loss = 0.56, batch loss = 0.27 (324.5 examples/sec; 0.025 sec/batch; 1h:13m:22s remains)
INFO - root - 2022-02-24 19:29:54.992847: step 20890, total loss = 0.62, batch loss = 0.33 (123.4 examples/sec; 0.065 sec/batch; 3h:12m:59s remains)
INFO - root - 2022-02-24 19:29:55.454233: step 20900, total loss = 0.69, batch loss = 0.40 (126.8 examples/sec; 0.063 sec/batch; 3h:07m:47s remains)
INFO - root - 2022-02-24 19:29:55.961800: step 20910, total loss = 0.55, batch loss = 0.26 (331.1 examples/sec; 0.024 sec/batch; 1h:11m:54s remains)
INFO - root - 2022-02-24 19:29:56.346110: step 20920, total loss = 0.59, batch loss = 0.30 (291.9 examples/sec; 0.027 sec/batch; 1h:21m:34s remains)
INFO - root - 2022-02-24 19:29:56.705111: step 20930, total loss = 0.60, batch loss = 0.31 (298.7 examples/sec; 0.027 sec/batch; 1h:19m:42s remains)
INFO - root - 2022-02-24 19:29:57.165321: step 20940, total loss = 0.70, batch loss = 0.40 (239.9 examples/sec; 0.033 sec/batch; 1h:39m:15s remains)
INFO - root - 2022-02-24 19:29:57.711639: step 20950, total loss = 0.66, batch loss = 0.37 (239.0 examples/sec; 0.033 sec/batch; 1h:39m:35s remains)
INFO - root - 2022-02-24 19:29:58.219254: step 20960, total loss = 0.63, batch loss = 0.34 (353.0 examples/sec; 0.023 sec/batch; 1h:07m:26s remains)
INFO - root - 2022-02-24 19:29:58.640379: step 20970, total loss = 0.62, batch loss = 0.33 (225.6 examples/sec; 0.035 sec/batch; 1h:45m:31s remains)
INFO - root - 2022-02-24 19:29:59.095070: step 20980, total loss = 0.71, batch loss = 0.42 (136.7 examples/sec; 0.059 sec/batch; 2h:54m:09s remains)
INFO - root - 2022-02-24 19:29:59.631462: step 20990, total loss = 0.60, batch loss = 0.31 (330.5 examples/sec; 0.024 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 19:30:00.142616: step 21000, total loss = 0.50, batch loss = 0.21 (102.6 examples/sec; 0.078 sec/batch; 3h:52m:03s remains)
INFO - root - 2022-02-24 19:30:01.169267: step 21010, total loss = 0.67, batch loss = 0.38 (177.8 examples/sec; 0.045 sec/batch; 2h:13m:50s remains)
INFO - root - 2022-02-24 19:30:01.656050: step 21020, total loss = 0.73, batch loss = 0.44 (125.2 examples/sec; 0.064 sec/batch; 3h:10m:06s remains)
INFO - root - 2022-02-24 19:30:02.113508: step 21030, total loss = 0.56, batch loss = 0.27 (222.2 examples/sec; 0.036 sec/batch; 1h:47m:06s remains)
INFO - root - 2022-02-24 19:30:02.620903: step 21040, total loss = 0.55, batch loss = 0.26 (146.6 examples/sec; 0.055 sec/batch; 2h:42m:18s remains)
INFO - root - 2022-02-24 19:30:03.164903: step 21050, total loss = 0.55, batch loss = 0.26 (178.6 examples/sec; 0.045 sec/batch; 2h:13m:13s remains)
INFO - root - 2022-02-24 19:30:03.642550: step 21060, total loss = 0.61, batch loss = 0.32 (116.4 examples/sec; 0.069 sec/batch; 3h:24m:25s remains)
INFO - root - 2022-02-24 19:30:04.059297: step 21070, total loss = 0.59, batch loss = 0.30 (314.0 examples/sec; 0.025 sec/batch; 1h:15m:46s remains)
INFO - root - 2022-02-24 19:30:04.555485: step 21080, total loss = 0.61, batch loss = 0.32 (90.8 examples/sec; 0.088 sec/batch; 4h:21m:51s remains)
INFO - root - 2022-02-24 19:30:05.022546: step 21090, total loss = 0.72, batch loss = 0.43 (323.2 examples/sec; 0.025 sec/batch; 1h:13m:36s remains)
INFO - root - 2022-02-24 19:30:05.482540: step 21100, total loss = 0.62, batch loss = 0.33 (86.4 examples/sec; 0.093 sec/batch; 4h:35m:18s remains)
INFO - root - 2022-02-24 19:30:06.295889: step 21110, total loss = 0.72, batch loss = 0.43 (29.7 examples/sec; 0.269 sec/batch; 13h:19m:39s remains)
INFO - root - 2022-02-24 19:30:06.698144: step 21120, total loss = 0.58, batch loss = 0.29 (298.6 examples/sec; 0.027 sec/batch; 1h:19m:39s remains)
INFO - root - 2022-02-24 19:30:07.144939: step 21130, total loss = 0.59, batch loss = 0.30 (246.3 examples/sec; 0.032 sec/batch; 1h:36m:32s remains)
INFO - root - 2022-02-24 19:30:07.492957: step 21140, total loss = 0.65, batch loss = 0.36 (201.1 examples/sec; 0.040 sec/batch; 1h:58m:13s remains)
INFO - root - 2022-02-24 19:30:07.909913: step 21150, total loss = 0.66, batch loss = 0.37 (153.6 examples/sec; 0.052 sec/batch; 2h:34m:48s remains)
INFO - root - 2022-02-24 19:30:08.512504: step 21160, total loss = 0.62, batch loss = 0.33 (276.2 examples/sec; 0.029 sec/batch; 1h:26m:06s remains)
INFO - root - 2022-02-24 19:30:08.984475: step 21170, total loss = 0.62, batch loss = 0.33 (302.4 examples/sec; 0.026 sec/batch; 1h:18m:38s remains)
INFO - root - 2022-02-24 19:30:09.592125: step 21180, total loss = 0.62, batch loss = 0.33 (254.6 examples/sec; 0.031 sec/batch; 1h:33m:23s remains)
INFO - root - 2022-02-24 19:30:10.089380: step 21190, total loss = 0.57, batch loss = 0.28 (132.2 examples/sec; 0.060 sec/batch; 2h:59m:47s remains)
INFO - root - 2022-02-24 19:30:10.495081: step 21200, total loss = 0.75, batch loss = 0.46 (200.2 examples/sec; 0.040 sec/batch; 1h:58m:44s remains)
INFO - root - 2022-02-24 19:30:10.963922: step 21210, total loss = 0.64, batch loss = 0.35 (93.8 examples/sec; 0.085 sec/batch; 4h:13m:27s remains)
INFO - root - 2022-02-24 19:30:11.683966: step 21220, total loss = 0.62, batch loss = 0.33 (23.2 examples/sec; 0.345 sec/batch; 17h:04m:35s remains)
INFO - root - 2022-02-24 19:30:12.128097: step 21230, total loss = 0.62, batch loss = 0.33 (271.5 examples/sec; 0.029 sec/batch; 1h:27m:33s remains)
INFO - root - 2022-02-24 19:30:12.518880: step 21240, total loss = 0.56, batch loss = 0.27 (256.2 examples/sec; 0.031 sec/batch; 1h:32m:45s remains)
INFO - root - 2022-02-24 19:30:12.925138: step 21250, total loss = 0.67, batch loss = 0.38 (221.8 examples/sec; 0.036 sec/batch; 1h:47m:08s remains)
INFO - root - 2022-02-24 19:30:13.319251: step 21260, total loss = 0.61, batch loss = 0.32 (324.7 examples/sec; 0.025 sec/batch; 1h:13m:12s remains)
INFO - root - 2022-02-24 19:30:13.646224: step 21270, total loss = 0.55, batch loss = 0.26 (361.6 examples/sec; 0.022 sec/batch; 1h:05m:43s remains)
INFO - root - 2022-02-24 19:30:14.056216: step 21280, total loss = 0.78, batch loss = 0.49 (118.4 examples/sec; 0.068 sec/batch; 3h:20m:46s remains)
INFO - root - 2022-02-24 19:30:14.559544: step 21290, total loss = 0.52, batch loss = 0.23 (119.9 examples/sec; 0.067 sec/batch; 3h:18m:09s remains)
INFO - root - 2022-02-24 19:30:14.966095: step 21300, total loss = 0.58, batch loss = 0.29 (121.0 examples/sec; 0.066 sec/batch; 3h:16m:26s remains)
INFO - root - 2022-02-24 19:30:15.400739: step 21310, total loss = 0.53, batch loss = 0.24 (264.7 examples/sec; 0.030 sec/batch; 1h:29m:45s remains)
INFO - root - 2022-02-24 19:30:15.793501: step 21320, total loss = 0.70, batch loss = 0.41 (280.2 examples/sec; 0.029 sec/batch; 1h:24m:46s remains)
INFO - root - 2022-02-24 19:30:16.185443: step 21330, total loss = 0.59, batch loss = 0.30 (272.5 examples/sec; 0.029 sec/batch; 1h:27m:10s remains)
INFO - root - 2022-02-24 19:30:16.701283: step 21340, total loss = 0.77, batch loss = 0.48 (126.0 examples/sec; 0.063 sec/batch; 3h:08m:30s remains)
INFO - root - 2022-02-24 19:30:17.223405: step 21350, total loss = 0.60, batch loss = 0.31 (84.0 examples/sec; 0.095 sec/batch; 4h:42m:42s remains)
INFO - root - 2022-02-24 19:30:17.576013: step 21360, total loss = 0.56, batch loss = 0.27 (326.0 examples/sec; 0.025 sec/batch; 1h:12m:51s remains)
INFO - root - 2022-02-24 19:30:18.012294: step 21370, total loss = 0.63, batch loss = 0.34 (329.0 examples/sec; 0.024 sec/batch; 1h:12m:11s remains)
INFO - root - 2022-02-24 19:30:18.402340: step 21380, total loss = 0.65, batch loss = 0.36 (326.2 examples/sec; 0.025 sec/batch; 1h:12m:47s remains)
INFO - root - 2022-02-24 19:30:18.910838: step 21390, total loss = 0.59, batch loss = 0.30 (172.4 examples/sec; 0.046 sec/batch; 2h:17m:42s remains)
INFO - root - 2022-02-24 19:30:19.388407: step 21400, total loss = 0.71, batch loss = 0.42 (371.4 examples/sec; 0.022 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 19:30:19.831568: step 21410, total loss = 0.57, batch loss = 0.28 (242.1 examples/sec; 0.033 sec/batch; 1h:38m:04s remains)
INFO - root - 2022-02-24 19:30:20.174550: step 21420, total loss = 0.62, batch loss = 0.33 (262.9 examples/sec; 0.030 sec/batch; 1h:30m:19s remains)
INFO - root - 2022-02-24 19:30:20.554360: step 21430, total loss = 0.58, batch loss = 0.29 (317.9 examples/sec; 0.025 sec/batch; 1h:14m:40s remains)
INFO - root - 2022-02-24 19:30:20.875596: step 21440, total loss = 0.58, batch loss = 0.29 (188.9 examples/sec; 0.042 sec/batch; 2h:05m:42s remains)
INFO - root - 2022-02-24 19:30:21.280917: step 21450, total loss = 0.52, batch loss = 0.23 (170.9 examples/sec; 0.047 sec/batch; 2h:18m:52s remains)
INFO - root - 2022-02-24 19:30:21.740498: step 21460, total loss = 0.59, batch loss = 0.30 (268.1 examples/sec; 0.030 sec/batch; 1h:28m:31s remains)
INFO - root - 2022-02-24 19:30:22.144322: step 21470, total loss = 0.60, batch loss = 0.31 (254.2 examples/sec; 0.031 sec/batch; 1h:33m:23s remains)
INFO - root - 2022-02-24 19:30:22.533521: step 21480, total loss = 0.60, batch loss = 0.31 (329.7 examples/sec; 0.024 sec/batch; 1h:11m:59s remains)
INFO - root - 2022-02-24 19:30:22.909876: step 21490, total loss = 0.56, batch loss = 0.27 (322.2 examples/sec; 0.025 sec/batch; 1h:13m:39s remains)
INFO - root - 2022-02-24 19:30:23.325768: step 21500, total loss = 0.67, batch loss = 0.38 (208.2 examples/sec; 0.038 sec/batch; 1h:53m:58s remains)
INFO - root - 2022-02-24 19:30:23.799913: step 21510, total loss = 0.65, batch loss = 0.36 (119.2 examples/sec; 0.067 sec/batch; 3h:19m:09s remains)
INFO - root - 2022-02-24 19:30:24.278062: step 21520, total loss = 0.61, batch loss = 0.32 (156.5 examples/sec; 0.051 sec/batch; 2h:31m:38s remains)
INFO - root - 2022-02-24 19:30:24.656242: step 21530, total loss = 0.54, batch loss = 0.25 (291.1 examples/sec; 0.027 sec/batch; 1h:21m:30s remains)
INFO - root - 2022-02-24 19:30:25.104220: step 21540, total loss = 0.56, batch loss = 0.27 (166.9 examples/sec; 0.048 sec/batch; 2h:22m:08s remains)
INFO - root - 2022-02-24 19:30:25.524718: step 21550, total loss = 0.63, batch loss = 0.34 (165.8 examples/sec; 0.048 sec/batch; 2h:23m:08s remains)
INFO - root - 2022-02-24 19:30:25.952475: step 21560, total loss = 0.69, batch loss = 0.40 (193.9 examples/sec; 0.041 sec/batch; 2h:02m:23s remains)
INFO - root - 2022-02-24 19:30:26.499243: step 21570, total loss = 0.57, batch loss = 0.28 (156.1 examples/sec; 0.051 sec/batch; 2h:31m:56s remains)
INFO - root - 2022-02-24 19:30:27.245774: step 21580, total loss = 0.70, batch loss = 0.41 (261.6 examples/sec; 0.031 sec/batch; 1h:30m:41s remains)
INFO - root - 2022-02-24 19:30:27.691096: step 21590, total loss = 0.62, batch loss = 0.33 (200.3 examples/sec; 0.040 sec/batch; 1h:58m:24s remains)
INFO - root - 2022-02-24 19:30:28.084442: step 21600, total loss = 0.61, batch loss = 0.32 (308.8 examples/sec; 0.026 sec/batch; 1h:16m:48s remains)
INFO - root - 2022-02-24 19:30:28.625438: step 21610, total loss = 0.58, batch loss = 0.29 (130.8 examples/sec; 0.061 sec/batch; 3h:01m:20s remains)
INFO - root - 2022-02-24 19:30:29.027830: step 21620, total loss = 0.70, batch loss = 0.41 (193.9 examples/sec; 0.041 sec/batch; 2h:02m:19s remains)
INFO - root - 2022-02-24 19:30:29.509185: step 21630, total loss = 0.67, batch loss = 0.38 (128.2 examples/sec; 0.062 sec/batch; 3h:04m:59s remains)
INFO - root - 2022-02-24 19:30:30.229093: step 21640, total loss = 0.65, batch loss = 0.36 (100.3 examples/sec; 0.080 sec/batch; 3h:56m:25s remains)
INFO - root - 2022-02-24 19:30:30.823956: step 21650, total loss = 0.61, batch loss = 0.32 (292.0 examples/sec; 0.027 sec/batch; 1h:21m:13s remains)
INFO - root - 2022-02-24 19:30:31.332313: step 21660, total loss = 0.77, batch loss = 0.48 (95.5 examples/sec; 0.084 sec/batch; 4h:08m:11s remains)
INFO - root - 2022-02-24 19:30:31.856673: step 21670, total loss = 0.67, batch loss = 0.38 (172.5 examples/sec; 0.046 sec/batch; 2h:17m:26s remains)
INFO - root - 2022-02-24 19:30:32.580564: step 21680, total loss = 0.59, batch loss = 0.30 (313.2 examples/sec; 0.026 sec/batch; 1h:15m:42s remains)
INFO - root - 2022-02-24 19:30:33.092115: step 21690, total loss = 0.60, batch loss = 0.31 (326.3 examples/sec; 0.025 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 19:30:33.527244: step 21700, total loss = 0.66, batch loss = 0.37 (191.0 examples/sec; 0.042 sec/batch; 2h:04m:05s remains)
INFO - root - 2022-02-24 19:30:33.999806: step 21710, total loss = 0.62, batch loss = 0.34 (177.5 examples/sec; 0.045 sec/batch; 2h:13m:33s remains)
INFO - root - 2022-02-24 19:30:34.385410: step 21720, total loss = 0.52, batch loss = 0.23 (247.8 examples/sec; 0.032 sec/batch; 1h:35m:39s remains)
INFO - root - 2022-02-24 19:30:34.766922: step 21730, total loss = 0.59, batch loss = 0.30 (137.1 examples/sec; 0.058 sec/batch; 2h:52m:52s remains)
INFO - root - 2022-02-24 19:30:35.253390: step 21740, total loss = 0.78, batch loss = 0.49 (157.4 examples/sec; 0.051 sec/batch; 2h:30m:35s remains)
INFO - root - 2022-02-24 19:30:35.669721: step 21750, total loss = 0.70, batch loss = 0.41 (162.8 examples/sec; 0.049 sec/batch; 2h:25m:33s remains)
INFO - root - 2022-02-24 19:30:36.041783: step 21760, total loss = 0.74, batch loss = 0.45 (337.1 examples/sec; 0.024 sec/batch; 1h:10m:18s remains)
INFO - root - 2022-02-24 19:30:36.391139: step 21770, total loss = 0.64, batch loss = 0.35 (224.6 examples/sec; 0.036 sec/batch; 1h:45m:30s remains)
INFO - root - 2022-02-24 19:30:36.810383: step 21780, total loss = 0.55, batch loss = 0.26 (226.3 examples/sec; 0.035 sec/batch; 1h:44m:42s remains)
INFO - root - 2022-02-24 19:30:37.260962: step 21790, total loss = 0.52, batch loss = 0.23 (158.3 examples/sec; 0.051 sec/batch; 2h:29m:42s remains)
INFO - root - 2022-02-24 19:30:37.736806: step 21800, total loss = 0.69, batch loss = 0.40 (280.9 examples/sec; 0.028 sec/batch; 1h:24m:21s remains)
INFO - root - 2022-02-24 19:30:38.203086: step 21810, total loss = 0.53, batch loss = 0.24 (278.9 examples/sec; 0.029 sec/batch; 1h:24m:56s remains)
INFO - root - 2022-02-24 19:30:38.573807: step 21820, total loss = 0.77, batch loss = 0.48 (229.8 examples/sec; 0.035 sec/batch; 1h:43m:04s remains)
INFO - root - 2022-02-24 19:30:38.955907: step 21830, total loss = 0.58, batch loss = 0.29 (255.9 examples/sec; 0.031 sec/batch; 1h:32m:34s remains)
INFO - root - 2022-02-24 19:30:39.414978: step 21840, total loss = 0.63, batch loss = 0.34 (171.9 examples/sec; 0.047 sec/batch; 2h:17m:46s remains)
INFO - root - 2022-02-24 19:30:39.945429: step 21850, total loss = 0.57, batch loss = 0.28 (181.2 examples/sec; 0.044 sec/batch; 2h:10m:43s remains)
INFO - root - 2022-02-24 19:30:40.382452: step 21860, total loss = 0.57, batch loss = 0.28 (264.6 examples/sec; 0.030 sec/batch; 1h:29m:30s remains)
INFO - root - 2022-02-24 19:30:40.731607: step 21870, total loss = 0.61, batch loss = 0.32 (228.6 examples/sec; 0.035 sec/batch; 1h:43m:35s remains)
INFO - root - 2022-02-24 19:30:41.054477: step 21880, total loss = 0.60, batch loss = 0.31 (198.7 examples/sec; 0.040 sec/batch; 1h:59m:11s remains)
INFO - root - 2022-02-24 19:30:41.500321: step 21890, total loss = 0.63, batch loss = 0.34 (240.7 examples/sec; 0.033 sec/batch; 1h:38m:23s remains)
INFO - root - 2022-02-24 19:30:42.015440: step 21900, total loss = 0.63, batch loss = 0.34 (141.1 examples/sec; 0.057 sec/batch; 2h:47m:52s remains)
INFO - root - 2022-02-24 19:30:42.470407: step 21910, total loss = 0.66, batch loss = 0.37 (330.8 examples/sec; 0.024 sec/batch; 1h:11m:34s remains)
INFO - root - 2022-02-24 19:30:42.833717: step 21920, total loss = 0.56, batch loss = 0.27 (334.7 examples/sec; 0.024 sec/batch; 1h:10m:44s remains)
INFO - root - 2022-02-24 19:30:43.220633: step 21930, total loss = 0.81, batch loss = 0.52 (357.4 examples/sec; 0.022 sec/batch; 1h:06m:14s remains)
INFO - root - 2022-02-24 19:30:43.708678: step 21940, total loss = 0.54, batch loss = 0.25 (106.8 examples/sec; 0.075 sec/batch; 3h:41m:34s remains)
INFO - root - 2022-02-24 19:30:44.117377: step 21950, total loss = 0.65, batch loss = 0.36 (312.0 examples/sec; 0.026 sec/batch; 1h:15m:52s remains)
INFO - root - 2022-02-24 19:30:44.523911: step 21960, total loss = 0.64, batch loss = 0.35 (296.5 examples/sec; 0.027 sec/batch; 1h:19m:50s remains)
INFO - root - 2022-02-24 19:30:44.933184: step 21970, total loss = 0.67, batch loss = 0.38 (241.3 examples/sec; 0.033 sec/batch; 1h:38m:04s remains)
INFO - root - 2022-02-24 19:30:45.311997: step 21980, total loss = 0.62, batch loss = 0.33 (262.8 examples/sec; 0.030 sec/batch; 1h:30m:03s remains)
INFO - root - 2022-02-24 19:30:45.692252: step 21990, total loss = 0.54, batch loss = 0.26 (203.0 examples/sec; 0.039 sec/batch; 1h:56m:34s remains)
INFO - root - 2022-02-24 19:30:46.305916: step 22000, total loss = 0.62, batch loss = 0.33 (251.2 examples/sec; 0.032 sec/batch; 1h:34m:13s remains)
INFO - root - 2022-02-24 19:30:46.733045: step 22010, total loss = 0.60, batch loss = 0.31 (209.4 examples/sec; 0.038 sec/batch; 1h:52m:59s remains)
INFO - root - 2022-02-24 19:30:47.313322: step 22020, total loss = 0.67, batch loss = 0.38 (98.5 examples/sec; 0.081 sec/batch; 4h:00m:18s remains)
INFO - root - 2022-02-24 19:30:48.337993: step 22030, total loss = 0.66, batch loss = 0.38 (15.6 examples/sec; 0.514 sec/batch; 25h:21m:31s remains)
INFO - root - 2022-02-24 19:30:48.794664: step 22040, total loss = 0.74, batch loss = 0.45 (100.8 examples/sec; 0.079 sec/batch; 3h:54m:40s remains)
INFO - root - 2022-02-24 19:30:49.302232: step 22050, total loss = 0.53, batch loss = 0.24 (217.5 examples/sec; 0.037 sec/batch; 1h:48m:47s remains)
INFO - root - 2022-02-24 19:30:49.724141: step 22060, total loss = 0.66, batch loss = 0.37 (247.4 examples/sec; 0.032 sec/batch; 1h:35m:37s remains)
INFO - root - 2022-02-24 19:30:50.168175: step 22070, total loss = 0.57, batch loss = 0.28 (162.3 examples/sec; 0.049 sec/batch; 2h:25m:46s remains)
INFO - root - 2022-02-24 19:30:50.601663: step 22080, total loss = 0.59, batch loss = 0.30 (137.5 examples/sec; 0.058 sec/batch; 2h:52m:04s remains)
INFO - root - 2022-02-24 19:30:51.085942: step 22090, total loss = 0.57, batch loss = 0.28 (199.6 examples/sec; 0.040 sec/batch; 1h:58m:31s remains)
INFO - root - 2022-02-24 19:30:51.467893: step 22100, total loss = 0.67, batch loss = 0.38 (341.2 examples/sec; 0.023 sec/batch; 1h:09m:19s remains)
INFO - root - 2022-02-24 19:30:51.882867: step 22110, total loss = 0.52, batch loss = 0.23 (203.7 examples/sec; 0.039 sec/batch; 1h:56m:05s remains)
INFO - root - 2022-02-24 19:30:52.266485: step 22120, total loss = 0.60, batch loss = 0.31 (292.7 examples/sec; 0.027 sec/batch; 1h:20m:47s remains)
INFO - root - 2022-02-24 19:30:52.736899: step 22130, total loss = 0.57, batch loss = 0.28 (347.2 examples/sec; 0.023 sec/batch; 1h:08m:06s remains)
INFO - root - 2022-02-24 19:30:53.488693: step 22140, total loss = 0.62, batch loss = 0.33 (152.9 examples/sec; 0.052 sec/batch; 2h:34m:38s remains)
INFO - root - 2022-02-24 19:30:53.923335: step 22150, total loss = 0.57, batch loss = 0.28 (162.3 examples/sec; 0.049 sec/batch; 2h:25m:39s remains)
INFO - root - 2022-02-24 19:30:54.299360: step 22160, total loss = 0.62, batch loss = 0.33 (267.2 examples/sec; 0.030 sec/batch; 1h:28m:29s remains)
INFO - root - 2022-02-24 19:30:54.703104: step 22170, total loss = 0.65, batch loss = 0.36 (183.7 examples/sec; 0.044 sec/batch; 2h:08m:41s remains)
INFO - root - 2022-02-24 19:30:55.157339: step 22180, total loss = 0.54, batch loss = 0.25 (138.8 examples/sec; 0.058 sec/batch; 2h:50m:22s remains)
INFO - root - 2022-02-24 19:30:55.606880: step 22190, total loss = 0.57, batch loss = 0.28 (125.7 examples/sec; 0.064 sec/batch; 3h:08m:03s remains)
INFO - root - 2022-02-24 19:30:55.896001: step 22200, total loss = 0.75, batch loss = 0.46 (354.7 examples/sec; 0.023 sec/batch; 1h:06m:38s remains)
INFO - root - 2022-02-24 19:30:56.333272: step 22210, total loss = 0.72, batch loss = 0.43 (287.8 examples/sec; 0.028 sec/batch; 1h:22m:07s remains)
INFO - root - 2022-02-24 19:30:56.663778: step 22220, total loss = 0.72, batch loss = 0.43 (282.8 examples/sec; 0.028 sec/batch; 1h:23m:35s remains)
INFO - root - 2022-02-24 19:30:57.059328: step 22230, total loss = 0.55, batch loss = 0.26 (321.4 examples/sec; 0.025 sec/batch; 1h:13m:31s remains)
INFO - root - 2022-02-24 19:30:57.585941: step 22240, total loss = 0.74, batch loss = 0.45 (116.6 examples/sec; 0.069 sec/batch; 3h:22m:37s remains)
INFO - root - 2022-02-24 19:30:57.961968: step 22250, total loss = 0.59, batch loss = 0.30 (338.7 examples/sec; 0.024 sec/batch; 1h:09m:47s remains)
INFO - root - 2022-02-24 19:30:58.370794: step 22260, total loss = 0.54, batch loss = 0.25 (184.7 examples/sec; 0.043 sec/batch; 2h:07m:55s remains)
INFO - root - 2022-02-24 19:30:58.760860: step 22270, total loss = 0.61, batch loss = 0.32 (279.2 examples/sec; 0.029 sec/batch; 1h:24m:38s remains)
INFO - root - 2022-02-24 19:30:59.142459: step 22280, total loss = 0.61, batch loss = 0.33 (268.9 examples/sec; 0.030 sec/batch; 1h:27m:52s remains)
INFO - root - 2022-02-24 19:30:59.636426: step 22290, total loss = 0.52, batch loss = 0.23 (70.2 examples/sec; 0.114 sec/batch; 5h:36m:24s remains)
INFO - root - 2022-02-24 19:31:00.000880: step 22300, total loss = 0.66, batch loss = 0.37 (245.9 examples/sec; 0.033 sec/batch; 1h:36m:03s remains)
INFO - root - 2022-02-24 19:31:00.467607: step 22310, total loss = 0.58, batch loss = 0.29 (215.3 examples/sec; 0.037 sec/batch; 1h:49m:43s remains)
INFO - root - 2022-02-24 19:31:00.843743: step 22320, total loss = 0.73, batch loss = 0.44 (151.6 examples/sec; 0.053 sec/batch; 2h:35m:46s remains)
INFO - root - 2022-02-24 19:31:01.252610: step 22330, total loss = 0.58, batch loss = 0.29 (307.7 examples/sec; 0.026 sec/batch; 1h:16m:46s remains)
INFO - root - 2022-02-24 19:31:01.648720: step 22340, total loss = 0.66, batch loss = 0.37 (242.9 examples/sec; 0.033 sec/batch; 1h:37m:14s remains)
INFO - root - 2022-02-24 19:31:02.273413: step 22350, total loss = 0.65, batch loss = 0.36 (113.8 examples/sec; 0.070 sec/batch; 3h:27m:28s remains)
INFO - root - 2022-02-24 19:31:02.686239: step 22360, total loss = 0.73, batch loss = 0.44 (204.5 examples/sec; 0.039 sec/batch; 1h:55m:29s remains)
INFO - root - 2022-02-24 19:31:03.119731: step 22370, total loss = 0.72, batch loss = 0.43 (218.0 examples/sec; 0.037 sec/batch; 1h:48m:20s remains)
INFO - root - 2022-02-24 19:31:03.496775: step 22380, total loss = 0.52, batch loss = 0.23 (328.8 examples/sec; 0.024 sec/batch; 1h:11m:49s remains)
INFO - root - 2022-02-24 19:31:04.015851: step 22390, total loss = 0.72, batch loss = 0.43 (191.9 examples/sec; 0.042 sec/batch; 2h:03m:01s remains)
INFO - root - 2022-02-24 19:31:04.390233: step 22400, total loss = 0.55, batch loss = 0.26 (344.3 examples/sec; 0.023 sec/batch; 1h:08m:35s remains)
INFO - root - 2022-02-24 19:31:04.798963: step 22410, total loss = 0.60, batch loss = 0.31 (358.0 examples/sec; 0.022 sec/batch; 1h:05m:57s remains)
INFO - root - 2022-02-24 19:31:05.259865: step 22420, total loss = 0.50, batch loss = 0.22 (75.6 examples/sec; 0.106 sec/batch; 5h:12m:20s remains)
INFO - root - 2022-02-24 19:31:05.726456: step 22430, total loss = 0.56, batch loss = 0.27 (103.5 examples/sec; 0.077 sec/batch; 3h:48m:07s remains)
INFO - root - 2022-02-24 19:31:06.377073: step 22440, total loss = 0.53, batch loss = 0.24 (66.7 examples/sec; 0.120 sec/batch; 5h:53m:54s remains)
INFO - root - 2022-02-24 19:31:06.795728: step 22450, total loss = 0.57, batch loss = 0.28 (195.2 examples/sec; 0.041 sec/batch; 2h:00m:55s remains)
INFO - root - 2022-02-24 19:31:07.235062: step 22460, total loss = 0.73, batch loss = 0.44 (135.1 examples/sec; 0.059 sec/batch; 2h:54m:41s remains)
INFO - root - 2022-02-24 19:31:07.787576: step 22470, total loss = 0.65, batch loss = 0.36 (111.7 examples/sec; 0.072 sec/batch; 3h:31m:15s remains)
INFO - root - 2022-02-24 19:31:08.883994: step 22480, total loss = 0.61, batch loss = 0.32 (202.0 examples/sec; 0.040 sec/batch; 1h:56m:50s remains)
INFO - root - 2022-02-24 19:31:09.300361: step 22490, total loss = 0.59, batch loss = 0.30 (128.4 examples/sec; 0.062 sec/batch; 3h:03m:46s remains)
INFO - root - 2022-02-24 19:31:09.770911: step 22500, total loss = 0.64, batch loss = 0.35 (101.0 examples/sec; 0.079 sec/batch; 3h:53m:38s remains)
INFO - root - 2022-02-24 19:31:10.310736: step 22510, total loss = 0.60, batch loss = 0.31 (177.3 examples/sec; 0.045 sec/batch; 2h:13m:07s remains)
INFO - root - 2022-02-24 19:31:10.695899: step 22520, total loss = 0.58, batch loss = 0.29 (94.3 examples/sec; 0.085 sec/batch; 4h:10m:15s remains)
INFO - root - 2022-02-24 19:31:11.076943: step 22530, total loss = 0.60, batch loss = 0.31 (216.8 examples/sec; 0.037 sec/batch; 1h:48m:49s remains)
INFO - root - 2022-02-24 19:31:11.436678: step 22540, total loss = 0.63, batch loss = 0.34 (233.4 examples/sec; 0.034 sec/batch; 1h:41m:05s remains)
INFO - root - 2022-02-24 19:31:11.828133: step 22550, total loss = 0.62, batch loss = 0.33 (324.9 examples/sec; 0.025 sec/batch; 1h:12m:37s remains)
INFO - root - 2022-02-24 19:31:12.251284: step 22560, total loss = 0.53, batch loss = 0.24 (281.8 examples/sec; 0.028 sec/batch; 1h:23m:42s remains)
INFO - root - 2022-02-24 19:31:12.741721: step 22570, total loss = 0.64, batch loss = 0.35 (112.1 examples/sec; 0.071 sec/batch; 3h:30m:25s remains)
INFO - root - 2022-02-24 19:31:13.328809: step 22580, total loss = 0.66, batch loss = 0.37 (258.1 examples/sec; 0.031 sec/batch; 1h:31m:24s remains)
INFO - root - 2022-02-24 19:31:13.683019: step 22590, total loss = 0.72, batch loss = 0.43 (309.8 examples/sec; 0.026 sec/batch; 1h:16m:08s remains)
INFO - root - 2022-02-24 19:31:14.038215: step 22600, total loss = 0.55, batch loss = 0.26 (218.8 examples/sec; 0.037 sec/batch; 1h:47m:49s remains)
INFO - root - 2022-02-24 19:31:14.485592: step 22610, total loss = 0.58, batch loss = 0.29 (196.8 examples/sec; 0.041 sec/batch; 1h:59m:51s remains)
INFO - root - 2022-02-24 19:31:14.940169: step 22620, total loss = 0.66, batch loss = 0.37 (337.6 examples/sec; 0.024 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 19:31:15.471975: step 22630, total loss = 0.78, batch loss = 0.49 (178.1 examples/sec; 0.045 sec/batch; 2h:12m:22s remains)
INFO - root - 2022-02-24 19:31:15.812507: step 22640, total loss = 0.59, batch loss = 0.31 (291.8 examples/sec; 0.027 sec/batch; 1h:20m:49s remains)
INFO - root - 2022-02-24 19:31:16.163093: step 22650, total loss = 0.56, batch loss = 0.27 (109.7 examples/sec; 0.073 sec/batch; 3h:34m:58s remains)
INFO - root - 2022-02-24 19:31:16.500628: step 22660, total loss = 0.57, batch loss = 0.28 (250.8 examples/sec; 0.032 sec/batch; 1h:34m:00s remains)
INFO - root - 2022-02-24 19:31:17.011686: step 22670, total loss = 0.72, batch loss = 0.43 (171.8 examples/sec; 0.047 sec/batch; 2h:17m:14s remains)
INFO - root - 2022-02-24 19:31:17.471387: step 22680, total loss = 0.69, batch loss = 0.40 (227.8 examples/sec; 0.035 sec/batch; 1h:43m:30s remains)
INFO - root - 2022-02-24 19:31:17.908476: step 22690, total loss = 0.55, batch loss = 0.26 (337.5 examples/sec; 0.024 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 19:31:18.312822: step 22700, total loss = 0.64, batch loss = 0.35 (177.8 examples/sec; 0.045 sec/batch; 2h:12m:34s remains)
INFO - root - 2022-02-24 19:31:18.791444: step 22710, total loss = 0.59, batch loss = 0.30 (192.6 examples/sec; 0.042 sec/batch; 2h:02m:22s remains)
INFO - root - 2022-02-24 19:31:19.247963: step 22720, total loss = 0.60, batch loss = 0.31 (171.0 examples/sec; 0.047 sec/batch; 2h:17m:49s remains)
INFO - root - 2022-02-24 19:31:19.704364: step 22730, total loss = 0.57, batch loss = 0.29 (241.6 examples/sec; 0.033 sec/batch; 1h:37m:33s remains)
INFO - root - 2022-02-24 19:31:20.156952: step 22740, total loss = 0.62, batch loss = 0.33 (96.3 examples/sec; 0.083 sec/batch; 4h:04m:42s remains)
INFO - root - 2022-02-24 19:31:20.519758: step 22750, total loss = 0.63, batch loss = 0.34 (273.0 examples/sec; 0.029 sec/batch; 1h:26m:19s remains)
INFO - root - 2022-02-24 19:31:20.982408: step 22760, total loss = 0.59, batch loss = 0.31 (212.4 examples/sec; 0.038 sec/batch; 1h:50m:57s remains)
INFO - root - 2022-02-24 19:31:21.438854: step 22770, total loss = 0.61, batch loss = 0.32 (266.7 examples/sec; 0.030 sec/batch; 1h:28m:20s remains)
INFO - root - 2022-02-24 19:31:21.913624: step 22780, total loss = 0.66, batch loss = 0.37 (134.6 examples/sec; 0.059 sec/batch; 2h:55m:05s remains)
INFO - root - 2022-02-24 19:31:22.249063: step 22790, total loss = 0.59, batch loss = 0.30 (203.8 examples/sec; 0.039 sec/batch; 1h:55m:36s remains)
INFO - root - 2022-02-24 19:31:22.627704: step 22800, total loss = 0.58, batch loss = 0.29 (222.9 examples/sec; 0.036 sec/batch; 1h:45m:41s remains)
INFO - root - 2022-02-24 19:31:23.026516: step 22810, total loss = 0.67, batch loss = 0.38 (254.8 examples/sec; 0.031 sec/batch; 1h:32m:26s remains)
INFO - root - 2022-02-24 19:31:23.487173: step 22820, total loss = 0.58, batch loss = 0.30 (129.2 examples/sec; 0.062 sec/batch; 3h:02m:16s remains)
INFO - root - 2022-02-24 19:31:23.910990: step 22830, total loss = 0.52, batch loss = 0.23 (112.9 examples/sec; 0.071 sec/batch; 3h:28m:33s remains)
INFO - root - 2022-02-24 19:31:24.326728: step 22840, total loss = 0.65, batch loss = 0.36 (201.8 examples/sec; 0.040 sec/batch; 1h:56m:44s remains)
INFO - root - 2022-02-24 19:31:24.718965: step 22850, total loss = 0.64, batch loss = 0.35 (218.0 examples/sec; 0.037 sec/batch; 1h:48m:01s remains)
INFO - root - 2022-02-24 19:31:25.190759: step 22860, total loss = 0.62, batch loss = 0.34 (65.2 examples/sec; 0.123 sec/batch; 6h:01m:06s remains)
INFO - root - 2022-02-24 19:31:25.645393: step 22870, total loss = 0.69, batch loss = 0.40 (205.0 examples/sec; 0.039 sec/batch; 1h:54m:51s remains)
INFO - root - 2022-02-24 19:31:26.097146: step 22880, total loss = 0.67, batch loss = 0.39 (157.9 examples/sec; 0.051 sec/batch; 2h:29m:08s remains)
INFO - root - 2022-02-24 19:31:26.576994: step 22890, total loss = 0.62, batch loss = 0.33 (293.1 examples/sec; 0.027 sec/batch; 1h:20m:19s remains)
INFO - root - 2022-02-24 19:31:27.015968: step 22900, total loss = 0.56, batch loss = 0.27 (215.9 examples/sec; 0.037 sec/batch; 1h:49m:03s remains)
INFO - root - 2022-02-24 19:31:27.575247: step 22910, total loss = 0.58, batch loss = 0.30 (150.5 examples/sec; 0.053 sec/batch; 2h:36m:27s remains)
INFO - root - 2022-02-24 19:31:28.145452: step 22920, total loss = 0.67, batch loss = 0.38 (203.5 examples/sec; 0.039 sec/batch; 1h:55m:42s remains)
INFO - root - 2022-02-24 19:31:29.087647: step 22930, total loss = 0.56, batch loss = 0.27 (166.1 examples/sec; 0.048 sec/batch; 2h:21m:45s remains)
INFO - root - 2022-02-24 19:31:29.469804: step 22940, total loss = 0.67, batch loss = 0.38 (324.0 examples/sec; 0.025 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 19:31:29.897472: step 22950, total loss = 0.67, batch loss = 0.38 (157.6 examples/sec; 0.051 sec/batch; 2h:29m:24s remains)
INFO - root - 2022-02-24 19:31:30.367089: step 22960, total loss = 0.64, batch loss = 0.35 (215.1 examples/sec; 0.037 sec/batch; 1h:49m:25s remains)
INFO - root - 2022-02-24 19:31:30.774212: step 22970, total loss = 0.72, batch loss = 0.43 (317.5 examples/sec; 0.025 sec/batch; 1h:14m:08s remains)
INFO - root - 2022-02-24 19:31:31.182977: step 22980, total loss = 0.70, batch loss = 0.41 (227.7 examples/sec; 0.035 sec/batch; 1h:43m:20s remains)
INFO - root - 2022-02-24 19:31:31.646532: step 22990, total loss = 0.64, batch loss = 0.36 (231.4 examples/sec; 0.035 sec/batch; 1h:41m:42s remains)
INFO - root - 2022-02-24 19:31:32.044378: step 23000, total loss = 0.61, batch loss = 0.32 (319.6 examples/sec; 0.025 sec/batch; 1h:13m:38s remains)
INFO - root - 2022-02-24 19:31:32.520260: step 23010, total loss = 0.66, batch loss = 0.37 (297.1 examples/sec; 0.027 sec/batch; 1h:19m:12s remains)
INFO - root - 2022-02-24 19:31:32.921653: step 23020, total loss = 0.68, batch loss = 0.39 (144.4 examples/sec; 0.055 sec/batch; 2h:42m:55s remains)
INFO - root - 2022-02-24 19:31:33.607262: step 23030, total loss = 0.68, batch loss = 0.39 (296.8 examples/sec; 0.027 sec/batch; 1h:19m:16s remains)
INFO - root - 2022-02-24 19:31:34.123677: step 23040, total loss = 0.57, batch loss = 0.28 (171.4 examples/sec; 0.047 sec/batch; 2h:17m:16s remains)
INFO - root - 2022-02-24 19:31:34.583108: step 23050, total loss = 0.58, batch loss = 0.29 (119.2 examples/sec; 0.067 sec/batch; 3h:17m:20s remains)
INFO - root - 2022-02-24 19:31:35.144281: step 23060, total loss = 0.56, batch loss = 0.27 (192.5 examples/sec; 0.042 sec/batch; 2h:02m:12s remains)
INFO - root - 2022-02-24 19:31:35.548378: step 23070, total loss = 0.73, batch loss = 0.44 (293.6 examples/sec; 0.027 sec/batch; 1h:20m:07s remains)
INFO - root - 2022-02-24 19:31:35.978111: step 23080, total loss = 0.68, batch loss = 0.39 (277.7 examples/sec; 0.029 sec/batch; 1h:24m:42s remains)
INFO - root - 2022-02-24 19:31:36.319367: step 23090, total loss = 0.66, batch loss = 0.37 (347.1 examples/sec; 0.023 sec/batch; 1h:07m:46s remains)
INFO - root - 2022-02-24 19:31:36.754230: step 23100, total loss = 0.65, batch loss = 0.36 (259.9 examples/sec; 0.031 sec/batch; 1h:30m:29s remains)
INFO - root - 2022-02-24 19:31:37.236336: step 23110, total loss = 0.59, batch loss = 0.30 (172.6 examples/sec; 0.046 sec/batch; 2h:16m:15s remains)
INFO - root - 2022-02-24 19:31:37.625823: step 23120, total loss = 0.62, batch loss = 0.33 (141.0 examples/sec; 0.057 sec/batch; 2h:46m:47s remains)
INFO - root - 2022-02-24 19:31:37.974947: step 23130, total loss = 0.61, batch loss = 0.32 (243.9 examples/sec; 0.033 sec/batch; 1h:36m:23s remains)
INFO - root - 2022-02-24 19:31:38.442063: step 23140, total loss = 0.81, batch loss = 0.53 (93.3 examples/sec; 0.086 sec/batch; 4h:11m:54s remains)
INFO - root - 2022-02-24 19:31:38.890887: step 23150, total loss = 0.60, batch loss = 0.31 (225.1 examples/sec; 0.036 sec/batch; 1h:44m:27s remains)
INFO - root - 2022-02-24 19:31:39.300670: step 23160, total loss = 0.62, batch loss = 0.33 (226.5 examples/sec; 0.035 sec/batch; 1h:43m:48s remains)
INFO - root - 2022-02-24 19:31:39.669640: step 23170, total loss = 0.64, batch loss = 0.35 (303.7 examples/sec; 0.026 sec/batch; 1h:17m:25s remains)
INFO - root - 2022-02-24 19:31:40.104857: step 23180, total loss = 0.53, batch loss = 0.24 (307.0 examples/sec; 0.026 sec/batch; 1h:16m:34s remains)
INFO - root - 2022-02-24 19:31:40.525608: step 23190, total loss = 0.62, batch loss = 0.33 (120.5 examples/sec; 0.066 sec/batch; 3h:15m:00s remains)
INFO - root - 2022-02-24 19:31:40.918424: step 23200, total loss = 0.53, batch loss = 0.24 (190.6 examples/sec; 0.042 sec/batch; 2h:03m:20s remains)
INFO - root - 2022-02-24 19:31:41.393624: step 23210, total loss = 0.60, batch loss = 0.31 (368.7 examples/sec; 0.022 sec/batch; 1h:03m:44s remains)
INFO - root - 2022-02-24 19:31:41.742147: step 23220, total loss = 0.63, batch loss = 0.34 (341.1 examples/sec; 0.023 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 19:31:42.072275: step 23230, total loss = 0.57, batch loss = 0.28 (218.2 examples/sec; 0.037 sec/batch; 1h:47m:43s remains)
INFO - root - 2022-02-24 19:31:42.403271: step 23240, total loss = 0.58, batch loss = 0.29 (316.9 examples/sec; 0.025 sec/batch; 1h:14m:09s remains)
INFO - root - 2022-02-24 19:31:42.863637: step 23250, total loss = 0.59, batch loss = 0.30 (282.2 examples/sec; 0.028 sec/batch; 1h:23m:16s remains)
INFO - root - 2022-02-24 19:31:43.355653: step 23260, total loss = 0.59, batch loss = 0.30 (163.4 examples/sec; 0.049 sec/batch; 2h:23m:47s remains)
INFO - root - 2022-02-24 19:31:43.825750: step 23270, total loss = 0.64, batch loss = 0.35 (329.2 examples/sec; 0.024 sec/batch; 1h:11m:22s remains)
INFO - root - 2022-02-24 19:31:44.207107: step 23280, total loss = 0.74, batch loss = 0.45 (287.5 examples/sec; 0.028 sec/batch; 1h:21m:43s remains)
INFO - root - 2022-02-24 19:31:44.589971: step 23290, total loss = 0.65, batch loss = 0.36 (93.0 examples/sec; 0.086 sec/batch; 4h:12m:33s remains)
INFO - root - 2022-02-24 19:31:45.077803: step 23300, total loss = 0.57, batch loss = 0.28 (163.5 examples/sec; 0.049 sec/batch; 2h:23m:41s remains)
INFO - root - 2022-02-24 19:31:45.657132: step 23310, total loss = 0.62, batch loss = 0.33 (124.7 examples/sec; 0.064 sec/batch; 3h:08m:22s remains)
INFO - root - 2022-02-24 19:31:46.114583: step 23320, total loss = 0.59, batch loss = 0.30 (230.8 examples/sec; 0.035 sec/batch; 1h:41m:47s remains)
INFO - root - 2022-02-24 19:31:46.570079: step 23330, total loss = 0.61, batch loss = 0.32 (201.7 examples/sec; 0.040 sec/batch; 1h:56m:26s remains)
INFO - root - 2022-02-24 19:31:46.983228: step 23340, total loss = 0.56, batch loss = 0.27 (275.0 examples/sec; 0.029 sec/batch; 1h:25m:24s remains)
INFO - root - 2022-02-24 19:31:47.410140: step 23350, total loss = 0.62, batch loss = 0.33 (116.7 examples/sec; 0.069 sec/batch; 3h:21m:12s remains)
INFO - root - 2022-02-24 19:31:48.203054: step 23360, total loss = 0.64, batch loss = 0.35 (104.9 examples/sec; 0.076 sec/batch; 3h:43m:55s remains)
INFO - root - 2022-02-24 19:31:49.281136: step 23370, total loss = 0.75, batch loss = 0.46 (14.0 examples/sec; 0.571 sec/batch; 27h:57m:27s remains)
INFO - root - 2022-02-24 19:31:49.802346: step 23380, total loss = 0.67, batch loss = 0.38 (79.6 examples/sec; 0.101 sec/batch; 4h:55m:02s remains)
INFO - root - 2022-02-24 19:31:50.307824: step 23390, total loss = 0.54, batch loss = 0.25 (134.3 examples/sec; 0.060 sec/batch; 2h:54m:51s remains)
INFO - root - 2022-02-24 19:31:50.790797: step 23400, total loss = 0.71, batch loss = 0.42 (311.7 examples/sec; 0.026 sec/batch; 1h:15m:19s remains)
INFO - root - 2022-02-24 19:31:51.302374: step 23410, total loss = 0.64, batch loss = 0.35 (329.1 examples/sec; 0.024 sec/batch; 1h:11m:20s remains)
INFO - root - 2022-02-24 19:31:51.737099: step 23420, total loss = 0.57, batch loss = 0.28 (293.5 examples/sec; 0.027 sec/batch; 1h:19m:58s remains)
INFO - root - 2022-02-24 19:31:52.183101: step 23430, total loss = 0.60, batch loss = 0.31 (152.0 examples/sec; 0.053 sec/batch; 2h:34m:26s remains)
INFO - root - 2022-02-24 19:31:52.656814: step 23440, total loss = 0.53, batch loss = 0.25 (92.1 examples/sec; 0.087 sec/batch; 4h:14m:56s remains)
INFO - root - 2022-02-24 19:31:53.068184: step 23450, total loss = 0.61, batch loss = 0.32 (321.7 examples/sec; 0.025 sec/batch; 1h:12m:57s remains)
INFO - root - 2022-02-24 19:31:53.439067: step 23460, total loss = 0.68, batch loss = 0.39 (180.2 examples/sec; 0.044 sec/batch; 2h:10m:13s remains)
INFO - root - 2022-02-24 19:31:53.837419: step 23470, total loss = 0.74, batch loss = 0.45 (152.9 examples/sec; 0.052 sec/batch; 2h:33m:31s remains)
INFO - root - 2022-02-24 19:31:54.550528: step 23480, total loss = 0.55, batch loss = 0.27 (106.9 examples/sec; 0.075 sec/batch; 3h:39m:30s remains)
INFO - root - 2022-02-24 19:31:54.946575: step 23490, total loss = 0.56, batch loss = 0.27 (284.8 examples/sec; 0.028 sec/batch; 1h:22m:24s remains)
INFO - root - 2022-02-24 19:31:55.314199: step 23500, total loss = 0.58, batch loss = 0.29 (273.4 examples/sec; 0.029 sec/batch; 1h:25m:49s remains)
INFO - root - 2022-02-24 19:31:55.763290: step 23510, total loss = 0.58, batch loss = 0.29 (293.7 examples/sec; 0.027 sec/batch; 1h:19m:54s remains)
INFO - root - 2022-02-24 19:31:56.159241: step 23520, total loss = 0.56, batch loss = 0.27 (226.8 examples/sec; 0.035 sec/batch; 1h:43m:27s remains)
INFO - root - 2022-02-24 19:31:56.597591: step 23530, total loss = 0.54, batch loss = 0.25 (127.1 examples/sec; 0.063 sec/batch; 3h:04m:33s remains)
INFO - root - 2022-02-24 19:31:57.024717: step 23540, total loss = 0.67, batch loss = 0.38 (215.2 examples/sec; 0.037 sec/batch; 1h:48m:59s remains)
INFO - root - 2022-02-24 19:31:57.486107: step 23550, total loss = 0.56, batch loss = 0.27 (321.1 examples/sec; 0.025 sec/batch; 1h:13m:03s remains)
INFO - root - 2022-02-24 19:31:57.805514: step 23560, total loss = 0.52, batch loss = 0.23 (198.8 examples/sec; 0.040 sec/batch; 1h:57m:59s remains)
INFO - root - 2022-02-24 19:31:58.158327: step 23570, total loss = 0.70, batch loss = 0.41 (334.2 examples/sec; 0.024 sec/batch; 1h:10m:11s remains)
INFO - root - 2022-02-24 19:31:58.614745: step 23580, total loss = 0.56, batch loss = 0.27 (147.7 examples/sec; 0.054 sec/batch; 2h:38m:49s remains)
INFO - root - 2022-02-24 19:31:59.078370: step 23590, total loss = 0.60, batch loss = 0.31 (235.7 examples/sec; 0.034 sec/batch; 1h:39m:31s remains)
INFO - root - 2022-02-24 19:31:59.537833: step 23600, total loss = 0.63, batch loss = 0.34 (109.9 examples/sec; 0.073 sec/batch; 3h:33m:29s remains)
INFO - root - 2022-02-24 19:32:00.024841: step 23610, total loss = 0.64, batch loss = 0.36 (209.5 examples/sec; 0.038 sec/batch; 1h:51m:56s remains)
INFO - root - 2022-02-24 19:32:00.368375: step 23620, total loss = 0.59, batch loss = 0.30 (327.5 examples/sec; 0.024 sec/batch; 1h:11m:35s remains)
INFO - root - 2022-02-24 19:32:00.725021: step 23630, total loss = 0.62, batch loss = 0.33 (176.1 examples/sec; 0.045 sec/batch; 2h:13m:11s remains)
INFO - root - 2022-02-24 19:32:01.219227: step 23640, total loss = 0.68, batch loss = 0.39 (106.8 examples/sec; 0.075 sec/batch; 3h:39m:28s remains)
INFO - root - 2022-02-24 19:32:01.656440: step 23650, total loss = 0.68, batch loss = 0.39 (320.8 examples/sec; 0.025 sec/batch; 1h:13m:04s remains)
INFO - root - 2022-02-24 19:32:01.969950: step 23660, total loss = 0.68, batch loss = 0.39 (269.6 examples/sec; 0.030 sec/batch; 1h:26m:58s remains)
INFO - root - 2022-02-24 19:32:02.335205: step 23670, total loss = 0.55, batch loss = 0.27 (237.5 examples/sec; 0.034 sec/batch; 1h:38m:43s remains)
INFO - root - 2022-02-24 19:32:02.626540: step 23680, total loss = 0.56, batch loss = 0.27 (202.0 examples/sec; 0.040 sec/batch; 1h:56m:02s remains)
INFO - root - 2022-02-24 19:32:02.956058: step 23690, total loss = 0.58, batch loss = 0.29 (319.2 examples/sec; 0.025 sec/batch; 1h:13m:26s remains)
INFO - root - 2022-02-24 19:32:03.435319: step 23700, total loss = 0.58, batch loss = 0.29 (120.3 examples/sec; 0.067 sec/batch; 3h:14m:54s remains)
INFO - root - 2022-02-24 19:32:03.930115: step 23710, total loss = 0.53, batch loss = 0.24 (145.4 examples/sec; 0.055 sec/batch; 2h:41m:14s remains)
INFO - root - 2022-02-24 19:32:04.275106: step 23720, total loss = 0.56, batch loss = 0.27 (340.3 examples/sec; 0.024 sec/batch; 1h:08m:52s remains)
INFO - root - 2022-02-24 19:32:04.994691: step 23730, total loss = 0.69, batch loss = 0.40 (159.4 examples/sec; 0.050 sec/batch; 2h:27m:01s remains)
INFO - root - 2022-02-24 19:32:05.587800: step 23740, total loss = 0.67, batch loss = 0.38 (148.2 examples/sec; 0.054 sec/batch; 2h:38m:08s remains)
INFO - root - 2022-02-24 19:32:06.121269: step 23750, total loss = 0.65, batch loss = 0.37 (85.6 examples/sec; 0.093 sec/batch; 4h:33m:36s remains)
INFO - root - 2022-02-24 19:32:06.522040: step 23760, total loss = 0.62, batch loss = 0.33 (244.1 examples/sec; 0.033 sec/batch; 1h:35m:58s remains)
INFO - root - 2022-02-24 19:32:07.039990: step 23770, total loss = 0.52, batch loss = 0.23 (339.5 examples/sec; 0.024 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 19:32:07.546721: step 23780, total loss = 0.67, batch loss = 0.38 (102.7 examples/sec; 0.078 sec/batch; 3h:48m:14s remains)
INFO - root - 2022-02-24 19:32:08.065593: step 23790, total loss = 0.58, batch loss = 0.29 (88.5 examples/sec; 0.090 sec/batch; 4h:24m:36s remains)
INFO - root - 2022-02-24 19:32:08.567255: step 23800, total loss = 0.66, batch loss = 0.37 (160.9 examples/sec; 0.050 sec/batch; 2h:25m:34s remains)
INFO - root - 2022-02-24 19:32:08.942653: step 23810, total loss = 0.59, batch loss = 0.30 (218.6 examples/sec; 0.037 sec/batch; 1h:47m:09s remains)
INFO - root - 2022-02-24 19:32:09.334880: step 23820, total loss = 0.70, batch loss = 0.41 (313.8 examples/sec; 0.025 sec/batch; 1h:14m:38s remains)
INFO - root - 2022-02-24 19:32:09.764088: step 23830, total loss = 0.55, batch loss = 0.27 (181.6 examples/sec; 0.044 sec/batch; 2h:08m:59s remains)
INFO - root - 2022-02-24 19:32:10.598275: step 23840, total loss = 0.60, batch loss = 0.31 (147.1 examples/sec; 0.054 sec/batch; 2h:39m:13s remains)
INFO - root - 2022-02-24 19:32:11.102964: step 23850, total loss = 0.70, batch loss = 0.41 (187.3 examples/sec; 0.043 sec/batch; 2h:05m:03s remains)
INFO - root - 2022-02-24 19:32:11.418749: step 23860, total loss = 0.50, batch loss = 0.21 (341.8 examples/sec; 0.023 sec/batch; 1h:08m:30s remains)
INFO - root - 2022-02-24 19:32:11.826118: step 23870, total loss = 0.58, batch loss = 0.29 (330.5 examples/sec; 0.024 sec/batch; 1h:10m:51s remains)
INFO - root - 2022-02-24 19:32:12.140152: step 23880, total loss = 0.72, batch loss = 0.43 (344.4 examples/sec; 0.023 sec/batch; 1h:07m:59s remains)
INFO - root - 2022-02-24 19:32:12.582569: step 23890, total loss = 0.73, batch loss = 0.45 (247.5 examples/sec; 0.032 sec/batch; 1h:34m:35s remains)
INFO - root - 2022-02-24 19:32:12.963225: step 23900, total loss = 0.66, batch loss = 0.37 (113.6 examples/sec; 0.070 sec/batch; 3h:26m:06s remains)
INFO - root - 2022-02-24 19:32:13.463035: step 23910, total loss = 0.61, batch loss = 0.32 (205.8 examples/sec; 0.039 sec/batch; 1h:53m:45s remains)
INFO - root - 2022-02-24 19:32:13.852594: step 23920, total loss = 0.55, batch loss = 0.26 (217.4 examples/sec; 0.037 sec/batch; 1h:47m:40s remains)
INFO - root - 2022-02-24 19:32:14.221942: step 23930, total loss = 0.57, batch loss = 0.28 (245.6 examples/sec; 0.033 sec/batch; 1h:35m:17s remains)
INFO - root - 2022-02-24 19:32:14.682906: step 23940, total loss = 0.51, batch loss = 0.22 (177.4 examples/sec; 0.045 sec/batch; 2h:11m:58s remains)
INFO - root - 2022-02-24 19:32:15.234369: step 23950, total loss = 0.63, batch loss = 0.35 (187.7 examples/sec; 0.043 sec/batch; 2h:04m:41s remains)
INFO - root - 2022-02-24 19:32:15.637179: step 23960, total loss = 0.58, batch loss = 0.29 (235.1 examples/sec; 0.034 sec/batch; 1h:39m:33s remains)
INFO - root - 2022-02-24 19:32:15.918983: step 23970, total loss = 0.71, batch loss = 0.42 (254.5 examples/sec; 0.031 sec/batch; 1h:31m:56s remains)
INFO - root - 2022-02-24 19:32:16.306982: step 23980, total loss = 0.70, batch loss = 0.41 (282.8 examples/sec; 0.028 sec/batch; 1h:22m:45s remains)
INFO - root - 2022-02-24 19:32:16.635511: step 23990, total loss = 0.76, batch loss = 0.47 (368.6 examples/sec; 0.022 sec/batch; 1h:03m:29s remains)
INFO - root - 2022-02-24 19:32:17.093052: step 24000, total loss = 0.63, batch loss = 0.34 (238.7 examples/sec; 0.034 sec/batch; 1h:38m:02s remains)
INFO - root - 2022-02-24 19:32:17.574792: step 24010, total loss = 0.53, batch loss = 0.24 (143.2 examples/sec; 0.056 sec/batch; 2h:43m:25s remains)
INFO - root - 2022-02-24 19:32:17.995227: step 24020, total loss = 0.51, batch loss = 0.22 (211.3 examples/sec; 0.038 sec/batch; 1h:50m:42s remains)
INFO - root - 2022-02-24 19:32:18.319156: step 24030, total loss = 0.57, batch loss = 0.28 (290.0 examples/sec; 0.028 sec/batch; 1h:20m:40s remains)
INFO - root - 2022-02-24 19:32:18.723590: step 24040, total loss = 0.64, batch loss = 0.35 (324.2 examples/sec; 0.025 sec/batch; 1h:12m:09s remains)
INFO - root - 2022-02-24 19:32:19.095101: step 24050, total loss = 0.56, batch loss = 0.28 (234.1 examples/sec; 0.034 sec/batch; 1h:39m:56s remains)
INFO - root - 2022-02-24 19:32:19.517984: step 24060, total loss = 0.63, batch loss = 0.34 (345.6 examples/sec; 0.023 sec/batch; 1h:07m:41s remains)
INFO - root - 2022-02-24 19:32:19.889132: step 24070, total loss = 0.82, batch loss = 0.53 (148.1 examples/sec; 0.054 sec/batch; 2h:37m:54s remains)
INFO - root - 2022-02-24 19:32:20.323262: step 24080, total loss = 0.64, batch loss = 0.35 (273.0 examples/sec; 0.029 sec/batch; 1h:25m:41s remains)
INFO - root - 2022-02-24 19:32:20.626351: step 24090, total loss = 0.56, batch loss = 0.27 (250.7 examples/sec; 0.032 sec/batch; 1h:33m:17s remains)
INFO - root - 2022-02-24 19:32:21.071944: step 24100, total loss = 0.79, batch loss = 0.50 (140.7 examples/sec; 0.057 sec/batch; 2h:46m:12s remains)
INFO - root - 2022-02-24 19:32:21.454099: step 24110, total loss = 0.60, batch loss = 0.31 (329.2 examples/sec; 0.024 sec/batch; 1h:11m:02s remains)
INFO - root - 2022-02-24 19:32:21.855155: step 24120, total loss = 0.58, batch loss = 0.29 (258.3 examples/sec; 0.031 sec/batch; 1h:30m:30s remains)
INFO - root - 2022-02-24 19:32:22.271774: step 24130, total loss = 0.61, batch loss = 0.32 (115.3 examples/sec; 0.069 sec/batch; 3h:22m:45s remains)
INFO - root - 2022-02-24 19:32:22.743162: step 24140, total loss = 0.54, batch loss = 0.25 (187.7 examples/sec; 0.043 sec/batch; 2h:04m:33s remains)
INFO - root - 2022-02-24 19:32:23.106296: step 24150, total loss = 0.78, batch loss = 0.49 (136.4 examples/sec; 0.059 sec/batch; 2h:51m:22s remains)
INFO - root - 2022-02-24 19:32:23.552415: step 24160, total loss = 0.71, batch loss = 0.42 (302.9 examples/sec; 0.026 sec/batch; 1h:17m:11s remains)
INFO - root - 2022-02-24 19:32:24.083254: step 24170, total loss = 0.69, batch loss = 0.40 (348.7 examples/sec; 0.023 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 19:32:24.646677: step 24180, total loss = 0.72, batch loss = 0.43 (342.3 examples/sec; 0.023 sec/batch; 1h:08m:17s remains)
INFO - root - 2022-02-24 19:32:25.484303: step 24190, total loss = 0.67, batch loss = 0.38 (136.7 examples/sec; 0.059 sec/batch; 2h:51m:03s remains)
INFO - root - 2022-02-24 19:32:25.939332: step 24200, total loss = 0.56, batch loss = 0.27 (105.8 examples/sec; 0.076 sec/batch; 3h:40m:58s remains)
INFO - root - 2022-02-24 19:32:26.376378: step 24210, total loss = 0.61, batch loss = 0.32 (185.7 examples/sec; 0.043 sec/batch; 2h:05m:51s remains)
INFO - root - 2022-02-24 19:32:26.742540: step 24220, total loss = 0.59, batch loss = 0.30 (245.5 examples/sec; 0.033 sec/batch; 1h:35m:11s remains)
INFO - root - 2022-02-24 19:32:27.264555: step 24230, total loss = 0.60, batch loss = 0.32 (120.0 examples/sec; 0.067 sec/batch; 3h:14m:48s remains)
INFO - root - 2022-02-24 19:32:27.675907: step 24240, total loss = 0.72, batch loss = 0.43 (316.3 examples/sec; 0.025 sec/batch; 1h:13m:52s remains)
INFO - root - 2022-02-24 19:32:28.117072: step 24250, total loss = 0.52, batch loss = 0.23 (201.0 examples/sec; 0.040 sec/batch; 1h:56m:14s remains)
INFO - root - 2022-02-24 19:32:28.596703: step 24260, total loss = 0.57, batch loss = 0.28 (208.3 examples/sec; 0.038 sec/batch; 1h:52m:11s remains)
INFO - root - 2022-02-24 19:32:29.051225: step 24270, total loss = 0.52, batch loss = 0.23 (332.3 examples/sec; 0.024 sec/batch; 1h:10m:18s remains)
INFO - root - 2022-02-24 19:32:29.459810: step 24280, total loss = 0.69, batch loss = 0.40 (295.9 examples/sec; 0.027 sec/batch; 1h:18m:57s remains)
INFO - root - 2022-02-24 19:32:29.864044: step 24290, total loss = 0.72, batch loss = 0.43 (240.7 examples/sec; 0.033 sec/batch; 1h:37m:03s remains)
INFO - root - 2022-02-24 19:32:30.359459: step 24300, total loss = 0.57, batch loss = 0.28 (163.9 examples/sec; 0.049 sec/batch; 2h:22m:31s remains)
INFO - root - 2022-02-24 19:32:31.127410: step 24310, total loss = 0.59, batch loss = 0.30 (295.7 examples/sec; 0.027 sec/batch; 1h:19m:00s remains)
INFO - root - 2022-02-24 19:32:31.541053: step 24320, total loss = 0.65, batch loss = 0.36 (156.7 examples/sec; 0.051 sec/batch; 2h:29m:05s remains)
INFO - root - 2022-02-24 19:32:31.903866: step 24330, total loss = 0.67, batch loss = 0.38 (184.7 examples/sec; 0.043 sec/batch; 2h:06m:28s remains)
INFO - root - 2022-02-24 19:32:32.374904: step 24340, total loss = 0.60, batch loss = 0.31 (220.7 examples/sec; 0.036 sec/batch; 1h:45m:49s remains)
INFO - root - 2022-02-24 19:32:32.750170: step 24350, total loss = 0.65, batch loss = 0.36 (335.2 examples/sec; 0.024 sec/batch; 1h:09m:40s remains)
INFO - root - 2022-02-24 19:32:33.178815: step 24360, total loss = 0.57, batch loss = 0.28 (281.1 examples/sec; 0.028 sec/batch; 1h:23m:04s remains)
INFO - root - 2022-02-24 19:32:33.604738: step 24370, total loss = 0.58, batch loss = 0.29 (346.8 examples/sec; 0.023 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 19:32:33.953239: step 24380, total loss = 0.65, batch loss = 0.36 (349.0 examples/sec; 0.023 sec/batch; 1h:06m:54s remains)
INFO - root - 2022-02-24 19:32:34.407013: step 24390, total loss = 0.73, batch loss = 0.45 (313.5 examples/sec; 0.026 sec/batch; 1h:14m:28s remains)
INFO - root - 2022-02-24 19:32:34.869968: step 24400, total loss = 0.71, batch loss = 0.42 (339.9 examples/sec; 0.024 sec/batch; 1h:08m:41s remains)
INFO - root - 2022-02-24 19:32:35.296892: step 24410, total loss = 0.55, batch loss = 0.26 (173.9 examples/sec; 0.046 sec/batch; 2h:14m:14s remains)
INFO - root - 2022-02-24 19:32:35.715975: step 24420, total loss = 0.69, batch loss = 0.40 (275.9 examples/sec; 0.029 sec/batch; 1h:24m:36s remains)
INFO - root - 2022-02-24 19:32:36.023401: step 24430, total loss = 0.58, batch loss = 0.29 (212.5 examples/sec; 0.038 sec/batch; 1h:49m:50s remains)
INFO - root - 2022-02-24 19:32:36.342187: step 24440, total loss = 0.62, batch loss = 0.33 (244.5 examples/sec; 0.033 sec/batch; 1h:35m:27s remains)
INFO - root - 2022-02-24 19:32:36.832852: step 24450, total loss = 0.56, batch loss = 0.27 (179.8 examples/sec; 0.044 sec/batch; 2h:09m:46s remains)
INFO - root - 2022-02-24 19:32:37.243287: step 24460, total loss = 0.59, batch loss = 0.30 (345.5 examples/sec; 0.023 sec/batch; 1h:07m:32s remains)
INFO - root - 2022-02-24 19:32:37.615206: step 24470, total loss = 0.55, batch loss = 0.26 (236.5 examples/sec; 0.034 sec/batch; 1h:38m:41s remains)
INFO - root - 2022-02-24 19:32:37.993588: step 24480, total loss = 0.58, batch loss = 0.30 (187.3 examples/sec; 0.043 sec/batch; 2h:04m:37s remains)
INFO - root - 2022-02-24 19:32:38.380681: step 24490, total loss = 0.67, batch loss = 0.38 (107.1 examples/sec; 0.075 sec/batch; 3h:37m:54s remains)
INFO - root - 2022-02-24 19:32:38.853199: step 24500, total loss = 0.66, batch loss = 0.37 (98.3 examples/sec; 0.081 sec/batch; 3h:57m:16s remains)
INFO - root - 2022-02-24 19:32:39.302989: step 24510, total loss = 0.61, batch loss = 0.32 (337.9 examples/sec; 0.024 sec/batch; 1h:09m:02s remains)
INFO - root - 2022-02-24 19:32:39.730086: step 24520, total loss = 0.58, batch loss = 0.29 (360.5 examples/sec; 0.022 sec/batch; 1h:04m:43s remains)
INFO - root - 2022-02-24 19:32:40.052659: step 24530, total loss = 0.59, batch loss = 0.30 (342.7 examples/sec; 0.023 sec/batch; 1h:08m:04s remains)
INFO - root - 2022-02-24 19:32:40.464031: step 24540, total loss = 0.53, batch loss = 0.25 (82.6 examples/sec; 0.097 sec/batch; 4h:42m:34s remains)
INFO - root - 2022-02-24 19:32:40.868380: step 24550, total loss = 0.60, batch loss = 0.31 (134.2 examples/sec; 0.060 sec/batch; 2h:53m:52s remains)
INFO - root - 2022-02-24 19:32:41.245158: step 24560, total loss = 0.56, batch loss = 0.28 (312.7 examples/sec; 0.026 sec/batch; 1h:14m:35s remains)
INFO - root - 2022-02-24 19:32:41.717727: step 24570, total loss = 0.64, batch loss = 0.35 (181.8 examples/sec; 0.044 sec/batch; 2h:08m:18s remains)
INFO - root - 2022-02-24 19:32:42.078573: step 24580, total loss = 0.61, batch loss = 0.33 (155.2 examples/sec; 0.052 sec/batch; 2h:30m:17s remains)
INFO - root - 2022-02-24 19:32:42.375618: step 24590, total loss = 0.65, batch loss = 0.36 (339.2 examples/sec; 0.024 sec/batch; 1h:08m:45s remains)
INFO - root - 2022-02-24 19:32:42.793901: step 24600, total loss = 0.52, batch loss = 0.24 (254.3 examples/sec; 0.031 sec/batch; 1h:31m:41s remains)
INFO - root - 2022-02-24 19:32:43.282797: step 24610, total loss = 0.56, batch loss = 0.27 (235.2 examples/sec; 0.034 sec/batch; 1h:39m:08s remains)
INFO - root - 2022-02-24 19:32:43.699582: step 24620, total loss = 0.60, batch loss = 0.31 (180.7 examples/sec; 0.044 sec/batch; 2h:09m:03s remains)
INFO - root - 2022-02-24 19:32:44.274393: step 24630, total loss = 0.66, batch loss = 0.37 (243.3 examples/sec; 0.033 sec/batch; 1h:35m:50s remains)
INFO - root - 2022-02-24 19:32:44.928414: step 24640, total loss = 0.63, batch loss = 0.34 (307.7 examples/sec; 0.026 sec/batch; 1h:15m:46s remains)
INFO - root - 2022-02-24 19:32:45.509903: step 24650, total loss = 0.67, batch loss = 0.38 (235.2 examples/sec; 0.034 sec/batch; 1h:39m:08s remains)
INFO - root - 2022-02-24 19:32:46.481494: step 24660, total loss = 0.64, batch loss = 0.35 (314.7 examples/sec; 0.025 sec/batch; 1h:14m:05s remains)
INFO - root - 2022-02-24 19:32:46.897646: step 24670, total loss = 0.60, batch loss = 0.31 (243.9 examples/sec; 0.033 sec/batch; 1h:35m:33s remains)
INFO - root - 2022-02-24 19:32:47.225122: step 24680, total loss = 0.71, batch loss = 0.42 (317.0 examples/sec; 0.025 sec/batch; 1h:13m:32s remains)
INFO - root - 2022-02-24 19:32:47.667211: step 24690, total loss = 0.60, batch loss = 0.31 (176.5 examples/sec; 0.045 sec/batch; 2h:12m:03s remains)
INFO - root - 2022-02-24 19:32:48.169313: step 24700, total loss = 0.67, batch loss = 0.39 (145.2 examples/sec; 0.055 sec/batch; 2h:40m:31s remains)
INFO - root - 2022-02-24 19:32:48.619264: step 24710, total loss = 0.58, batch loss = 0.30 (181.2 examples/sec; 0.044 sec/batch; 2h:08m:36s remains)
INFO - root - 2022-02-24 19:32:49.004224: step 24720, total loss = 0.53, batch loss = 0.24 (230.9 examples/sec; 0.035 sec/batch; 1h:40m:54s remains)
INFO - root - 2022-02-24 19:32:49.338467: step 24730, total loss = 0.61, batch loss = 0.32 (344.0 examples/sec; 0.023 sec/batch; 1h:07m:44s remains)
INFO - root - 2022-02-24 19:32:49.728414: step 24740, total loss = 0.67, batch loss = 0.38 (245.2 examples/sec; 0.033 sec/batch; 1h:35m:02s remains)
INFO - root - 2022-02-24 19:32:50.093307: step 24750, total loss = 0.70, batch loss = 0.41 (293.7 examples/sec; 0.027 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 19:32:50.566337: step 24760, total loss = 0.63, batch loss = 0.35 (201.3 examples/sec; 0.040 sec/batch; 1h:55m:43s remains)
INFO - root - 2022-02-24 19:32:50.978368: step 24770, total loss = 0.71, batch loss = 0.42 (267.8 examples/sec; 0.030 sec/batch; 1h:26m:58s remains)
INFO - root - 2022-02-24 19:32:51.601998: step 24780, total loss = 0.57, batch loss = 0.28 (172.5 examples/sec; 0.046 sec/batch; 2h:15m:05s remains)
INFO - root - 2022-02-24 19:32:52.076696: step 24790, total loss = 0.63, batch loss = 0.34 (129.0 examples/sec; 0.062 sec/batch; 3h:00m:32s remains)
INFO - root - 2022-02-24 19:32:52.528352: step 24800, total loss = 0.61, batch loss = 0.32 (277.1 examples/sec; 0.029 sec/batch; 1h:24m:04s remains)
INFO - root - 2022-02-24 19:32:52.942188: step 24810, total loss = 0.52, batch loss = 0.23 (208.9 examples/sec; 0.038 sec/batch; 1h:51m:29s remains)
INFO - root - 2022-02-24 19:32:53.257957: step 24820, total loss = 0.58, batch loss = 0.29 (223.9 examples/sec; 0.036 sec/batch; 1h:44m:00s remains)
INFO - root - 2022-02-24 19:32:53.567171: step 24830, total loss = 0.53, batch loss = 0.25 (321.0 examples/sec; 0.025 sec/batch; 1h:12m:33s remains)
INFO - root - 2022-02-24 19:32:54.003418: step 24840, total loss = 0.54, batch loss = 0.25 (95.2 examples/sec; 0.084 sec/batch; 4h:04m:38s remains)
INFO - root - 2022-02-24 19:32:54.440898: step 24850, total loss = 0.56, batch loss = 0.27 (297.2 examples/sec; 0.027 sec/batch; 1h:18m:21s remains)
INFO - root - 2022-02-24 19:32:54.899561: step 24860, total loss = 0.50, batch loss = 0.21 (178.9 examples/sec; 0.045 sec/batch; 2h:10m:08s remains)
INFO - root - 2022-02-24 19:32:55.266925: step 24870, total loss = 0.51, batch loss = 0.23 (373.4 examples/sec; 0.021 sec/batch; 1h:02m:21s remains)
INFO - root - 2022-02-24 19:32:55.674791: step 24880, total loss = 0.60, batch loss = 0.31 (152.8 examples/sec; 0.052 sec/batch; 2h:32m:21s remains)
INFO - root - 2022-02-24 19:32:56.194293: step 24890, total loss = 0.64, batch loss = 0.35 (213.3 examples/sec; 0.038 sec/batch; 1h:49m:08s remains)
INFO - root - 2022-02-24 19:32:56.639712: step 24900, total loss = 0.65, batch loss = 0.36 (361.5 examples/sec; 0.022 sec/batch; 1h:04m:24s remains)
INFO - root - 2022-02-24 19:32:57.015561: step 24910, total loss = 0.67, batch loss = 0.38 (323.9 examples/sec; 0.025 sec/batch; 1h:11m:51s remains)
INFO - root - 2022-02-24 19:32:57.380168: step 24920, total loss = 0.59, batch loss = 0.30 (185.3 examples/sec; 0.043 sec/batch; 2h:05m:36s remains)
INFO - root - 2022-02-24 19:32:57.780717: step 24930, total loss = 0.68, batch loss = 0.39 (251.3 examples/sec; 0.032 sec/batch; 1h:32m:37s remains)
INFO - root - 2022-02-24 19:32:58.288230: step 24940, total loss = 0.64, batch loss = 0.35 (271.1 examples/sec; 0.030 sec/batch; 1h:25m:51s remains)
INFO - root - 2022-02-24 19:32:58.677286: step 24950, total loss = 0.57, batch loss = 0.29 (335.0 examples/sec; 0.024 sec/batch; 1h:09m:27s remains)
INFO - root - 2022-02-24 19:32:59.029024: step 24960, total loss = 0.62, batch loss = 0.33 (311.2 examples/sec; 0.026 sec/batch; 1h:14m:46s remains)
INFO - root - 2022-02-24 19:32:59.346960: step 24970, total loss = 0.51, batch loss = 0.23 (253.5 examples/sec; 0.032 sec/batch; 1h:31m:47s remains)
INFO - root - 2022-02-24 19:32:59.884668: step 24980, total loss = 0.61, batch loss = 0.32 (139.3 examples/sec; 0.057 sec/batch; 2h:47m:01s remains)
INFO - root - 2022-02-24 19:33:00.408811: step 24990, total loss = 0.59, batch loss = 0.30 (268.6 examples/sec; 0.030 sec/batch; 1h:26m:36s remains)
INFO - root - 2022-02-24 19:33:00.824445: step 25000, total loss = 0.53, batch loss = 0.24 (220.0 examples/sec; 0.036 sec/batch; 1h:45m:45s remains)
INFO - root - 2022-02-24 19:33:01.242701: step 25010, total loss = 0.59, batch loss = 0.30 (248.1 examples/sec; 0.032 sec/batch; 1h:33m:47s remains)
INFO - root - 2022-02-24 19:33:01.644141: step 25020, total loss = 0.53, batch loss = 0.25 (203.9 examples/sec; 0.039 sec/batch; 1h:54m:05s remains)
INFO - root - 2022-02-24 19:33:02.058177: step 25030, total loss = 0.63, batch loss = 0.34 (178.0 examples/sec; 0.045 sec/batch; 2h:10m:39s remains)
INFO - root - 2022-02-24 19:33:02.560302: step 25040, total loss = 0.68, batch loss = 0.39 (111.4 examples/sec; 0.072 sec/batch; 3h:28m:48s remains)
INFO - root - 2022-02-24 19:33:03.083974: step 25050, total loss = 0.56, batch loss = 0.27 (204.0 examples/sec; 0.039 sec/batch; 1h:53m:59s remains)
INFO - root - 2022-02-24 19:33:03.661818: step 25060, total loss = 0.60, batch loss = 0.31 (318.7 examples/sec; 0.025 sec/batch; 1h:12m:58s remains)
INFO - root - 2022-02-24 19:33:04.192327: step 25070, total loss = 0.61, batch loss = 0.32 (197.8 examples/sec; 0.040 sec/batch; 1h:57m:33s remains)
INFO - root - 2022-02-24 19:33:04.708456: step 25080, total loss = 0.80, batch loss = 0.52 (117.7 examples/sec; 0.068 sec/batch; 3h:17m:38s remains)
INFO - root - 2022-02-24 19:33:05.360273: step 25090, total loss = 0.55, batch loss = 0.26 (249.9 examples/sec; 0.032 sec/batch; 1h:33m:02s remains)
INFO - root - 2022-02-24 19:33:05.852235: step 25100, total loss = 0.57, batch loss = 0.28 (152.0 examples/sec; 0.053 sec/batch; 2h:33m:00s remains)
INFO - root - 2022-02-24 19:33:06.350930: step 25110, total loss = 0.60, batch loss = 0.31 (312.8 examples/sec; 0.026 sec/batch; 1h:14m:20s remains)
INFO - root - 2022-02-24 19:33:07.183572: step 25120, total loss = 0.59, batch loss = 0.31 (321.9 examples/sec; 0.025 sec/batch; 1h:12m:13s remains)
INFO - root - 2022-02-24 19:33:07.512079: step 25130, total loss = 0.53, batch loss = 0.24 (236.4 examples/sec; 0.034 sec/batch; 1h:38m:20s remains)
INFO - root - 2022-02-24 19:33:07.971338: step 25140, total loss = 0.60, batch loss = 0.32 (121.9 examples/sec; 0.066 sec/batch; 3h:10m:43s remains)
INFO - root - 2022-02-24 19:33:08.391436: step 25150, total loss = 0.79, batch loss = 0.50 (257.2 examples/sec; 0.031 sec/batch; 1h:30m:22s remains)
INFO - root - 2022-02-24 19:33:08.727315: step 25160, total loss = 0.56, batch loss = 0.28 (342.2 examples/sec; 0.023 sec/batch; 1h:07m:56s remains)
INFO - root - 2022-02-24 19:33:09.019687: step 25170, total loss = 0.58, batch loss = 0.29 (259.1 examples/sec; 0.031 sec/batch; 1h:29m:42s remains)
INFO - root - 2022-02-24 19:33:09.391811: step 25180, total loss = 0.61, batch loss = 0.33 (282.6 examples/sec; 0.028 sec/batch; 1h:22m:13s remains)
INFO - root - 2022-02-24 19:33:09.771653: step 25190, total loss = 0.58, batch loss = 0.29 (199.5 examples/sec; 0.040 sec/batch; 1h:56m:30s remains)
INFO - root - 2022-02-24 19:33:10.155632: step 25200, total loss = 0.73, batch loss = 0.44 (245.8 examples/sec; 0.033 sec/batch; 1h:34m:33s remains)
INFO - root - 2022-02-24 19:33:10.734530: step 25210, total loss = 0.58, batch loss = 0.29 (333.2 examples/sec; 0.024 sec/batch; 1h:09m:44s remains)
INFO - root - 2022-02-24 19:33:11.195591: step 25220, total loss = 0.76, batch loss = 0.47 (259.3 examples/sec; 0.031 sec/batch; 1h:29m:35s remains)
INFO - root - 2022-02-24 19:33:11.667626: step 25230, total loss = 0.60, batch loss = 0.31 (333.2 examples/sec; 0.024 sec/batch; 1h:09m:44s remains)
INFO - root - 2022-02-24 19:33:12.245841: step 25240, total loss = 0.53, batch loss = 0.24 (218.3 examples/sec; 0.037 sec/batch; 1h:46m:25s remains)
INFO - root - 2022-02-24 19:33:12.724368: step 25250, total loss = 0.64, batch loss = 0.35 (149.4 examples/sec; 0.054 sec/batch; 2h:35m:29s remains)
INFO - root - 2022-02-24 19:33:13.127564: step 25260, total loss = 0.65, batch loss = 0.36 (166.9 examples/sec; 0.048 sec/batch; 2h:19m:09s remains)
INFO - root - 2022-02-24 19:33:13.755742: step 25270, total loss = 0.71, batch loss = 0.42 (136.9 examples/sec; 0.058 sec/batch; 2h:49m:44s remains)
INFO - root - 2022-02-24 19:33:14.272913: step 25280, total loss = 0.59, batch loss = 0.30 (141.3 examples/sec; 0.057 sec/batch; 2h:44m:23s remains)
INFO - root - 2022-02-24 19:33:14.617436: step 25290, total loss = 0.74, batch loss = 0.46 (254.0 examples/sec; 0.031 sec/batch; 1h:31m:27s remains)
INFO - root - 2022-02-24 19:33:14.982374: step 25300, total loss = 0.64, batch loss = 0.35 (280.4 examples/sec; 0.029 sec/batch; 1h:22m:50s remains)
INFO - root - 2022-02-24 19:33:15.501456: step 25310, total loss = 0.56, batch loss = 0.27 (85.2 examples/sec; 0.094 sec/batch; 4h:32m:35s remains)
INFO - root - 2022-02-24 19:33:15.956332: step 25320, total loss = 0.58, batch loss = 0.30 (131.2 examples/sec; 0.061 sec/batch; 2h:56m:57s remains)
INFO - root - 2022-02-24 19:33:16.374335: step 25330, total loss = 0.60, batch loss = 0.32 (258.6 examples/sec; 0.031 sec/batch; 1h:29m:47s remains)
INFO - root - 2022-02-24 19:33:16.753287: step 25340, total loss = 0.53, batch loss = 0.24 (118.3 examples/sec; 0.068 sec/batch; 3h:16m:21s remains)
INFO - root - 2022-02-24 19:33:17.121538: step 25350, total loss = 0.57, batch loss = 0.28 (174.9 examples/sec; 0.046 sec/batch; 2h:12m:44s remains)
INFO - root - 2022-02-24 19:33:17.558134: step 25360, total loss = 0.59, batch loss = 0.30 (274.4 examples/sec; 0.029 sec/batch; 1h:24m:36s remains)
INFO - root - 2022-02-24 19:33:17.978555: step 25370, total loss = 0.60, batch loss = 0.31 (213.6 examples/sec; 0.037 sec/batch; 1h:48m:41s remains)
INFO - root - 2022-02-24 19:33:18.390226: step 25380, total loss = 0.64, batch loss = 0.35 (184.0 examples/sec; 0.043 sec/batch; 2h:06m:09s remains)
INFO - root - 2022-02-24 19:33:18.767845: step 25390, total loss = 0.58, batch loss = 0.29 (110.4 examples/sec; 0.072 sec/batch; 3h:30m:19s remains)
INFO - root - 2022-02-24 19:33:19.160109: step 25400, total loss = 0.65, batch loss = 0.36 (322.1 examples/sec; 0.025 sec/batch; 1h:12m:03s remains)
INFO - root - 2022-02-24 19:33:19.646704: step 25410, total loss = 0.58, batch loss = 0.29 (195.9 examples/sec; 0.041 sec/batch; 1h:58m:28s remains)
INFO - root - 2022-02-24 19:33:20.139664: step 25420, total loss = 0.67, batch loss = 0.38 (259.7 examples/sec; 0.031 sec/batch; 1h:29m:23s remains)
INFO - root - 2022-02-24 19:33:20.632675: step 25430, total loss = 0.66, batch loss = 0.37 (182.5 examples/sec; 0.044 sec/batch; 2h:07m:12s remains)
INFO - root - 2022-02-24 19:33:21.053963: step 25440, total loss = 0.55, batch loss = 0.26 (232.4 examples/sec; 0.034 sec/batch; 1h:39m:51s remains)
INFO - root - 2022-02-24 19:33:21.431135: step 25450, total loss = 0.64, batch loss = 0.35 (197.6 examples/sec; 0.040 sec/batch; 1h:57m:27s remains)
INFO - root - 2022-02-24 19:33:21.932492: step 25460, total loss = 0.61, batch loss = 0.32 (230.7 examples/sec; 0.035 sec/batch; 1h:40m:34s remains)
INFO - root - 2022-02-24 19:33:22.746517: step 25470, total loss = 0.51, batch loss = 0.22 (246.7 examples/sec; 0.032 sec/batch; 1h:34m:02s remains)
INFO - root - 2022-02-24 19:33:23.295419: step 25480, total loss = 0.51, batch loss = 0.22 (172.7 examples/sec; 0.046 sec/batch; 2h:14m:19s remains)
INFO - root - 2022-02-24 19:33:23.631970: step 25490, total loss = 0.57, batch loss = 0.29 (306.9 examples/sec; 0.026 sec/batch; 1h:15m:35s remains)
INFO - root - 2022-02-24 19:33:24.073329: step 25500, total loss = 0.49, batch loss = 0.20 (135.9 examples/sec; 0.059 sec/batch; 2h:50m:45s remains)
INFO - root - 2022-02-24 19:33:24.538820: step 25510, total loss = 0.69, batch loss = 0.40 (121.6 examples/sec; 0.066 sec/batch; 3h:10m:43s remains)
INFO - root - 2022-02-24 19:33:25.004923: step 25520, total loss = 0.53, batch loss = 0.25 (121.8 examples/sec; 0.066 sec/batch; 3h:10m:30s remains)
INFO - root - 2022-02-24 19:33:25.457954: step 25530, total loss = 0.56, batch loss = 0.28 (93.7 examples/sec; 0.085 sec/batch; 4h:07m:31s remains)
INFO - root - 2022-02-24 19:33:25.918281: step 25540, total loss = 0.54, batch loss = 0.25 (266.9 examples/sec; 0.030 sec/batch; 1h:26m:54s remains)
INFO - root - 2022-02-24 19:33:26.429792: step 25550, total loss = 0.53, batch loss = 0.25 (115.0 examples/sec; 0.070 sec/batch; 3h:21m:37s remains)
INFO - root - 2022-02-24 19:33:26.899538: step 25560, total loss = 0.62, batch loss = 0.33 (110.4 examples/sec; 0.072 sec/batch; 3h:29m:58s remains)
INFO - root - 2022-02-24 19:33:27.325357: step 25570, total loss = 0.56, batch loss = 0.27 (189.5 examples/sec; 0.042 sec/batch; 2h:02m:24s remains)
INFO - root - 2022-02-24 19:33:28.106472: step 25580, total loss = 0.59, batch loss = 0.31 (155.7 examples/sec; 0.051 sec/batch; 2h:28m:57s remains)
INFO - root - 2022-02-24 19:33:28.558536: step 25590, total loss = 0.57, batch loss = 0.28 (179.1 examples/sec; 0.045 sec/batch; 2h:09m:29s remains)
INFO - root - 2022-02-24 19:33:28.884205: step 25600, total loss = 0.55, batch loss = 0.26 (173.2 examples/sec; 0.046 sec/batch; 2h:13m:54s remains)
INFO - root - 2022-02-24 19:33:29.423805: step 25610, total loss = 0.54, batch loss = 0.25 (216.1 examples/sec; 0.037 sec/batch; 1h:47m:16s remains)
INFO - root - 2022-02-24 19:33:29.770155: step 25620, total loss = 0.64, batch loss = 0.35 (349.8 examples/sec; 0.023 sec/batch; 1h:06m:17s remains)
INFO - root - 2022-02-24 19:33:30.133652: step 25630, total loss = 0.53, batch loss = 0.25 (350.2 examples/sec; 0.023 sec/batch; 1h:06m:11s remains)
INFO - root - 2022-02-24 19:33:30.462042: step 25640, total loss = 0.54, batch loss = 0.25 (205.5 examples/sec; 0.039 sec/batch; 1h:52m:47s remains)
INFO - root - 2022-02-24 19:33:31.034804: step 25650, total loss = 0.59, batch loss = 0.30 (140.2 examples/sec; 0.057 sec/batch; 2h:45m:19s remains)
INFO - root - 2022-02-24 19:33:31.460732: step 25660, total loss = 0.59, batch loss = 0.30 (302.1 examples/sec; 0.026 sec/batch; 1h:16m:44s remains)
INFO - root - 2022-02-24 19:33:31.850798: step 25670, total loss = 0.69, batch loss = 0.40 (327.3 examples/sec; 0.024 sec/batch; 1h:10m:48s remains)
INFO - root - 2022-02-24 19:33:32.246726: step 25680, total loss = 0.52, batch loss = 0.24 (197.1 examples/sec; 0.041 sec/batch; 1h:57m:35s remains)
INFO - root - 2022-02-24 19:33:32.572980: step 25690, total loss = 0.65, batch loss = 0.36 (332.9 examples/sec; 0.024 sec/batch; 1h:09m:37s remains)
INFO - root - 2022-02-24 19:33:33.042712: step 25700, total loss = 0.66, batch loss = 0.38 (361.8 examples/sec; 0.022 sec/batch; 1h:04m:02s remains)
INFO - root - 2022-02-24 19:33:33.490809: step 25710, total loss = 0.61, batch loss = 0.32 (254.4 examples/sec; 0.031 sec/batch; 1h:31m:05s remains)
INFO - root - 2022-02-24 19:33:33.905075: step 25720, total loss = 0.60, batch loss = 0.32 (308.4 examples/sec; 0.026 sec/batch; 1h:15m:08s remains)
INFO - root - 2022-02-24 19:33:34.239300: step 25730, total loss = 0.56, batch loss = 0.27 (309.0 examples/sec; 0.026 sec/batch; 1h:14m:59s remains)
INFO - root - 2022-02-24 19:33:34.601562: step 25740, total loss = 0.57, batch loss = 0.28 (329.1 examples/sec; 0.024 sec/batch; 1h:10m:23s remains)
INFO - root - 2022-02-24 19:33:35.057230: step 25750, total loss = 0.64, batch loss = 0.36 (264.2 examples/sec; 0.030 sec/batch; 1h:27m:40s remains)
INFO - root - 2022-02-24 19:33:35.529075: step 25760, total loss = 0.59, batch loss = 0.31 (302.6 examples/sec; 0.026 sec/batch; 1h:16m:32s remains)
INFO - root - 2022-02-24 19:33:35.927153: step 25770, total loss = 0.74, batch loss = 0.45 (133.4 examples/sec; 0.060 sec/batch; 2h:53m:40s remains)
INFO - root - 2022-02-24 19:33:36.323048: step 25780, total loss = 0.54, batch loss = 0.25 (162.2 examples/sec; 0.049 sec/batch; 2h:22m:46s remains)
INFO - root - 2022-02-24 19:33:36.677679: step 25790, total loss = 0.54, batch loss = 0.25 (311.7 examples/sec; 0.026 sec/batch; 1h:14m:17s remains)
INFO - root - 2022-02-24 19:33:37.055756: step 25800, total loss = 0.63, batch loss = 0.34 (233.8 examples/sec; 0.034 sec/batch; 1h:39m:04s remains)
INFO - root - 2022-02-24 19:33:37.542965: step 25810, total loss = 0.58, batch loss = 0.30 (291.9 examples/sec; 0.027 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 19:33:38.013776: step 25820, total loss = 0.54, batch loss = 0.26 (119.6 examples/sec; 0.067 sec/batch; 3h:13m:41s remains)
INFO - root - 2022-02-24 19:33:38.516235: step 25830, total loss = 0.62, batch loss = 0.33 (195.7 examples/sec; 0.041 sec/batch; 1h:58m:19s remains)
INFO - root - 2022-02-24 19:33:38.877534: step 25840, total loss = 0.58, batch loss = 0.29 (209.0 examples/sec; 0.038 sec/batch; 1h:50m:46s remains)
INFO - root - 2022-02-24 19:33:39.233374: step 25850, total loss = 0.58, batch loss = 0.29 (318.5 examples/sec; 0.025 sec/batch; 1h:12m:42s remains)
INFO - root - 2022-02-24 19:33:39.616921: step 25860, total loss = 0.52, batch loss = 0.23 (335.2 examples/sec; 0.024 sec/batch; 1h:09m:03s remains)
INFO - root - 2022-02-24 19:33:40.065344: step 25870, total loss = 0.57, batch loss = 0.28 (189.5 examples/sec; 0.042 sec/batch; 2h:02m:10s remains)
INFO - root - 2022-02-24 19:33:40.478577: step 25880, total loss = 0.58, batch loss = 0.30 (157.9 examples/sec; 0.051 sec/batch; 2h:26m:36s remains)
INFO - root - 2022-02-24 19:33:40.864303: step 25890, total loss = 0.54, batch loss = 0.25 (201.1 examples/sec; 0.040 sec/batch; 1h:55m:05s remains)
INFO - root - 2022-02-24 19:33:41.315953: step 25900, total loss = 0.58, batch loss = 0.29 (109.2 examples/sec; 0.073 sec/batch; 3h:31m:52s remains)
INFO - root - 2022-02-24 19:33:41.818884: step 25910, total loss = 0.56, batch loss = 0.28 (254.8 examples/sec; 0.031 sec/batch; 1h:30m:50s remains)
INFO - root - 2022-02-24 19:33:42.403066: step 25920, total loss = 0.69, batch loss = 0.41 (151.0 examples/sec; 0.053 sec/batch; 2h:33m:14s remains)
INFO - root - 2022-02-24 19:33:42.908373: step 25930, total loss = 0.70, batch loss = 0.41 (165.1 examples/sec; 0.048 sec/batch; 2h:20m:11s remains)
INFO - root - 2022-02-24 19:33:43.747082: step 25940, total loss = 0.61, batch loss = 0.33 (156.9 examples/sec; 0.051 sec/batch; 2h:27m:31s remains)
INFO - root - 2022-02-24 19:33:44.157208: step 25950, total loss = 0.53, batch loss = 0.24 (176.4 examples/sec; 0.045 sec/batch; 2h:11m:12s remains)
INFO - root - 2022-02-24 19:33:44.665081: step 25960, total loss = 0.73, batch loss = 0.44 (175.0 examples/sec; 0.046 sec/batch; 2h:12m:12s remains)
INFO - root - 2022-02-24 19:33:45.154011: step 25970, total loss = 0.59, batch loss = 0.30 (196.0 examples/sec; 0.041 sec/batch; 1h:58m:04s remains)
INFO - root - 2022-02-24 19:33:45.714807: step 25980, total loss = 0.61, batch loss = 0.32 (169.2 examples/sec; 0.047 sec/batch; 2h:16m:44s remains)
INFO - root - 2022-02-24 19:33:46.107664: step 25990, total loss = 0.61, batch loss = 0.32 (226.4 examples/sec; 0.035 sec/batch; 1h:42m:10s remains)
INFO - root - 2022-02-24 19:33:46.598541: step 26000, total loss = 0.60, batch loss = 0.31 (137.2 examples/sec; 0.058 sec/batch; 2h:48m:35s remains)
INFO - root - 2022-02-24 19:33:47.049041: step 26010, total loss = 0.64, batch loss = 0.35 (304.8 examples/sec; 0.026 sec/batch; 1h:15m:53s remains)
INFO - root - 2022-02-24 19:33:47.461840: step 26020, total loss = 0.59, batch loss = 0.31 (287.7 examples/sec; 0.028 sec/batch; 1h:20m:23s remains)
INFO - root - 2022-02-24 19:33:47.934178: step 26030, total loss = 0.59, batch loss = 0.30 (155.2 examples/sec; 0.052 sec/batch; 2h:28m:58s remains)
INFO - root - 2022-02-24 19:33:48.768809: step 26040, total loss = 0.70, batch loss = 0.42 (272.4 examples/sec; 0.029 sec/batch; 1h:24m:55s remains)
INFO - root - 2022-02-24 19:33:49.204414: step 26050, total loss = 0.62, batch loss = 0.33 (136.8 examples/sec; 0.058 sec/batch; 2h:49m:02s remains)
INFO - root - 2022-02-24 19:33:49.559044: step 26060, total loss = 0.54, batch loss = 0.25 (270.1 examples/sec; 0.030 sec/batch; 1h:25m:37s remains)
INFO - root - 2022-02-24 19:33:49.928790: step 26070, total loss = 0.53, batch loss = 0.24 (90.2 examples/sec; 0.089 sec/batch; 4h:16m:18s remains)
INFO - root - 2022-02-24 19:33:50.449569: step 26080, total loss = 0.74, batch loss = 0.45 (180.8 examples/sec; 0.044 sec/batch; 2h:07m:55s remains)
INFO - root - 2022-02-24 19:33:50.898817: step 26090, total loss = 0.57, batch loss = 0.29 (205.1 examples/sec; 0.039 sec/batch; 1h:52m:43s remains)
INFO - root - 2022-02-24 19:33:51.331515: step 26100, total loss = 0.56, batch loss = 0.27 (154.7 examples/sec; 0.052 sec/batch; 2h:29m:29s remains)
INFO - root - 2022-02-24 19:33:51.800250: step 26110, total loss = 0.65, batch loss = 0.36 (201.9 examples/sec; 0.040 sec/batch; 1h:54m:30s remains)
INFO - root - 2022-02-24 19:33:52.147172: step 26120, total loss = 0.56, batch loss = 0.28 (332.2 examples/sec; 0.024 sec/batch; 1h:09m:34s remains)
INFO - root - 2022-02-24 19:33:52.641236: step 26130, total loss = 0.64, batch loss = 0.36 (137.7 examples/sec; 0.058 sec/batch; 2h:47m:55s remains)
INFO - root - 2022-02-24 19:33:53.071430: step 26140, total loss = 0.58, batch loss = 0.29 (335.1 examples/sec; 0.024 sec/batch; 1h:08m:58s remains)
INFO - root - 2022-02-24 19:33:53.442542: step 26150, total loss = 0.60, batch loss = 0.31 (340.7 examples/sec; 0.023 sec/batch; 1h:07m:50s remains)
INFO - root - 2022-02-24 19:33:53.839517: step 26160, total loss = 0.58, batch loss = 0.29 (206.3 examples/sec; 0.039 sec/batch; 1h:52m:01s remains)
INFO - root - 2022-02-24 19:33:54.217830: step 26170, total loss = 0.62, batch loss = 0.33 (140.5 examples/sec; 0.057 sec/batch; 2h:44m:27s remains)
INFO - root - 2022-02-24 19:33:54.627792: step 26180, total loss = 0.68, batch loss = 0.40 (90.4 examples/sec; 0.088 sec/batch; 4h:15m:35s remains)
INFO - root - 2022-02-24 19:33:55.076192: step 26190, total loss = 0.49, batch loss = 0.21 (284.2 examples/sec; 0.028 sec/batch; 1h:21m:18s remains)
INFO - root - 2022-02-24 19:33:55.434025: step 26200, total loss = 0.53, batch loss = 0.24 (286.6 examples/sec; 0.028 sec/batch; 1h:20m:36s remains)
INFO - root - 2022-02-24 19:33:55.910688: step 26210, total loss = 0.67, batch loss = 0.38 (140.3 examples/sec; 0.057 sec/batch; 2h:44m:41s remains)
INFO - root - 2022-02-24 19:33:56.276961: step 26220, total loss = 0.60, batch loss = 0.31 (195.5 examples/sec; 0.041 sec/batch; 1h:58m:11s remains)
INFO - root - 2022-02-24 19:33:56.740818: step 26230, total loss = 0.60, batch loss = 0.31 (143.5 examples/sec; 0.056 sec/batch; 2h:40m:57s remains)
INFO - root - 2022-02-24 19:33:57.163674: step 26240, total loss = 0.60, batch loss = 0.31 (203.6 examples/sec; 0.039 sec/batch; 1h:53m:29s remains)
INFO - root - 2022-02-24 19:33:57.556597: step 26250, total loss = 0.58, batch loss = 0.30 (233.4 examples/sec; 0.034 sec/batch; 1h:38m:57s remains)
INFO - root - 2022-02-24 19:33:57.928901: step 26260, total loss = 0.55, batch loss = 0.26 (227.2 examples/sec; 0.035 sec/batch; 1h:41m:40s remains)
INFO - root - 2022-02-24 19:33:58.323757: step 26270, total loss = 0.55, batch loss = 0.27 (334.6 examples/sec; 0.024 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 19:33:58.727012: step 26280, total loss = 0.53, batch loss = 0.24 (315.9 examples/sec; 0.025 sec/batch; 1h:13m:06s remains)
INFO - root - 2022-02-24 19:33:59.099550: step 26290, total loss = 0.58, batch loss = 0.30 (337.2 examples/sec; 0.024 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 19:33:59.491983: step 26300, total loss = 0.58, batch loss = 0.29 (141.6 examples/sec; 0.056 sec/batch; 2h:43m:02s remains)
INFO - root - 2022-02-24 19:33:59.873640: step 26310, total loss = 0.62, batch loss = 0.34 (307.3 examples/sec; 0.026 sec/batch; 1h:15m:08s remains)
INFO - root - 2022-02-24 19:34:00.191363: step 26320, total loss = 0.49, batch loss = 0.20 (345.4 examples/sec; 0.023 sec/batch; 1h:06m:51s remains)
INFO - root - 2022-02-24 19:34:00.492440: step 26330, total loss = 0.57, batch loss = 0.28 (175.9 examples/sec; 0.045 sec/batch; 2h:11m:13s remains)
INFO - root - 2022-02-24 19:34:00.948033: step 26340, total loss = 0.69, batch loss = 0.40 (158.0 examples/sec; 0.051 sec/batch; 2h:26m:07s remains)
INFO - root - 2022-02-24 19:34:01.544887: step 26350, total loss = 0.61, batch loss = 0.32 (115.2 examples/sec; 0.069 sec/batch; 3h:20m:26s remains)
INFO - root - 2022-02-24 19:34:02.122973: step 26360, total loss = 0.60, batch loss = 0.31 (113.6 examples/sec; 0.070 sec/batch; 3h:23m:11s remains)
INFO - root - 2022-02-24 19:34:02.680530: step 26370, total loss = 0.64, batch loss = 0.36 (265.3 examples/sec; 0.030 sec/batch; 1h:27m:00s remains)
INFO - root - 2022-02-24 19:34:03.861158: step 26380, total loss = 0.66, batch loss = 0.38 (107.3 examples/sec; 0.075 sec/batch; 3h:35m:07s remains)
INFO - root - 2022-02-24 19:34:04.286223: step 26390, total loss = 0.74, batch loss = 0.45 (187.7 examples/sec; 0.043 sec/batch; 2h:02m:57s remains)
INFO - root - 2022-02-24 19:34:04.717472: step 26400, total loss = 0.52, batch loss = 0.23 (180.8 examples/sec; 0.044 sec/batch; 2h:07m:40s remains)
INFO - root - 2022-02-24 19:34:05.087838: step 26410, total loss = 0.71, batch loss = 0.42 (263.6 examples/sec; 0.030 sec/batch; 1h:27m:33s remains)
INFO - root - 2022-02-24 19:34:05.506818: step 26420, total loss = 0.69, batch loss = 0.40 (279.2 examples/sec; 0.029 sec/batch; 1h:22m:38s remains)
INFO - root - 2022-02-24 19:34:05.909388: step 26430, total loss = 0.61, batch loss = 0.32 (269.1 examples/sec; 0.030 sec/batch; 1h:25m:44s remains)
INFO - root - 2022-02-24 19:34:06.304100: step 26440, total loss = 0.52, batch loss = 0.23 (174.3 examples/sec; 0.046 sec/batch; 2h:12m:21s remains)
INFO - root - 2022-02-24 19:34:06.716476: step 26450, total loss = 0.57, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 1h:09m:55s remains)
INFO - root - 2022-02-24 19:34:07.112749: step 26460, total loss = 0.56, batch loss = 0.28 (308.6 examples/sec; 0.026 sec/batch; 1h:14m:46s remains)
INFO - root - 2022-02-24 19:34:07.612074: step 26470, total loss = 0.63, batch loss = 0.35 (143.4 examples/sec; 0.056 sec/batch; 2h:40m:54s remains)
INFO - root - 2022-02-24 19:34:08.061434: step 26480, total loss = 0.68, batch loss = 0.39 (239.1 examples/sec; 0.033 sec/batch; 1h:36m:29s remains)
INFO - root - 2022-02-24 19:34:08.525367: step 26490, total loss = 0.57, batch loss = 0.28 (219.6 examples/sec; 0.036 sec/batch; 1h:45m:02s remains)
INFO - root - 2022-02-24 19:34:08.923639: step 26500, total loss = 0.58, batch loss = 0.29 (209.4 examples/sec; 0.038 sec/batch; 1h:50m:07s remains)
INFO - root - 2022-02-24 19:34:09.338858: step 26510, total loss = 0.61, batch loss = 0.32 (135.4 examples/sec; 0.059 sec/batch; 2h:50m:24s remains)
INFO - root - 2022-02-24 19:34:09.670046: step 26520, total loss = 0.72, batch loss = 0.43 (298.4 examples/sec; 0.027 sec/batch; 1h:17m:17s remains)
INFO - root - 2022-02-24 19:34:10.164327: step 26530, total loss = 0.57, batch loss = 0.28 (251.7 examples/sec; 0.032 sec/batch; 1h:31m:37s remains)
INFO - root - 2022-02-24 19:34:10.622799: step 26540, total loss = 0.62, batch loss = 0.34 (245.6 examples/sec; 0.033 sec/batch; 1h:33m:53s remains)
INFO - root - 2022-02-24 19:34:11.030686: step 26550, total loss = 0.63, batch loss = 0.34 (207.6 examples/sec; 0.039 sec/batch; 1h:51m:05s remains)
INFO - root - 2022-02-24 19:34:11.381255: step 26560, total loss = 0.74, batch loss = 0.45 (224.7 examples/sec; 0.036 sec/batch; 1h:42m:35s remains)
INFO - root - 2022-02-24 19:34:11.825267: step 26570, total loss = 0.63, batch loss = 0.34 (163.7 examples/sec; 0.049 sec/batch; 2h:20m:49s remains)
INFO - root - 2022-02-24 19:34:12.212565: step 26580, total loss = 0.64, batch loss = 0.36 (333.0 examples/sec; 0.024 sec/batch; 1h:09m:13s remains)
INFO - root - 2022-02-24 19:34:12.743416: step 26590, total loss = 0.61, batch loss = 0.33 (132.0 examples/sec; 0.061 sec/batch; 2h:54m:37s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-26599 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-26599 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:34:13.608588: step 26600, total loss = 0.63, batch loss = 0.34 (288.3 examples/sec; 0.028 sec/batch; 1h:19m:57s remains)
INFO - root - 2022-02-24 19:34:13.941723: step 26610, total loss = 0.67, batch loss = 0.38 (322.4 examples/sec; 0.025 sec/batch; 1h:11m:30s remains)
INFO - root - 2022-02-24 19:34:14.216043: step 26620, total loss = 0.61, batch loss = 0.32 (302.8 examples/sec; 0.026 sec/batch; 1h:16m:08s remains)
INFO - root - 2022-02-24 19:34:14.636372: step 26630, total loss = 0.79, batch loss = 0.50 (115.7 examples/sec; 0.069 sec/batch; 3h:19m:08s remains)
INFO - root - 2022-02-24 19:34:15.035689: step 26640, total loss = 0.58, batch loss = 0.29 (208.8 examples/sec; 0.038 sec/batch; 1h:50m:23s remains)
INFO - root - 2022-02-24 19:34:15.493694: step 26650, total loss = 0.53, batch loss = 0.25 (256.2 examples/sec; 0.031 sec/batch; 1h:29m:57s remains)
INFO - root - 2022-02-24 19:34:15.919279: step 26660, total loss = 0.54, batch loss = 0.25 (171.8 examples/sec; 0.047 sec/batch; 2h:14m:07s remains)
INFO - root - 2022-02-24 19:34:16.268410: step 26670, total loss = 0.61, batch loss = 0.32 (262.2 examples/sec; 0.031 sec/batch; 1h:27m:52s remains)
INFO - root - 2022-02-24 19:34:16.772797: step 26680, total loss = 0.60, batch loss = 0.32 (95.5 examples/sec; 0.084 sec/batch; 4h:01m:20s remains)
INFO - root - 2022-02-24 19:34:17.208907: step 26690, total loss = 0.54, batch loss = 0.25 (153.7 examples/sec; 0.052 sec/batch; 2h:29m:57s remains)
INFO - root - 2022-02-24 19:34:17.636964: step 26700, total loss = 0.68, batch loss = 0.40 (158.5 examples/sec; 0.050 sec/batch; 2h:25m:20s remains)
INFO - root - 2022-02-24 19:34:18.035338: step 26710, total loss = 0.54, batch loss = 0.25 (327.8 examples/sec; 0.024 sec/batch; 1h:10m:17s remains)
INFO - root - 2022-02-24 19:34:18.398979: step 26720, total loss = 0.65, batch loss = 0.36 (137.7 examples/sec; 0.058 sec/batch; 2h:47m:17s remains)
INFO - root - 2022-02-24 19:34:18.836912: step 26730, total loss = 0.75, batch loss = 0.47 (130.6 examples/sec; 0.061 sec/batch; 2h:56m:23s remains)
INFO - root - 2022-02-24 19:34:19.486955: step 26740, total loss = 0.94, batch loss = 0.65 (233.1 examples/sec; 0.034 sec/batch; 1h:38m:48s remains)
INFO - root - 2022-02-24 19:34:19.884913: step 26750, total loss = 0.75, batch loss = 0.46 (340.3 examples/sec; 0.024 sec/batch; 1h:07m:40s remains)
INFO - root - 2022-02-24 19:34:20.210486: step 26760, total loss = 0.51, batch loss = 0.23 (257.1 examples/sec; 0.031 sec/batch; 1h:29m:35s remains)
INFO - root - 2022-02-24 19:34:20.586248: step 26770, total loss = 0.69, batch loss = 0.40 (192.9 examples/sec; 0.041 sec/batch; 1h:59m:23s remains)
INFO - root - 2022-02-24 19:34:21.016642: step 26780, total loss = 0.58, batch loss = 0.29 (92.8 examples/sec; 0.086 sec/batch; 4h:08m:07s remains)
INFO - root - 2022-02-24 19:34:21.433562: step 26790, total loss = 0.72, batch loss = 0.43 (388.6 examples/sec; 0.021 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 19:34:22.001079: step 26800, total loss = 0.55, batch loss = 0.27 (203.2 examples/sec; 0.039 sec/batch; 1h:53m:18s remains)
INFO - root - 2022-02-24 19:34:22.516497: step 26810, total loss = 0.73, batch loss = 0.45 (209.5 examples/sec; 0.038 sec/batch; 1h:49m:53s remains)
INFO - root - 2022-02-24 19:34:23.020760: step 26820, total loss = 0.61, batch loss = 0.33 (142.9 examples/sec; 0.056 sec/batch; 2h:41m:03s remains)
INFO - root - 2022-02-24 19:34:23.529873: step 26830, total loss = 0.67, batch loss = 0.38 (130.8 examples/sec; 0.061 sec/batch; 2h:55m:59s remains)
INFO - root - 2022-02-24 19:34:24.016334: step 26840, total loss = 0.59, batch loss = 0.30 (279.6 examples/sec; 0.029 sec/batch; 1h:22m:19s remains)
INFO - root - 2022-02-24 19:34:25.031501: step 26850, total loss = 0.52, batch loss = 0.24 (93.2 examples/sec; 0.086 sec/batch; 4h:07m:02s remains)
INFO - root - 2022-02-24 19:34:25.453779: step 26860, total loss = 0.65, batch loss = 0.36 (307.9 examples/sec; 0.026 sec/batch; 1h:14m:46s remains)
INFO - root - 2022-02-24 19:34:25.850325: step 26870, total loss = 0.61, batch loss = 0.33 (216.6 examples/sec; 0.037 sec/batch; 1h:46m:15s remains)
INFO - root - 2022-02-24 19:34:26.324600: step 26880, total loss = 0.52, batch loss = 0.24 (176.8 examples/sec; 0.045 sec/batch; 2h:10m:09s remains)
INFO - root - 2022-02-24 19:34:26.844300: step 26890, total loss = 0.54, batch loss = 0.26 (324.9 examples/sec; 0.025 sec/batch; 1h:10m:50s remains)
INFO - root - 2022-02-24 19:34:27.274896: step 26900, total loss = 0.59, batch loss = 0.30 (176.0 examples/sec; 0.045 sec/batch; 2h:10m:44s remains)
INFO - root - 2022-02-24 19:34:27.683997: step 26910, total loss = 0.53, batch loss = 0.25 (300.2 examples/sec; 0.027 sec/batch; 1h:16m:38s remains)
INFO - root - 2022-02-24 19:34:28.150366: step 26920, total loss = 0.64, batch loss = 0.36 (118.3 examples/sec; 0.068 sec/batch; 3h:14m:28s remains)
INFO - root - 2022-02-24 19:34:28.616703: step 26930, total loss = 0.57, batch loss = 0.28 (387.5 examples/sec; 0.021 sec/batch; 0h:59m:23s remains)
INFO - root - 2022-02-24 19:34:29.225677: step 26940, total loss = 0.57, batch loss = 0.29 (28.6 examples/sec; 0.279 sec/batch; 13h:23m:43s remains)
INFO - root - 2022-02-24 19:34:29.581791: step 26950, total loss = 0.55, batch loss = 0.26 (227.3 examples/sec; 0.035 sec/batch; 1h:41m:13s remains)
INFO - root - 2022-02-24 19:34:29.956683: step 26960, total loss = 0.65, batch loss = 0.37 (137.1 examples/sec; 0.058 sec/batch; 2h:47m:46s remains)
INFO - root - 2022-02-24 19:34:30.282192: step 26970, total loss = 0.54, batch loss = 0.25 (223.2 examples/sec; 0.036 sec/batch; 1h:43m:04s remains)
INFO - root - 2022-02-24 19:34:30.740275: step 26980, total loss = 0.51, batch loss = 0.23 (151.7 examples/sec; 0.053 sec/batch; 2h:31m:38s remains)
INFO - root - 2022-02-24 19:34:31.163937: step 26990, total loss = 0.65, batch loss = 0.36 (119.9 examples/sec; 0.067 sec/batch; 3h:11m:49s remains)
INFO - root - 2022-02-24 19:34:31.552313: step 27000, total loss = 0.56, batch loss = 0.27 (101.4 examples/sec; 0.079 sec/batch; 3h:46m:47s remains)
INFO - root - 2022-02-24 19:34:31.945503: step 27010, total loss = 0.72, batch loss = 0.43 (341.3 examples/sec; 0.023 sec/batch; 1h:07m:23s remains)
INFO - root - 2022-02-24 19:34:32.276998: step 27020, total loss = 0.67, batch loss = 0.38 (344.0 examples/sec; 0.023 sec/batch; 1h:06m:51s remains)
INFO - root - 2022-02-24 19:34:32.723612: step 27030, total loss = 0.58, batch loss = 0.30 (320.7 examples/sec; 0.025 sec/batch; 1h:11m:42s remains)
INFO - root - 2022-02-24 19:34:33.168318: step 27040, total loss = 0.59, batch loss = 0.30 (252.5 examples/sec; 0.032 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 19:34:33.554711: step 27050, total loss = 0.52, batch loss = 0.23 (116.8 examples/sec; 0.068 sec/batch; 3h:16m:46s remains)
INFO - root - 2022-02-24 19:34:33.883765: step 27060, total loss = 0.70, batch loss = 0.41 (332.2 examples/sec; 0.024 sec/batch; 1h:09m:12s remains)
INFO - root - 2022-02-24 19:34:34.315783: step 27070, total loss = 0.56, batch loss = 0.28 (358.3 examples/sec; 0.022 sec/batch; 1h:04m:10s remains)
INFO - root - 2022-02-24 19:34:34.793044: step 27080, total loss = 0.56, batch loss = 0.27 (191.8 examples/sec; 0.042 sec/batch; 1h:59m:50s remains)
INFO - root - 2022-02-24 19:34:35.206856: step 27090, total loss = 0.59, batch loss = 0.30 (198.2 examples/sec; 0.040 sec/batch; 1h:55m:58s remains)
INFO - root - 2022-02-24 19:34:35.584916: step 27100, total loss = 0.55, batch loss = 0.27 (163.8 examples/sec; 0.049 sec/batch; 2h:20m:21s remains)
INFO - root - 2022-02-24 19:34:36.067170: step 27110, total loss = 0.63, batch loss = 0.34 (336.4 examples/sec; 0.024 sec/batch; 1h:08m:19s remains)
INFO - root - 2022-02-24 19:34:36.520900: step 27120, total loss = 0.50, batch loss = 0.21 (216.9 examples/sec; 0.037 sec/batch; 1h:45m:57s remains)
INFO - root - 2022-02-24 19:34:36.953855: step 27130, total loss = 0.60, batch loss = 0.32 (164.2 examples/sec; 0.049 sec/batch; 2h:20m:00s remains)
INFO - root - 2022-02-24 19:34:37.371323: step 27140, total loss = 0.60, batch loss = 0.31 (204.7 examples/sec; 0.039 sec/batch; 1h:52m:16s remains)
INFO - root - 2022-02-24 19:34:37.733625: step 27150, total loss = 0.63, batch loss = 0.35 (360.5 examples/sec; 0.022 sec/batch; 1h:03m:45s remains)
INFO - root - 2022-02-24 19:34:38.117134: step 27160, total loss = 0.53, batch loss = 0.24 (285.7 examples/sec; 0.028 sec/batch; 1h:20m:26s remains)
INFO - root - 2022-02-24 19:34:38.463661: step 27170, total loss = 0.55, batch loss = 0.27 (290.9 examples/sec; 0.028 sec/batch; 1h:18m:59s remains)
INFO - root - 2022-02-24 19:34:38.836466: step 27180, total loss = 0.68, batch loss = 0.39 (143.1 examples/sec; 0.056 sec/batch; 2h:40m:32s remains)
INFO - root - 2022-02-24 19:34:39.399960: step 27190, total loss = 0.52, batch loss = 0.24 (163.2 examples/sec; 0.049 sec/batch; 2h:20m:47s remains)
INFO - root - 2022-02-24 19:34:39.843726: step 27200, total loss = 0.57, batch loss = 0.28 (263.0 examples/sec; 0.030 sec/batch; 1h:27m:20s remains)
INFO - root - 2022-02-24 19:34:40.361131: step 27210, total loss = 0.54, batch loss = 0.26 (230.7 examples/sec; 0.035 sec/batch; 1h:39m:34s remains)
INFO - root - 2022-02-24 19:34:40.700781: step 27220, total loss = 0.58, batch loss = 0.29 (211.9 examples/sec; 0.038 sec/batch; 1h:48m:24s remains)
INFO - root - 2022-02-24 19:34:41.151777: step 27230, total loss = 0.53, batch loss = 0.24 (107.5 examples/sec; 0.074 sec/batch; 3h:33m:38s remains)
INFO - root - 2022-02-24 19:34:41.664292: step 27240, total loss = 0.72, batch loss = 0.43 (270.5 examples/sec; 0.030 sec/batch; 1h:24m:54s remains)
INFO - root - 2022-02-24 19:34:42.064510: step 27250, total loss = 0.62, batch loss = 0.33 (196.9 examples/sec; 0.041 sec/batch; 1h:56m:39s remains)
INFO - root - 2022-02-24 19:34:42.447713: step 27260, total loss = 0.60, batch loss = 0.32 (134.7 examples/sec; 0.059 sec/batch; 2h:50m:30s remains)
INFO - root - 2022-02-24 19:34:42.835241: step 27270, total loss = 0.64, batch loss = 0.35 (169.8 examples/sec; 0.047 sec/batch; 2h:15m:16s remains)
INFO - root - 2022-02-24 19:34:43.232586: step 27280, total loss = 0.56, batch loss = 0.28 (182.7 examples/sec; 0.044 sec/batch; 2h:05m:40s remains)
INFO - root - 2022-02-24 19:34:43.729202: step 27290, total loss = 0.69, batch loss = 0.41 (130.1 examples/sec; 0.061 sec/batch; 2h:56m:26s remains)
INFO - root - 2022-02-24 19:34:44.168367: step 27300, total loss = 0.78, batch loss = 0.50 (130.1 examples/sec; 0.062 sec/batch; 2h:56m:32s remains)
INFO - root - 2022-02-24 19:34:44.639495: step 27310, total loss = 0.66, batch loss = 0.37 (331.6 examples/sec; 0.024 sec/batch; 1h:09m:13s remains)
INFO - root - 2022-02-24 19:34:45.017233: step 27320, total loss = 0.58, batch loss = 0.29 (161.9 examples/sec; 0.049 sec/batch; 2h:21m:46s remains)
INFO - root - 2022-02-24 19:34:45.418466: step 27330, total loss = 0.55, batch loss = 0.27 (124.5 examples/sec; 0.064 sec/batch; 3h:04m:22s remains)
INFO - root - 2022-02-24 19:34:45.839844: step 27340, total loss = 0.56, batch loss = 0.27 (203.3 examples/sec; 0.039 sec/batch; 1h:52m:55s remains)
INFO - root - 2022-02-24 19:34:46.338428: step 27350, total loss = 0.57, batch loss = 0.29 (151.2 examples/sec; 0.053 sec/batch; 2h:31m:47s remains)
INFO - root - 2022-02-24 19:34:46.744569: step 27360, total loss = 0.60, batch loss = 0.31 (294.0 examples/sec; 0.027 sec/batch; 1h:18m:03s remains)
INFO - root - 2022-02-24 19:34:47.097024: step 27370, total loss = 0.65, batch loss = 0.36 (199.5 examples/sec; 0.040 sec/batch; 1h:55m:02s remains)
INFO - root - 2022-02-24 19:34:47.498662: step 27380, total loss = 0.65, batch loss = 0.37 (211.0 examples/sec; 0.038 sec/batch; 1h:48m:44s remains)
INFO - root - 2022-02-24 19:34:47.898202: step 27390, total loss = 0.58, batch loss = 0.30 (273.8 examples/sec; 0.029 sec/batch; 1h:23m:48s remains)
INFO - root - 2022-02-24 19:34:48.332275: step 27400, total loss = 0.52, batch loss = 0.23 (329.5 examples/sec; 0.024 sec/batch; 1h:09m:38s remains)
INFO - root - 2022-02-24 19:34:48.817680: step 27410, total loss = 0.74, batch loss = 0.46 (150.4 examples/sec; 0.053 sec/batch; 2h:32m:34s remains)
INFO - root - 2022-02-24 19:34:49.533176: step 27420, total loss = 0.57, batch loss = 0.28 (24.4 examples/sec; 0.327 sec/batch; 15h:38m:28s remains)
INFO - root - 2022-02-24 19:34:50.070924: step 27430, total loss = 0.55, batch loss = 0.27 (171.6 examples/sec; 0.047 sec/batch; 2h:13m:42s remains)
INFO - root - 2022-02-24 19:34:50.504220: step 27440, total loss = 0.65, batch loss = 0.36 (338.5 examples/sec; 0.024 sec/batch; 1h:07m:46s remains)
INFO - root - 2022-02-24 19:34:50.901209: step 27450, total loss = 0.63, batch loss = 0.35 (312.2 examples/sec; 0.026 sec/batch; 1h:13m:29s remains)
INFO - root - 2022-02-24 19:34:51.400580: step 27460, total loss = 0.66, batch loss = 0.37 (238.9 examples/sec; 0.033 sec/batch; 1h:36m:01s remains)
INFO - root - 2022-02-24 19:34:51.874973: step 27470, total loss = 0.64, batch loss = 0.35 (145.5 examples/sec; 0.055 sec/batch; 2h:37m:41s remains)
INFO - root - 2022-02-24 19:34:52.423082: step 27480, total loss = 0.63, batch loss = 0.35 (316.7 examples/sec; 0.025 sec/batch; 1h:12m:25s remains)
INFO - root - 2022-02-24 19:34:52.975797: step 27490, total loss = 0.99, batch loss = 0.70 (222.6 examples/sec; 0.036 sec/batch; 1h:43m:02s remains)
INFO - root - 2022-02-24 19:34:53.332203: step 27500, total loss = 0.66, batch loss = 0.37 (275.8 examples/sec; 0.029 sec/batch; 1h:23m:08s remains)
INFO - root - 2022-02-24 19:34:53.827091: step 27510, total loss = 0.52, batch loss = 0.23 (172.0 examples/sec; 0.046 sec/batch; 2h:13m:17s remains)
INFO - root - 2022-02-24 19:34:54.879023: step 27520, total loss = 0.63, batch loss = 0.34 (99.4 examples/sec; 0.080 sec/batch; 3h:50m:38s remains)
INFO - root - 2022-02-24 19:34:55.262148: step 27530, total loss = 0.63, batch loss = 0.35 (222.3 examples/sec; 0.036 sec/batch; 1h:43m:09s remains)
INFO - root - 2022-02-24 19:34:55.690193: step 27540, total loss = 0.71, batch loss = 0.42 (180.9 examples/sec; 0.044 sec/batch; 2h:06m:43s remains)
INFO - root - 2022-02-24 19:34:56.137811: step 27550, total loss = 0.60, batch loss = 0.31 (177.5 examples/sec; 0.045 sec/batch; 2h:09m:08s remains)
INFO - root - 2022-02-24 19:34:56.550575: step 27560, total loss = 0.53, batch loss = 0.24 (182.9 examples/sec; 0.044 sec/batch; 2h:05m:21s remains)
INFO - root - 2022-02-24 19:34:57.021553: step 27570, total loss = 0.71, batch loss = 0.42 (216.9 examples/sec; 0.037 sec/batch; 1h:45m:40s remains)
INFO - root - 2022-02-24 19:34:57.478480: step 27580, total loss = 0.62, batch loss = 0.33 (78.0 examples/sec; 0.103 sec/batch; 4h:53m:43s remains)
INFO - root - 2022-02-24 19:34:57.867487: step 27590, total loss = 0.63, batch loss = 0.34 (218.7 examples/sec; 0.037 sec/batch; 1h:44m:48s remains)
INFO - root - 2022-02-24 19:34:58.193912: step 27600, total loss = 0.76, batch loss = 0.47 (322.4 examples/sec; 0.025 sec/batch; 1h:11m:05s remains)
INFO - root - 2022-02-24 19:34:58.703727: step 27610, total loss = 0.57, batch loss = 0.29 (149.1 examples/sec; 0.054 sec/batch; 2h:33m:42s remains)
INFO - root - 2022-02-24 19:34:59.218473: step 27620, total loss = 0.56, batch loss = 0.27 (343.5 examples/sec; 0.023 sec/batch; 1h:06m:42s remains)
INFO - root - 2022-02-24 19:34:59.665147: step 27630, total loss = 0.65, batch loss = 0.36 (218.4 examples/sec; 0.037 sec/batch; 1h:44m:55s remains)
INFO - root - 2022-02-24 19:35:00.067508: step 27640, total loss = 0.58, batch loss = 0.30 (159.4 examples/sec; 0.050 sec/batch; 2h:23m:43s remains)
INFO - root - 2022-02-24 19:35:00.552896: step 27650, total loss = 0.58, batch loss = 0.30 (114.5 examples/sec; 0.070 sec/batch; 3h:20m:05s remains)
INFO - root - 2022-02-24 19:35:01.059215: step 27660, total loss = 0.50, batch loss = 0.22 (213.0 examples/sec; 0.038 sec/batch; 1h:47m:32s remains)
INFO - root - 2022-02-24 19:35:01.591353: step 27670, total loss = 0.54, batch loss = 0.26 (86.0 examples/sec; 0.093 sec/batch; 4h:26m:26s remains)
INFO - root - 2022-02-24 19:35:01.946066: step 27680, total loss = 0.63, batch loss = 0.35 (204.2 examples/sec; 0.039 sec/batch; 1h:52m:12s remains)
INFO - root - 2022-02-24 19:35:02.338385: step 27690, total loss = 0.58, batch loss = 0.30 (353.1 examples/sec; 0.023 sec/batch; 1h:04m:52s remains)
INFO - root - 2022-02-24 19:35:02.800321: step 27700, total loss = 0.60, batch loss = 0.31 (341.2 examples/sec; 0.023 sec/batch; 1h:07m:08s remains)
INFO - root - 2022-02-24 19:35:03.486395: step 27710, total loss = 0.78, batch loss = 0.49 (159.6 examples/sec; 0.050 sec/batch; 2h:23m:30s remains)
INFO - root - 2022-02-24 19:35:03.877000: step 27720, total loss = 0.58, batch loss = 0.29 (311.6 examples/sec; 0.026 sec/batch; 1h:13m:30s remains)
INFO - root - 2022-02-24 19:35:04.331797: step 27730, total loss = 0.53, batch loss = 0.24 (75.9 examples/sec; 0.105 sec/batch; 5h:01m:48s remains)
INFO - root - 2022-02-24 19:35:04.771940: step 27740, total loss = 0.59, batch loss = 0.31 (148.9 examples/sec; 0.054 sec/batch; 2h:33m:45s remains)
INFO - root - 2022-02-24 19:35:05.348959: step 27750, total loss = 0.59, batch loss = 0.31 (94.5 examples/sec; 0.085 sec/batch; 4h:02m:23s remains)
INFO - root - 2022-02-24 19:35:05.741817: step 27760, total loss = 0.88, batch loss = 0.59 (227.3 examples/sec; 0.035 sec/batch; 1h:40m:44s remains)
INFO - root - 2022-02-24 19:35:06.128247: step 27770, total loss = 0.50, batch loss = 0.22 (320.3 examples/sec; 0.025 sec/batch; 1h:11m:29s remains)
INFO - root - 2022-02-24 19:35:06.507368: step 27780, total loss = 0.59, batch loss = 0.31 (334.7 examples/sec; 0.024 sec/batch; 1h:08m:24s remains)
INFO - root - 2022-02-24 19:35:06.940134: step 27790, total loss = 0.60, batch loss = 0.31 (102.7 examples/sec; 0.078 sec/batch; 3h:42m:58s remains)
INFO - root - 2022-02-24 19:35:07.408173: step 27800, total loss = 0.65, batch loss = 0.37 (296.1 examples/sec; 0.027 sec/batch; 1h:17m:18s remains)
INFO - root - 2022-02-24 19:35:07.867084: step 27810, total loss = 0.57, batch loss = 0.28 (146.9 examples/sec; 0.054 sec/batch; 2h:35m:51s remains)
INFO - root - 2022-02-24 19:35:08.242754: step 27820, total loss = 0.63, batch loss = 0.34 (324.9 examples/sec; 0.025 sec/batch; 1h:10m:26s remains)
INFO - root - 2022-02-24 19:35:08.570489: step 27830, total loss = 0.59, batch loss = 0.30 (263.6 examples/sec; 0.030 sec/batch; 1h:26m:49s remains)
INFO - root - 2022-02-24 19:35:08.934108: step 27840, total loss = 0.53, batch loss = 0.24 (322.5 examples/sec; 0.025 sec/batch; 1h:10m:57s remains)
INFO - root - 2022-02-24 19:35:09.367381: step 27850, total loss = 0.61, batch loss = 0.32 (266.6 examples/sec; 0.030 sec/batch; 1h:25m:50s remains)
INFO - root - 2022-02-24 19:35:09.810645: step 27860, total loss = 0.47, batch loss = 0.19 (247.0 examples/sec; 0.032 sec/batch; 1h:32m:39s remains)
INFO - root - 2022-02-24 19:35:10.189188: step 27870, total loss = 0.54, batch loss = 0.26 (339.4 examples/sec; 0.024 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 19:35:10.523355: step 27880, total loss = 0.65, batch loss = 0.37 (193.9 examples/sec; 0.041 sec/batch; 1h:58m:01s remains)
INFO - root - 2022-02-24 19:35:11.066599: step 27890, total loss = 0.63, batch loss = 0.34 (156.3 examples/sec; 0.051 sec/batch; 2h:26m:23s remains)
INFO - root - 2022-02-24 19:35:11.536151: step 27900, total loss = 0.59, batch loss = 0.31 (133.8 examples/sec; 0.060 sec/batch; 2h:50m:56s remains)
INFO - root - 2022-02-24 19:35:11.959797: step 27910, total loss = 0.55, batch loss = 0.26 (307.8 examples/sec; 0.026 sec/batch; 1h:14m:19s remains)
INFO - root - 2022-02-24 19:35:12.446961: step 27920, total loss = 0.61, batch loss = 0.32 (191.7 examples/sec; 0.042 sec/batch; 1h:59m:21s remains)
INFO - root - 2022-02-24 19:35:12.921855: step 27930, total loss = 0.67, batch loss = 0.39 (243.9 examples/sec; 0.033 sec/batch; 1h:33m:48s remains)
INFO - root - 2022-02-24 19:35:13.373021: step 27940, total loss = 0.62, batch loss = 0.33 (131.5 examples/sec; 0.061 sec/batch; 2h:53m:59s remains)
INFO - root - 2022-02-24 19:35:13.942236: step 27950, total loss = 0.62, batch loss = 0.33 (134.6 examples/sec; 0.059 sec/batch; 2h:49m:56s remains)
INFO - root - 2022-02-24 19:35:14.500920: step 27960, total loss = 0.63, batch loss = 0.35 (307.7 examples/sec; 0.026 sec/batch; 1h:14m:19s remains)
INFO - root - 2022-02-24 19:35:15.527795: step 27970, total loss = 0.68, batch loss = 0.40 (307.5 examples/sec; 0.026 sec/batch; 1h:14m:22s remains)
INFO - root - 2022-02-24 19:35:16.006403: step 27980, total loss = 0.54, batch loss = 0.25 (95.4 examples/sec; 0.084 sec/batch; 3h:59m:47s remains)
INFO - root - 2022-02-24 19:35:16.426119: step 27990, total loss = 0.62, batch loss = 0.33 (197.8 examples/sec; 0.040 sec/batch; 1h:55m:34s remains)
INFO - root - 2022-02-24 19:35:16.848045: step 28000, total loss = 0.62, batch loss = 0.34 (314.4 examples/sec; 0.025 sec/batch; 1h:12m:43s remains)
INFO - root - 2022-02-24 19:35:17.274402: step 28010, total loss = 0.56, batch loss = 0.28 (148.4 examples/sec; 0.054 sec/batch; 2h:34m:01s remains)
INFO - root - 2022-02-24 19:35:17.664221: step 28020, total loss = 0.56, batch loss = 0.27 (165.5 examples/sec; 0.048 sec/batch; 2h:18m:11s remains)
INFO - root - 2022-02-24 19:35:18.132591: step 28030, total loss = 0.57, batch loss = 0.29 (220.3 examples/sec; 0.036 sec/batch; 1h:43m:45s remains)
INFO - root - 2022-02-24 19:35:18.596951: step 28040, total loss = 0.58, batch loss = 0.29 (149.6 examples/sec; 0.053 sec/batch; 2h:32m:50s remains)
INFO - root - 2022-02-24 19:35:18.952838: step 28050, total loss = 0.54, batch loss = 0.25 (282.9 examples/sec; 0.028 sec/batch; 1h:20m:48s remains)
INFO - root - 2022-02-24 19:35:19.348314: step 28060, total loss = 0.55, batch loss = 0.27 (269.9 examples/sec; 0.030 sec/batch; 1h:24m:42s remains)
INFO - root - 2022-02-24 19:35:19.765737: step 28070, total loss = 0.55, batch loss = 0.26 (305.3 examples/sec; 0.026 sec/batch; 1h:14m:51s remains)
INFO - root - 2022-02-24 19:35:20.300056: step 28080, total loss = 0.74, batch loss = 0.45 (339.6 examples/sec; 0.024 sec/batch; 1h:07m:18s remains)
INFO - root - 2022-02-24 19:35:20.717428: step 28090, total loss = 0.62, batch loss = 0.34 (354.2 examples/sec; 0.023 sec/batch; 1h:04m:31s remains)
INFO - root - 2022-02-24 19:35:21.021187: step 28100, total loss = 0.69, batch loss = 0.40 (370.1 examples/sec; 0.022 sec/batch; 1h:01m:44s remains)
INFO - root - 2022-02-24 19:35:21.435488: step 28110, total loss = 0.48, batch loss = 0.20 (178.6 examples/sec; 0.045 sec/batch; 2h:07m:56s remains)
INFO - root - 2022-02-24 19:35:21.824621: step 28120, total loss = 0.69, batch loss = 0.40 (125.6 examples/sec; 0.064 sec/batch; 3h:01m:59s remains)
INFO - root - 2022-02-24 19:35:22.250451: step 28130, total loss = 0.64, batch loss = 0.35 (217.3 examples/sec; 0.037 sec/batch; 1h:45m:10s remains)
INFO - root - 2022-02-24 19:35:22.658963: step 28140, total loss = 0.53, batch loss = 0.25 (208.7 examples/sec; 0.038 sec/batch; 1h:49m:30s remains)
INFO - root - 2022-02-24 19:35:23.097216: step 28150, total loss = 0.62, batch loss = 0.33 (266.5 examples/sec; 0.030 sec/batch; 1h:25m:43s remains)
INFO - root - 2022-02-24 19:35:23.517746: step 28160, total loss = 0.61, batch loss = 0.32 (138.5 examples/sec; 0.058 sec/batch; 2h:44m:57s remains)
INFO - root - 2022-02-24 19:35:23.845451: step 28170, total loss = 0.62, batch loss = 0.33 (224.6 examples/sec; 0.036 sec/batch; 1h:41m:43s remains)
INFO - root - 2022-02-24 19:35:24.267693: step 28180, total loss = 0.69, batch loss = 0.40 (170.3 examples/sec; 0.047 sec/batch; 2h:14m:10s remains)
INFO - root - 2022-02-24 19:35:24.725975: step 28190, total loss = 0.61, batch loss = 0.32 (135.1 examples/sec; 0.059 sec/batch; 2h:49m:04s remains)
INFO - root - 2022-02-24 19:35:25.140848: step 28200, total loss = 0.52, batch loss = 0.23 (237.0 examples/sec; 0.034 sec/batch; 1h:36m:23s remains)
INFO - root - 2022-02-24 19:35:25.595797: step 28210, total loss = 0.51, batch loss = 0.22 (309.2 examples/sec; 0.026 sec/batch; 1h:13m:52s remains)
INFO - root - 2022-02-24 19:35:25.987306: step 28220, total loss = 0.59, batch loss = 0.31 (165.7 examples/sec; 0.048 sec/batch; 2h:17m:48s remains)
INFO - root - 2022-02-24 19:35:26.365352: step 28230, total loss = 0.93, batch loss = 0.64 (201.9 examples/sec; 0.040 sec/batch; 1h:53m:06s remains)
INFO - root - 2022-02-24 19:35:26.871281: step 28240, total loss = 0.59, batch loss = 0.30 (293.5 examples/sec; 0.027 sec/batch; 1h:17m:47s remains)
INFO - root - 2022-02-24 19:35:27.298674: step 28250, total loss = 0.65, batch loss = 0.36 (240.7 examples/sec; 0.033 sec/batch; 1h:34m:52s remains)
INFO - root - 2022-02-24 19:35:27.575405: step 28260, total loss = 0.59, batch loss = 0.30 (305.7 examples/sec; 0.026 sec/batch; 1h:14m:41s remains)
INFO - root - 2022-02-24 19:35:27.943882: step 28270, total loss = 0.56, batch loss = 0.28 (131.1 examples/sec; 0.061 sec/batch; 2h:54m:11s remains)
INFO - root - 2022-02-24 19:35:28.285927: step 28280, total loss = 0.59, batch loss = 0.30 (347.5 examples/sec; 0.023 sec/batch; 1h:05m:41s remains)
INFO - root - 2022-02-24 19:35:28.739630: step 28290, total loss = 0.58, batch loss = 0.29 (224.2 examples/sec; 0.036 sec/batch; 1h:41m:48s remains)
INFO - root - 2022-02-24 19:35:29.245892: step 28300, total loss = 0.62, batch loss = 0.34 (222.5 examples/sec; 0.036 sec/batch; 1h:42m:34s remains)
INFO - root - 2022-02-24 19:35:29.769709: step 28310, total loss = 0.66, batch loss = 0.37 (177.0 examples/sec; 0.045 sec/batch; 2h:08m:58s remains)
INFO - root - 2022-02-24 19:35:30.243779: step 28320, total loss = 0.53, batch loss = 0.24 (154.7 examples/sec; 0.052 sec/batch; 2h:27m:30s remains)
INFO - root - 2022-02-24 19:35:30.692954: step 28330, total loss = 0.76, batch loss = 0.48 (140.4 examples/sec; 0.057 sec/batch; 2h:42m:29s remains)
INFO - root - 2022-02-24 19:35:31.056881: step 28340, total loss = 0.86, batch loss = 0.57 (140.3 examples/sec; 0.057 sec/batch; 2h:42m:38s remains)
INFO - root - 2022-02-24 19:35:31.562786: step 28350, total loss = 0.54, batch loss = 0.26 (245.2 examples/sec; 0.033 sec/batch; 1h:33m:03s remains)
INFO - root - 2022-02-24 19:35:32.166064: step 28360, total loss = 0.61, batch loss = 0.33 (140.5 examples/sec; 0.057 sec/batch; 2h:42m:26s remains)
INFO - root - 2022-02-24 19:35:32.715465: step 28370, total loss = 0.60, batch loss = 0.32 (105.9 examples/sec; 0.076 sec/batch; 3h:35m:29s remains)
INFO - root - 2022-02-24 19:35:33.322451: step 28380, total loss = 0.61, batch loss = 0.32 (160.0 examples/sec; 0.050 sec/batch; 2h:22m:35s remains)
INFO - root - 2022-02-24 19:35:34.128530: step 28390, total loss = 0.56, batch loss = 0.27 (261.0 examples/sec; 0.031 sec/batch; 1h:27m:24s remains)
INFO - root - 2022-02-24 19:35:34.572615: step 28400, total loss = 0.52, batch loss = 0.23 (259.0 examples/sec; 0.031 sec/batch; 1h:28m:04s remains)
INFO - root - 2022-02-24 19:35:35.507782: step 28410, total loss = 0.75, batch loss = 0.47 (142.1 examples/sec; 0.056 sec/batch; 2h:40m:34s remains)
INFO - root - 2022-02-24 19:35:36.013886: step 28420, total loss = 0.63, batch loss = 0.34 (86.8 examples/sec; 0.092 sec/batch; 4h:22m:40s remains)
INFO - root - 2022-02-24 19:35:36.427640: step 28430, total loss = 0.72, batch loss = 0.44 (221.6 examples/sec; 0.036 sec/batch; 1h:42m:55s remains)
INFO - root - 2022-02-24 19:35:36.769287: step 28440, total loss = 0.59, batch loss = 0.30 (307.7 examples/sec; 0.026 sec/batch; 1h:14m:08s remains)
INFO - root - 2022-02-24 19:35:37.179298: step 28450, total loss = 0.75, batch loss = 0.46 (102.1 examples/sec; 0.078 sec/batch; 3h:43m:17s remains)
INFO - root - 2022-02-24 19:35:37.640833: step 28460, total loss = 0.57, batch loss = 0.28 (202.5 examples/sec; 0.040 sec/batch; 1h:52m:38s remains)
INFO - root - 2022-02-24 19:35:38.079360: step 28470, total loss = 0.61, batch loss = 0.33 (98.3 examples/sec; 0.081 sec/batch; 3h:52m:02s remains)
INFO - root - 2022-02-24 19:35:38.534207: step 28480, total loss = 0.65, batch loss = 0.36 (216.6 examples/sec; 0.037 sec/batch; 1h:45m:17s remains)
INFO - root - 2022-02-24 19:35:38.916112: step 28490, total loss = 0.54, batch loss = 0.26 (175.0 examples/sec; 0.046 sec/batch; 2h:10m:16s remains)
INFO - root - 2022-02-24 19:35:39.295772: step 28500, total loss = 0.64, batch loss = 0.35 (251.0 examples/sec; 0.032 sec/batch; 1h:30m:50s remains)
INFO - root - 2022-02-24 19:35:39.804596: step 28510, total loss = 0.49, batch loss = 0.21 (308.3 examples/sec; 0.026 sec/batch; 1h:13m:56s remains)
INFO - root - 2022-02-24 19:35:40.163143: step 28520, total loss = 0.55, batch loss = 0.26 (223.4 examples/sec; 0.036 sec/batch; 1h:42m:02s remains)
INFO - root - 2022-02-24 19:35:40.724451: step 28530, total loss = 0.64, batch loss = 0.36 (255.9 examples/sec; 0.031 sec/batch; 1h:29m:05s remains)
INFO - root - 2022-02-24 19:35:41.028495: step 28540, total loss = 0.58, batch loss = 0.30 (331.9 examples/sec; 0.024 sec/batch; 1h:08m:40s remains)
INFO - root - 2022-02-24 19:35:41.447190: step 28550, total loss = 0.57, batch loss = 0.29 (199.0 examples/sec; 0.040 sec/batch; 1h:54m:32s remains)
INFO - root - 2022-02-24 19:35:41.807418: step 28560, total loss = 0.67, batch loss = 0.39 (272.8 examples/sec; 0.029 sec/batch; 1h:23m:33s remains)
INFO - root - 2022-02-24 19:35:42.261371: step 28570, total loss = 0.53, batch loss = 0.24 (289.3 examples/sec; 0.028 sec/batch; 1h:18m:46s remains)
INFO - root - 2022-02-24 19:35:42.766754: step 28580, total loss = 0.52, batch loss = 0.23 (278.8 examples/sec; 0.029 sec/batch; 1h:21m:43s remains)
INFO - root - 2022-02-24 19:35:43.152636: step 28590, total loss = 0.63, batch loss = 0.35 (130.3 examples/sec; 0.061 sec/batch; 2h:54m:50s remains)
INFO - root - 2022-02-24 19:35:43.488096: step 28600, total loss = 0.64, batch loss = 0.35 (218.8 examples/sec; 0.037 sec/batch; 1h:44m:07s remains)
INFO - root - 2022-02-24 19:35:43.936740: step 28610, total loss = 0.55, batch loss = 0.27 (141.1 examples/sec; 0.057 sec/batch; 2h:41m:25s remains)
INFO - root - 2022-02-24 19:35:44.394228: step 28620, total loss = 0.53, batch loss = 0.24 (167.5 examples/sec; 0.048 sec/batch; 2h:16m:01s remains)
INFO - root - 2022-02-24 19:35:44.792367: step 28630, total loss = 0.64, batch loss = 0.35 (299.5 examples/sec; 0.027 sec/batch; 1h:16m:04s remains)
INFO - root - 2022-02-24 19:35:45.143338: step 28640, total loss = 0.53, batch loss = 0.25 (237.8 examples/sec; 0.034 sec/batch; 1h:35m:47s remains)
INFO - root - 2022-02-24 19:35:45.483418: step 28650, total loss = 0.64, batch loss = 0.35 (186.8 examples/sec; 0.043 sec/batch; 2h:01m:56s remains)
INFO - root - 2022-02-24 19:35:45.838845: step 28660, total loss = 0.61, batch loss = 0.33 (249.4 examples/sec; 0.032 sec/batch; 1h:31m:20s remains)
INFO - root - 2022-02-24 19:35:46.272361: step 28670, total loss = 0.61, batch loss = 0.33 (335.5 examples/sec; 0.024 sec/batch; 1h:07m:53s remains)
INFO - root - 2022-02-24 19:35:46.677152: step 28680, total loss = 0.61, batch loss = 0.32 (184.6 examples/sec; 0.043 sec/batch; 2h:03m:22s remains)
INFO - root - 2022-02-24 19:35:47.027684: step 28690, total loss = 0.61, batch loss = 0.32 (163.6 examples/sec; 0.049 sec/batch; 2h:19m:14s remains)
INFO - root - 2022-02-24 19:35:47.320461: step 28700, total loss = 0.59, batch loss = 0.30 (310.2 examples/sec; 0.026 sec/batch; 1h:13m:24s remains)
INFO - root - 2022-02-24 19:35:47.821449: step 28710, total loss = 0.54, batch loss = 0.26 (118.8 examples/sec; 0.067 sec/batch; 3h:11m:37s remains)
INFO - root - 2022-02-24 19:35:48.228488: step 28720, total loss = 0.53, batch loss = 0.25 (288.5 examples/sec; 0.028 sec/batch; 1h:18m:56s remains)
INFO - root - 2022-02-24 19:35:48.684202: step 28730, total loss = 0.62, batch loss = 0.33 (267.0 examples/sec; 0.030 sec/batch; 1h:25m:16s remains)
INFO - root - 2022-02-24 19:35:49.060490: step 28740, total loss = 0.55, batch loss = 0.27 (102.4 examples/sec; 0.078 sec/batch; 3h:42m:14s remains)
INFO - root - 2022-02-24 19:35:49.386869: step 28750, total loss = 0.54, batch loss = 0.26 (301.1 examples/sec; 0.027 sec/batch; 1h:15m:37s remains)
INFO - root - 2022-02-24 19:35:49.713427: step 28760, total loss = 0.54, batch loss = 0.25 (229.1 examples/sec; 0.035 sec/batch; 1h:39m:22s remains)
INFO - root - 2022-02-24 19:35:50.284404: step 28770, total loss = 0.59, batch loss = 0.30 (277.2 examples/sec; 0.029 sec/batch; 1h:22m:07s remains)
INFO - root - 2022-02-24 19:35:51.162232: step 28780, total loss = 0.59, batch loss = 0.31 (332.3 examples/sec; 0.024 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 19:35:51.613191: step 28790, total loss = 0.57, batch loss = 0.29 (283.5 examples/sec; 0.028 sec/batch; 1h:20m:16s remains)
INFO - root - 2022-02-24 19:35:52.006818: step 28800, total loss = 0.56, batch loss = 0.27 (318.2 examples/sec; 0.025 sec/batch; 1h:11m:31s remains)
INFO - root - 2022-02-24 19:35:52.527636: step 28810, total loss = 0.55, batch loss = 0.26 (282.3 examples/sec; 0.028 sec/batch; 1h:20m:37s remains)
INFO - root - 2022-02-24 19:35:53.051589: step 28820, total loss = 0.57, batch loss = 0.29 (105.0 examples/sec; 0.076 sec/batch; 3h:36m:39s remains)
INFO - root - 2022-02-24 19:35:53.554060: step 28830, total loss = 0.57, batch loss = 0.29 (108.3 examples/sec; 0.074 sec/batch; 3h:30m:01s remains)
INFO - root - 2022-02-24 19:35:53.893119: step 28840, total loss = 0.71, batch loss = 0.42 (131.6 examples/sec; 0.061 sec/batch; 2h:52m:56s remains)
INFO - root - 2022-02-24 19:35:54.271270: step 28850, total loss = 0.52, batch loss = 0.24 (340.7 examples/sec; 0.023 sec/batch; 1h:06m:46s remains)
INFO - root - 2022-02-24 19:35:54.694252: step 28860, total loss = 0.63, batch loss = 0.34 (267.1 examples/sec; 0.030 sec/batch; 1h:25m:11s remains)
INFO - root - 2022-02-24 19:35:55.101227: step 28870, total loss = 0.69, batch loss = 0.40 (153.7 examples/sec; 0.052 sec/batch; 2h:28m:00s remains)
INFO - root - 2022-02-24 19:35:55.593316: step 28880, total loss = 0.58, batch loss = 0.29 (195.6 examples/sec; 0.041 sec/batch; 1h:56m:19s remains)
INFO - root - 2022-02-24 19:35:56.002695: step 28890, total loss = 0.59, batch loss = 0.31 (278.5 examples/sec; 0.029 sec/batch; 1h:21m:39s remains)
INFO - root - 2022-02-24 19:35:56.752633: step 28900, total loss = 0.57, batch loss = 0.29 (238.3 examples/sec; 0.034 sec/batch; 1h:35m:26s remains)
INFO - root - 2022-02-24 19:35:57.263243: step 28910, total loss = 0.63, batch loss = 0.34 (205.4 examples/sec; 0.039 sec/batch; 1h:50m:42s remains)
INFO - root - 2022-02-24 19:35:57.793213: step 28920, total loss = 0.56, batch loss = 0.27 (164.9 examples/sec; 0.049 sec/batch; 2h:17m:57s remains)
INFO - root - 2022-02-24 19:35:58.297750: step 28930, total loss = 0.55, batch loss = 0.27 (96.6 examples/sec; 0.083 sec/batch; 3h:55m:19s remains)
INFO - root - 2022-02-24 19:35:58.610537: step 28940, total loss = 0.73, batch loss = 0.44 (316.3 examples/sec; 0.025 sec/batch; 1h:11m:53s remains)
INFO - root - 2022-02-24 19:35:58.933380: step 28950, total loss = 0.57, batch loss = 0.28 (334.2 examples/sec; 0.024 sec/batch; 1h:08m:02s remains)
INFO - root - 2022-02-24 19:35:59.295260: step 28960, total loss = 0.50, batch loss = 0.22 (153.2 examples/sec; 0.052 sec/batch; 2h:28m:23s remains)
INFO - root - 2022-02-24 19:35:59.836114: step 28970, total loss = 0.55, batch loss = 0.26 (297.7 examples/sec; 0.027 sec/batch; 1h:16m:23s remains)
INFO - root - 2022-02-24 19:36:00.152940: step 28980, total loss = 0.67, batch loss = 0.38 (320.1 examples/sec; 0.025 sec/batch; 1h:11m:01s remains)
INFO - root - 2022-02-24 19:36:00.458068: step 28990, total loss = 0.64, batch loss = 0.35 (311.9 examples/sec; 0.026 sec/batch; 1h:12m:53s remains)
INFO - root - 2022-02-24 19:36:00.801277: step 29000, total loss = 0.75, batch loss = 0.46 (129.3 examples/sec; 0.062 sec/batch; 2h:55m:48s remains)
INFO - root - 2022-02-24 19:36:01.328768: step 29010, total loss = 0.60, batch loss = 0.32 (269.8 examples/sec; 0.030 sec/batch; 1h:24m:15s remains)
INFO - root - 2022-02-24 19:36:01.817694: step 29020, total loss = 0.57, batch loss = 0.29 (272.1 examples/sec; 0.029 sec/batch; 1h:23m:32s remains)
INFO - root - 2022-02-24 19:36:02.144267: step 29030, total loss = 0.54, batch loss = 0.25 (313.2 examples/sec; 0.026 sec/batch; 1h:12m:34s remains)
INFO - root - 2022-02-24 19:36:02.525437: step 29040, total loss = 0.58, batch loss = 0.30 (218.6 examples/sec; 0.037 sec/batch; 1h:43m:57s remains)
INFO - root - 2022-02-24 19:36:02.872902: step 29050, total loss = 0.65, batch loss = 0.37 (306.9 examples/sec; 0.026 sec/batch; 1h:14m:03s remains)
INFO - root - 2022-02-24 19:36:03.175519: step 29060, total loss = 0.65, batch loss = 0.37 (302.1 examples/sec; 0.026 sec/batch; 1h:15m:13s remains)
INFO - root - 2022-02-24 19:36:03.637689: step 29070, total loss = 0.56, batch loss = 0.27 (212.4 examples/sec; 0.038 sec/batch; 1h:46m:59s remains)
INFO - root - 2022-02-24 19:36:04.135448: step 29080, total loss = 0.61, batch loss = 0.32 (96.4 examples/sec; 0.083 sec/batch; 3h:55m:48s remains)
INFO - root - 2022-02-24 19:36:04.457483: step 29090, total loss = 0.53, batch loss = 0.25 (219.7 examples/sec; 0.036 sec/batch; 1h:43m:26s remains)
INFO - root - 2022-02-24 19:36:04.783130: step 29100, total loss = 0.63, batch loss = 0.34 (288.4 examples/sec; 0.028 sec/batch; 1h:18m:46s remains)
INFO - root - 2022-02-24 19:36:05.198934: step 29110, total loss = 0.63, batch loss = 0.35 (137.8 examples/sec; 0.058 sec/batch; 2h:44m:52s remains)
INFO - root - 2022-02-24 19:36:05.646944: step 29120, total loss = 0.51, batch loss = 0.22 (132.7 examples/sec; 0.060 sec/batch; 2h:51m:12s remains)
INFO - root - 2022-02-24 19:36:06.092132: step 29130, total loss = 0.68, batch loss = 0.40 (200.6 examples/sec; 0.040 sec/batch; 1h:53m:15s remains)
INFO - root - 2022-02-24 19:36:06.447176: step 29140, total loss = 0.58, batch loss = 0.29 (290.5 examples/sec; 0.028 sec/batch; 1h:18m:11s remains)
INFO - root - 2022-02-24 19:36:06.855499: step 29150, total loss = 0.63, batch loss = 0.35 (318.4 examples/sec; 0.025 sec/batch; 1h:11m:20s remains)
INFO - root - 2022-02-24 19:36:07.313226: step 29160, total loss = 0.54, batch loss = 0.25 (223.3 examples/sec; 0.036 sec/batch; 1h:41m:42s remains)
INFO - root - 2022-02-24 19:36:07.745864: step 29170, total loss = 0.59, batch loss = 0.30 (337.2 examples/sec; 0.024 sec/batch; 1h:07m:21s remains)
INFO - root - 2022-02-24 19:36:08.212780: step 29180, total loss = 0.54, batch loss = 0.25 (142.0 examples/sec; 0.056 sec/batch; 2h:39m:56s remains)
INFO - root - 2022-02-24 19:36:08.762234: step 29190, total loss = 0.51, batch loss = 0.22 (192.7 examples/sec; 0.042 sec/batch; 1h:57m:50s remains)
INFO - root - 2022-02-24 19:36:09.367304: step 29200, total loss = 0.68, batch loss = 0.40 (227.0 examples/sec; 0.035 sec/batch; 1h:40m:02s remains)
INFO - root - 2022-02-24 19:36:10.057242: step 29210, total loss = 0.61, batch loss = 0.33 (223.5 examples/sec; 0.036 sec/batch; 1h:41m:34s remains)
INFO - root - 2022-02-24 19:36:10.574827: step 29220, total loss = 0.59, batch loss = 0.31 (250.5 examples/sec; 0.032 sec/batch; 1h:30m:38s remains)
INFO - root - 2022-02-24 19:36:10.968446: step 29230, total loss = 0.65, batch loss = 0.36 (243.8 examples/sec; 0.033 sec/batch; 1h:33m:07s remains)
INFO - root - 2022-02-24 19:36:11.373596: step 29240, total loss = 0.59, batch loss = 0.30 (327.0 examples/sec; 0.024 sec/batch; 1h:09m:25s remains)
INFO - root - 2022-02-24 19:36:12.190565: step 29250, total loss = 0.61, batch loss = 0.32 (311.3 examples/sec; 0.026 sec/batch; 1h:12m:54s remains)
INFO - root - 2022-02-24 19:36:12.617423: step 29260, total loss = 0.61, batch loss = 0.33 (352.3 examples/sec; 0.023 sec/batch; 1h:04m:25s remains)
INFO - root - 2022-02-24 19:36:13.012899: step 29270, total loss = 0.54, batch loss = 0.25 (142.3 examples/sec; 0.056 sec/batch; 2h:39m:31s remains)
INFO - root - 2022-02-24 19:36:13.381424: step 29280, total loss = 0.64, batch loss = 0.35 (264.7 examples/sec; 0.030 sec/batch; 1h:25m:44s remains)
INFO - root - 2022-02-24 19:36:13.743788: step 29290, total loss = 0.64, batch loss = 0.36 (348.3 examples/sec; 0.023 sec/batch; 1h:05m:09s remains)
INFO - root - 2022-02-24 19:36:14.126887: step 29300, total loss = 0.61, batch loss = 0.33 (247.8 examples/sec; 0.032 sec/batch; 1h:31m:35s remains)
INFO - root - 2022-02-24 19:36:14.755396: step 29310, total loss = 0.66, batch loss = 0.38 (190.7 examples/sec; 0.042 sec/batch; 1h:59m:00s remains)
INFO - root - 2022-02-24 19:36:15.104414: step 29320, total loss = 0.71, batch loss = 0.42 (339.1 examples/sec; 0.024 sec/batch; 1h:06m:55s remains)
INFO - root - 2022-02-24 19:36:15.512277: step 29330, total loss = 0.59, batch loss = 0.30 (130.0 examples/sec; 0.062 sec/batch; 2h:54m:29s remains)
INFO - root - 2022-02-24 19:36:15.983506: step 29340, total loss = 0.68, batch loss = 0.39 (227.4 examples/sec; 0.035 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 19:36:16.511850: step 29350, total loss = 0.55, batch loss = 0.26 (213.2 examples/sec; 0.038 sec/batch; 1h:46m:24s remains)
INFO - root - 2022-02-24 19:36:17.135508: step 29360, total loss = 0.67, batch loss = 0.39 (159.6 examples/sec; 0.050 sec/batch; 2h:22m:06s remains)
INFO - root - 2022-02-24 19:36:17.490531: step 29370, total loss = 0.55, batch loss = 0.27 (328.2 examples/sec; 0.024 sec/batch; 1h:09m:07s remains)
INFO - root - 2022-02-24 19:36:17.945357: step 29380, total loss = 0.59, batch loss = 0.30 (133.1 examples/sec; 0.060 sec/batch; 2h:50m:26s remains)
INFO - root - 2022-02-24 19:36:18.302528: step 29390, total loss = 0.59, batch loss = 0.31 (140.0 examples/sec; 0.057 sec/batch; 2h:41m:57s remains)
INFO - root - 2022-02-24 19:36:18.852904: step 29400, total loss = 0.63, batch loss = 0.34 (326.3 examples/sec; 0.025 sec/batch; 1h:09m:29s remains)
INFO - root - 2022-02-24 19:36:19.378707: step 29410, total loss = 0.60, batch loss = 0.31 (105.5 examples/sec; 0.076 sec/batch; 3h:34m:56s remains)
INFO - root - 2022-02-24 19:36:19.734011: step 29420, total loss = 0.58, batch loss = 0.30 (321.8 examples/sec; 0.025 sec/batch; 1h:10m:28s remains)
INFO - root - 2022-02-24 19:36:20.106971: step 29430, total loss = 0.58, batch loss = 0.29 (244.2 examples/sec; 0.033 sec/batch; 1h:32m:52s remains)
INFO - root - 2022-02-24 19:36:20.472174: step 29440, total loss = 0.61, batch loss = 0.32 (283.3 examples/sec; 0.028 sec/batch; 1h:20m:02s remains)
INFO - root - 2022-02-24 19:36:20.896102: step 29450, total loss = 0.63, batch loss = 0.35 (285.9 examples/sec; 0.028 sec/batch; 1h:19m:18s remains)
INFO - root - 2022-02-24 19:36:21.345977: step 29460, total loss = 0.65, batch loss = 0.36 (339.0 examples/sec; 0.024 sec/batch; 1h:06m:52s remains)
INFO - root - 2022-02-24 19:36:21.876112: step 29470, total loss = 0.51, batch loss = 0.22 (297.3 examples/sec; 0.027 sec/batch; 1h:16m:14s remains)
INFO - root - 2022-02-24 19:36:22.269500: step 29480, total loss = 0.50, batch loss = 0.22 (151.8 examples/sec; 0.053 sec/batch; 2h:29m:23s remains)
INFO - root - 2022-02-24 19:36:22.697489: step 29490, total loss = 0.61, batch loss = 0.33 (280.3 examples/sec; 0.029 sec/batch; 1h:20m:51s remains)
INFO - root - 2022-02-24 19:36:23.155389: step 29500, total loss = 0.63, batch loss = 0.34 (162.2 examples/sec; 0.049 sec/batch; 2h:19m:44s remains)
INFO - root - 2022-02-24 19:36:23.715741: step 29510, total loss = 0.62, batch loss = 0.33 (173.6 examples/sec; 0.046 sec/batch; 2h:10m:35s remains)
INFO - root - 2022-02-24 19:36:24.035526: step 29520, total loss = 0.74, batch loss = 0.45 (304.5 examples/sec; 0.026 sec/batch; 1h:14m:25s remains)
INFO - root - 2022-02-24 19:36:24.418206: step 29530, total loss = 0.62, batch loss = 0.33 (160.6 examples/sec; 0.050 sec/batch; 2h:21m:05s remains)
INFO - root - 2022-02-24 19:36:24.791683: step 29540, total loss = 0.58, batch loss = 0.29 (344.5 examples/sec; 0.023 sec/batch; 1h:05m:47s remains)
INFO - root - 2022-02-24 19:36:25.194578: step 29550, total loss = 0.55, batch loss = 0.26 (257.6 examples/sec; 0.031 sec/batch; 1h:27m:57s remains)
INFO - root - 2022-02-24 19:36:25.608687: step 29560, total loss = 0.60, batch loss = 0.32 (264.9 examples/sec; 0.030 sec/batch; 1h:25m:32s remains)
INFO - root - 2022-02-24 19:36:26.030367: step 29570, total loss = 0.60, batch loss = 0.31 (134.5 examples/sec; 0.059 sec/batch; 2h:48m:27s remains)
INFO - root - 2022-02-24 19:36:26.367453: step 29580, total loss = 0.62, batch loss = 0.33 (277.8 examples/sec; 0.029 sec/batch; 1h:21m:33s remains)
INFO - root - 2022-02-24 19:36:26.725162: step 29590, total loss = 0.59, batch loss = 0.30 (225.3 examples/sec; 0.036 sec/batch; 1h:40m:33s remains)
INFO - root - 2022-02-24 19:36:27.446007: step 29600, total loss = 0.68, batch loss = 0.39 (177.5 examples/sec; 0.045 sec/batch; 2h:07m:36s remains)
INFO - root - 2022-02-24 19:36:27.982486: step 29610, total loss = 0.62, batch loss = 0.33 (183.4 examples/sec; 0.044 sec/batch; 2h:03m:31s remains)
INFO - root - 2022-02-24 19:36:28.378539: step 29620, total loss = 0.60, batch loss = 0.31 (351.8 examples/sec; 0.023 sec/batch; 1h:04m:22s remains)
INFO - root - 2022-02-24 19:36:28.800349: step 29630, total loss = 0.74, batch loss = 0.45 (341.1 examples/sec; 0.023 sec/batch; 1h:06m:23s remains)
INFO - root - 2022-02-24 19:36:29.248222: step 29640, total loss = 0.54, batch loss = 0.25 (107.0 examples/sec; 0.075 sec/batch; 3h:31m:42s remains)
INFO - root - 2022-02-24 19:36:29.834092: step 29650, total loss = 0.61, batch loss = 0.33 (205.3 examples/sec; 0.039 sec/batch; 1h:50m:18s remains)
INFO - root - 2022-02-24 19:36:30.311965: step 29660, total loss = 0.76, batch loss = 0.48 (287.6 examples/sec; 0.028 sec/batch; 1h:18m:44s remains)
INFO - root - 2022-02-24 19:36:30.693182: step 29670, total loss = 0.59, batch loss = 0.30 (317.0 examples/sec; 0.025 sec/batch; 1h:11m:26s remains)
INFO - root - 2022-02-24 19:36:31.066193: step 29680, total loss = 0.60, batch loss = 0.31 (265.4 examples/sec; 0.030 sec/batch; 1h:25m:19s remains)
INFO - root - 2022-02-24 19:36:31.572534: step 29690, total loss = 0.66, batch loss = 0.37 (157.2 examples/sec; 0.051 sec/batch; 2h:24m:02s remains)
INFO - root - 2022-02-24 19:36:31.963193: step 29700, total loss = 0.73, batch loss = 0.45 (355.8 examples/sec; 0.022 sec/batch; 1h:03m:38s remains)
INFO - root - 2022-02-24 19:36:32.802171: step 29710, total loss = 0.62, batch loss = 0.34 (257.7 examples/sec; 0.031 sec/batch; 1h:27m:50s remains)
INFO - root - 2022-02-24 19:36:33.107864: step 29720, total loss = 0.62, batch loss = 0.33 (219.7 examples/sec; 0.036 sec/batch; 1h:43m:03s remains)
INFO - root - 2022-02-24 19:36:33.494018: step 29730, total loss = 0.58, batch loss = 0.30 (364.5 examples/sec; 0.022 sec/batch; 1h:02m:05s remains)
INFO - root - 2022-02-24 19:36:33.882882: step 29740, total loss = 0.60, batch loss = 0.31 (197.5 examples/sec; 0.041 sec/batch; 1h:54m:35s remains)
INFO - root - 2022-02-24 19:36:34.378444: step 29750, total loss = 0.64, batch loss = 0.36 (131.9 examples/sec; 0.061 sec/batch; 2h:51m:38s remains)
INFO - root - 2022-02-24 19:36:34.869996: step 29760, total loss = 0.51, batch loss = 0.22 (166.4 examples/sec; 0.048 sec/batch; 2h:16m:00s remains)
INFO - root - 2022-02-24 19:36:35.305672: step 29770, total loss = 0.58, batch loss = 0.29 (311.2 examples/sec; 0.026 sec/batch; 1h:12m:43s remains)
INFO - root - 2022-02-24 19:36:35.683008: step 29780, total loss = 0.57, batch loss = 0.28 (158.0 examples/sec; 0.051 sec/batch; 2h:23m:12s remains)
INFO - root - 2022-02-24 19:36:36.001945: step 29790, total loss = 0.71, batch loss = 0.42 (325.4 examples/sec; 0.025 sec/batch; 1h:09m:32s remains)
INFO - root - 2022-02-24 19:36:36.506334: step 29800, total loss = 0.71, batch loss = 0.42 (359.8 examples/sec; 0.022 sec/batch; 1h:02m:53s remains)
INFO - root - 2022-02-24 19:36:36.993734: step 29810, total loss = 0.67, batch loss = 0.38 (179.6 examples/sec; 0.045 sec/batch; 2h:05m:57s remains)
INFO - root - 2022-02-24 19:36:37.476981: step 29820, total loss = 0.50, batch loss = 0.21 (115.9 examples/sec; 0.069 sec/batch; 3h:15m:10s remains)
INFO - root - 2022-02-24 19:36:37.836479: step 29830, total loss = 0.65, batch loss = 0.36 (281.0 examples/sec; 0.028 sec/batch; 1h:20m:30s remains)
INFO - root - 2022-02-24 19:36:38.203067: step 29840, total loss = 0.57, batch loss = 0.29 (341.9 examples/sec; 0.023 sec/batch; 1h:06m:09s remains)
INFO - root - 2022-02-24 19:36:38.513869: step 29850, total loss = 0.65, batch loss = 0.36 (318.4 examples/sec; 0.025 sec/batch; 1h:11m:02s remains)
INFO - root - 2022-02-24 19:36:38.950862: step 29860, total loss = 0.53, batch loss = 0.24 (145.5 examples/sec; 0.055 sec/batch; 2h:35m:28s remains)
INFO - root - 2022-02-24 19:36:39.385908: step 29870, total loss = 0.57, batch loss = 0.29 (280.2 examples/sec; 0.029 sec/batch; 1h:20m:43s remains)
INFO - root - 2022-02-24 19:36:39.874610: step 29880, total loss = 0.70, batch loss = 0.41 (135.5 examples/sec; 0.059 sec/batch; 2h:46m:56s remains)
INFO - root - 2022-02-24 19:36:40.249936: step 29890, total loss = 0.69, batch loss = 0.40 (258.1 examples/sec; 0.031 sec/batch; 1h:27m:36s remains)
INFO - root - 2022-02-24 19:36:40.665879: step 29900, total loss = 0.62, batch loss = 0.34 (113.9 examples/sec; 0.070 sec/batch; 3h:18m:32s remains)
INFO - root - 2022-02-24 19:36:41.065813: step 29910, total loss = 0.67, batch loss = 0.38 (314.1 examples/sec; 0.025 sec/batch; 1h:11m:59s remains)
INFO - root - 2022-02-24 19:36:41.447577: step 29920, total loss = 0.66, batch loss = 0.37 (227.3 examples/sec; 0.035 sec/batch; 1h:39m:29s remains)
INFO - root - 2022-02-24 19:36:41.930602: step 29930, total loss = 0.56, batch loss = 0.27 (401.6 examples/sec; 0.020 sec/batch; 0h:56m:18s remains)
INFO - root - 2022-02-24 19:36:42.288588: step 29940, total loss = 0.52, batch loss = 0.24 (155.1 examples/sec; 0.052 sec/batch; 2h:25m:45s remains)
INFO - root - 2022-02-24 19:36:42.663038: step 29950, total loss = 0.56, batch loss = 0.28 (184.1 examples/sec; 0.043 sec/batch; 2h:02m:47s remains)
INFO - root - 2022-02-24 19:36:42.999242: step 29960, total loss = 0.54, batch loss = 0.26 (357.4 examples/sec; 0.022 sec/batch; 1h:03m:15s remains)
INFO - root - 2022-02-24 19:36:43.490883: step 29970, total loss = 0.56, batch loss = 0.28 (374.6 examples/sec; 0.021 sec/batch; 1h:00m:20s remains)
INFO - root - 2022-02-24 19:36:43.948075: step 29980, total loss = 0.62, batch loss = 0.34 (110.1 examples/sec; 0.073 sec/batch; 3h:25m:19s remains)
INFO - root - 2022-02-24 19:36:44.325427: step 29990, total loss = 0.57, batch loss = 0.29 (332.6 examples/sec; 0.024 sec/batch; 1h:07m:57s remains)
INFO - root - 2022-02-24 19:36:44.708495: step 30000, total loss = 0.56, batch loss = 0.28 (199.5 examples/sec; 0.040 sec/batch; 1h:53m:16s remains)
INFO - root - 2022-02-24 19:36:45.147593: step 30010, total loss = 0.60, batch loss = 0.32 (165.7 examples/sec; 0.048 sec/batch; 2h:16m:20s remains)
INFO - root - 2022-02-24 19:36:45.666942: step 30020, total loss = 0.54, batch loss = 0.25 (145.3 examples/sec; 0.055 sec/batch; 2h:35m:29s remains)
INFO - root - 2022-02-24 19:36:46.267011: step 30030, total loss = 0.66, batch loss = 0.38 (77.8 examples/sec; 0.103 sec/batch; 4h:50m:27s remains)
INFO - root - 2022-02-24 19:36:47.068577: step 30040, total loss = 0.58, batch loss = 0.30 (60.9 examples/sec; 0.131 sec/batch; 6h:11m:13s remains)
INFO - root - 2022-02-24 19:36:48.091911: step 30050, total loss = 0.56, batch loss = 0.27 (118.9 examples/sec; 0.067 sec/batch; 3h:10m:03s remains)
INFO - root - 2022-02-24 19:36:48.483615: step 30060, total loss = 0.57, batch loss = 0.29 (220.4 examples/sec; 0.036 sec/batch; 1h:42m:30s remains)
INFO - root - 2022-02-24 19:36:48.815021: step 30070, total loss = 0.62, batch loss = 0.34 (205.7 examples/sec; 0.039 sec/batch; 1h:49m:48s remains)
INFO - root - 2022-02-24 19:36:49.205716: step 30080, total loss = 0.73, batch loss = 0.44 (159.2 examples/sec; 0.050 sec/batch; 2h:21m:56s remains)
INFO - root - 2022-02-24 19:36:49.621707: step 30090, total loss = 0.66, batch loss = 0.38 (161.4 examples/sec; 0.050 sec/batch; 2h:19m:54s remains)
INFO - root - 2022-02-24 19:36:50.149501: step 30100, total loss = 0.52, batch loss = 0.24 (156.2 examples/sec; 0.051 sec/batch; 2h:24m:37s remains)
INFO - root - 2022-02-24 19:36:50.734842: step 30110, total loss = 0.67, batch loss = 0.38 (175.3 examples/sec; 0.046 sec/batch; 2h:08m:51s remains)
INFO - root - 2022-02-24 19:36:51.106001: step 30120, total loss = 0.59, batch loss = 0.31 (232.6 examples/sec; 0.034 sec/batch; 1h:37m:06s remains)
INFO - root - 2022-02-24 19:36:51.544767: step 30130, total loss = 0.56, batch loss = 0.27 (328.4 examples/sec; 0.024 sec/batch; 1h:08m:45s remains)
INFO - root - 2022-02-24 19:36:52.016285: step 30140, total loss = 0.53, batch loss = 0.25 (213.1 examples/sec; 0.038 sec/batch; 1h:45m:58s remains)
INFO - root - 2022-02-24 19:36:52.726084: step 30150, total loss = 0.65, batch loss = 0.37 (234.7 examples/sec; 0.034 sec/batch; 1h:36m:13s remains)
INFO - root - 2022-02-24 19:36:53.160400: step 30160, total loss = 0.61, batch loss = 0.32 (232.8 examples/sec; 0.034 sec/batch; 1h:37m:00s remains)
INFO - root - 2022-02-24 19:36:53.589672: step 30170, total loss = 0.61, batch loss = 0.32 (313.9 examples/sec; 0.025 sec/batch; 1h:11m:55s remains)
INFO - root - 2022-02-24 19:36:54.008580: step 30180, total loss = 0.64, batch loss = 0.36 (213.5 examples/sec; 0.037 sec/batch; 1h:45m:43s remains)
INFO - root - 2022-02-24 19:36:54.478760: step 30190, total loss = 0.66, batch loss = 0.38 (222.0 examples/sec; 0.036 sec/batch; 1h:41m:40s remains)
INFO - root - 2022-02-24 19:36:54.981263: step 30200, total loss = 0.55, batch loss = 0.27 (155.2 examples/sec; 0.052 sec/batch; 2h:25m:28s remains)
INFO - root - 2022-02-24 19:36:55.533623: step 30210, total loss = 0.66, batch loss = 0.37 (169.8 examples/sec; 0.047 sec/batch; 2h:12m:54s remains)
INFO - root - 2022-02-24 19:36:55.878656: step 30220, total loss = 0.57, batch loss = 0.29 (164.3 examples/sec; 0.049 sec/batch; 2h:17m:24s remains)
INFO - root - 2022-02-24 19:36:56.381639: step 30230, total loss = 0.55, batch loss = 0.26 (107.2 examples/sec; 0.075 sec/batch; 3h:30m:36s remains)
INFO - root - 2022-02-24 19:36:56.836340: step 30240, total loss = 0.62, batch loss = 0.33 (222.8 examples/sec; 0.036 sec/batch; 1h:41m:16s remains)
INFO - root - 2022-02-24 19:36:57.204874: step 30250, total loss = 0.73, batch loss = 0.45 (319.4 examples/sec; 0.025 sec/batch; 1h:10m:39s remains)
INFO - root - 2022-02-24 19:36:57.615094: step 30260, total loss = 0.64, batch loss = 0.35 (205.3 examples/sec; 0.039 sec/batch; 1h:49m:55s remains)
INFO - root - 2022-02-24 19:36:57.972105: step 30270, total loss = 0.57, batch loss = 0.29 (272.1 examples/sec; 0.029 sec/batch; 1h:22m:54s remains)
INFO - root - 2022-02-24 19:36:58.459592: step 30280, total loss = 0.71, batch loss = 0.43 (87.4 examples/sec; 0.092 sec/batch; 4h:18m:17s remains)
INFO - root - 2022-02-24 19:36:58.866695: step 30290, total loss = 0.64, batch loss = 0.36 (140.8 examples/sec; 0.057 sec/batch; 2h:40m:15s remains)
INFO - root - 2022-02-24 19:36:59.260170: step 30300, total loss = 0.56, batch loss = 0.28 (141.0 examples/sec; 0.057 sec/batch; 2h:40m:01s remains)
INFO - root - 2022-02-24 19:36:59.756940: step 30310, total loss = 0.68, batch loss = 0.39 (203.2 examples/sec; 0.039 sec/batch; 1h:51m:00s remains)
INFO - root - 2022-02-24 19:37:00.291182: step 30320, total loss = 0.69, batch loss = 0.41 (133.9 examples/sec; 0.060 sec/batch; 2h:48m:24s remains)
INFO - root - 2022-02-24 19:37:00.720969: step 30330, total loss = 0.72, batch loss = 0.43 (157.4 examples/sec; 0.051 sec/batch; 2h:23m:15s remains)
INFO - root - 2022-02-24 19:37:01.134244: step 30340, total loss = 0.56, batch loss = 0.27 (204.1 examples/sec; 0.039 sec/batch; 1h:50m:30s remains)
INFO - root - 2022-02-24 19:37:01.455567: step 30350, total loss = 0.49, batch loss = 0.21 (258.4 examples/sec; 0.031 sec/batch; 1h:27m:17s remains)
INFO - root - 2022-02-24 19:37:01.779384: step 30360, total loss = 0.58, batch loss = 0.29 (242.8 examples/sec; 0.033 sec/batch; 1h:32m:53s remains)
INFO - root - 2022-02-24 19:37:02.212318: step 30370, total loss = 0.54, batch loss = 0.25 (231.8 examples/sec; 0.035 sec/batch; 1h:37m:16s remains)
INFO - root - 2022-02-24 19:37:02.676057: step 30380, total loss = 0.63, batch loss = 0.35 (354.4 examples/sec; 0.023 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 19:37:03.032728: step 30390, total loss = 0.67, batch loss = 0.39 (169.4 examples/sec; 0.047 sec/batch; 2h:13m:05s remains)
INFO - root - 2022-02-24 19:37:03.331756: step 30400, total loss = 0.72, batch loss = 0.43 (373.6 examples/sec; 0.021 sec/batch; 1h:00m:21s remains)
INFO - root - 2022-02-24 19:37:03.763764: step 30410, total loss = 0.56, batch loss = 0.27 (244.9 examples/sec; 0.033 sec/batch; 1h:32m:02s remains)
INFO - root - 2022-02-24 19:37:04.259799: step 30420, total loss = 0.66, batch loss = 0.37 (152.0 examples/sec; 0.053 sec/batch; 2h:28m:21s remains)
INFO - root - 2022-02-24 19:37:04.773123: step 30430, total loss = 0.53, batch loss = 0.24 (111.6 examples/sec; 0.072 sec/batch; 3h:21m:56s remains)
INFO - root - 2022-02-24 19:37:05.273773: step 30440, total loss = 0.67, batch loss = 0.38 (204.0 examples/sec; 0.039 sec/batch; 1h:50m:30s remains)
INFO - root - 2022-02-24 19:37:05.853734: step 30450, total loss = 0.48, batch loss = 0.20 (92.3 examples/sec; 0.087 sec/batch; 4h:04m:04s remains)
INFO - root - 2022-02-24 19:37:06.566138: step 30460, total loss = 0.75, batch loss = 0.47 (221.3 examples/sec; 0.036 sec/batch; 1h:41m:49s remains)
INFO - root - 2022-02-24 19:37:07.150710: step 30470, total loss = 0.60, batch loss = 0.31 (104.1 examples/sec; 0.077 sec/batch; 3h:36m:31s remains)
INFO - root - 2022-02-24 19:37:07.962086: step 30480, total loss = 0.55, batch loss = 0.26 (294.8 examples/sec; 0.027 sec/batch; 1h:16m:26s remains)
INFO - root - 2022-02-24 19:37:08.393664: step 30490, total loss = 0.63, batch loss = 0.35 (256.7 examples/sec; 0.031 sec/batch; 1h:27m:47s remains)
INFO - root - 2022-02-24 19:37:08.844984: step 30500, total loss = 0.62, batch loss = 0.34 (309.0 examples/sec; 0.026 sec/batch; 1h:12m:55s remains)
INFO - root - 2022-02-24 19:37:09.284493: step 30510, total loss = 0.64, batch loss = 0.36 (312.0 examples/sec; 0.026 sec/batch; 1h:12m:13s remains)
INFO - root - 2022-02-24 19:37:09.663136: step 30520, total loss = 0.53, batch loss = 0.24 (175.9 examples/sec; 0.045 sec/batch; 2h:08m:04s remains)
INFO - root - 2022-02-24 19:37:10.058633: step 30530, total loss = 0.58, batch loss = 0.29 (159.2 examples/sec; 0.050 sec/batch; 2h:21m:30s remains)
INFO - root - 2022-02-24 19:37:10.546830: step 30540, total loss = 0.58, batch loss = 0.30 (209.8 examples/sec; 0.038 sec/batch; 1h:47m:23s remains)
INFO - root - 2022-02-24 19:37:10.919793: step 30550, total loss = 0.65, batch loss = 0.37 (234.1 examples/sec; 0.034 sec/batch; 1h:36m:14s remains)
INFO - root - 2022-02-24 19:37:11.303854: step 30560, total loss = 0.53, batch loss = 0.25 (168.4 examples/sec; 0.048 sec/batch; 2h:13m:45s remains)
INFO - root - 2022-02-24 19:37:11.634201: step 30570, total loss = 0.52, batch loss = 0.24 (352.0 examples/sec; 0.023 sec/batch; 1h:03m:59s remains)
INFO - root - 2022-02-24 19:37:11.963532: step 30580, total loss = 0.51, batch loss = 0.22 (340.7 examples/sec; 0.023 sec/batch; 1h:06m:06s remains)
INFO - root - 2022-02-24 19:37:12.385525: step 30590, total loss = 0.56, batch loss = 0.28 (132.8 examples/sec; 0.060 sec/batch; 2h:49m:32s remains)
INFO - root - 2022-02-24 19:37:12.731719: step 30600, total loss = 0.66, batch loss = 0.38 (249.6 examples/sec; 0.032 sec/batch; 1h:30m:13s remains)
INFO - root - 2022-02-24 19:37:13.201538: step 30610, total loss = 0.61, batch loss = 0.32 (340.3 examples/sec; 0.024 sec/batch; 1h:06m:10s remains)
INFO - root - 2022-02-24 19:37:13.550352: step 30620, total loss = 0.71, batch loss = 0.43 (323.8 examples/sec; 0.025 sec/batch; 1h:09m:32s remains)
INFO - root - 2022-02-24 19:37:13.941399: step 30630, total loss = 0.61, batch loss = 0.33 (166.3 examples/sec; 0.048 sec/batch; 2h:15m:24s remains)
INFO - root - 2022-02-24 19:37:14.256693: step 30640, total loss = 0.50, batch loss = 0.22 (156.2 examples/sec; 0.051 sec/batch; 2h:24m:08s remains)
INFO - root - 2022-02-24 19:37:14.666915: step 30650, total loss = 0.54, batch loss = 0.26 (100.1 examples/sec; 0.080 sec/batch; 3h:44m:52s remains)
INFO - root - 2022-02-24 19:37:15.077734: step 30660, total loss = 0.61, batch loss = 0.33 (149.2 examples/sec; 0.054 sec/batch; 2h:30m:53s remains)
INFO - root - 2022-02-24 19:37:15.474275: step 30670, total loss = 0.60, batch loss = 0.32 (110.0 examples/sec; 0.073 sec/batch; 3h:24m:43s remains)
INFO - root - 2022-02-24 19:37:15.776728: step 30680, total loss = 0.61, batch loss = 0.32 (323.2 examples/sec; 0.025 sec/batch; 1h:09m:38s remains)
INFO - root - 2022-02-24 19:37:16.114601: step 30690, total loss = 0.76, batch loss = 0.47 (149.2 examples/sec; 0.054 sec/batch; 2h:30m:53s remains)
INFO - root - 2022-02-24 19:37:16.520729: step 30700, total loss = 0.66, batch loss = 0.38 (300.5 examples/sec; 0.027 sec/batch; 1h:14m:54s remains)
INFO - root - 2022-02-24 19:37:17.052297: step 30710, total loss = 0.69, batch loss = 0.41 (222.0 examples/sec; 0.036 sec/batch; 1h:41m:21s remains)
INFO - root - 2022-02-24 19:37:17.461691: step 30720, total loss = 0.64, batch loss = 0.35 (186.4 examples/sec; 0.043 sec/batch; 2h:00m:44s remains)
INFO - root - 2022-02-24 19:37:17.840750: step 30730, total loss = 0.67, batch loss = 0.39 (245.4 examples/sec; 0.033 sec/batch; 1h:31m:41s remains)
INFO - root - 2022-02-24 19:37:18.191842: step 30740, total loss = 0.56, batch loss = 0.28 (164.7 examples/sec; 0.049 sec/batch; 2h:16m:39s remains)
INFO - root - 2022-02-24 19:37:18.474787: step 30750, total loss = 0.66, batch loss = 0.38 (235.2 examples/sec; 0.034 sec/batch; 1h:35m:39s remains)
INFO - root - 2022-02-24 19:37:18.941903: step 30760, total loss = 0.58, batch loss = 0.29 (186.6 examples/sec; 0.043 sec/batch; 2h:00m:32s remains)
INFO - root - 2022-02-24 19:37:19.283292: step 30770, total loss = 0.69, batch loss = 0.40 (189.6 examples/sec; 0.042 sec/batch; 1h:58m:39s remains)
INFO - root - 2022-02-24 19:37:19.610852: step 30780, total loss = 0.60, batch loss = 0.32 (325.6 examples/sec; 0.025 sec/batch; 1h:09m:05s remains)
INFO - root - 2022-02-24 19:37:19.939570: step 30790, total loss = 0.51, batch loss = 0.23 (287.6 examples/sec; 0.028 sec/batch; 1h:18m:13s remains)
INFO - root - 2022-02-24 19:37:20.336120: step 30800, total loss = 0.53, batch loss = 0.24 (164.5 examples/sec; 0.049 sec/batch; 2h:16m:45s remains)
INFO - root - 2022-02-24 19:37:20.905632: step 30810, total loss = 0.66, batch loss = 0.37 (326.1 examples/sec; 0.025 sec/batch; 1h:08m:58s remains)
INFO - root - 2022-02-24 19:37:21.286387: step 30820, total loss = 0.50, batch loss = 0.22 (268.9 examples/sec; 0.030 sec/batch; 1h:23m:38s remains)
INFO - root - 2022-02-24 19:37:21.721335: step 30830, total loss = 0.64, batch loss = 0.35 (343.3 examples/sec; 0.023 sec/batch; 1h:05m:31s remains)
INFO - root - 2022-02-24 19:37:22.092433: step 30840, total loss = 0.55, batch loss = 0.27 (194.2 examples/sec; 0.041 sec/batch; 1h:55m:47s remains)
INFO - root - 2022-02-24 19:37:22.395588: step 30850, total loss = 0.51, batch loss = 0.23 (183.9 examples/sec; 0.044 sec/batch; 2h:02m:16s remains)
INFO - root - 2022-02-24 19:37:22.730694: step 30860, total loss = 0.60, batch loss = 0.31 (189.1 examples/sec; 0.042 sec/batch; 1h:58m:53s remains)
INFO - root - 2022-02-24 19:37:23.496149: step 30870, total loss = 0.63, batch loss = 0.34 (182.3 examples/sec; 0.044 sec/batch; 2h:03m:20s remains)
INFO - root - 2022-02-24 19:37:23.926488: step 30880, total loss = 0.58, batch loss = 0.29 (264.7 examples/sec; 0.030 sec/batch; 1h:24m:55s remains)
INFO - root - 2022-02-24 19:37:24.341540: step 30890, total loss = 0.72, batch loss = 0.43 (236.4 examples/sec; 0.034 sec/batch; 1h:35m:07s remains)
INFO - root - 2022-02-24 19:37:24.733420: step 30900, total loss = 0.53, batch loss = 0.24 (191.3 examples/sec; 0.042 sec/batch; 1h:57m:30s remains)
INFO - root - 2022-02-24 19:37:25.202637: step 30910, total loss = 0.49, batch loss = 0.20 (246.0 examples/sec; 0.033 sec/batch; 1h:31m:23s remains)
INFO - root - 2022-02-24 19:37:25.805042: step 30920, total loss = 0.55, batch loss = 0.27 (190.5 examples/sec; 0.042 sec/batch; 1h:58m:01s remains)
INFO - root - 2022-02-24 19:37:26.276902: step 30930, total loss = 0.61, batch loss = 0.33 (153.7 examples/sec; 0.052 sec/batch; 2h:26m:16s remains)
INFO - root - 2022-02-24 19:37:26.726577: step 30940, total loss = 0.57, batch loss = 0.28 (148.5 examples/sec; 0.054 sec/batch; 2h:31m:17s remains)
INFO - root - 2022-02-24 19:37:27.148994: step 30950, total loss = 0.60, batch loss = 0.32 (196.3 examples/sec; 0.041 sec/batch; 1h:54m:29s remains)
INFO - root - 2022-02-24 19:37:27.663831: step 30960, total loss = 0.52, batch loss = 0.23 (218.0 examples/sec; 0.037 sec/batch; 1h:43m:05s remains)
INFO - root - 2022-02-24 19:37:28.082491: step 30970, total loss = 0.64, batch loss = 0.36 (220.4 examples/sec; 0.036 sec/batch; 1h:41m:57s remains)
INFO - root - 2022-02-24 19:37:28.982484: step 30980, total loss = 0.64, batch loss = 0.36 (261.8 examples/sec; 0.031 sec/batch; 1h:25m:48s remains)
INFO - root - 2022-02-24 19:37:29.431008: step 30990, total loss = 0.60, batch loss = 0.32 (321.4 examples/sec; 0.025 sec/batch; 1h:09m:54s remains)
INFO - root - 2022-02-24 19:37:29.838199: step 31000, total loss = 0.66, batch loss = 0.38 (186.5 examples/sec; 0.043 sec/batch; 2h:00m:28s remains)
INFO - root - 2022-02-24 19:37:30.367187: step 31010, total loss = 0.55, batch loss = 0.27 (191.0 examples/sec; 0.042 sec/batch; 1h:57m:38s remains)
INFO - root - 2022-02-24 19:37:30.902164: step 31020, total loss = 0.71, batch loss = 0.42 (91.4 examples/sec; 0.087 sec/batch; 4h:05m:40s remains)
INFO - root - 2022-02-24 19:37:31.318076: step 31030, total loss = 0.59, batch loss = 0.31 (139.2 examples/sec; 0.057 sec/batch; 2h:41m:24s remains)
INFO - root - 2022-02-24 19:37:31.718515: step 31040, total loss = 0.60, batch loss = 0.32 (270.0 examples/sec; 0.030 sec/batch; 1h:23m:11s remains)
INFO - root - 2022-02-24 19:37:32.155774: step 31050, total loss = 0.58, batch loss = 0.29 (263.7 examples/sec; 0.030 sec/batch; 1h:25m:10s remains)
INFO - root - 2022-02-24 19:37:32.570808: step 31060, total loss = 0.67, batch loss = 0.39 (348.9 examples/sec; 0.023 sec/batch; 1h:04m:21s remains)
INFO - root - 2022-02-24 19:37:33.088368: step 31070, total loss = 0.77, batch loss = 0.48 (282.8 examples/sec; 0.028 sec/batch; 1h:19m:24s remains)
INFO - root - 2022-02-24 19:37:33.522627: step 31080, total loss = 0.55, batch loss = 0.26 (286.1 examples/sec; 0.028 sec/batch; 1h:18m:29s remains)
INFO - root - 2022-02-24 19:37:33.833386: step 31090, total loss = 0.54, batch loss = 0.25 (228.5 examples/sec; 0.035 sec/batch; 1h:38m:15s remains)
INFO - root - 2022-02-24 19:37:34.221037: step 31100, total loss = 0.54, batch loss = 0.25 (157.4 examples/sec; 0.051 sec/batch; 2h:22m:40s remains)
INFO - root - 2022-02-24 19:37:34.612298: step 31110, total loss = 0.56, batch loss = 0.27 (248.7 examples/sec; 0.032 sec/batch; 1h:30m:17s remains)
INFO - root - 2022-02-24 19:37:35.050237: step 31120, total loss = 0.62, batch loss = 0.34 (187.9 examples/sec; 0.043 sec/batch; 1h:59m:27s remains)
INFO - root - 2022-02-24 19:37:35.467440: step 31130, total loss = 0.62, batch loss = 0.33 (289.1 examples/sec; 0.028 sec/batch; 1h:17m:38s remains)
INFO - root - 2022-02-24 19:37:35.855571: step 31140, total loss = 0.58, batch loss = 0.30 (199.0 examples/sec; 0.040 sec/batch; 1h:52m:49s remains)
INFO - root - 2022-02-24 19:37:36.190529: step 31150, total loss = 0.53, batch loss = 0.25 (166.5 examples/sec; 0.048 sec/batch; 2h:14m:46s remains)
INFO - root - 2022-02-24 19:37:36.560263: step 31160, total loss = 0.53, batch loss = 0.24 (317.1 examples/sec; 0.025 sec/batch; 1h:10m:46s remains)
INFO - root - 2022-02-24 19:37:36.843011: step 31170, total loss = 0.68, batch loss = 0.40 (322.9 examples/sec; 0.025 sec/batch; 1h:09m:29s remains)
INFO - root - 2022-02-24 19:37:37.223377: step 31180, total loss = 0.59, batch loss = 0.31 (200.7 examples/sec; 0.040 sec/batch; 1h:51m:49s remains)
INFO - root - 2022-02-24 19:37:37.705396: step 31190, total loss = 0.54, batch loss = 0.26 (209.9 examples/sec; 0.038 sec/batch; 1h:46m:54s remains)
INFO - root - 2022-02-24 19:37:38.109690: step 31200, total loss = 0.58, batch loss = 0.30 (244.8 examples/sec; 0.033 sec/batch; 1h:31m:39s remains)
INFO - root - 2022-02-24 19:37:38.556445: step 31210, total loss = 0.54, batch loss = 0.26 (175.3 examples/sec; 0.046 sec/batch; 2h:07m:57s remains)
INFO - root - 2022-02-24 19:37:38.930555: step 31220, total loss = 0.54, batch loss = 0.25 (249.8 examples/sec; 0.032 sec/batch; 1h:29m:48s remains)
INFO - root - 2022-02-24 19:37:39.403722: step 31230, total loss = 0.51, batch loss = 0.22 (191.8 examples/sec; 0.042 sec/batch; 1h:57m:00s remains)
INFO - root - 2022-02-24 19:37:39.800538: step 31240, total loss = 0.53, batch loss = 0.24 (122.4 examples/sec; 0.065 sec/batch; 3h:03m:16s remains)
INFO - root - 2022-02-24 19:37:40.205252: step 31250, total loss = 0.57, batch loss = 0.29 (278.8 examples/sec; 0.029 sec/batch; 1h:20m:27s remains)
INFO - root - 2022-02-24 19:37:40.568225: step 31260, total loss = 0.60, batch loss = 0.32 (149.5 examples/sec; 0.054 sec/batch; 2h:30m:00s remains)
INFO - root - 2022-02-24 19:37:40.936114: step 31270, total loss = 0.52, batch loss = 0.24 (159.6 examples/sec; 0.050 sec/batch; 2h:20m:32s remains)
INFO - root - 2022-02-24 19:37:41.248155: step 31280, total loss = 0.66, batch loss = 0.37 (214.8 examples/sec; 0.037 sec/batch; 1h:44m:26s remains)
INFO - root - 2022-02-24 19:37:41.672013: step 31290, total loss = 0.75, batch loss = 0.46 (330.9 examples/sec; 0.024 sec/batch; 1h:07m:46s remains)
INFO - root - 2022-02-24 19:37:42.140213: step 31300, total loss = 0.60, batch loss = 0.31 (300.5 examples/sec; 0.027 sec/batch; 1h:14m:37s remains)
INFO - root - 2022-02-24 19:37:42.540127: step 31310, total loss = 0.64, batch loss = 0.35 (217.2 examples/sec; 0.037 sec/batch; 1h:43m:13s remains)
INFO - root - 2022-02-24 19:37:42.905182: step 31320, total loss = 0.60, batch loss = 0.32 (177.0 examples/sec; 0.045 sec/batch; 2h:06m:40s remains)
INFO - root - 2022-02-24 19:37:43.286171: step 31330, total loss = 0.66, batch loss = 0.37 (345.2 examples/sec; 0.023 sec/batch; 1h:04m:56s remains)
INFO - root - 2022-02-24 19:37:43.698552: step 31340, total loss = 0.64, batch loss = 0.36 (150.1 examples/sec; 0.053 sec/batch; 2h:29m:24s remains)
INFO - root - 2022-02-24 19:37:44.552898: step 31350, total loss = 0.69, batch loss = 0.41 (207.2 examples/sec; 0.039 sec/batch; 1h:48m:11s remains)
INFO - root - 2022-02-24 19:37:45.042067: step 31360, total loss = 0.58, batch loss = 0.30 (257.2 examples/sec; 0.031 sec/batch; 1h:27m:09s remains)
INFO - root - 2022-02-24 19:37:45.457333: step 31370, total loss = 0.58, batch loss = 0.29 (220.5 examples/sec; 0.036 sec/batch; 1h:41m:40s remains)
INFO - root - 2022-02-24 19:37:45.831169: step 31380, total loss = 0.53, batch loss = 0.24 (225.4 examples/sec; 0.035 sec/batch; 1h:39m:28s remains)
INFO - root - 2022-02-24 19:37:46.305200: step 31390, total loss = 0.56, batch loss = 0.27 (250.3 examples/sec; 0.032 sec/batch; 1h:29m:32s remains)
INFO - root - 2022-02-24 19:37:46.788606: step 31400, total loss = 0.52, batch loss = 0.24 (160.3 examples/sec; 0.050 sec/batch; 2h:19m:49s remains)
INFO - root - 2022-02-24 19:37:47.360191: step 31410, total loss = 0.58, batch loss = 0.29 (84.2 examples/sec; 0.095 sec/batch; 4h:26m:11s remains)
INFO - root - 2022-02-24 19:37:47.815693: step 31420, total loss = 0.51, batch loss = 0.23 (172.4 examples/sec; 0.046 sec/batch; 2h:10m:00s remains)
INFO - root - 2022-02-24 19:37:48.189087: step 31430, total loss = 0.63, batch loss = 0.35 (303.1 examples/sec; 0.026 sec/batch; 1h:13m:55s remains)
INFO - root - 2022-02-24 19:37:48.662506: step 31440, total loss = 0.50, batch loss = 0.22 (136.3 examples/sec; 0.059 sec/batch; 2h:44m:23s remains)
INFO - root - 2022-02-24 19:37:49.144477: step 31450, total loss = 0.54, batch loss = 0.26 (278.5 examples/sec; 0.029 sec/batch; 1h:20m:27s remains)
INFO - root - 2022-02-24 19:37:50.025620: step 31460, total loss = 0.65, batch loss = 0.37 (329.4 examples/sec; 0.024 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 19:37:50.440660: step 31470, total loss = 0.75, batch loss = 0.47 (174.2 examples/sec; 0.046 sec/batch; 2h:08m:37s remains)
INFO - root - 2022-02-24 19:37:50.926702: step 31480, total loss = 0.54, batch loss = 0.26 (71.8 examples/sec; 0.111 sec/batch; 5h:12m:02s remains)
INFO - root - 2022-02-24 19:37:51.311517: step 31490, total loss = 0.61, batch loss = 0.33 (123.5 examples/sec; 0.065 sec/batch; 3h:01m:25s remains)
INFO - root - 2022-02-24 19:37:51.690435: step 31500, total loss = 0.62, batch loss = 0.33 (312.8 examples/sec; 0.026 sec/batch; 1h:11m:36s remains)
INFO - root - 2022-02-24 19:37:52.108203: step 31510, total loss = 0.51, batch loss = 0.22 (224.0 examples/sec; 0.036 sec/batch; 1h:39m:59s remains)
INFO - root - 2022-02-24 19:37:52.449466: step 31520, total loss = 0.57, batch loss = 0.29 (346.0 examples/sec; 0.023 sec/batch; 1h:04m:44s remains)
INFO - root - 2022-02-24 19:37:52.905624: step 31530, total loss = 0.50, batch loss = 0.22 (84.5 examples/sec; 0.095 sec/batch; 4h:24m:59s remains)
INFO - root - 2022-02-24 19:37:53.608586: step 31540, total loss = 0.63, batch loss = 0.35 (172.9 examples/sec; 0.046 sec/batch; 2h:09m:29s remains)
INFO - root - 2022-02-24 19:37:54.543210: step 31550, total loss = 0.71, batch loss = 0.42 (63.4 examples/sec; 0.126 sec/batch; 5h:53m:01s remains)
INFO - root - 2022-02-24 19:37:55.260469: step 31560, total loss = 0.49, batch loss = 0.20 (171.1 examples/sec; 0.047 sec/batch; 2h:10m:50s remains)
INFO - root - 2022-02-24 19:37:55.804461: step 31570, total loss = 0.64, batch loss = 0.36 (67.5 examples/sec; 0.119 sec/batch; 5h:31m:47s remains)
INFO - root - 2022-02-24 19:37:56.422388: step 31580, total loss = 0.67, batch loss = 0.39 (246.6 examples/sec; 0.032 sec/batch; 1h:30m:46s remains)
INFO - root - 2022-02-24 19:37:56.880668: step 31590, total loss = 0.72, batch loss = 0.44 (207.9 examples/sec; 0.038 sec/batch; 1h:47m:39s remains)
INFO - root - 2022-02-24 19:37:57.383239: step 31600, total loss = 0.64, batch loss = 0.35 (144.3 examples/sec; 0.055 sec/batch; 2h:35m:05s remains)
INFO - root - 2022-02-24 19:37:58.057949: step 31610, total loss = 0.64, batch loss = 0.36 (163.2 examples/sec; 0.049 sec/batch; 2h:17m:09s remains)
INFO - root - 2022-02-24 19:37:58.643062: step 31620, total loss = 0.58, batch loss = 0.30 (133.4 examples/sec; 0.060 sec/batch; 2h:47m:44s remains)
INFO - root - 2022-02-24 19:37:59.282534: step 31630, total loss = 0.56, batch loss = 0.28 (76.0 examples/sec; 0.105 sec/batch; 4h:54m:37s remains)
INFO - root - 2022-02-24 19:37:59.966005: step 31640, total loss = 0.57, batch loss = 0.29 (108.5 examples/sec; 0.074 sec/batch; 3h:26m:16s remains)
INFO - root - 2022-02-24 19:38:00.422934: step 31650, total loss = 0.60, batch loss = 0.31 (222.4 examples/sec; 0.036 sec/batch; 1h:40m:36s remains)
INFO - root - 2022-02-24 19:38:01.660863: step 31660, total loss = 0.56, batch loss = 0.28 (132.4 examples/sec; 0.060 sec/batch; 2h:48m:59s remains)
INFO - root - 2022-02-24 19:38:02.086422: step 31670, total loss = 0.62, batch loss = 0.34 (225.1 examples/sec; 0.036 sec/batch; 1h:39m:24s remains)
INFO - root - 2022-02-24 19:38:02.605555: step 31680, total loss = 0.55, batch loss = 0.26 (169.2 examples/sec; 0.047 sec/batch; 2h:12m:16s remains)
INFO - root - 2022-02-24 19:38:03.130464: step 31690, total loss = 0.61, batch loss = 0.32 (312.1 examples/sec; 0.026 sec/batch; 1h:11m:41s remains)
INFO - root - 2022-02-24 19:38:03.477657: step 31700, total loss = 0.56, batch loss = 0.28 (300.1 examples/sec; 0.027 sec/batch; 1h:14m:33s remains)
INFO - root - 2022-02-24 19:38:03.958353: step 31710, total loss = 0.68, batch loss = 0.39 (168.6 examples/sec; 0.047 sec/batch; 2h:12m:39s remains)
INFO - root - 2022-02-24 19:38:04.415663: step 31720, total loss = 0.70, batch loss = 0.41 (141.2 examples/sec; 0.057 sec/batch; 2h:38m:25s remains)
INFO - root - 2022-02-24 19:38:04.934215: step 31730, total loss = 0.57, batch loss = 0.29 (330.4 examples/sec; 0.024 sec/batch; 1h:07m:41s remains)
INFO - root - 2022-02-24 19:38:05.267161: step 31740, total loss = 0.55, batch loss = 0.27 (233.9 examples/sec; 0.034 sec/batch; 1h:35m:39s remains)
INFO - root - 2022-02-24 19:38:05.687245: step 31750, total loss = 0.65, batch loss = 0.36 (277.8 examples/sec; 0.029 sec/batch; 1h:20m:30s remains)
INFO - root - 2022-02-24 19:38:06.112100: step 31760, total loss = 0.55, batch loss = 0.27 (187.3 examples/sec; 0.043 sec/batch; 1h:59m:26s remains)
INFO - root - 2022-02-24 19:38:06.616565: step 31770, total loss = 0.55, batch loss = 0.27 (139.2 examples/sec; 0.057 sec/batch; 2h:40m:38s remains)
INFO - root - 2022-02-24 19:38:07.087177: step 31780, total loss = 0.50, batch loss = 0.22 (92.3 examples/sec; 0.087 sec/batch; 4h:02m:12s remains)
INFO - root - 2022-02-24 19:38:07.405890: step 31790, total loss = 0.54, batch loss = 0.26 (324.5 examples/sec; 0.025 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 19:38:07.739153: step 31800, total loss = 0.67, batch loss = 0.38 (198.3 examples/sec; 0.040 sec/batch; 1h:52m:44s remains)
INFO - root - 2022-02-24 19:38:08.207577: step 31810, total loss = 0.49, batch loss = 0.20 (355.7 examples/sec; 0.022 sec/batch; 1h:02m:51s remains)
INFO - root - 2022-02-24 19:38:08.630016: step 31820, total loss = 0.59, batch loss = 0.31 (381.5 examples/sec; 0.021 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 19:38:09.094539: step 31830, total loss = 0.67, batch loss = 0.38 (224.1 examples/sec; 0.036 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 19:38:09.383682: step 31840, total loss = 0.48, batch loss = 0.19 (231.3 examples/sec; 0.035 sec/batch; 1h:36m:38s remains)
INFO - root - 2022-02-24 19:38:09.746251: step 31850, total loss = 0.57, batch loss = 0.28 (265.1 examples/sec; 0.030 sec/batch; 1h:24m:20s remains)
INFO - root - 2022-02-24 19:38:10.012189: step 31860, total loss = 0.51, batch loss = 0.22 (197.9 examples/sec; 0.040 sec/batch; 1h:52m:55s remains)
INFO - root - 2022-02-24 19:38:10.347011: step 31870, total loss = 0.68, batch loss = 0.39 (253.9 examples/sec; 0.032 sec/batch; 1h:28m:02s remains)
INFO - root - 2022-02-24 19:38:10.731351: step 31880, total loss = 0.68, batch loss = 0.40 (290.5 examples/sec; 0.028 sec/batch; 1h:16m:55s remains)
INFO - root - 2022-02-24 19:38:11.145725: step 31890, total loss = 0.71, batch loss = 0.43 (337.8 examples/sec; 0.024 sec/batch; 1h:06m:09s remains)
INFO - root - 2022-02-24 19:38:11.537128: step 31900, total loss = 0.62, batch loss = 0.34 (301.0 examples/sec; 0.027 sec/batch; 1h:14m:13s remains)
INFO - root - 2022-02-24 19:38:11.930162: step 31910, total loss = 0.53, batch loss = 0.25 (179.0 examples/sec; 0.045 sec/batch; 2h:04m:49s remains)
INFO - root - 2022-02-24 19:38:12.305791: step 31920, total loss = 0.64, batch loss = 0.35 (181.4 examples/sec; 0.044 sec/batch; 2h:03m:11s remains)
INFO - root - 2022-02-24 19:38:12.709193: step 31930, total loss = 0.67, batch loss = 0.39 (146.3 examples/sec; 0.055 sec/batch; 2h:32m:45s remains)
INFO - root - 2022-02-24 19:38:13.134688: step 31940, total loss = 0.54, batch loss = 0.25 (199.4 examples/sec; 0.040 sec/batch; 1h:52m:01s remains)
INFO - root - 2022-02-24 19:38:13.619757: step 31950, total loss = 0.50, batch loss = 0.22 (264.4 examples/sec; 0.030 sec/batch; 1h:24m:28s remains)
INFO - root - 2022-02-24 19:38:13.943695: step 31960, total loss = 0.54, batch loss = 0.25 (319.1 examples/sec; 0.025 sec/batch; 1h:10m:00s remains)
INFO - root - 2022-02-24 19:38:14.293809: step 31970, total loss = 0.61, batch loss = 0.33 (216.4 examples/sec; 0.037 sec/batch; 1h:43m:14s remains)
INFO - root - 2022-02-24 19:38:14.625678: step 31980, total loss = 0.62, batch loss = 0.33 (190.7 examples/sec; 0.042 sec/batch; 1h:57m:09s remains)
INFO - root - 2022-02-24 19:38:14.977101: step 31990, total loss = 0.61, batch loss = 0.32 (140.1 examples/sec; 0.057 sec/batch; 2h:39m:24s remains)
INFO - root - 2022-02-24 19:38:15.430253: step 32000, total loss = 0.58, batch loss = 0.30 (305.7 examples/sec; 0.026 sec/batch; 1h:13m:03s remains)
INFO - root - 2022-02-24 19:38:15.995997: step 32010, total loss = 0.54, batch loss = 0.26 (124.7 examples/sec; 0.064 sec/batch; 2h:59m:05s remains)
INFO - root - 2022-02-24 19:38:16.346567: step 32020, total loss = 0.66, batch loss = 0.37 (287.0 examples/sec; 0.028 sec/batch; 1h:17m:47s remains)
INFO - root - 2022-02-24 19:38:16.780787: step 32030, total loss = 0.63, batch loss = 0.34 (300.1 examples/sec; 0.027 sec/batch; 1h:14m:24s remains)
INFO - root - 2022-02-24 19:38:17.285394: step 32040, total loss = 0.59, batch loss = 0.31 (135.8 examples/sec; 0.059 sec/batch; 2h:44m:26s remains)
INFO - root - 2022-02-24 19:38:17.764393: step 32050, total loss = 0.60, batch loss = 0.31 (99.6 examples/sec; 0.080 sec/batch; 3h:44m:12s remains)
INFO - root - 2022-02-24 19:38:18.108740: step 32060, total loss = 0.61, batch loss = 0.33 (221.2 examples/sec; 0.036 sec/batch; 1h:40m:54s remains)
INFO - root - 2022-02-24 19:38:18.507426: step 32070, total loss = 0.56, batch loss = 0.28 (316.5 examples/sec; 0.025 sec/batch; 1h:10m:32s remains)
INFO - root - 2022-02-24 19:38:18.847886: step 32080, total loss = 0.64, batch loss = 0.36 (281.6 examples/sec; 0.028 sec/batch; 1h:19m:16s remains)
INFO - root - 2022-02-24 19:38:19.370483: step 32090, total loss = 0.55, batch loss = 0.26 (102.3 examples/sec; 0.078 sec/batch; 3h:38m:08s remains)
INFO - root - 2022-02-24 19:38:19.903639: step 32100, total loss = 0.67, batch loss = 0.39 (263.8 examples/sec; 0.030 sec/batch; 1h:24m:36s remains)
INFO - root - 2022-02-24 19:38:20.361806: step 32110, total loss = 0.67, batch loss = 0.39 (197.8 examples/sec; 0.040 sec/batch; 1h:52m:51s remains)
INFO - root - 2022-02-24 19:38:20.762053: step 32120, total loss = 0.60, batch loss = 0.32 (342.6 examples/sec; 0.023 sec/batch; 1h:05m:08s remains)
INFO - root - 2022-02-24 19:38:21.112729: step 32130, total loss = 0.72, batch loss = 0.44 (296.9 examples/sec; 0.027 sec/batch; 1h:15m:09s remains)
INFO - root - 2022-02-24 19:38:21.613888: step 32140, total loss = 0.50, batch loss = 0.22 (167.9 examples/sec; 0.048 sec/batch; 2h:12m:52s remains)
INFO - root - 2022-02-24 19:38:22.275088: step 32150, total loss = 0.58, batch loss = 0.30 (316.6 examples/sec; 0.025 sec/batch; 1h:10m:28s remains)
INFO - root - 2022-02-24 19:38:22.693276: step 32160, total loss = 0.65, batch loss = 0.37 (209.4 examples/sec; 0.038 sec/batch; 1h:46m:31s remains)
INFO - root - 2022-02-24 19:38:23.184018: step 32170, total loss = 0.59, batch loss = 0.31 (101.7 examples/sec; 0.079 sec/batch; 3h:39m:24s remains)
INFO - root - 2022-02-24 19:38:23.755590: step 32180, total loss = 0.57, batch loss = 0.28 (125.1 examples/sec; 0.064 sec/batch; 2h:58m:23s remains)
INFO - root - 2022-02-24 19:38:24.288584: step 32190, total loss = 0.59, batch loss = 0.31 (328.5 examples/sec; 0.024 sec/batch; 1h:07m:54s remains)
INFO - root - 2022-02-24 19:38:25.142769: step 32200, total loss = 0.64, batch loss = 0.36 (17.6 examples/sec; 0.456 sec/batch; 21h:10m:20s remains)
INFO - root - 2022-02-24 19:38:25.629442: step 32210, total loss = 0.54, batch loss = 0.26 (328.4 examples/sec; 0.024 sec/batch; 1h:07m:55s remains)
INFO - root - 2022-02-24 19:38:26.172999: step 32220, total loss = 0.69, batch loss = 0.41 (296.6 examples/sec; 0.027 sec/batch; 1h:15m:12s remains)
INFO - root - 2022-02-24 19:38:26.567515: step 32230, total loss = 0.60, batch loss = 0.32 (321.8 examples/sec; 0.025 sec/batch; 1h:09m:18s remains)
INFO - root - 2022-02-24 19:38:26.974987: step 32240, total loss = 0.58, batch loss = 0.29 (270.6 examples/sec; 0.030 sec/batch; 1h:22m:25s remains)
INFO - root - 2022-02-24 19:38:27.377329: step 32250, total loss = 0.50, batch loss = 0.22 (323.1 examples/sec; 0.025 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 19:38:27.826475: step 32260, total loss = 0.59, batch loss = 0.30 (73.0 examples/sec; 0.110 sec/batch; 5h:05m:22s remains)
INFO - root - 2022-02-24 19:38:28.238502: step 32270, total loss = 0.64, batch loss = 0.35 (276.7 examples/sec; 0.029 sec/batch; 1h:20m:34s remains)
INFO - root - 2022-02-24 19:38:28.704640: step 32280, total loss = 0.62, batch loss = 0.34 (326.4 examples/sec; 0.025 sec/batch; 1h:08m:19s remains)
INFO - root - 2022-02-24 19:38:29.081446: step 32290, total loss = 0.64, batch loss = 0.35 (229.9 examples/sec; 0.035 sec/batch; 1h:36m:57s remains)
INFO - root - 2022-02-24 19:38:29.473545: step 32300, total loss = 0.55, batch loss = 0.26 (159.3 examples/sec; 0.050 sec/batch; 2h:19m:58s remains)
INFO - root - 2022-02-24 19:38:30.326611: step 32310, total loss = 0.66, batch loss = 0.37 (265.1 examples/sec; 0.030 sec/batch; 1h:24m:04s remains)
INFO - root - 2022-02-24 19:38:30.794976: step 32320, total loss = 0.56, batch loss = 0.28 (229.7 examples/sec; 0.035 sec/batch; 1h:37m:01s remains)
INFO - root - 2022-02-24 19:38:31.111821: step 32330, total loss = 0.66, batch loss = 0.37 (242.9 examples/sec; 0.033 sec/batch; 1h:31m:45s remains)
INFO - root - 2022-02-24 19:38:31.496356: step 32340, total loss = 0.69, batch loss = 0.41 (192.4 examples/sec; 0.042 sec/batch; 1h:55m:51s remains)
INFO - root - 2022-02-24 19:38:31.902863: step 32350, total loss = 0.55, batch loss = 0.27 (355.5 examples/sec; 0.023 sec/batch; 1h:02m:41s remains)
INFO - root - 2022-02-24 19:38:32.326510: step 32360, total loss = 0.59, batch loss = 0.31 (174.0 examples/sec; 0.046 sec/batch; 2h:08m:03s remains)
INFO - root - 2022-02-24 19:38:32.799923: step 32370, total loss = 0.59, batch loss = 0.31 (315.3 examples/sec; 0.025 sec/batch; 1h:10m:40s remains)
INFO - root - 2022-02-24 19:38:33.152570: step 32380, total loss = 0.51, batch loss = 0.23 (338.4 examples/sec; 0.024 sec/batch; 1h:05m:51s remains)
INFO - root - 2022-02-24 19:38:33.538132: step 32390, total loss = 0.55, batch loss = 0.26 (198.3 examples/sec; 0.040 sec/batch; 1h:52m:21s remains)
INFO - root - 2022-02-24 19:38:33.929273: step 32400, total loss = 0.48, batch loss = 0.19 (199.8 examples/sec; 0.040 sec/batch; 1h:51m:29s remains)
INFO - root - 2022-02-24 19:38:34.336123: step 32410, total loss = 0.56, batch loss = 0.28 (318.7 examples/sec; 0.025 sec/batch; 1h:09m:54s remains)
INFO - root - 2022-02-24 19:38:34.806738: step 32420, total loss = 0.58, batch loss = 0.29 (172.1 examples/sec; 0.046 sec/batch; 2h:09m:28s remains)
INFO - root - 2022-02-24 19:38:35.315548: step 32430, total loss = 0.62, batch loss = 0.34 (309.4 examples/sec; 0.026 sec/batch; 1h:11m:59s remains)
INFO - root - 2022-02-24 19:38:35.671131: step 32440, total loss = 0.66, batch loss = 0.38 (254.4 examples/sec; 0.031 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 19:38:36.055562: step 32450, total loss = 0.52, batch loss = 0.24 (348.2 examples/sec; 0.023 sec/batch; 1h:03m:57s remains)
INFO - root - 2022-02-24 19:38:36.417969: step 32460, total loss = 0.61, batch loss = 0.32 (133.7 examples/sec; 0.060 sec/batch; 2h:46m:33s remains)
INFO - root - 2022-02-24 19:38:36.841583: step 32470, total loss = 0.61, batch loss = 0.32 (136.8 examples/sec; 0.058 sec/batch; 2h:42m:49s remains)
INFO - root - 2022-02-24 19:38:37.280255: step 32480, total loss = 0.65, batch loss = 0.36 (230.2 examples/sec; 0.035 sec/batch; 1h:36m:44s remains)
INFO - root - 2022-02-24 19:38:37.672512: step 32490, total loss = 0.57, batch loss = 0.29 (226.4 examples/sec; 0.035 sec/batch; 1h:38m:20s remains)
INFO - root - 2022-02-24 19:38:38.039440: step 32500, total loss = 0.47, batch loss = 0.19 (304.5 examples/sec; 0.026 sec/batch; 1h:13m:07s remains)
INFO - root - 2022-02-24 19:38:38.424769: step 32510, total loss = 0.60, batch loss = 0.32 (295.6 examples/sec; 0.027 sec/batch; 1h:15m:18s remains)
INFO - root - 2022-02-24 19:38:38.812307: step 32520, total loss = 0.65, batch loss = 0.37 (176.5 examples/sec; 0.045 sec/batch; 2h:06m:10s remains)
INFO - root - 2022-02-24 19:38:39.269342: step 32530, total loss = 0.71, batch loss = 0.42 (265.8 examples/sec; 0.030 sec/batch; 1h:23m:46s remains)
INFO - root - 2022-02-24 19:38:39.732307: step 32540, total loss = 0.59, batch loss = 0.31 (129.4 examples/sec; 0.062 sec/batch; 2h:52m:00s remains)
INFO - root - 2022-02-24 19:38:40.056875: step 32550, total loss = 0.67, batch loss = 0.39 (368.8 examples/sec; 0.022 sec/batch; 1h:00m:21s remains)
INFO - root - 2022-02-24 19:38:40.490166: step 32560, total loss = 0.60, batch loss = 0.32 (242.8 examples/sec; 0.033 sec/batch; 1h:31m:40s remains)
INFO - root - 2022-02-24 19:38:40.948181: step 32570, total loss = 0.66, batch loss = 0.38 (196.7 examples/sec; 0.041 sec/batch; 1h:53m:10s remains)
INFO - root - 2022-02-24 19:38:41.341274: step 32580, total loss = 0.55, batch loss = 0.27 (321.4 examples/sec; 0.025 sec/batch; 1h:09m:14s remains)
INFO - root - 2022-02-24 19:38:41.738580: step 32590, total loss = 0.58, batch loss = 0.29 (322.8 examples/sec; 0.025 sec/batch; 1h:08m:57s remains)
INFO - root - 2022-02-24 19:38:42.065661: step 32600, total loss = 0.63, batch loss = 0.35 (218.0 examples/sec; 0.037 sec/batch; 1h:42m:05s remains)
INFO - root - 2022-02-24 19:38:42.537945: step 32610, total loss = 0.51, batch loss = 0.23 (136.1 examples/sec; 0.059 sec/batch; 2h:43m:29s remains)
INFO - root - 2022-02-24 19:38:42.920427: step 32620, total loss = 0.57, batch loss = 0.28 (352.1 examples/sec; 0.023 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 19:38:43.416933: step 32630, total loss = 0.68, batch loss = 0.39 (301.0 examples/sec; 0.027 sec/batch; 1h:13m:54s remains)
INFO - root - 2022-02-24 19:38:43.791404: step 32640, total loss = 0.61, batch loss = 0.33 (340.3 examples/sec; 0.024 sec/batch; 1h:05m:22s remains)
INFO - root - 2022-02-24 19:38:44.154290: step 32650, total loss = 0.64, batch loss = 0.36 (223.4 examples/sec; 0.036 sec/batch; 1h:39m:35s remains)
INFO - root - 2022-02-24 19:38:44.600591: step 32660, total loss = 0.59, batch loss = 0.31 (256.9 examples/sec; 0.031 sec/batch; 1h:26m:35s remains)
INFO - root - 2022-02-24 19:38:45.075817: step 32670, total loss = 0.57, batch loss = 0.29 (341.0 examples/sec; 0.023 sec/batch; 1h:05m:13s remains)
INFO - root - 2022-02-24 19:38:45.851348: step 32680, total loss = 0.67, batch loss = 0.39 (329.1 examples/sec; 0.024 sec/batch; 1h:07m:35s remains)
INFO - root - 2022-02-24 19:38:46.242003: step 32690, total loss = 0.57, batch loss = 0.29 (184.7 examples/sec; 0.043 sec/batch; 2h:00m:23s remains)
INFO - root - 2022-02-24 19:38:46.613577: step 32700, total loss = 0.65, batch loss = 0.37 (245.6 examples/sec; 0.033 sec/batch; 1h:30m:32s remains)
INFO - root - 2022-02-24 19:38:47.050486: step 32710, total loss = 0.70, batch loss = 0.42 (194.3 examples/sec; 0.041 sec/batch; 1h:54m:28s remains)
INFO - root - 2022-02-24 19:38:47.516312: step 32720, total loss = 0.50, batch loss = 0.21 (94.3 examples/sec; 0.085 sec/batch; 3h:55m:53s remains)
INFO - root - 2022-02-24 19:38:48.039498: step 32730, total loss = 0.54, batch loss = 0.26 (342.8 examples/sec; 0.023 sec/batch; 1h:04m:51s remains)
INFO - root - 2022-02-24 19:38:48.451279: step 32740, total loss = 0.53, batch loss = 0.24 (218.7 examples/sec; 0.037 sec/batch; 1h:41m:39s remains)
INFO - root - 2022-02-24 19:38:48.912390: step 32750, total loss = 0.54, batch loss = 0.26 (205.8 examples/sec; 0.039 sec/batch; 1h:48m:01s remains)
INFO - root - 2022-02-24 19:38:49.397507: step 32760, total loss = 0.56, batch loss = 0.28 (334.1 examples/sec; 0.024 sec/batch; 1h:06m:32s remains)
INFO - root - 2022-02-24 19:38:49.868073: step 32770, total loss = 0.63, batch loss = 0.34 (144.8 examples/sec; 0.055 sec/batch; 2h:33m:29s remains)
INFO - root - 2022-02-24 19:38:50.665684: step 32780, total loss = 0.55, batch loss = 0.27 (19.2 examples/sec; 0.416 sec/batch; 19h:15m:21s remains)
INFO - root - 2022-02-24 19:38:51.153421: step 32790, total loss = 0.52, batch loss = 0.24 (324.7 examples/sec; 0.025 sec/batch; 1h:08m:27s remains)
INFO - root - 2022-02-24 19:38:51.512408: step 32800, total loss = 0.62, batch loss = 0.34 (149.0 examples/sec; 0.054 sec/batch; 2h:29m:12s remains)
INFO - root - 2022-02-24 19:38:51.970168: step 32810, total loss = 0.59, batch loss = 0.31 (163.0 examples/sec; 0.049 sec/batch; 2h:16m:19s remains)
INFO - root - 2022-02-24 19:38:52.420351: step 32820, total loss = 0.70, batch loss = 0.42 (227.0 examples/sec; 0.035 sec/batch; 1h:37m:54s remains)
INFO - root - 2022-02-24 19:38:52.815773: step 32830, total loss = 0.66, batch loss = 0.37 (288.1 examples/sec; 0.028 sec/batch; 1h:17m:07s remains)
INFO - root - 2022-02-24 19:38:53.219101: step 32840, total loss = 0.57, batch loss = 0.29 (153.8 examples/sec; 0.052 sec/batch; 2h:24m:27s remains)
INFO - root - 2022-02-24 19:38:53.605637: step 32850, total loss = 0.55, batch loss = 0.27 (245.8 examples/sec; 0.033 sec/batch; 1h:30m:24s remains)
INFO - root - 2022-02-24 19:38:54.012420: step 32860, total loss = 0.62, batch loss = 0.34 (354.3 examples/sec; 0.023 sec/batch; 1h:02m:42s remains)
INFO - root - 2022-02-24 19:38:54.488314: step 32870, total loss = 0.58, batch loss = 0.29 (152.3 examples/sec; 0.053 sec/batch; 2h:25m:50s remains)
INFO - root - 2022-02-24 19:38:54.962530: step 32880, total loss = 0.67, batch loss = 0.39 (93.9 examples/sec; 0.085 sec/batch; 3h:56m:33s remains)
INFO - root - 2022-02-24 19:38:55.377315: step 32890, total loss = 0.65, batch loss = 0.37 (186.1 examples/sec; 0.043 sec/batch; 1h:59m:20s remains)
INFO - root - 2022-02-24 19:38:55.720349: step 32900, total loss = 0.75, batch loss = 0.47 (310.3 examples/sec; 0.026 sec/batch; 1h:11m:35s remains)
INFO - root - 2022-02-24 19:38:56.342898: step 32910, total loss = 0.59, batch loss = 0.30 (187.7 examples/sec; 0.043 sec/batch; 1h:58m:20s remains)
INFO - root - 2022-02-24 19:38:56.813578: step 32920, total loss = 0.56, batch loss = 0.28 (198.8 examples/sec; 0.040 sec/batch; 1h:51m:41s remains)
INFO - root - 2022-02-24 19:38:57.200830: step 32930, total loss = 0.53, batch loss = 0.25 (165.3 examples/sec; 0.048 sec/batch; 2h:14m:22s remains)
INFO - root - 2022-02-24 19:38:57.516472: step 32940, total loss = 0.62, batch loss = 0.34 (228.5 examples/sec; 0.035 sec/batch; 1h:37m:12s remains)
INFO - root - 2022-02-24 19:38:57.925051: step 32950, total loss = 0.49, batch loss = 0.21 (165.2 examples/sec; 0.048 sec/batch; 2h:14m:23s remains)
INFO - root - 2022-02-24 19:38:58.389043: step 32960, total loss = 0.64, batch loss = 0.35 (193.4 examples/sec; 0.041 sec/batch; 1h:54m:47s remains)
INFO - root - 2022-02-24 19:38:58.916056: step 32970, total loss = 0.55, batch loss = 0.27 (84.0 examples/sec; 0.095 sec/batch; 4h:24m:12s remains)
INFO - root - 2022-02-24 19:38:59.317420: step 32980, total loss = 0.56, batch loss = 0.27 (155.0 examples/sec; 0.052 sec/batch; 2h:23m:12s remains)
INFO - root - 2022-02-24 19:38:59.694641: step 32990, total loss = 0.58, batch loss = 0.29 (179.9 examples/sec; 0.044 sec/batch; 2h:03m:23s remains)
INFO - root - 2022-02-24 19:39:00.055443: step 33000, total loss = 0.51, batch loss = 0.23 (194.5 examples/sec; 0.041 sec/batch; 1h:54m:06s remains)
INFO - root - 2022-02-24 19:39:00.577613: step 33010, total loss = 0.59, batch loss = 0.31 (246.3 examples/sec; 0.032 sec/batch; 1h:30m:08s remains)
INFO - root - 2022-02-24 19:39:01.085328: step 33020, total loss = 0.57, batch loss = 0.29 (219.8 examples/sec; 0.036 sec/batch; 1h:41m:00s remains)
INFO - root - 2022-02-24 19:39:01.502332: step 33030, total loss = 0.63, batch loss = 0.35 (228.0 examples/sec; 0.035 sec/batch; 1h:37m:19s remains)
INFO - root - 2022-02-24 19:39:01.833433: step 33040, total loss = 0.60, batch loss = 0.32 (285.0 examples/sec; 0.028 sec/batch; 1h:17m:52s remains)
INFO - root - 2022-02-24 19:39:02.181946: step 33050, total loss = 0.61, batch loss = 0.33 (363.6 examples/sec; 0.022 sec/batch; 1h:01m:02s remains)
INFO - root - 2022-02-24 19:39:02.562898: step 33060, total loss = 0.77, batch loss = 0.49 (205.5 examples/sec; 0.039 sec/batch; 1h:47m:58s remains)
INFO - root - 2022-02-24 19:39:03.023211: step 33070, total loss = 0.55, batch loss = 0.27 (159.7 examples/sec; 0.050 sec/batch; 2h:18m:59s remains)
INFO - root - 2022-02-24 19:39:03.451195: step 33080, total loss = 0.66, batch loss = 0.38 (342.3 examples/sec; 0.023 sec/batch; 1h:04m:49s remains)
INFO - root - 2022-02-24 19:39:03.785716: step 33090, total loss = 0.69, batch loss = 0.41 (290.7 examples/sec; 0.028 sec/batch; 1h:16m:19s remains)
INFO - root - 2022-02-24 19:39:04.151235: step 33100, total loss = 0.58, batch loss = 0.30 (307.8 examples/sec; 0.026 sec/batch; 1h:12m:05s remains)
INFO - root - 2022-02-24 19:39:04.571091: step 33110, total loss = 0.60, batch loss = 0.31 (181.2 examples/sec; 0.044 sec/batch; 2h:02m:27s remains)
INFO - root - 2022-02-24 19:39:05.029335: step 33120, total loss = 0.58, batch loss = 0.29 (155.0 examples/sec; 0.052 sec/batch; 2h:23m:06s remains)
INFO - root - 2022-02-24 19:39:05.664698: step 33130, total loss = 0.62, batch loss = 0.33 (98.6 examples/sec; 0.081 sec/batch; 3h:44m:57s remains)
INFO - root - 2022-02-24 19:39:06.594744: step 33140, total loss = 0.55, batch loss = 0.26 (79.9 examples/sec; 0.100 sec/batch; 4h:37m:32s remains)
INFO - root - 2022-02-24 19:39:06.957699: step 33150, total loss = 0.55, batch loss = 0.27 (182.5 examples/sec; 0.044 sec/batch; 2h:01m:33s remains)
INFO - root - 2022-02-24 19:39:07.355050: step 33160, total loss = 0.61, batch loss = 0.33 (195.1 examples/sec; 0.041 sec/batch; 1h:53m:41s remains)
INFO - root - 2022-02-24 19:39:07.716796: step 33170, total loss = 0.75, batch loss = 0.46 (334.0 examples/sec; 0.024 sec/batch; 1h:06m:24s remains)
INFO - root - 2022-02-24 19:39:08.114331: step 33180, total loss = 0.76, batch loss = 0.48 (327.4 examples/sec; 0.024 sec/batch; 1h:07m:44s remains)
INFO - root - 2022-02-24 19:39:08.621650: step 33190, total loss = 0.53, batch loss = 0.24 (225.2 examples/sec; 0.036 sec/batch; 1h:38m:26s remains)
INFO - root - 2022-02-24 19:39:09.094378: step 33200, total loss = 0.65, batch loss = 0.37 (113.0 examples/sec; 0.071 sec/batch; 3h:16m:10s remains)
INFO - root - 2022-02-24 19:39:09.667207: step 33210, total loss = 0.58, batch loss = 0.30 (320.3 examples/sec; 0.025 sec/batch; 1h:09m:13s remains)
INFO - root - 2022-02-24 19:39:10.008549: step 33220, total loss = 0.63, batch loss = 0.35 (242.0 examples/sec; 0.033 sec/batch; 1h:31m:36s remains)
INFO - root - 2022-02-24 19:39:10.374385: step 33230, total loss = 0.56, batch loss = 0.27 (177.3 examples/sec; 0.045 sec/batch; 2h:05m:00s remains)
INFO - root - 2022-02-24 19:39:10.745031: step 33240, total loss = 0.60, batch loss = 0.32 (208.5 examples/sec; 0.038 sec/batch; 1h:46m:18s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-33249 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-33249 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:39:11.546862: step 33250, total loss = 0.55, batch loss = 0.26 (344.9 examples/sec; 0.023 sec/batch; 1h:04m:16s remains)
INFO - root - 2022-02-24 19:39:12.047703: step 33260, total loss = 0.53, batch loss = 0.24 (214.1 examples/sec; 0.037 sec/batch; 1h:43m:32s remains)
INFO - root - 2022-02-24 19:39:12.440827: step 33270, total loss = 0.52, batch loss = 0.23 (330.9 examples/sec; 0.024 sec/batch; 1h:06m:58s remains)
INFO - root - 2022-02-24 19:39:12.762275: step 33280, total loss = 0.58, batch loss = 0.30 (254.1 examples/sec; 0.031 sec/batch; 1h:27m:13s remains)
INFO - root - 2022-02-24 19:39:13.226365: step 33290, total loss = 0.70, batch loss = 0.42 (237.3 examples/sec; 0.034 sec/batch; 1h:33m:22s remains)
INFO - root - 2022-02-24 19:39:13.736761: step 33300, total loss = 0.70, batch loss = 0.41 (173.3 examples/sec; 0.046 sec/batch; 2h:07m:50s remains)
INFO - root - 2022-02-24 19:39:14.161202: step 33310, total loss = 0.55, batch loss = 0.27 (328.6 examples/sec; 0.024 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 19:39:14.516014: step 33320, total loss = 0.52, batch loss = 0.24 (294.0 examples/sec; 0.027 sec/batch; 1h:15m:22s remains)
INFO - root - 2022-02-24 19:39:14.895648: step 33330, total loss = 0.67, batch loss = 0.39 (153.1 examples/sec; 0.052 sec/batch; 2h:24m:41s remains)
INFO - root - 2022-02-24 19:39:15.292887: step 33340, total loss = 0.64, batch loss = 0.36 (234.2 examples/sec; 0.034 sec/batch; 1h:34m:35s remains)
INFO - root - 2022-02-24 19:39:15.745574: step 33350, total loss = 0.64, batch loss = 0.36 (208.7 examples/sec; 0.038 sec/batch; 1h:46m:09s remains)
INFO - root - 2022-02-24 19:39:16.174138: step 33360, total loss = 0.61, batch loss = 0.33 (333.5 examples/sec; 0.024 sec/batch; 1h:06m:24s remains)
INFO - root - 2022-02-24 19:39:16.508648: step 33370, total loss = 0.70, batch loss = 0.42 (188.5 examples/sec; 0.042 sec/batch; 1h:57m:29s remains)
INFO - root - 2022-02-24 19:39:16.962381: step 33380, total loss = 0.53, batch loss = 0.25 (152.9 examples/sec; 0.052 sec/batch; 2h:24m:52s remains)
INFO - root - 2022-02-24 19:39:17.404391: step 33390, total loss = 0.67, batch loss = 0.39 (102.0 examples/sec; 0.078 sec/batch; 3h:37m:09s remains)
INFO - root - 2022-02-24 19:39:17.918403: step 33400, total loss = 0.55, batch loss = 0.27 (165.9 examples/sec; 0.048 sec/batch; 2h:13m:28s remains)
INFO - root - 2022-02-24 19:39:18.313708: step 33410, total loss = 0.52, batch loss = 0.24 (335.1 examples/sec; 0.024 sec/batch; 1h:06m:04s remains)
INFO - root - 2022-02-24 19:39:18.673508: step 33420, total loss = 0.56, batch loss = 0.28 (232.2 examples/sec; 0.034 sec/batch; 1h:35m:22s remains)
INFO - root - 2022-02-24 19:39:18.988996: step 33430, total loss = 0.69, batch loss = 0.40 (145.6 examples/sec; 0.055 sec/batch; 2h:32m:05s remains)
INFO - root - 2022-02-24 19:39:19.404382: step 33440, total loss = 0.54, batch loss = 0.25 (133.5 examples/sec; 0.060 sec/batch; 2h:45m:49s remains)
INFO - root - 2022-02-24 19:39:19.807447: step 33450, total loss = 0.62, batch loss = 0.34 (239.1 examples/sec; 0.033 sec/batch; 1h:32m:34s remains)
INFO - root - 2022-02-24 19:39:20.299836: step 33460, total loss = 0.62, batch loss = 0.33 (132.6 examples/sec; 0.060 sec/batch; 2h:46m:58s remains)
INFO - root - 2022-02-24 19:39:20.666857: step 33470, total loss = 0.53, batch loss = 0.24 (165.3 examples/sec; 0.048 sec/batch; 2h:13m:57s remains)
INFO - root - 2022-02-24 19:39:21.106889: step 33480, total loss = 0.72, batch loss = 0.43 (306.4 examples/sec; 0.026 sec/batch; 1h:12m:14s remains)
INFO - root - 2022-02-24 19:39:21.510287: step 33490, total loss = 0.57, batch loss = 0.28 (133.3 examples/sec; 0.060 sec/batch; 2h:46m:01s remains)
INFO - root - 2022-02-24 19:39:21.970363: step 33500, total loss = 0.59, batch loss = 0.31 (150.2 examples/sec; 0.053 sec/batch; 2h:27m:23s remains)
INFO - root - 2022-02-24 19:39:22.499599: step 33510, total loss = 0.57, batch loss = 0.28 (176.5 examples/sec; 0.045 sec/batch; 2h:05m:25s remains)
INFO - root - 2022-02-24 19:39:22.894556: step 33520, total loss = 0.62, batch loss = 0.33 (154.3 examples/sec; 0.052 sec/batch; 2h:23m:23s remains)
INFO - root - 2022-02-24 19:39:23.306904: step 33530, total loss = 0.58, batch loss = 0.30 (118.2 examples/sec; 0.068 sec/batch; 3h:07m:16s remains)
INFO - root - 2022-02-24 19:39:23.690030: step 33540, total loss = 0.62, batch loss = 0.33 (197.6 examples/sec; 0.040 sec/batch; 1h:52m:00s remains)
INFO - root - 2022-02-24 19:39:24.183052: step 33550, total loss = 0.60, batch loss = 0.32 (335.1 examples/sec; 0.024 sec/batch; 1h:06m:02s remains)
INFO - root - 2022-02-24 19:39:24.743465: step 33560, total loss = 0.55, batch loss = 0.27 (230.7 examples/sec; 0.035 sec/batch; 1h:35m:53s remains)
INFO - root - 2022-02-24 19:39:25.494980: step 33570, total loss = 0.62, batch loss = 0.34 (114.1 examples/sec; 0.070 sec/batch; 3h:13m:59s remains)
INFO - root - 2022-02-24 19:39:26.023671: step 33580, total loss = 0.58, batch loss = 0.30 (97.2 examples/sec; 0.082 sec/batch; 3h:47m:42s remains)
INFO - root - 2022-02-24 19:39:26.439451: step 33590, total loss = 0.52, batch loss = 0.23 (325.1 examples/sec; 0.025 sec/batch; 1h:08m:02s remains)
INFO - root - 2022-02-24 19:39:27.378806: step 33600, total loss = 0.69, batch loss = 0.40 (189.9 examples/sec; 0.042 sec/batch; 1h:56m:28s remains)
INFO - root - 2022-02-24 19:39:28.173026: step 33610, total loss = 0.51, batch loss = 0.22 (342.9 examples/sec; 0.023 sec/batch; 1h:04m:30s remains)
INFO - root - 2022-02-24 19:39:28.421487: step 33620, total loss = 0.49, batch loss = 0.20 (327.6 examples/sec; 0.024 sec/batch; 1h:07m:30s remains)
INFO - root - 2022-02-24 19:39:28.665617: step 33630, total loss = 0.71, batch loss = 0.43 (321.5 examples/sec; 0.025 sec/batch; 1h:08m:47s remains)
INFO - root - 2022-02-24 19:39:29.029667: step 33640, total loss = 0.68, batch loss = 0.40 (231.7 examples/sec; 0.035 sec/batch; 1h:35m:26s remains)
INFO - root - 2022-02-24 19:39:29.494063: step 33650, total loss = 0.56, batch loss = 0.28 (206.0 examples/sec; 0.039 sec/batch; 1h:47m:21s remains)
INFO - root - 2022-02-24 19:39:29.920438: step 33660, total loss = 0.59, batch loss = 0.31 (265.8 examples/sec; 0.030 sec/batch; 1h:23m:10s remains)
INFO - root - 2022-02-24 19:39:30.264997: step 33670, total loss = 0.62, batch loss = 0.34 (305.6 examples/sec; 0.026 sec/batch; 1h:12m:21s remains)
INFO - root - 2022-02-24 19:39:30.690889: step 33680, total loss = 0.57, batch loss = 0.28 (329.4 examples/sec; 0.024 sec/batch; 1h:07m:06s remains)
INFO - root - 2022-02-24 19:39:31.069039: step 33690, total loss = 0.68, batch loss = 0.40 (286.8 examples/sec; 0.028 sec/batch; 1h:17m:05s remains)
INFO - root - 2022-02-24 19:39:31.512978: step 33700, total loss = 0.55, batch loss = 0.26 (174.2 examples/sec; 0.046 sec/batch; 2h:06m:54s remains)
INFO - root - 2022-02-24 19:39:32.221188: step 33710, total loss = 0.53, batch loss = 0.25 (166.8 examples/sec; 0.048 sec/batch; 2h:12m:30s remains)
INFO - root - 2022-02-24 19:39:32.680486: step 33720, total loss = 0.57, batch loss = 0.29 (116.4 examples/sec; 0.069 sec/batch; 3h:09m:54s remains)
INFO - root - 2022-02-24 19:39:33.314401: step 33730, total loss = 0.62, batch loss = 0.33 (159.0 examples/sec; 0.050 sec/batch; 2h:19m:03s remains)
INFO - root - 2022-02-24 19:39:33.776044: step 33740, total loss = 0.55, batch loss = 0.27 (138.1 examples/sec; 0.058 sec/batch; 2h:39m:59s remains)
INFO - root - 2022-02-24 19:39:34.187114: step 33750, total loss = 0.60, batch loss = 0.32 (333.7 examples/sec; 0.024 sec/batch; 1h:06m:13s remains)
INFO - root - 2022-02-24 19:39:34.617297: step 33760, total loss = 0.57, batch loss = 0.28 (171.1 examples/sec; 0.047 sec/batch; 2h:09m:11s remains)
INFO - root - 2022-02-24 19:39:35.019014: step 33770, total loss = 0.76, batch loss = 0.48 (251.1 examples/sec; 0.032 sec/batch; 1h:28m:00s remains)
INFO - root - 2022-02-24 19:39:35.425781: step 33780, total loss = 0.54, batch loss = 0.26 (157.7 examples/sec; 0.051 sec/batch; 2h:20m:08s remains)
INFO - root - 2022-02-24 19:39:35.696140: step 33790, total loss = 0.55, batch loss = 0.27 (274.1 examples/sec; 0.029 sec/batch; 1h:20m:35s remains)
INFO - root - 2022-02-24 19:39:36.138059: step 33800, total loss = 0.57, batch loss = 0.29 (84.8 examples/sec; 0.094 sec/batch; 4h:20m:33s remains)
INFO - root - 2022-02-24 19:39:36.650381: step 33810, total loss = 0.52, batch loss = 0.24 (201.5 examples/sec; 0.040 sec/batch; 1h:49m:38s remains)
INFO - root - 2022-02-24 19:39:37.123898: step 33820, total loss = 0.55, batch loss = 0.26 (248.3 examples/sec; 0.032 sec/batch; 1h:28m:57s remains)
INFO - root - 2022-02-24 19:39:37.520001: step 33830, total loss = 0.54, batch loss = 0.26 (317.7 examples/sec; 0.025 sec/batch; 1h:09m:31s remains)
INFO - root - 2022-02-24 19:39:37.865803: step 33840, total loss = 0.59, batch loss = 0.31 (309.9 examples/sec; 0.026 sec/batch; 1h:11m:16s remains)
INFO - root - 2022-02-24 19:39:38.219517: step 33850, total loss = 0.62, batch loss = 0.33 (235.9 examples/sec; 0.034 sec/batch; 1h:33m:37s remains)
INFO - root - 2022-02-24 19:39:38.667988: step 33860, total loss = 0.56, batch loss = 0.28 (341.3 examples/sec; 0.023 sec/batch; 1h:04m:42s remains)
INFO - root - 2022-02-24 19:39:39.137852: step 33870, total loss = 0.58, batch loss = 0.30 (161.2 examples/sec; 0.050 sec/batch; 2h:16m:59s remains)
INFO - root - 2022-02-24 19:39:39.476261: step 33880, total loss = 0.58, batch loss = 0.30 (281.2 examples/sec; 0.028 sec/batch; 1h:18m:31s remains)
INFO - root - 2022-02-24 19:39:39.857105: step 33890, total loss = 0.54, batch loss = 0.25 (311.9 examples/sec; 0.026 sec/batch; 1h:10m:48s remains)
INFO - root - 2022-02-24 19:39:40.207952: step 33900, total loss = 0.59, batch loss = 0.31 (318.2 examples/sec; 0.025 sec/batch; 1h:09m:23s remains)
INFO - root - 2022-02-24 19:39:40.756095: step 33910, total loss = 0.53, batch loss = 0.25 (345.8 examples/sec; 0.023 sec/batch; 1h:03m:50s remains)
INFO - root - 2022-02-24 19:39:41.271197: step 33920, total loss = 0.53, batch loss = 0.24 (116.9 examples/sec; 0.068 sec/batch; 3h:08m:50s remains)
INFO - root - 2022-02-24 19:39:41.796059: step 33930, total loss = 0.62, batch loss = 0.34 (144.6 examples/sec; 0.055 sec/batch; 2h:32m:38s remains)
INFO - root - 2022-02-24 19:39:42.146837: step 33940, total loss = 0.54, batch loss = 0.26 (305.4 examples/sec; 0.026 sec/batch; 1h:12m:16s remains)
INFO - root - 2022-02-24 19:39:42.514199: step 33950, total loss = 0.61, batch loss = 0.33 (302.7 examples/sec; 0.026 sec/batch; 1h:12m:54s remains)
INFO - root - 2022-02-24 19:39:42.873135: step 33960, total loss = 0.59, batch loss = 0.31 (194.6 examples/sec; 0.041 sec/batch; 1h:53m:25s remains)
INFO - root - 2022-02-24 19:39:43.369975: step 33970, total loss = 0.56, batch loss = 0.28 (103.4 examples/sec; 0.077 sec/batch; 3h:33m:33s remains)
INFO - root - 2022-02-24 19:39:43.757421: step 33980, total loss = 0.60, batch loss = 0.32 (122.1 examples/sec; 0.066 sec/batch; 3h:00m:46s remains)
INFO - root - 2022-02-24 19:39:44.128330: step 33990, total loss = 0.59, batch loss = 0.30 (313.1 examples/sec; 0.026 sec/batch; 1h:10m:28s remains)
INFO - root - 2022-02-24 19:39:44.423035: step 34000, total loss = 0.57, batch loss = 0.29 (298.3 examples/sec; 0.027 sec/batch; 1h:13m:58s remains)
INFO - root - 2022-02-24 19:39:44.861885: step 34010, total loss = 0.49, batch loss = 0.21 (175.0 examples/sec; 0.046 sec/batch; 2h:06m:05s remains)
INFO - root - 2022-02-24 19:39:45.201216: step 34020, total loss = 0.64, batch loss = 0.35 (161.1 examples/sec; 0.050 sec/batch; 2h:16m:58s remains)
INFO - root - 2022-02-24 19:39:45.615867: step 34030, total loss = 0.63, batch loss = 0.35 (166.9 examples/sec; 0.048 sec/batch; 2h:12m:09s remains)
INFO - root - 2022-02-24 19:39:45.968272: step 34040, total loss = 0.62, batch loss = 0.34 (141.9 examples/sec; 0.056 sec/batch; 2h:35m:28s remains)
INFO - root - 2022-02-24 19:39:46.326345: step 34050, total loss = 0.57, batch loss = 0.29 (274.5 examples/sec; 0.029 sec/batch; 1h:20m:22s remains)
INFO - root - 2022-02-24 19:39:46.646134: step 34060, total loss = 0.61, batch loss = 0.32 (229.6 examples/sec; 0.035 sec/batch; 1h:36m:05s remains)
INFO - root - 2022-02-24 19:39:46.992744: step 34070, total loss = 0.63, batch loss = 0.35 (195.3 examples/sec; 0.041 sec/batch; 1h:52m:55s remains)
INFO - root - 2022-02-24 19:39:47.316692: step 34080, total loss = 0.48, batch loss = 0.20 (167.6 examples/sec; 0.048 sec/batch; 2h:11m:37s remains)
INFO - root - 2022-02-24 19:39:47.844705: step 34090, total loss = 0.62, batch loss = 0.34 (85.2 examples/sec; 0.094 sec/batch; 4h:18m:59s remains)
INFO - root - 2022-02-24 19:39:48.342631: step 34100, total loss = 0.69, batch loss = 0.41 (145.7 examples/sec; 0.055 sec/batch; 2h:31m:21s remains)
INFO - root - 2022-02-24 19:39:48.796711: step 34110, total loss = 0.69, batch loss = 0.41 (298.4 examples/sec; 0.027 sec/batch; 1h:13m:54s remains)
INFO - root - 2022-02-24 19:39:49.113970: step 34120, total loss = 0.61, batch loss = 0.33 (296.4 examples/sec; 0.027 sec/batch; 1h:14m:24s remains)
INFO - root - 2022-02-24 19:39:49.528256: step 34130, total loss = 0.62, batch loss = 0.34 (201.5 examples/sec; 0.040 sec/batch; 1h:49m:26s remains)
INFO - root - 2022-02-24 19:39:49.989382: step 34140, total loss = 0.58, batch loss = 0.30 (144.3 examples/sec; 0.055 sec/batch; 2h:32m:47s remains)
INFO - root - 2022-02-24 19:39:50.420853: step 34150, total loss = 0.52, batch loss = 0.24 (344.0 examples/sec; 0.023 sec/batch; 1h:04m:04s remains)
INFO - root - 2022-02-24 19:39:50.910605: step 34160, total loss = 0.72, batch loss = 0.44 (120.9 examples/sec; 0.066 sec/batch; 3h:02m:18s remains)
INFO - root - 2022-02-24 19:39:51.338942: step 34170, total loss = 0.58, batch loss = 0.29 (188.4 examples/sec; 0.042 sec/batch; 1h:56m:59s remains)
INFO - root - 2022-02-24 19:39:51.679571: step 34180, total loss = 0.57, batch loss = 0.28 (129.0 examples/sec; 0.062 sec/batch; 2h:50m:49s remains)
INFO - root - 2022-02-24 19:39:52.059591: step 34190, total loss = 0.71, batch loss = 0.43 (138.1 examples/sec; 0.058 sec/batch; 2h:39m:37s remains)
INFO - root - 2022-02-24 19:39:52.520544: step 34200, total loss = 0.55, batch loss = 0.27 (232.5 examples/sec; 0.034 sec/batch; 1h:34m:48s remains)
INFO - root - 2022-02-24 19:39:53.107047: step 34210, total loss = 0.52, batch loss = 0.24 (254.0 examples/sec; 0.031 sec/batch; 1h:26m:45s remains)
INFO - root - 2022-02-24 19:39:53.539556: step 34220, total loss = 0.53, batch loss = 0.25 (104.1 examples/sec; 0.077 sec/batch; 3h:31m:40s remains)
INFO - root - 2022-02-24 19:39:53.872721: step 34230, total loss = 0.57, batch loss = 0.28 (301.2 examples/sec; 0.027 sec/batch; 1h:13m:09s remains)
INFO - root - 2022-02-24 19:39:54.268804: step 34240, total loss = 0.69, batch loss = 0.41 (235.2 examples/sec; 0.034 sec/batch; 1h:33m:40s remains)
INFO - root - 2022-02-24 19:39:54.719095: step 34250, total loss = 0.63, batch loss = 0.35 (116.0 examples/sec; 0.069 sec/batch; 3h:09m:54s remains)
INFO - root - 2022-02-24 19:39:55.179634: step 34260, total loss = 0.61, batch loss = 0.33 (152.7 examples/sec; 0.052 sec/batch; 2h:24m:15s remains)
INFO - root - 2022-02-24 19:39:55.590502: step 34270, total loss = 0.58, batch loss = 0.30 (124.8 examples/sec; 0.064 sec/batch; 2h:56m:35s remains)
INFO - root - 2022-02-24 19:39:56.158546: step 34280, total loss = 0.61, batch loss = 0.32 (127.9 examples/sec; 0.063 sec/batch; 2h:52m:16s remains)
INFO - root - 2022-02-24 19:39:56.670936: step 34290, total loss = 0.66, batch loss = 0.38 (279.9 examples/sec; 0.029 sec/batch; 1h:18m:42s remains)
INFO - root - 2022-02-24 19:39:57.471267: step 34300, total loss = 0.61, batch loss = 0.33 (123.0 examples/sec; 0.065 sec/batch; 2h:59m:06s remains)
INFO - root - 2022-02-24 19:39:57.982298: step 34310, total loss = 0.61, batch loss = 0.32 (349.8 examples/sec; 0.023 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 19:39:58.382908: step 34320, total loss = 0.56, batch loss = 0.27 (273.7 examples/sec; 0.029 sec/batch; 1h:20m:28s remains)
INFO - root - 2022-02-24 19:39:58.792836: step 34330, total loss = 0.55, batch loss = 0.27 (164.0 examples/sec; 0.049 sec/batch; 2h:14m:18s remains)
INFO - root - 2022-02-24 19:39:59.227271: step 34340, total loss = 0.58, batch loss = 0.30 (163.5 examples/sec; 0.049 sec/batch; 2h:14m:40s remains)
INFO - root - 2022-02-24 19:39:59.837125: step 34350, total loss = 0.71, batch loss = 0.43 (248.7 examples/sec; 0.032 sec/batch; 1h:28m:32s remains)
INFO - root - 2022-02-24 19:40:00.300151: step 34360, total loss = 0.55, batch loss = 0.27 (233.2 examples/sec; 0.034 sec/batch; 1h:34m:24s remains)
INFO - root - 2022-02-24 19:40:00.684565: step 34370, total loss = 0.61, batch loss = 0.33 (141.3 examples/sec; 0.057 sec/batch; 2h:35m:50s remains)
INFO - root - 2022-02-24 19:40:01.010499: step 34380, total loss = 0.53, batch loss = 0.25 (216.5 examples/sec; 0.037 sec/batch; 1h:41m:41s remains)
INFO - root - 2022-02-24 19:40:01.433780: step 34390, total loss = 0.57, batch loss = 0.29 (245.5 examples/sec; 0.033 sec/batch; 1h:29m:39s remains)
INFO - root - 2022-02-24 19:40:01.989923: step 34400, total loss = 0.57, batch loss = 0.29 (150.3 examples/sec; 0.053 sec/batch; 2h:26m:26s remains)
INFO - root - 2022-02-24 19:40:02.569524: step 34410, total loss = 0.63, batch loss = 0.35 (242.9 examples/sec; 0.033 sec/batch; 1h:30m:36s remains)
INFO - root - 2022-02-24 19:40:02.939756: step 34420, total loss = 0.60, batch loss = 0.32 (239.9 examples/sec; 0.033 sec/batch; 1h:31m:45s remains)
INFO - root - 2022-02-24 19:40:03.399085: step 34430, total loss = 0.55, batch loss = 0.27 (226.0 examples/sec; 0.035 sec/batch; 1h:37m:22s remains)
INFO - root - 2022-02-24 19:40:03.810176: step 34440, total loss = 0.81, batch loss = 0.53 (169.1 examples/sec; 0.047 sec/batch; 2h:10m:10s remains)
INFO - root - 2022-02-24 19:40:04.157262: step 34450, total loss = 0.63, batch loss = 0.35 (150.0 examples/sec; 0.053 sec/batch; 2h:26m:41s remains)
INFO - root - 2022-02-24 19:40:04.697264: step 34460, total loss = 0.61, batch loss = 0.33 (111.0 examples/sec; 0.072 sec/batch; 3h:18m:13s remains)
INFO - root - 2022-02-24 19:40:05.089036: step 34470, total loss = 0.70, batch loss = 0.42 (129.8 examples/sec; 0.062 sec/batch; 2h:49m:31s remains)
INFO - root - 2022-02-24 19:40:05.411791: step 34480, total loss = 0.54, batch loss = 0.26 (239.0 examples/sec; 0.033 sec/batch; 1h:32m:03s remains)
INFO - root - 2022-02-24 19:40:05.902335: step 34490, total loss = 0.61, batch loss = 0.32 (110.1 examples/sec; 0.073 sec/batch; 3h:19m:46s remains)
INFO - root - 2022-02-24 19:40:06.377303: step 34500, total loss = 0.59, batch loss = 0.31 (169.1 examples/sec; 0.047 sec/batch; 2h:10m:06s remains)
INFO - root - 2022-02-24 19:40:06.808358: step 34510, total loss = 0.59, batch loss = 0.30 (326.7 examples/sec; 0.024 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 19:40:07.161139: step 34520, total loss = 0.54, batch loss = 0.26 (287.3 examples/sec; 0.028 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 19:40:07.953455: step 34530, total loss = 0.62, batch loss = 0.34 (242.0 examples/sec; 0.033 sec/batch; 1h:30m:54s remains)
INFO - root - 2022-02-24 19:40:08.385607: step 34540, total loss = 0.62, batch loss = 0.34 (255.3 examples/sec; 0.031 sec/batch; 1h:26m:08s remains)
INFO - root - 2022-02-24 19:40:08.778239: step 34550, total loss = 0.60, batch loss = 0.32 (315.8 examples/sec; 0.025 sec/batch; 1h:09m:38s remains)
INFO - root - 2022-02-24 19:40:09.078339: step 34560, total loss = 0.64, batch loss = 0.36 (232.7 examples/sec; 0.034 sec/batch; 1h:34m:29s remains)
INFO - root - 2022-02-24 19:40:09.478577: step 34570, total loss = 0.61, batch loss = 0.33 (136.0 examples/sec; 0.059 sec/batch; 2h:41m:40s remains)
INFO - root - 2022-02-24 19:40:10.034656: step 34580, total loss = 0.62, batch loss = 0.34 (206.7 examples/sec; 0.039 sec/batch; 1h:46m:23s remains)
INFO - root - 2022-02-24 19:40:10.458604: step 34590, total loss = 0.60, batch loss = 0.32 (366.2 examples/sec; 0.022 sec/batch; 1h:00m:02s remains)
INFO - root - 2022-02-24 19:40:10.822797: step 34600, total loss = 0.57, batch loss = 0.28 (243.8 examples/sec; 0.033 sec/batch; 1h:30m:10s remains)
INFO - root - 2022-02-24 19:40:11.238590: step 34610, total loss = 0.72, batch loss = 0.44 (235.0 examples/sec; 0.034 sec/batch; 1h:33m:32s remains)
INFO - root - 2022-02-24 19:40:11.527279: step 34620, total loss = 0.58, batch loss = 0.29 (345.6 examples/sec; 0.023 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 19:40:12.000091: step 34630, total loss = 0.62, batch loss = 0.34 (142.4 examples/sec; 0.056 sec/batch; 2h:34m:25s remains)
INFO - root - 2022-02-24 19:40:12.461619: step 34640, total loss = 0.57, batch loss = 0.29 (167.6 examples/sec; 0.048 sec/batch; 2h:11m:07s remains)
INFO - root - 2022-02-24 19:40:12.851195: step 34650, total loss = 0.55, batch loss = 0.27 (316.2 examples/sec; 0.025 sec/batch; 1h:09m:31s remains)
INFO - root - 2022-02-24 19:40:13.232669: step 34660, total loss = 0.62, batch loss = 0.34 (96.1 examples/sec; 0.083 sec/batch; 3h:48m:44s remains)
INFO - root - 2022-02-24 19:40:13.592021: step 34670, total loss = 0.57, batch loss = 0.29 (166.4 examples/sec; 0.048 sec/batch; 2h:12m:04s remains)
INFO - root - 2022-02-24 19:40:13.998150: step 34680, total loss = 0.53, batch loss = 0.25 (178.4 examples/sec; 0.045 sec/batch; 2h:03m:11s remains)
INFO - root - 2022-02-24 19:40:14.400838: step 34690, total loss = 0.65, batch loss = 0.36 (144.0 examples/sec; 0.056 sec/batch; 2h:32m:35s remains)
INFO - root - 2022-02-24 19:40:14.822097: step 34700, total loss = 0.61, batch loss = 0.32 (254.5 examples/sec; 0.031 sec/batch; 1h:26m:19s remains)
INFO - root - 2022-02-24 19:40:15.249672: step 34710, total loss = 0.55, batch loss = 0.27 (275.3 examples/sec; 0.029 sec/batch; 1h:19m:47s remains)
INFO - root - 2022-02-24 19:40:15.608592: step 34720, total loss = 0.66, batch loss = 0.38 (219.7 examples/sec; 0.036 sec/batch; 1h:40m:01s remains)
INFO - root - 2022-02-24 19:40:16.040503: step 34730, total loss = 0.53, batch loss = 0.25 (273.3 examples/sec; 0.029 sec/batch; 1h:20m:22s remains)
INFO - root - 2022-02-24 19:40:16.472811: step 34740, total loss = 0.71, batch loss = 0.43 (271.6 examples/sec; 0.029 sec/batch; 1h:20m:53s remains)
INFO - root - 2022-02-24 19:40:16.870292: step 34750, total loss = 0.55, batch loss = 0.27 (263.7 examples/sec; 0.030 sec/batch; 1h:23m:18s remains)
INFO - root - 2022-02-24 19:40:17.280618: step 34760, total loss = 0.54, batch loss = 0.26 (267.9 examples/sec; 0.030 sec/batch; 1h:21m:59s remains)
INFO - root - 2022-02-24 19:40:17.693384: step 34770, total loss = 0.64, batch loss = 0.36 (210.0 examples/sec; 0.038 sec/batch; 1h:44m:36s remains)
INFO - root - 2022-02-24 19:40:18.085829: step 34780, total loss = 0.62, batch loss = 0.34 (131.6 examples/sec; 0.061 sec/batch; 2h:46m:51s remains)
INFO - root - 2022-02-24 19:40:18.553944: step 34790, total loss = 0.58, batch loss = 0.29 (209.5 examples/sec; 0.038 sec/batch; 1h:44m:50s remains)
INFO - root - 2022-02-24 19:40:19.022349: step 34800, total loss = 0.62, batch loss = 0.34 (283.8 examples/sec; 0.028 sec/batch; 1h:17m:22s remains)
INFO - root - 2022-02-24 19:40:19.443923: step 34810, total loss = 0.49, batch loss = 0.21 (236.8 examples/sec; 0.034 sec/batch; 1h:32m:43s remains)
INFO - root - 2022-02-24 19:40:19.803912: step 34820, total loss = 0.63, batch loss = 0.35 (144.4 examples/sec; 0.055 sec/batch; 2h:32m:05s remains)
INFO - root - 2022-02-24 19:40:20.223844: step 34830, total loss = 0.67, batch loss = 0.39 (241.0 examples/sec; 0.033 sec/batch; 1h:31m:07s remains)
INFO - root - 2022-02-24 19:40:20.701212: step 34840, total loss = 0.58, batch loss = 0.30 (173.5 examples/sec; 0.046 sec/batch; 2h:06m:33s remains)
INFO - root - 2022-02-24 19:40:21.020603: step 34850, total loss = 0.57, batch loss = 0.29 (315.6 examples/sec; 0.025 sec/batch; 1h:09m:33s remains)
INFO - root - 2022-02-24 19:40:21.569372: step 34860, total loss = 0.60, batch loss = 0.32 (144.4 examples/sec; 0.055 sec/batch; 2h:32m:03s remains)
INFO - root - 2022-02-24 19:40:22.312100: step 34870, total loss = 0.49, batch loss = 0.20 (81.7 examples/sec; 0.098 sec/batch; 4h:28m:34s remains)
INFO - root - 2022-02-24 19:40:23.164022: step 34880, total loss = 0.67, batch loss = 0.39 (104.2 examples/sec; 0.077 sec/batch; 3h:30m:32s remains)
INFO - root - 2022-02-24 19:40:23.655276: step 34890, total loss = 0.52, batch loss = 0.23 (111.5 examples/sec; 0.072 sec/batch; 3h:16m:54s remains)
INFO - root - 2022-02-24 19:40:23.998299: step 34900, total loss = 0.63, batch loss = 0.35 (342.2 examples/sec; 0.023 sec/batch; 1h:04m:07s remains)
INFO - root - 2022-02-24 19:40:24.442625: step 34910, total loss = 0.60, batch loss = 0.31 (330.9 examples/sec; 0.024 sec/batch; 1h:06m:18s remains)
INFO - root - 2022-02-24 19:40:24.871447: step 34920, total loss = 0.67, batch loss = 0.39 (150.2 examples/sec; 0.053 sec/batch; 2h:26m:03s remains)
INFO - root - 2022-02-24 19:40:25.473294: step 34930, total loss = 0.56, batch loss = 0.27 (228.9 examples/sec; 0.035 sec/batch; 1h:35m:51s remains)
INFO - root - 2022-02-24 19:40:25.947353: step 34940, total loss = 0.63, batch loss = 0.35 (192.5 examples/sec; 0.042 sec/batch; 1h:53m:58s remains)
INFO - root - 2022-02-24 19:40:26.357827: step 34950, total loss = 0.61, batch loss = 0.33 (334.3 examples/sec; 0.024 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 19:40:26.731239: step 34960, total loss = 0.64, batch loss = 0.36 (156.6 examples/sec; 0.051 sec/batch; 2h:20m:08s remains)
INFO - root - 2022-02-24 19:40:27.209070: step 34970, total loss = 0.60, batch loss = 0.32 (191.0 examples/sec; 0.042 sec/batch; 1h:54m:51s remains)
INFO - root - 2022-02-24 19:40:27.654528: step 34980, total loss = 0.63, batch loss = 0.35 (213.7 examples/sec; 0.037 sec/batch; 1h:42m:37s remains)
INFO - root - 2022-02-24 19:40:28.262516: step 34990, total loss = 0.70, batch loss = 0.42 (162.7 examples/sec; 0.049 sec/batch; 2h:14m:49s remains)
INFO - root - 2022-02-24 19:40:28.531515: step 35000, total loss = 0.69, batch loss = 0.41 (368.6 examples/sec; 0.022 sec/batch; 0h:59m:30s remains)
INFO - root - 2022-02-24 19:40:28.956487: step 35010, total loss = 0.60, batch loss = 0.32 (338.0 examples/sec; 0.024 sec/batch; 1h:04m:52s remains)
INFO - root - 2022-02-24 19:40:29.381094: step 35020, total loss = 0.48, batch loss = 0.20 (275.9 examples/sec; 0.029 sec/batch; 1h:19m:29s remains)
INFO - root - 2022-02-24 19:40:29.924056: step 35030, total loss = 0.54, batch loss = 0.25 (115.0 examples/sec; 0.070 sec/batch; 3h:10m:42s remains)
INFO - root - 2022-02-24 19:40:30.273459: step 35040, total loss = 0.54, batch loss = 0.26 (223.7 examples/sec; 0.036 sec/batch; 1h:38m:02s remains)
INFO - root - 2022-02-24 19:40:30.589842: step 35050, total loss = 0.51, batch loss = 0.22 (239.6 examples/sec; 0.033 sec/batch; 1h:31m:31s remains)
INFO - root - 2022-02-24 19:40:30.926595: step 35060, total loss = 0.55, batch loss = 0.27 (328.3 examples/sec; 0.024 sec/batch; 1h:06m:47s remains)
INFO - root - 2022-02-24 19:40:31.316845: step 35070, total loss = 0.57, batch loss = 0.29 (108.4 examples/sec; 0.074 sec/batch; 3h:22m:11s remains)
INFO - root - 2022-02-24 19:40:31.783194: step 35080, total loss = 0.58, batch loss = 0.30 (278.1 examples/sec; 0.029 sec/batch; 1h:18m:49s remains)
INFO - root - 2022-02-24 19:40:32.232775: step 35090, total loss = 0.51, batch loss = 0.23 (88.9 examples/sec; 0.090 sec/batch; 4h:06m:28s remains)
INFO - root - 2022-02-24 19:40:32.647172: step 35100, total loss = 0.58, batch loss = 0.29 (190.8 examples/sec; 0.042 sec/batch; 1h:54m:53s remains)
INFO - root - 2022-02-24 19:40:33.135833: step 35110, total loss = 0.64, batch loss = 0.36 (90.7 examples/sec; 0.088 sec/batch; 4h:01m:44s remains)
INFO - root - 2022-02-24 19:40:33.524282: step 35120, total loss = 0.54, batch loss = 0.25 (116.4 examples/sec; 0.069 sec/batch; 3h:08m:19s remains)
INFO - root - 2022-02-24 19:40:33.986910: step 35130, total loss = 0.50, batch loss = 0.22 (141.2 examples/sec; 0.057 sec/batch; 2h:35m:09s remains)
INFO - root - 2022-02-24 19:40:34.380794: step 35140, total loss = 0.58, batch loss = 0.29 (321.2 examples/sec; 0.025 sec/batch; 1h:08m:13s remains)
INFO - root - 2022-02-24 19:40:34.741322: step 35150, total loss = 0.60, batch loss = 0.31 (136.0 examples/sec; 0.059 sec/batch; 2h:41m:06s remains)
INFO - root - 2022-02-24 19:40:35.063665: step 35160, total loss = 0.80, batch loss = 0.52 (322.2 examples/sec; 0.025 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 19:40:35.443135: step 35170, total loss = 0.56, batch loss = 0.28 (180.6 examples/sec; 0.044 sec/batch; 2h:01m:17s remains)
INFO - root - 2022-02-24 19:40:35.854887: step 35180, total loss = 0.52, batch loss = 0.24 (78.1 examples/sec; 0.102 sec/batch; 4h:40m:27s remains)
INFO - root - 2022-02-24 19:40:36.343426: step 35190, total loss = 0.57, batch loss = 0.29 (109.8 examples/sec; 0.073 sec/batch; 3h:19m:29s remains)
INFO - root - 2022-02-24 19:40:36.624581: step 35200, total loss = 0.64, batch loss = 0.36 (291.9 examples/sec; 0.027 sec/batch; 1h:15m:02s remains)
INFO - root - 2022-02-24 19:40:37.029575: step 35210, total loss = 0.63, batch loss = 0.35 (166.4 examples/sec; 0.048 sec/batch; 2h:11m:39s remains)
INFO - root - 2022-02-24 19:40:37.382333: step 35220, total loss = 0.51, batch loss = 0.23 (214.7 examples/sec; 0.037 sec/batch; 1h:42m:01s remains)
INFO - root - 2022-02-24 19:40:37.788767: step 35230, total loss = 0.70, batch loss = 0.41 (294.4 examples/sec; 0.027 sec/batch; 1h:14m:23s remains)
INFO - root - 2022-02-24 19:40:38.305729: step 35240, total loss = 0.60, batch loss = 0.32 (327.8 examples/sec; 0.024 sec/batch; 1h:06m:48s remains)
INFO - root - 2022-02-24 19:40:38.698518: step 35250, total loss = 0.57, batch loss = 0.28 (234.5 examples/sec; 0.034 sec/batch; 1h:33m:22s remains)
INFO - root - 2022-02-24 19:40:39.028810: step 35260, total loss = 0.48, batch loss = 0.20 (297.7 examples/sec; 0.027 sec/batch; 1h:13m:32s remains)
INFO - root - 2022-02-24 19:40:39.364161: step 35270, total loss = 0.59, batch loss = 0.31 (133.9 examples/sec; 0.060 sec/batch; 2h:43m:28s remains)
INFO - root - 2022-02-24 19:40:39.738006: step 35280, total loss = 0.53, batch loss = 0.25 (338.2 examples/sec; 0.024 sec/batch; 1h:04m:44s remains)
INFO - root - 2022-02-24 19:40:40.166017: step 35290, total loss = 0.55, batch loss = 0.27 (134.0 examples/sec; 0.060 sec/batch; 2h:43m:21s remains)
INFO - root - 2022-02-24 19:40:40.582234: step 35300, total loss = 0.58, batch loss = 0.29 (391.9 examples/sec; 0.020 sec/batch; 0h:55m:52s remains)
INFO - root - 2022-02-24 19:40:40.948312: step 35310, total loss = 0.58, batch loss = 0.30 (305.3 examples/sec; 0.026 sec/batch; 1h:11m:42s remains)
INFO - root - 2022-02-24 19:40:41.289850: step 35320, total loss = 0.54, batch loss = 0.26 (308.7 examples/sec; 0.026 sec/batch; 1h:10m:55s remains)
INFO - root - 2022-02-24 19:40:41.687026: step 35330, total loss = 0.61, batch loss = 0.32 (196.0 examples/sec; 0.041 sec/batch; 1h:51m:39s remains)
INFO - root - 2022-02-24 19:40:42.108787: step 35340, total loss = 0.58, batch loss = 0.30 (183.2 examples/sec; 0.044 sec/batch; 1h:59m:29s remains)
INFO - root - 2022-02-24 19:40:42.567227: step 35350, total loss = 0.59, batch loss = 0.31 (314.2 examples/sec; 0.025 sec/batch; 1h:09m:40s remains)
INFO - root - 2022-02-24 19:40:42.916041: step 35360, total loss = 0.49, batch loss = 0.21 (192.1 examples/sec; 0.042 sec/batch; 1h:53m:56s remains)
INFO - root - 2022-02-24 19:40:43.224270: step 35370, total loss = 0.61, batch loss = 0.33 (297.5 examples/sec; 0.027 sec/batch; 1h:13m:33s remains)
INFO - root - 2022-02-24 19:40:43.582296: step 35380, total loss = 0.53, batch loss = 0.24 (309.5 examples/sec; 0.026 sec/batch; 1h:10m:42s remains)
INFO - root - 2022-02-24 19:40:43.970779: step 35390, total loss = 0.58, batch loss = 0.30 (322.9 examples/sec; 0.025 sec/batch; 1h:07m:45s remains)
INFO - root - 2022-02-24 19:40:44.558332: step 35400, total loss = 0.58, batch loss = 0.30 (258.6 examples/sec; 0.031 sec/batch; 1h:24m:36s remains)
INFO - root - 2022-02-24 19:40:44.994208: step 35410, total loss = 0.72, batch loss = 0.43 (271.4 examples/sec; 0.029 sec/batch; 1h:20m:36s remains)
INFO - root - 2022-02-24 19:40:45.498135: step 35420, total loss = 0.59, batch loss = 0.31 (287.2 examples/sec; 0.028 sec/batch; 1h:16m:10s remains)
INFO - root - 2022-02-24 19:40:46.132519: step 35430, total loss = 0.59, batch loss = 0.30 (118.2 examples/sec; 0.068 sec/batch; 3h:05m:03s remains)
INFO - root - 2022-02-24 19:40:46.518366: step 35440, total loss = 0.58, batch loss = 0.30 (73.8 examples/sec; 0.108 sec/batch; 4h:56m:22s remains)
INFO - root - 2022-02-24 19:40:46.981183: step 35450, total loss = 0.51, batch loss = 0.23 (121.2 examples/sec; 0.066 sec/batch; 3h:00m:28s remains)
INFO - root - 2022-02-24 19:40:47.515426: step 35460, total loss = 0.62, batch loss = 0.34 (277.8 examples/sec; 0.029 sec/batch; 1h:18m:44s remains)
INFO - root - 2022-02-24 19:40:48.140151: step 35470, total loss = 0.54, batch loss = 0.26 (118.9 examples/sec; 0.067 sec/batch; 3h:03m:54s remains)
INFO - root - 2022-02-24 19:40:48.850666: step 35480, total loss = 0.63, batch loss = 0.35 (74.1 examples/sec; 0.108 sec/batch; 4h:55m:15s remains)
INFO - root - 2022-02-24 19:40:49.659117: step 35490, total loss = 0.60, batch loss = 0.31 (284.8 examples/sec; 0.028 sec/batch; 1h:16m:47s remains)
INFO - root - 2022-02-24 19:40:50.013082: step 35500, total loss = 0.58, batch loss = 0.29 (230.2 examples/sec; 0.035 sec/batch; 1h:34m:58s remains)
INFO - root - 2022-02-24 19:40:50.478532: step 35510, total loss = 0.50, batch loss = 0.22 (163.9 examples/sec; 0.049 sec/batch; 2h:13m:21s remains)
INFO - root - 2022-02-24 19:40:50.948667: step 35520, total loss = 0.58, batch loss = 0.30 (116.8 examples/sec; 0.068 sec/batch; 3h:07m:09s remains)
INFO - root - 2022-02-24 19:40:51.432914: step 35530, total loss = 0.61, batch loss = 0.33 (138.5 examples/sec; 0.058 sec/batch; 2h:37m:49s remains)
INFO - root - 2022-02-24 19:40:51.920476: step 35540, total loss = 0.84, batch loss = 0.55 (107.7 examples/sec; 0.074 sec/batch; 3h:22m:54s remains)
INFO - root - 2022-02-24 19:40:52.274605: step 35550, total loss = 0.53, batch loss = 0.25 (132.3 examples/sec; 0.060 sec/batch; 2h:45m:15s remains)
INFO - root - 2022-02-24 19:40:52.602904: step 35560, total loss = 0.53, batch loss = 0.25 (207.1 examples/sec; 0.039 sec/batch; 1h:45m:33s remains)
INFO - root - 2022-02-24 19:40:52.975723: step 35570, total loss = 0.65, batch loss = 0.37 (244.7 examples/sec; 0.033 sec/batch; 1h:29m:18s remains)
INFO - root - 2022-02-24 19:40:53.440681: step 35580, total loss = 0.59, batch loss = 0.31 (184.5 examples/sec; 0.043 sec/batch; 1h:58m:27s remains)
INFO - root - 2022-02-24 19:40:53.899190: step 35590, total loss = 0.55, batch loss = 0.26 (211.8 examples/sec; 0.038 sec/batch; 1h:43m:11s remains)
INFO - root - 2022-02-24 19:40:54.345583: step 35600, total loss = 0.55, batch loss = 0.27 (187.2 examples/sec; 0.043 sec/batch; 1h:56m:45s remains)
INFO - root - 2022-02-24 19:40:54.721616: step 35610, total loss = 0.65, batch loss = 0.37 (256.8 examples/sec; 0.031 sec/batch; 1h:25m:05s remains)
INFO - root - 2022-02-24 19:40:55.134777: step 35620, total loss = 0.63, batch loss = 0.34 (204.3 examples/sec; 0.039 sec/batch; 1h:46m:58s remains)
INFO - root - 2022-02-24 19:40:55.560018: step 35630, total loss = 0.59, batch loss = 0.31 (157.8 examples/sec; 0.051 sec/batch; 2h:18m:26s remains)
INFO - root - 2022-02-24 19:40:55.986939: step 35640, total loss = 0.66, batch loss = 0.38 (366.4 examples/sec; 0.022 sec/batch; 0h:59m:37s remains)
INFO - root - 2022-02-24 19:40:56.278127: step 35650, total loss = 0.59, batch loss = 0.31 (291.6 examples/sec; 0.027 sec/batch; 1h:14m:55s remains)
INFO - root - 2022-02-24 19:40:56.634067: step 35660, total loss = 0.54, batch loss = 0.26 (352.6 examples/sec; 0.023 sec/batch; 1h:01m:57s remains)
INFO - root - 2022-02-24 19:40:56.985091: step 35670, total loss = 0.58, batch loss = 0.30 (214.6 examples/sec; 0.037 sec/batch; 1h:41m:47s remains)
INFO - root - 2022-02-24 19:40:57.469646: step 35680, total loss = 0.49, batch loss = 0.20 (125.3 examples/sec; 0.064 sec/batch; 2h:54m:19s remains)
INFO - root - 2022-02-24 19:40:57.957748: step 35690, total loss = 0.53, batch loss = 0.25 (194.5 examples/sec; 0.041 sec/batch; 1h:52m:16s remains)
INFO - root - 2022-02-24 19:40:58.431051: step 35700, total loss = 0.60, batch loss = 0.32 (190.2 examples/sec; 0.042 sec/batch; 1h:54m:50s remains)
INFO - root - 2022-02-24 19:40:58.855102: step 35710, total loss = 0.57, batch loss = 0.29 (221.9 examples/sec; 0.036 sec/batch; 1h:38m:25s remains)
INFO - root - 2022-02-24 19:40:59.189560: step 35720, total loss = 0.53, batch loss = 0.24 (244.4 examples/sec; 0.033 sec/batch; 1h:29m:20s remains)
INFO - root - 2022-02-24 19:40:59.584045: step 35730, total loss = 0.57, batch loss = 0.29 (255.7 examples/sec; 0.031 sec/batch; 1h:25m:23s remains)
INFO - root - 2022-02-24 19:41:00.057154: step 35740, total loss = 0.62, batch loss = 0.34 (148.9 examples/sec; 0.054 sec/batch; 2h:26m:40s remains)
INFO - root - 2022-02-24 19:41:00.465448: step 35750, total loss = 0.59, batch loss = 0.30 (142.6 examples/sec; 0.056 sec/batch; 2h:33m:07s remains)
INFO - root - 2022-02-24 19:41:00.836921: step 35760, total loss = 0.59, batch loss = 0.31 (263.8 examples/sec; 0.030 sec/batch; 1h:22m:46s remains)
INFO - root - 2022-02-24 19:41:01.141644: step 35770, total loss = 0.60, batch loss = 0.32 (240.7 examples/sec; 0.033 sec/batch; 1h:30m:42s remains)
INFO - root - 2022-02-24 19:41:01.507740: step 35780, total loss = 0.59, batch loss = 0.31 (164.1 examples/sec; 0.049 sec/batch; 2h:13m:03s remains)
INFO - root - 2022-02-24 19:41:02.012769: step 35790, total loss = 0.49, batch loss = 0.21 (272.6 examples/sec; 0.029 sec/batch; 1h:20m:04s remains)
INFO - root - 2022-02-24 19:41:02.415966: step 35800, total loss = 0.65, batch loss = 0.37 (132.5 examples/sec; 0.060 sec/batch; 2h:44m:42s remains)
INFO - root - 2022-02-24 19:41:02.754493: step 35810, total loss = 0.65, batch loss = 0.37 (310.5 examples/sec; 0.026 sec/batch; 1h:10m:17s remains)
INFO - root - 2022-02-24 19:41:03.051399: step 35820, total loss = 0.65, batch loss = 0.37 (183.9 examples/sec; 0.043 sec/batch; 1h:58m:39s remains)
INFO - root - 2022-02-24 19:41:03.482932: step 35830, total loss = 0.59, batch loss = 0.31 (334.6 examples/sec; 0.024 sec/batch; 1h:05m:13s remains)
INFO - root - 2022-02-24 19:41:03.800792: step 35840, total loss = 0.61, batch loss = 0.33 (383.9 examples/sec; 0.021 sec/batch; 0h:56m:50s remains)
INFO - root - 2022-02-24 19:41:04.290310: step 35850, total loss = 0.55, batch loss = 0.27 (162.1 examples/sec; 0.049 sec/batch; 2h:14m:34s remains)
INFO - root - 2022-02-24 19:41:04.627117: step 35860, total loss = 0.63, batch loss = 0.34 (326.4 examples/sec; 0.025 sec/batch; 1h:06m:50s remains)
INFO - root - 2022-02-24 19:41:04.985826: step 35870, total loss = 0.57, batch loss = 0.29 (176.8 examples/sec; 0.045 sec/batch; 2h:03m:22s remains)
INFO - root - 2022-02-24 19:41:05.484187: step 35880, total loss = 0.63, batch loss = 0.35 (308.1 examples/sec; 0.026 sec/batch; 1h:10m:48s remains)
INFO - root - 2022-02-24 19:41:06.081655: step 35890, total loss = 0.65, batch loss = 0.36 (152.6 examples/sec; 0.052 sec/batch; 2h:22m:59s remains)
INFO - root - 2022-02-24 19:41:06.690086: step 35900, total loss = 0.81, batch loss = 0.53 (133.6 examples/sec; 0.060 sec/batch; 2h:43m:17s remains)
INFO - root - 2022-02-24 19:41:07.724636: step 35910, total loss = 0.59, batch loss = 0.31 (301.5 examples/sec; 0.027 sec/batch; 1h:12m:20s remains)
INFO - root - 2022-02-24 19:41:07.968398: step 35920, total loss = 0.60, batch loss = 0.32 (335.7 examples/sec; 0.024 sec/batch; 1h:04m:58s remains)
INFO - root - 2022-02-24 19:41:08.206083: step 35930, total loss = 0.50, batch loss = 0.22 (332.4 examples/sec; 0.024 sec/batch; 1h:05m:36s remains)
INFO - root - 2022-02-24 19:41:08.881443: step 35940, total loss = 0.52, batch loss = 0.24 (105.9 examples/sec; 0.076 sec/batch; 3h:25m:53s remains)
INFO - root - 2022-02-24 19:41:09.362131: step 35950, total loss = 0.71, batch loss = 0.43 (271.9 examples/sec; 0.029 sec/batch; 1h:20m:11s remains)
INFO - root - 2022-02-24 19:41:09.793318: step 35960, total loss = 0.81, batch loss = 0.53 (291.1 examples/sec; 0.027 sec/batch; 1h:14m:54s remains)
INFO - root - 2022-02-24 19:41:10.162336: step 35970, total loss = 0.60, batch loss = 0.32 (289.4 examples/sec; 0.028 sec/batch; 1h:15m:20s remains)
INFO - root - 2022-02-24 19:41:10.463701: step 35980, total loss = 0.66, batch loss = 0.38 (341.9 examples/sec; 0.023 sec/batch; 1h:03m:46s remains)
INFO - root - 2022-02-24 19:41:10.804559: step 35990, total loss = 0.66, batch loss = 0.38 (314.3 examples/sec; 0.025 sec/batch; 1h:09m:22s remains)
INFO - root - 2022-02-24 19:41:11.222638: step 36000, total loss = 0.55, batch loss = 0.27 (162.7 examples/sec; 0.049 sec/batch; 2h:13m:59s remains)
INFO - root - 2022-02-24 19:41:11.728138: step 36010, total loss = 0.67, batch loss = 0.39 (189.1 examples/sec; 0.042 sec/batch; 1h:55m:16s remains)
INFO - root - 2022-02-24 19:41:12.093728: step 36020, total loss = 0.53, batch loss = 0.24 (221.5 examples/sec; 0.036 sec/batch; 1h:38m:24s remains)
INFO - root - 2022-02-24 19:41:12.390093: step 36030, total loss = 0.56, batch loss = 0.28 (345.0 examples/sec; 0.023 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 19:41:12.728776: step 36040, total loss = 0.68, batch loss = 0.40 (207.2 examples/sec; 0.039 sec/batch; 1h:45m:12s remains)
INFO - root - 2022-02-24 19:41:13.182630: step 36050, total loss = 0.66, batch loss = 0.38 (157.3 examples/sec; 0.051 sec/batch; 2h:18m:32s remains)
INFO - root - 2022-02-24 19:41:13.613738: step 36060, total loss = 0.54, batch loss = 0.26 (358.1 examples/sec; 0.022 sec/batch; 1h:00m:51s remains)
INFO - root - 2022-02-24 19:41:14.102149: step 36070, total loss = 0.60, batch loss = 0.32 (268.2 examples/sec; 0.030 sec/batch; 1h:21m:15s remains)
INFO - root - 2022-02-24 19:41:14.498785: step 36080, total loss = 0.68, batch loss = 0.40 (227.2 examples/sec; 0.035 sec/batch; 1h:35m:53s remains)
INFO - root - 2022-02-24 19:41:14.838358: step 36090, total loss = 0.55, batch loss = 0.27 (242.6 examples/sec; 0.033 sec/batch; 1h:29m:48s remains)
INFO - root - 2022-02-24 19:41:15.202545: step 36100, total loss = 0.75, batch loss = 0.47 (218.4 examples/sec; 0.037 sec/batch; 1h:39m:44s remains)
INFO - root - 2022-02-24 19:41:15.760106: step 36110, total loss = 0.61, batch loss = 0.33 (113.9 examples/sec; 0.070 sec/batch; 3h:11m:19s remains)
INFO - root - 2022-02-24 19:41:16.203346: step 36120, total loss = 0.53, batch loss = 0.25 (277.3 examples/sec; 0.029 sec/batch; 1h:18m:32s remains)
INFO - root - 2022-02-24 19:41:16.485802: step 36130, total loss = 0.59, batch loss = 0.31 (239.2 examples/sec; 0.033 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 19:41:16.808283: step 36140, total loss = 0.61, batch loss = 0.33 (311.9 examples/sec; 0.026 sec/batch; 1h:09m:50s remains)
INFO - root - 2022-02-24 19:41:17.095954: step 36150, total loss = 0.52, batch loss = 0.24 (143.4 examples/sec; 0.056 sec/batch; 2h:31m:51s remains)
INFO - root - 2022-02-24 19:41:17.545244: step 36160, total loss = 0.60, batch loss = 0.32 (126.8 examples/sec; 0.063 sec/batch; 2h:51m:45s remains)
INFO - root - 2022-02-24 19:41:18.022910: step 36170, total loss = 0.66, batch loss = 0.37 (169.3 examples/sec; 0.047 sec/batch; 2h:08m:35s remains)
INFO - root - 2022-02-24 19:41:18.475812: step 36180, total loss = 0.60, batch loss = 0.32 (130.1 examples/sec; 0.061 sec/batch; 2h:47m:20s remains)
INFO - root - 2022-02-24 19:41:18.890256: step 36190, total loss = 0.61, batch loss = 0.33 (146.0 examples/sec; 0.055 sec/batch; 2h:29m:10s remains)
INFO - root - 2022-02-24 19:41:19.244008: step 36200, total loss = 0.77, batch loss = 0.48 (256.8 examples/sec; 0.031 sec/batch; 1h:24m:47s remains)
INFO - root - 2022-02-24 19:41:19.754297: step 36210, total loss = 0.61, batch loss = 0.33 (328.2 examples/sec; 0.024 sec/batch; 1h:06m:20s remains)
INFO - root - 2022-02-24 19:41:20.171010: step 36220, total loss = 0.59, batch loss = 0.30 (142.1 examples/sec; 0.056 sec/batch; 2h:33m:11s remains)
INFO - root - 2022-02-24 19:41:20.603081: step 36230, total loss = 0.60, batch loss = 0.32 (224.1 examples/sec; 0.036 sec/batch; 1h:37m:08s remains)
INFO - root - 2022-02-24 19:41:20.973973: step 36240, total loss = 0.64, batch loss = 0.36 (321.2 examples/sec; 0.025 sec/batch; 1h:07m:46s remains)
INFO - root - 2022-02-24 19:41:21.295781: step 36250, total loss = 0.53, batch loss = 0.24 (345.7 examples/sec; 0.023 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 19:41:21.634057: step 36260, total loss = 0.57, batch loss = 0.28 (124.5 examples/sec; 0.064 sec/batch; 2h:54m:45s remains)
INFO - root - 2022-02-24 19:41:22.086025: step 36270, total loss = 0.68, batch loss = 0.40 (225.4 examples/sec; 0.035 sec/batch; 1h:36m:33s remains)
INFO - root - 2022-02-24 19:41:22.544421: step 36280, total loss = 0.58, batch loss = 0.30 (370.9 examples/sec; 0.022 sec/batch; 0h:58m:40s remains)
INFO - root - 2022-02-24 19:41:22.948761: step 36290, total loss = 0.59, batch loss = 0.30 (337.1 examples/sec; 0.024 sec/batch; 1h:04m:33s remains)
INFO - root - 2022-02-24 19:41:23.921726: step 36300, total loss = 0.59, batch loss = 0.31 (14.8 examples/sec; 0.539 sec/batch; 24h:25m:49s remains)
INFO - root - 2022-02-24 19:41:24.455217: step 36310, total loss = 0.61, batch loss = 0.33 (271.8 examples/sec; 0.029 sec/batch; 1h:20m:03s remains)
INFO - root - 2022-02-24 19:41:24.865794: step 36320, total loss = 0.63, batch loss = 0.35 (214.7 examples/sec; 0.037 sec/batch; 1h:41m:20s remains)
INFO - root - 2022-02-24 19:41:25.234890: step 36330, total loss = 0.62, batch loss = 0.34 (164.5 examples/sec; 0.049 sec/batch; 2h:12m:16s remains)
INFO - root - 2022-02-24 19:41:25.651203: step 36340, total loss = 0.64, batch loss = 0.35 (182.7 examples/sec; 0.044 sec/batch; 1h:59m:05s remains)
INFO - root - 2022-02-24 19:41:26.119680: step 36350, total loss = 0.55, batch loss = 0.27 (189.8 examples/sec; 0.042 sec/batch; 1h:54m:38s remains)
INFO - root - 2022-02-24 19:41:26.530697: step 36360, total loss = 0.58, batch loss = 0.30 (151.4 examples/sec; 0.053 sec/batch; 2h:23m:41s remains)
INFO - root - 2022-02-24 19:41:26.962922: step 36370, total loss = 0.65, batch loss = 0.37 (178.8 examples/sec; 0.045 sec/batch; 2h:01m:40s remains)
INFO - root - 2022-02-24 19:41:27.322833: step 36380, total loss = 0.65, batch loss = 0.36 (234.3 examples/sec; 0.034 sec/batch; 1h:32m:48s remains)
INFO - root - 2022-02-24 19:41:27.684046: step 36390, total loss = 0.76, batch loss = 0.48 (347.5 examples/sec; 0.023 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 19:41:28.027374: step 36400, total loss = 0.72, batch loss = 0.44 (239.1 examples/sec; 0.033 sec/batch; 1h:30m:56s remains)
INFO - root - 2022-02-24 19:41:28.411615: step 36410, total loss = 0.52, batch loss = 0.24 (323.0 examples/sec; 0.025 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 19:41:29.274432: step 36420, total loss = 0.48, batch loss = 0.20 (350.4 examples/sec; 0.023 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 19:41:29.755215: step 36430, total loss = 0.72, batch loss = 0.44 (201.3 examples/sec; 0.040 sec/batch; 1h:48m:01s remains)
INFO - root - 2022-02-24 19:41:30.136482: step 36440, total loss = 0.50, batch loss = 0.22 (319.7 examples/sec; 0.025 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 19:41:30.454514: step 36450, total loss = 0.60, batch loss = 0.32 (235.4 examples/sec; 0.034 sec/batch; 1h:32m:21s remains)
INFO - root - 2022-02-24 19:41:30.788874: step 36460, total loss = 0.53, batch loss = 0.24 (225.5 examples/sec; 0.035 sec/batch; 1h:36m:25s remains)
INFO - root - 2022-02-24 19:41:31.222276: step 36470, total loss = 0.51, batch loss = 0.23 (336.6 examples/sec; 0.024 sec/batch; 1h:04m:35s remains)
INFO - root - 2022-02-24 19:41:31.697631: step 36480, total loss = 0.59, batch loss = 0.31 (203.0 examples/sec; 0.039 sec/batch; 1h:47m:03s remains)
INFO - root - 2022-02-24 19:41:32.056009: step 36490, total loss = 0.58, batch loss = 0.30 (316.7 examples/sec; 0.025 sec/batch; 1h:08m:37s remains)
INFO - root - 2022-02-24 19:41:32.484222: step 36500, total loss = 0.61, batch loss = 0.33 (176.1 examples/sec; 0.045 sec/batch; 2h:03m:24s remains)
INFO - root - 2022-02-24 19:41:32.921402: step 36510, total loss = 0.46, batch loss = 0.18 (303.3 examples/sec; 0.026 sec/batch; 1h:11m:39s remains)
INFO - root - 2022-02-24 19:41:33.350754: step 36520, total loss = 0.59, batch loss = 0.31 (195.7 examples/sec; 0.041 sec/batch; 1h:51m:02s remains)
INFO - root - 2022-02-24 19:41:33.800305: step 36530, total loss = 0.53, batch loss = 0.25 (302.5 examples/sec; 0.026 sec/batch; 1h:11m:49s remains)
INFO - root - 2022-02-24 19:41:34.176938: step 36540, total loss = 0.73, batch loss = 0.45 (294.7 examples/sec; 0.027 sec/batch; 1h:13m:44s remains)
INFO - root - 2022-02-24 19:41:34.484313: step 36550, total loss = 0.58, batch loss = 0.30 (263.3 examples/sec; 0.030 sec/batch; 1h:22m:31s remains)
INFO - root - 2022-02-24 19:41:34.793990: step 36560, total loss = 0.52, batch loss = 0.24 (250.2 examples/sec; 0.032 sec/batch; 1h:26m:50s remains)
INFO - root - 2022-02-24 19:41:35.298180: step 36570, total loss = 0.56, batch loss = 0.28 (94.4 examples/sec; 0.085 sec/batch; 3h:50m:00s remains)
INFO - root - 2022-02-24 19:41:35.696643: step 36580, total loss = 0.54, batch loss = 0.26 (200.5 examples/sec; 0.040 sec/batch; 1h:48m:19s remains)
INFO - root - 2022-02-24 19:41:36.092559: step 36590, total loss = 0.70, batch loss = 0.42 (297.5 examples/sec; 0.027 sec/batch; 1h:13m:00s remains)
INFO - root - 2022-02-24 19:41:36.406788: step 36600, total loss = 0.55, batch loss = 0.27 (347.4 examples/sec; 0.023 sec/batch; 1h:02m:30s remains)
INFO - root - 2022-02-24 19:41:36.772977: step 36610, total loss = 0.55, batch loss = 0.27 (322.5 examples/sec; 0.025 sec/batch; 1h:07m:20s remains)
INFO - root - 2022-02-24 19:41:37.043559: step 36620, total loss = 0.60, batch loss = 0.32 (218.0 examples/sec; 0.037 sec/batch; 1h:39m:36s remains)
INFO - root - 2022-02-24 19:41:37.447584: step 36630, total loss = 0.70, batch loss = 0.42 (106.7 examples/sec; 0.075 sec/batch; 3h:23m:30s remains)
INFO - root - 2022-02-24 19:41:37.888914: step 36640, total loss = 0.60, batch loss = 0.32 (228.7 examples/sec; 0.035 sec/batch; 1h:34m:57s remains)
INFO - root - 2022-02-24 19:41:38.256800: step 36650, total loss = 0.49, batch loss = 0.21 (226.7 examples/sec; 0.035 sec/batch; 1h:35m:46s remains)
INFO - root - 2022-02-24 19:41:38.648564: step 36660, total loss = 0.62, batch loss = 0.34 (104.7 examples/sec; 0.076 sec/batch; 3h:27m:25s remains)
INFO - root - 2022-02-24 19:41:39.008661: step 36670, total loss = 0.60, batch loss = 0.32 (324.3 examples/sec; 0.025 sec/batch; 1h:06m:56s remains)
INFO - root - 2022-02-24 19:41:39.344496: step 36680, total loss = 0.58, batch loss = 0.29 (303.0 examples/sec; 0.026 sec/batch; 1h:11m:38s remains)
INFO - root - 2022-02-24 19:41:39.842561: step 36690, total loss = 0.52, batch loss = 0.24 (124.5 examples/sec; 0.064 sec/batch; 2h:54m:23s remains)
INFO - root - 2022-02-24 19:41:40.307829: step 36700, total loss = 0.54, batch loss = 0.26 (119.7 examples/sec; 0.067 sec/batch; 3h:01m:23s remains)
INFO - root - 2022-02-24 19:41:40.677388: step 36710, total loss = 0.62, batch loss = 0.34 (370.6 examples/sec; 0.022 sec/batch; 0h:58m:33s remains)
INFO - root - 2022-02-24 19:41:40.997619: step 36720, total loss = 0.68, batch loss = 0.40 (263.1 examples/sec; 0.030 sec/batch; 1h:22m:29s remains)
INFO - root - 2022-02-24 19:41:41.336360: step 36730, total loss = 0.62, batch loss = 0.34 (344.6 examples/sec; 0.023 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 19:41:41.772800: step 36740, total loss = 0.59, batch loss = 0.30 (233.8 examples/sec; 0.034 sec/batch; 1h:32m:48s remains)
INFO - root - 2022-02-24 19:41:42.214985: step 36750, total loss = 0.66, batch loss = 0.38 (324.2 examples/sec; 0.025 sec/batch; 1h:06m:55s remains)
INFO - root - 2022-02-24 19:41:42.636963: step 36760, total loss = 0.57, batch loss = 0.29 (122.1 examples/sec; 0.065 sec/batch; 2h:57m:39s remains)
INFO - root - 2022-02-24 19:41:43.030168: step 36770, total loss = 0.62, batch loss = 0.34 (174.1 examples/sec; 0.046 sec/batch; 2h:04m:36s remains)
INFO - root - 2022-02-24 19:41:43.516791: step 36780, total loss = 0.56, batch loss = 0.27 (119.2 examples/sec; 0.067 sec/batch; 3h:01m:56s remains)
INFO - root - 2022-02-24 19:41:44.373352: step 36790, total loss = 0.69, batch loss = 0.41 (167.4 examples/sec; 0.048 sec/batch; 2h:09m:35s remains)
INFO - root - 2022-02-24 19:41:44.811326: step 36800, total loss = 0.58, batch loss = 0.30 (283.0 examples/sec; 0.028 sec/batch; 1h:16m:39s remains)
INFO - root - 2022-02-24 19:41:45.362258: step 36810, total loss = 0.58, batch loss = 0.30 (345.9 examples/sec; 0.023 sec/batch; 1h:02m:42s remains)
INFO - root - 2022-02-24 19:41:45.721391: step 36820, total loss = 0.55, batch loss = 0.27 (196.9 examples/sec; 0.041 sec/batch; 1h:50m:11s remains)
INFO - root - 2022-02-24 19:41:46.136285: step 36830, total loss = 0.53, batch loss = 0.25 (173.7 examples/sec; 0.046 sec/batch; 2h:04m:50s remains)
INFO - root - 2022-02-24 19:41:46.644051: step 36840, total loss = 0.64, batch loss = 0.35 (224.8 examples/sec; 0.036 sec/batch; 1h:36m:29s remains)
INFO - root - 2022-02-24 19:41:47.154653: step 36850, total loss = 0.51, batch loss = 0.23 (157.6 examples/sec; 0.051 sec/batch; 2h:17m:38s remains)
INFO - root - 2022-02-24 19:41:47.625886: step 36860, total loss = 0.66, batch loss = 0.38 (100.5 examples/sec; 0.080 sec/batch; 3h:35m:45s remains)
INFO - root - 2022-02-24 19:41:47.984547: step 36870, total loss = 0.69, batch loss = 0.41 (182.9 examples/sec; 0.044 sec/batch; 1h:58m:34s remains)
INFO - root - 2022-02-24 19:41:48.389581: step 36880, total loss = 0.55, batch loss = 0.27 (157.3 examples/sec; 0.051 sec/batch; 2h:17m:49s remains)
INFO - root - 2022-02-24 19:41:49.199189: step 36890, total loss = 0.54, batch loss = 0.26 (100.5 examples/sec; 0.080 sec/batch; 3h:35m:44s remains)
INFO - root - 2022-02-24 19:41:49.642251: step 36900, total loss = 0.56, batch loss = 0.27 (245.6 examples/sec; 0.033 sec/batch; 1h:28m:15s remains)
INFO - root - 2022-02-24 19:41:50.037727: step 36910, total loss = 0.70, batch loss = 0.42 (274.5 examples/sec; 0.029 sec/batch; 1h:18m:59s remains)
INFO - root - 2022-02-24 19:41:50.378534: step 36920, total loss = 0.52, batch loss = 0.24 (342.0 examples/sec; 0.023 sec/batch; 1h:03m:23s remains)
INFO - root - 2022-02-24 19:41:50.737357: step 36930, total loss = 0.59, batch loss = 0.30 (322.4 examples/sec; 0.025 sec/batch; 1h:07m:14s remains)
INFO - root - 2022-02-24 19:41:51.107816: step 36940, total loss = 0.53, batch loss = 0.25 (126.4 examples/sec; 0.063 sec/batch; 2h:51m:29s remains)
INFO - root - 2022-02-24 19:41:51.580686: step 36950, total loss = 0.60, batch loss = 0.32 (339.6 examples/sec; 0.024 sec/batch; 1h:03m:48s remains)
INFO - root - 2022-02-24 19:41:51.971287: step 36960, total loss = 0.52, batch loss = 0.24 (213.1 examples/sec; 0.038 sec/batch; 1h:41m:41s remains)
INFO - root - 2022-02-24 19:41:52.306264: step 36970, total loss = 0.58, batch loss = 0.30 (289.5 examples/sec; 0.028 sec/batch; 1h:14m:51s remains)
INFO - root - 2022-02-24 19:41:52.677999: step 36980, total loss = 0.60, batch loss = 0.32 (223.6 examples/sec; 0.036 sec/batch; 1h:36m:55s remains)
INFO - root - 2022-02-24 19:41:52.989818: step 36990, total loss = 0.61, batch loss = 0.33 (310.5 examples/sec; 0.026 sec/batch; 1h:09m:47s remains)
INFO - root - 2022-02-24 19:41:53.386495: step 37000, total loss = 0.55, batch loss = 0.27 (171.8 examples/sec; 0.047 sec/batch; 2h:06m:07s remains)
INFO - root - 2022-02-24 19:41:53.893787: step 37010, total loss = 0.51, batch loss = 0.23 (201.3 examples/sec; 0.040 sec/batch; 1h:47m:39s remains)
INFO - root - 2022-02-24 19:41:54.271767: step 37020, total loss = 0.54, batch loss = 0.26 (165.3 examples/sec; 0.048 sec/batch; 2h:11m:03s remains)
INFO - root - 2022-02-24 19:41:54.631563: step 37030, total loss = 0.55, batch loss = 0.27 (243.2 examples/sec; 0.033 sec/batch; 1h:29m:04s remains)
INFO - root - 2022-02-24 19:41:54.943285: step 37040, total loss = 0.55, batch loss = 0.27 (349.1 examples/sec; 0.023 sec/batch; 1h:02m:02s remains)
INFO - root - 2022-02-24 19:41:55.233308: step 37050, total loss = 0.63, batch loss = 0.35 (245.9 examples/sec; 0.033 sec/batch; 1h:28m:04s remains)
INFO - root - 2022-02-24 19:41:55.713851: step 37060, total loss = 0.65, batch loss = 0.37 (154.5 examples/sec; 0.052 sec/batch; 2h:20m:09s remains)
INFO - root - 2022-02-24 19:41:56.164790: step 37070, total loss = 0.59, batch loss = 0.31 (149.8 examples/sec; 0.053 sec/batch; 2h:24m:33s remains)
INFO - root - 2022-02-24 19:41:56.577786: step 37080, total loss = 0.72, batch loss = 0.43 (206.7 examples/sec; 0.039 sec/batch; 1h:44m:46s remains)
INFO - root - 2022-02-24 19:41:56.933405: step 37090, total loss = 0.54, batch loss = 0.26 (310.3 examples/sec; 0.026 sec/batch; 1h:09m:47s remains)
INFO - root - 2022-02-24 19:41:57.310265: step 37100, total loss = 0.55, batch loss = 0.27 (176.8 examples/sec; 0.045 sec/batch; 2h:02m:27s remains)
INFO - root - 2022-02-24 19:41:57.839508: step 37110, total loss = 0.77, batch loss = 0.48 (145.8 examples/sec; 0.055 sec/batch; 2h:28m:28s remains)
INFO - root - 2022-02-24 19:41:58.292658: step 37120, total loss = 0.68, batch loss = 0.40 (308.7 examples/sec; 0.026 sec/batch; 1h:10m:08s remains)
INFO - root - 2022-02-24 19:41:58.678587: step 37130, total loss = 0.63, batch loss = 0.35 (239.6 examples/sec; 0.033 sec/batch; 1h:30m:22s remains)
INFO - root - 2022-02-24 19:41:59.053149: step 37140, total loss = 0.74, batch loss = 0.46 (322.0 examples/sec; 0.025 sec/batch; 1h:07m:14s remains)
INFO - root - 2022-02-24 19:41:59.389134: step 37150, total loss = 0.46, batch loss = 0.18 (233.1 examples/sec; 0.034 sec/batch; 1h:32m:52s remains)
INFO - root - 2022-02-24 19:41:59.823912: step 37160, total loss = 0.63, batch loss = 0.35 (145.7 examples/sec; 0.055 sec/batch; 2h:28m:31s remains)
INFO - root - 2022-02-24 19:42:00.284493: step 37170, total loss = 0.57, batch loss = 0.29 (342.6 examples/sec; 0.023 sec/batch; 1h:03m:10s remains)
INFO - root - 2022-02-24 19:42:00.629227: step 37180, total loss = 0.63, batch loss = 0.35 (192.6 examples/sec; 0.042 sec/batch; 1h:52m:20s remains)
INFO - root - 2022-02-24 19:42:00.974901: step 37190, total loss = 0.62, batch loss = 0.34 (312.8 examples/sec; 0.026 sec/batch; 1h:09m:10s remains)
INFO - root - 2022-02-24 19:42:01.350382: step 37200, total loss = 0.58, batch loss = 0.30 (255.7 examples/sec; 0.031 sec/batch; 1h:24m:38s remains)
INFO - root - 2022-02-24 19:42:01.855888: step 37210, total loss = 0.50, batch loss = 0.22 (185.9 examples/sec; 0.043 sec/batch; 1h:56m:25s remains)
INFO - root - 2022-02-24 19:42:02.247893: step 37220, total loss = 0.59, batch loss = 0.31 (106.8 examples/sec; 0.075 sec/batch; 3h:22m:31s remains)
INFO - root - 2022-02-24 19:42:02.811489: step 37230, total loss = 0.56, batch loss = 0.28 (76.4 examples/sec; 0.105 sec/batch; 4h:43m:06s remains)
INFO - root - 2022-02-24 19:42:03.620991: step 37240, total loss = 0.59, batch loss = 0.30 (59.0 examples/sec; 0.136 sec/batch; 6h:06m:45s remains)
INFO - root - 2022-02-24 19:42:04.591228: step 37250, total loss = 0.55, batch loss = 0.26 (253.2 examples/sec; 0.032 sec/batch; 1h:25m:25s remains)
INFO - root - 2022-02-24 19:42:05.085425: step 37260, total loss = 0.59, batch loss = 0.31 (309.4 examples/sec; 0.026 sec/batch; 1h:09m:55s remains)
INFO - root - 2022-02-24 19:42:05.442152: step 37270, total loss = 0.58, batch loss = 0.30 (288.2 examples/sec; 0.028 sec/batch; 1h:15m:03s remains)
INFO - root - 2022-02-24 19:42:05.801328: step 37280, total loss = 0.63, batch loss = 0.35 (212.3 examples/sec; 0.038 sec/batch; 1h:41m:54s remains)
INFO - root - 2022-02-24 19:42:06.154837: step 37290, total loss = 0.68, batch loss = 0.40 (129.8 examples/sec; 0.062 sec/batch; 2h:46m:35s remains)
INFO - root - 2022-02-24 19:42:06.724628: step 37300, total loss = 0.56, batch loss = 0.28 (203.6 examples/sec; 0.039 sec/batch; 1h:46m:14s remains)
INFO - root - 2022-02-24 19:42:07.191822: step 37310, total loss = 0.54, batch loss = 0.26 (243.1 examples/sec; 0.033 sec/batch; 1h:28m:57s remains)
INFO - root - 2022-02-24 19:42:07.580450: step 37320, total loss = 0.55, batch loss = 0.27 (138.3 examples/sec; 0.058 sec/batch; 2h:36m:21s remains)
INFO - root - 2022-02-24 19:42:07.937100: step 37330, total loss = 0.58, batch loss = 0.30 (327.2 examples/sec; 0.024 sec/batch; 1h:06m:04s remains)
INFO - root - 2022-02-24 19:42:08.349875: step 37340, total loss = 0.60, batch loss = 0.32 (336.8 examples/sec; 0.024 sec/batch; 1h:04m:12s remains)
INFO - root - 2022-02-24 19:42:08.833718: step 37350, total loss = 0.62, batch loss = 0.34 (221.2 examples/sec; 0.036 sec/batch; 1h:37m:45s remains)
INFO - root - 2022-02-24 19:42:09.342240: step 37360, total loss = 0.53, batch loss = 0.25 (319.7 examples/sec; 0.025 sec/batch; 1h:07m:37s remains)
INFO - root - 2022-02-24 19:42:09.675890: step 37370, total loss = 0.58, batch loss = 0.30 (357.0 examples/sec; 0.022 sec/batch; 1h:00m:33s remains)
INFO - root - 2022-02-24 19:42:10.025730: step 37380, total loss = 0.66, batch loss = 0.38 (233.3 examples/sec; 0.034 sec/batch; 1h:32m:39s remains)
INFO - root - 2022-02-24 19:42:10.469103: step 37390, total loss = 0.57, batch loss = 0.29 (312.9 examples/sec; 0.026 sec/batch; 1h:09m:04s remains)
INFO - root - 2022-02-24 19:42:10.906329: step 37400, total loss = 0.55, batch loss = 0.27 (198.0 examples/sec; 0.040 sec/batch; 1h:49m:08s remains)
INFO - root - 2022-02-24 19:42:11.336774: step 37410, total loss = 0.51, batch loss = 0.23 (322.3 examples/sec; 0.025 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 19:42:11.739478: step 37420, total loss = 0.45, batch loss = 0.16 (159.9 examples/sec; 0.050 sec/batch; 2h:15m:07s remains)
INFO - root - 2022-02-24 19:42:12.077656: step 37430, total loss = 0.56, batch loss = 0.28 (172.1 examples/sec; 0.046 sec/batch; 2h:05m:33s remains)
INFO - root - 2022-02-24 19:42:12.416945: step 37440, total loss = 0.62, batch loss = 0.34 (122.1 examples/sec; 0.066 sec/batch; 2h:57m:00s remains)
INFO - root - 2022-02-24 19:42:12.797949: step 37450, total loss = 0.51, batch loss = 0.22 (374.6 examples/sec; 0.021 sec/batch; 0h:57m:40s remains)
INFO - root - 2022-02-24 19:42:13.234466: step 37460, total loss = 0.57, batch loss = 0.29 (369.7 examples/sec; 0.022 sec/batch; 0h:58m:26s remains)
INFO - root - 2022-02-24 19:42:13.662227: step 37470, total loss = 0.56, batch loss = 0.28 (148.9 examples/sec; 0.054 sec/batch; 2h:25m:04s remains)
INFO - root - 2022-02-24 19:42:13.987433: step 37480, total loss = 0.69, batch loss = 0.41 (122.1 examples/sec; 0.066 sec/batch; 2h:56m:55s remains)
INFO - root - 2022-02-24 19:42:14.451429: step 37490, total loss = 0.63, batch loss = 0.35 (80.2 examples/sec; 0.100 sec/batch; 4h:29m:22s remains)
INFO - root - 2022-02-24 19:42:14.788244: step 37500, total loss = 0.59, batch loss = 0.31 (125.0 examples/sec; 0.064 sec/batch; 2h:52m:51s remains)
INFO - root - 2022-02-24 19:42:15.411755: step 37510, total loss = 0.57, batch loss = 0.29 (79.7 examples/sec; 0.100 sec/batch; 4h:30m:57s remains)
INFO - root - 2022-02-24 19:42:15.881135: step 37520, total loss = 0.60, batch loss = 0.32 (205.7 examples/sec; 0.039 sec/batch; 1h:44m:58s remains)
INFO - root - 2022-02-24 19:42:16.325138: step 37530, total loss = 0.57, batch loss = 0.29 (137.8 examples/sec; 0.058 sec/batch; 2h:36m:40s remains)
INFO - root - 2022-02-24 19:42:16.714762: step 37540, total loss = 0.65, batch loss = 0.37 (212.8 examples/sec; 0.038 sec/batch; 1h:41m:29s remains)
INFO - root - 2022-02-24 19:42:17.165687: step 37550, total loss = 0.62, batch loss = 0.33 (301.1 examples/sec; 0.027 sec/batch; 1h:11m:42s remains)
INFO - root - 2022-02-24 19:42:17.674346: step 37560, total loss = 0.73, batch loss = 0.45 (222.6 examples/sec; 0.036 sec/batch; 1h:36m:59s remains)
INFO - root - 2022-02-24 19:42:18.054055: step 37570, total loss = 0.62, batch loss = 0.33 (161.8 examples/sec; 0.049 sec/batch; 2h:13m:26s remains)
INFO - root - 2022-02-24 19:42:18.356997: step 37580, total loss = 0.62, batch loss = 0.34 (175.8 examples/sec; 0.046 sec/batch; 2h:02m:48s remains)
INFO - root - 2022-02-24 19:42:18.720692: step 37590, total loss = 0.56, batch loss = 0.28 (244.2 examples/sec; 0.033 sec/batch; 1h:28m:24s remains)
INFO - root - 2022-02-24 19:42:19.157955: step 37600, total loss = 0.69, batch loss = 0.41 (93.6 examples/sec; 0.086 sec/batch; 3h:50m:44s remains)
INFO - root - 2022-02-24 19:42:19.648193: step 37610, total loss = 0.55, batch loss = 0.27 (239.9 examples/sec; 0.033 sec/batch; 1h:29m:58s remains)
INFO - root - 2022-02-24 19:42:20.053554: step 37620, total loss = 0.49, batch loss = 0.21 (170.2 examples/sec; 0.047 sec/batch; 2h:06m:49s remains)
INFO - root - 2022-02-24 19:42:20.486634: step 37630, total loss = 0.65, batch loss = 0.37 (228.3 examples/sec; 0.035 sec/batch; 1h:34m:32s remains)
INFO - root - 2022-02-24 19:42:20.820529: step 37640, total loss = 0.63, batch loss = 0.35 (286.3 examples/sec; 0.028 sec/batch; 1h:15m:22s remains)
INFO - root - 2022-02-24 19:42:21.217526: step 37650, total loss = 0.52, batch loss = 0.24 (159.4 examples/sec; 0.050 sec/batch; 2h:15m:23s remains)
INFO - root - 2022-02-24 19:42:21.739854: step 37660, total loss = 0.49, batch loss = 0.21 (222.6 examples/sec; 0.036 sec/batch; 1h:36m:56s remains)
INFO - root - 2022-02-24 19:42:22.128986: step 37670, total loss = 0.56, batch loss = 0.28 (183.8 examples/sec; 0.044 sec/batch; 1h:57m:23s remains)
INFO - root - 2022-02-24 19:42:22.544373: step 37680, total loss = 0.64, batch loss = 0.35 (226.5 examples/sec; 0.035 sec/batch; 1h:35m:15s remains)
INFO - root - 2022-02-24 19:42:22.912721: step 37690, total loss = 0.71, batch loss = 0.43 (326.6 examples/sec; 0.024 sec/batch; 1h:06m:03s remains)
INFO - root - 2022-02-24 19:42:23.242742: step 37700, total loss = 0.66, batch loss = 0.38 (237.1 examples/sec; 0.034 sec/batch; 1h:30m:58s remains)
INFO - root - 2022-02-24 19:42:23.762442: step 37710, total loss = 0.72, batch loss = 0.44 (363.0 examples/sec; 0.022 sec/batch; 0h:59m:25s remains)
INFO - root - 2022-02-24 19:42:24.113700: step 37720, total loss = 0.64, batch loss = 0.36 (348.4 examples/sec; 0.023 sec/batch; 1h:01m:54s remains)
INFO - root - 2022-02-24 19:42:24.477157: step 37730, total loss = 0.61, batch loss = 0.32 (172.5 examples/sec; 0.046 sec/batch; 2h:05m:03s remains)
INFO - root - 2022-02-24 19:42:24.887276: step 37740, total loss = 0.58, batch loss = 0.30 (109.2 examples/sec; 0.073 sec/batch; 3h:17m:29s remains)
INFO - root - 2022-02-24 19:42:25.347187: step 37750, total loss = 0.52, batch loss = 0.24 (243.3 examples/sec; 0.033 sec/batch; 1h:28m:38s remains)
INFO - root - 2022-02-24 19:42:26.034601: step 37760, total loss = 0.65, batch loss = 0.37 (216.9 examples/sec; 0.037 sec/batch; 1h:39m:25s remains)
INFO - root - 2022-02-24 19:42:26.951974: step 37770, total loss = 0.54, batch loss = 0.26 (279.3 examples/sec; 0.029 sec/batch; 1h:17m:13s remains)
INFO - root - 2022-02-24 19:42:27.383262: step 37780, total loss = 0.66, batch loss = 0.38 (292.4 examples/sec; 0.027 sec/batch; 1h:13m:44s remains)
INFO - root - 2022-02-24 19:42:27.731752: step 37790, total loss = 0.54, batch loss = 0.26 (147.0 examples/sec; 0.054 sec/batch; 2h:26m:41s remains)
INFO - root - 2022-02-24 19:42:28.096385: step 37800, total loss = 0.68, batch loss = 0.40 (183.6 examples/sec; 0.044 sec/batch; 1h:57m:24s remains)
INFO - root - 2022-02-24 19:42:29.638245: step 37810, total loss = 0.51, batch loss = 0.23 (290.3 examples/sec; 0.028 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 19:42:29.892431: step 37820, total loss = 0.63, batch loss = 0.35 (262.5 examples/sec; 0.030 sec/batch; 1h:22m:07s remains)
INFO - root - 2022-02-24 19:42:30.128484: step 37830, total loss = 0.49, batch loss = 0.21 (356.8 examples/sec; 0.022 sec/batch; 1h:00m:24s remains)
INFO - root - 2022-02-24 19:42:30.491875: step 37840, total loss = 0.55, batch loss = 0.27 (244.2 examples/sec; 0.033 sec/batch; 1h:28m:16s remains)
INFO - root - 2022-02-24 19:42:30.995920: step 37850, total loss = 0.58, batch loss = 0.30 (321.6 examples/sec; 0.025 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 19:42:31.842219: step 37860, total loss = 0.47, batch loss = 0.19 (139.2 examples/sec; 0.057 sec/batch; 2h:34m:48s remains)
INFO - root - 2022-02-24 19:42:32.328072: step 37870, total loss = 0.65, batch loss = 0.37 (255.8 examples/sec; 0.031 sec/batch; 1h:24m:15s remains)
INFO - root - 2022-02-24 19:42:32.706140: step 37880, total loss = 0.61, batch loss = 0.33 (175.2 examples/sec; 0.046 sec/batch; 2h:03m:01s remains)
INFO - root - 2022-02-24 19:42:33.095398: step 37890, total loss = 0.64, batch loss = 0.36 (185.9 examples/sec; 0.043 sec/batch; 1h:55m:56s remains)
INFO - root - 2022-02-24 19:42:33.527242: step 37900, total loss = 0.69, batch loss = 0.40 (348.1 examples/sec; 0.023 sec/batch; 1h:01m:53s remains)
INFO - root - 2022-02-24 19:42:34.059357: step 37910, total loss = 0.57, batch loss = 0.29 (189.1 examples/sec; 0.042 sec/batch; 1h:53m:54s remains)
INFO - root - 2022-02-24 19:42:34.459065: step 37920, total loss = 0.53, batch loss = 0.25 (320.7 examples/sec; 0.025 sec/batch; 1h:07m:11s remains)
INFO - root - 2022-02-24 19:42:34.777695: step 37930, total loss = 0.58, batch loss = 0.30 (357.2 examples/sec; 0.022 sec/batch; 1h:00m:18s remains)
INFO - root - 2022-02-24 19:42:35.105880: step 37940, total loss = 0.56, batch loss = 0.28 (346.5 examples/sec; 0.023 sec/batch; 1h:02m:10s remains)
INFO - root - 2022-02-24 19:42:35.458583: step 37950, total loss = 0.76, batch loss = 0.48 (281.7 examples/sec; 0.028 sec/batch; 1h:16m:28s remains)
INFO - root - 2022-02-24 19:42:35.898139: step 37960, total loss = 0.73, batch loss = 0.45 (187.6 examples/sec; 0.043 sec/batch; 1h:54m:50s remains)
INFO - root - 2022-02-24 19:42:36.315530: step 37970, total loss = 0.54, batch loss = 0.26 (242.9 examples/sec; 0.033 sec/batch; 1h:28m:40s remains)
INFO - root - 2022-02-24 19:42:36.639976: step 37980, total loss = 0.63, batch loss = 0.35 (321.9 examples/sec; 0.025 sec/batch; 1h:06m:53s remains)
INFO - root - 2022-02-24 19:42:36.978524: step 37990, total loss = 0.62, batch loss = 0.34 (344.7 examples/sec; 0.023 sec/batch; 1h:02m:27s remains)
INFO - root - 2022-02-24 19:42:37.324723: step 38000, total loss = 0.60, batch loss = 0.32 (220.4 examples/sec; 0.036 sec/batch; 1h:37m:42s remains)
INFO - root - 2022-02-24 19:42:37.917801: step 38010, total loss = 0.69, batch loss = 0.41 (178.2 examples/sec; 0.045 sec/batch; 2h:00m:47s remains)
INFO - root - 2022-02-24 19:42:38.519490: step 38020, total loss = 0.58, batch loss = 0.30 (171.4 examples/sec; 0.047 sec/batch; 2h:05m:37s remains)
INFO - root - 2022-02-24 19:42:38.818144: step 38030, total loss = 0.62, batch loss = 0.34 (304.1 examples/sec; 0.026 sec/batch; 1h:10m:47s remains)
INFO - root - 2022-02-24 19:42:39.159888: step 38040, total loss = 0.55, batch loss = 0.27 (353.3 examples/sec; 0.023 sec/batch; 1h:00m:55s remains)
INFO - root - 2022-02-24 19:42:39.530723: step 38050, total loss = 0.65, batch loss = 0.37 (311.0 examples/sec; 0.026 sec/batch; 1h:09m:13s remains)
INFO - root - 2022-02-24 19:42:39.910046: step 38060, total loss = 0.61, batch loss = 0.33 (161.7 examples/sec; 0.049 sec/batch; 2h:13m:05s remains)
INFO - root - 2022-02-24 19:42:40.381807: step 38070, total loss = 0.58, batch loss = 0.30 (234.4 examples/sec; 0.034 sec/batch; 1h:31m:49s remains)
INFO - root - 2022-02-24 19:42:40.727670: step 38080, total loss = 0.65, batch loss = 0.37 (384.0 examples/sec; 0.021 sec/batch; 0h:56m:02s remains)
INFO - root - 2022-02-24 19:42:41.078908: step 38090, total loss = 0.64, batch loss = 0.36 (245.0 examples/sec; 0.033 sec/batch; 1h:27m:50s remains)
INFO - root - 2022-02-24 19:42:41.368477: step 38100, total loss = 0.71, batch loss = 0.43 (280.7 examples/sec; 0.029 sec/batch; 1h:16m:40s remains)
INFO - root - 2022-02-24 19:42:41.874959: step 38110, total loss = 0.64, batch loss = 0.36 (120.0 examples/sec; 0.067 sec/batch; 2h:59m:20s remains)
INFO - root - 2022-02-24 19:42:42.330590: step 38120, total loss = 0.55, batch loss = 0.27 (152.9 examples/sec; 0.052 sec/batch; 2h:20m:42s remains)
INFO - root - 2022-02-24 19:42:42.750490: step 38130, total loss = 0.63, batch loss = 0.35 (311.3 examples/sec; 0.026 sec/batch; 1h:09m:07s remains)
INFO - root - 2022-02-24 19:42:43.196870: step 38140, total loss = 0.80, batch loss = 0.52 (231.8 examples/sec; 0.035 sec/batch; 1h:32m:49s remains)
INFO - root - 2022-02-24 19:42:43.782199: step 38150, total loss = 0.56, batch loss = 0.28 (272.7 examples/sec; 0.029 sec/batch; 1h:18m:53s remains)
INFO - root - 2022-02-24 19:42:44.477972: step 38160, total loss = 0.57, batch loss = 0.29 (202.1 examples/sec; 0.040 sec/batch; 1h:46m:26s remains)
INFO - root - 2022-02-24 19:42:44.892545: step 38170, total loss = 0.60, batch loss = 0.32 (302.0 examples/sec; 0.026 sec/batch; 1h:11m:13s remains)
INFO - root - 2022-02-24 19:42:45.496635: step 38180, total loss = 0.48, batch loss = 0.20 (105.7 examples/sec; 0.076 sec/batch; 3h:23m:29s remains)
INFO - root - 2022-02-24 19:42:46.205577: step 38190, total loss = 0.63, batch loss = 0.35 (311.4 examples/sec; 0.026 sec/batch; 1h:09m:03s remains)
INFO - root - 2022-02-24 19:42:46.652857: step 38200, total loss = 0.60, batch loss = 0.32 (170.5 examples/sec; 0.047 sec/batch; 2h:06m:08s remains)
INFO - root - 2022-02-24 19:42:47.550152: step 38210, total loss = 0.60, batch loss = 0.32 (196.0 examples/sec; 0.041 sec/batch; 1h:49m:44s remains)
INFO - root - 2022-02-24 19:42:47.896290: step 38220, total loss = 0.51, batch loss = 0.23 (318.4 examples/sec; 0.025 sec/batch; 1h:07m:32s remains)
INFO - root - 2022-02-24 19:42:48.183464: step 38230, total loss = 0.54, batch loss = 0.26 (341.6 examples/sec; 0.023 sec/batch; 1h:02m:56s remains)
INFO - root - 2022-02-24 19:42:48.574894: step 38240, total loss = 0.49, batch loss = 0.21 (151.0 examples/sec; 0.053 sec/batch; 2h:22m:20s remains)
INFO - root - 2022-02-24 19:42:48.940040: step 38250, total loss = 0.64, batch loss = 0.36 (241.1 examples/sec; 0.033 sec/batch; 1h:29m:10s remains)
INFO - root - 2022-02-24 19:42:49.467373: step 38260, total loss = 0.60, batch loss = 0.32 (272.3 examples/sec; 0.029 sec/batch; 1h:18m:57s remains)
INFO - root - 2022-02-24 19:42:49.898164: step 38270, total loss = 0.62, batch loss = 0.33 (256.4 examples/sec; 0.031 sec/batch; 1h:23m:50s remains)
INFO - root - 2022-02-24 19:42:50.265679: step 38280, total loss = 0.60, batch loss = 0.32 (171.2 examples/sec; 0.047 sec/batch; 2h:05m:35s remains)
INFO - root - 2022-02-24 19:42:50.539217: step 38290, total loss = 0.66, batch loss = 0.38 (291.3 examples/sec; 0.027 sec/batch; 1h:13m:46s remains)
INFO - root - 2022-02-24 19:42:50.898731: step 38300, total loss = 0.61, batch loss = 0.33 (354.3 examples/sec; 0.023 sec/batch; 1h:00m:40s remains)
INFO - root - 2022-02-24 19:42:51.514517: step 38310, total loss = 0.50, batch loss = 0.22 (117.4 examples/sec; 0.068 sec/batch; 3h:03m:07s remains)
INFO - root - 2022-02-24 19:42:52.099866: step 38320, total loss = 0.60, batch loss = 0.32 (200.4 examples/sec; 0.040 sec/batch; 1h:47m:14s remains)
INFO - root - 2022-02-24 19:42:52.462525: step 38330, total loss = 0.55, batch loss = 0.27 (153.7 examples/sec; 0.052 sec/batch; 2h:19m:46s remains)
INFO - root - 2022-02-24 19:42:52.797482: step 38340, total loss = 0.56, batch loss = 0.27 (336.2 examples/sec; 0.024 sec/batch; 1h:03m:54s remains)
INFO - root - 2022-02-24 19:42:53.084927: step 38350, total loss = 0.57, batch loss = 0.29 (326.0 examples/sec; 0.025 sec/batch; 1h:05m:55s remains)
INFO - root - 2022-02-24 19:42:53.461144: step 38360, total loss = 0.64, batch loss = 0.36 (91.3 examples/sec; 0.088 sec/batch; 3h:55m:21s remains)
INFO - root - 2022-02-24 19:42:53.926925: step 38370, total loss = 0.72, batch loss = 0.44 (357.7 examples/sec; 0.022 sec/batch; 1h:00m:04s remains)
INFO - root - 2022-02-24 19:42:54.276786: step 38380, total loss = 0.69, batch loss = 0.41 (304.1 examples/sec; 0.026 sec/batch; 1h:10m:38s remains)
INFO - root - 2022-02-24 19:42:54.597909: step 38390, total loss = 0.58, batch loss = 0.30 (158.5 examples/sec; 0.050 sec/batch; 2h:15m:33s remains)
INFO - root - 2022-02-24 19:42:54.918514: step 38400, total loss = 0.54, batch loss = 0.26 (314.3 examples/sec; 0.025 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 19:42:55.312491: step 38410, total loss = 0.56, batch loss = 0.28 (342.2 examples/sec; 0.023 sec/batch; 1h:02m:45s remains)
INFO - root - 2022-02-24 19:42:55.843222: step 38420, total loss = 0.62, batch loss = 0.34 (95.7 examples/sec; 0.084 sec/batch; 3h:44m:21s remains)
INFO - root - 2022-02-24 19:42:56.253539: step 38430, total loss = 0.59, batch loss = 0.31 (259.2 examples/sec; 0.031 sec/batch; 1h:22m:51s remains)
INFO - root - 2022-02-24 19:42:56.608445: step 38440, total loss = 0.52, batch loss = 0.24 (213.8 examples/sec; 0.037 sec/batch; 1h:40m:25s remains)
INFO - root - 2022-02-24 19:42:56.936241: step 38450, total loss = 0.52, batch loss = 0.24 (308.2 examples/sec; 0.026 sec/batch; 1h:09m:39s remains)
INFO - root - 2022-02-24 19:42:57.260763: step 38460, total loss = 0.59, batch loss = 0.31 (253.5 examples/sec; 0.032 sec/batch; 1h:24m:41s remains)
INFO - root - 2022-02-24 19:42:57.735218: step 38470, total loss = 0.62, batch loss = 0.34 (109.0 examples/sec; 0.073 sec/batch; 3h:16m:57s remains)
INFO - root - 2022-02-24 19:42:58.260938: step 38480, total loss = 0.57, batch loss = 0.29 (201.7 examples/sec; 0.040 sec/batch; 1h:46m:27s remains)
INFO - root - 2022-02-24 19:42:58.591535: step 38490, total loss = 0.53, batch loss = 0.25 (242.6 examples/sec; 0.033 sec/batch; 1h:28m:28s remains)
INFO - root - 2022-02-24 19:42:58.953126: step 38500, total loss = 0.61, batch loss = 0.33 (354.5 examples/sec; 0.023 sec/batch; 1h:00m:33s remains)
INFO - root - 2022-02-24 19:42:59.471803: step 38510, total loss = 0.68, batch loss = 0.40 (237.8 examples/sec; 0.034 sec/batch; 1h:30m:16s remains)
INFO - root - 2022-02-24 19:42:59.994721: step 38520, total loss = 0.54, batch loss = 0.26 (102.8 examples/sec; 0.078 sec/batch; 3h:28m:43s remains)
INFO - root - 2022-02-24 19:43:00.407196: step 38530, total loss = 0.60, batch loss = 0.32 (205.5 examples/sec; 0.039 sec/batch; 1h:44m:25s remains)
INFO - root - 2022-02-24 19:43:00.765227: step 38540, total loss = 0.66, batch loss = 0.38 (153.3 examples/sec; 0.052 sec/batch; 2h:19m:57s remains)
INFO - root - 2022-02-24 19:43:01.160023: step 38550, total loss = 0.59, batch loss = 0.31 (255.5 examples/sec; 0.031 sec/batch; 1h:23m:59s remains)
INFO - root - 2022-02-24 19:43:01.718107: step 38560, total loss = 0.54, batch loss = 0.26 (98.1 examples/sec; 0.082 sec/batch; 3h:38m:41s remains)
INFO - root - 2022-02-24 19:43:02.733168: step 38570, total loss = 0.58, batch loss = 0.30 (335.5 examples/sec; 0.024 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 19:43:03.144071: step 38580, total loss = 0.69, batch loss = 0.41 (335.9 examples/sec; 0.024 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 19:43:03.499738: step 38590, total loss = 0.62, batch loss = 0.34 (311.1 examples/sec; 0.026 sec/batch; 1h:08m:57s remains)
INFO - root - 2022-02-24 19:43:03.877451: step 38600, total loss = 0.59, batch loss = 0.31 (296.3 examples/sec; 0.027 sec/batch; 1h:12m:24s remains)
INFO - root - 2022-02-24 19:43:04.767553: step 38610, total loss = 0.70, batch loss = 0.42 (238.1 examples/sec; 0.034 sec/batch; 1h:30m:06s remains)
INFO - root - 2022-02-24 19:43:05.109744: step 38620, total loss = 0.54, batch loss = 0.26 (347.8 examples/sec; 0.023 sec/batch; 1h:01m:40s remains)
INFO - root - 2022-02-24 19:43:05.605773: step 38630, total loss = 0.63, batch loss = 0.35 (222.1 examples/sec; 0.036 sec/batch; 1h:36m:35s remains)
INFO - root - 2022-02-24 19:43:06.057226: step 38640, total loss = 0.57, batch loss = 0.29 (235.5 examples/sec; 0.034 sec/batch; 1h:31m:04s remains)
INFO - root - 2022-02-24 19:43:06.526183: step 38650, total loss = 0.59, batch loss = 0.31 (273.2 examples/sec; 0.029 sec/batch; 1h:18m:29s remains)
INFO - root - 2022-02-24 19:43:06.846453: step 38660, total loss = 0.57, batch loss = 0.29 (254.6 examples/sec; 0.031 sec/batch; 1h:24m:13s remains)
INFO - root - 2022-02-24 19:43:07.303674: step 38670, total loss = 0.63, batch loss = 0.35 (256.8 examples/sec; 0.031 sec/batch; 1h:23m:30s remains)
INFO - root - 2022-02-24 19:43:07.675329: step 38680, total loss = 0.60, batch loss = 0.31 (226.8 examples/sec; 0.035 sec/batch; 1h:34m:32s remains)
INFO - root - 2022-02-24 19:43:08.124849: step 38690, total loss = 0.74, batch loss = 0.46 (98.7 examples/sec; 0.081 sec/batch; 3h:37m:10s remains)
INFO - root - 2022-02-24 19:43:08.536444: step 38700, total loss = 0.52, batch loss = 0.24 (258.0 examples/sec; 0.031 sec/batch; 1h:23m:06s remains)
INFO - root - 2022-02-24 19:43:09.011510: step 38710, total loss = 0.66, batch loss = 0.38 (280.9 examples/sec; 0.028 sec/batch; 1h:16m:18s remains)
INFO - root - 2022-02-24 19:43:09.415354: step 38720, total loss = 0.59, batch loss = 0.31 (336.9 examples/sec; 0.024 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 19:43:09.710465: step 38730, total loss = 0.57, batch loss = 0.29 (291.3 examples/sec; 0.027 sec/batch; 1h:13m:35s remains)
INFO - root - 2022-02-24 19:43:10.087333: step 38740, total loss = 0.60, batch loss = 0.32 (223.8 examples/sec; 0.036 sec/batch; 1h:35m:47s remains)
INFO - root - 2022-02-24 19:43:10.532975: step 38750, total loss = 0.53, batch loss = 0.25 (104.6 examples/sec; 0.076 sec/batch; 3h:24m:53s remains)
INFO - root - 2022-02-24 19:43:10.939149: step 38760, total loss = 0.52, batch loss = 0.24 (171.6 examples/sec; 0.047 sec/batch; 2h:04m:55s remains)
INFO - root - 2022-02-24 19:43:11.433841: step 38770, total loss = 0.66, batch loss = 0.38 (160.9 examples/sec; 0.050 sec/batch; 2h:13m:10s remains)
INFO - root - 2022-02-24 19:43:11.801675: step 38780, total loss = 0.61, batch loss = 0.33 (176.6 examples/sec; 0.045 sec/batch; 2h:01m:19s remains)
INFO - root - 2022-02-24 19:43:12.122378: step 38790, total loss = 0.73, batch loss = 0.45 (250.9 examples/sec; 0.032 sec/batch; 1h:25m:24s remains)
INFO - root - 2022-02-24 19:43:12.586212: step 38800, total loss = 0.56, batch loss = 0.28 (177.5 examples/sec; 0.045 sec/batch; 2h:00m:42s remains)
INFO - root - 2022-02-24 19:43:13.073874: step 38810, total loss = 0.64, batch loss = 0.36 (197.5 examples/sec; 0.041 sec/batch; 1h:48m:30s remains)
INFO - root - 2022-02-24 19:43:13.393724: step 38820, total loss = 0.57, batch loss = 0.29 (281.8 examples/sec; 0.028 sec/batch; 1h:16m:02s remains)
INFO - root - 2022-02-24 19:43:13.742072: step 38830, total loss = 0.59, batch loss = 0.31 (243.8 examples/sec; 0.033 sec/batch; 1h:27m:52s remains)
INFO - root - 2022-02-24 19:43:14.046311: step 38840, total loss = 0.61, batch loss = 0.33 (259.7 examples/sec; 0.031 sec/batch; 1h:22m:28s remains)
INFO - root - 2022-02-24 19:43:14.494661: step 38850, total loss = 0.60, batch loss = 0.32 (116.4 examples/sec; 0.069 sec/batch; 3h:03m:57s remains)
INFO - root - 2022-02-24 19:43:14.996652: step 38860, total loss = 0.50, batch loss = 0.22 (245.1 examples/sec; 0.033 sec/batch; 1h:27m:22s remains)
INFO - root - 2022-02-24 19:43:15.370259: step 38870, total loss = 0.61, batch loss = 0.33 (260.5 examples/sec; 0.031 sec/batch; 1h:22m:13s remains)
INFO - root - 2022-02-24 19:43:15.728893: step 38880, total loss = 0.61, batch loss = 0.33 (327.3 examples/sec; 0.024 sec/batch; 1h:05m:26s remains)
INFO - root - 2022-02-24 19:43:16.029349: step 38890, total loss = 0.52, batch loss = 0.24 (367.2 examples/sec; 0.022 sec/batch; 0h:58m:18s remains)
INFO - root - 2022-02-24 19:43:16.381193: step 38900, total loss = 0.54, batch loss = 0.26 (142.0 examples/sec; 0.056 sec/batch; 2h:30m:47s remains)
INFO - root - 2022-02-24 19:43:16.780508: step 38910, total loss = 0.72, batch loss = 0.44 (347.2 examples/sec; 0.023 sec/batch; 1h:01m:40s remains)
INFO - root - 2022-02-24 19:43:17.152521: step 38920, total loss = 0.63, batch loss = 0.35 (365.4 examples/sec; 0.022 sec/batch; 0h:58m:35s remains)
INFO - root - 2022-02-24 19:43:17.663554: step 38930, total loss = 0.57, batch loss = 0.29 (231.4 examples/sec; 0.035 sec/batch; 1h:32m:31s remains)
INFO - root - 2022-02-24 19:43:18.048676: step 38940, total loss = 0.55, batch loss = 0.27 (179.9 examples/sec; 0.044 sec/batch; 1h:59m:00s remains)
INFO - root - 2022-02-24 19:43:18.414255: step 38950, total loss = 0.51, batch loss = 0.23 (297.3 examples/sec; 0.027 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 19:43:18.778015: step 38960, total loss = 0.64, batch loss = 0.36 (304.6 examples/sec; 0.026 sec/batch; 1h:10m:16s remains)
INFO - root - 2022-02-24 19:43:19.221281: step 38970, total loss = 0.64, batch loss = 0.36 (126.7 examples/sec; 0.063 sec/batch; 2h:48m:57s remains)
INFO - root - 2022-02-24 19:43:19.587227: step 38980, total loss = 0.63, batch loss = 0.35 (165.2 examples/sec; 0.048 sec/batch; 2h:09m:32s remains)
INFO - root - 2022-02-24 19:43:20.087553: step 38990, total loss = 0.60, batch loss = 0.32 (97.7 examples/sec; 0.082 sec/batch; 3h:39m:03s remains)
INFO - root - 2022-02-24 19:43:20.601875: step 39000, total loss = 0.57, batch loss = 0.29 (85.7 examples/sec; 0.093 sec/batch; 4h:09m:45s remains)
INFO - root - 2022-02-24 19:43:21.290111: step 39010, total loss = 0.61, batch loss = 0.33 (315.1 examples/sec; 0.025 sec/batch; 1h:07m:54s remains)
INFO - root - 2022-02-24 19:43:21.729433: step 39020, total loss = 0.68, batch loss = 0.40 (237.2 examples/sec; 0.034 sec/batch; 1h:30m:13s remains)
INFO - root - 2022-02-24 19:43:22.102556: step 39030, total loss = 0.69, batch loss = 0.41 (316.4 examples/sec; 0.025 sec/batch; 1h:07m:36s remains)
INFO - root - 2022-02-24 19:43:23.016730: step 39040, total loss = 0.55, batch loss = 0.27 (331.5 examples/sec; 0.024 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 19:43:23.371263: step 39050, total loss = 0.62, batch loss = 0.34 (327.3 examples/sec; 0.024 sec/batch; 1h:05m:22s remains)
INFO - root - 2022-02-24 19:43:23.749940: step 39060, total loss = 0.54, batch loss = 0.26 (282.7 examples/sec; 0.028 sec/batch; 1h:15m:39s remains)
INFO - root - 2022-02-24 19:43:24.175893: step 39070, total loss = 0.55, batch loss = 0.27 (286.2 examples/sec; 0.028 sec/batch; 1h:14m:44s remains)
INFO - root - 2022-02-24 19:43:24.682017: step 39080, total loss = 0.51, batch loss = 0.23 (172.4 examples/sec; 0.046 sec/batch; 2h:04m:04s remains)
INFO - root - 2022-02-24 19:43:25.171665: step 39090, total loss = 0.53, batch loss = 0.25 (171.9 examples/sec; 0.047 sec/batch; 2h:04m:26s remains)
INFO - root - 2022-02-24 19:43:25.490051: step 39100, total loss = 0.59, batch loss = 0.31 (314.3 examples/sec; 0.025 sec/batch; 1h:08m:02s remains)
INFO - root - 2022-02-24 19:43:25.920168: step 39110, total loss = 0.56, batch loss = 0.28 (319.1 examples/sec; 0.025 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 19:43:26.440385: step 39120, total loss = 0.61, batch loss = 0.33 (163.5 examples/sec; 0.049 sec/batch; 2h:10m:46s remains)
INFO - root - 2022-02-24 19:43:26.926332: step 39130, total loss = 0.50, batch loss = 0.22 (151.1 examples/sec; 0.053 sec/batch; 2h:21m:29s remains)
INFO - root - 2022-02-24 19:43:27.578252: step 39140, total loss = 0.60, batch loss = 0.32 (341.4 examples/sec; 0.023 sec/batch; 1h:02m:37s remains)
INFO - root - 2022-02-24 19:43:27.863606: step 39150, total loss = 0.73, batch loss = 0.45 (349.5 examples/sec; 0.023 sec/batch; 1h:01m:10s remains)
INFO - root - 2022-02-24 19:43:28.211774: step 39160, total loss = 0.47, batch loss = 0.19 (118.9 examples/sec; 0.067 sec/batch; 2h:59m:52s remains)
INFO - root - 2022-02-24 19:43:28.695960: step 39170, total loss = 0.69, batch loss = 0.41 (110.4 examples/sec; 0.072 sec/batch; 3h:13m:35s remains)
INFO - root - 2022-02-24 19:43:29.211652: step 39180, total loss = 0.52, batch loss = 0.24 (344.9 examples/sec; 0.023 sec/batch; 1h:01m:58s remains)
INFO - root - 2022-02-24 19:43:29.643032: step 39190, total loss = 0.52, batch loss = 0.24 (137.4 examples/sec; 0.058 sec/batch; 2h:35m:33s remains)
INFO - root - 2022-02-24 19:43:29.989866: step 39200, total loss = 0.61, batch loss = 0.33 (187.5 examples/sec; 0.043 sec/batch; 1h:54m:00s remains)
INFO - root - 2022-02-24 19:43:30.456555: step 39210, total loss = 0.54, batch loss = 0.26 (262.0 examples/sec; 0.031 sec/batch; 1h:21m:34s remains)
INFO - root - 2022-02-24 19:43:30.883243: step 39220, total loss = 0.54, batch loss = 0.26 (362.8 examples/sec; 0.022 sec/batch; 0h:58m:54s remains)
INFO - root - 2022-02-24 19:43:31.370970: step 39230, total loss = 0.69, batch loss = 0.41 (210.4 examples/sec; 0.038 sec/batch; 1h:41m:34s remains)
INFO - root - 2022-02-24 19:43:31.748567: step 39240, total loss = 0.60, batch loss = 0.32 (282.7 examples/sec; 0.028 sec/batch; 1h:15m:35s remains)
INFO - root - 2022-02-24 19:43:32.090775: step 39250, total loss = 0.51, batch loss = 0.23 (143.6 examples/sec; 0.056 sec/batch; 2h:28m:50s remains)
INFO - root - 2022-02-24 19:43:32.381658: step 39260, total loss = 0.52, batch loss = 0.24 (240.7 examples/sec; 0.033 sec/batch; 1h:28m:46s remains)
INFO - root - 2022-02-24 19:43:32.827428: step 39270, total loss = 0.69, batch loss = 0.41 (298.3 examples/sec; 0.027 sec/batch; 1h:11m:36s remains)
INFO - root - 2022-02-24 19:43:33.323202: step 39280, total loss = 0.64, batch loss = 0.36 (87.8 examples/sec; 0.091 sec/batch; 4h:03m:24s remains)
INFO - root - 2022-02-24 19:43:33.768740: step 39290, total loss = 0.56, batch loss = 0.28 (374.2 examples/sec; 0.021 sec/batch; 0h:57m:05s remains)
INFO - root - 2022-02-24 19:43:34.120061: step 39300, total loss = 0.56, batch loss = 0.28 (327.4 examples/sec; 0.024 sec/batch; 1h:05m:13s remains)
INFO - root - 2022-02-24 19:43:34.597429: step 39310, total loss = 0.59, batch loss = 0.31 (207.3 examples/sec; 0.039 sec/batch; 1h:43m:00s remains)
INFO - root - 2022-02-24 19:43:34.947084: step 39320, total loss = 0.71, batch loss = 0.43 (284.9 examples/sec; 0.028 sec/batch; 1h:14m:58s remains)
INFO - root - 2022-02-24 19:43:35.398576: step 39330, total loss = 0.55, batch loss = 0.27 (112.2 examples/sec; 0.071 sec/batch; 3h:10m:18s remains)
INFO - root - 2022-02-24 19:43:35.798860: step 39340, total loss = 0.64, batch loss = 0.36 (104.4 examples/sec; 0.077 sec/batch; 3h:24m:33s remains)
INFO - root - 2022-02-24 19:43:36.156361: step 39350, total loss = 0.58, batch loss = 0.30 (123.6 examples/sec; 0.065 sec/batch; 2h:52m:46s remains)
INFO - root - 2022-02-24 19:43:36.625968: step 39360, total loss = 0.51, batch loss = 0.23 (90.0 examples/sec; 0.089 sec/batch; 3h:57m:16s remains)
INFO - root - 2022-02-24 19:43:37.055694: step 39370, total loss = 0.56, batch loss = 0.28 (296.4 examples/sec; 0.027 sec/batch; 1h:12m:02s remains)
INFO - root - 2022-02-24 19:43:37.458080: step 39380, total loss = 0.57, batch loss = 0.29 (297.6 examples/sec; 0.027 sec/batch; 1h:11m:44s remains)
INFO - root - 2022-02-24 19:43:37.994392: step 39390, total loss = 0.64, batch loss = 0.36 (278.6 examples/sec; 0.029 sec/batch; 1h:16m:37s remains)
INFO - root - 2022-02-24 19:43:38.401127: step 39400, total loss = 0.51, batch loss = 0.23 (310.4 examples/sec; 0.026 sec/batch; 1h:08m:46s remains)
INFO - root - 2022-02-24 19:43:38.786743: step 39410, total loss = 0.65, batch loss = 0.37 (287.5 examples/sec; 0.028 sec/batch; 1h:14m:14s remains)
INFO - root - 2022-02-24 19:43:39.198304: step 39420, total loss = 0.57, batch loss = 0.29 (155.2 examples/sec; 0.052 sec/batch; 2h:17m:31s remains)
INFO - root - 2022-02-24 19:43:39.530457: step 39430, total loss = 0.66, batch loss = 0.38 (197.2 examples/sec; 0.041 sec/batch; 1h:48m:14s remains)
INFO - root - 2022-02-24 19:43:39.848693: step 39440, total loss = 0.54, batch loss = 0.26 (365.3 examples/sec; 0.022 sec/batch; 0h:58m:24s remains)
INFO - root - 2022-02-24 19:43:40.290832: step 39450, total loss = 0.55, batch loss = 0.27 (182.4 examples/sec; 0.044 sec/batch; 1h:56m:59s remains)
INFO - root - 2022-02-24 19:43:40.694124: step 39460, total loss = 0.65, batch loss = 0.37 (184.7 examples/sec; 0.043 sec/batch; 1h:55m:30s remains)
INFO - root - 2022-02-24 19:43:41.120718: step 39470, total loss = 0.62, batch loss = 0.34 (131.5 examples/sec; 0.061 sec/batch; 2h:42m:17s remains)
INFO - root - 2022-02-24 19:43:41.496191: step 39480, total loss = 0.54, batch loss = 0.26 (311.5 examples/sec; 0.026 sec/batch; 1h:08m:30s remains)
INFO - root - 2022-02-24 19:43:41.901046: step 39490, total loss = 0.61, batch loss = 0.33 (214.7 examples/sec; 0.037 sec/batch; 1h:39m:22s remains)
INFO - root - 2022-02-24 19:43:42.341450: step 39500, total loss = 0.65, batch loss = 0.37 (109.4 examples/sec; 0.073 sec/batch; 3h:15m:04s remains)
INFO - root - 2022-02-24 19:43:42.884683: step 39510, total loss = 0.56, batch loss = 0.28 (120.0 examples/sec; 0.067 sec/batch; 2h:57m:45s remains)
INFO - root - 2022-02-24 19:43:43.220115: step 39520, total loss = 0.48, batch loss = 0.20 (277.1 examples/sec; 0.029 sec/batch; 1h:16m:58s remains)
INFO - root - 2022-02-24 19:43:43.504137: step 39530, total loss = 0.60, batch loss = 0.32 (199.9 examples/sec; 0.040 sec/batch; 1h:46m:43s remains)
INFO - root - 2022-02-24 19:43:43.829666: step 39540, total loss = 0.62, batch loss = 0.34 (238.6 examples/sec; 0.034 sec/batch; 1h:29m:24s remains)
INFO - root - 2022-02-24 19:43:44.242505: step 39550, total loss = 0.51, batch loss = 0.23 (122.9 examples/sec; 0.065 sec/batch; 2h:53m:29s remains)
INFO - root - 2022-02-24 19:43:44.631390: step 39560, total loss = 0.56, batch loss = 0.28 (263.8 examples/sec; 0.030 sec/batch; 1h:20m:50s remains)
INFO - root - 2022-02-24 19:43:45.026628: step 39570, total loss = 0.71, batch loss = 0.43 (199.4 examples/sec; 0.040 sec/batch; 1h:46m:56s remains)
INFO - root - 2022-02-24 19:43:45.480659: step 39580, total loss = 0.65, batch loss = 0.37 (183.5 examples/sec; 0.044 sec/batch; 1h:56m:10s remains)
INFO - root - 2022-02-24 19:43:45.781977: step 39590, total loss = 0.61, batch loss = 0.33 (323.2 examples/sec; 0.025 sec/batch; 1h:05m:58s remains)
INFO - root - 2022-02-24 19:43:46.175813: step 39600, total loss = 0.59, batch loss = 0.31 (228.9 examples/sec; 0.035 sec/batch; 1h:33m:08s remains)
INFO - root - 2022-02-24 19:43:46.585572: step 39610, total loss = 0.56, batch loss = 0.28 (231.2 examples/sec; 0.035 sec/batch; 1h:32m:12s remains)
INFO - root - 2022-02-24 19:43:47.182651: step 39620, total loss = 0.52, batch loss = 0.24 (82.3 examples/sec; 0.097 sec/batch; 4h:18m:57s remains)
INFO - root - 2022-02-24 19:43:47.596902: step 39630, total loss = 0.61, batch loss = 0.33 (347.3 examples/sec; 0.023 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 19:43:47.969620: step 39640, total loss = 0.63, batch loss = 0.35 (307.0 examples/sec; 0.026 sec/batch; 1h:09m:25s remains)
INFO - root - 2022-02-24 19:43:48.286475: step 39650, total loss = 0.63, batch loss = 0.35 (338.2 examples/sec; 0.024 sec/batch; 1h:03m:01s remains)
INFO - root - 2022-02-24 19:43:48.737503: step 39660, total loss = 0.53, batch loss = 0.25 (206.5 examples/sec; 0.039 sec/batch; 1h:43m:13s remains)
INFO - root - 2022-02-24 19:43:49.111625: step 39670, total loss = 0.56, batch loss = 0.28 (196.8 examples/sec; 0.041 sec/batch; 1h:48m:17s remains)
INFO - root - 2022-02-24 19:43:49.497359: step 39680, total loss = 0.66, batch loss = 0.38 (355.8 examples/sec; 0.022 sec/batch; 0h:59m:53s remains)
INFO - root - 2022-02-24 19:43:49.821305: step 39690, total loss = 0.50, batch loss = 0.22 (340.7 examples/sec; 0.023 sec/batch; 1h:02m:32s remains)
INFO - root - 2022-02-24 19:43:50.185637: step 39700, total loss = 0.68, batch loss = 0.40 (330.2 examples/sec; 0.024 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 19:43:50.649231: step 39710, total loss = 0.53, batch loss = 0.25 (132.6 examples/sec; 0.060 sec/batch; 2h:40m:38s remains)
INFO - root - 2022-02-24 19:43:51.039021: step 39720, total loss = 0.54, batch loss = 0.26 (199.8 examples/sec; 0.040 sec/batch; 1h:46m:38s remains)
INFO - root - 2022-02-24 19:43:51.457724: step 39730, total loss = 0.49, batch loss = 0.21 (305.4 examples/sec; 0.026 sec/batch; 1h:09m:44s remains)
INFO - root - 2022-02-24 19:43:51.846032: step 39740, total loss = 0.59, batch loss = 0.31 (322.4 examples/sec; 0.025 sec/batch; 1h:06m:04s remains)
INFO - root - 2022-02-24 19:43:52.220073: step 39750, total loss = 0.69, batch loss = 0.41 (274.0 examples/sec; 0.029 sec/batch; 1h:17m:43s remains)
INFO - root - 2022-02-24 19:43:52.597452: step 39760, total loss = 0.56, batch loss = 0.28 (142.1 examples/sec; 0.056 sec/batch; 2h:29m:50s remains)
INFO - root - 2022-02-24 19:43:53.116253: step 39770, total loss = 0.51, batch loss = 0.23 (356.6 examples/sec; 0.022 sec/batch; 0h:59m:43s remains)
INFO - root - 2022-02-24 19:43:53.573419: step 39780, total loss = 0.57, batch loss = 0.29 (299.1 examples/sec; 0.027 sec/batch; 1h:11m:12s remains)
INFO - root - 2022-02-24 19:43:53.965423: step 39790, total loss = 0.59, batch loss = 0.31 (213.5 examples/sec; 0.037 sec/batch; 1h:39m:43s remains)
INFO - root - 2022-02-24 19:43:54.413945: step 39800, total loss = 0.60, batch loss = 0.32 (228.6 examples/sec; 0.035 sec/batch; 1h:33m:08s remains)
INFO - root - 2022-02-24 19:43:54.935992: step 39810, total loss = 0.58, batch loss = 0.30 (303.2 examples/sec; 0.026 sec/batch; 1h:10m:13s remains)
INFO - root - 2022-02-24 19:43:55.480443: step 39820, total loss = 0.62, batch loss = 0.34 (331.9 examples/sec; 0.024 sec/batch; 1h:04m:09s remains)
INFO - root - 2022-02-24 19:43:55.949791: step 39830, total loss = 0.57, batch loss = 0.29 (328.4 examples/sec; 0.024 sec/batch; 1h:04m:50s remains)
INFO - root - 2022-02-24 19:43:56.375844: step 39840, total loss = 0.58, batch loss = 0.30 (317.7 examples/sec; 0.025 sec/batch; 1h:07m:00s remains)
INFO - root - 2022-02-24 19:43:57.248628: step 39850, total loss = 0.62, batch loss = 0.34 (102.8 examples/sec; 0.078 sec/batch; 3h:27m:07s remains)
INFO - root - 2022-02-24 19:43:57.638936: step 39860, total loss = 0.57, batch loss = 0.29 (357.1 examples/sec; 0.022 sec/batch; 0h:59m:36s remains)
INFO - root - 2022-02-24 19:43:58.065003: step 39870, total loss = 0.51, batch loss = 0.23 (336.5 examples/sec; 0.024 sec/batch; 1h:03m:15s remains)
INFO - root - 2022-02-24 19:43:58.404608: step 39880, total loss = 0.63, batch loss = 0.35 (232.7 examples/sec; 0.034 sec/batch; 1h:31m:27s remains)
INFO - root - 2022-02-24 19:43:58.821247: step 39890, total loss = 0.55, batch loss = 0.27 (222.6 examples/sec; 0.036 sec/batch; 1h:35m:37s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-39899 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-39899 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:43:59.928750: step 39900, total loss = 0.58, batch loss = 0.30 (327.0 examples/sec; 0.024 sec/batch; 1h:05m:04s remains)
INFO - root - 2022-02-24 19:44:00.285369: step 39910, total loss = 0.55, batch loss = 0.27 (357.8 examples/sec; 0.022 sec/batch; 0h:59m:28s remains)
INFO - root - 2022-02-24 19:44:00.531140: step 39920, total loss = 0.64, batch loss = 0.36 (314.5 examples/sec; 0.025 sec/batch; 1h:07m:38s remains)
INFO - root - 2022-02-24 19:44:00.941407: step 39930, total loss = 0.53, batch loss = 0.25 (123.5 examples/sec; 0.065 sec/batch; 2h:52m:17s remains)
INFO - root - 2022-02-24 19:44:01.425181: step 39940, total loss = 0.49, batch loss = 0.21 (144.3 examples/sec; 0.055 sec/batch; 2h:27m:24s remains)
INFO - root - 2022-02-24 19:44:01.803920: step 39950, total loss = 0.65, batch loss = 0.37 (332.8 examples/sec; 0.024 sec/batch; 1h:03m:55s remains)
INFO - root - 2022-02-24 19:44:02.735168: step 39960, total loss = 0.51, batch loss = 0.23 (144.8 examples/sec; 0.055 sec/batch; 2h:26m:55s remains)
INFO - root - 2022-02-24 19:44:03.096732: step 39970, total loss = 0.56, batch loss = 0.28 (140.9 examples/sec; 0.057 sec/batch; 2h:30m:59s remains)
INFO - root - 2022-02-24 19:44:03.455528: step 39980, total loss = 0.57, batch loss = 0.29 (140.9 examples/sec; 0.057 sec/batch; 2h:30m:55s remains)
INFO - root - 2022-02-24 19:44:03.946041: step 39990, total loss = 0.67, batch loss = 0.39 (124.8 examples/sec; 0.064 sec/batch; 2h:50m:21s remains)
INFO - root - 2022-02-24 19:44:04.324146: step 40000, total loss = 0.56, batch loss = 0.28 (267.7 examples/sec; 0.030 sec/batch; 1h:19m:25s remains)
INFO - root - 2022-02-24 19:44:04.776740: step 40010, total loss = 0.55, batch loss = 0.27 (159.8 examples/sec; 0.050 sec/batch; 2h:13m:03s remains)
INFO - root - 2022-02-24 19:44:05.147141: step 40020, total loss = 0.70, batch loss = 0.42 (377.8 examples/sec; 0.021 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 19:44:05.510688: step 40030, total loss = 0.62, batch loss = 0.34 (126.0 examples/sec; 0.064 sec/batch; 2h:48m:48s remains)
INFO - root - 2022-02-24 19:44:05.854527: step 40040, total loss = 0.59, batch loss = 0.31 (222.7 examples/sec; 0.036 sec/batch; 1h:35m:28s remains)
INFO - root - 2022-02-24 19:44:06.266790: step 40050, total loss = 0.50, batch loss = 0.22 (146.7 examples/sec; 0.055 sec/batch; 2h:24m:56s remains)
INFO - root - 2022-02-24 19:44:06.525098: step 40060, total loss = 0.53, batch loss = 0.25 (234.2 examples/sec; 0.034 sec/batch; 1h:30m:47s remains)
INFO - root - 2022-02-24 19:44:06.857309: step 40070, total loss = 0.55, batch loss = 0.27 (254.2 examples/sec; 0.031 sec/batch; 1h:23m:36s remains)
INFO - root - 2022-02-24 19:44:07.172253: step 40080, total loss = 0.62, batch loss = 0.34 (152.8 examples/sec; 0.052 sec/batch; 2h:19m:07s remains)
INFO - root - 2022-02-24 19:44:07.586843: step 40090, total loss = 0.56, batch loss = 0.28 (144.3 examples/sec; 0.055 sec/batch; 2h:27m:14s remains)
INFO - root - 2022-02-24 19:44:07.942365: step 40100, total loss = 0.69, batch loss = 0.41 (310.3 examples/sec; 0.026 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 19:44:08.583585: step 40110, total loss = 0.54, batch loss = 0.26 (132.8 examples/sec; 0.060 sec/batch; 2h:40m:01s remains)
INFO - root - 2022-02-24 19:44:08.962235: step 40120, total loss = 0.66, batch loss = 0.38 (346.7 examples/sec; 0.023 sec/batch; 1h:01m:17s remains)
INFO - root - 2022-02-24 19:44:09.355945: step 40130, total loss = 0.52, batch loss = 0.24 (186.4 examples/sec; 0.043 sec/batch; 1h:54m:01s remains)
INFO - root - 2022-02-24 19:44:09.695168: step 40140, total loss = 0.52, batch loss = 0.24 (168.7 examples/sec; 0.047 sec/batch; 2h:05m:57s remains)
INFO - root - 2022-02-24 19:44:10.077669: step 40150, total loss = 0.60, batch loss = 0.32 (129.0 examples/sec; 0.062 sec/batch; 2h:44m:41s remains)
INFO - root - 2022-02-24 19:44:10.568940: step 40160, total loss = 0.61, batch loss = 0.33 (90.5 examples/sec; 0.088 sec/batch; 3h:54m:49s remains)
INFO - root - 2022-02-24 19:44:10.950816: step 40170, total loss = 0.61, batch loss = 0.33 (330.7 examples/sec; 0.024 sec/batch; 1h:04m:14s remains)
INFO - root - 2022-02-24 19:44:11.284728: step 40180, total loss = 0.47, batch loss = 0.19 (253.6 examples/sec; 0.032 sec/batch; 1h:23m:45s remains)
INFO - root - 2022-02-24 19:44:11.630735: step 40190, total loss = 0.53, batch loss = 0.25 (342.3 examples/sec; 0.023 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 19:44:12.015988: step 40200, total loss = 0.68, batch loss = 0.40 (151.2 examples/sec; 0.053 sec/batch; 2h:20m:26s remains)
INFO - root - 2022-02-24 19:44:12.557838: step 40210, total loss = 0.57, batch loss = 0.29 (335.8 examples/sec; 0.024 sec/batch; 1h:03m:14s remains)
INFO - root - 2022-02-24 19:44:12.985368: step 40220, total loss = 0.57, batch loss = 0.29 (189.8 examples/sec; 0.042 sec/batch; 1h:51m:54s remains)
INFO - root - 2022-02-24 19:44:13.332438: step 40230, total loss = 0.57, batch loss = 0.29 (190.2 examples/sec; 0.042 sec/batch; 1h:51m:39s remains)
INFO - root - 2022-02-24 19:44:13.780871: step 40240, total loss = 0.63, batch loss = 0.35 (117.6 examples/sec; 0.068 sec/batch; 3h:00m:33s remains)
INFO - root - 2022-02-24 19:44:14.117340: step 40250, total loss = 0.48, batch loss = 0.20 (341.6 examples/sec; 0.023 sec/batch; 1h:02m:09s remains)
INFO - root - 2022-02-24 19:44:14.542918: step 40260, total loss = 0.56, batch loss = 0.28 (334.6 examples/sec; 0.024 sec/batch; 1h:03m:27s remains)
INFO - root - 2022-02-24 19:44:14.938523: step 40270, total loss = 0.54, batch loss = 0.27 (249.7 examples/sec; 0.032 sec/batch; 1h:25m:02s remains)
INFO - root - 2022-02-24 19:44:15.365404: step 40280, total loss = 0.58, batch loss = 0.30 (263.7 examples/sec; 0.030 sec/batch; 1h:20m:30s remains)
INFO - root - 2022-02-24 19:44:15.678468: step 40290, total loss = 0.52, batch loss = 0.24 (320.1 examples/sec; 0.025 sec/batch; 1h:06m:18s remains)
INFO - root - 2022-02-24 19:44:16.022483: step 40300, total loss = 0.70, batch loss = 0.42 (331.3 examples/sec; 0.024 sec/batch; 1h:04m:04s remains)
INFO - root - 2022-02-24 19:44:16.462800: step 40310, total loss = 0.55, batch loss = 0.27 (205.3 examples/sec; 0.039 sec/batch; 1h:43m:22s remains)
INFO - root - 2022-02-24 19:44:16.938592: step 40320, total loss = 0.51, batch loss = 0.23 (118.9 examples/sec; 0.067 sec/batch; 2h:58m:32s remains)
INFO - root - 2022-02-24 19:44:17.396017: step 40330, total loss = 0.66, batch loss = 0.38 (96.6 examples/sec; 0.083 sec/batch; 3h:39m:41s remains)
INFO - root - 2022-02-24 19:44:17.801572: step 40340, total loss = 0.59, batch loss = 0.31 (249.1 examples/sec; 0.032 sec/batch; 1h:25m:11s remains)
INFO - root - 2022-02-24 19:44:18.441181: step 40350, total loss = 0.61, batch loss = 0.33 (134.9 examples/sec; 0.059 sec/batch; 2h:37m:21s remains)
INFO - root - 2022-02-24 19:44:18.885919: step 40360, total loss = 0.63, batch loss = 0.35 (140.4 examples/sec; 0.057 sec/batch; 2h:31m:07s remains)
INFO - root - 2022-02-24 19:44:19.426879: step 40370, total loss = 0.59, batch loss = 0.31 (113.1 examples/sec; 0.071 sec/batch; 3h:07m:36s remains)
INFO - root - 2022-02-24 19:44:19.871878: step 40380, total loss = 0.68, batch loss = 0.40 (254.8 examples/sec; 0.031 sec/batch; 1h:23m:15s remains)
INFO - root - 2022-02-24 19:44:20.527390: step 40390, total loss = 0.57, batch loss = 0.29 (250.4 examples/sec; 0.032 sec/batch; 1h:24m:44s remains)
INFO - root - 2022-02-24 19:44:21.128630: step 40400, total loss = 0.61, batch loss = 0.33 (150.8 examples/sec; 0.053 sec/batch; 2h:20m:39s remains)
INFO - root - 2022-02-24 19:44:21.664447: step 40410, total loss = 0.55, batch loss = 0.27 (118.5 examples/sec; 0.067 sec/batch; 2h:58m:56s remains)
INFO - root - 2022-02-24 19:44:22.078892: step 40420, total loss = 0.47, batch loss = 0.20 (183.5 examples/sec; 0.044 sec/batch; 1h:55m:33s remains)
INFO - root - 2022-02-24 19:44:23.035063: step 40430, total loss = 0.54, batch loss = 0.26 (125.4 examples/sec; 0.064 sec/batch; 2h:49m:08s remains)
INFO - root - 2022-02-24 19:44:23.417925: step 40440, total loss = 0.50, batch loss = 0.22 (187.7 examples/sec; 0.043 sec/batch; 1h:52m:57s remains)
INFO - root - 2022-02-24 19:44:23.858760: step 40450, total loss = 0.65, batch loss = 0.37 (314.0 examples/sec; 0.025 sec/batch; 1h:07m:32s remains)
INFO - root - 2022-02-24 19:44:24.249059: step 40460, total loss = 0.53, batch loss = 0.25 (164.9 examples/sec; 0.049 sec/batch; 2h:08m:36s remains)
INFO - root - 2022-02-24 19:44:24.607962: step 40470, total loss = 0.61, batch loss = 0.33 (322.5 examples/sec; 0.025 sec/batch; 1h:05m:44s remains)
INFO - root - 2022-02-24 19:44:24.975564: step 40480, total loss = 0.57, batch loss = 0.29 (277.1 examples/sec; 0.029 sec/batch; 1h:16m:31s remains)
INFO - root - 2022-02-24 19:44:25.440376: step 40490, total loss = 0.63, batch loss = 0.35 (166.7 examples/sec; 0.048 sec/batch; 2h:07m:09s remains)
INFO - root - 2022-02-24 19:44:25.862452: step 40500, total loss = 0.62, batch loss = 0.34 (163.3 examples/sec; 0.049 sec/batch; 2h:09m:49s remains)
INFO - root - 2022-02-24 19:44:26.292189: step 40510, total loss = 0.68, batch loss = 0.40 (189.7 examples/sec; 0.042 sec/batch; 1h:51m:44s remains)
INFO - root - 2022-02-24 19:44:26.691969: step 40520, total loss = 0.53, batch loss = 0.26 (186.3 examples/sec; 0.043 sec/batch; 1h:53m:46s remains)
INFO - root - 2022-02-24 19:44:26.987602: step 40530, total loss = 0.55, batch loss = 0.27 (222.5 examples/sec; 0.036 sec/batch; 1h:35m:14s remains)
INFO - root - 2022-02-24 19:44:27.503756: step 40540, total loss = 0.63, batch loss = 0.35 (91.1 examples/sec; 0.088 sec/batch; 3h:52m:45s remains)
INFO - root - 2022-02-24 19:44:27.947590: step 40550, total loss = 0.54, batch loss = 0.26 (247.5 examples/sec; 0.032 sec/batch; 1h:25m:38s remains)
INFO - root - 2022-02-24 19:44:28.367093: step 40560, total loss = 0.85, batch loss = 0.57 (262.5 examples/sec; 0.030 sec/batch; 1h:20m:43s remains)
INFO - root - 2022-02-24 19:44:28.811376: step 40570, total loss = 0.65, batch loss = 0.37 (95.8 examples/sec; 0.084 sec/batch; 3h:41m:13s remains)
INFO - root - 2022-02-24 19:44:29.267506: step 40580, total loss = 0.63, batch loss = 0.35 (218.2 examples/sec; 0.037 sec/batch; 1h:37m:07s remains)
INFO - root - 2022-02-24 19:44:29.680126: step 40590, total loss = 0.61, batch loss = 0.33 (194.0 examples/sec; 0.041 sec/batch; 1h:49m:12s remains)
INFO - root - 2022-02-24 19:44:30.155199: step 40600, total loss = 0.68, batch loss = 0.40 (201.7 examples/sec; 0.040 sec/batch; 1h:45m:03s remains)
INFO - root - 2022-02-24 19:44:30.581787: step 40610, total loss = 0.57, batch loss = 0.29 (303.0 examples/sec; 0.026 sec/batch; 1h:09m:54s remains)
INFO - root - 2022-02-24 19:44:30.919592: step 40620, total loss = 0.53, batch loss = 0.25 (293.5 examples/sec; 0.027 sec/batch; 1h:12m:09s remains)
INFO - root - 2022-02-24 19:44:31.250579: step 40630, total loss = 0.59, batch loss = 0.31 (286.9 examples/sec; 0.028 sec/batch; 1h:13m:50s remains)
INFO - root - 2022-02-24 19:44:31.659169: step 40640, total loss = 0.53, batch loss = 0.25 (200.8 examples/sec; 0.040 sec/batch; 1h:45m:27s remains)
INFO - root - 2022-02-24 19:44:32.122491: step 40650, total loss = 0.54, batch loss = 0.26 (187.8 examples/sec; 0.043 sec/batch; 1h:52m:45s remains)
INFO - root - 2022-02-24 19:44:32.495056: step 40660, total loss = 0.60, batch loss = 0.32 (220.3 examples/sec; 0.036 sec/batch; 1h:36m:08s remains)
INFO - root - 2022-02-24 19:44:32.848985: step 40670, total loss = 0.57, batch loss = 0.29 (256.0 examples/sec; 0.031 sec/batch; 1h:22m:44s remains)
INFO - root - 2022-02-24 19:44:33.281171: step 40680, total loss = 0.61, batch loss = 0.33 (103.1 examples/sec; 0.078 sec/batch; 3h:25m:21s remains)
INFO - root - 2022-02-24 19:44:33.642117: step 40690, total loss = 0.55, batch loss = 0.27 (348.9 examples/sec; 0.023 sec/batch; 1h:00m:41s remains)
INFO - root - 2022-02-24 19:44:34.065317: step 40700, total loss = 0.66, batch loss = 0.38 (232.5 examples/sec; 0.034 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 19:44:34.551529: step 40710, total loss = 0.64, batch loss = 0.36 (202.2 examples/sec; 0.040 sec/batch; 1h:44m:42s remains)
INFO - root - 2022-02-24 19:44:34.902819: step 40720, total loss = 0.54, batch loss = 0.26 (193.7 examples/sec; 0.041 sec/batch; 1h:49m:17s remains)
INFO - root - 2022-02-24 19:44:35.255215: step 40730, total loss = 0.61, batch loss = 0.33 (332.3 examples/sec; 0.024 sec/batch; 1h:03m:42s remains)
INFO - root - 2022-02-24 19:44:35.667407: step 40740, total loss = 0.54, batch loss = 0.26 (164.8 examples/sec; 0.049 sec/batch; 2h:08m:25s remains)
INFO - root - 2022-02-24 19:44:36.053669: step 40750, total loss = 0.62, batch loss = 0.34 (314.8 examples/sec; 0.025 sec/batch; 1h:07m:14s remains)
INFO - root - 2022-02-24 19:44:36.471229: step 40760, total loss = 0.57, batch loss = 0.29 (334.7 examples/sec; 0.024 sec/batch; 1h:03m:13s remains)
INFO - root - 2022-02-24 19:44:36.756932: step 40770, total loss = 0.55, batch loss = 0.27 (260.6 examples/sec; 0.031 sec/batch; 1h:21m:12s remains)
INFO - root - 2022-02-24 19:44:37.083593: step 40780, total loss = 0.55, batch loss = 0.27 (291.0 examples/sec; 0.027 sec/batch; 1h:12m:44s remains)
INFO - root - 2022-02-24 19:44:37.408514: step 40790, total loss = 0.58, batch loss = 0.30 (297.7 examples/sec; 0.027 sec/batch; 1h:11m:04s remains)
INFO - root - 2022-02-24 19:44:37.837452: step 40800, total loss = 0.56, batch loss = 0.28 (164.4 examples/sec; 0.049 sec/batch; 2h:08m:43s remains)
INFO - root - 2022-02-24 19:44:38.371794: step 40810, total loss = 0.58, batch loss = 0.30 (137.4 examples/sec; 0.058 sec/batch; 2h:34m:02s remains)
INFO - root - 2022-02-24 19:44:38.723678: step 40820, total loss = 0.61, batch loss = 0.33 (165.7 examples/sec; 0.048 sec/batch; 2h:07m:39s remains)
INFO - root - 2022-02-24 19:44:39.065167: step 40830, total loss = 0.65, batch loss = 0.37 (351.2 examples/sec; 0.023 sec/batch; 1h:00m:14s remains)
INFO - root - 2022-02-24 19:44:39.430929: step 40840, total loss = 0.64, batch loss = 0.36 (229.5 examples/sec; 0.035 sec/batch; 1h:32m:09s remains)
INFO - root - 2022-02-24 19:44:39.759371: step 40850, total loss = 0.65, batch loss = 0.37 (201.9 examples/sec; 0.040 sec/batch; 1h:44m:47s remains)
INFO - root - 2022-02-24 19:44:40.187880: step 40860, total loss = 0.64, batch loss = 0.36 (210.9 examples/sec; 0.038 sec/batch; 1h:40m:18s remains)
INFO - root - 2022-02-24 19:44:40.596107: step 40870, total loss = 0.61, batch loss = 0.33 (346.0 examples/sec; 0.023 sec/batch; 1h:01m:07s remains)
INFO - root - 2022-02-24 19:44:40.972280: step 40880, total loss = 0.51, batch loss = 0.23 (313.7 examples/sec; 0.026 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 19:44:41.331869: step 40890, total loss = 0.62, batch loss = 0.34 (281.0 examples/sec; 0.028 sec/batch; 1h:15m:15s remains)
INFO - root - 2022-02-24 19:44:41.720603: step 40900, total loss = 0.56, batch loss = 0.28 (303.1 examples/sec; 0.026 sec/batch; 1h:09m:45s remains)
INFO - root - 2022-02-24 19:44:42.217429: step 40910, total loss = 0.57, batch loss = 0.29 (173.1 examples/sec; 0.046 sec/batch; 2h:02m:09s remains)
INFO - root - 2022-02-24 19:44:42.658553: step 40920, total loss = 0.57, batch loss = 0.29 (308.4 examples/sec; 0.026 sec/batch; 1h:08m:33s remains)
INFO - root - 2022-02-24 19:44:43.043132: step 40930, total loss = 0.71, batch loss = 0.43 (269.6 examples/sec; 0.030 sec/batch; 1h:18m:25s remains)
INFO - root - 2022-02-24 19:44:43.336203: step 40940, total loss = 0.49, batch loss = 0.21 (292.1 examples/sec; 0.027 sec/batch; 1h:12m:21s remains)
INFO - root - 2022-02-24 19:44:43.668153: step 40950, total loss = 0.55, batch loss = 0.28 (317.8 examples/sec; 0.025 sec/batch; 1h:06m:30s remains)
INFO - root - 2022-02-24 19:44:44.037772: step 40960, total loss = 0.56, batch loss = 0.28 (245.6 examples/sec; 0.033 sec/batch; 1h:26m:04s remains)
INFO - root - 2022-02-24 19:44:44.442655: step 40970, total loss = 0.62, batch loss = 0.34 (139.8 examples/sec; 0.057 sec/batch; 2h:31m:11s remains)
INFO - root - 2022-02-24 19:44:44.854602: step 40980, total loss = 0.72, batch loss = 0.44 (366.3 examples/sec; 0.022 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 19:44:45.214079: step 40990, total loss = 0.66, batch loss = 0.38 (246.9 examples/sec; 0.032 sec/batch; 1h:25m:35s remains)
INFO - root - 2022-02-24 19:44:45.544168: step 41000, total loss = 0.54, batch loss = 0.26 (335.7 examples/sec; 0.024 sec/batch; 1h:02m:57s remains)
INFO - root - 2022-02-24 19:44:46.039710: step 41010, total loss = 0.66, batch loss = 0.38 (348.8 examples/sec; 0.023 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 19:44:46.472632: step 41020, total loss = 0.55, batch loss = 0.28 (156.1 examples/sec; 0.051 sec/batch; 2h:15m:20s remains)
INFO - root - 2022-02-24 19:44:46.978817: step 41030, total loss = 0.67, batch loss = 0.39 (266.2 examples/sec; 0.030 sec/batch; 1h:19m:22s remains)
INFO - root - 2022-02-24 19:44:47.306203: step 41040, total loss = 0.53, batch loss = 0.25 (234.0 examples/sec; 0.034 sec/batch; 1h:30m:17s remains)
INFO - root - 2022-02-24 19:44:47.703067: step 41050, total loss = 0.56, batch loss = 0.28 (246.3 examples/sec; 0.032 sec/batch; 1h:25m:46s remains)
INFO - root - 2022-02-24 19:44:48.052323: step 41060, total loss = 0.54, batch loss = 0.26 (223.2 examples/sec; 0.036 sec/batch; 1h:34m:37s remains)
INFO - root - 2022-02-24 19:44:48.494616: step 41070, total loss = 0.56, batch loss = 0.28 (175.2 examples/sec; 0.046 sec/batch; 2h:00m:34s remains)
INFO - root - 2022-02-24 19:44:48.930042: step 41080, total loss = 0.65, batch loss = 0.37 (317.1 examples/sec; 0.025 sec/batch; 1h:06m:37s remains)
INFO - root - 2022-02-24 19:44:49.247540: step 41090, total loss = 0.56, batch loss = 0.28 (216.2 examples/sec; 0.037 sec/batch; 1h:37m:41s remains)
INFO - root - 2022-02-24 19:44:49.562828: step 41100, total loss = 0.55, batch loss = 0.27 (260.1 examples/sec; 0.031 sec/batch; 1h:21m:11s remains)
INFO - root - 2022-02-24 19:44:49.919159: step 41110, total loss = 0.51, batch loss = 0.23 (326.5 examples/sec; 0.025 sec/batch; 1h:04m:41s remains)
INFO - root - 2022-02-24 19:44:50.362102: step 41120, total loss = 0.61, batch loss = 0.33 (144.8 examples/sec; 0.055 sec/batch; 2h:25m:48s remains)
INFO - root - 2022-02-24 19:44:50.840289: step 41130, total loss = 0.61, batch loss = 0.33 (258.2 examples/sec; 0.031 sec/batch; 1h:21m:47s remains)
INFO - root - 2022-02-24 19:44:51.298160: step 41140, total loss = 0.60, batch loss = 0.32 (138.6 examples/sec; 0.058 sec/batch; 2h:32m:23s remains)
INFO - root - 2022-02-24 19:44:51.666876: step 41150, total loss = 0.60, batch loss = 0.32 (227.1 examples/sec; 0.035 sec/batch; 1h:32m:56s remains)
INFO - root - 2022-02-24 19:44:51.974409: step 41160, total loss = 0.54, batch loss = 0.26 (355.4 examples/sec; 0.023 sec/batch; 0h:59m:24s remains)
INFO - root - 2022-02-24 19:44:52.300473: step 41170, total loss = 0.66, batch loss = 0.38 (206.2 examples/sec; 0.039 sec/batch; 1h:42m:24s remains)
INFO - root - 2022-02-24 19:44:52.746340: step 41180, total loss = 0.55, batch loss = 0.27 (157.6 examples/sec; 0.051 sec/batch; 2h:13m:57s remains)
INFO - root - 2022-02-24 19:44:53.096438: step 41190, total loss = 0.71, batch loss = 0.43 (150.1 examples/sec; 0.053 sec/batch; 2h:20m:36s remains)
INFO - root - 2022-02-24 19:44:53.548656: step 41200, total loss = 0.52, batch loss = 0.25 (366.0 examples/sec; 0.022 sec/batch; 0h:57m:40s remains)
INFO - root - 2022-02-24 19:44:54.037760: step 41210, total loss = 0.63, batch loss = 0.35 (212.8 examples/sec; 0.038 sec/batch; 1h:39m:11s remains)
INFO - root - 2022-02-24 19:44:54.369848: step 41220, total loss = 0.65, batch loss = 0.37 (256.6 examples/sec; 0.031 sec/batch; 1h:22m:14s remains)
INFO - root - 2022-02-24 19:44:54.817712: step 41230, total loss = 0.59, batch loss = 0.31 (172.8 examples/sec; 0.046 sec/batch; 2h:02m:08s remains)
INFO - root - 2022-02-24 19:44:55.269811: step 41240, total loss = 0.59, batch loss = 0.31 (141.4 examples/sec; 0.057 sec/batch; 2h:29m:16s remains)
INFO - root - 2022-02-24 19:44:55.746722: step 41250, total loss = 0.53, batch loss = 0.25 (159.9 examples/sec; 0.050 sec/batch; 2h:11m:59s remains)
INFO - root - 2022-02-24 19:44:56.134381: step 41260, total loss = 0.60, batch loss = 0.33 (333.3 examples/sec; 0.024 sec/batch; 1h:03m:17s remains)
INFO - root - 2022-02-24 19:44:56.477203: step 41270, total loss = 0.50, batch loss = 0.22 (286.4 examples/sec; 0.028 sec/batch; 1h:13m:40s remains)
INFO - root - 2022-02-24 19:44:56.824514: step 41280, total loss = 0.55, batch loss = 0.27 (128.3 examples/sec; 0.062 sec/batch; 2h:44m:24s remains)
INFO - root - 2022-02-24 19:44:57.285459: step 41290, total loss = 0.52, batch loss = 0.24 (358.4 examples/sec; 0.022 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 19:44:58.197615: step 41300, total loss = 0.49, batch loss = 0.21 (202.0 examples/sec; 0.040 sec/batch; 1h:44m:26s remains)
INFO - root - 2022-02-24 19:44:58.673252: step 41310, total loss = 0.62, batch loss = 0.34 (190.6 examples/sec; 0.042 sec/batch; 1h:50m:40s remains)
INFO - root - 2022-02-24 19:44:59.041276: step 41320, total loss = 0.56, batch loss = 0.29 (388.6 examples/sec; 0.021 sec/batch; 0h:54m:16s remains)
INFO - root - 2022-02-24 19:44:59.481150: step 41330, total loss = 0.59, batch loss = 0.31 (236.1 examples/sec; 0.034 sec/batch; 1h:29m:19s remains)
INFO - root - 2022-02-24 19:44:59.984223: step 41340, total loss = 0.61, batch loss = 0.33 (98.5 examples/sec; 0.081 sec/batch; 3h:34m:01s remains)
INFO - root - 2022-02-24 19:45:00.566447: step 41350, total loss = 0.66, batch loss = 0.38 (69.4 examples/sec; 0.115 sec/batch; 5h:03m:48s remains)
INFO - root - 2022-02-24 19:45:01.054200: step 41360, total loss = 0.52, batch loss = 0.24 (221.3 examples/sec; 0.036 sec/batch; 1h:35m:15s remains)
INFO - root - 2022-02-24 19:45:01.560097: step 41370, total loss = 0.56, batch loss = 0.28 (173.6 examples/sec; 0.046 sec/batch; 2h:01m:25s remains)
INFO - root - 2022-02-24 19:45:02.123987: step 41380, total loss = 0.55, batch loss = 0.27 (135.4 examples/sec; 0.059 sec/batch; 2h:35m:39s remains)
INFO - root - 2022-02-24 19:45:02.917663: step 41390, total loss = 0.52, batch loss = 0.24 (23.2 examples/sec; 0.344 sec/batch; 15h:07m:08s remains)
INFO - root - 2022-02-24 19:45:03.285601: step 41400, total loss = 0.60, batch loss = 0.32 (240.0 examples/sec; 0.033 sec/batch; 1h:27m:50s remains)
INFO - root - 2022-02-24 19:45:03.747946: step 41410, total loss = 0.57, batch loss = 0.29 (240.5 examples/sec; 0.033 sec/batch; 1h:27m:37s remains)
INFO - root - 2022-02-24 19:45:04.098980: step 41420, total loss = 0.58, batch loss = 0.30 (184.7 examples/sec; 0.043 sec/batch; 1h:54m:08s remains)
INFO - root - 2022-02-24 19:45:04.466542: step 41430, total loss = 0.58, batch loss = 0.30 (225.0 examples/sec; 0.036 sec/batch; 1h:33m:41s remains)
INFO - root - 2022-02-24 19:45:04.769639: step 41440, total loss = 0.57, batch loss = 0.29 (268.6 examples/sec; 0.030 sec/batch; 1h:18m:28s remains)
INFO - root - 2022-02-24 19:45:05.103108: step 41450, total loss = 0.66, batch loss = 0.38 (290.6 examples/sec; 0.028 sec/batch; 1h:12m:30s remains)
INFO - root - 2022-02-24 19:45:05.445418: step 41460, total loss = 0.54, batch loss = 0.26 (158.9 examples/sec; 0.050 sec/batch; 2h:12m:37s remains)
INFO - root - 2022-02-24 19:45:05.858610: step 41470, total loss = 0.54, batch loss = 0.26 (120.5 examples/sec; 0.066 sec/batch; 2h:54m:47s remains)
INFO - root - 2022-02-24 19:45:06.244335: step 41480, total loss = 0.57, batch loss = 0.29 (218.4 examples/sec; 0.037 sec/batch; 1h:36m:28s remains)
INFO - root - 2022-02-24 19:45:06.573652: step 41490, total loss = 0.52, batch loss = 0.24 (266.0 examples/sec; 0.030 sec/batch; 1h:19m:11s remains)
INFO - root - 2022-02-24 19:45:06.893027: step 41500, total loss = 0.59, batch loss = 0.31 (337.5 examples/sec; 0.024 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 19:45:07.345103: step 41510, total loss = 0.79, batch loss = 0.51 (334.6 examples/sec; 0.024 sec/batch; 1h:02m:57s remains)
INFO - root - 2022-02-24 19:45:07.836043: step 41520, total loss = 0.54, batch loss = 0.26 (326.0 examples/sec; 0.025 sec/batch; 1h:04m:36s remains)
INFO - root - 2022-02-24 19:45:08.325539: step 41530, total loss = 0.53, batch loss = 0.26 (138.7 examples/sec; 0.058 sec/batch; 2h:31m:50s remains)
INFO - root - 2022-02-24 19:45:08.661675: step 41540, total loss = 0.66, batch loss = 0.39 (260.6 examples/sec; 0.031 sec/batch; 1h:20m:49s remains)
INFO - root - 2022-02-24 19:45:09.005606: step 41550, total loss = 0.54, batch loss = 0.26 (168.4 examples/sec; 0.047 sec/batch; 2h:05m:01s remains)
INFO - root - 2022-02-24 19:45:09.314590: step 41560, total loss = 0.65, batch loss = 0.37 (235.1 examples/sec; 0.034 sec/batch; 1h:29m:34s remains)
INFO - root - 2022-02-24 19:45:09.690815: step 41570, total loss = 0.54, batch loss = 0.26 (181.9 examples/sec; 0.044 sec/batch; 1h:55m:47s remains)
INFO - root - 2022-02-24 19:45:10.071699: step 41580, total loss = 0.80, batch loss = 0.52 (128.7 examples/sec; 0.062 sec/batch; 2h:43m:35s remains)
INFO - root - 2022-02-24 19:45:10.464980: step 41590, total loss = 0.72, batch loss = 0.44 (184.9 examples/sec; 0.043 sec/batch; 1h:53m:53s remains)
INFO - root - 2022-02-24 19:45:10.811217: step 41600, total loss = 0.55, batch loss = 0.27 (94.5 examples/sec; 0.085 sec/batch; 3h:42m:40s remains)
INFO - root - 2022-02-24 19:45:11.242334: step 41610, total loss = 0.52, batch loss = 0.24 (202.4 examples/sec; 0.040 sec/batch; 1h:44m:02s remains)
INFO - root - 2022-02-24 19:45:11.573241: step 41620, total loss = 0.59, batch loss = 0.31 (306.3 examples/sec; 0.026 sec/batch; 1h:08m:43s remains)
INFO - root - 2022-02-24 19:45:11.924192: step 41630, total loss = 0.71, batch loss = 0.43 (336.1 examples/sec; 0.024 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:45:12.428516: step 41640, total loss = 0.54, batch loss = 0.26 (254.4 examples/sec; 0.031 sec/batch; 1h:22m:43s remains)
INFO - root - 2022-02-24 19:45:12.913055: step 41650, total loss = 0.55, batch loss = 0.27 (157.4 examples/sec; 0.051 sec/batch; 2h:13m:43s remains)
INFO - root - 2022-02-24 19:45:13.304211: step 41660, total loss = 0.52, batch loss = 0.24 (210.2 examples/sec; 0.038 sec/batch; 1h:40m:07s remains)
INFO - root - 2022-02-24 19:45:13.648511: step 41670, total loss = 0.54, batch loss = 0.26 (351.0 examples/sec; 0.023 sec/batch; 0h:59m:57s remains)
INFO - root - 2022-02-24 19:45:14.091738: step 41680, total loss = 0.48, batch loss = 0.21 (342.7 examples/sec; 0.023 sec/batch; 1h:01m:24s remains)
INFO - root - 2022-02-24 19:45:14.635277: step 41690, total loss = 0.59, batch loss = 0.31 (206.6 examples/sec; 0.039 sec/batch; 1h:41m:49s remains)
INFO - root - 2022-02-24 19:45:14.985410: step 41700, total loss = 0.56, batch loss = 0.28 (201.4 examples/sec; 0.040 sec/batch; 1h:44m:28s remains)
INFO - root - 2022-02-24 19:45:15.356326: step 41710, total loss = 0.56, batch loss = 0.28 (313.8 examples/sec; 0.025 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 19:45:15.695784: step 41720, total loss = 0.55, batch loss = 0.27 (224.7 examples/sec; 0.036 sec/batch; 1h:33m:38s remains)
INFO - root - 2022-02-24 19:45:16.051463: step 41730, total loss = 0.63, batch loss = 0.35 (335.8 examples/sec; 0.024 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:45:16.503387: step 41740, total loss = 0.65, batch loss = 0.37 (114.9 examples/sec; 0.070 sec/batch; 3h:03m:05s remains)
INFO - root - 2022-02-24 19:45:16.914863: step 41750, total loss = 0.54, batch loss = 0.26 (241.8 examples/sec; 0.033 sec/batch; 1h:27m:00s remains)
INFO - root - 2022-02-24 19:45:17.280251: step 41760, total loss = 0.55, batch loss = 0.27 (367.1 examples/sec; 0.022 sec/batch; 0h:57m:17s remains)
INFO - root - 2022-02-24 19:45:17.691782: step 41770, total loss = 0.61, batch loss = 0.33 (223.3 examples/sec; 0.036 sec/batch; 1h:34m:11s remains)
INFO - root - 2022-02-24 19:45:18.138881: step 41780, total loss = 0.67, batch loss = 0.39 (163.2 examples/sec; 0.049 sec/batch; 2h:08m:50s remains)
INFO - root - 2022-02-24 19:45:18.621479: step 41790, total loss = 0.56, batch loss = 0.28 (134.3 examples/sec; 0.060 sec/batch; 2h:36m:36s remains)
INFO - root - 2022-02-24 19:45:18.954798: step 41800, total loss = 0.51, batch loss = 0.23 (264.9 examples/sec; 0.030 sec/batch; 1h:19m:22s remains)
INFO - root - 2022-02-24 19:45:19.391383: step 41810, total loss = 0.54, batch loss = 0.26 (311.5 examples/sec; 0.026 sec/batch; 1h:07m:29s remains)
INFO - root - 2022-02-24 19:45:19.750516: step 41820, total loss = 0.52, batch loss = 0.24 (338.4 examples/sec; 0.024 sec/batch; 1h:02m:07s remains)
INFO - root - 2022-02-24 19:45:20.174219: step 41830, total loss = 0.53, batch loss = 0.25 (237.0 examples/sec; 0.034 sec/batch; 1h:28m:41s remains)
INFO - root - 2022-02-24 19:45:20.557360: step 41840, total loss = 0.59, batch loss = 0.31 (235.4 examples/sec; 0.034 sec/batch; 1h:29m:18s remains)
INFO - root - 2022-02-24 19:45:20.946180: step 41850, total loss = 0.56, batch loss = 0.28 (277.2 examples/sec; 0.029 sec/batch; 1h:15m:49s remains)
INFO - root - 2022-02-24 19:45:21.257798: step 41860, total loss = 0.52, batch loss = 0.24 (349.2 examples/sec; 0.023 sec/batch; 1h:00m:11s remains)
INFO - root - 2022-02-24 19:45:21.586144: step 41870, total loss = 0.49, batch loss = 0.21 (350.8 examples/sec; 0.023 sec/batch; 0h:59m:55s remains)
INFO - root - 2022-02-24 19:45:21.870858: step 41880, total loss = 0.62, batch loss = 0.34 (311.1 examples/sec; 0.026 sec/batch; 1h:07m:33s remains)
INFO - root - 2022-02-24 19:45:22.283922: step 41890, total loss = 0.51, batch loss = 0.23 (114.0 examples/sec; 0.070 sec/batch; 3h:04m:19s remains)
INFO - root - 2022-02-24 19:45:22.781984: step 41900, total loss = 0.49, batch loss = 0.21 (341.4 examples/sec; 0.023 sec/batch; 1h:01m:33s remains)
INFO - root - 2022-02-24 19:45:23.207457: step 41910, total loss = 0.64, batch loss = 0.36 (328.5 examples/sec; 0.024 sec/batch; 1h:03m:57s remains)
INFO - root - 2022-02-24 19:45:23.538278: step 41920, total loss = 0.68, batch loss = 0.40 (348.8 examples/sec; 0.023 sec/batch; 1h:00m:14s remains)
INFO - root - 2022-02-24 19:45:23.944385: step 41930, total loss = 0.55, batch loss = 0.27 (116.3 examples/sec; 0.069 sec/batch; 3h:00m:38s remains)
INFO - root - 2022-02-24 19:45:24.421230: step 41940, total loss = 0.51, batch loss = 0.23 (96.1 examples/sec; 0.083 sec/batch; 3h:38m:38s remains)
INFO - root - 2022-02-24 19:45:24.849636: step 41950, total loss = 0.55, batch loss = 0.27 (207.5 examples/sec; 0.039 sec/batch; 1h:41m:13s remains)
INFO - root - 2022-02-24 19:45:25.215614: step 41960, total loss = 0.58, batch loss = 0.30 (276.2 examples/sec; 0.029 sec/batch; 1h:16m:02s remains)
INFO - root - 2022-02-24 19:45:25.554044: step 41970, total loss = 0.66, batch loss = 0.38 (280.9 examples/sec; 0.028 sec/batch; 1h:14m:46s remains)
INFO - root - 2022-02-24 19:45:25.908182: step 41980, total loss = 0.52, batch loss = 0.24 (327.8 examples/sec; 0.024 sec/batch; 1h:04m:04s remains)
INFO - root - 2022-02-24 19:45:26.277983: step 41990, total loss = 0.55, batch loss = 0.27 (151.2 examples/sec; 0.053 sec/batch; 2h:18m:54s remains)
INFO - root - 2022-02-24 19:45:26.748604: step 42000, total loss = 0.54, batch loss = 0.26 (153.4 examples/sec; 0.052 sec/batch; 2h:16m:54s remains)
INFO - root - 2022-02-24 19:45:27.334711: step 42010, total loss = 0.56, batch loss = 0.28 (222.6 examples/sec; 0.036 sec/batch; 1h:34m:19s remains)
INFO - root - 2022-02-24 19:45:27.648022: step 42020, total loss = 0.55, batch loss = 0.27 (325.6 examples/sec; 0.025 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 19:45:28.032824: step 42030, total loss = 0.56, batch loss = 0.29 (180.9 examples/sec; 0.044 sec/batch; 1h:56m:04s remains)
INFO - root - 2022-02-24 19:45:28.393379: step 42040, total loss = 0.58, batch loss = 0.30 (226.5 examples/sec; 0.035 sec/batch; 1h:32m:41s remains)
INFO - root - 2022-02-24 19:45:28.843522: step 42050, total loss = 0.63, batch loss = 0.35 (80.6 examples/sec; 0.099 sec/batch; 4h:20m:24s remains)
INFO - root - 2022-02-24 19:45:29.276326: step 42060, total loss = 0.56, batch loss = 0.28 (125.6 examples/sec; 0.064 sec/batch; 2h:47m:04s remains)
INFO - root - 2022-02-24 19:45:29.619543: step 42070, total loss = 0.59, batch loss = 0.31 (362.0 examples/sec; 0.022 sec/batch; 0h:57m:58s remains)
INFO - root - 2022-02-24 19:45:29.942429: step 42080, total loss = 0.56, batch loss = 0.28 (331.5 examples/sec; 0.024 sec/batch; 1h:03m:19s remains)
INFO - root - 2022-02-24 19:45:30.224490: step 42090, total loss = 0.54, batch loss = 0.26 (223.6 examples/sec; 0.036 sec/batch; 1h:33m:52s remains)
INFO - root - 2022-02-24 19:45:30.660758: step 42100, total loss = 0.62, batch loss = 0.34 (152.6 examples/sec; 0.052 sec/batch; 2h:17m:30s remains)
INFO - root - 2022-02-24 19:45:31.144570: step 42110, total loss = 0.60, batch loss = 0.32 (345.7 examples/sec; 0.023 sec/batch; 1h:00m:41s remains)
INFO - root - 2022-02-24 19:45:31.600195: step 42120, total loss = 0.69, batch loss = 0.41 (289.5 examples/sec; 0.028 sec/batch; 1h:12m:28s remains)
INFO - root - 2022-02-24 19:45:31.953531: step 42130, total loss = 0.52, batch loss = 0.24 (221.2 examples/sec; 0.036 sec/batch; 1h:34m:52s remains)
INFO - root - 2022-02-24 19:45:32.283489: step 42140, total loss = 0.60, batch loss = 0.32 (131.6 examples/sec; 0.061 sec/batch; 2h:39m:22s remains)
INFO - root - 2022-02-24 19:45:32.732810: step 42150, total loss = 0.64, batch loss = 0.36 (100.1 examples/sec; 0.080 sec/batch; 3h:29m:34s remains)
INFO - root - 2022-02-24 19:45:33.283859: step 42160, total loss = 0.66, batch loss = 0.38 (149.8 examples/sec; 0.053 sec/batch; 2h:20m:01s remains)
INFO - root - 2022-02-24 19:45:33.800822: step 42170, total loss = 0.65, batch loss = 0.37 (267.2 examples/sec; 0.030 sec/batch; 1h:18m:30s remains)
INFO - root - 2022-02-24 19:45:34.140149: step 42180, total loss = 0.51, batch loss = 0.23 (330.9 examples/sec; 0.024 sec/batch; 1h:03m:23s remains)
INFO - root - 2022-02-24 19:45:34.556859: step 42190, total loss = 0.55, batch loss = 0.27 (240.7 examples/sec; 0.033 sec/batch; 1h:27m:08s remains)
INFO - root - 2022-02-24 19:45:35.017111: step 42200, total loss = 0.58, batch loss = 0.30 (152.4 examples/sec; 0.052 sec/batch; 2h:17m:37s remains)
INFO - root - 2022-02-24 19:45:35.534288: step 42210, total loss = 0.54, batch loss = 0.26 (154.6 examples/sec; 0.052 sec/batch; 2h:15m:39s remains)
INFO - root - 2022-02-24 19:45:36.037958: step 42220, total loss = 0.64, batch loss = 0.36 (174.4 examples/sec; 0.046 sec/batch; 2h:00m:16s remains)
INFO - root - 2022-02-24 19:45:36.420328: step 42230, total loss = 0.54, batch loss = 0.26 (293.6 examples/sec; 0.027 sec/batch; 1h:11m:24s remains)
INFO - root - 2022-02-24 19:45:36.883775: step 42240, total loss = 0.57, batch loss = 0.29 (185.7 examples/sec; 0.043 sec/batch; 1h:52m:54s remains)
INFO - root - 2022-02-24 19:45:37.390569: step 42250, total loss = 0.58, batch loss = 0.30 (158.2 examples/sec; 0.051 sec/batch; 2h:12m:31s remains)
INFO - root - 2022-02-24 19:45:38.349774: step 42260, total loss = 0.50, batch loss = 0.23 (153.1 examples/sec; 0.052 sec/batch; 2h:16m:57s remains)
INFO - root - 2022-02-24 19:45:38.716208: step 42270, total loss = 0.56, batch loss = 0.28 (216.1 examples/sec; 0.037 sec/batch; 1h:37m:01s remains)
INFO - root - 2022-02-24 19:45:39.177061: step 42280, total loss = 0.53, batch loss = 0.25 (132.7 examples/sec; 0.060 sec/batch; 2h:37m:57s remains)
INFO - root - 2022-02-24 19:45:39.656793: step 42290, total loss = 0.51, batch loss = 0.23 (145.2 examples/sec; 0.055 sec/batch; 2h:24m:19s remains)
INFO - root - 2022-02-24 19:45:40.270291: step 42300, total loss = 0.61, batch loss = 0.33 (189.0 examples/sec; 0.042 sec/batch; 1h:50m:52s remains)
INFO - root - 2022-02-24 19:45:40.763423: step 42310, total loss = 0.72, batch loss = 0.44 (259.5 examples/sec; 0.031 sec/batch; 1h:20m:45s remains)
INFO - root - 2022-02-24 19:45:41.337239: step 42320, total loss = 0.49, batch loss = 0.22 (145.4 examples/sec; 0.055 sec/batch; 2h:24m:09s remains)
INFO - root - 2022-02-24 19:45:41.712662: step 42330, total loss = 0.68, batch loss = 0.41 (291.3 examples/sec; 0.027 sec/batch; 1h:11m:56s remains)
INFO - root - 2022-02-24 19:45:42.126317: step 42340, total loss = 0.53, batch loss = 0.25 (177.3 examples/sec; 0.045 sec/batch; 1h:58m:12s remains)
INFO - root - 2022-02-24 19:45:42.626238: step 42350, total loss = 0.58, batch loss = 0.30 (117.8 examples/sec; 0.068 sec/batch; 2h:57m:54s remains)
INFO - root - 2022-02-24 19:45:43.437872: step 42360, total loss = 0.59, batch loss = 0.32 (169.9 examples/sec; 0.047 sec/batch; 2h:03m:19s remains)
INFO - root - 2022-02-24 19:45:43.782818: step 42370, total loss = 0.76, batch loss = 0.48 (182.0 examples/sec; 0.044 sec/batch; 1h:55m:06s remains)
INFO - root - 2022-02-24 19:45:44.148726: step 42380, total loss = 0.56, batch loss = 0.28 (192.7 examples/sec; 0.042 sec/batch; 1h:48m:42s remains)
INFO - root - 2022-02-24 19:45:44.642207: step 42390, total loss = 0.58, batch loss = 0.30 (348.4 examples/sec; 0.023 sec/batch; 1h:00m:07s remains)
INFO - root - 2022-02-24 19:45:45.014295: step 42400, total loss = 0.54, batch loss = 0.26 (128.6 examples/sec; 0.062 sec/batch; 2h:42m:56s remains)
INFO - root - 2022-02-24 19:45:45.456512: step 42410, total loss = 0.56, batch loss = 0.28 (133.7 examples/sec; 0.060 sec/batch; 2h:36m:40s remains)
INFO - root - 2022-02-24 19:45:45.807481: step 42420, total loss = 0.56, batch loss = 0.28 (214.6 examples/sec; 0.037 sec/batch; 1h:37m:35s remains)
INFO - root - 2022-02-24 19:45:46.279420: step 42430, total loss = 0.56, batch loss = 0.29 (176.9 examples/sec; 0.045 sec/batch; 1h:58m:23s remains)
INFO - root - 2022-02-24 19:45:46.706346: step 42440, total loss = 0.65, batch loss = 0.37 (179.1 examples/sec; 0.045 sec/batch; 1h:56m:54s remains)
INFO - root - 2022-02-24 19:45:47.121957: step 42450, total loss = 0.63, batch loss = 0.35 (244.3 examples/sec; 0.033 sec/batch; 1h:25m:42s remains)
INFO - root - 2022-02-24 19:45:47.496823: step 42460, total loss = 0.59, batch loss = 0.31 (250.8 examples/sec; 0.032 sec/batch; 1h:23m:29s remains)
INFO - root - 2022-02-24 19:45:47.874434: step 42470, total loss = 0.58, batch loss = 0.31 (278.3 examples/sec; 0.029 sec/batch; 1h:15m:14s remains)
INFO - root - 2022-02-24 19:45:48.255509: step 42480, total loss = 0.68, batch loss = 0.40 (329.6 examples/sec; 0.024 sec/batch; 1h:03m:31s remains)
INFO - root - 2022-02-24 19:45:48.648946: step 42490, total loss = 0.65, batch loss = 0.37 (351.7 examples/sec; 0.023 sec/batch; 0h:59m:31s remains)
INFO - root - 2022-02-24 19:45:49.021805: step 42500, total loss = 0.54, batch loss = 0.26 (331.3 examples/sec; 0.024 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 19:45:49.367248: step 42510, total loss = 0.57, batch loss = 0.29 (301.3 examples/sec; 0.027 sec/batch; 1h:09m:28s remains)
INFO - root - 2022-02-24 19:45:49.698631: step 42520, total loss = 0.50, batch loss = 0.23 (345.4 examples/sec; 0.023 sec/batch; 1h:00m:36s remains)
INFO - root - 2022-02-24 19:45:50.085712: step 42530, total loss = 0.63, batch loss = 0.36 (243.7 examples/sec; 0.033 sec/batch; 1h:25m:52s remains)
INFO - root - 2022-02-24 19:45:50.556257: step 42540, total loss = 0.56, batch loss = 0.28 (125.1 examples/sec; 0.064 sec/batch; 2h:47m:18s remains)
INFO - root - 2022-02-24 19:45:50.937853: step 42550, total loss = 0.52, batch loss = 0.24 (201.3 examples/sec; 0.040 sec/batch; 1h:43m:58s remains)
INFO - root - 2022-02-24 19:45:51.282170: step 42560, total loss = 0.53, batch loss = 0.25 (330.0 examples/sec; 0.024 sec/batch; 1h:03m:24s remains)
INFO - root - 2022-02-24 19:45:51.574138: step 42570, total loss = 0.60, batch loss = 0.33 (349.6 examples/sec; 0.023 sec/batch; 0h:59m:51s remains)
INFO - root - 2022-02-24 19:45:52.025600: step 42580, total loss = 0.62, batch loss = 0.34 (360.8 examples/sec; 0.022 sec/batch; 0h:57m:59s remains)
INFO - root - 2022-02-24 19:45:52.483009: step 42590, total loss = 0.73, batch loss = 0.45 (318.4 examples/sec; 0.025 sec/batch; 1h:05m:42s remains)
INFO - root - 2022-02-24 19:45:52.860660: step 42600, total loss = 0.83, batch loss = 0.55 (246.9 examples/sec; 0.032 sec/batch; 1h:24m:43s remains)
INFO - root - 2022-02-24 19:45:53.361362: step 42610, total loss = 0.48, batch loss = 0.20 (266.5 examples/sec; 0.030 sec/batch; 1h:18m:29s remains)
INFO - root - 2022-02-24 19:45:53.675827: step 42620, total loss = 0.52, batch loss = 0.25 (313.4 examples/sec; 0.026 sec/batch; 1h:06m:44s remains)
INFO - root - 2022-02-24 19:45:54.076268: step 42630, total loss = 0.57, batch loss = 0.29 (277.2 examples/sec; 0.029 sec/batch; 1h:15m:26s remains)
INFO - root - 2022-02-24 19:45:54.524844: step 42640, total loss = 0.62, batch loss = 0.34 (298.1 examples/sec; 0.027 sec/batch; 1h:10m:09s remains)
INFO - root - 2022-02-24 19:45:54.916321: step 42650, total loss = 0.54, batch loss = 0.26 (328.8 examples/sec; 0.024 sec/batch; 1h:03m:36s remains)
INFO - root - 2022-02-24 19:45:55.235108: step 42660, total loss = 0.56, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 1h:03m:22s remains)
INFO - root - 2022-02-24 19:45:55.671218: step 42670, total loss = 0.65, batch loss = 0.37 (329.0 examples/sec; 0.024 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 19:45:56.102221: step 42680, total loss = 0.62, batch loss = 0.34 (378.8 examples/sec; 0.021 sec/batch; 0h:55m:11s remains)
INFO - root - 2022-02-24 19:45:56.475555: step 42690, total loss = 0.49, batch loss = 0.22 (206.9 examples/sec; 0.039 sec/batch; 1h:41m:04s remains)
INFO - root - 2022-02-24 19:45:56.871690: step 42700, total loss = 0.59, batch loss = 0.31 (372.2 examples/sec; 0.021 sec/batch; 0h:56m:10s remains)
INFO - root - 2022-02-24 19:45:57.264120: step 42710, total loss = 0.53, batch loss = 0.25 (222.9 examples/sec; 0.036 sec/batch; 1h:33m:47s remains)
INFO - root - 2022-02-24 19:45:57.620758: step 42720, total loss = 0.57, batch loss = 0.29 (197.2 examples/sec; 0.041 sec/batch; 1h:46m:01s remains)
INFO - root - 2022-02-24 19:45:58.054725: step 42730, total loss = 0.61, batch loss = 0.33 (254.1 examples/sec; 0.031 sec/batch; 1h:22m:15s remains)
INFO - root - 2022-02-24 19:45:58.495364: step 42740, total loss = 0.59, batch loss = 0.31 (346.8 examples/sec; 0.023 sec/batch; 1h:00m:15s remains)
INFO - root - 2022-02-24 19:45:58.918029: step 42750, total loss = 0.53, batch loss = 0.25 (331.4 examples/sec; 0.024 sec/batch; 1h:03m:03s remains)
INFO - root - 2022-02-24 19:45:59.309147: step 42760, total loss = 0.56, batch loss = 0.28 (227.9 examples/sec; 0.035 sec/batch; 1h:31m:41s remains)
INFO - root - 2022-02-24 19:45:59.649121: step 42770, total loss = 0.73, batch loss = 0.45 (277.9 examples/sec; 0.029 sec/batch; 1h:15m:11s remains)
INFO - root - 2022-02-24 19:46:00.099724: step 42780, total loss = 0.56, batch loss = 0.28 (126.5 examples/sec; 0.063 sec/batch; 2h:45m:10s remains)
INFO - root - 2022-02-24 19:46:00.526419: step 42790, total loss = 0.57, batch loss = 0.29 (263.3 examples/sec; 0.030 sec/batch; 1h:19m:22s remains)
INFO - root - 2022-02-24 19:46:00.895783: step 42800, total loss = 0.60, batch loss = 0.32 (154.0 examples/sec; 0.052 sec/batch; 2h:15m:38s remains)
INFO - root - 2022-02-24 19:46:01.317236: step 42810, total loss = 0.65, batch loss = 0.37 (307.9 examples/sec; 0.026 sec/batch; 1h:07m:50s remains)
INFO - root - 2022-02-24 19:46:01.669995: step 42820, total loss = 0.67, batch loss = 0.39 (115.8 examples/sec; 0.069 sec/batch; 3h:00m:20s remains)
INFO - root - 2022-02-24 19:46:02.096782: step 42830, total loss = 0.57, batch loss = 0.29 (202.7 examples/sec; 0.039 sec/batch; 1h:43m:03s remains)
INFO - root - 2022-02-24 19:46:02.515884: step 42840, total loss = 0.69, batch loss = 0.41 (137.8 examples/sec; 0.058 sec/batch; 2h:31m:36s remains)
INFO - root - 2022-02-24 19:46:02.947021: step 42850, total loss = 0.62, batch loss = 0.34 (162.1 examples/sec; 0.049 sec/batch; 2h:08m:53s remains)
INFO - root - 2022-02-24 19:46:03.426199: step 42860, total loss = 0.63, batch loss = 0.35 (78.2 examples/sec; 0.102 sec/batch; 4h:27m:00s remains)
INFO - root - 2022-02-24 19:46:03.783806: step 42870, total loss = 0.57, batch loss = 0.29 (341.9 examples/sec; 0.023 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 19:46:04.143320: step 42880, total loss = 0.64, batch loss = 0.37 (172.5 examples/sec; 0.046 sec/batch; 2h:01m:05s remains)
INFO - root - 2022-02-24 19:46:04.495279: step 42890, total loss = 0.68, batch loss = 0.40 (361.1 examples/sec; 0.022 sec/batch; 0h:57m:49s remains)
INFO - root - 2022-02-24 19:46:04.891931: step 42900, total loss = 0.60, batch loss = 0.32 (195.5 examples/sec; 0.041 sec/batch; 1h:46m:49s remains)
INFO - root - 2022-02-24 19:46:05.345987: step 42910, total loss = 0.57, batch loss = 0.29 (338.0 examples/sec; 0.024 sec/batch; 1h:01m:46s remains)
INFO - root - 2022-02-24 19:46:05.709000: step 42920, total loss = 0.68, batch loss = 0.40 (328.3 examples/sec; 0.024 sec/batch; 1h:03m:34s remains)
INFO - root - 2022-02-24 19:46:06.022392: step 42930, total loss = 0.50, batch loss = 0.22 (335.5 examples/sec; 0.024 sec/batch; 1h:02m:13s remains)
INFO - root - 2022-02-24 19:46:06.330482: step 42940, total loss = 0.50, batch loss = 0.22 (183.2 examples/sec; 0.044 sec/batch; 1h:53m:57s remains)
INFO - root - 2022-02-24 19:46:06.747849: step 42950, total loss = 0.55, batch loss = 0.27 (325.9 examples/sec; 0.025 sec/batch; 1h:04m:02s remains)
INFO - root - 2022-02-24 19:46:07.171104: step 42960, total loss = 0.62, batch loss = 0.34 (219.6 examples/sec; 0.036 sec/batch; 1h:35m:02s remains)
INFO - root - 2022-02-24 19:46:07.475029: step 42970, total loss = 0.54, batch loss = 0.27 (334.9 examples/sec; 0.024 sec/batch; 1h:02m:19s remains)
INFO - root - 2022-02-24 19:46:07.784690: step 42980, total loss = 0.50, batch loss = 0.22 (302.9 examples/sec; 0.026 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 19:46:08.170812: step 42990, total loss = 0.58, batch loss = 0.30 (329.4 examples/sec; 0.024 sec/batch; 1h:03m:20s remains)
INFO - root - 2022-02-24 19:46:08.588351: step 43000, total loss = 0.55, batch loss = 0.27 (231.7 examples/sec; 0.035 sec/batch; 1h:30m:03s remains)
INFO - root - 2022-02-24 19:46:09.040710: step 43010, total loss = 0.61, batch loss = 0.33 (161.6 examples/sec; 0.050 sec/batch; 2h:09m:06s remains)
INFO - root - 2022-02-24 19:46:09.437184: step 43020, total loss = 0.60, batch loss = 0.32 (174.3 examples/sec; 0.046 sec/batch; 1h:59m:42s remains)
INFO - root - 2022-02-24 19:46:09.784026: step 43030, total loss = 0.58, batch loss = 0.31 (344.3 examples/sec; 0.023 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 19:46:10.128045: step 43040, total loss = 0.64, batch loss = 0.37 (368.6 examples/sec; 0.022 sec/batch; 0h:56m:35s remains)
INFO - root - 2022-02-24 19:46:10.485974: step 43050, total loss = 0.57, batch loss = 0.29 (151.7 examples/sec; 0.053 sec/batch; 2h:17m:30s remains)
INFO - root - 2022-02-24 19:46:10.868917: step 43060, total loss = 0.50, batch loss = 0.22 (341.0 examples/sec; 0.023 sec/batch; 1h:01m:10s remains)
INFO - root - 2022-02-24 19:46:11.284688: step 43070, total loss = 0.56, batch loss = 0.28 (141.0 examples/sec; 0.057 sec/batch; 2h:27m:55s remains)
INFO - root - 2022-02-24 19:46:11.641860: step 43080, total loss = 0.59, batch loss = 0.31 (149.8 examples/sec; 0.053 sec/batch; 2h:19m:14s remains)
INFO - root - 2022-02-24 19:46:11.977773: step 43090, total loss = 0.63, batch loss = 0.35 (321.5 examples/sec; 0.025 sec/batch; 1h:04m:51s remains)
INFO - root - 2022-02-24 19:46:12.329147: step 43100, total loss = 0.54, batch loss = 0.27 (196.1 examples/sec; 0.041 sec/batch; 1h:46m:19s remains)
INFO - root - 2022-02-24 19:46:12.749025: step 43110, total loss = 0.53, batch loss = 0.25 (222.7 examples/sec; 0.036 sec/batch; 1h:33m:38s remains)
INFO - root - 2022-02-24 19:46:13.251862: step 43120, total loss = 0.56, batch loss = 0.28 (111.2 examples/sec; 0.072 sec/batch; 3h:07m:35s remains)
INFO - root - 2022-02-24 19:46:13.777584: step 43130, total loss = 0.79, batch loss = 0.51 (202.7 examples/sec; 0.039 sec/batch; 1h:42m:52s remains)
INFO - root - 2022-02-24 19:46:14.128611: step 43140, total loss = 0.72, batch loss = 0.44 (259.6 examples/sec; 0.031 sec/batch; 1h:20m:18s remains)
INFO - root - 2022-02-24 19:46:14.485072: step 43150, total loss = 0.76, batch loss = 0.48 (315.2 examples/sec; 0.025 sec/batch; 1h:06m:08s remains)
INFO - root - 2022-02-24 19:46:14.858589: step 43160, total loss = 0.60, batch loss = 0.32 (190.2 examples/sec; 0.042 sec/batch; 1h:49m:34s remains)
INFO - root - 2022-02-24 19:46:15.286102: step 43170, total loss = 0.61, batch loss = 0.33 (346.3 examples/sec; 0.023 sec/batch; 1h:00m:11s remains)
INFO - root - 2022-02-24 19:46:15.834183: step 43180, total loss = 0.55, batch loss = 0.27 (179.6 examples/sec; 0.045 sec/batch; 1h:56m:01s remains)
INFO - root - 2022-02-24 19:46:16.444755: step 43190, total loss = 0.60, batch loss = 0.32 (111.2 examples/sec; 0.072 sec/batch; 3h:07m:20s remains)
INFO - root - 2022-02-24 19:46:16.919053: step 43200, total loss = 0.50, batch loss = 0.22 (278.8 examples/sec; 0.029 sec/batch; 1h:14m:44s remains)
INFO - root - 2022-02-24 19:46:17.478516: step 43210, total loss = 0.60, batch loss = 0.32 (327.3 examples/sec; 0.024 sec/batch; 1h:03m:39s remains)
INFO - root - 2022-02-24 19:46:17.963441: step 43220, total loss = 0.59, batch loss = 0.31 (346.7 examples/sec; 0.023 sec/batch; 1h:00m:06s remains)
INFO - root - 2022-02-24 19:46:18.448969: step 43230, total loss = 0.55, batch loss = 0.28 (118.2 examples/sec; 0.068 sec/batch; 2h:56m:19s remains)
INFO - root - 2022-02-24 19:46:19.275313: step 43240, total loss = 0.62, batch loss = 0.34 (201.0 examples/sec; 0.040 sec/batch; 1h:43m:39s remains)
INFO - root - 2022-02-24 19:46:19.705427: step 43250, total loss = 0.53, batch loss = 0.25 (96.3 examples/sec; 0.083 sec/batch; 3h:36m:19s remains)
INFO - root - 2022-02-24 19:46:20.185594: step 43260, total loss = 0.50, batch loss = 0.22 (156.6 examples/sec; 0.051 sec/batch; 2h:13m:01s remains)
INFO - root - 2022-02-24 19:46:20.618811: step 43270, total loss = 0.63, batch loss = 0.35 (170.9 examples/sec; 0.047 sec/batch; 2h:01m:51s remains)
INFO - root - 2022-02-24 19:46:21.053927: step 43280, total loss = 0.55, batch loss = 0.27 (271.2 examples/sec; 0.029 sec/batch; 1h:16m:48s remains)
INFO - root - 2022-02-24 19:46:21.471196: step 43290, total loss = 0.73, batch loss = 0.46 (172.2 examples/sec; 0.046 sec/batch; 2h:00m:55s remains)
INFO - root - 2022-02-24 19:46:21.879111: step 43300, total loss = 0.60, batch loss = 0.33 (140.3 examples/sec; 0.057 sec/batch; 2h:28m:24s remains)
INFO - root - 2022-02-24 19:46:22.443182: step 43310, total loss = 0.77, batch loss = 0.49 (131.4 examples/sec; 0.061 sec/batch; 2h:38m:30s remains)
INFO - root - 2022-02-24 19:46:22.883813: step 43320, total loss = 0.57, batch loss = 0.29 (188.3 examples/sec; 0.042 sec/batch; 1h:50m:36s remains)
INFO - root - 2022-02-24 19:46:23.360646: step 43330, total loss = 0.70, batch loss = 0.42 (232.0 examples/sec; 0.034 sec/batch; 1h:29m:45s remains)
INFO - root - 2022-02-24 19:46:24.177850: step 43340, total loss = 0.47, batch loss = 0.19 (292.1 examples/sec; 0.027 sec/batch; 1h:11m:16s remains)
INFO - root - 2022-02-24 19:46:24.608427: step 43350, total loss = 0.62, batch loss = 0.34 (206.4 examples/sec; 0.039 sec/batch; 1h:40m:53s remains)
INFO - root - 2022-02-24 19:46:25.079583: step 43360, total loss = 0.63, batch loss = 0.35 (104.9 examples/sec; 0.076 sec/batch; 3h:18m:27s remains)
INFO - root - 2022-02-24 19:46:25.393152: step 43370, total loss = 0.59, batch loss = 0.31 (222.6 examples/sec; 0.036 sec/batch; 1h:33m:29s remains)
INFO - root - 2022-02-24 19:46:25.779488: step 43380, total loss = 0.55, batch loss = 0.27 (283.8 examples/sec; 0.028 sec/batch; 1h:13m:21s remains)
INFO - root - 2022-02-24 19:46:26.081306: step 43390, total loss = 0.52, batch loss = 0.24 (211.5 examples/sec; 0.038 sec/batch; 1h:38m:23s remains)
INFO - root - 2022-02-24 19:46:26.502940: step 43400, total loss = 0.58, batch loss = 0.30 (110.6 examples/sec; 0.072 sec/batch; 3h:08m:09s remains)
INFO - root - 2022-02-24 19:46:26.976922: step 43410, total loss = 0.48, batch loss = 0.21 (156.0 examples/sec; 0.051 sec/batch; 2h:13m:23s remains)
INFO - root - 2022-02-24 19:46:27.389890: step 43420, total loss = 0.57, batch loss = 0.29 (192.4 examples/sec; 0.042 sec/batch; 1h:48m:09s remains)
INFO - root - 2022-02-24 19:46:27.725922: step 43430, total loss = 0.61, batch loss = 0.33 (282.7 examples/sec; 0.028 sec/batch; 1h:13m:35s remains)
INFO - root - 2022-02-24 19:46:28.073138: step 43440, total loss = 0.56, batch loss = 0.28 (296.3 examples/sec; 0.027 sec/batch; 1h:10m:13s remains)
INFO - root - 2022-02-24 19:46:28.392921: step 43450, total loss = 0.55, batch loss = 0.27 (317.1 examples/sec; 0.025 sec/batch; 1h:05m:36s remains)
INFO - root - 2022-02-24 19:46:28.840730: step 43460, total loss = 0.45, batch loss = 0.17 (225.9 examples/sec; 0.035 sec/batch; 1h:32m:07s remains)
INFO - root - 2022-02-24 19:46:29.268337: step 43470, total loss = 0.78, batch loss = 0.50 (270.8 examples/sec; 0.030 sec/batch; 1h:16m:49s remains)
INFO - root - 2022-02-24 19:46:29.732770: step 43480, total loss = 0.60, batch loss = 0.32 (182.8 examples/sec; 0.044 sec/batch; 1h:53m:47s remains)
INFO - root - 2022-02-24 19:46:30.110500: step 43490, total loss = 0.61, batch loss = 0.33 (246.1 examples/sec; 0.033 sec/batch; 1h:24m:32s remains)
INFO - root - 2022-02-24 19:46:30.461702: step 43500, total loss = 0.62, batch loss = 0.35 (224.1 examples/sec; 0.036 sec/batch; 1h:32m:48s remains)
INFO - root - 2022-02-24 19:46:30.936437: step 43510, total loss = 0.54, batch loss = 0.26 (174.1 examples/sec; 0.046 sec/batch; 1h:59m:29s remains)
INFO - root - 2022-02-24 19:46:31.376883: step 43520, total loss = 0.53, batch loss = 0.25 (142.2 examples/sec; 0.056 sec/batch; 2h:26m:12s remains)
INFO - root - 2022-02-24 19:46:31.743946: step 43530, total loss = 0.56, batch loss = 0.29 (166.0 examples/sec; 0.048 sec/batch; 2h:05m:14s remains)
INFO - root - 2022-02-24 19:46:32.108893: step 43540, total loss = 0.78, batch loss = 0.51 (157.0 examples/sec; 0.051 sec/batch; 2h:12m:28s remains)
INFO - root - 2022-02-24 19:46:32.447822: step 43550, total loss = 0.60, batch loss = 0.32 (174.3 examples/sec; 0.046 sec/batch; 1h:59m:19s remains)
INFO - root - 2022-02-24 19:46:32.832931: step 43560, total loss = 0.64, batch loss = 0.36 (126.9 examples/sec; 0.063 sec/batch; 2h:43m:53s remains)
INFO - root - 2022-02-24 19:46:33.174778: step 43570, total loss = 0.60, batch loss = 0.32 (342.8 examples/sec; 0.023 sec/batch; 1h:00m:38s remains)
INFO - root - 2022-02-24 19:46:33.603978: step 43580, total loss = 0.59, batch loss = 0.31 (196.5 examples/sec; 0.041 sec/batch; 1h:45m:46s remains)
INFO - root - 2022-02-24 19:46:33.935538: step 43590, total loss = 0.60, batch loss = 0.32 (359.3 examples/sec; 0.022 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 19:46:34.312089: step 43600, total loss = 0.53, batch loss = 0.25 (177.2 examples/sec; 0.045 sec/batch; 1h:57m:20s remains)
INFO - root - 2022-02-24 19:46:34.656556: step 43610, total loss = 0.66, batch loss = 0.38 (295.3 examples/sec; 0.027 sec/batch; 1h:10m:22s remains)
INFO - root - 2022-02-24 19:46:35.019486: step 43620, total loss = 0.53, batch loss = 0.25 (104.0 examples/sec; 0.077 sec/batch; 3h:19m:52s remains)
INFO - root - 2022-02-24 19:46:35.349311: step 43630, total loss = 0.52, batch loss = 0.24 (164.4 examples/sec; 0.049 sec/batch; 2h:06m:22s remains)
INFO - root - 2022-02-24 19:46:35.731289: step 43640, total loss = 0.71, batch loss = 0.43 (176.1 examples/sec; 0.045 sec/batch; 1h:58m:02s remains)
INFO - root - 2022-02-24 19:46:36.119486: step 43650, total loss = 0.57, batch loss = 0.29 (337.1 examples/sec; 0.024 sec/batch; 1h:01m:38s remains)
INFO - root - 2022-02-24 19:46:36.452463: step 43660, total loss = 0.67, batch loss = 0.40 (326.3 examples/sec; 0.025 sec/batch; 1h:03m:40s remains)
INFO - root - 2022-02-24 19:46:36.824304: step 43670, total loss = 0.49, batch loss = 0.21 (163.3 examples/sec; 0.049 sec/batch; 2h:07m:14s remains)
INFO - root - 2022-02-24 19:46:37.191805: step 43680, total loss = 0.56, batch loss = 0.29 (113.8 examples/sec; 0.070 sec/batch; 3h:02m:34s remains)
INFO - root - 2022-02-24 19:46:37.550661: step 43690, total loss = 0.65, batch loss = 0.37 (234.2 examples/sec; 0.034 sec/batch; 1h:28m:42s remains)
INFO - root - 2022-02-24 19:46:37.944092: step 43700, total loss = 0.50, batch loss = 0.22 (148.1 examples/sec; 0.054 sec/batch; 2h:20m:14s remains)
INFO - root - 2022-02-24 19:46:38.415867: step 43710, total loss = 0.62, batch loss = 0.34 (326.8 examples/sec; 0.024 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 19:46:38.770394: step 43720, total loss = 0.61, batch loss = 0.33 (339.9 examples/sec; 0.024 sec/batch; 1h:01m:06s remains)
INFO - root - 2022-02-24 19:46:39.059929: step 43730, total loss = 0.62, batch loss = 0.34 (329.0 examples/sec; 0.024 sec/batch; 1h:03m:07s remains)
INFO - root - 2022-02-24 19:46:39.512828: step 43740, total loss = 0.72, batch loss = 0.44 (137.9 examples/sec; 0.058 sec/batch; 2h:30m:34s remains)
INFO - root - 2022-02-24 19:46:39.998890: step 43750, total loss = 0.50, batch loss = 0.22 (104.9 examples/sec; 0.076 sec/batch; 3h:17m:54s remains)
INFO - root - 2022-02-24 19:46:40.418319: step 43760, total loss = 0.59, batch loss = 0.31 (108.7 examples/sec; 0.074 sec/batch; 3h:10m:59s remains)
INFO - root - 2022-02-24 19:46:40.786582: step 43770, total loss = 0.54, batch loss = 0.26 (242.5 examples/sec; 0.033 sec/batch; 1h:25m:38s remains)
INFO - root - 2022-02-24 19:46:41.129300: step 43780, total loss = 0.57, batch loss = 0.30 (281.4 examples/sec; 0.028 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 19:46:41.428601: step 43790, total loss = 0.55, batch loss = 0.28 (359.7 examples/sec; 0.022 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 19:46:41.827738: step 43800, total loss = 0.60, batch loss = 0.32 (372.2 examples/sec; 0.021 sec/batch; 0h:55m:46s remains)
INFO - root - 2022-02-24 19:46:42.355331: step 43810, total loss = 0.65, batch loss = 0.37 (133.9 examples/sec; 0.060 sec/batch; 2h:35m:01s remains)
INFO - root - 2022-02-24 19:46:42.681056: step 43820, total loss = 0.58, batch loss = 0.31 (263.2 examples/sec; 0.030 sec/batch; 1h:18m:52s remains)
INFO - root - 2022-02-24 19:46:43.067885: step 43830, total loss = 0.52, batch loss = 0.24 (141.0 examples/sec; 0.057 sec/batch; 2h:27m:14s remains)
INFO - root - 2022-02-24 19:46:43.370102: step 43840, total loss = 0.88, batch loss = 0.60 (245.0 examples/sec; 0.033 sec/batch; 1h:24m:42s remains)
INFO - root - 2022-02-24 19:46:43.735163: step 43850, total loss = 0.55, batch loss = 0.27 (123.5 examples/sec; 0.065 sec/batch; 2h:48m:02s remains)
INFO - root - 2022-02-24 19:46:44.140641: step 43860, total loss = 0.59, batch loss = 0.31 (231.9 examples/sec; 0.035 sec/batch; 1h:29m:29s remains)
INFO - root - 2022-02-24 19:46:44.633432: step 43870, total loss = 0.65, batch loss = 0.37 (115.4 examples/sec; 0.069 sec/batch; 2h:59m:53s remains)
INFO - root - 2022-02-24 19:46:44.945268: step 43880, total loss = 0.52, batch loss = 0.24 (277.4 examples/sec; 0.029 sec/batch; 1h:14m:47s remains)
INFO - root - 2022-02-24 19:46:45.282134: step 43890, total loss = 0.56, batch loss = 0.29 (243.9 examples/sec; 0.033 sec/batch; 1h:25m:04s remains)
INFO - root - 2022-02-24 19:46:45.593089: step 43900, total loss = 0.58, batch loss = 0.30 (251.0 examples/sec; 0.032 sec/batch; 1h:22m:38s remains)
INFO - root - 2022-02-24 19:46:46.018620: step 43910, total loss = 0.64, batch loss = 0.36 (126.9 examples/sec; 0.063 sec/batch; 2h:43m:30s remains)
INFO - root - 2022-02-24 19:46:46.427115: step 43920, total loss = 0.61, batch loss = 0.33 (183.7 examples/sec; 0.044 sec/batch; 1h:52m:55s remains)
INFO - root - 2022-02-24 19:46:46.930705: step 43930, total loss = 0.62, batch loss = 0.34 (150.3 examples/sec; 0.053 sec/batch; 2h:17m:59s remains)
INFO - root - 2022-02-24 19:46:47.196933: step 43940, total loss = 0.56, batch loss = 0.28 (252.4 examples/sec; 0.032 sec/batch; 1h:22m:10s remains)
INFO - root - 2022-02-24 19:46:47.549353: step 43950, total loss = 0.61, batch loss = 0.33 (250.6 examples/sec; 0.032 sec/batch; 1h:22m:46s remains)
INFO - root - 2022-02-24 19:46:47.802200: step 43960, total loss = 0.80, batch loss = 0.52 (331.0 examples/sec; 0.024 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:46:48.167842: step 43970, total loss = 0.62, batch loss = 0.34 (347.5 examples/sec; 0.023 sec/batch; 0h:59m:40s remains)
INFO - root - 2022-02-24 19:46:48.598362: step 43980, total loss = 0.69, batch loss = 0.42 (343.2 examples/sec; 0.023 sec/batch; 1h:00m:25s remains)
INFO - root - 2022-02-24 19:46:48.983044: step 43990, total loss = 0.67, batch loss = 0.39 (315.6 examples/sec; 0.025 sec/batch; 1h:05m:41s remains)
INFO - root - 2022-02-24 19:46:49.347428: step 44000, total loss = 0.58, batch loss = 0.30 (288.2 examples/sec; 0.028 sec/batch; 1h:11m:57s remains)
INFO - root - 2022-02-24 19:46:49.726772: step 44010, total loss = 0.52, batch loss = 0.24 (210.4 examples/sec; 0.038 sec/batch; 1h:38m:33s remains)
INFO - root - 2022-02-24 19:46:50.120755: step 44020, total loss = 0.58, batch loss = 0.30 (331.5 examples/sec; 0.024 sec/batch; 1h:02m:32s remains)
INFO - root - 2022-02-24 19:46:50.573681: step 44030, total loss = 0.56, batch loss = 0.28 (108.4 examples/sec; 0.074 sec/batch; 3h:11m:17s remains)
INFO - root - 2022-02-24 19:46:50.930524: step 44040, total loss = 0.52, batch loss = 0.24 (296.7 examples/sec; 0.027 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 19:46:51.266846: step 44050, total loss = 0.51, batch loss = 0.23 (201.1 examples/sec; 0.040 sec/batch; 1h:43m:02s remains)
INFO - root - 2022-02-24 19:46:51.672220: step 44060, total loss = 0.54, batch loss = 0.26 (148.9 examples/sec; 0.054 sec/batch; 2h:19m:13s remains)
INFO - root - 2022-02-24 19:46:52.060682: step 44070, total loss = 0.63, batch loss = 0.35 (143.1 examples/sec; 0.056 sec/batch; 2h:24m:46s remains)
INFO - root - 2022-02-24 19:46:52.517464: step 44080, total loss = 0.56, batch loss = 0.28 (136.7 examples/sec; 0.059 sec/batch; 2h:31m:35s remains)
INFO - root - 2022-02-24 19:46:52.967409: step 44090, total loss = 0.56, batch loss = 0.28 (138.4 examples/sec; 0.058 sec/batch; 2h:29m:44s remains)
INFO - root - 2022-02-24 19:46:53.335571: step 44100, total loss = 0.53, batch loss = 0.25 (276.7 examples/sec; 0.029 sec/batch; 1h:14m:53s remains)
INFO - root - 2022-02-24 19:46:53.722906: step 44110, total loss = 0.58, batch loss = 0.30 (270.5 examples/sec; 0.030 sec/batch; 1h:16m:35s remains)
INFO - root - 2022-02-24 19:46:54.136666: step 44120, total loss = 0.57, batch loss = 0.29 (233.9 examples/sec; 0.034 sec/batch; 1h:28m:34s remains)
INFO - root - 2022-02-24 19:46:54.544795: step 44130, total loss = 0.55, batch loss = 0.27 (284.6 examples/sec; 0.028 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 19:46:55.019951: step 44140, total loss = 0.64, batch loss = 0.36 (235.0 examples/sec; 0.034 sec/batch; 1h:28m:09s remains)
INFO - root - 2022-02-24 19:46:55.486541: step 44150, total loss = 0.61, batch loss = 0.33 (109.7 examples/sec; 0.073 sec/batch; 3h:08m:45s remains)
INFO - root - 2022-02-24 19:46:55.972895: step 44160, total loss = 0.70, batch loss = 0.42 (135.0 examples/sec; 0.059 sec/batch; 2h:33m:26s remains)
INFO - root - 2022-02-24 19:46:56.350464: step 44170, total loss = 0.59, batch loss = 0.31 (146.6 examples/sec; 0.055 sec/batch; 2h:21m:18s remains)
INFO - root - 2022-02-24 19:46:56.732186: step 44180, total loss = 0.58, batch loss = 0.30 (222.2 examples/sec; 0.036 sec/batch; 1h:33m:12s remains)
INFO - root - 2022-02-24 19:46:57.296561: step 44190, total loss = 0.53, batch loss = 0.26 (256.6 examples/sec; 0.031 sec/batch; 1h:20m:42s remains)
INFO - root - 2022-02-24 19:46:57.808680: step 44200, total loss = 0.59, batch loss = 0.31 (183.4 examples/sec; 0.044 sec/batch; 1h:52m:53s remains)
INFO - root - 2022-02-24 19:46:58.256298: step 44210, total loss = 0.64, batch loss = 0.36 (310.3 examples/sec; 0.026 sec/batch; 1h:06m:43s remains)
INFO - root - 2022-02-24 19:46:59.078763: step 44220, total loss = 0.59, batch loss = 0.31 (24.6 examples/sec; 0.325 sec/batch; 14h:02m:12s remains)
INFO - root - 2022-02-24 19:46:59.496696: step 44230, total loss = 0.58, batch loss = 0.30 (255.1 examples/sec; 0.031 sec/batch; 1h:21m:10s remains)
INFO - root - 2022-02-24 19:46:59.994904: step 44240, total loss = 0.53, batch loss = 0.25 (190.5 examples/sec; 0.042 sec/batch; 1h:48m:41s remains)
INFO - root - 2022-02-24 19:47:00.491091: step 44250, total loss = 0.48, batch loss = 0.20 (337.0 examples/sec; 0.024 sec/batch; 1h:01m:25s remains)
INFO - root - 2022-02-24 19:47:01.071495: step 44260, total loss = 0.55, batch loss = 0.28 (335.8 examples/sec; 0.024 sec/batch; 1h:01m:38s remains)
INFO - root - 2022-02-24 19:47:01.530839: step 44270, total loss = 0.54, batch loss = 0.26 (185.7 examples/sec; 0.043 sec/batch; 1h:51m:26s remains)
INFO - root - 2022-02-24 19:47:01.980643: step 44280, total loss = 0.59, batch loss = 0.31 (294.0 examples/sec; 0.027 sec/batch; 1h:10m:24s remains)
INFO - root - 2022-02-24 19:47:02.483924: step 44290, total loss = 0.58, batch loss = 0.31 (94.6 examples/sec; 0.085 sec/batch; 3h:38m:49s remains)
INFO - root - 2022-02-24 19:47:02.879145: step 44300, total loss = 0.60, batch loss = 0.32 (284.7 examples/sec; 0.028 sec/batch; 1h:12m:40s remains)
INFO - root - 2022-02-24 19:47:03.415938: step 44310, total loss = 0.58, batch loss = 0.31 (89.5 examples/sec; 0.089 sec/batch; 3h:51m:19s remains)
INFO - root - 2022-02-24 19:47:04.271144: step 44320, total loss = 0.53, batch loss = 0.25 (82.7 examples/sec; 0.097 sec/batch; 4h:10m:14s remains)
INFO - root - 2022-02-24 19:47:04.683001: step 44330, total loss = 0.58, batch loss = 0.30 (180.2 examples/sec; 0.044 sec/batch; 1h:54m:50s remains)
INFO - root - 2022-02-24 19:47:05.028204: step 44340, total loss = 0.69, batch loss = 0.41 (270.8 examples/sec; 0.030 sec/batch; 1h:16m:24s remains)
INFO - root - 2022-02-24 19:47:05.311910: step 44350, total loss = 0.50, batch loss = 0.22 (284.3 examples/sec; 0.028 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 19:47:05.689282: step 44360, total loss = 0.63, batch loss = 0.35 (302.5 examples/sec; 0.026 sec/batch; 1h:08m:22s remains)
INFO - root - 2022-02-24 19:47:06.017259: step 44370, total loss = 0.62, batch loss = 0.34 (294.3 examples/sec; 0.027 sec/batch; 1h:10m:17s remains)
INFO - root - 2022-02-24 19:47:06.372346: step 44380, total loss = 0.57, batch loss = 0.29 (331.5 examples/sec; 0.024 sec/batch; 1h:02m:23s remains)
INFO - root - 2022-02-24 19:47:06.678661: step 44390, total loss = 0.57, batch loss = 0.30 (330.4 examples/sec; 0.024 sec/batch; 1h:02m:35s remains)
INFO - root - 2022-02-24 19:47:07.065347: step 44400, total loss = 0.60, batch loss = 0.32 (350.9 examples/sec; 0.023 sec/batch; 0h:58m:55s remains)
INFO - root - 2022-02-24 19:47:08.049732: step 44410, total loss = 0.56, batch loss = 0.28 (93.1 examples/sec; 0.086 sec/batch; 3h:42m:12s remains)
INFO - root - 2022-02-24 19:47:08.754696: step 44420, total loss = 0.64, batch loss = 0.36 (205.6 examples/sec; 0.039 sec/batch; 1h:40m:33s remains)
INFO - root - 2022-02-24 19:47:09.168782: step 44430, total loss = 0.62, batch loss = 0.34 (260.8 examples/sec; 0.031 sec/batch; 1h:19m:17s remains)
INFO - root - 2022-02-24 19:47:09.829412: step 44440, total loss = 0.52, batch loss = 0.24 (79.0 examples/sec; 0.101 sec/batch; 4h:21m:50s remains)
INFO - root - 2022-02-24 19:47:10.334062: step 44450, total loss = 0.58, batch loss = 0.30 (357.3 examples/sec; 0.022 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 19:47:11.096501: step 44460, total loss = 0.74, batch loss = 0.46 (148.5 examples/sec; 0.054 sec/batch; 2h:19m:11s remains)
INFO - root - 2022-02-24 19:47:11.637527: step 44470, total loss = 0.54, batch loss = 0.27 (65.2 examples/sec; 0.123 sec/batch; 5h:16m:47s remains)
INFO - root - 2022-02-24 19:47:12.206323: step 44480, total loss = 0.63, batch loss = 0.35 (175.3 examples/sec; 0.046 sec/batch; 1h:57m:56s remains)
INFO - root - 2022-02-24 19:47:12.852320: step 44490, total loss = 0.55, batch loss = 0.27 (235.5 examples/sec; 0.034 sec/batch; 1h:27m:45s remains)
INFO - root - 2022-02-24 19:47:13.509256: step 44500, total loss = 0.61, batch loss = 0.33 (115.6 examples/sec; 0.069 sec/batch; 2h:58m:45s remains)
INFO - root - 2022-02-24 19:47:14.049271: step 44510, total loss = 0.56, batch loss = 0.28 (58.1 examples/sec; 0.138 sec/batch; 5h:55m:39s remains)
INFO - root - 2022-02-24 19:47:14.741143: step 44520, total loss = 0.64, batch loss = 0.36 (202.8 examples/sec; 0.039 sec/batch; 1h:41m:52s remains)
INFO - root - 2022-02-24 19:47:15.270762: step 44530, total loss = 0.50, batch loss = 0.22 (110.4 examples/sec; 0.072 sec/batch; 3h:07m:14s remains)
INFO - root - 2022-02-24 19:47:15.874892: step 44540, total loss = 0.69, batch loss = 0.41 (150.0 examples/sec; 0.053 sec/batch; 2h:17m:44s remains)
INFO - root - 2022-02-24 19:47:16.776162: step 44550, total loss = 0.60, batch loss = 0.32 (163.0 examples/sec; 0.049 sec/batch; 2h:06m:45s remains)
INFO - root - 2022-02-24 19:47:17.270112: step 44560, total loss = 0.58, batch loss = 0.30 (279.0 examples/sec; 0.029 sec/batch; 1h:14m:02s remains)
INFO - root - 2022-02-24 19:47:17.675914: step 44570, total loss = 0.55, batch loss = 0.28 (226.5 examples/sec; 0.035 sec/batch; 1h:31m:12s remains)
INFO - root - 2022-02-24 19:47:17.996972: step 44580, total loss = 0.51, batch loss = 0.23 (229.8 examples/sec; 0.035 sec/batch; 1h:29m:54s remains)
INFO - root - 2022-02-24 19:47:18.393437: step 44590, total loss = 0.53, batch loss = 0.26 (309.1 examples/sec; 0.026 sec/batch; 1h:06m:49s remains)
INFO - root - 2022-02-24 19:47:18.741062: step 44600, total loss = 0.55, batch loss = 0.27 (206.6 examples/sec; 0.039 sec/batch; 1h:39m:58s remains)
INFO - root - 2022-02-24 19:47:19.197133: step 44610, total loss = 0.57, batch loss = 0.29 (141.0 examples/sec; 0.057 sec/batch; 2h:26m:27s remains)
INFO - root - 2022-02-24 19:47:19.694445: step 44620, total loss = 0.63, batch loss = 0.35 (173.6 examples/sec; 0.046 sec/batch; 1h:58m:56s remains)
INFO - root - 2022-02-24 19:47:20.119175: step 44630, total loss = 0.55, batch loss = 0.27 (169.5 examples/sec; 0.047 sec/batch; 2h:01m:49s remains)
INFO - root - 2022-02-24 19:47:20.391732: step 44640, total loss = 0.60, batch loss = 0.32 (278.3 examples/sec; 0.029 sec/batch; 1h:14m:11s remains)
INFO - root - 2022-02-24 19:47:20.697820: step 44650, total loss = 0.54, batch loss = 0.26 (317.2 examples/sec; 0.025 sec/batch; 1h:05m:05s remains)
INFO - root - 2022-02-24 19:47:21.033902: step 44660, total loss = 0.64, batch loss = 0.36 (312.2 examples/sec; 0.026 sec/batch; 1h:06m:07s remains)
INFO - root - 2022-02-24 19:47:21.366995: step 44670, total loss = 0.50, batch loss = 0.22 (126.5 examples/sec; 0.063 sec/batch; 2h:43m:09s remains)
INFO - root - 2022-02-24 19:47:21.729473: step 44680, total loss = 0.60, batch loss = 0.32 (183.0 examples/sec; 0.044 sec/batch; 1h:52m:48s remains)
INFO - root - 2022-02-24 19:47:22.177768: step 44690, total loss = 0.64, batch loss = 0.36 (283.6 examples/sec; 0.028 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 19:47:22.552305: step 44700, total loss = 0.68, batch loss = 0.40 (331.8 examples/sec; 0.024 sec/batch; 1h:02m:12s remains)
INFO - root - 2022-02-24 19:47:22.997232: step 44710, total loss = 0.57, batch loss = 0.29 (335.3 examples/sec; 0.024 sec/batch; 1h:01m:32s remains)
INFO - root - 2022-02-24 19:47:23.352977: step 44720, total loss = 0.56, batch loss = 0.28 (158.9 examples/sec; 0.050 sec/batch; 2h:09m:54s remains)
INFO - root - 2022-02-24 19:47:23.792414: step 44730, total loss = 0.59, batch loss = 0.31 (168.6 examples/sec; 0.047 sec/batch; 2h:02m:23s remains)
INFO - root - 2022-02-24 19:47:24.273844: step 44740, total loss = 0.48, batch loss = 0.20 (327.0 examples/sec; 0.024 sec/batch; 1h:03m:06s remains)
INFO - root - 2022-02-24 19:47:24.648313: step 44750, total loss = 0.52, batch loss = 0.25 (299.3 examples/sec; 0.027 sec/batch; 1h:08m:55s remains)
INFO - root - 2022-02-24 19:47:25.049486: step 44760, total loss = 0.59, batch loss = 0.31 (352.0 examples/sec; 0.023 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 19:47:25.345395: step 44770, total loss = 0.68, batch loss = 0.41 (327.0 examples/sec; 0.024 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 19:47:25.812897: step 44780, total loss = 0.84, batch loss = 0.57 (156.8 examples/sec; 0.051 sec/batch; 2h:11m:35s remains)
INFO - root - 2022-02-24 19:47:26.234749: step 44790, total loss = 0.58, batch loss = 0.31 (285.7 examples/sec; 0.028 sec/batch; 1h:12m:12s remains)
INFO - root - 2022-02-24 19:47:26.568347: step 44800, total loss = 0.61, batch loss = 0.33 (142.5 examples/sec; 0.056 sec/batch; 2h:24m:43s remains)
INFO - root - 2022-02-24 19:47:27.022606: step 44810, total loss = 0.51, batch loss = 0.24 (171.5 examples/sec; 0.047 sec/batch; 2h:00m:14s remains)
INFO - root - 2022-02-24 19:47:27.400604: step 44820, total loss = 0.54, batch loss = 0.26 (212.0 examples/sec; 0.038 sec/batch; 1h:37m:17s remains)
INFO - root - 2022-02-24 19:47:27.787437: step 44830, total loss = 0.65, batch loss = 0.37 (333.0 examples/sec; 0.024 sec/batch; 1h:01m:55s remains)
INFO - root - 2022-02-24 19:47:28.155509: step 44840, total loss = 0.61, batch loss = 0.33 (196.7 examples/sec; 0.041 sec/batch; 1h:44m:50s remains)
INFO - root - 2022-02-24 19:47:28.550309: step 44850, total loss = 0.62, batch loss = 0.34 (267.9 examples/sec; 0.030 sec/batch; 1h:16m:58s remains)
INFO - root - 2022-02-24 19:47:28.910285: step 44860, total loss = 0.57, batch loss = 0.30 (266.9 examples/sec; 0.030 sec/batch; 1h:17m:15s remains)
INFO - root - 2022-02-24 19:47:29.233072: step 44870, total loss = 0.66, batch loss = 0.38 (182.0 examples/sec; 0.044 sec/batch; 1h:53m:18s remains)
INFO - root - 2022-02-24 19:47:29.559110: step 44880, total loss = 0.54, batch loss = 0.26 (375.0 examples/sec; 0.021 sec/batch; 0h:54m:58s remains)
INFO - root - 2022-02-24 19:47:29.967347: step 44890, total loss = 0.56, batch loss = 0.28 (225.9 examples/sec; 0.035 sec/batch; 1h:31m:15s remains)
INFO - root - 2022-02-24 19:47:30.402198: step 44900, total loss = 0.64, batch loss = 0.36 (335.8 examples/sec; 0.024 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 19:47:30.825865: step 44910, total loss = 0.51, batch loss = 0.23 (140.1 examples/sec; 0.057 sec/batch; 2h:27m:09s remains)
INFO - root - 2022-02-24 19:47:31.175194: step 44920, total loss = 0.62, batch loss = 0.34 (181.6 examples/sec; 0.044 sec/batch; 1h:53m:28s remains)
INFO - root - 2022-02-24 19:47:31.492461: step 44930, total loss = 0.59, batch loss = 0.31 (205.9 examples/sec; 0.039 sec/batch; 1h:40m:05s remains)
INFO - root - 2022-02-24 19:47:32.007056: step 44940, total loss = 0.54, batch loss = 0.26 (191.1 examples/sec; 0.042 sec/batch; 1h:47m:51s remains)
INFO - root - 2022-02-24 19:47:32.464760: step 44950, total loss = 0.50, batch loss = 0.22 (229.8 examples/sec; 0.035 sec/batch; 1h:29m:40s remains)
INFO - root - 2022-02-24 19:47:32.839409: step 44960, total loss = 0.58, batch loss = 0.30 (210.4 examples/sec; 0.038 sec/batch; 1h:37m:56s remains)
INFO - root - 2022-02-24 19:47:33.210120: step 44970, total loss = 0.60, batch loss = 0.32 (333.5 examples/sec; 0.024 sec/batch; 1h:01m:47s remains)
INFO - root - 2022-02-24 19:47:33.539329: step 44980, total loss = 0.79, batch loss = 0.51 (212.3 examples/sec; 0.038 sec/batch; 1h:37m:02s remains)
INFO - root - 2022-02-24 19:47:33.971862: step 44990, total loss = 0.55, batch loss = 0.27 (88.2 examples/sec; 0.091 sec/batch; 3h:53m:32s remains)
INFO - root - 2022-02-24 19:47:34.412241: step 45000, total loss = 0.60, batch loss = 0.32 (250.4 examples/sec; 0.032 sec/batch; 1h:22m:15s remains)
INFO - root - 2022-02-24 19:47:34.870811: step 45010, total loss = 0.60, batch loss = 0.33 (374.3 examples/sec; 0.021 sec/batch; 0h:55m:02s remains)
INFO - root - 2022-02-24 19:47:35.256385: step 45020, total loss = 0.54, batch loss = 0.27 (156.8 examples/sec; 0.051 sec/batch; 2h:11m:21s remains)
INFO - root - 2022-02-24 19:47:35.870906: step 45030, total loss = 0.63, batch loss = 0.35 (23.4 examples/sec; 0.341 sec/batch; 14h:39m:06s remains)
INFO - root - 2022-02-24 19:47:36.365212: step 45040, total loss = 0.48, batch loss = 0.20 (88.7 examples/sec; 0.090 sec/batch; 3h:52m:16s remains)
INFO - root - 2022-02-24 19:47:36.998124: step 45050, total loss = 0.66, batch loss = 0.38 (141.3 examples/sec; 0.057 sec/batch; 2h:25m:45s remains)
INFO - root - 2022-02-24 19:47:37.417698: step 45060, total loss = 0.53, batch loss = 0.25 (320.7 examples/sec; 0.025 sec/batch; 1h:04m:12s remains)
INFO - root - 2022-02-24 19:47:37.895484: step 45070, total loss = 0.54, batch loss = 0.26 (283.0 examples/sec; 0.028 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 19:47:38.330901: step 45080, total loss = 0.58, batch loss = 0.30 (167.8 examples/sec; 0.048 sec/batch; 2h:02m:43s remains)
INFO - root - 2022-02-24 19:47:38.792595: step 45090, total loss = 0.56, batch loss = 0.28 (90.7 examples/sec; 0.088 sec/batch; 3h:46m:58s remains)
INFO - root - 2022-02-24 19:47:39.163181: step 45100, total loss = 0.55, batch loss = 0.27 (230.9 examples/sec; 0.035 sec/batch; 1h:29m:10s remains)
INFO - root - 2022-02-24 19:47:39.670251: step 45110, total loss = 0.52, batch loss = 0.24 (207.5 examples/sec; 0.039 sec/batch; 1h:39m:12s remains)
INFO - root - 2022-02-24 19:47:40.078136: step 45120, total loss = 0.63, batch loss = 0.36 (229.5 examples/sec; 0.035 sec/batch; 1h:29m:42s remains)
INFO - root - 2022-02-24 19:47:40.510521: step 45130, total loss = 0.65, batch loss = 0.37 (174.1 examples/sec; 0.046 sec/batch; 1h:58m:11s remains)
INFO - root - 2022-02-24 19:47:40.826460: step 45140, total loss = 0.52, batch loss = 0.25 (155.9 examples/sec; 0.051 sec/batch; 2h:12m:00s remains)
INFO - root - 2022-02-24 19:47:41.300670: step 45150, total loss = 0.50, batch loss = 0.22 (154.4 examples/sec; 0.052 sec/batch; 2h:13m:17s remains)
INFO - root - 2022-02-24 19:47:41.746559: step 45160, total loss = 0.57, batch loss = 0.29 (219.1 examples/sec; 0.037 sec/batch; 1h:33m:54s remains)
INFO - root - 2022-02-24 19:47:42.102995: step 45170, total loss = 0.53, batch loss = 0.26 (328.4 examples/sec; 0.024 sec/batch; 1h:02m:39s remains)
INFO - root - 2022-02-24 19:47:43.157043: step 45180, total loss = 0.49, batch loss = 0.21 (18.0 examples/sec; 0.444 sec/batch; 19h:01m:32s remains)
INFO - root - 2022-02-24 19:47:43.496989: step 45190, total loss = 0.55, batch loss = 0.27 (156.5 examples/sec; 0.051 sec/batch; 2h:11m:25s remains)
INFO - root - 2022-02-24 19:47:43.953265: step 45200, total loss = 0.57, batch loss = 0.30 (176.3 examples/sec; 0.045 sec/batch; 1h:56m:43s remains)
INFO - root - 2022-02-24 19:47:44.456057: step 45210, total loss = 0.63, batch loss = 0.35 (186.6 examples/sec; 0.043 sec/batch; 1h:50m:13s remains)
INFO - root - 2022-02-24 19:47:44.842388: step 45220, total loss = 0.61, batch loss = 0.33 (325.2 examples/sec; 0.025 sec/batch; 1h:03m:15s remains)
INFO - root - 2022-02-24 19:47:45.226929: step 45230, total loss = 0.62, batch loss = 0.34 (234.9 examples/sec; 0.034 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 19:47:45.539920: step 45240, total loss = 0.64, batch loss = 0.36 (290.2 examples/sec; 0.028 sec/batch; 1h:10m:52s remains)
INFO - root - 2022-02-24 19:47:45.923354: step 45250, total loss = 0.66, batch loss = 0.39 (108.6 examples/sec; 0.074 sec/batch; 3h:09m:24s remains)
INFO - root - 2022-02-24 19:47:46.435705: step 45260, total loss = 0.57, batch loss = 0.29 (157.7 examples/sec; 0.051 sec/batch; 2h:10m:25s remains)
INFO - root - 2022-02-24 19:47:46.813826: step 45270, total loss = 0.53, batch loss = 0.26 (280.7 examples/sec; 0.029 sec/batch; 1h:13m:16s remains)
INFO - root - 2022-02-24 19:47:47.314090: step 45280, total loss = 0.52, batch loss = 0.24 (77.8 examples/sec; 0.103 sec/batch; 4h:24m:25s remains)
INFO - root - 2022-02-24 19:47:47.680671: step 45290, total loss = 0.55, batch loss = 0.28 (335.8 examples/sec; 0.024 sec/batch; 1h:01m:14s remains)
INFO - root - 2022-02-24 19:47:48.132393: step 45300, total loss = 0.55, batch loss = 0.27 (148.8 examples/sec; 0.054 sec/batch; 2h:18m:12s remains)
INFO - root - 2022-02-24 19:47:48.743725: step 45310, total loss = 0.59, batch loss = 0.31 (224.0 examples/sec; 0.036 sec/batch; 1h:31m:46s remains)
INFO - root - 2022-02-24 19:47:49.090439: step 45320, total loss = 0.63, batch loss = 0.35 (355.6 examples/sec; 0.022 sec/batch; 0h:57m:48s remains)
INFO - root - 2022-02-24 19:47:49.373607: step 45330, total loss = 0.60, batch loss = 0.32 (245.0 examples/sec; 0.033 sec/batch; 1h:23m:53s remains)
INFO - root - 2022-02-24 19:47:49.694753: step 45340, total loss = 0.64, batch loss = 0.36 (319.5 examples/sec; 0.025 sec/batch; 1h:04m:19s remains)
INFO - root - 2022-02-24 19:47:49.991873: step 45350, total loss = 0.61, batch loss = 0.34 (333.7 examples/sec; 0.024 sec/batch; 1h:01m:36s remains)
INFO - root - 2022-02-24 19:47:50.356279: step 45360, total loss = 0.59, batch loss = 0.31 (303.2 examples/sec; 0.026 sec/batch; 1h:07m:46s remains)
INFO - root - 2022-02-24 19:47:50.844413: step 45370, total loss = 0.55, batch loss = 0.28 (284.0 examples/sec; 0.028 sec/batch; 1h:12m:21s remains)
INFO - root - 2022-02-24 19:47:51.177356: step 45380, total loss = 0.62, batch loss = 0.34 (187.5 examples/sec; 0.043 sec/batch; 1h:49m:34s remains)
INFO - root - 2022-02-24 19:47:51.478936: step 45390, total loss = 0.51, batch loss = 0.23 (155.9 examples/sec; 0.051 sec/batch; 2h:11m:48s remains)
INFO - root - 2022-02-24 19:47:51.835708: step 45400, total loss = 0.53, batch loss = 0.25 (269.5 examples/sec; 0.030 sec/batch; 1h:16m:13s remains)
INFO - root - 2022-02-24 19:47:52.291155: step 45410, total loss = 0.62, batch loss = 0.34 (356.1 examples/sec; 0.022 sec/batch; 0h:57m:41s remains)
INFO - root - 2022-02-24 19:47:52.710269: step 45420, total loss = 0.49, batch loss = 0.22 (322.2 examples/sec; 0.025 sec/batch; 1h:03m:45s remains)
INFO - root - 2022-02-24 19:47:53.221669: step 45430, total loss = 0.61, batch loss = 0.33 (104.6 examples/sec; 0.076 sec/batch; 3h:16m:20s remains)
INFO - root - 2022-02-24 19:47:53.578440: step 45440, total loss = 0.57, batch loss = 0.29 (347.3 examples/sec; 0.023 sec/batch; 0h:59m:08s remains)
INFO - root - 2022-02-24 19:47:53.942489: step 45450, total loss = 0.52, batch loss = 0.24 (251.4 examples/sec; 0.032 sec/batch; 1h:21m:43s remains)
INFO - root - 2022-02-24 19:47:54.335111: step 45460, total loss = 0.51, batch loss = 0.23 (264.5 examples/sec; 0.030 sec/batch; 1h:17m:39s remains)
INFO - root - 2022-02-24 19:47:54.755970: step 45470, total loss = 0.63, batch loss = 0.35 (206.2 examples/sec; 0.039 sec/batch; 1h:39m:37s remains)
INFO - root - 2022-02-24 19:47:55.118683: step 45480, total loss = 0.57, batch loss = 0.30 (202.9 examples/sec; 0.039 sec/batch; 1h:41m:13s remains)
INFO - root - 2022-02-24 19:47:55.488488: step 45490, total loss = 0.62, batch loss = 0.35 (231.8 examples/sec; 0.035 sec/batch; 1h:28m:35s remains)
INFO - root - 2022-02-24 19:47:55.882346: step 45500, total loss = 0.60, batch loss = 0.32 (201.5 examples/sec; 0.040 sec/batch; 1h:41m:55s remains)
INFO - root - 2022-02-24 19:47:56.320449: step 45510, total loss = 0.54, batch loss = 0.26 (90.9 examples/sec; 0.088 sec/batch; 3h:45m:55s remains)
INFO - root - 2022-02-24 19:47:56.759401: step 45520, total loss = 0.74, batch loss = 0.46 (97.6 examples/sec; 0.082 sec/batch; 3h:30m:26s remains)
INFO - root - 2022-02-24 19:47:57.223214: step 45530, total loss = 0.59, batch loss = 0.31 (124.2 examples/sec; 0.064 sec/batch; 2h:45m:13s remains)
INFO - root - 2022-02-24 19:47:57.577086: step 45540, total loss = 0.55, batch loss = 0.27 (187.4 examples/sec; 0.043 sec/batch; 1h:49m:33s remains)
INFO - root - 2022-02-24 19:47:57.933224: step 45550, total loss = 0.66, batch loss = 0.38 (98.6 examples/sec; 0.081 sec/batch; 3h:28m:10s remains)
INFO - root - 2022-02-24 19:47:58.303309: step 45560, total loss = 0.60, batch loss = 0.33 (75.6 examples/sec; 0.106 sec/batch; 4h:31m:24s remains)
INFO - root - 2022-02-24 19:47:58.680830: step 45570, total loss = 0.54, batch loss = 0.26 (303.8 examples/sec; 0.026 sec/batch; 1h:07m:33s remains)
INFO - root - 2022-02-24 19:47:59.107536: step 45580, total loss = 0.56, batch loss = 0.28 (241.8 examples/sec; 0.033 sec/batch; 1h:24m:51s remains)
INFO - root - 2022-02-24 19:47:59.455838: step 45590, total loss = 0.69, batch loss = 0.42 (161.3 examples/sec; 0.050 sec/batch; 2h:07m:13s remains)
INFO - root - 2022-02-24 19:47:59.796956: step 45600, total loss = 0.58, batch loss = 0.31 (326.4 examples/sec; 0.025 sec/batch; 1h:02m:52s remains)
INFO - root - 2022-02-24 19:48:00.218125: step 45610, total loss = 0.65, batch loss = 0.37 (325.1 examples/sec; 0.025 sec/batch; 1h:03m:06s remains)
INFO - root - 2022-02-24 19:48:00.501489: step 45620, total loss = 0.65, batch loss = 0.38 (348.4 examples/sec; 0.023 sec/batch; 0h:58m:53s remains)
INFO - root - 2022-02-24 19:48:00.827108: step 45630, total loss = 0.64, batch loss = 0.36 (312.0 examples/sec; 0.026 sec/batch; 1h:05m:45s remains)
INFO - root - 2022-02-24 19:48:01.229785: step 45640, total loss = 0.52, batch loss = 0.25 (123.7 examples/sec; 0.065 sec/batch; 2h:45m:51s remains)
INFO - root - 2022-02-24 19:48:01.678357: step 45650, total loss = 0.49, batch loss = 0.22 (117.1 examples/sec; 0.068 sec/batch; 2h:55m:09s remains)
INFO - root - 2022-02-24 19:48:01.997824: step 45660, total loss = 0.59, batch loss = 0.31 (331.4 examples/sec; 0.024 sec/batch; 1h:01m:53s remains)
INFO - root - 2022-02-24 19:48:02.309965: step 45670, total loss = 0.55, batch loss = 0.27 (191.8 examples/sec; 0.042 sec/batch; 1h:46m:55s remains)
INFO - root - 2022-02-24 19:48:02.711109: step 45680, total loss = 0.61, batch loss = 0.33 (292.6 examples/sec; 0.027 sec/batch; 1h:10m:05s remains)
INFO - root - 2022-02-24 19:48:03.149176: step 45690, total loss = 0.70, batch loss = 0.43 (360.4 examples/sec; 0.022 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 19:48:03.600727: step 45700, total loss = 0.61, batch loss = 0.33 (239.4 examples/sec; 0.033 sec/batch; 1h:25m:38s remains)
INFO - root - 2022-02-24 19:48:04.024675: step 45710, total loss = 0.59, batch loss = 0.31 (337.6 examples/sec; 0.024 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 19:48:04.311466: step 45720, total loss = 0.63, batch loss = 0.36 (301.1 examples/sec; 0.027 sec/batch; 1h:08m:06s remains)
INFO - root - 2022-02-24 19:48:04.654503: step 45730, total loss = 0.52, batch loss = 0.25 (327.9 examples/sec; 0.024 sec/batch; 1h:02m:31s remains)
INFO - root - 2022-02-24 19:48:05.014511: step 45740, total loss = 0.57, batch loss = 0.29 (132.4 examples/sec; 0.060 sec/batch; 2h:34m:49s remains)
INFO - root - 2022-02-24 19:48:05.449614: step 45750, total loss = 0.50, batch loss = 0.22 (338.9 examples/sec; 0.024 sec/batch; 1h:00m:29s remains)
INFO - root - 2022-02-24 19:48:05.832711: step 45760, total loss = 0.53, batch loss = 0.25 (299.3 examples/sec; 0.027 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 19:48:06.209682: step 45770, total loss = 0.55, batch loss = 0.27 (263.3 examples/sec; 0.030 sec/batch; 1h:17m:51s remains)
INFO - root - 2022-02-24 19:48:06.582539: step 45780, total loss = 0.74, batch loss = 0.46 (188.2 examples/sec; 0.042 sec/batch; 1h:48m:52s remains)
INFO - root - 2022-02-24 19:48:06.923313: step 45790, total loss = 0.55, batch loss = 0.27 (149.6 examples/sec; 0.053 sec/batch; 2h:17m:02s remains)
INFO - root - 2022-02-24 19:48:07.398812: step 45800, total loss = 0.58, batch loss = 0.31 (328.4 examples/sec; 0.024 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 19:48:07.898639: step 45810, total loss = 0.73, batch loss = 0.45 (114.2 examples/sec; 0.070 sec/batch; 2h:59m:29s remains)
INFO - root - 2022-02-24 19:48:08.259349: step 45820, total loss = 0.57, batch loss = 0.29 (227.8 examples/sec; 0.035 sec/batch; 1h:29m:56s remains)
INFO - root - 2022-02-24 19:48:08.693031: step 45830, total loss = 0.53, batch loss = 0.25 (166.3 examples/sec; 0.048 sec/batch; 2h:03m:10s remains)
INFO - root - 2022-02-24 19:48:09.008623: step 45840, total loss = 0.68, batch loss = 0.40 (351.8 examples/sec; 0.023 sec/batch; 0h:58m:14s remains)
INFO - root - 2022-02-24 19:48:09.342632: step 45850, total loss = 0.56, batch loss = 0.28 (273.1 examples/sec; 0.029 sec/batch; 1h:15m:01s remains)
INFO - root - 2022-02-24 19:48:09.741737: step 45860, total loss = 0.60, batch loss = 0.33 (350.0 examples/sec; 0.023 sec/batch; 0h:58m:31s remains)
INFO - root - 2022-02-24 19:48:10.117267: step 45870, total loss = 0.52, batch loss = 0.24 (264.0 examples/sec; 0.030 sec/batch; 1h:17m:36s remains)
INFO - root - 2022-02-24 19:48:10.367952: step 45880, total loss = 0.55, batch loss = 0.28 (351.2 examples/sec; 0.023 sec/batch; 0h:58m:19s remains)
INFO - root - 2022-02-24 19:48:10.785379: step 45890, total loss = 0.51, batch loss = 0.23 (235.2 examples/sec; 0.034 sec/batch; 1h:27m:04s remains)
INFO - root - 2022-02-24 19:48:11.239220: step 45900, total loss = 0.71, batch loss = 0.43 (90.9 examples/sec; 0.088 sec/batch; 3h:45m:20s remains)
INFO - root - 2022-02-24 19:48:11.734047: step 45910, total loss = 0.62, batch loss = 0.34 (316.0 examples/sec; 0.025 sec/batch; 1h:04m:48s remains)
INFO - root - 2022-02-24 19:48:12.174918: step 45920, total loss = 0.59, batch loss = 0.32 (239.1 examples/sec; 0.033 sec/batch; 1h:25m:38s remains)
INFO - root - 2022-02-24 19:48:12.514902: step 45930, total loss = 0.68, batch loss = 0.40 (210.1 examples/sec; 0.038 sec/batch; 1h:37m:28s remains)
INFO - root - 2022-02-24 19:48:12.827288: step 45940, total loss = 0.54, batch loss = 0.27 (324.6 examples/sec; 0.025 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 19:48:13.187394: step 45950, total loss = 0.48, batch loss = 0.20 (142.4 examples/sec; 0.056 sec/batch; 2h:23m:47s remains)
INFO - root - 2022-02-24 19:48:13.545231: step 45960, total loss = 0.64, batch loss = 0.36 (219.8 examples/sec; 0.036 sec/batch; 1h:33m:07s remains)
INFO - root - 2022-02-24 19:48:13.944453: step 45970, total loss = 0.64, batch loss = 0.36 (310.0 examples/sec; 0.026 sec/batch; 1h:06m:02s remains)
INFO - root - 2022-02-24 19:48:14.359834: step 45980, total loss = 0.54, batch loss = 0.26 (222.3 examples/sec; 0.036 sec/batch; 1h:32m:03s remains)
INFO - root - 2022-02-24 19:48:14.695258: step 45990, total loss = 0.59, batch loss = 0.31 (283.0 examples/sec; 0.028 sec/batch; 1h:12m:18s remains)
INFO - root - 2022-02-24 19:48:15.018384: step 46000, total loss = 0.61, batch loss = 0.33 (357.9 examples/sec; 0.022 sec/batch; 0h:57m:10s remains)
INFO - root - 2022-02-24 19:48:15.339811: step 46010, total loss = 0.51, batch loss = 0.24 (369.1 examples/sec; 0.022 sec/batch; 0h:55m:26s remains)
INFO - root - 2022-02-24 19:48:15.697848: step 46020, total loss = 0.69, batch loss = 0.41 (354.2 examples/sec; 0.023 sec/batch; 0h:57m:46s remains)
INFO - root - 2022-02-24 19:48:16.093125: step 46030, total loss = 0.67, batch loss = 0.39 (338.9 examples/sec; 0.024 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 19:48:16.451533: step 46040, total loss = 0.69, batch loss = 0.42 (366.8 examples/sec; 0.022 sec/batch; 0h:55m:46s remains)
INFO - root - 2022-02-24 19:48:16.855766: step 46050, total loss = 0.57, batch loss = 0.29 (218.4 examples/sec; 0.037 sec/batch; 1h:33m:41s remains)
INFO - root - 2022-02-24 19:48:17.259671: step 46060, total loss = 0.57, batch loss = 0.29 (129.8 examples/sec; 0.062 sec/batch; 2h:37m:35s remains)
INFO - root - 2022-02-24 19:48:17.573962: step 46070, total loss = 0.66, batch loss = 0.38 (328.8 examples/sec; 0.024 sec/batch; 1h:02m:13s remains)
INFO - root - 2022-02-24 19:48:17.968654: step 46080, total loss = 0.56, batch loss = 0.28 (345.9 examples/sec; 0.023 sec/batch; 0h:59m:08s remains)
INFO - root - 2022-02-24 19:48:18.501837: step 46090, total loss = 0.61, batch loss = 0.34 (73.8 examples/sec; 0.108 sec/batch; 4h:36m:58s remains)
INFO - root - 2022-02-24 19:48:19.334257: step 46100, total loss = 0.56, batch loss = 0.28 (133.0 examples/sec; 0.060 sec/batch; 2h:33m:48s remains)
INFO - root - 2022-02-24 19:48:19.760147: step 46110, total loss = 0.60, batch loss = 0.33 (348.6 examples/sec; 0.023 sec/batch; 0h:58m:40s remains)
INFO - root - 2022-02-24 19:48:20.126412: step 46120, total loss = 0.59, batch loss = 0.32 (353.7 examples/sec; 0.023 sec/batch; 0h:57m:49s remains)
INFO - root - 2022-02-24 19:48:20.537863: step 46130, total loss = 0.59, batch loss = 0.31 (207.2 examples/sec; 0.039 sec/batch; 1h:38m:41s remains)
INFO - root - 2022-02-24 19:48:21.319180: step 46140, total loss = 0.60, batch loss = 0.32 (339.7 examples/sec; 0.024 sec/batch; 1h:00m:11s remains)
INFO - root - 2022-02-24 19:48:21.715973: step 46150, total loss = 0.59, batch loss = 0.31 (356.4 examples/sec; 0.022 sec/batch; 0h:57m:21s remains)
INFO - root - 2022-02-24 19:48:22.040628: step 46160, total loss = 0.59, batch loss = 0.31 (146.6 examples/sec; 0.055 sec/batch; 2h:19m:25s remains)
INFO - root - 2022-02-24 19:48:22.438662: step 46170, total loss = 0.50, batch loss = 0.22 (207.9 examples/sec; 0.038 sec/batch; 1h:38m:19s remains)
INFO - root - 2022-02-24 19:48:22.841097: step 46180, total loss = 0.58, batch loss = 0.31 (322.8 examples/sec; 0.025 sec/batch; 1h:03m:20s remains)
INFO - root - 2022-02-24 19:48:23.235125: step 46190, total loss = 0.53, batch loss = 0.25 (106.7 examples/sec; 0.075 sec/batch; 3h:11m:29s remains)
INFO - root - 2022-02-24 19:48:23.939270: step 46200, total loss = 0.53, batch loss = 0.25 (195.7 examples/sec; 0.041 sec/batch; 1h:44m:25s remains)
INFO - root - 2022-02-24 19:48:24.405225: step 46210, total loss = 0.67, batch loss = 0.39 (337.9 examples/sec; 0.024 sec/batch; 1h:00m:29s remains)
INFO - root - 2022-02-24 19:48:24.947127: step 46220, total loss = 0.56, batch loss = 0.29 (109.4 examples/sec; 0.073 sec/batch; 3h:06m:51s remains)
INFO - root - 2022-02-24 19:48:25.539508: step 46230, total loss = 0.59, batch loss = 0.31 (256.6 examples/sec; 0.031 sec/batch; 1h:19m:37s remains)
INFO - root - 2022-02-24 19:48:26.059166: step 46240, total loss = 0.67, batch loss = 0.40 (177.6 examples/sec; 0.045 sec/batch; 1h:55m:02s remains)
INFO - root - 2022-02-24 19:48:26.812539: step 46250, total loss = 0.53, batch loss = 0.26 (236.1 examples/sec; 0.034 sec/batch; 1h:26m:32s remains)
INFO - root - 2022-02-24 19:48:27.189846: step 46260, total loss = 0.67, batch loss = 0.39 (310.3 examples/sec; 0.026 sec/batch; 1h:05m:50s remains)
INFO - root - 2022-02-24 19:48:27.540752: step 46270, total loss = 0.53, batch loss = 0.25 (191.7 examples/sec; 0.042 sec/batch; 1h:46m:35s remains)
INFO - root - 2022-02-24 19:48:27.866294: step 46280, total loss = 0.63, batch loss = 0.36 (308.8 examples/sec; 0.026 sec/batch; 1h:06m:09s remains)
INFO - root - 2022-02-24 19:48:28.352685: step 46290, total loss = 0.59, batch loss = 0.31 (142.1 examples/sec; 0.056 sec/batch; 2h:23m:44s remains)
INFO - root - 2022-02-24 19:48:28.784523: step 46300, total loss = 0.56, batch loss = 0.28 (210.4 examples/sec; 0.038 sec/batch; 1h:37m:03s remains)
INFO - root - 2022-02-24 19:48:29.199597: step 46310, total loss = 0.69, batch loss = 0.41 (227.4 examples/sec; 0.035 sec/batch; 1h:29m:48s remains)
INFO - root - 2022-02-24 19:48:29.491660: step 46320, total loss = 0.59, batch loss = 0.31 (332.8 examples/sec; 0.024 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 19:48:29.794008: step 46330, total loss = 0.51, batch loss = 0.24 (229.5 examples/sec; 0.035 sec/batch; 1h:28m:59s remains)
INFO - root - 2022-02-24 19:48:30.235404: step 46340, total loss = 0.68, batch loss = 0.40 (88.8 examples/sec; 0.090 sec/batch; 3h:49m:51s remains)
INFO - root - 2022-02-24 19:48:30.586730: step 46350, total loss = 0.54, batch loss = 0.27 (194.0 examples/sec; 0.041 sec/batch; 1h:45m:14s remains)
INFO - root - 2022-02-24 19:48:31.088968: step 46360, total loss = 0.56, batch loss = 0.29 (119.2 examples/sec; 0.067 sec/batch; 2h:51m:16s remains)
INFO - root - 2022-02-24 19:48:31.456843: step 46370, total loss = 0.57, batch loss = 0.30 (227.2 examples/sec; 0.035 sec/batch; 1h:29m:52s remains)
INFO - root - 2022-02-24 19:48:31.816709: step 46380, total loss = 0.70, batch loss = 0.43 (183.9 examples/sec; 0.043 sec/batch; 1h:51m:00s remains)
INFO - root - 2022-02-24 19:48:32.206541: step 46390, total loss = 0.52, batch loss = 0.25 (160.7 examples/sec; 0.050 sec/batch; 2h:07m:00s remains)
INFO - root - 2022-02-24 19:48:32.739270: step 46400, total loss = 0.72, batch loss = 0.44 (139.2 examples/sec; 0.057 sec/batch; 2h:26m:40s remains)
INFO - root - 2022-02-24 19:48:33.232510: step 46410, total loss = 0.52, batch loss = 0.24 (247.0 examples/sec; 0.032 sec/batch; 1h:22m:37s remains)
INFO - root - 2022-02-24 19:48:33.551144: step 46420, total loss = 0.58, batch loss = 0.30 (285.8 examples/sec; 0.028 sec/batch; 1h:11m:25s remains)
INFO - root - 2022-02-24 19:48:33.903486: step 46430, total loss = 0.59, batch loss = 0.31 (196.2 examples/sec; 0.041 sec/batch; 1h:44m:02s remains)
INFO - root - 2022-02-24 19:48:34.303656: step 46440, total loss = 0.52, batch loss = 0.25 (174.7 examples/sec; 0.046 sec/batch; 1h:56m:48s remains)
INFO - root - 2022-02-24 19:48:34.734797: step 46450, total loss = 0.68, batch loss = 0.40 (120.3 examples/sec; 0.067 sec/batch; 2h:49m:39s remains)
INFO - root - 2022-02-24 19:48:35.084372: step 46460, total loss = 0.54, batch loss = 0.26 (253.9 examples/sec; 0.032 sec/batch; 1h:20m:21s remains)
INFO - root - 2022-02-24 19:48:35.424880: step 46470, total loss = 0.61, batch loss = 0.33 (356.7 examples/sec; 0.022 sec/batch; 0h:57m:11s remains)
INFO - root - 2022-02-24 19:48:35.741354: step 46480, total loss = 0.49, batch loss = 0.21 (208.2 examples/sec; 0.038 sec/batch; 1h:38m:00s remains)
INFO - root - 2022-02-24 19:48:36.142291: step 46490, total loss = 0.54, batch loss = 0.26 (184.4 examples/sec; 0.043 sec/batch; 1h:50m:38s remains)
INFO - root - 2022-02-24 19:48:36.633583: step 46500, total loss = 0.65, batch loss = 0.37 (354.1 examples/sec; 0.023 sec/batch; 0h:57m:36s remains)
INFO - root - 2022-02-24 19:48:37.160885: step 46510, total loss = 0.52, batch loss = 0.24 (367.7 examples/sec; 0.022 sec/batch; 0h:55m:28s remains)
INFO - root - 2022-02-24 19:48:37.507274: step 46520, total loss = 0.57, batch loss = 0.30 (202.0 examples/sec; 0.040 sec/batch; 1h:41m:00s remains)
INFO - root - 2022-02-24 19:48:37.889548: step 46530, total loss = 0.61, batch loss = 0.33 (97.4 examples/sec; 0.082 sec/batch; 3h:29m:18s remains)
INFO - root - 2022-02-24 19:48:38.193431: step 46540, total loss = 0.72, batch loss = 0.44 (346.4 examples/sec; 0.023 sec/batch; 0h:58m:52s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-46549 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-46549 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:48:38.916032: step 46550, total loss = 0.54, batch loss = 0.27 (340.4 examples/sec; 0.023 sec/batch; 0h:59m:54s remains)
INFO - root - 2022-02-24 19:48:39.155636: step 46560, total loss = 0.70, batch loss = 0.42 (350.3 examples/sec; 0.023 sec/batch; 0h:58m:13s remains)
INFO - root - 2022-02-24 19:48:39.481880: step 46570, total loss = 0.49, batch loss = 0.21 (222.5 examples/sec; 0.036 sec/batch; 1h:31m:37s remains)
INFO - root - 2022-02-24 19:48:39.830162: step 46580, total loss = 0.53, batch loss = 0.25 (323.8 examples/sec; 0.025 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 19:48:40.180438: step 46590, total loss = 0.65, batch loss = 0.37 (347.4 examples/sec; 0.023 sec/batch; 0h:58m:41s remains)
INFO - root - 2022-02-24 19:48:40.681093: step 46600, total loss = 0.59, batch loss = 0.31 (374.4 examples/sec; 0.021 sec/batch; 0h:54m:26s remains)
INFO - root - 2022-02-24 19:48:41.120234: step 46610, total loss = 0.57, batch loss = 0.29 (289.0 examples/sec; 0.028 sec/batch; 1h:10m:32s remains)
INFO - root - 2022-02-24 19:48:41.465660: step 46620, total loss = 0.60, batch loss = 0.33 (357.5 examples/sec; 0.022 sec/batch; 0h:57m:00s remains)
INFO - root - 2022-02-24 19:48:41.859136: step 46630, total loss = 0.60, batch loss = 0.32 (319.1 examples/sec; 0.025 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 19:48:42.252721: step 46640, total loss = 0.77, batch loss = 0.49 (404.3 examples/sec; 0.020 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 19:48:42.783199: step 46650, total loss = 0.55, batch loss = 0.27 (182.9 examples/sec; 0.044 sec/batch; 1h:51m:24s remains)
INFO - root - 2022-02-24 19:48:43.166262: step 46660, total loss = 0.73, batch loss = 0.45 (143.1 examples/sec; 0.056 sec/batch; 2h:22m:24s remains)
INFO - root - 2022-02-24 19:48:43.559124: step 46670, total loss = 0.61, batch loss = 0.33 (145.9 examples/sec; 0.055 sec/batch; 2h:19m:39s remains)
INFO - root - 2022-02-24 19:48:43.883868: step 46680, total loss = 0.54, batch loss = 0.26 (181.0 examples/sec; 0.044 sec/batch; 1h:52m:34s remains)
INFO - root - 2022-02-24 19:48:44.277662: step 46690, total loss = 0.68, batch loss = 0.40 (294.0 examples/sec; 0.027 sec/batch; 1h:09m:17s remains)
INFO - root - 2022-02-24 19:48:44.742683: step 46700, total loss = 0.53, batch loss = 0.25 (154.3 examples/sec; 0.052 sec/batch; 2h:12m:03s remains)
INFO - root - 2022-02-24 19:48:45.257099: step 46710, total loss = 0.53, batch loss = 0.25 (159.0 examples/sec; 0.050 sec/batch; 2h:08m:07s remains)
INFO - root - 2022-02-24 19:48:45.570358: step 46720, total loss = 0.67, batch loss = 0.39 (299.3 examples/sec; 0.027 sec/batch; 1h:08m:03s remains)
INFO - root - 2022-02-24 19:48:45.969495: step 46730, total loss = 0.66, batch loss = 0.38 (164.6 examples/sec; 0.049 sec/batch; 2h:03m:45s remains)
INFO - root - 2022-02-24 19:48:46.361641: step 46740, total loss = 0.55, batch loss = 0.28 (93.6 examples/sec; 0.085 sec/batch; 3h:37m:38s remains)
INFO - root - 2022-02-24 19:48:46.864670: step 46750, total loss = 0.50, batch loss = 0.22 (143.1 examples/sec; 0.056 sec/batch; 2h:22m:18s remains)
INFO - root - 2022-02-24 19:48:47.235265: step 46760, total loss = 0.57, batch loss = 0.30 (229.4 examples/sec; 0.035 sec/batch; 1h:28m:45s remains)
INFO - root - 2022-02-24 19:48:47.596890: step 46770, total loss = 0.65, batch loss = 0.37 (164.4 examples/sec; 0.049 sec/batch; 2h:03m:54s remains)
INFO - root - 2022-02-24 19:48:47.980516: step 46780, total loss = 0.55, batch loss = 0.27 (177.1 examples/sec; 0.045 sec/batch; 1h:54m:57s remains)
INFO - root - 2022-02-24 19:48:48.331269: step 46790, total loss = 0.66, batch loss = 0.39 (167.4 examples/sec; 0.048 sec/batch; 2h:01m:37s remains)
INFO - root - 2022-02-24 19:48:48.787660: step 46800, total loss = 0.64, batch loss = 0.36 (322.7 examples/sec; 0.025 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 19:48:49.253287: step 46810, total loss = 0.62, batch loss = 0.34 (247.9 examples/sec; 0.032 sec/batch; 1h:22m:07s remains)
INFO - root - 2022-02-24 19:48:49.490833: step 46820, total loss = 0.53, batch loss = 0.26 (309.9 examples/sec; 0.026 sec/batch; 1h:05m:41s remains)
INFO - root - 2022-02-24 19:48:49.821219: step 46830, total loss = 0.50, batch loss = 0.22 (185.1 examples/sec; 0.043 sec/batch; 1h:49m:57s remains)
INFO - root - 2022-02-24 19:48:50.167509: step 46840, total loss = 0.74, batch loss = 0.47 (333.7 examples/sec; 0.024 sec/batch; 1h:00m:59s remains)
INFO - root - 2022-02-24 19:48:50.622995: step 46850, total loss = 0.54, batch loss = 0.27 (211.7 examples/sec; 0.038 sec/batch; 1h:36m:09s remains)
INFO - root - 2022-02-24 19:48:51.058141: step 46860, total loss = 0.50, batch loss = 0.22 (81.0 examples/sec; 0.099 sec/batch; 4h:11m:13s remains)
INFO - root - 2022-02-24 19:48:51.457770: step 46870, total loss = 0.68, batch loss = 0.40 (369.0 examples/sec; 0.022 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 19:48:51.830408: step 46880, total loss = 0.65, batch loss = 0.38 (333.1 examples/sec; 0.024 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 19:48:52.203896: step 46890, total loss = 0.61, batch loss = 0.33 (240.5 examples/sec; 0.033 sec/batch; 1h:24m:35s remains)
INFO - root - 2022-02-24 19:48:52.591266: step 46900, total loss = 0.58, batch loss = 0.31 (170.3 examples/sec; 0.047 sec/batch; 1h:59m:30s remains)
INFO - root - 2022-02-24 19:48:53.116114: step 46910, total loss = 0.52, batch loss = 0.24 (127.9 examples/sec; 0.063 sec/batch; 2h:39m:03s remains)
INFO - root - 2022-02-24 19:48:53.515089: step 46920, total loss = 0.58, batch loss = 0.31 (338.4 examples/sec; 0.024 sec/batch; 1h:00m:07s remains)
INFO - root - 2022-02-24 19:48:53.872729: step 46930, total loss = 0.57, batch loss = 0.29 (267.1 examples/sec; 0.030 sec/batch; 1h:16m:09s remains)
INFO - root - 2022-02-24 19:48:54.228352: step 46940, total loss = 0.57, batch loss = 0.30 (325.2 examples/sec; 0.025 sec/batch; 1h:02m:33s remains)
INFO - root - 2022-02-24 19:48:54.559224: step 46950, total loss = 0.65, batch loss = 0.37 (194.5 examples/sec; 0.041 sec/batch; 1h:44m:35s remains)
INFO - root - 2022-02-24 19:48:55.015527: step 46960, total loss = 0.56, batch loss = 0.28 (178.9 examples/sec; 0.045 sec/batch; 1h:53m:41s remains)
INFO - root - 2022-02-24 19:48:55.440690: step 46970, total loss = 0.52, batch loss = 0.24 (177.4 examples/sec; 0.045 sec/batch; 1h:54m:38s remains)
INFO - root - 2022-02-24 19:48:55.830317: step 46980, total loss = 0.59, batch loss = 0.31 (208.5 examples/sec; 0.038 sec/batch; 1h:37m:30s remains)
INFO - root - 2022-02-24 19:48:56.162733: step 46990, total loss = 0.61, batch loss = 0.33 (185.6 examples/sec; 0.043 sec/batch; 1h:49m:33s remains)
INFO - root - 2022-02-24 19:48:56.537196: step 47000, total loss = 0.68, batch loss = 0.41 (230.9 examples/sec; 0.035 sec/batch; 1h:28m:03s remains)
INFO - root - 2022-02-24 19:48:56.993785: step 47010, total loss = 0.58, batch loss = 0.30 (159.8 examples/sec; 0.050 sec/batch; 2h:07m:12s remains)
INFO - root - 2022-02-24 19:48:57.389747: step 47020, total loss = 0.58, batch loss = 0.30 (130.5 examples/sec; 0.061 sec/batch; 2h:35m:48s remains)
INFO - root - 2022-02-24 19:48:57.834215: step 47030, total loss = 0.54, batch loss = 0.27 (345.2 examples/sec; 0.023 sec/batch; 0h:58m:53s remains)
INFO - root - 2022-02-24 19:48:58.268958: step 47040, total loss = 0.61, batch loss = 0.34 (230.6 examples/sec; 0.035 sec/batch; 1h:28m:09s remains)
INFO - root - 2022-02-24 19:48:58.780404: step 47050, total loss = 0.56, batch loss = 0.28 (310.1 examples/sec; 0.026 sec/batch; 1h:05m:33s remains)
INFO - root - 2022-02-24 19:48:59.400707: step 47060, total loss = 0.55, batch loss = 0.28 (106.0 examples/sec; 0.075 sec/batch; 3h:11m:44s remains)
INFO - root - 2022-02-24 19:48:59.870939: step 47070, total loss = 0.62, batch loss = 0.34 (124.8 examples/sec; 0.064 sec/batch; 2h:42m:51s remains)
INFO - root - 2022-02-24 19:49:00.306403: step 47080, total loss = 0.58, batch loss = 0.31 (283.6 examples/sec; 0.028 sec/batch; 1h:11m:40s remains)
INFO - root - 2022-02-24 19:49:00.999140: step 47090, total loss = 0.69, batch loss = 0.41 (92.1 examples/sec; 0.087 sec/batch; 3h:40m:34s remains)
INFO - root - 2022-02-24 19:49:01.491818: step 47100, total loss = 0.59, batch loss = 0.31 (240.9 examples/sec; 0.033 sec/batch; 1h:24m:21s remains)
INFO - root - 2022-02-24 19:49:02.438053: step 47110, total loss = 0.71, batch loss = 0.44 (312.4 examples/sec; 0.026 sec/batch; 1h:05m:02s remains)
INFO - root - 2022-02-24 19:49:02.794514: step 47120, total loss = 0.65, batch loss = 0.37 (184.4 examples/sec; 0.043 sec/batch; 1h:50m:12s remains)
INFO - root - 2022-02-24 19:49:03.183235: step 47130, total loss = 0.68, batch loss = 0.40 (269.2 examples/sec; 0.030 sec/batch; 1h:15m:28s remains)
INFO - root - 2022-02-24 19:49:03.624774: step 47140, total loss = 0.57, batch loss = 0.29 (259.9 examples/sec; 0.031 sec/batch; 1h:18m:09s remains)
INFO - root - 2022-02-24 19:49:04.131415: step 47150, total loss = 0.51, batch loss = 0.23 (247.1 examples/sec; 0.032 sec/batch; 1h:22m:11s remains)
INFO - root - 2022-02-24 19:49:04.598230: step 47160, total loss = 0.62, batch loss = 0.35 (111.2 examples/sec; 0.072 sec/batch; 3h:02m:37s remains)
INFO - root - 2022-02-24 19:49:04.968777: step 47170, total loss = 0.57, batch loss = 0.29 (176.5 examples/sec; 0.045 sec/batch; 1h:55m:03s remains)
INFO - root - 2022-02-24 19:49:05.295081: step 47180, total loss = 0.59, batch loss = 0.31 (206.2 examples/sec; 0.039 sec/batch; 1h:38m:30s remains)
INFO - root - 2022-02-24 19:49:05.637515: step 47190, total loss = 0.54, batch loss = 0.26 (270.3 examples/sec; 0.030 sec/batch; 1h:15m:08s remains)
INFO - root - 2022-02-24 19:49:06.090348: step 47200, total loss = 0.54, batch loss = 0.26 (152.2 examples/sec; 0.053 sec/batch; 2h:13m:22s remains)
INFO - root - 2022-02-24 19:49:06.661947: step 47210, total loss = 0.59, batch loss = 0.32 (358.9 examples/sec; 0.022 sec/batch; 0h:56m:34s remains)
INFO - root - 2022-02-24 19:49:07.333901: step 47220, total loss = 0.62, batch loss = 0.35 (188.3 examples/sec; 0.042 sec/batch; 1h:47m:50s remains)
INFO - root - 2022-02-24 19:49:07.668113: step 47230, total loss = 0.55, batch loss = 0.27 (294.1 examples/sec; 0.027 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 19:49:08.035249: step 47240, total loss = 0.51, batch loss = 0.23 (161.9 examples/sec; 0.049 sec/batch; 2h:05m:22s remains)
INFO - root - 2022-02-24 19:49:08.450858: step 47250, total loss = 0.56, batch loss = 0.28 (134.7 examples/sec; 0.059 sec/batch; 2h:30m:45s remains)
INFO - root - 2022-02-24 19:49:08.851161: step 47260, total loss = 0.59, batch loss = 0.31 (346.3 examples/sec; 0.023 sec/batch; 0h:58m:37s remains)
INFO - root - 2022-02-24 19:49:09.269662: step 47270, total loss = 0.54, batch loss = 0.26 (146.1 examples/sec; 0.055 sec/batch; 2h:18m:55s remains)
INFO - root - 2022-02-24 19:49:09.632617: step 47280, total loss = 0.65, batch loss = 0.37 (339.7 examples/sec; 0.024 sec/batch; 0h:59m:44s remains)
INFO - root - 2022-02-24 19:49:09.959790: step 47290, total loss = 0.56, batch loss = 0.28 (287.0 examples/sec; 0.028 sec/batch; 1h:10m:42s remains)
INFO - root - 2022-02-24 19:49:10.269792: step 47300, total loss = 0.67, batch loss = 0.39 (305.9 examples/sec; 0.026 sec/batch; 1h:06m:19s remains)
INFO - root - 2022-02-24 19:49:10.655768: step 47310, total loss = 0.56, batch loss = 0.28 (173.2 examples/sec; 0.046 sec/batch; 1h:57m:08s remains)
INFO - root - 2022-02-24 19:49:11.016284: step 47320, total loss = 0.50, batch loss = 0.22 (225.0 examples/sec; 0.036 sec/batch; 1h:30m:11s remains)
INFO - root - 2022-02-24 19:49:11.635335: step 47330, total loss = 0.62, batch loss = 0.35 (213.7 examples/sec; 0.037 sec/batch; 1h:34m:56s remains)
INFO - root - 2022-02-24 19:49:12.038379: step 47340, total loss = 0.56, batch loss = 0.28 (226.7 examples/sec; 0.035 sec/batch; 1h:29m:29s remains)
INFO - root - 2022-02-24 19:49:12.405614: step 47350, total loss = 0.49, batch loss = 0.21 (220.9 examples/sec; 0.036 sec/batch; 1h:31m:50s remains)
INFO - root - 2022-02-24 19:49:12.730612: step 47360, total loss = 0.50, batch loss = 0.22 (332.4 examples/sec; 0.024 sec/batch; 1h:01m:01s remains)
INFO - root - 2022-02-24 19:49:13.186111: step 47370, total loss = 0.54, batch loss = 0.26 (155.5 examples/sec; 0.051 sec/batch; 2h:10m:28s remains)
INFO - root - 2022-02-24 19:49:13.679113: step 47380, total loss = 0.58, batch loss = 0.30 (179.0 examples/sec; 0.045 sec/batch; 1h:53m:18s remains)
INFO - root - 2022-02-24 19:49:13.982552: step 47390, total loss = 0.68, batch loss = 0.40 (230.3 examples/sec; 0.035 sec/batch; 1h:28m:03s remains)
INFO - root - 2022-02-24 19:49:14.328989: step 47400, total loss = 0.59, batch loss = 0.31 (159.8 examples/sec; 0.050 sec/batch; 2h:06m:56s remains)
INFO - root - 2022-02-24 19:49:14.749805: step 47410, total loss = 0.56, batch loss = 0.28 (287.2 examples/sec; 0.028 sec/batch; 1h:10m:37s remains)
INFO - root - 2022-02-24 19:49:15.067399: step 47420, total loss = 0.58, batch loss = 0.30 (276.2 examples/sec; 0.029 sec/batch; 1h:13m:24s remains)
INFO - root - 2022-02-24 19:49:15.536874: step 47430, total loss = 0.53, batch loss = 0.25 (106.5 examples/sec; 0.075 sec/batch; 3h:10m:25s remains)
INFO - root - 2022-02-24 19:49:15.963831: step 47440, total loss = 0.49, batch loss = 0.22 (327.1 examples/sec; 0.024 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 19:49:16.327527: step 47450, total loss = 0.62, batch loss = 0.34 (179.0 examples/sec; 0.045 sec/batch; 1h:53m:13s remains)
INFO - root - 2022-02-24 19:49:16.694407: step 47460, total loss = 0.51, batch loss = 0.24 (329.6 examples/sec; 0.024 sec/batch; 1h:01m:30s remains)
INFO - root - 2022-02-24 19:49:17.056440: step 47470, total loss = 0.49, batch loss = 0.22 (213.0 examples/sec; 0.038 sec/batch; 1h:35m:09s remains)
INFO - root - 2022-02-24 19:49:17.544237: step 47480, total loss = 0.51, batch loss = 0.24 (232.4 examples/sec; 0.034 sec/batch; 1h:27m:13s remains)
INFO - root - 2022-02-24 19:49:17.979516: step 47490, total loss = 0.67, batch loss = 0.40 (104.7 examples/sec; 0.076 sec/batch; 3h:13m:33s remains)
INFO - root - 2022-02-24 19:49:18.408061: step 47500, total loss = 0.57, batch loss = 0.30 (258.2 examples/sec; 0.031 sec/batch; 1h:18m:29s remains)
INFO - root - 2022-02-24 19:49:18.822105: step 47510, total loss = 0.55, batch loss = 0.27 (222.6 examples/sec; 0.036 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 19:49:19.118715: step 47520, total loss = 0.56, batch loss = 0.28 (302.1 examples/sec; 0.026 sec/batch; 1h:07m:04s remains)
INFO - root - 2022-02-24 19:49:19.558292: step 47530, total loss = 0.49, batch loss = 0.22 (157.7 examples/sec; 0.051 sec/batch; 2h:08m:29s remains)
INFO - root - 2022-02-24 19:49:20.116462: step 47540, total loss = 0.61, batch loss = 0.33 (343.2 examples/sec; 0.023 sec/batch; 0h:59m:02s remains)
INFO - root - 2022-02-24 19:49:20.548786: step 47550, total loss = 0.62, batch loss = 0.34 (189.6 examples/sec; 0.042 sec/batch; 1h:46m:50s remains)
INFO - root - 2022-02-24 19:49:20.866908: step 47560, total loss = 0.63, batch loss = 0.35 (318.9 examples/sec; 0.025 sec/batch; 1h:03m:31s remains)
INFO - root - 2022-02-24 19:49:21.158342: step 47570, total loss = 0.66, batch loss = 0.38 (228.5 examples/sec; 0.035 sec/batch; 1h:28m:38s remains)
INFO - root - 2022-02-24 19:49:21.469493: step 47580, total loss = 0.52, batch loss = 0.24 (323.7 examples/sec; 0.025 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 19:49:21.799029: step 47590, total loss = 0.59, batch loss = 0.31 (230.5 examples/sec; 0.035 sec/batch; 1h:27m:52s remains)
INFO - root - 2022-02-24 19:49:22.206695: step 47600, total loss = 0.52, batch loss = 0.25 (312.6 examples/sec; 0.026 sec/batch; 1h:04m:47s remains)
INFO - root - 2022-02-24 19:49:22.692199: step 47610, total loss = 0.56, batch loss = 0.28 (141.9 examples/sec; 0.056 sec/batch; 2h:22m:44s remains)
INFO - root - 2022-02-24 19:49:23.004851: step 47620, total loss = 0.83, batch loss = 0.56 (150.1 examples/sec; 0.053 sec/batch; 2h:14m:56s remains)
INFO - root - 2022-02-24 19:49:23.402370: step 47630, total loss = 0.59, batch loss = 0.32 (149.7 examples/sec; 0.053 sec/batch; 2h:15m:14s remains)
INFO - root - 2022-02-24 19:49:23.753445: step 47640, total loss = 0.61, batch loss = 0.33 (231.8 examples/sec; 0.035 sec/batch; 1h:27m:20s remains)
INFO - root - 2022-02-24 19:49:24.153154: step 47650, total loss = 0.63, batch loss = 0.35 (189.4 examples/sec; 0.042 sec/batch; 1h:46m:55s remains)
INFO - root - 2022-02-24 19:49:24.542756: step 47660, total loss = 0.57, batch loss = 0.30 (239.3 examples/sec; 0.033 sec/batch; 1h:24m:36s remains)
INFO - root - 2022-02-24 19:49:24.895912: step 47670, total loss = 0.51, batch loss = 0.24 (281.0 examples/sec; 0.028 sec/batch; 1h:12m:02s remains)
INFO - root - 2022-02-24 19:49:25.183641: step 47680, total loss = 0.49, batch loss = 0.22 (221.3 examples/sec; 0.036 sec/batch; 1h:31m:27s remains)
INFO - root - 2022-02-24 19:49:25.625094: step 47690, total loss = 0.67, batch loss = 0.39 (194.1 examples/sec; 0.041 sec/batch; 1h:44m:15s remains)
INFO - root - 2022-02-24 19:49:26.028197: step 47700, total loss = 0.54, batch loss = 0.26 (126.9 examples/sec; 0.063 sec/batch; 2h:39m:32s remains)
INFO - root - 2022-02-24 19:49:26.533873: step 47710, total loss = 0.51, batch loss = 0.24 (154.6 examples/sec; 0.052 sec/batch; 2h:10m:52s remains)
INFO - root - 2022-02-24 19:49:26.907463: step 47720, total loss = 0.53, batch loss = 0.25 (343.8 examples/sec; 0.023 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 19:49:27.241817: step 47730, total loss = 0.59, batch loss = 0.31 (234.2 examples/sec; 0.034 sec/batch; 1h:26m:24s remains)
INFO - root - 2022-02-24 19:49:27.568892: step 47740, total loss = 0.72, batch loss = 0.44 (336.5 examples/sec; 0.024 sec/batch; 1h:00m:08s remains)
INFO - root - 2022-02-24 19:49:27.839872: step 47750, total loss = 0.64, batch loss = 0.37 (336.2 examples/sec; 0.024 sec/batch; 1h:00m:10s remains)
INFO - root - 2022-02-24 19:49:28.262525: step 47760, total loss = 0.56, batch loss = 0.28 (195.3 examples/sec; 0.041 sec/batch; 1h:43m:35s remains)
INFO - root - 2022-02-24 19:49:28.678210: step 47770, total loss = 0.56, batch loss = 0.29 (146.2 examples/sec; 0.055 sec/batch; 2h:18m:20s remains)
INFO - root - 2022-02-24 19:49:29.022254: step 47780, total loss = 0.61, batch loss = 0.33 (321.5 examples/sec; 0.025 sec/batch; 1h:02m:55s remains)
INFO - root - 2022-02-24 19:49:29.335204: step 47790, total loss = 0.55, batch loss = 0.27 (317.2 examples/sec; 0.025 sec/batch; 1h:03m:46s remains)
INFO - root - 2022-02-24 19:49:29.671215: step 47800, total loss = 0.59, batch loss = 0.32 (133.1 examples/sec; 0.060 sec/batch; 2h:31m:55s remains)
INFO - root - 2022-02-24 19:49:30.050247: step 47810, total loss = 0.49, batch loss = 0.21 (229.6 examples/sec; 0.035 sec/batch; 1h:28m:06s remains)
INFO - root - 2022-02-24 19:49:30.557488: step 47820, total loss = 0.54, batch loss = 0.26 (352.6 examples/sec; 0.023 sec/batch; 0h:57m:21s remains)
INFO - root - 2022-02-24 19:49:30.935430: step 47830, total loss = 0.60, batch loss = 0.33 (323.2 examples/sec; 0.025 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 19:49:31.243460: step 47840, total loss = 0.46, batch loss = 0.18 (124.7 examples/sec; 0.064 sec/batch; 2h:42m:10s remains)
INFO - root - 2022-02-24 19:49:31.564799: step 47850, total loss = 0.57, batch loss = 0.29 (317.4 examples/sec; 0.025 sec/batch; 1h:03m:42s remains)
INFO - root - 2022-02-24 19:49:31.916811: step 47860, total loss = 0.57, batch loss = 0.29 (309.9 examples/sec; 0.026 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 19:49:32.219889: step 47870, total loss = 0.54, batch loss = 0.26 (370.3 examples/sec; 0.022 sec/batch; 0h:54m:35s remains)
INFO - root - 2022-02-24 19:49:32.605212: step 47880, total loss = 0.61, batch loss = 0.34 (150.3 examples/sec; 0.053 sec/batch; 2h:14m:28s remains)
INFO - root - 2022-02-24 19:49:33.077284: step 47890, total loss = 0.56, batch loss = 0.29 (352.1 examples/sec; 0.023 sec/batch; 0h:57m:24s remains)
INFO - root - 2022-02-24 19:49:33.449721: step 47900, total loss = 0.66, batch loss = 0.38 (198.5 examples/sec; 0.040 sec/batch; 1h:41m:49s remains)
INFO - root - 2022-02-24 19:49:33.805138: step 47910, total loss = 0.61, batch loss = 0.33 (244.7 examples/sec; 0.033 sec/batch; 1h:22m:35s remains)
INFO - root - 2022-02-24 19:49:34.203153: step 47920, total loss = 0.56, batch loss = 0.28 (119.4 examples/sec; 0.067 sec/batch; 2h:49m:13s remains)
INFO - root - 2022-02-24 19:49:34.601915: step 47930, total loss = 0.66, batch loss = 0.38 (137.0 examples/sec; 0.058 sec/batch; 2h:27m:30s remains)
INFO - root - 2022-02-24 19:49:34.941923: step 47940, total loss = 0.66, batch loss = 0.38 (139.1 examples/sec; 0.058 sec/batch; 2h:25m:17s remains)
INFO - root - 2022-02-24 19:49:35.399507: step 47950, total loss = 0.64, batch loss = 0.36 (173.3 examples/sec; 0.046 sec/batch; 1h:56m:37s remains)
INFO - root - 2022-02-24 19:49:35.765346: step 47960, total loss = 0.52, batch loss = 0.24 (310.8 examples/sec; 0.026 sec/batch; 1h:05m:00s remains)
INFO - root - 2022-02-24 19:49:36.070892: step 47970, total loss = 0.57, batch loss = 0.30 (274.4 examples/sec; 0.029 sec/batch; 1h:13m:38s remains)
INFO - root - 2022-02-24 19:49:36.447969: step 47980, total loss = 0.53, batch loss = 0.25 (251.0 examples/sec; 0.032 sec/batch; 1h:20m:29s remains)
INFO - root - 2022-02-24 19:49:36.916556: step 47990, total loss = 0.55, batch loss = 0.27 (146.9 examples/sec; 0.054 sec/batch; 2h:17m:30s remains)
INFO - root - 2022-02-24 19:49:37.310094: step 48000, total loss = 0.59, batch loss = 0.32 (302.5 examples/sec; 0.026 sec/batch; 1h:06m:46s remains)
INFO - root - 2022-02-24 19:49:37.755982: step 48010, total loss = 0.56, batch loss = 0.28 (244.1 examples/sec; 0.033 sec/batch; 1h:22m:45s remains)
INFO - root - 2022-02-24 19:49:38.624859: step 48020, total loss = 0.57, batch loss = 0.29 (258.6 examples/sec; 0.031 sec/batch; 1h:18m:05s remains)
INFO - root - 2022-02-24 19:49:39.322497: step 48030, total loss = 0.55, batch loss = 0.28 (26.6 examples/sec; 0.300 sec/batch; 12h:38m:18s remains)
INFO - root - 2022-02-24 19:49:40.171146: step 48040, total loss = 0.56, batch loss = 0.28 (33.7 examples/sec; 0.238 sec/batch; 9h:59m:42s remains)
INFO - root - 2022-02-24 19:49:40.534268: step 48050, total loss = 0.56, batch loss = 0.29 (261.3 examples/sec; 0.031 sec/batch; 1h:17m:17s remains)
INFO - root - 2022-02-24 19:49:40.998017: step 48060, total loss = 0.64, batch loss = 0.36 (324.3 examples/sec; 0.025 sec/batch; 1h:02m:16s remains)
INFO - root - 2022-02-24 19:49:41.497546: step 48070, total loss = 0.50, batch loss = 0.22 (112.3 examples/sec; 0.071 sec/batch; 2h:59m:48s remains)
INFO - root - 2022-02-24 19:49:41.909903: step 48080, total loss = 0.52, batch loss = 0.24 (228.8 examples/sec; 0.035 sec/batch; 1h:28m:14s remains)
INFO - root - 2022-02-24 19:49:42.240580: step 48090, total loss = 0.64, batch loss = 0.36 (312.3 examples/sec; 0.026 sec/batch; 1h:04m:38s remains)
INFO - root - 2022-02-24 19:49:42.564162: step 48100, total loss = 0.74, batch loss = 0.47 (332.2 examples/sec; 0.024 sec/batch; 1h:00m:46s remains)
INFO - root - 2022-02-24 19:49:43.094215: step 48110, total loss = 0.53, batch loss = 0.25 (262.5 examples/sec; 0.030 sec/batch; 1h:16m:53s remains)
INFO - root - 2022-02-24 19:49:43.633986: step 48120, total loss = 0.53, batch loss = 0.26 (91.4 examples/sec; 0.088 sec/batch; 3h:40m:53s remains)
INFO - root - 2022-02-24 19:49:44.241162: step 48130, total loss = 0.62, batch loss = 0.34 (105.5 examples/sec; 0.076 sec/batch; 3h:11m:22s remains)
INFO - root - 2022-02-24 19:49:44.724456: step 48140, total loss = 0.63, batch loss = 0.35 (237.0 examples/sec; 0.034 sec/batch; 1h:25m:09s remains)
INFO - root - 2022-02-24 19:49:45.202705: step 48150, total loss = 0.65, batch loss = 0.38 (179.9 examples/sec; 0.044 sec/batch; 1h:52m:11s remains)
INFO - root - 2022-02-24 19:49:45.914494: step 48160, total loss = 0.50, batch loss = 0.22 (147.3 examples/sec; 0.054 sec/batch; 2h:16m:57s remains)
INFO - root - 2022-02-24 19:49:46.295029: step 48170, total loss = 0.54, batch loss = 0.26 (294.2 examples/sec; 0.027 sec/batch; 1h:08m:34s remains)
INFO - root - 2022-02-24 19:49:46.647676: step 48180, total loss = 0.62, batch loss = 0.34 (288.1 examples/sec; 0.028 sec/batch; 1h:10m:01s remains)
INFO - root - 2022-02-24 19:49:46.984171: step 48190, total loss = 0.58, batch loss = 0.31 (217.0 examples/sec; 0.037 sec/batch; 1h:32m:58s remains)
INFO - root - 2022-02-24 19:49:47.337545: step 48200, total loss = 0.57, batch loss = 0.30 (147.5 examples/sec; 0.054 sec/batch; 2h:16m:45s remains)
INFO - root - 2022-02-24 19:49:47.889260: step 48210, total loss = 0.76, batch loss = 0.48 (345.2 examples/sec; 0.023 sec/batch; 0h:58m:26s remains)
INFO - root - 2022-02-24 19:49:48.223707: step 48220, total loss = 0.52, batch loss = 0.25 (306.2 examples/sec; 0.026 sec/batch; 1h:05m:52s remains)
INFO - root - 2022-02-24 19:49:48.568514: step 48230, total loss = 0.51, batch loss = 0.24 (129.2 examples/sec; 0.062 sec/batch; 2h:36m:09s remains)
INFO - root - 2022-02-24 19:49:48.880178: step 48240, total loss = 0.60, batch loss = 0.32 (128.1 examples/sec; 0.062 sec/batch; 2h:37m:24s remains)
INFO - root - 2022-02-24 19:49:49.214698: step 48250, total loss = 0.51, batch loss = 0.24 (247.9 examples/sec; 0.032 sec/batch; 1h:21m:21s remains)
INFO - root - 2022-02-24 19:49:49.715506: step 48260, total loss = 0.49, batch loss = 0.22 (138.6 examples/sec; 0.058 sec/batch; 2h:25m:32s remains)
INFO - root - 2022-02-24 19:49:50.154405: step 48270, total loss = 0.55, batch loss = 0.28 (124.2 examples/sec; 0.064 sec/batch; 2h:42m:23s remains)
INFO - root - 2022-02-24 19:49:50.549646: step 48280, total loss = 0.64, batch loss = 0.37 (366.9 examples/sec; 0.022 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 19:49:50.873975: step 48290, total loss = 0.72, batch loss = 0.44 (319.7 examples/sec; 0.025 sec/batch; 1h:03m:03s remains)
INFO - root - 2022-02-24 19:49:51.221679: step 48300, total loss = 0.58, batch loss = 0.30 (201.7 examples/sec; 0.040 sec/batch; 1h:39m:58s remains)
INFO - root - 2022-02-24 19:49:51.682001: step 48310, total loss = 0.64, batch loss = 0.37 (291.3 examples/sec; 0.027 sec/batch; 1h:09m:12s remains)
INFO - root - 2022-02-24 19:49:52.110569: step 48320, total loss = 0.58, batch loss = 0.30 (139.5 examples/sec; 0.057 sec/batch; 2h:24m:31s remains)
INFO - root - 2022-02-24 19:49:52.545326: step 48330, total loss = 0.54, batch loss = 0.26 (371.7 examples/sec; 0.022 sec/batch; 0h:54m:13s remains)
INFO - root - 2022-02-24 19:49:52.875105: step 48340, total loss = 0.45, batch loss = 0.17 (160.2 examples/sec; 0.050 sec/batch; 2h:05m:47s remains)
INFO - root - 2022-02-24 19:49:53.264116: step 48350, total loss = 0.53, batch loss = 0.25 (101.1 examples/sec; 0.079 sec/batch; 3h:19m:18s remains)
INFO - root - 2022-02-24 19:49:53.553544: step 48360, total loss = 0.51, batch loss = 0.24 (306.9 examples/sec; 0.026 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 19:49:53.924437: step 48370, total loss = 0.50, batch loss = 0.23 (339.3 examples/sec; 0.024 sec/batch; 0h:59m:23s remains)
INFO - root - 2022-02-24 19:49:54.331608: step 48380, total loss = 0.57, batch loss = 0.29 (204.1 examples/sec; 0.039 sec/batch; 1h:38m:42s remains)
INFO - root - 2022-02-24 19:49:54.791529: step 48390, total loss = 0.56, batch loss = 0.28 (145.0 examples/sec; 0.055 sec/batch; 2h:18m:57s remains)
INFO - root - 2022-02-24 19:49:55.154589: step 48400, total loss = 0.57, batch loss = 0.29 (340.4 examples/sec; 0.024 sec/batch; 0h:59m:11s remains)
INFO - root - 2022-02-24 19:49:55.576574: step 48410, total loss = 0.73, batch loss = 0.45 (215.4 examples/sec; 0.037 sec/batch; 1h:33m:30s remains)
INFO - root - 2022-02-24 19:49:55.923158: step 48420, total loss = 0.60, batch loss = 0.33 (179.2 examples/sec; 0.045 sec/batch; 1h:52m:24s remains)
INFO - root - 2022-02-24 19:49:56.431844: step 48430, total loss = 0.55, batch loss = 0.27 (134.6 examples/sec; 0.059 sec/batch; 2h:29m:42s remains)
INFO - root - 2022-02-24 19:49:56.885126: step 48440, total loss = 0.61, batch loss = 0.34 (231.2 examples/sec; 0.035 sec/batch; 1h:27m:07s remains)
INFO - root - 2022-02-24 19:49:57.231504: step 48450, total loss = 0.54, batch loss = 0.26 (238.1 examples/sec; 0.034 sec/batch; 1h:24m:35s remains)
INFO - root - 2022-02-24 19:49:57.580964: step 48460, total loss = 0.56, batch loss = 0.28 (332.5 examples/sec; 0.024 sec/batch; 1h:00m:33s remains)
INFO - root - 2022-02-24 19:49:57.878125: step 48470, total loss = 0.53, batch loss = 0.26 (331.6 examples/sec; 0.024 sec/batch; 1h:00m:43s remains)
INFO - root - 2022-02-24 19:49:58.333787: step 48480, total loss = 0.53, batch loss = 0.26 (173.7 examples/sec; 0.046 sec/batch; 1h:55m:55s remains)
INFO - root - 2022-02-24 19:49:58.714222: step 48490, total loss = 0.56, batch loss = 0.28 (331.6 examples/sec; 0.024 sec/batch; 1h:00m:43s remains)
INFO - root - 2022-02-24 19:49:59.144358: step 48500, total loss = 0.66, batch loss = 0.39 (247.5 examples/sec; 0.032 sec/batch; 1h:21m:20s remains)
INFO - root - 2022-02-24 19:49:59.577636: step 48510, total loss = 0.52, batch loss = 0.24 (287.0 examples/sec; 0.028 sec/batch; 1h:10m:09s remains)
INFO - root - 2022-02-24 19:49:59.884432: step 48520, total loss = 0.54, batch loss = 0.27 (310.4 examples/sec; 0.026 sec/batch; 1h:04m:51s remains)
INFO - root - 2022-02-24 19:50:00.303272: step 48530, total loss = 0.61, batch loss = 0.33 (322.1 examples/sec; 0.025 sec/batch; 1h:02m:29s remains)
INFO - root - 2022-02-24 19:50:00.805383: step 48540, total loss = 0.54, batch loss = 0.27 (217.3 examples/sec; 0.037 sec/batch; 1h:32m:38s remains)
INFO - root - 2022-02-24 19:50:01.139824: step 48550, total loss = 0.53, batch loss = 0.25 (322.9 examples/sec; 0.025 sec/batch; 1h:02m:19s remains)
INFO - root - 2022-02-24 19:50:01.455455: step 48560, total loss = 0.51, batch loss = 0.23 (328.9 examples/sec; 0.024 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 19:50:01.796787: step 48570, total loss = 0.62, batch loss = 0.34 (239.6 examples/sec; 0.033 sec/batch; 1h:24m:00s remains)
INFO - root - 2022-02-24 19:50:02.158491: step 48580, total loss = 0.65, batch loss = 0.37 (119.9 examples/sec; 0.067 sec/batch; 2h:47m:47s remains)
INFO - root - 2022-02-24 19:50:02.678676: step 48590, total loss = 0.57, batch loss = 0.29 (105.5 examples/sec; 0.076 sec/batch; 3h:10m:48s remains)
INFO - root - 2022-02-24 19:50:03.000809: step 48600, total loss = 0.50, batch loss = 0.23 (339.5 examples/sec; 0.024 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 19:50:03.445948: step 48610, total loss = 0.71, batch loss = 0.43 (161.6 examples/sec; 0.049 sec/batch; 2h:04m:28s remains)
INFO - root - 2022-02-24 19:50:03.711661: step 48620, total loss = 0.58, batch loss = 0.30 (357.4 examples/sec; 0.022 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 19:50:04.156443: step 48630, total loss = 0.62, batch loss = 0.34 (90.1 examples/sec; 0.089 sec/batch; 3h:43m:22s remains)
INFO - root - 2022-02-24 19:50:04.594312: step 48640, total loss = 0.57, batch loss = 0.30 (214.6 examples/sec; 0.037 sec/batch; 1h:33m:42s remains)
INFO - root - 2022-02-24 19:50:04.962225: step 48650, total loss = 0.65, batch loss = 0.37 (282.9 examples/sec; 0.028 sec/batch; 1h:11m:05s remains)
INFO - root - 2022-02-24 19:50:05.294281: step 48660, total loss = 0.59, batch loss = 0.31 (335.5 examples/sec; 0.024 sec/batch; 0h:59m:57s remains)
INFO - root - 2022-02-24 19:50:05.781162: step 48670, total loss = 0.63, batch loss = 0.36 (283.2 examples/sec; 0.028 sec/batch; 1h:11m:01s remains)
INFO - root - 2022-02-24 19:50:06.232133: step 48680, total loss = 0.60, batch loss = 0.32 (311.2 examples/sec; 0.026 sec/batch; 1h:04m:37s remains)
INFO - root - 2022-02-24 19:50:06.722254: step 48690, total loss = 0.54, batch loss = 0.27 (124.4 examples/sec; 0.064 sec/batch; 2h:41m:37s remains)
INFO - root - 2022-02-24 19:50:07.107331: step 48700, total loss = 0.57, batch loss = 0.30 (134.0 examples/sec; 0.060 sec/batch; 2h:30m:01s remains)
INFO - root - 2022-02-24 19:50:07.489484: step 48710, total loss = 0.56, batch loss = 0.28 (343.0 examples/sec; 0.023 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 19:50:07.825497: step 48720, total loss = 0.74, batch loss = 0.46 (289.3 examples/sec; 0.028 sec/batch; 1h:09m:29s remains)
INFO - root - 2022-02-24 19:50:08.164477: step 48730, total loss = 0.63, batch loss = 0.35 (238.0 examples/sec; 0.034 sec/batch; 1h:24m:28s remains)
INFO - root - 2022-02-24 19:50:08.518750: step 48740, total loss = 0.68, batch loss = 0.40 (282.8 examples/sec; 0.028 sec/batch; 1h:11m:04s remains)
INFO - root - 2022-02-24 19:50:08.968560: step 48750, total loss = 0.56, batch loss = 0.28 (222.7 examples/sec; 0.036 sec/batch; 1h:30m:15s remains)
INFO - root - 2022-02-24 19:50:09.376196: step 48760, total loss = 0.66, batch loss = 0.38 (200.1 examples/sec; 0.040 sec/batch; 1h:40m:27s remains)
INFO - root - 2022-02-24 19:50:09.742436: step 48770, total loss = 0.53, batch loss = 0.25 (320.9 examples/sec; 0.025 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:50:10.141661: step 48780, total loss = 0.68, batch loss = 0.40 (196.4 examples/sec; 0.041 sec/batch; 1h:42m:19s remains)
INFO - root - 2022-02-24 19:50:11.094558: step 48790, total loss = 0.62, batch loss = 0.34 (175.6 examples/sec; 0.046 sec/batch; 1h:54m:27s remains)
INFO - root - 2022-02-24 19:50:11.536906: step 48800, total loss = 0.51, batch loss = 0.23 (113.5 examples/sec; 0.071 sec/batch; 2h:57m:04s remains)
INFO - root - 2022-02-24 19:50:12.048403: step 48810, total loss = 0.63, batch loss = 0.35 (220.0 examples/sec; 0.036 sec/batch; 1h:31m:19s remains)
INFO - root - 2022-02-24 19:50:12.386732: step 48820, total loss = 0.62, batch loss = 0.34 (313.2 examples/sec; 0.026 sec/batch; 1h:04m:09s remains)
INFO - root - 2022-02-24 19:50:12.749917: step 48830, total loss = 0.65, batch loss = 0.38 (349.0 examples/sec; 0.023 sec/batch; 0h:57m:33s remains)
INFO - root - 2022-02-24 19:50:13.202446: step 48840, total loss = 0.56, batch loss = 0.28 (201.4 examples/sec; 0.040 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 19:50:13.635775: step 48850, total loss = 0.57, batch loss = 0.29 (82.9 examples/sec; 0.096 sec/batch; 4h:02m:14s remains)
INFO - root - 2022-02-24 19:50:14.165695: step 48860, total loss = 0.58, batch loss = 0.31 (149.6 examples/sec; 0.053 sec/batch; 2h:14m:17s remains)
INFO - root - 2022-02-24 19:50:14.564848: step 48870, total loss = 0.53, batch loss = 0.25 (247.5 examples/sec; 0.032 sec/batch; 1h:21m:08s remains)
INFO - root - 2022-02-24 19:50:14.906984: step 48880, total loss = 0.62, batch loss = 0.35 (307.4 examples/sec; 0.026 sec/batch; 1h:05m:19s remains)
INFO - root - 2022-02-24 19:50:15.445573: step 48890, total loss = 0.50, batch loss = 0.22 (250.5 examples/sec; 0.032 sec/batch; 1h:20m:10s remains)
INFO - root - 2022-02-24 19:50:16.289256: step 48900, total loss = 0.55, batch loss = 0.27 (158.6 examples/sec; 0.050 sec/batch; 2h:06m:36s remains)
INFO - root - 2022-02-24 19:50:16.749735: step 48910, total loss = 0.49, batch loss = 0.22 (329.2 examples/sec; 0.024 sec/batch; 1h:00m:59s remains)
INFO - root - 2022-02-24 19:50:17.100988: step 48920, total loss = 0.56, batch loss = 0.29 (198.1 examples/sec; 0.040 sec/batch; 1h:41m:20s remains)
INFO - root - 2022-02-24 19:50:17.484419: step 48930, total loss = 0.53, batch loss = 0.26 (144.8 examples/sec; 0.055 sec/batch; 2h:18m:36s remains)
INFO - root - 2022-02-24 19:50:17.906301: step 48940, total loss = 0.55, batch loss = 0.28 (97.7 examples/sec; 0.082 sec/batch; 3h:25m:27s remains)
INFO - root - 2022-02-24 19:50:18.280046: step 48950, total loss = 0.54, batch loss = 0.27 (221.7 examples/sec; 0.036 sec/batch; 1h:30m:32s remains)
INFO - root - 2022-02-24 19:50:18.657962: step 48960, total loss = 0.49, batch loss = 0.21 (326.0 examples/sec; 0.025 sec/batch; 1h:01m:34s remains)
INFO - root - 2022-02-24 19:50:18.932094: step 48970, total loss = 0.63, batch loss = 0.35 (248.3 examples/sec; 0.032 sec/batch; 1h:20m:50s remains)
INFO - root - 2022-02-24 19:50:19.235094: step 48980, total loss = 0.53, batch loss = 0.25 (337.8 examples/sec; 0.024 sec/batch; 0h:59m:24s remains)
INFO - root - 2022-02-24 19:50:19.661815: step 48990, total loss = 0.69, batch loss = 0.41 (165.8 examples/sec; 0.048 sec/batch; 2h:01m:00s remains)
INFO - root - 2022-02-24 19:50:20.109404: step 49000, total loss = 0.56, batch loss = 0.28 (106.1 examples/sec; 0.075 sec/batch; 3h:09m:04s remains)
INFO - root - 2022-02-24 19:50:20.765059: step 49010, total loss = 0.54, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:09m:01s remains)
INFO - root - 2022-02-24 19:50:21.140852: step 49020, total loss = 0.66, batch loss = 0.39 (161.0 examples/sec; 0.050 sec/batch; 2h:04m:38s remains)
INFO - root - 2022-02-24 19:50:21.569642: step 49030, total loss = 0.62, batch loss = 0.34 (189.5 examples/sec; 0.042 sec/batch; 1h:45m:51s remains)
INFO - root - 2022-02-24 19:50:22.057821: step 49040, total loss = 0.56, batch loss = 0.29 (329.5 examples/sec; 0.024 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 19:50:22.476193: step 49050, total loss = 0.67, batch loss = 0.40 (215.2 examples/sec; 0.037 sec/batch; 1h:33m:13s remains)
INFO - root - 2022-02-24 19:50:22.842941: step 49060, total loss = 0.56, batch loss = 0.28 (261.4 examples/sec; 0.031 sec/batch; 1h:16m:43s remains)
INFO - root - 2022-02-24 19:50:23.205080: step 49070, total loss = 0.61, batch loss = 0.33 (279.1 examples/sec; 0.029 sec/batch; 1h:11m:51s remains)
INFO - root - 2022-02-24 19:50:23.585244: step 49080, total loss = 0.58, batch loss = 0.30 (138.9 examples/sec; 0.058 sec/batch; 2h:24m:23s remains)
INFO - root - 2022-02-24 19:50:24.062066: step 49090, total loss = 0.65, batch loss = 0.37 (162.2 examples/sec; 0.049 sec/batch; 2h:03m:40s remains)
INFO - root - 2022-02-24 19:50:24.425955: step 49100, total loss = 0.62, batch loss = 0.35 (350.9 examples/sec; 0.023 sec/batch; 0h:57m:09s remains)
INFO - root - 2022-02-24 19:50:24.811868: step 49110, total loss = 0.57, batch loss = 0.29 (187.3 examples/sec; 0.043 sec/batch; 1h:47m:04s remains)
INFO - root - 2022-02-24 19:50:25.091778: step 49120, total loss = 0.56, batch loss = 0.28 (335.0 examples/sec; 0.024 sec/batch; 0h:59m:51s remains)
INFO - root - 2022-02-24 19:50:25.444482: step 49130, total loss = 0.58, batch loss = 0.30 (191.5 examples/sec; 0.042 sec/batch; 1h:44m:42s remains)
INFO - root - 2022-02-24 19:50:26.006385: step 49140, total loss = 0.59, batch loss = 0.31 (193.4 examples/sec; 0.041 sec/batch; 1h:43m:39s remains)
INFO - root - 2022-02-24 19:50:26.426929: step 49150, total loss = 0.52, batch loss = 0.25 (236.6 examples/sec; 0.034 sec/batch; 1h:24m:44s remains)
INFO - root - 2022-02-24 19:50:26.782807: step 49160, total loss = 0.67, batch loss = 0.39 (301.7 examples/sec; 0.027 sec/batch; 1h:06m:26s remains)
INFO - root - 2022-02-24 19:50:27.164992: step 49170, total loss = 0.61, batch loss = 0.34 (167.6 examples/sec; 0.048 sec/batch; 1h:59m:34s remains)
INFO - root - 2022-02-24 19:50:27.500690: step 49180, total loss = 0.56, batch loss = 0.28 (310.2 examples/sec; 0.026 sec/batch; 1h:04m:36s remains)
INFO - root - 2022-02-24 19:50:27.825680: step 49190, total loss = 0.54, batch loss = 0.26 (235.6 examples/sec; 0.034 sec/batch; 1h:25m:04s remains)
INFO - root - 2022-02-24 19:50:28.215960: step 49200, total loss = 0.56, batch loss = 0.28 (195.3 examples/sec; 0.041 sec/batch; 1h:42m:36s remains)
INFO - root - 2022-02-24 19:50:28.638255: step 49210, total loss = 0.55, batch loss = 0.28 (233.8 examples/sec; 0.034 sec/batch; 1h:25m:42s remains)
INFO - root - 2022-02-24 19:50:28.993574: step 49220, total loss = 0.64, batch loss = 0.37 (315.2 examples/sec; 0.025 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 19:50:29.358869: step 49230, total loss = 0.57, batch loss = 0.29 (218.5 examples/sec; 0.037 sec/batch; 1h:31m:42s remains)
INFO - root - 2022-02-24 19:50:29.630800: step 49240, total loss = 0.70, batch loss = 0.42 (182.2 examples/sec; 0.044 sec/batch; 1h:49m:58s remains)
INFO - root - 2022-02-24 19:50:29.997662: step 49250, total loss = 0.63, batch loss = 0.35 (349.7 examples/sec; 0.023 sec/batch; 0h:57m:17s remains)
INFO - root - 2022-02-24 19:50:30.340820: step 49260, total loss = 0.56, batch loss = 0.28 (320.5 examples/sec; 0.025 sec/batch; 1h:02m:30s remains)
INFO - root - 2022-02-24 19:50:30.785121: step 49270, total loss = 0.58, batch loss = 0.30 (79.6 examples/sec; 0.101 sec/batch; 4h:11m:42s remains)
INFO - root - 2022-02-24 19:50:31.151289: step 49280, total loss = 0.71, batch loss = 0.43 (249.9 examples/sec; 0.032 sec/batch; 1h:20m:09s remains)
INFO - root - 2022-02-24 19:50:31.513625: step 49290, total loss = 0.54, batch loss = 0.26 (187.0 examples/sec; 0.043 sec/batch; 1h:47m:05s remains)
INFO - root - 2022-02-24 19:50:31.845501: step 49300, total loss = 0.58, batch loss = 0.30 (169.0 examples/sec; 0.047 sec/batch; 1h:58m:30s remains)
INFO - root - 2022-02-24 19:50:32.355455: step 49310, total loss = 0.54, batch loss = 0.26 (338.7 examples/sec; 0.024 sec/batch; 0h:59m:07s remains)
INFO - root - 2022-02-24 19:50:32.872905: step 49320, total loss = 0.52, batch loss = 0.24 (106.3 examples/sec; 0.075 sec/batch; 3h:08m:17s remains)
INFO - root - 2022-02-24 19:50:33.243179: step 49330, total loss = 0.59, batch loss = 0.31 (318.1 examples/sec; 0.025 sec/batch; 1h:02m:57s remains)
INFO - root - 2022-02-24 19:50:33.545703: step 49340, total loss = 0.56, batch loss = 0.28 (347.5 examples/sec; 0.023 sec/batch; 0h:57m:37s remains)
INFO - root - 2022-02-24 19:50:33.870314: step 49350, total loss = 0.57, batch loss = 0.29 (348.5 examples/sec; 0.023 sec/batch; 0h:57m:26s remains)
INFO - root - 2022-02-24 19:50:34.179568: step 49360, total loss = 0.66, batch loss = 0.39 (140.4 examples/sec; 0.057 sec/batch; 2h:22m:36s remains)
INFO - root - 2022-02-24 19:50:34.574186: step 49370, total loss = 0.54, batch loss = 0.27 (348.3 examples/sec; 0.023 sec/batch; 0h:57m:28s remains)
INFO - root - 2022-02-24 19:50:35.062399: step 49380, total loss = 0.54, batch loss = 0.27 (99.8 examples/sec; 0.080 sec/batch; 3h:20m:28s remains)
INFO - root - 2022-02-24 19:50:35.462901: step 49390, total loss = 0.58, batch loss = 0.31 (308.5 examples/sec; 0.026 sec/batch; 1h:04m:53s remains)
INFO - root - 2022-02-24 19:50:35.900211: step 49400, total loss = 0.64, batch loss = 0.36 (90.8 examples/sec; 0.088 sec/batch; 3h:40m:19s remains)
INFO - root - 2022-02-24 19:50:36.314436: step 49410, total loss = 0.64, batch loss = 0.36 (105.1 examples/sec; 0.076 sec/batch; 3h:10m:25s remains)
INFO - root - 2022-02-24 19:50:36.751234: step 49420, total loss = 0.56, batch loss = 0.29 (166.4 examples/sec; 0.048 sec/batch; 2h:00m:14s remains)
INFO - root - 2022-02-24 19:50:37.150892: step 49430, total loss = 0.65, batch loss = 0.37 (303.3 examples/sec; 0.026 sec/batch; 1h:05m:57s remains)
INFO - root - 2022-02-24 19:50:37.563930: step 49440, total loss = 0.61, batch loss = 0.34 (106.2 examples/sec; 0.075 sec/batch; 3h:08m:19s remains)
INFO - root - 2022-02-24 19:50:37.852229: step 49450, total loss = 0.67, batch loss = 0.40 (304.5 examples/sec; 0.026 sec/batch; 1h:05m:42s remains)
INFO - root - 2022-02-24 19:50:38.191084: step 49460, total loss = 0.66, batch loss = 0.39 (331.0 examples/sec; 0.024 sec/batch; 1h:00m:26s remains)
INFO - root - 2022-02-24 19:50:38.566816: step 49470, total loss = 0.56, batch loss = 0.28 (133.7 examples/sec; 0.060 sec/batch; 2h:29m:38s remains)
INFO - root - 2022-02-24 19:50:38.962736: step 49480, total loss = 0.56, batch loss = 0.29 (358.1 examples/sec; 0.022 sec/batch; 0h:55m:51s remains)
INFO - root - 2022-02-24 19:50:39.421144: step 49490, total loss = 0.47, batch loss = 0.19 (216.3 examples/sec; 0.037 sec/batch; 1h:32m:28s remains)
INFO - root - 2022-02-24 19:50:39.755355: step 49500, total loss = 0.63, batch loss = 0.36 (354.1 examples/sec; 0.023 sec/batch; 0h:56m:28s remains)
INFO - root - 2022-02-24 19:50:40.064984: step 49510, total loss = 0.57, batch loss = 0.29 (335.1 examples/sec; 0.024 sec/batch; 0h:59m:40s remains)
INFO - root - 2022-02-24 19:50:40.430650: step 49520, total loss = 0.53, batch loss = 0.25 (328.2 examples/sec; 0.024 sec/batch; 1h:00m:55s remains)
INFO - root - 2022-02-24 19:50:40.869161: step 49530, total loss = 0.63, batch loss = 0.35 (162.1 examples/sec; 0.049 sec/batch; 2h:03m:23s remains)
INFO - root - 2022-02-24 19:50:41.269251: step 49540, total loss = 0.69, batch loss = 0.41 (178.5 examples/sec; 0.045 sec/batch; 1h:52m:00s remains)
INFO - root - 2022-02-24 19:50:41.714070: step 49550, total loss = 0.51, batch loss = 0.24 (84.4 examples/sec; 0.095 sec/batch; 3h:56m:57s remains)
INFO - root - 2022-02-24 19:50:42.091688: step 49560, total loss = 0.59, batch loss = 0.32 (254.4 examples/sec; 0.031 sec/batch; 1h:18m:35s remains)
INFO - root - 2022-02-24 19:50:42.582872: step 49570, total loss = 0.60, batch loss = 0.33 (160.8 examples/sec; 0.050 sec/batch; 2h:04m:17s remains)
INFO - root - 2022-02-24 19:50:43.320330: step 49580, total loss = 0.59, batch loss = 0.31 (173.8 examples/sec; 0.046 sec/batch; 1h:54m:59s remains)
INFO - root - 2022-02-24 19:50:43.765532: step 49590, total loss = 0.55, batch loss = 0.27 (346.1 examples/sec; 0.023 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 19:50:44.254443: step 49600, total loss = 0.51, batch loss = 0.24 (295.9 examples/sec; 0.027 sec/batch; 1h:07m:32s remains)
INFO - root - 2022-02-24 19:50:44.886232: step 49610, total loss = 0.51, batch loss = 0.23 (120.4 examples/sec; 0.066 sec/batch; 2h:45m:56s remains)
INFO - root - 2022-02-24 19:50:45.581812: step 49620, total loss = 0.69, batch loss = 0.41 (139.4 examples/sec; 0.057 sec/batch; 2h:23m:23s remains)
INFO - root - 2022-02-24 19:50:46.404335: step 49630, total loss = 0.50, batch loss = 0.22 (96.7 examples/sec; 0.083 sec/batch; 3h:26m:40s remains)
INFO - root - 2022-02-24 19:50:46.720527: step 49640, total loss = 0.71, batch loss = 0.43 (246.5 examples/sec; 0.032 sec/batch; 1h:21m:02s remains)
INFO - root - 2022-02-24 19:50:47.034983: step 49650, total loss = 0.59, batch loss = 0.32 (336.8 examples/sec; 0.024 sec/batch; 0h:59m:18s remains)
INFO - root - 2022-02-24 19:50:47.365420: step 49660, total loss = 0.52, batch loss = 0.25 (213.4 examples/sec; 0.037 sec/batch; 1h:33m:37s remains)
INFO - root - 2022-02-24 19:50:47.824677: step 49670, total loss = 0.56, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 6h:17m:01s remains)
INFO - root - 2022-02-24 19:50:48.402819: step 49680, total loss = 0.55, batch loss = 0.27 (217.1 examples/sec; 0.037 sec/batch; 1h:32m:00s remains)
INFO - root - 2022-02-24 19:50:48.867401: step 49690, total loss = 0.50, batch loss = 0.23 (124.3 examples/sec; 0.064 sec/batch; 2h:40m:44s remains)
INFO - root - 2022-02-24 19:50:49.266828: step 49700, total loss = 0.52, batch loss = 0.24 (221.4 examples/sec; 0.036 sec/batch; 1h:30m:12s remains)
INFO - root - 2022-02-24 19:50:49.614741: step 49710, total loss = 0.53, batch loss = 0.26 (359.0 examples/sec; 0.022 sec/batch; 0h:55m:38s remains)
INFO - root - 2022-02-24 19:50:49.907865: step 49720, total loss = 0.58, batch loss = 0.30 (330.1 examples/sec; 0.024 sec/batch; 1h:00m:30s remains)
INFO - root - 2022-02-24 19:50:50.274675: step 49730, total loss = 0.60, batch loss = 0.32 (323.4 examples/sec; 0.025 sec/batch; 1h:01m:45s remains)
INFO - root - 2022-02-24 19:50:50.641950: step 49740, total loss = 0.54, batch loss = 0.26 (304.4 examples/sec; 0.026 sec/batch; 1h:05m:35s remains)
INFO - root - 2022-02-24 19:50:51.143118: step 49750, total loss = 0.58, batch loss = 0.30 (184.1 examples/sec; 0.043 sec/batch; 1h:48m:25s remains)
INFO - root - 2022-02-24 19:50:51.903004: step 49760, total loss = 0.55, batch loss = 0.28 (348.4 examples/sec; 0.023 sec/batch; 0h:57m:18s remains)
INFO - root - 2022-02-24 19:50:52.232541: step 49770, total loss = 0.66, batch loss = 0.39 (253.8 examples/sec; 0.032 sec/batch; 1h:18m:39s remains)
INFO - root - 2022-02-24 19:50:52.539787: step 49780, total loss = 0.54, batch loss = 0.27 (321.7 examples/sec; 0.025 sec/batch; 1h:02m:02s remains)
INFO - root - 2022-02-24 19:50:52.990945: step 49790, total loss = 0.59, batch loss = 0.32 (175.0 examples/sec; 0.046 sec/batch; 1h:54m:04s remains)
INFO - root - 2022-02-24 19:50:53.456168: step 49800, total loss = 0.63, batch loss = 0.35 (157.6 examples/sec; 0.051 sec/batch; 2h:06m:40s remains)
INFO - root - 2022-02-24 19:50:53.872177: step 49810, total loss = 0.52, batch loss = 0.24 (162.3 examples/sec; 0.049 sec/batch; 2h:02m:56s remains)
INFO - root - 2022-02-24 19:50:54.229634: step 49820, total loss = 0.60, batch loss = 0.33 (268.7 examples/sec; 0.030 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 19:50:54.549459: step 49830, total loss = 0.68, batch loss = 0.40 (189.5 examples/sec; 0.042 sec/batch; 1h:45m:18s remains)
INFO - root - 2022-02-24 19:50:54.935908: step 49840, total loss = 0.68, batch loss = 0.40 (322.1 examples/sec; 0.025 sec/batch; 1h:01m:57s remains)
INFO - root - 2022-02-24 19:50:55.333363: step 49850, total loss = 0.52, batch loss = 0.25 (243.3 examples/sec; 0.033 sec/batch; 1h:22m:00s remains)
INFO - root - 2022-02-24 19:50:55.775977: step 49860, total loss = 0.67, batch loss = 0.40 (211.3 examples/sec; 0.038 sec/batch; 1h:34m:24s remains)
INFO - root - 2022-02-24 19:50:56.124414: step 49870, total loss = 0.62, batch loss = 0.35 (239.5 examples/sec; 0.033 sec/batch; 1h:23m:17s remains)
INFO - root - 2022-02-24 19:50:56.494550: step 49880, total loss = 0.56, batch loss = 0.29 (356.8 examples/sec; 0.022 sec/batch; 0h:55m:54s remains)
INFO - root - 2022-02-24 19:50:56.881692: step 49890, total loss = 0.64, batch loss = 0.37 (317.0 examples/sec; 0.025 sec/batch; 1h:02m:55s remains)
INFO - root - 2022-02-24 19:50:57.274794: step 49900, total loss = 0.47, batch loss = 0.19 (322.3 examples/sec; 0.025 sec/batch; 1h:01m:53s remains)
INFO - root - 2022-02-24 19:50:57.654423: step 49910, total loss = 0.58, batch loss = 0.31 (255.6 examples/sec; 0.031 sec/batch; 1h:18m:01s remains)
INFO - root - 2022-02-24 19:50:58.004621: step 49920, total loss = 0.52, batch loss = 0.24 (91.9 examples/sec; 0.087 sec/batch; 3h:36m:58s remains)
INFO - root - 2022-02-24 19:50:58.280927: step 49930, total loss = 0.53, batch loss = 0.25 (318.0 examples/sec; 0.025 sec/batch; 1h:02m:42s remains)
INFO - root - 2022-02-24 19:50:58.634646: step 49940, total loss = 0.68, batch loss = 0.40 (176.7 examples/sec; 0.045 sec/batch; 1h:52m:52s remains)
INFO - root - 2022-02-24 19:50:59.047507: step 49950, total loss = 0.67, batch loss = 0.40 (136.8 examples/sec; 0.058 sec/batch; 2h:25m:43s remains)
INFO - root - 2022-02-24 19:50:59.544572: step 49960, total loss = 0.51, batch loss = 0.23 (302.5 examples/sec; 0.026 sec/batch; 1h:05m:54s remains)
INFO - root - 2022-02-24 19:50:59.905640: step 49970, total loss = 0.54, batch loss = 0.26 (332.6 examples/sec; 0.024 sec/batch; 0h:59m:56s remains)
INFO - root - 2022-02-24 19:51:00.262136: step 49980, total loss = 0.62, batch loss = 0.34 (168.7 examples/sec; 0.047 sec/batch; 1h:58m:09s remains)
INFO - root - 2022-02-24 19:51:00.565923: step 49990, total loss = 0.49, batch loss = 0.22 (328.7 examples/sec; 0.024 sec/batch; 1h:00m:38s remains)
INFO - root - 2022-02-24 19:51:01.035222: step 50000, total loss = 0.58, batch loss = 0.31 (133.1 examples/sec; 0.060 sec/batch; 2h:29m:43s remains)
INFO - root - 2022-02-24 19:51:01.516838: step 50010, total loss = 0.54, batch loss = 0.26 (198.2 examples/sec; 0.040 sec/batch; 1h:40m:32s remains)
INFO - root - 2022-02-24 19:51:01.895540: step 50020, total loss = 0.50, batch loss = 0.22 (136.2 examples/sec; 0.059 sec/batch; 2h:26m:21s remains)
INFO - root - 2022-02-24 19:51:02.155453: step 50030, total loss = 0.62, batch loss = 0.35 (342.0 examples/sec; 0.023 sec/batch; 0h:58m:16s remains)
INFO - root - 2022-02-24 19:51:02.489696: step 50040, total loss = 0.47, batch loss = 0.20 (323.4 examples/sec; 0.025 sec/batch; 1h:01m:37s remains)
INFO - root - 2022-02-24 19:51:02.879394: step 50050, total loss = 0.70, batch loss = 0.43 (128.0 examples/sec; 0.063 sec/batch; 2h:35m:41s remains)
INFO - root - 2022-02-24 19:51:03.362719: step 50060, total loss = 0.59, batch loss = 0.31 (98.2 examples/sec; 0.081 sec/batch; 3h:22m:50s remains)
INFO - root - 2022-02-24 19:51:03.784896: step 50070, total loss = 0.66, batch loss = 0.38 (336.2 examples/sec; 0.024 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 19:51:04.146593: step 50080, total loss = 0.64, batch loss = 0.36 (224.4 examples/sec; 0.036 sec/batch; 1h:28m:47s remains)
INFO - root - 2022-02-24 19:51:04.531150: step 50090, total loss = 0.61, batch loss = 0.34 (273.1 examples/sec; 0.029 sec/batch; 1h:12m:57s remains)
INFO - root - 2022-02-24 19:51:04.848135: step 50100, total loss = 0.59, batch loss = 0.31 (349.9 examples/sec; 0.023 sec/batch; 0h:56m:56s remains)
INFO - root - 2022-02-24 19:51:05.247730: step 50110, total loss = 0.53, batch loss = 0.25 (207.7 examples/sec; 0.039 sec/batch; 1h:35m:53s remains)
INFO - root - 2022-02-24 19:51:05.678985: step 50120, total loss = 0.61, batch loss = 0.33 (340.7 examples/sec; 0.023 sec/batch; 0h:58m:27s remains)
INFO - root - 2022-02-24 19:51:06.028069: step 50130, total loss = 0.50, batch loss = 0.22 (255.0 examples/sec; 0.031 sec/batch; 1h:18m:05s remains)
INFO - root - 2022-02-24 19:51:06.403600: step 50140, total loss = 0.58, batch loss = 0.30 (359.3 examples/sec; 0.022 sec/batch; 0h:55m:25s remains)
INFO - root - 2022-02-24 19:51:06.681225: step 50150, total loss = 0.64, batch loss = 0.37 (327.5 examples/sec; 0.024 sec/batch; 1h:00m:48s remains)
INFO - root - 2022-02-24 19:51:06.962452: step 50160, total loss = 0.53, batch loss = 0.25 (334.7 examples/sec; 0.024 sec/batch; 0h:59m:29s remains)
INFO - root - 2022-02-24 19:51:07.423633: step 50170, total loss = 0.64, batch loss = 0.36 (194.5 examples/sec; 0.041 sec/batch; 1h:42m:22s remains)
INFO - root - 2022-02-24 19:51:07.860100: step 50180, total loss = 0.52, batch loss = 0.25 (246.6 examples/sec; 0.032 sec/batch; 1h:20m:44s remains)
INFO - root - 2022-02-24 19:51:08.252494: step 50190, total loss = 0.61, batch loss = 0.33 (265.8 examples/sec; 0.030 sec/batch; 1h:14m:53s remains)
INFO - root - 2022-02-24 19:51:08.570322: step 50200, total loss = 0.55, batch loss = 0.28 (297.4 examples/sec; 0.027 sec/batch; 1h:06m:56s remains)
INFO - root - 2022-02-24 19:51:08.905783: step 50210, total loss = 0.70, batch loss = 0.42 (325.2 examples/sec; 0.025 sec/batch; 1h:01m:12s remains)
INFO - root - 2022-02-24 19:51:09.223414: step 50220, total loss = 0.60, batch loss = 0.32 (160.5 examples/sec; 0.050 sec/batch; 2h:04m:00s remains)
INFO - root - 2022-02-24 19:51:09.722476: step 50230, total loss = 0.68, batch loss = 0.41 (224.5 examples/sec; 0.036 sec/batch; 1h:28m:38s remains)
INFO - root - 2022-02-24 19:51:10.088142: step 50240, total loss = 0.49, batch loss = 0.22 (326.9 examples/sec; 0.024 sec/batch; 1h:00m:52s remains)
INFO - root - 2022-02-24 19:51:10.419215: step 50250, total loss = 0.53, batch loss = 0.25 (139.9 examples/sec; 0.057 sec/batch; 2h:22m:16s remains)
INFO - root - 2022-02-24 19:51:10.707379: step 50260, total loss = 0.66, batch loss = 0.38 (355.2 examples/sec; 0.023 sec/batch; 0h:56m:01s remains)
INFO - root - 2022-02-24 19:51:11.127302: step 50270, total loss = 0.65, batch loss = 0.37 (170.2 examples/sec; 0.047 sec/batch; 1h:56m:54s remains)
INFO - root - 2022-02-24 19:51:11.571691: step 50280, total loss = 0.70, batch loss = 0.43 (198.9 examples/sec; 0.040 sec/batch; 1h:40m:00s remains)
INFO - root - 2022-02-24 19:51:12.020287: step 50290, total loss = 0.55, batch loss = 0.27 (208.2 examples/sec; 0.038 sec/batch; 1h:35m:32s remains)
INFO - root - 2022-02-24 19:51:12.378224: step 50300, total loss = 0.51, batch loss = 0.24 (137.0 examples/sec; 0.058 sec/batch; 2h:25m:12s remains)
INFO - root - 2022-02-24 19:51:12.751658: step 50310, total loss = 0.56, batch loss = 0.28 (337.1 examples/sec; 0.024 sec/batch; 0h:59m:00s remains)
INFO - root - 2022-02-24 19:51:13.078364: step 50320, total loss = 0.60, batch loss = 0.32 (213.1 examples/sec; 0.038 sec/batch; 1h:33m:19s remains)
INFO - root - 2022-02-24 19:51:13.489496: step 50330, total loss = 0.64, batch loss = 0.36 (149.1 examples/sec; 0.054 sec/batch; 2h:13m:23s remains)
INFO - root - 2022-02-24 19:51:13.984259: step 50340, total loss = 0.57, batch loss = 0.29 (186.1 examples/sec; 0.043 sec/batch; 1h:46m:50s remains)
INFO - root - 2022-02-24 19:51:14.358702: step 50350, total loss = 0.58, batch loss = 0.30 (345.4 examples/sec; 0.023 sec/batch; 0h:57m:34s remains)
INFO - root - 2022-02-24 19:51:14.641812: step 50360, total loss = 0.70, batch loss = 0.43 (316.3 examples/sec; 0.025 sec/batch; 1h:02m:52s remains)
INFO - root - 2022-02-24 19:51:15.015352: step 50370, total loss = 0.55, batch loss = 0.27 (331.8 examples/sec; 0.024 sec/batch; 0h:59m:56s remains)
INFO - root - 2022-02-24 19:51:15.356631: step 50380, total loss = 0.55, batch loss = 0.27 (140.3 examples/sec; 0.057 sec/batch; 2h:21m:43s remains)
INFO - root - 2022-02-24 19:51:15.853480: step 50390, total loss = 0.52, batch loss = 0.25 (232.8 examples/sec; 0.034 sec/batch; 1h:25m:23s remains)
INFO - root - 2022-02-24 19:51:16.276705: step 50400, total loss = 0.53, batch loss = 0.25 (218.3 examples/sec; 0.037 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 19:51:16.643116: step 50410, total loss = 0.58, batch loss = 0.31 (320.2 examples/sec; 0.025 sec/batch; 1h:02m:04s remains)
INFO - root - 2022-02-24 19:51:16.925558: step 50420, total loss = 0.58, batch loss = 0.30 (291.7 examples/sec; 0.027 sec/batch; 1h:08m:09s remains)
INFO - root - 2022-02-24 19:51:17.221227: step 50430, total loss = 0.58, batch loss = 0.31 (186.8 examples/sec; 0.043 sec/batch; 1h:46m:23s remains)
INFO - root - 2022-02-24 19:51:17.715376: step 50440, total loss = 0.55, batch loss = 0.27 (166.3 examples/sec; 0.048 sec/batch; 1h:59m:31s remains)
INFO - root - 2022-02-24 19:51:18.130109: step 50450, total loss = 0.59, batch loss = 0.31 (111.5 examples/sec; 0.072 sec/batch; 2h:58m:15s remains)
INFO - root - 2022-02-24 19:51:18.417904: step 50460, total loss = 0.49, batch loss = 0.21 (336.9 examples/sec; 0.024 sec/batch; 0h:58m:59s remains)
INFO - root - 2022-02-24 19:51:18.730349: step 50470, total loss = 0.65, batch loss = 0.38 (253.2 examples/sec; 0.032 sec/batch; 1h:18m:27s remains)
INFO - root - 2022-02-24 19:51:19.062846: step 50480, total loss = 0.73, batch loss = 0.45 (263.9 examples/sec; 0.030 sec/batch; 1h:15m:17s remains)
INFO - root - 2022-02-24 19:51:19.520214: step 50490, total loss = 0.54, batch loss = 0.27 (332.3 examples/sec; 0.024 sec/batch; 0h:59m:47s remains)
INFO - root - 2022-02-24 19:51:19.875849: step 50500, total loss = 0.59, batch loss = 0.31 (122.2 examples/sec; 0.065 sec/batch; 2h:42m:31s remains)
INFO - root - 2022-02-24 19:51:20.370831: step 50510, total loss = 0.54, batch loss = 0.27 (353.0 examples/sec; 0.023 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 19:51:20.877638: step 50520, total loss = 0.53, batch loss = 0.26 (247.0 examples/sec; 0.032 sec/batch; 1h:20m:24s remains)
INFO - root - 2022-02-24 19:51:21.322304: step 50530, total loss = 0.63, batch loss = 0.36 (163.7 examples/sec; 0.049 sec/batch; 2h:01m:21s remains)
INFO - root - 2022-02-24 19:51:21.809289: step 50540, total loss = 0.55, batch loss = 0.27 (202.7 examples/sec; 0.039 sec/batch; 1h:38m:00s remains)
INFO - root - 2022-02-24 19:51:22.238699: step 50550, total loss = 0.48, batch loss = 0.20 (334.5 examples/sec; 0.024 sec/batch; 0h:59m:21s remains)
INFO - root - 2022-02-24 19:51:22.778697: step 50560, total loss = 0.60, batch loss = 0.33 (169.2 examples/sec; 0.047 sec/batch; 1h:57m:23s remains)
INFO - root - 2022-02-24 19:51:23.176423: step 50570, total loss = 0.57, batch loss = 0.30 (138.9 examples/sec; 0.058 sec/batch; 2h:22m:55s remains)
INFO - root - 2022-02-24 19:51:23.652612: step 50580, total loss = 0.55, batch loss = 0.28 (165.5 examples/sec; 0.048 sec/batch; 1h:59m:59s remains)
INFO - root - 2022-02-24 19:51:23.999597: step 50590, total loss = 0.51, batch loss = 0.23 (377.0 examples/sec; 0.021 sec/batch; 0h:52m:39s remains)
INFO - root - 2022-02-24 19:51:24.435826: step 50600, total loss = 0.51, batch loss = 0.24 (193.2 examples/sec; 0.041 sec/batch; 1h:42m:46s remains)
INFO - root - 2022-02-24 19:51:25.011100: step 50610, total loss = 0.61, batch loss = 0.33 (119.0 examples/sec; 0.067 sec/batch; 2h:46m:47s remains)
INFO - root - 2022-02-24 19:51:25.588732: step 50620, total loss = 0.62, batch loss = 0.34 (154.9 examples/sec; 0.052 sec/batch; 2h:08m:10s remains)
INFO - root - 2022-02-24 19:51:26.273206: step 50630, total loss = 0.53, batch loss = 0.26 (131.0 examples/sec; 0.061 sec/batch; 2h:31m:28s remains)
INFO - root - 2022-02-24 19:51:27.336367: step 50640, total loss = 0.76, batch loss = 0.49 (130.1 examples/sec; 0.061 sec/batch; 2h:32m:32s remains)
INFO - root - 2022-02-24 19:51:27.682199: step 50650, total loss = 0.63, batch loss = 0.35 (235.8 examples/sec; 0.034 sec/batch; 1h:24m:09s remains)
INFO - root - 2022-02-24 19:51:28.035325: step 50660, total loss = 0.55, batch loss = 0.28 (318.2 examples/sec; 0.025 sec/batch; 1h:02m:21s remains)
INFO - root - 2022-02-24 19:51:28.380283: step 50670, total loss = 0.65, batch loss = 0.38 (326.0 examples/sec; 0.025 sec/batch; 1h:00m:51s remains)
INFO - root - 2022-02-24 19:51:28.711538: step 50680, total loss = 0.55, batch loss = 0.28 (373.5 examples/sec; 0.021 sec/batch; 0h:53m:07s remains)
INFO - root - 2022-02-24 19:51:29.248647: step 50690, total loss = 0.51, batch loss = 0.23 (165.7 examples/sec; 0.048 sec/batch; 1h:59m:45s remains)
INFO - root - 2022-02-24 19:51:29.757506: step 50700, total loss = 0.58, batch loss = 0.30 (219.1 examples/sec; 0.037 sec/batch; 1h:30m:33s remains)
INFO - root - 2022-02-24 19:51:30.323228: step 50710, total loss = 0.74, batch loss = 0.47 (137.2 examples/sec; 0.058 sec/batch; 2h:24m:38s remains)
INFO - root - 2022-02-24 19:51:30.775844: step 50720, total loss = 0.55, batch loss = 0.28 (202.6 examples/sec; 0.039 sec/batch; 1h:37m:55s remains)
INFO - root - 2022-02-24 19:51:31.196466: step 50730, total loss = 0.52, batch loss = 0.25 (267.2 examples/sec; 0.030 sec/batch; 1h:14m:14s remains)
INFO - root - 2022-02-24 19:51:32.010312: step 50740, total loss = 0.51, batch loss = 0.24 (267.8 examples/sec; 0.030 sec/batch; 1h:14m:03s remains)
INFO - root - 2022-02-24 19:51:32.399468: step 50750, total loss = 0.51, batch loss = 0.24 (235.2 examples/sec; 0.034 sec/batch; 1h:24m:19s remains)
INFO - root - 2022-02-24 19:51:32.669227: step 50760, total loss = 0.57, batch loss = 0.30 (271.1 examples/sec; 0.030 sec/batch; 1h:13m:09s remains)
INFO - root - 2022-02-24 19:51:32.905026: step 50770, total loss = 0.49, batch loss = 0.21 (350.4 examples/sec; 0.023 sec/batch; 0h:56m:35s remains)
INFO - root - 2022-02-24 19:51:33.286695: step 50780, total loss = 0.53, batch loss = 0.26 (375.2 examples/sec; 0.021 sec/batch; 0h:52m:51s remains)
INFO - root - 2022-02-24 19:51:33.708904: step 50790, total loss = 0.62, batch loss = 0.34 (146.8 examples/sec; 0.055 sec/batch; 2h:15m:05s remains)
INFO - root - 2022-02-24 19:51:34.061816: step 50800, total loss = 0.56, batch loss = 0.28 (374.0 examples/sec; 0.021 sec/batch; 0h:53m:00s remains)
INFO - root - 2022-02-24 19:51:34.526957: step 50810, total loss = 0.69, batch loss = 0.41 (294.4 examples/sec; 0.027 sec/batch; 1h:07m:20s remains)
INFO - root - 2022-02-24 19:51:34.847968: step 50820, total loss = 0.55, batch loss = 0.28 (194.4 examples/sec; 0.041 sec/batch; 1h:41m:57s remains)
INFO - root - 2022-02-24 19:51:35.153767: step 50830, total loss = 0.50, batch loss = 0.22 (280.2 examples/sec; 0.029 sec/batch; 1h:10m:45s remains)
INFO - root - 2022-02-24 19:51:35.487475: step 50840, total loss = 0.67, batch loss = 0.40 (259.5 examples/sec; 0.031 sec/batch; 1h:16m:23s remains)
INFO - root - 2022-02-24 19:51:35.857122: step 50850, total loss = 0.51, batch loss = 0.23 (301.5 examples/sec; 0.027 sec/batch; 1h:05m:43s remains)
INFO - root - 2022-02-24 19:51:36.232374: step 50860, total loss = 0.56, batch loss = 0.29 (259.2 examples/sec; 0.031 sec/batch; 1h:16m:28s remains)
INFO - root - 2022-02-24 19:51:36.527898: step 50870, total loss = 0.51, batch loss = 0.23 (322.0 examples/sec; 0.025 sec/batch; 1h:01m:33s remains)
INFO - root - 2022-02-24 19:51:36.933928: step 50880, total loss = 0.66, batch loss = 0.38 (344.9 examples/sec; 0.023 sec/batch; 0h:57m:26s remains)
INFO - root - 2022-02-24 19:51:37.245259: step 50890, total loss = 0.55, batch loss = 0.28 (323.0 examples/sec; 0.025 sec/batch; 1h:01m:20s remains)
INFO - root - 2022-02-24 19:51:37.641304: step 50900, total loss = 0.54, batch loss = 0.26 (176.7 examples/sec; 0.045 sec/batch; 1h:52m:06s remains)
INFO - root - 2022-02-24 19:51:38.193349: step 50910, total loss = 0.60, batch loss = 0.33 (322.1 examples/sec; 0.025 sec/batch; 1h:01m:30s remains)
INFO - root - 2022-02-24 19:51:38.512240: step 50920, total loss = 0.49, batch loss = 0.22 (338.9 examples/sec; 0.024 sec/batch; 0h:58m:27s remains)
INFO - root - 2022-02-24 19:51:38.838672: step 50930, total loss = 0.68, batch loss = 0.41 (255.7 examples/sec; 0.031 sec/batch; 1h:17m:28s remains)
INFO - root - 2022-02-24 19:51:39.211830: step 50940, total loss = 0.55, batch loss = 0.27 (253.4 examples/sec; 0.032 sec/batch; 1h:18m:10s remains)
INFO - root - 2022-02-24 19:51:39.516079: step 50950, total loss = 0.59, batch loss = 0.31 (308.3 examples/sec; 0.026 sec/batch; 1h:04m:14s remains)
INFO - root - 2022-02-24 19:51:39.965154: step 50960, total loss = 0.68, batch loss = 0.40 (379.9 examples/sec; 0.021 sec/batch; 0h:52m:08s remains)
INFO - root - 2022-02-24 19:51:40.306891: step 50970, total loss = 0.57, batch loss = 0.30 (276.3 examples/sec; 0.029 sec/batch; 1h:11m:40s remains)
INFO - root - 2022-02-24 19:51:40.609129: step 50980, total loss = 0.60, batch loss = 0.33 (314.8 examples/sec; 0.025 sec/batch; 1h:02m:54s remains)
INFO - root - 2022-02-24 19:51:40.926986: step 50990, total loss = 0.57, batch loss = 0.29 (369.5 examples/sec; 0.022 sec/batch; 0h:53m:35s remains)
INFO - root - 2022-02-24 19:51:41.248870: step 51000, total loss = 0.66, batch loss = 0.39 (190.4 examples/sec; 0.042 sec/batch; 1h:43m:59s remains)
INFO - root - 2022-02-24 19:51:41.632385: step 51010, total loss = 0.53, batch loss = 0.25 (188.1 examples/sec; 0.043 sec/batch; 1h:45m:16s remains)
INFO - root - 2022-02-24 19:51:42.144968: step 51020, total loss = 0.62, batch loss = 0.35 (252.7 examples/sec; 0.032 sec/batch; 1h:18m:20s remains)
INFO - root - 2022-02-24 19:51:42.543108: step 51030, total loss = 0.63, batch loss = 0.35 (166.7 examples/sec; 0.048 sec/batch; 1h:58m:43s remains)
INFO - root - 2022-02-24 19:51:42.837604: step 51040, total loss = 0.52, batch loss = 0.24 (321.6 examples/sec; 0.025 sec/batch; 1h:01m:32s remains)
INFO - root - 2022-02-24 19:51:43.126540: step 51050, total loss = 0.71, batch loss = 0.44 (248.0 examples/sec; 0.032 sec/batch; 1h:19m:48s remains)
INFO - root - 2022-02-24 19:51:43.513094: step 51060, total loss = 0.57, batch loss = 0.29 (144.0 examples/sec; 0.056 sec/batch; 2h:17m:27s remains)
INFO - root - 2022-02-24 19:51:43.795017: step 51070, total loss = 0.52, batch loss = 0.24 (223.4 examples/sec; 0.036 sec/batch; 1h:28m:36s remains)
INFO - root - 2022-02-24 19:51:44.222022: step 51080, total loss = 0.64, batch loss = 0.37 (370.1 examples/sec; 0.022 sec/batch; 0h:53m:28s remains)
INFO - root - 2022-02-24 19:51:44.518517: step 51090, total loss = 0.63, batch loss = 0.36 (261.3 examples/sec; 0.031 sec/batch; 1h:15m:43s remains)
INFO - root - 2022-02-24 19:51:44.881979: step 51100, total loss = 0.50, batch loss = 0.23 (190.0 examples/sec; 0.042 sec/batch; 1h:44m:07s remains)
INFO - root - 2022-02-24 19:51:45.237700: step 51110, total loss = 0.66, batch loss = 0.38 (340.8 examples/sec; 0.023 sec/batch; 0h:58m:03s remains)
INFO - root - 2022-02-24 19:51:45.639422: step 51120, total loss = 0.53, batch loss = 0.25 (315.8 examples/sec; 0.025 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:51:46.089103: step 51130, total loss = 0.67, batch loss = 0.40 (174.8 examples/sec; 0.046 sec/batch; 1h:53m:10s remains)
INFO - root - 2022-02-24 19:51:46.472702: step 51140, total loss = 0.55, batch loss = 0.28 (365.7 examples/sec; 0.022 sec/batch; 0h:54m:05s remains)
INFO - root - 2022-02-24 19:51:46.846329: step 51150, total loss = 0.58, batch loss = 0.30 (173.8 examples/sec; 0.046 sec/batch; 1h:53m:47s remains)
INFO - root - 2022-02-24 19:51:47.226889: step 51160, total loss = 0.66, batch loss = 0.39 (183.2 examples/sec; 0.044 sec/batch; 1h:47m:56s remains)
INFO - root - 2022-02-24 19:51:47.625602: step 51170, total loss = 0.53, batch loss = 0.25 (335.9 examples/sec; 0.024 sec/batch; 0h:58m:52s remains)
INFO - root - 2022-02-24 19:51:48.102267: step 51180, total loss = 0.55, batch loss = 0.28 (136.7 examples/sec; 0.059 sec/batch; 2h:24m:41s remains)
INFO - root - 2022-02-24 19:51:48.501722: step 51190, total loss = 0.62, batch loss = 0.35 (225.2 examples/sec; 0.036 sec/batch; 1h:27m:47s remains)
INFO - root - 2022-02-24 19:51:48.927251: step 51200, total loss = 0.56, batch loss = 0.28 (275.3 examples/sec; 0.029 sec/batch; 1h:11m:50s remains)
INFO - root - 2022-02-24 19:51:49.250752: step 51210, total loss = 0.67, batch loss = 0.40 (345.1 examples/sec; 0.023 sec/batch; 0h:57m:17s remains)
INFO - root - 2022-02-24 19:51:49.650077: step 51220, total loss = 0.56, batch loss = 0.28 (139.9 examples/sec; 0.057 sec/batch; 2h:21m:20s remains)
INFO - root - 2022-02-24 19:51:50.030848: step 51230, total loss = 0.59, batch loss = 0.31 (360.3 examples/sec; 0.022 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 19:51:50.508369: step 51240, total loss = 0.57, batch loss = 0.30 (180.5 examples/sec; 0.044 sec/batch; 1h:49m:29s remains)
INFO - root - 2022-02-24 19:51:50.849881: step 51250, total loss = 0.55, batch loss = 0.28 (237.3 examples/sec; 0.034 sec/batch; 1h:23m:17s remains)
INFO - root - 2022-02-24 19:51:51.228143: step 51260, total loss = 0.69, batch loss = 0.42 (291.1 examples/sec; 0.027 sec/batch; 1h:07m:54s remains)
INFO - root - 2022-02-24 19:51:51.594131: step 51270, total loss = 0.56, batch loss = 0.29 (225.2 examples/sec; 0.036 sec/batch; 1h:27m:44s remains)
INFO - root - 2022-02-24 19:51:52.142232: step 51280, total loss = 0.65, batch loss = 0.38 (146.8 examples/sec; 0.055 sec/batch; 2h:14m:38s remains)
INFO - root - 2022-02-24 19:51:52.570710: step 51290, total loss = 0.55, batch loss = 0.27 (116.4 examples/sec; 0.069 sec/batch; 2h:49m:45s remains)
INFO - root - 2022-02-24 19:51:52.831884: step 51300, total loss = 0.59, batch loss = 0.31 (222.7 examples/sec; 0.036 sec/batch; 1h:28m:44s remains)
INFO - root - 2022-02-24 19:51:53.226019: step 51310, total loss = 0.58, batch loss = 0.31 (260.4 examples/sec; 0.031 sec/batch; 1h:15m:52s remains)
INFO - root - 2022-02-24 19:51:53.578946: step 51320, total loss = 0.71, batch loss = 0.43 (222.3 examples/sec; 0.036 sec/batch; 1h:28m:53s remains)
INFO - root - 2022-02-24 19:51:53.913192: step 51330, total loss = 0.47, batch loss = 0.19 (241.1 examples/sec; 0.033 sec/batch; 1h:21m:55s remains)
INFO - root - 2022-02-24 19:51:54.416496: step 51340, total loss = 0.53, batch loss = 0.25 (237.4 examples/sec; 0.034 sec/batch; 1h:23m:11s remains)
INFO - root - 2022-02-24 19:51:54.774423: step 51350, total loss = 0.52, batch loss = 0.25 (211.1 examples/sec; 0.038 sec/batch; 1h:33m:35s remains)
INFO - root - 2022-02-24 19:51:55.094945: step 51360, total loss = 0.72, batch loss = 0.45 (332.5 examples/sec; 0.024 sec/batch; 0h:59m:24s remains)
INFO - root - 2022-02-24 19:51:55.448695: step 51370, total loss = 0.57, batch loss = 0.29 (184.6 examples/sec; 0.043 sec/batch; 1h:47m:00s remains)
INFO - root - 2022-02-24 19:51:55.764922: step 51380, total loss = 0.57, batch loss = 0.29 (272.1 examples/sec; 0.029 sec/batch; 1h:12m:35s remains)
INFO - root - 2022-02-24 19:51:56.138636: step 51390, total loss = 0.52, batch loss = 0.25 (120.6 examples/sec; 0.066 sec/batch; 2h:43m:41s remains)
INFO - root - 2022-02-24 19:51:56.581045: step 51400, total loss = 0.57, batch loss = 0.29 (192.9 examples/sec; 0.041 sec/batch; 1h:42m:23s remains)
INFO - root - 2022-02-24 19:51:57.293938: step 51410, total loss = 0.64, batch loss = 0.37 (133.5 examples/sec; 0.060 sec/batch; 2h:27m:55s remains)
INFO - root - 2022-02-24 19:51:57.734016: step 51420, total loss = 0.72, batch loss = 0.45 (325.7 examples/sec; 0.025 sec/batch; 1h:00m:37s remains)
INFO - root - 2022-02-24 19:51:58.199593: step 51430, total loss = 0.60, batch loss = 0.32 (202.7 examples/sec; 0.039 sec/batch; 1h:37m:22s remains)
INFO - root - 2022-02-24 19:51:58.631382: step 51440, total loss = 0.63, batch loss = 0.35 (261.1 examples/sec; 0.031 sec/batch; 1h:15m:36s remains)
INFO - root - 2022-02-24 19:51:58.938416: step 51450, total loss = 0.52, batch loss = 0.24 (353.1 examples/sec; 0.023 sec/batch; 0h:55m:54s remains)
INFO - root - 2022-02-24 19:51:59.396652: step 51460, total loss = 0.65, batch loss = 0.37 (96.5 examples/sec; 0.083 sec/batch; 3h:24m:30s remains)
INFO - root - 2022-02-24 19:51:59.908560: step 51470, total loss = 0.55, batch loss = 0.27 (326.9 examples/sec; 0.024 sec/batch; 1h:00m:22s remains)
INFO - root - 2022-02-24 19:52:00.547958: step 51480, total loss = 0.59, batch loss = 0.31 (96.7 examples/sec; 0.083 sec/batch; 3h:24m:02s remains)
INFO - root - 2022-02-24 19:52:00.918482: step 51490, total loss = 0.56, batch loss = 0.28 (319.4 examples/sec; 0.025 sec/batch; 1h:01m:46s remains)
INFO - root - 2022-02-24 19:52:01.264738: step 51500, total loss = 0.56, batch loss = 0.29 (202.1 examples/sec; 0.040 sec/batch; 1h:37m:39s remains)
INFO - root - 2022-02-24 19:52:01.717471: step 51510, total loss = 0.58, batch loss = 0.30 (292.6 examples/sec; 0.027 sec/batch; 1h:07m:26s remains)
INFO - root - 2022-02-24 19:52:02.432137: step 51520, total loss = 0.60, batch loss = 0.33 (169.3 examples/sec; 0.047 sec/batch; 1h:56m:31s remains)
INFO - root - 2022-02-24 19:52:02.836670: step 51530, total loss = 0.61, batch loss = 0.33 (203.3 examples/sec; 0.039 sec/batch; 1h:37m:02s remains)
INFO - root - 2022-02-24 19:52:03.167483: step 51540, total loss = 0.60, batch loss = 0.33 (322.9 examples/sec; 0.025 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 19:52:03.442458: step 51550, total loss = 0.64, batch loss = 0.37 (334.9 examples/sec; 0.024 sec/batch; 0h:58m:54s remains)
INFO - root - 2022-02-24 19:52:03.796393: step 51560, total loss = 0.52, batch loss = 0.25 (174.4 examples/sec; 0.046 sec/batch; 1h:53m:06s remains)
INFO - root - 2022-02-24 19:52:04.186422: step 51570, total loss = 0.53, batch loss = 0.25 (184.2 examples/sec; 0.043 sec/batch; 1h:47m:04s remains)
INFO - root - 2022-02-24 19:52:04.599519: step 51580, total loss = 0.54, batch loss = 0.27 (279.8 examples/sec; 0.029 sec/batch; 1h:10m:29s remains)
INFO - root - 2022-02-24 19:52:04.981987: step 51590, total loss = 0.51, batch loss = 0.24 (158.8 examples/sec; 0.050 sec/batch; 2h:04m:12s remains)
INFO - root - 2022-02-24 19:52:05.338561: step 51600, total loss = 0.50, batch loss = 0.23 (168.8 examples/sec; 0.047 sec/batch; 1h:56m:51s remains)
INFO - root - 2022-02-24 19:52:05.782953: step 51610, total loss = 0.56, batch loss = 0.29 (231.1 examples/sec; 0.035 sec/batch; 1h:25m:19s remains)
INFO - root - 2022-02-24 19:52:06.267453: step 51620, total loss = 0.75, batch loss = 0.48 (219.3 examples/sec; 0.036 sec/batch; 1h:29m:54s remains)
INFO - root - 2022-02-24 19:52:06.795576: step 51630, total loss = 0.51, batch loss = 0.23 (263.2 examples/sec; 0.030 sec/batch; 1h:14m:54s remains)
INFO - root - 2022-02-24 19:52:07.243844: step 51640, total loss = 0.68, batch loss = 0.40 (130.4 examples/sec; 0.061 sec/batch; 2h:31m:07s remains)
INFO - root - 2022-02-24 19:52:07.618124: step 51650, total loss = 0.58, batch loss = 0.30 (300.2 examples/sec; 0.027 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 19:52:08.050037: step 51660, total loss = 0.65, batch loss = 0.37 (197.2 examples/sec; 0.041 sec/batch; 1h:39m:58s remains)
INFO - root - 2022-02-24 19:52:08.430596: step 51670, total loss = 0.60, batch loss = 0.33 (241.2 examples/sec; 0.033 sec/batch; 1h:21m:42s remains)
INFO - root - 2022-02-24 19:52:09.272729: step 51680, total loss = 0.52, batch loss = 0.24 (174.4 examples/sec; 0.046 sec/batch; 1h:53m:02s remains)
INFO - root - 2022-02-24 19:52:09.700171: step 51690, total loss = 0.54, batch loss = 0.26 (128.8 examples/sec; 0.062 sec/batch; 2h:33m:00s remains)
INFO - root - 2022-02-24 19:52:10.077443: step 51700, total loss = 0.57, batch loss = 0.29 (145.3 examples/sec; 0.055 sec/batch; 2h:15m:35s remains)
INFO - root - 2022-02-24 19:52:10.426956: step 51710, total loss = 0.57, batch loss = 0.29 (341.6 examples/sec; 0.023 sec/batch; 0h:57m:40s remains)
INFO - root - 2022-02-24 19:52:10.732481: step 51720, total loss = 0.62, batch loss = 0.35 (372.9 examples/sec; 0.021 sec/batch; 0h:52m:50s remains)
INFO - root - 2022-02-24 19:52:11.089791: step 51730, total loss = 0.69, batch loss = 0.41 (262.4 examples/sec; 0.030 sec/batch; 1h:15m:04s remains)
INFO - root - 2022-02-24 19:52:11.461924: step 51740, total loss = 0.59, batch loss = 0.31 (179.6 examples/sec; 0.045 sec/batch; 1h:49m:41s remains)
INFO - root - 2022-02-24 19:52:11.857326: step 51750, total loss = 0.60, batch loss = 0.33 (344.9 examples/sec; 0.023 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 19:52:12.251705: step 51760, total loss = 0.59, batch loss = 0.32 (160.4 examples/sec; 0.050 sec/batch; 2h:02m:50s remains)
INFO - root - 2022-02-24 19:52:12.577389: step 51770, total loss = 0.59, batch loss = 0.31 (271.1 examples/sec; 0.030 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 19:52:12.917463: step 51780, total loss = 0.52, batch loss = 0.24 (358.7 examples/sec; 0.022 sec/batch; 0h:54m:54s remains)
INFO - root - 2022-02-24 19:52:13.322955: step 51790, total loss = 0.60, batch loss = 0.32 (183.5 examples/sec; 0.044 sec/batch; 1h:47m:19s remains)
INFO - root - 2022-02-24 19:52:13.762514: step 51800, total loss = 0.58, batch loss = 0.30 (98.0 examples/sec; 0.082 sec/batch; 3h:20m:52s remains)
INFO - root - 2022-02-24 19:52:14.238421: step 51810, total loss = 0.65, batch loss = 0.37 (215.2 examples/sec; 0.037 sec/batch; 1h:31m:30s remains)
INFO - root - 2022-02-24 19:52:14.576032: step 51820, total loss = 0.49, batch loss = 0.22 (305.3 examples/sec; 0.026 sec/batch; 1h:04m:29s remains)
INFO - root - 2022-02-24 19:52:14.870077: step 51830, total loss = 0.56, batch loss = 0.29 (325.6 examples/sec; 0.025 sec/batch; 1h:00m:28s remains)
INFO - root - 2022-02-24 19:52:15.212443: step 51840, total loss = 0.52, batch loss = 0.24 (309.5 examples/sec; 0.026 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 19:52:15.517184: step 51850, total loss = 0.55, batch loss = 0.28 (326.4 examples/sec; 0.025 sec/batch; 1h:00m:19s remains)
INFO - root - 2022-02-24 19:52:15.989146: step 51860, total loss = 0.61, batch loss = 0.34 (253.3 examples/sec; 0.032 sec/batch; 1h:17m:43s remains)
INFO - root - 2022-02-24 19:52:16.455889: step 51870, total loss = 0.62, batch loss = 0.34 (340.1 examples/sec; 0.024 sec/batch; 0h:57m:53s remains)
INFO - root - 2022-02-24 19:52:16.791517: step 51880, total loss = 0.59, batch loss = 0.31 (369.2 examples/sec; 0.022 sec/batch; 0h:53m:18s remains)
INFO - root - 2022-02-24 19:52:17.083531: step 51890, total loss = 0.64, batch loss = 0.36 (213.9 examples/sec; 0.037 sec/batch; 1h:32m:01s remains)
INFO - root - 2022-02-24 19:52:17.450029: step 51900, total loss = 0.61, batch loss = 0.33 (124.0 examples/sec; 0.065 sec/batch; 2h:38m:42s remains)
INFO - root - 2022-02-24 19:52:17.929119: step 51910, total loss = 0.56, batch loss = 0.28 (216.0 examples/sec; 0.037 sec/batch; 1h:31m:07s remains)
INFO - root - 2022-02-24 19:52:18.397246: step 51920, total loss = 0.56, batch loss = 0.28 (139.6 examples/sec; 0.057 sec/batch; 2h:20m:56s remains)
INFO - root - 2022-02-24 19:52:18.690569: step 51930, total loss = 0.59, batch loss = 0.31 (207.3 examples/sec; 0.039 sec/batch; 1h:34m:55s remains)
INFO - root - 2022-02-24 19:52:19.056119: step 51940, total loss = 0.52, batch loss = 0.25 (319.0 examples/sec; 0.025 sec/batch; 1h:01m:40s remains)
INFO - root - 2022-02-24 19:52:19.370432: step 51950, total loss = 0.62, batch loss = 0.34 (236.6 examples/sec; 0.034 sec/batch; 1h:23m:09s remains)
INFO - root - 2022-02-24 19:52:19.755352: step 51960, total loss = 0.61, batch loss = 0.33 (176.5 examples/sec; 0.045 sec/batch; 1h:51m:27s remains)
INFO - root - 2022-02-24 19:52:20.177171: step 51970, total loss = 0.62, batch loss = 0.35 (189.5 examples/sec; 0.042 sec/batch; 1h:43m:49s remains)
INFO - root - 2022-02-24 19:52:20.606705: step 51980, total loss = 0.62, batch loss = 0.35 (287.4 examples/sec; 0.028 sec/batch; 1h:08m:26s remains)
INFO - root - 2022-02-24 19:52:20.907326: step 51990, total loss = 0.58, batch loss = 0.30 (246.1 examples/sec; 0.033 sec/batch; 1h:19m:54s remains)
INFO - root - 2022-02-24 19:52:21.229491: step 52000, total loss = 0.51, batch loss = 0.24 (373.4 examples/sec; 0.021 sec/batch; 0h:52m:40s remains)
INFO - root - 2022-02-24 19:52:21.715314: step 52010, total loss = 0.57, batch loss = 0.30 (204.1 examples/sec; 0.039 sec/batch; 1h:36m:20s remains)
INFO - root - 2022-02-24 19:52:22.076525: step 52020, total loss = 0.60, batch loss = 0.33 (319.8 examples/sec; 0.025 sec/batch; 1h:01m:29s remains)
INFO - root - 2022-02-24 19:52:22.543602: step 52030, total loss = 0.64, batch loss = 0.36 (273.0 examples/sec; 0.029 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 19:52:22.846086: step 52040, total loss = 0.58, batch loss = 0.30 (307.6 examples/sec; 0.026 sec/batch; 1h:03m:55s remains)
INFO - root - 2022-02-24 19:52:23.136720: step 52050, total loss = 0.63, batch loss = 0.35 (206.8 examples/sec; 0.039 sec/batch; 1h:35m:04s remains)
INFO - root - 2022-02-24 19:52:23.503060: step 52060, total loss = 0.56, batch loss = 0.29 (193.9 examples/sec; 0.041 sec/batch; 1h:41m:24s remains)
INFO - root - 2022-02-24 19:52:23.813490: step 52070, total loss = 0.59, batch loss = 0.32 (297.6 examples/sec; 0.027 sec/batch; 1h:06m:02s remains)
INFO - root - 2022-02-24 19:52:24.228240: step 52080, total loss = 0.54, batch loss = 0.27 (170.6 examples/sec; 0.047 sec/batch; 1h:55m:11s remains)
INFO - root - 2022-02-24 19:52:24.621134: step 52090, total loss = 0.53, batch loss = 0.26 (346.7 examples/sec; 0.023 sec/batch; 0h:56m:41s remains)
INFO - root - 2022-02-24 19:52:24.925455: step 52100, total loss = 0.52, batch loss = 0.24 (149.1 examples/sec; 0.054 sec/batch; 2h:11m:49s remains)
INFO - root - 2022-02-24 19:52:25.295688: step 52110, total loss = 0.60, batch loss = 0.32 (303.0 examples/sec; 0.026 sec/batch; 1h:04m:51s remains)
INFO - root - 2022-02-24 19:52:25.639066: step 52120, total loss = 0.52, batch loss = 0.25 (177.7 examples/sec; 0.045 sec/batch; 1h:50m:34s remains)
INFO - root - 2022-02-24 19:52:26.041461: step 52130, total loss = 0.76, batch loss = 0.49 (310.6 examples/sec; 0.026 sec/batch; 1h:03m:16s remains)
INFO - root - 2022-02-24 19:52:26.461793: step 52140, total loss = 0.49, batch loss = 0.21 (380.2 examples/sec; 0.021 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 19:52:26.826192: step 52150, total loss = 0.51, batch loss = 0.23 (249.8 examples/sec; 0.032 sec/batch; 1h:18m:39s remains)
INFO - root - 2022-02-24 19:52:27.169386: step 52160, total loss = 0.58, batch loss = 0.30 (189.6 examples/sec; 0.042 sec/batch; 1h:43m:36s remains)
INFO - root - 2022-02-24 19:52:27.533923: step 52170, total loss = 0.56, batch loss = 0.29 (327.6 examples/sec; 0.024 sec/batch; 0h:59m:58s remains)
INFO - root - 2022-02-24 19:52:27.887329: step 52180, total loss = 0.46, batch loss = 0.19 (177.4 examples/sec; 0.045 sec/batch; 1h:50m:43s remains)
INFO - root - 2022-02-24 19:52:28.373253: step 52190, total loss = 0.49, batch loss = 0.21 (163.7 examples/sec; 0.049 sec/batch; 1h:59m:59s remains)
INFO - root - 2022-02-24 19:52:28.763901: step 52200, total loss = 0.57, batch loss = 0.30 (243.3 examples/sec; 0.033 sec/batch; 1h:20m:43s remains)
INFO - root - 2022-02-24 19:52:29.122399: step 52210, total loss = 0.61, batch loss = 0.34 (326.6 examples/sec; 0.024 sec/batch; 1h:00m:07s remains)
INFO - root - 2022-02-24 19:52:29.411555: step 52220, total loss = 0.54, batch loss = 0.27 (266.7 examples/sec; 0.030 sec/batch; 1h:13m:38s remains)
INFO - root - 2022-02-24 19:52:29.761947: step 52230, total loss = 0.70, batch loss = 0.43 (333.9 examples/sec; 0.024 sec/batch; 0h:58m:47s remains)
INFO - root - 2022-02-24 19:52:30.062621: step 52240, total loss = 0.56, batch loss = 0.29 (226.9 examples/sec; 0.035 sec/batch; 1h:26m:32s remains)
INFO - root - 2022-02-24 19:52:30.435296: step 52250, total loss = 0.55, batch loss = 0.28 (273.8 examples/sec; 0.029 sec/batch; 1h:11m:42s remains)
INFO - root - 2022-02-24 19:52:30.802234: step 52260, total loss = 0.56, batch loss = 0.29 (287.1 examples/sec; 0.028 sec/batch; 1h:08m:23s remains)
INFO - root - 2022-02-24 19:52:31.214226: step 52270, total loss = 0.63, batch loss = 0.35 (340.0 examples/sec; 0.024 sec/batch; 0h:57m:44s remains)
INFO - root - 2022-02-24 19:52:31.559574: step 52280, total loss = 0.56, batch loss = 0.28 (269.3 examples/sec; 0.030 sec/batch; 1h:12m:53s remains)
INFO - root - 2022-02-24 19:52:31.911834: step 52290, total loss = 0.61, batch loss = 0.33 (303.7 examples/sec; 0.026 sec/batch; 1h:04m:37s remains)
INFO - root - 2022-02-24 19:52:32.335997: step 52300, total loss = 0.67, batch loss = 0.40 (172.9 examples/sec; 0.046 sec/batch; 1h:53m:31s remains)
INFO - root - 2022-02-24 19:52:32.889922: step 52310, total loss = 0.78, batch loss = 0.51 (375.6 examples/sec; 0.021 sec/batch; 0h:52m:15s remains)
INFO - root - 2022-02-24 19:52:33.235486: step 52320, total loss = 0.55, batch loss = 0.27 (253.9 examples/sec; 0.032 sec/batch; 1h:17m:17s remains)
INFO - root - 2022-02-24 19:52:33.563890: step 52330, total loss = 0.55, batch loss = 0.28 (135.5 examples/sec; 0.059 sec/batch; 2h:24m:50s remains)
INFO - root - 2022-02-24 19:52:33.886583: step 52340, total loss = 0.56, batch loss = 0.29 (228.9 examples/sec; 0.035 sec/batch; 1h:25m:43s remains)
INFO - root - 2022-02-24 19:52:34.251422: step 52350, total loss = 0.51, batch loss = 0.24 (168.3 examples/sec; 0.048 sec/batch; 1h:56m:36s remains)
INFO - root - 2022-02-24 19:52:34.668506: step 52360, total loss = 0.66, batch loss = 0.39 (204.0 examples/sec; 0.039 sec/batch; 1h:36m:09s remains)
INFO - root - 2022-02-24 19:52:35.058323: step 52370, total loss = 0.53, batch loss = 0.25 (197.8 examples/sec; 0.040 sec/batch; 1h:39m:11s remains)
INFO - root - 2022-02-24 19:52:35.406728: step 52380, total loss = 0.56, batch loss = 0.29 (189.0 examples/sec; 0.042 sec/batch; 1h:43m:47s remains)
INFO - root - 2022-02-24 19:52:35.710549: step 52390, total loss = 0.58, batch loss = 0.30 (218.9 examples/sec; 0.037 sec/batch; 1h:29m:37s remains)
INFO - root - 2022-02-24 19:52:36.024997: step 52400, total loss = 0.60, batch loss = 0.32 (307.1 examples/sec; 0.026 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 19:52:36.438855: step 52410, total loss = 0.60, batch loss = 0.32 (314.9 examples/sec; 0.025 sec/batch; 1h:02m:16s remains)
INFO - root - 2022-02-24 19:52:36.880063: step 52420, total loss = 0.56, batch loss = 0.28 (255.9 examples/sec; 0.031 sec/batch; 1h:16m:37s remains)
INFO - root - 2022-02-24 19:52:37.359111: step 52430, total loss = 0.62, batch loss = 0.35 (161.6 examples/sec; 0.050 sec/batch; 2h:01m:20s remains)
INFO - root - 2022-02-24 19:52:37.816146: step 52440, total loss = 0.57, batch loss = 0.30 (145.6 examples/sec; 0.055 sec/batch; 2h:14m:38s remains)
INFO - root - 2022-02-24 19:52:38.199463: step 52450, total loss = 0.53, batch loss = 0.25 (136.7 examples/sec; 0.059 sec/batch; 2h:23m:25s remains)
INFO - root - 2022-02-24 19:52:38.514661: step 52460, total loss = 0.58, batch loss = 0.30 (338.4 examples/sec; 0.024 sec/batch; 0h:57m:56s remains)
INFO - root - 2022-02-24 19:52:38.958403: step 52470, total loss = 0.61, batch loss = 0.34 (97.2 examples/sec; 0.082 sec/batch; 3h:21m:45s remains)
INFO - root - 2022-02-24 19:52:39.451944: step 52480, total loss = 0.56, batch loss = 0.29 (271.7 examples/sec; 0.029 sec/batch; 1h:12m:09s remains)
INFO - root - 2022-02-24 19:52:39.894619: step 52490, total loss = 0.55, batch loss = 0.28 (226.9 examples/sec; 0.035 sec/batch; 1h:26m:22s remains)
INFO - root - 2022-02-24 19:52:40.392014: step 52500, total loss = 0.63, batch loss = 0.36 (317.8 examples/sec; 0.025 sec/batch; 1h:01m:40s remains)
INFO - root - 2022-02-24 19:52:40.831138: step 52510, total loss = 0.62, batch loss = 0.34 (109.3 examples/sec; 0.073 sec/batch; 2h:59m:22s remains)
INFO - root - 2022-02-24 19:52:41.343118: step 52520, total loss = 0.58, batch loss = 0.31 (233.4 examples/sec; 0.034 sec/batch; 1h:23m:57s remains)
INFO - root - 2022-02-24 19:52:41.919811: step 52530, total loss = 0.64, batch loss = 0.36 (121.2 examples/sec; 0.066 sec/batch; 2h:41m:44s remains)
INFO - root - 2022-02-24 19:52:42.888126: step 52540, total loss = 0.65, batch loss = 0.37 (23.6 examples/sec; 0.340 sec/batch; 13h:51m:39s remains)
INFO - root - 2022-02-24 19:52:43.360052: step 52550, total loss = 0.51, batch loss = 0.24 (149.3 examples/sec; 0.054 sec/batch; 2h:11m:12s remains)
INFO - root - 2022-02-24 19:52:43.837360: step 52560, total loss = 0.62, batch loss = 0.34 (132.2 examples/sec; 0.061 sec/batch; 2h:28m:13s remains)
INFO - root - 2022-02-24 19:52:44.148535: step 52570, total loss = 0.61, batch loss = 0.33 (309.4 examples/sec; 0.026 sec/batch; 1h:03m:18s remains)
INFO - root - 2022-02-24 19:52:44.545269: step 52580, total loss = 0.67, batch loss = 0.40 (117.2 examples/sec; 0.068 sec/batch; 2h:47m:09s remains)
INFO - root - 2022-02-24 19:52:44.866633: step 52590, total loss = 0.67, batch loss = 0.40 (144.4 examples/sec; 0.055 sec/batch; 2h:15m:38s remains)
INFO - root - 2022-02-24 19:52:45.368729: step 52600, total loss = 0.57, batch loss = 0.29 (138.2 examples/sec; 0.058 sec/batch; 2h:21m:42s remains)
INFO - root - 2022-02-24 19:52:45.969885: step 52610, total loss = 0.60, batch loss = 0.33 (133.8 examples/sec; 0.060 sec/batch; 2h:26m:21s remains)
INFO - root - 2022-02-24 19:52:46.282193: step 52620, total loss = 0.51, batch loss = 0.24 (313.8 examples/sec; 0.025 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 19:52:46.699103: step 52630, total loss = 0.50, batch loss = 0.23 (284.5 examples/sec; 0.028 sec/batch; 1h:08m:49s remains)
INFO - root - 2022-02-24 19:52:47.097204: step 52640, total loss = 0.63, batch loss = 0.36 (310.5 examples/sec; 0.026 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 19:52:47.483856: step 52650, total loss = 0.55, batch loss = 0.28 (321.3 examples/sec; 0.025 sec/batch; 1h:00m:56s remains)
INFO - root - 2022-02-24 19:52:48.288403: step 52660, total loss = 0.59, batch loss = 0.32 (162.7 examples/sec; 0.049 sec/batch; 2h:00m:20s remains)
INFO - root - 2022-02-24 19:52:48.722457: step 52670, total loss = 0.52, batch loss = 0.25 (174.0 examples/sec; 0.046 sec/batch; 1h:52m:31s remains)
INFO - root - 2022-02-24 19:52:49.211964: step 52680, total loss = 0.53, batch loss = 0.26 (273.6 examples/sec; 0.029 sec/batch; 1h:11m:33s remains)
INFO - root - 2022-02-24 19:52:49.505911: step 52690, total loss = 0.61, batch loss = 0.34 (313.1 examples/sec; 0.026 sec/batch; 1h:02m:31s remains)
INFO - root - 2022-02-24 19:52:49.787582: step 52700, total loss = 0.56, batch loss = 0.28 (365.7 examples/sec; 0.022 sec/batch; 0h:53m:31s remains)
INFO - root - 2022-02-24 19:52:50.235933: step 52710, total loss = 0.56, batch loss = 0.28 (241.5 examples/sec; 0.033 sec/batch; 1h:21m:03s remains)
INFO - root - 2022-02-24 19:52:50.646114: step 52720, total loss = 0.51, batch loss = 0.23 (110.0 examples/sec; 0.073 sec/batch; 2h:57m:59s remains)
INFO - root - 2022-02-24 19:52:51.083158: step 52730, total loss = 0.48, batch loss = 0.20 (179.0 examples/sec; 0.045 sec/batch; 1h:49m:17s remains)
INFO - root - 2022-02-24 19:52:51.464875: step 52740, total loss = 0.60, batch loss = 0.32 (154.1 examples/sec; 0.052 sec/batch; 2h:07m:00s remains)
INFO - root - 2022-02-24 19:52:51.788718: step 52750, total loss = 0.57, batch loss = 0.30 (287.0 examples/sec; 0.028 sec/batch; 1h:08m:10s remains)
INFO - root - 2022-02-24 19:52:52.149946: step 52760, total loss = 0.56, batch loss = 0.29 (214.2 examples/sec; 0.037 sec/batch; 1h:31m:20s remains)
INFO - root - 2022-02-24 19:52:52.551240: step 52770, total loss = 0.65, batch loss = 0.37 (265.1 examples/sec; 0.030 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 19:52:53.033099: step 52780, total loss = 0.49, batch loss = 0.22 (214.8 examples/sec; 0.037 sec/batch; 1h:31m:04s remains)
INFO - root - 2022-02-24 19:52:53.495659: step 52790, total loss = 0.56, batch loss = 0.29 (129.5 examples/sec; 0.062 sec/batch; 2h:31m:03s remains)
INFO - root - 2022-02-24 19:52:53.821368: step 52800, total loss = 0.55, batch loss = 0.27 (316.3 examples/sec; 0.025 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 19:52:54.196383: step 52810, total loss = 0.64, batch loss = 0.36 (273.5 examples/sec; 0.029 sec/batch; 1h:11m:30s remains)
INFO - root - 2022-02-24 19:52:54.527144: step 52820, total loss = 0.55, batch loss = 0.27 (337.8 examples/sec; 0.024 sec/batch; 0h:57m:54s remains)
INFO - root - 2022-02-24 19:52:54.943738: step 52830, total loss = 0.54, batch loss = 0.26 (126.2 examples/sec; 0.063 sec/batch; 2h:35m:00s remains)
INFO - root - 2022-02-24 19:52:55.342141: step 52840, total loss = 0.62, batch loss = 0.34 (345.5 examples/sec; 0.023 sec/batch; 0h:56m:35s remains)
INFO - root - 2022-02-24 19:52:55.670715: step 52850, total loss = 0.59, batch loss = 0.32 (191.1 examples/sec; 0.042 sec/batch; 1h:42m:20s remains)
INFO - root - 2022-02-24 19:52:55.972916: step 52860, total loss = 0.57, batch loss = 0.30 (361.4 examples/sec; 0.022 sec/batch; 0h:54m:06s remains)
INFO - root - 2022-02-24 19:52:56.259449: step 52870, total loss = 0.53, batch loss = 0.25 (258.9 examples/sec; 0.031 sec/batch; 1h:15m:31s remains)
INFO - root - 2022-02-24 19:52:56.549646: step 52880, total loss = 0.69, batch loss = 0.42 (269.9 examples/sec; 0.030 sec/batch; 1h:12m:26s remains)
INFO - root - 2022-02-24 19:52:56.917326: step 52890, total loss = 0.57, batch loss = 0.29 (106.3 examples/sec; 0.075 sec/batch; 3h:03m:55s remains)
INFO - root - 2022-02-24 19:52:57.259354: step 52900, total loss = 0.64, batch loss = 0.36 (164.5 examples/sec; 0.049 sec/batch; 1h:58m:48s remains)
INFO - root - 2022-02-24 19:52:57.740012: step 52910, total loss = 0.59, batch loss = 0.31 (322.6 examples/sec; 0.025 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 19:52:58.127970: step 52920, total loss = 0.49, batch loss = 0.21 (144.8 examples/sec; 0.055 sec/batch; 2h:15m:00s remains)
INFO - root - 2022-02-24 19:52:58.423816: step 52930, total loss = 0.55, batch loss = 0.27 (196.6 examples/sec; 0.041 sec/batch; 1h:39m:23s remains)
INFO - root - 2022-02-24 19:52:58.795210: step 52940, total loss = 0.59, batch loss = 0.31 (230.0 examples/sec; 0.035 sec/batch; 1h:24m:58s remains)
INFO - root - 2022-02-24 19:52:59.337634: step 52950, total loss = 0.55, batch loss = 0.27 (97.6 examples/sec; 0.082 sec/batch; 3h:20m:08s remains)
INFO - root - 2022-02-24 19:52:59.635023: step 52960, total loss = 0.50, batch loss = 0.22 (375.6 examples/sec; 0.021 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 19:52:59.961542: step 52970, total loss = 0.66, batch loss = 0.38 (222.3 examples/sec; 0.036 sec/batch; 1h:27m:52s remains)
INFO - root - 2022-02-24 19:53:00.330090: step 52980, total loss = 0.57, batch loss = 0.30 (320.4 examples/sec; 0.025 sec/batch; 1h:00m:58s remains)
INFO - root - 2022-02-24 19:53:00.662368: step 52990, total loss = 0.58, batch loss = 0.31 (362.9 examples/sec; 0.022 sec/batch; 0h:53m:50s remains)
INFO - root - 2022-02-24 19:53:01.097587: step 53000, total loss = 0.53, batch loss = 0.26 (343.3 examples/sec; 0.023 sec/batch; 0h:56m:53s remains)
INFO - root - 2022-02-24 19:53:01.440184: step 53010, total loss = 0.51, batch loss = 0.24 (345.2 examples/sec; 0.023 sec/batch; 0h:56m:34s remains)
INFO - root - 2022-02-24 19:53:01.724221: step 53020, total loss = 0.57, batch loss = 0.29 (321.6 examples/sec; 0.025 sec/batch; 1h:00m:43s remains)
INFO - root - 2022-02-24 19:53:02.015510: step 53030, total loss = 0.61, batch loss = 0.34 (267.7 examples/sec; 0.030 sec/batch; 1h:12m:57s remains)
INFO - root - 2022-02-24 19:53:02.418802: step 53040, total loss = 0.64, batch loss = 0.37 (317.3 examples/sec; 0.025 sec/batch; 1h:01m:32s remains)
INFO - root - 2022-02-24 19:53:02.890561: step 53050, total loss = 0.54, batch loss = 0.27 (285.0 examples/sec; 0.028 sec/batch; 1h:08m:30s remains)
INFO - root - 2022-02-24 19:53:03.218265: step 53060, total loss = 0.64, batch loss = 0.37 (332.7 examples/sec; 0.024 sec/batch; 0h:58m:41s remains)
INFO - root - 2022-02-24 19:53:03.539018: step 53070, total loss = 0.65, batch loss = 0.37 (206.6 examples/sec; 0.039 sec/batch; 1h:34m:29s remains)
INFO - root - 2022-02-24 19:53:03.854145: step 53080, total loss = 0.51, batch loss = 0.24 (181.3 examples/sec; 0.044 sec/batch; 1h:47m:41s remains)
INFO - root - 2022-02-24 19:53:04.158525: step 53090, total loss = 0.49, batch loss = 0.22 (312.0 examples/sec; 0.026 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 19:53:04.578412: step 53100, total loss = 0.50, batch loss = 0.23 (119.8 examples/sec; 0.067 sec/batch; 2h:42m:56s remains)
INFO - root - 2022-02-24 19:53:05.080119: step 53110, total loss = 0.58, batch loss = 0.30 (339.1 examples/sec; 0.024 sec/batch; 0h:57m:33s remains)
INFO - root - 2022-02-24 19:53:05.380919: step 53120, total loss = 0.58, batch loss = 0.31 (275.9 examples/sec; 0.029 sec/batch; 1h:10m:44s remains)
INFO - root - 2022-02-24 19:53:05.756530: step 53130, total loss = 0.56, batch loss = 0.28 (204.6 examples/sec; 0.039 sec/batch; 1h:35m:22s remains)
INFO - root - 2022-02-24 19:53:06.086434: step 53140, total loss = 0.57, batch loss = 0.30 (345.2 examples/sec; 0.023 sec/batch; 0h:56m:32s remains)
INFO - root - 2022-02-24 19:53:06.488859: step 53150, total loss = 0.53, batch loss = 0.26 (154.0 examples/sec; 0.052 sec/batch; 2h:06m:40s remains)
INFO - root - 2022-02-24 19:53:06.842170: step 53160, total loss = 0.50, batch loss = 0.22 (314.2 examples/sec; 0.025 sec/batch; 1h:02m:05s remains)
INFO - root - 2022-02-24 19:53:07.297665: step 53170, total loss = 0.56, batch loss = 0.29 (136.8 examples/sec; 0.058 sec/batch; 2h:22m:38s remains)
INFO - root - 2022-02-24 19:53:07.830415: step 53180, total loss = 0.62, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 8h:49m:49s remains)
INFO - root - 2022-02-24 19:53:08.144902: step 53190, total loss = 0.58, batch loss = 0.30 (290.8 examples/sec; 0.028 sec/batch; 1h:07m:04s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-53199 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-53199 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:53:09.404561: step 53200, total loss = 0.48, batch loss = 0.21 (355.9 examples/sec; 0.022 sec/batch; 0h:54m:48s remains)
INFO - root - 2022-02-24 19:53:09.707936: step 53210, total loss = 0.57, batch loss = 0.30 (347.5 examples/sec; 0.023 sec/batch; 0h:56m:07s remains)
INFO - root - 2022-02-24 19:53:09.940084: step 53220, total loss = 0.67, batch loss = 0.40 (332.5 examples/sec; 0.024 sec/batch; 0h:58m:39s remains)
INFO - root - 2022-02-24 19:53:10.324365: step 53230, total loss = 0.57, batch loss = 0.30 (360.2 examples/sec; 0.022 sec/batch; 0h:54m:08s remains)
INFO - root - 2022-02-24 19:53:10.812328: step 53240, total loss = 0.56, batch loss = 0.29 (208.0 examples/sec; 0.038 sec/batch; 1h:33m:46s remains)
INFO - root - 2022-02-24 19:53:11.289171: step 53250, total loss = 0.52, batch loss = 0.24 (157.4 examples/sec; 0.051 sec/batch; 2h:03m:52s remains)
INFO - root - 2022-02-24 19:53:11.713159: step 53260, total loss = 0.54, batch loss = 0.26 (213.1 examples/sec; 0.038 sec/batch; 1h:31m:29s remains)
INFO - root - 2022-02-24 19:53:12.084071: step 53270, total loss = 0.51, batch loss = 0.24 (138.3 examples/sec; 0.058 sec/batch; 2h:20m:58s remains)
INFO - root - 2022-02-24 19:53:12.529148: step 53280, total loss = 0.51, batch loss = 0.24 (161.4 examples/sec; 0.050 sec/batch; 2h:00m:46s remains)
INFO - root - 2022-02-24 19:53:13.360497: step 53290, total loss = 0.63, batch loss = 0.35 (110.3 examples/sec; 0.073 sec/batch; 2h:56m:42s remains)
INFO - root - 2022-02-24 19:53:13.798698: step 53300, total loss = 0.56, batch loss = 0.28 (166.1 examples/sec; 0.048 sec/batch; 1h:57m:23s remains)
INFO - root - 2022-02-24 19:53:14.221141: step 53310, total loss = 0.53, batch loss = 0.26 (191.3 examples/sec; 0.042 sec/batch; 1h:41m:52s remains)
INFO - root - 2022-02-24 19:53:14.607938: step 53320, total loss = 0.65, batch loss = 0.37 (105.9 examples/sec; 0.076 sec/batch; 3h:03m:59s remains)
INFO - root - 2022-02-24 19:53:15.020854: step 53330, total loss = 0.56, batch loss = 0.29 (149.8 examples/sec; 0.053 sec/batch; 2h:10m:06s remains)
INFO - root - 2022-02-24 19:53:15.410126: step 53340, total loss = 0.58, batch loss = 0.31 (293.5 examples/sec; 0.027 sec/batch; 1h:06m:23s remains)
INFO - root - 2022-02-24 19:53:15.785339: step 53350, total loss = 0.56, batch loss = 0.29 (158.4 examples/sec; 0.050 sec/batch; 2h:03m:00s remains)
INFO - root - 2022-02-24 19:53:16.113789: step 53360, total loss = 0.59, batch loss = 0.31 (270.6 examples/sec; 0.030 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 19:53:16.510971: step 53370, total loss = 0.52, batch loss = 0.24 (104.1 examples/sec; 0.077 sec/batch; 3h:07m:05s remains)
INFO - root - 2022-02-24 19:53:17.005058: step 53380, total loss = 0.47, batch loss = 0.20 (118.1 examples/sec; 0.068 sec/batch; 2h:44m:56s remains)
INFO - root - 2022-02-24 19:53:17.314040: step 53390, total loss = 0.55, batch loss = 0.28 (222.7 examples/sec; 0.036 sec/batch; 1h:27m:29s remains)
INFO - root - 2022-02-24 19:53:17.636678: step 53400, total loss = 0.56, batch loss = 0.28 (343.5 examples/sec; 0.023 sec/batch; 0h:56m:42s remains)
INFO - root - 2022-02-24 19:53:18.024288: step 53410, total loss = 0.61, batch loss = 0.33 (318.2 examples/sec; 0.025 sec/batch; 1h:01m:12s remains)
INFO - root - 2022-02-24 19:53:18.641202: step 53420, total loss = 0.66, batch loss = 0.38 (266.3 examples/sec; 0.030 sec/batch; 1h:13m:08s remains)
INFO - root - 2022-02-24 19:53:18.988384: step 53430, total loss = 0.54, batch loss = 0.26 (336.2 examples/sec; 0.024 sec/batch; 0h:57m:56s remains)
INFO - root - 2022-02-24 19:53:19.346863: step 53440, total loss = 0.64, batch loss = 0.37 (264.2 examples/sec; 0.030 sec/batch; 1h:13m:42s remains)
INFO - root - 2022-02-24 19:53:19.635334: step 53450, total loss = 0.65, batch loss = 0.38 (316.2 examples/sec; 0.025 sec/batch; 1h:01m:35s remains)
INFO - root - 2022-02-24 19:53:19.958710: step 53460, total loss = 0.69, batch loss = 0.42 (321.9 examples/sec; 0.025 sec/batch; 1h:00m:29s remains)
INFO - root - 2022-02-24 19:53:20.243829: step 53470, total loss = 0.62, batch loss = 0.34 (337.2 examples/sec; 0.024 sec/batch; 0h:57m:44s remains)
INFO - root - 2022-02-24 19:53:20.624214: step 53480, total loss = 0.56, batch loss = 0.28 (199.8 examples/sec; 0.040 sec/batch; 1h:37m:27s remains)
INFO - root - 2022-02-24 19:53:21.026712: step 53490, total loss = 0.68, batch loss = 0.40 (167.5 examples/sec; 0.048 sec/batch; 1h:56m:14s remains)
INFO - root - 2022-02-24 19:53:21.423453: step 53500, total loss = 0.49, batch loss = 0.21 (226.6 examples/sec; 0.035 sec/batch; 1h:25m:55s remains)
INFO - root - 2022-02-24 19:53:21.804107: step 53510, total loss = 0.58, batch loss = 0.30 (328.1 examples/sec; 0.024 sec/batch; 0h:59m:19s remains)
INFO - root - 2022-02-24 19:53:22.090866: step 53520, total loss = 0.47, batch loss = 0.19 (208.1 examples/sec; 0.038 sec/batch; 1h:33m:31s remains)
INFO - root - 2022-02-24 19:53:22.446029: step 53530, total loss = 0.49, batch loss = 0.22 (227.2 examples/sec; 0.035 sec/batch; 1h:25m:39s remains)
INFO - root - 2022-02-24 19:53:22.852311: step 53540, total loss = 0.58, batch loss = 0.31 (324.1 examples/sec; 0.025 sec/batch; 1h:00m:03s remains)
INFO - root - 2022-02-24 19:53:23.362828: step 53550, total loss = 0.58, batch loss = 0.30 (231.7 examples/sec; 0.035 sec/batch; 1h:23m:58s remains)
INFO - root - 2022-02-24 19:53:23.674836: step 53560, total loss = 0.53, batch loss = 0.25 (330.4 examples/sec; 0.024 sec/batch; 0h:58m:53s remains)
INFO - root - 2022-02-24 19:53:23.954466: step 53570, total loss = 0.56, batch loss = 0.29 (349.2 examples/sec; 0.023 sec/batch; 0h:55m:42s remains)
INFO - root - 2022-02-24 19:53:24.223490: step 53580, total loss = 0.57, batch loss = 0.30 (367.2 examples/sec; 0.022 sec/batch; 0h:52m:59s remains)
INFO - root - 2022-02-24 19:53:24.545532: step 53590, total loss = 0.67, batch loss = 0.39 (303.1 examples/sec; 0.026 sec/batch; 1h:04m:11s remains)
INFO - root - 2022-02-24 19:53:24.878436: step 53600, total loss = 0.71, batch loss = 0.43 (296.3 examples/sec; 0.027 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 19:53:25.325668: step 53610, total loss = 0.54, batch loss = 0.26 (364.5 examples/sec; 0.022 sec/batch; 0h:53m:22s remains)
INFO - root - 2022-02-24 19:53:25.705985: step 53620, total loss = 0.47, batch loss = 0.20 (338.4 examples/sec; 0.024 sec/batch; 0h:57m:29s remains)
INFO - root - 2022-02-24 19:53:26.075830: step 53630, total loss = 0.61, batch loss = 0.33 (280.3 examples/sec; 0.029 sec/batch; 1h:09m:23s remains)
INFO - root - 2022-02-24 19:53:26.355680: step 53640, total loss = 0.55, batch loss = 0.28 (254.7 examples/sec; 0.031 sec/batch; 1h:16m:21s remains)
INFO - root - 2022-02-24 19:53:26.666925: step 53650, total loss = 0.49, batch loss = 0.22 (338.7 examples/sec; 0.024 sec/batch; 0h:57m:25s remains)
INFO - root - 2022-02-24 19:53:27.050473: step 53660, total loss = 0.77, batch loss = 0.50 (191.2 examples/sec; 0.042 sec/batch; 1h:41m:43s remains)
INFO - root - 2022-02-24 19:53:27.418529: step 53670, total loss = 0.60, batch loss = 0.33 (260.4 examples/sec; 0.031 sec/batch; 1h:14m:39s remains)
INFO - root - 2022-02-24 19:53:27.907538: step 53680, total loss = 0.54, batch loss = 0.26 (112.0 examples/sec; 0.071 sec/batch; 2h:53m:36s remains)
INFO - root - 2022-02-24 19:53:28.310261: step 53690, total loss = 0.50, batch loss = 0.23 (109.2 examples/sec; 0.073 sec/batch; 2h:58m:00s remains)
INFO - root - 2022-02-24 19:53:28.687907: step 53700, total loss = 0.61, batch loss = 0.34 (156.1 examples/sec; 0.051 sec/batch; 2h:04m:33s remains)
INFO - root - 2022-02-24 19:53:29.101594: step 53710, total loss = 0.64, batch loss = 0.37 (200.3 examples/sec; 0.040 sec/batch; 1h:37m:03s remains)
INFO - root - 2022-02-24 19:53:29.386026: step 53720, total loss = 0.60, batch loss = 0.33 (267.8 examples/sec; 0.030 sec/batch; 1h:12m:34s remains)
INFO - root - 2022-02-24 19:53:29.806425: step 53730, total loss = 0.53, batch loss = 0.25 (264.5 examples/sec; 0.030 sec/batch; 1h:13m:28s remains)
INFO - root - 2022-02-24 19:53:30.286459: step 53740, total loss = 0.50, batch loss = 0.23 (321.5 examples/sec; 0.025 sec/batch; 1h:00m:27s remains)
INFO - root - 2022-02-24 19:53:30.581371: step 53750, total loss = 0.54, batch loss = 0.27 (312.4 examples/sec; 0.026 sec/batch; 1h:02m:12s remains)
INFO - root - 2022-02-24 19:53:30.882641: step 53760, total loss = 0.62, batch loss = 0.35 (253.8 examples/sec; 0.032 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 19:53:31.251093: step 53770, total loss = 0.55, batch loss = 0.28 (207.1 examples/sec; 0.039 sec/batch; 1h:33m:48s remains)
INFO - root - 2022-02-24 19:53:31.611547: step 53780, total loss = 0.55, batch loss = 0.27 (156.0 examples/sec; 0.051 sec/batch; 2h:04m:31s remains)
INFO - root - 2022-02-24 19:53:32.134561: step 53790, total loss = 0.61, batch loss = 0.34 (188.8 examples/sec; 0.042 sec/batch; 1h:42m:55s remains)
INFO - root - 2022-02-24 19:53:32.707054: step 53800, total loss = 0.53, batch loss = 0.26 (331.2 examples/sec; 0.024 sec/batch; 0h:58m:39s remains)
INFO - root - 2022-02-24 19:53:33.873785: step 53810, total loss = 0.58, batch loss = 0.30 (15.8 examples/sec; 0.507 sec/batch; 20h:31m:22s remains)
INFO - root - 2022-02-24 19:53:34.382870: step 53820, total loss = 0.61, batch loss = 0.33 (229.7 examples/sec; 0.035 sec/batch; 1h:24m:33s remains)
INFO - root - 2022-02-24 19:53:34.746835: step 53830, total loss = 0.58, batch loss = 0.30 (298.0 examples/sec; 0.027 sec/batch; 1h:05m:09s remains)
INFO - root - 2022-02-24 19:53:35.103262: step 53840, total loss = 0.63, batch loss = 0.36 (326.1 examples/sec; 0.025 sec/batch; 0h:59m:33s remains)
INFO - root - 2022-02-24 19:53:35.537630: step 53850, total loss = 0.52, batch loss = 0.24 (234.1 examples/sec; 0.034 sec/batch; 1h:22m:56s remains)
INFO - root - 2022-02-24 19:53:35.983409: step 53860, total loss = 0.54, batch loss = 0.26 (216.6 examples/sec; 0.037 sec/batch; 1h:29m:38s remains)
INFO - root - 2022-02-24 19:53:36.478353: step 53870, total loss = 0.58, batch loss = 0.30 (312.0 examples/sec; 0.026 sec/batch; 1h:02m:14s remains)
INFO - root - 2022-02-24 19:53:36.912088: step 53880, total loss = 0.59, batch loss = 0.32 (314.9 examples/sec; 0.025 sec/batch; 1h:01m:39s remains)
INFO - root - 2022-02-24 19:53:37.277629: step 53890, total loss = 0.52, batch loss = 0.25 (192.2 examples/sec; 0.042 sec/batch; 1h:41m:01s remains)
INFO - root - 2022-02-24 19:53:37.597906: step 53900, total loss = 0.52, batch loss = 0.25 (343.9 examples/sec; 0.023 sec/batch; 0h:56m:26s remains)
INFO - root - 2022-02-24 19:53:38.081876: step 53910, total loss = 0.67, batch loss = 0.40 (228.9 examples/sec; 0.035 sec/batch; 1h:24m:48s remains)
INFO - root - 2022-02-24 19:53:38.472548: step 53920, total loss = 0.56, batch loss = 0.28 (137.3 examples/sec; 0.058 sec/batch; 2h:21m:21s remains)
INFO - root - 2022-02-24 19:53:39.262258: step 53930, total loss = 0.61, batch loss = 0.33 (22.2 examples/sec; 0.361 sec/batch; 14h:35m:38s remains)
INFO - root - 2022-02-24 19:53:39.617635: step 53940, total loss = 0.62, batch loss = 0.35 (241.6 examples/sec; 0.033 sec/batch; 1h:20m:20s remains)
INFO - root - 2022-02-24 19:53:39.952499: step 53950, total loss = 0.56, batch loss = 0.28 (184.0 examples/sec; 0.043 sec/batch; 1h:45m:29s remains)
INFO - root - 2022-02-24 19:53:40.244134: step 53960, total loss = 0.60, batch loss = 0.33 (312.9 examples/sec; 0.026 sec/batch; 1h:02m:01s remains)
INFO - root - 2022-02-24 19:53:40.583357: step 53970, total loss = 0.51, batch loss = 0.24 (159.2 examples/sec; 0.050 sec/batch; 2h:01m:52s remains)
INFO - root - 2022-02-24 19:53:41.008652: step 53980, total loss = 0.53, batch loss = 0.25 (272.2 examples/sec; 0.029 sec/batch; 1h:11m:17s remains)
INFO - root - 2022-02-24 19:53:41.532571: step 53990, total loss = 0.54, batch loss = 0.27 (194.6 examples/sec; 0.041 sec/batch; 1h:39m:42s remains)
INFO - root - 2022-02-24 19:53:41.821156: step 54000, total loss = 0.67, batch loss = 0.39 (366.8 examples/sec; 0.022 sec/batch; 0h:52m:53s remains)
INFO - root - 2022-02-24 19:53:42.203472: step 54010, total loss = 0.59, batch loss = 0.32 (265.9 examples/sec; 0.030 sec/batch; 1h:12m:56s remains)
INFO - root - 2022-02-24 19:53:42.543469: step 54020, total loss = 0.55, batch loss = 0.28 (156.8 examples/sec; 0.051 sec/batch; 2h:03m:44s remains)
INFO - root - 2022-02-24 19:53:43.014997: step 54030, total loss = 0.55, batch loss = 0.28 (244.8 examples/sec; 0.033 sec/batch; 1h:19m:14s remains)
INFO - root - 2022-02-24 19:53:43.399168: step 54040, total loss = 0.71, batch loss = 0.44 (245.6 examples/sec; 0.033 sec/batch; 1h:18m:57s remains)
INFO - root - 2022-02-24 19:53:43.774450: step 54050, total loss = 0.60, batch loss = 0.33 (305.8 examples/sec; 0.026 sec/batch; 1h:03m:24s remains)
INFO - root - 2022-02-24 19:53:44.179076: step 54060, total loss = 0.66, batch loss = 0.38 (315.6 examples/sec; 0.025 sec/batch; 1h:01m:26s remains)
INFO - root - 2022-02-24 19:53:44.538769: step 54070, total loss = 0.58, batch loss = 0.30 (189.3 examples/sec; 0.042 sec/batch; 1h:42m:26s remains)
INFO - root - 2022-02-24 19:53:44.934239: step 54080, total loss = 0.57, batch loss = 0.30 (365.1 examples/sec; 0.022 sec/batch; 0h:53m:06s remains)
INFO - root - 2022-02-24 19:53:45.344628: step 54090, total loss = 0.54, batch loss = 0.26 (225.3 examples/sec; 0.036 sec/batch; 1h:26m:02s remains)
INFO - root - 2022-02-24 19:53:45.660509: step 54100, total loss = 0.61, batch loss = 0.34 (264.1 examples/sec; 0.030 sec/batch; 1h:13m:23s remains)
INFO - root - 2022-02-24 19:53:46.031706: step 54110, total loss = 0.59, batch loss = 0.31 (325.9 examples/sec; 0.025 sec/batch; 0h:59m:29s remains)
INFO - root - 2022-02-24 19:53:46.360028: step 54120, total loss = 0.57, batch loss = 0.30 (316.3 examples/sec; 0.025 sec/batch; 1h:01m:16s remains)
INFO - root - 2022-02-24 19:53:46.674284: step 54130, total loss = 0.63, batch loss = 0.36 (209.5 examples/sec; 0.038 sec/batch; 1h:32m:31s remains)
INFO - root - 2022-02-24 19:53:47.111402: step 54140, total loss = 0.64, batch loss = 0.36 (210.4 examples/sec; 0.038 sec/batch; 1h:32m:06s remains)
INFO - root - 2022-02-24 19:53:47.547072: step 54150, total loss = 0.51, batch loss = 0.23 (365.1 examples/sec; 0.022 sec/batch; 0h:53m:04s remains)
INFO - root - 2022-02-24 19:53:47.881980: step 54160, total loss = 0.63, batch loss = 0.35 (326.6 examples/sec; 0.024 sec/batch; 0h:59m:20s remains)
INFO - root - 2022-02-24 19:53:48.196780: step 54170, total loss = 0.51, batch loss = 0.24 (190.7 examples/sec; 0.042 sec/batch; 1h:41m:35s remains)
INFO - root - 2022-02-24 19:53:48.475260: step 54180, total loss = 0.57, batch loss = 0.30 (289.2 examples/sec; 0.028 sec/batch; 1h:06m:59s remains)
INFO - root - 2022-02-24 19:53:48.912869: step 54190, total loss = 0.62, batch loss = 0.34 (154.9 examples/sec; 0.052 sec/batch; 2h:05m:06s remains)
INFO - root - 2022-02-24 19:53:49.264390: step 54200, total loss = 0.50, batch loss = 0.23 (253.8 examples/sec; 0.032 sec/batch; 1h:16m:20s remains)
INFO - root - 2022-02-24 19:53:49.682014: step 54210, total loss = 0.56, batch loss = 0.28 (240.3 examples/sec; 0.033 sec/batch; 1h:20m:37s remains)
INFO - root - 2022-02-24 19:53:50.034218: step 54220, total loss = 0.63, batch loss = 0.36 (295.6 examples/sec; 0.027 sec/batch; 1h:05m:31s remains)
INFO - root - 2022-02-24 19:53:50.351182: step 54230, total loss = 0.70, batch loss = 0.43 (312.1 examples/sec; 0.026 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 19:53:50.702281: step 54240, total loss = 0.57, batch loss = 0.30 (293.2 examples/sec; 0.027 sec/batch; 1h:06m:03s remains)
INFO - root - 2022-02-24 19:53:51.059211: step 54250, total loss = 0.62, batch loss = 0.34 (162.6 examples/sec; 0.049 sec/batch; 1h:59m:05s remains)
INFO - root - 2022-02-24 19:53:51.528840: step 54260, total loss = 0.73, batch loss = 0.46 (121.6 examples/sec; 0.066 sec/batch; 2h:39m:12s remains)
INFO - root - 2022-02-24 19:53:51.949208: step 54270, total loss = 0.60, batch loss = 0.33 (178.7 examples/sec; 0.045 sec/batch; 1h:48m:23s remains)
INFO - root - 2022-02-24 19:53:52.320829: step 54280, total loss = 0.61, batch loss = 0.33 (148.1 examples/sec; 0.054 sec/batch; 2h:10m:43s remains)
INFO - root - 2022-02-24 19:53:52.660607: step 54290, total loss = 0.55, batch loss = 0.27 (154.6 examples/sec; 0.052 sec/batch; 2h:05m:12s remains)
INFO - root - 2022-02-24 19:53:53.051534: step 54300, total loss = 0.48, batch loss = 0.21 (248.1 examples/sec; 0.032 sec/batch; 1h:18m:02s remains)
INFO - root - 2022-02-24 19:53:53.572787: step 54310, total loss = 0.55, batch loss = 0.28 (165.3 examples/sec; 0.048 sec/batch; 1h:57m:08s remains)
INFO - root - 2022-02-24 19:53:53.966129: step 54320, total loss = 0.56, batch loss = 0.29 (182.0 examples/sec; 0.044 sec/batch; 1h:46m:21s remains)
INFO - root - 2022-02-24 19:53:54.296487: step 54330, total loss = 0.61, batch loss = 0.34 (323.5 examples/sec; 0.025 sec/batch; 0h:59m:49s remains)
INFO - root - 2022-02-24 19:53:54.580553: step 54340, total loss = 0.54, batch loss = 0.26 (177.5 examples/sec; 0.045 sec/batch; 1h:49m:03s remains)
INFO - root - 2022-02-24 19:53:54.958888: step 54350, total loss = 0.56, batch loss = 0.28 (355.8 examples/sec; 0.022 sec/batch; 0h:54m:23s remains)
INFO - root - 2022-02-24 19:53:55.309021: step 54360, total loss = 0.57, batch loss = 0.29 (339.6 examples/sec; 0.024 sec/batch; 0h:56m:59s remains)
INFO - root - 2022-02-24 19:53:55.791937: step 54370, total loss = 0.60, batch loss = 0.33 (212.6 examples/sec; 0.038 sec/batch; 1h:31m:01s remains)
INFO - root - 2022-02-24 19:53:56.109520: step 54380, total loss = 0.58, batch loss = 0.31 (245.0 examples/sec; 0.033 sec/batch; 1h:18m:59s remains)
INFO - root - 2022-02-24 19:53:56.402540: step 54390, total loss = 0.57, batch loss = 0.29 (162.7 examples/sec; 0.049 sec/batch; 1h:58m:53s remains)
INFO - root - 2022-02-24 19:53:56.722262: step 54400, total loss = 0.59, batch loss = 0.31 (325.3 examples/sec; 0.025 sec/batch; 0h:59m:28s remains)
INFO - root - 2022-02-24 19:53:57.120880: step 54410, total loss = 0.66, batch loss = 0.38 (213.7 examples/sec; 0.037 sec/batch; 1h:30m:30s remains)
INFO - root - 2022-02-24 19:53:57.477349: step 54420, total loss = 0.60, batch loss = 0.33 (234.5 examples/sec; 0.034 sec/batch; 1h:22m:30s remains)
INFO - root - 2022-02-24 19:53:57.930463: step 54430, total loss = 0.51, batch loss = 0.23 (286.2 examples/sec; 0.028 sec/batch; 1h:07m:35s remains)
INFO - root - 2022-02-24 19:53:58.279226: step 54440, total loss = 0.56, batch loss = 0.28 (146.1 examples/sec; 0.055 sec/batch; 2h:12m:25s remains)
INFO - root - 2022-02-24 19:53:58.609607: step 54450, total loss = 0.52, batch loss = 0.25 (363.6 examples/sec; 0.022 sec/batch; 0h:53m:11s remains)
INFO - root - 2022-02-24 19:53:58.967715: step 54460, total loss = 0.54, batch loss = 0.27 (150.7 examples/sec; 0.053 sec/batch; 2h:08m:17s remains)
INFO - root - 2022-02-24 19:53:59.452311: step 54470, total loss = 0.53, batch loss = 0.25 (240.8 examples/sec; 0.033 sec/batch; 1h:20m:19s remains)
INFO - root - 2022-02-24 19:53:59.900951: step 54480, total loss = 0.53, batch loss = 0.26 (244.2 examples/sec; 0.033 sec/batch; 1h:19m:10s remains)
INFO - root - 2022-02-24 19:54:00.190690: step 54490, total loss = 0.56, batch loss = 0.29 (161.2 examples/sec; 0.050 sec/batch; 1h:59m:57s remains)
INFO - root - 2022-02-24 19:54:00.507871: step 54500, total loss = 0.54, batch loss = 0.27 (271.9 examples/sec; 0.029 sec/batch; 1h:11m:06s remains)
INFO - root - 2022-02-24 19:54:00.853678: step 54510, total loss = 0.65, batch loss = 0.38 (354.3 examples/sec; 0.023 sec/batch; 0h:54m:33s remains)
INFO - root - 2022-02-24 19:54:01.249168: step 54520, total loss = 0.57, batch loss = 0.30 (175.1 examples/sec; 0.046 sec/batch; 1h:50m:23s remains)
INFO - root - 2022-02-24 19:54:01.663033: step 54530, total loss = 0.56, batch loss = 0.28 (193.5 examples/sec; 0.041 sec/batch; 1h:39m:54s remains)
INFO - root - 2022-02-24 19:54:02.064325: step 54540, total loss = 0.62, batch loss = 0.35 (103.9 examples/sec; 0.077 sec/batch; 3h:06m:05s remains)
INFO - root - 2022-02-24 19:54:02.351956: step 54550, total loss = 0.60, batch loss = 0.33 (231.8 examples/sec; 0.035 sec/batch; 1h:23m:23s remains)
INFO - root - 2022-02-24 19:54:02.789617: step 54560, total loss = 0.60, batch loss = 0.33 (284.4 examples/sec; 0.028 sec/batch; 1h:07m:57s remains)
INFO - root - 2022-02-24 19:54:03.326458: step 54570, total loss = 0.54, batch loss = 0.27 (154.1 examples/sec; 0.052 sec/batch; 2h:05m:26s remains)
INFO - root - 2022-02-24 19:54:03.854576: step 54580, total loss = 0.57, batch loss = 0.30 (308.0 examples/sec; 0.026 sec/batch; 1h:02m:44s remains)
INFO - root - 2022-02-24 19:54:04.790064: step 54590, total loss = 0.56, batch loss = 0.28 (15.4 examples/sec; 0.520 sec/batch; 20h:55m:26s remains)
INFO - root - 2022-02-24 19:54:05.106052: step 54600, total loss = 0.64, batch loss = 0.36 (322.3 examples/sec; 0.025 sec/batch; 0h:59m:56s remains)
INFO - root - 2022-02-24 19:54:05.700050: step 54610, total loss = 0.70, batch loss = 0.42 (356.1 examples/sec; 0.022 sec/batch; 0h:54m:15s remains)
INFO - root - 2022-02-24 19:54:06.165251: step 54620, total loss = 0.68, batch loss = 0.41 (130.8 examples/sec; 0.061 sec/batch; 2h:27m:42s remains)
INFO - root - 2022-02-24 19:54:06.551733: step 54630, total loss = 0.51, batch loss = 0.23 (156.6 examples/sec; 0.051 sec/batch; 2h:03m:19s remains)
INFO - root - 2022-02-24 19:54:06.890010: step 54640, total loss = 0.51, batch loss = 0.23 (258.8 examples/sec; 0.031 sec/batch; 1h:14m:38s remains)
INFO - root - 2022-02-24 19:54:07.266752: step 54650, total loss = 0.57, batch loss = 0.29 (299.0 examples/sec; 0.027 sec/batch; 1h:04m:35s remains)
INFO - root - 2022-02-24 19:54:07.789385: step 54660, total loss = 0.56, batch loss = 0.29 (188.2 examples/sec; 0.043 sec/batch; 1h:42m:37s remains)
INFO - root - 2022-02-24 19:54:08.160652: step 54670, total loss = 0.57, batch loss = 0.29 (263.5 examples/sec; 0.030 sec/batch; 1h:13m:16s remains)
INFO - root - 2022-02-24 19:54:08.523803: step 54680, total loss = 0.56, batch loss = 0.29 (163.3 examples/sec; 0.049 sec/batch; 1h:58m:14s remains)
INFO - root - 2022-02-24 19:54:08.843748: step 54690, total loss = 0.54, batch loss = 0.26 (193.3 examples/sec; 0.041 sec/batch; 1h:39m:53s remains)
INFO - root - 2022-02-24 19:54:09.237448: step 54700, total loss = 0.56, batch loss = 0.28 (340.5 examples/sec; 0.023 sec/batch; 0h:56m:42s remains)
INFO - root - 2022-02-24 19:54:09.764575: step 54710, total loss = 0.65, batch loss = 0.38 (157.1 examples/sec; 0.051 sec/batch; 2h:02m:53s remains)
INFO - root - 2022-02-24 19:54:10.383168: step 54720, total loss = 0.54, batch loss = 0.27 (182.1 examples/sec; 0.044 sec/batch; 1h:46m:00s remains)
INFO - root - 2022-02-24 19:54:10.711730: step 54730, total loss = 0.55, batch loss = 0.27 (216.5 examples/sec; 0.037 sec/batch; 1h:29m:08s remains)
INFO - root - 2022-02-24 19:54:11.010584: step 54740, total loss = 0.51, batch loss = 0.24 (350.1 examples/sec; 0.023 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 19:54:11.268974: step 54750, total loss = 0.56, batch loss = 0.29 (345.4 examples/sec; 0.023 sec/batch; 0h:55m:53s remains)
INFO - root - 2022-02-24 19:54:11.701860: step 54760, total loss = 0.60, batch loss = 0.33 (158.9 examples/sec; 0.050 sec/batch; 2h:01m:29s remains)
INFO - root - 2022-02-24 19:54:12.177077: step 54770, total loss = 0.58, batch loss = 0.30 (323.7 examples/sec; 0.025 sec/batch; 0h:59m:36s remains)
INFO - root - 2022-02-24 19:54:12.564463: step 54780, total loss = 0.52, batch loss = 0.24 (137.5 examples/sec; 0.058 sec/batch; 2h:20m:17s remains)
INFO - root - 2022-02-24 19:54:12.901323: step 54790, total loss = 0.53, batch loss = 0.26 (343.9 examples/sec; 0.023 sec/batch; 0h:56m:06s remains)
INFO - root - 2022-02-24 19:54:13.351451: step 54800, total loss = 0.64, batch loss = 0.36 (201.5 examples/sec; 0.040 sec/batch; 1h:35m:44s remains)
INFO - root - 2022-02-24 19:54:13.794563: step 54810, total loss = 0.49, batch loss = 0.22 (294.9 examples/sec; 0.027 sec/batch; 1h:05m:25s remains)
INFO - root - 2022-02-24 19:54:14.288770: step 54820, total loss = 0.55, batch loss = 0.28 (198.8 examples/sec; 0.040 sec/batch; 1h:37m:00s remains)
INFO - root - 2022-02-24 19:54:14.714161: step 54830, total loss = 0.49, batch loss = 0.22 (303.6 examples/sec; 0.026 sec/batch; 1h:03m:31s remains)
INFO - root - 2022-02-24 19:54:15.284973: step 54840, total loss = 0.51, batch loss = 0.23 (329.5 examples/sec; 0.024 sec/batch; 0h:58m:31s remains)
INFO - root - 2022-02-24 19:54:15.644648: step 54850, total loss = 0.58, batch loss = 0.31 (192.5 examples/sec; 0.042 sec/batch; 1h:40m:11s remains)
INFO - root - 2022-02-24 19:54:16.076447: step 54860, total loss = 0.64, batch loss = 0.36 (108.0 examples/sec; 0.074 sec/batch; 2h:58m:37s remains)
INFO - root - 2022-02-24 19:54:16.530125: step 54870, total loss = 0.66, batch loss = 0.38 (358.1 examples/sec; 0.022 sec/batch; 0h:53m:51s remains)
INFO - root - 2022-02-24 19:54:16.864603: step 54880, total loss = 0.54, batch loss = 0.27 (322.9 examples/sec; 0.025 sec/batch; 0h:59m:42s remains)
INFO - root - 2022-02-24 19:54:17.245604: step 54890, total loss = 0.47, batch loss = 0.19 (196.8 examples/sec; 0.041 sec/batch; 1h:37m:59s remains)
INFO - root - 2022-02-24 19:54:17.570898: step 54900, total loss = 0.61, batch loss = 0.34 (309.1 examples/sec; 0.026 sec/batch; 1h:02m:22s remains)
INFO - root - 2022-02-24 19:54:18.073360: step 54910, total loss = 0.61, batch loss = 0.34 (115.6 examples/sec; 0.069 sec/batch; 2h:46m:47s remains)
INFO - root - 2022-02-24 19:54:18.427676: step 54920, total loss = 0.55, batch loss = 0.27 (175.0 examples/sec; 0.046 sec/batch; 1h:50m:07s remains)
INFO - root - 2022-02-24 19:54:18.792311: step 54930, total loss = 0.65, batch loss = 0.37 (342.2 examples/sec; 0.023 sec/batch; 0h:56m:19s remains)
INFO - root - 2022-02-24 19:54:19.077621: step 54940, total loss = 0.51, batch loss = 0.24 (297.5 examples/sec; 0.027 sec/batch; 1h:04m:46s remains)
INFO - root - 2022-02-24 19:54:19.414272: step 54950, total loss = 0.54, batch loss = 0.26 (210.8 examples/sec; 0.038 sec/batch; 1h:31m:25s remains)
INFO - root - 2022-02-24 19:54:19.840394: step 54960, total loss = 0.59, batch loss = 0.31 (338.6 examples/sec; 0.024 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 19:54:20.334659: step 54970, total loss = 0.51, batch loss = 0.23 (307.2 examples/sec; 0.026 sec/batch; 1h:02m:43s remains)
INFO - root - 2022-02-24 19:54:20.676728: step 54980, total loss = 0.68, batch loss = 0.41 (328.5 examples/sec; 0.024 sec/batch; 0h:58m:39s remains)
INFO - root - 2022-02-24 19:54:21.014933: step 54990, total loss = 0.56, batch loss = 0.29 (231.0 examples/sec; 0.035 sec/batch; 1h:23m:24s remains)
INFO - root - 2022-02-24 19:54:21.356720: step 55000, total loss = 0.55, batch loss = 0.27 (192.4 examples/sec; 0.042 sec/batch; 1h:40m:08s remains)
INFO - root - 2022-02-24 19:54:21.714235: step 55010, total loss = 0.67, batch loss = 0.40 (330.9 examples/sec; 0.024 sec/batch; 0h:58m:12s remains)
INFO - root - 2022-02-24 19:54:22.047946: step 55020, total loss = 0.64, batch loss = 0.36 (299.3 examples/sec; 0.027 sec/batch; 1h:04m:21s remains)
INFO - root - 2022-02-24 19:54:22.506037: step 55030, total loss = 0.56, batch loss = 0.29 (221.8 examples/sec; 0.036 sec/batch; 1h:26m:50s remains)
INFO - root - 2022-02-24 19:54:22.929639: step 55040, total loss = 0.52, batch loss = 0.25 (203.9 examples/sec; 0.039 sec/batch; 1h:34m:27s remains)
INFO - root - 2022-02-24 19:54:23.255991: step 55050, total loss = 0.60, batch loss = 0.32 (251.9 examples/sec; 0.032 sec/batch; 1h:16m:27s remains)
INFO - root - 2022-02-24 19:54:23.541099: step 55060, total loss = 0.69, batch loss = 0.42 (324.2 examples/sec; 0.025 sec/batch; 0h:59m:23s remains)
INFO - root - 2022-02-24 19:54:23.843198: step 55070, total loss = 0.59, batch loss = 0.32 (233.5 examples/sec; 0.034 sec/batch; 1h:22m:28s remains)
INFO - root - 2022-02-24 19:54:24.305706: step 55080, total loss = 0.59, batch loss = 0.32 (247.5 examples/sec; 0.032 sec/batch; 1h:17m:48s remains)
INFO - root - 2022-02-24 19:54:24.716135: step 55090, total loss = 0.54, batch loss = 0.27 (299.7 examples/sec; 0.027 sec/batch; 1h:04m:14s remains)
INFO - root - 2022-02-24 19:54:25.027929: step 55100, total loss = 0.52, batch loss = 0.25 (314.2 examples/sec; 0.025 sec/batch; 1h:01m:16s remains)
INFO - root - 2022-02-24 19:54:25.483068: step 55110, total loss = 0.57, batch loss = 0.30 (230.2 examples/sec; 0.035 sec/batch; 1h:23m:36s remains)
INFO - root - 2022-02-24 19:54:25.775206: step 55120, total loss = 0.59, batch loss = 0.32 (181.9 examples/sec; 0.044 sec/batch; 1h:45m:49s remains)
INFO - root - 2022-02-24 19:54:26.149223: step 55130, total loss = 0.57, batch loss = 0.30 (141.7 examples/sec; 0.056 sec/batch; 2h:15m:50s remains)
INFO - root - 2022-02-24 19:54:26.534437: step 55140, total loss = 0.57, batch loss = 0.30 (275.7 examples/sec; 0.029 sec/batch; 1h:09m:48s remains)
INFO - root - 2022-02-24 19:54:26.947228: step 55150, total loss = 0.55, batch loss = 0.28 (365.3 examples/sec; 0.022 sec/batch; 0h:52m:41s remains)
INFO - root - 2022-02-24 19:54:27.223924: step 55160, total loss = 0.60, batch loss = 0.32 (256.4 examples/sec; 0.031 sec/batch; 1h:15m:03s remains)
INFO - root - 2022-02-24 19:54:27.520753: step 55170, total loss = 0.59, batch loss = 0.32 (310.6 examples/sec; 0.026 sec/batch; 1h:01m:57s remains)
INFO - root - 2022-02-24 19:54:27.863611: step 55180, total loss = 0.60, batch loss = 0.33 (298.7 examples/sec; 0.027 sec/batch; 1h:04m:24s remains)
INFO - root - 2022-02-24 19:54:28.142065: step 55190, total loss = 0.66, batch loss = 0.39 (207.0 examples/sec; 0.039 sec/batch; 1h:32m:56s remains)
INFO - root - 2022-02-24 19:54:28.486067: step 55200, total loss = 0.55, batch loss = 0.27 (173.1 examples/sec; 0.046 sec/batch; 1h:51m:09s remains)
INFO - root - 2022-02-24 19:54:28.932638: step 55210, total loss = 0.66, batch loss = 0.38 (110.7 examples/sec; 0.072 sec/batch; 2h:53m:47s remains)
INFO - root - 2022-02-24 19:54:29.273617: step 55220, total loss = 0.59, batch loss = 0.31 (274.3 examples/sec; 0.029 sec/batch; 1h:10m:08s remains)
INFO - root - 2022-02-24 19:54:29.617473: step 55230, total loss = 0.54, batch loss = 0.27 (182.5 examples/sec; 0.044 sec/batch; 1h:45m:23s remains)
INFO - root - 2022-02-24 19:54:29.890970: step 55240, total loss = 0.54, batch loss = 0.27 (254.1 examples/sec; 0.031 sec/batch; 1h:15m:42s remains)
INFO - root - 2022-02-24 19:54:30.263798: step 55250, total loss = 0.54, batch loss = 0.27 (250.9 examples/sec; 0.032 sec/batch; 1h:16m:39s remains)
INFO - root - 2022-02-24 19:54:30.703687: step 55260, total loss = 0.58, batch loss = 0.31 (384.4 examples/sec; 0.021 sec/batch; 0h:50m:01s remains)
INFO - root - 2022-02-24 19:54:31.109359: step 55270, total loss = 0.52, batch loss = 0.25 (212.3 examples/sec; 0.038 sec/batch; 1h:30m:34s remains)
INFO - root - 2022-02-24 19:54:31.443309: step 55280, total loss = 0.68, batch loss = 0.40 (304.9 examples/sec; 0.026 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 19:54:31.737164: step 55290, total loss = 0.59, batch loss = 0.32 (199.8 examples/sec; 0.040 sec/batch; 1h:36m:15s remains)
INFO - root - 2022-02-24 19:54:32.086115: step 55300, total loss = 0.71, batch loss = 0.43 (336.1 examples/sec; 0.024 sec/batch; 0h:57m:12s remains)
INFO - root - 2022-02-24 19:54:32.543527: step 55310, total loss = 0.51, batch loss = 0.24 (314.7 examples/sec; 0.025 sec/batch; 1h:01m:04s remains)
INFO - root - 2022-02-24 19:54:33.069637: step 55320, total loss = 0.49, batch loss = 0.21 (197.6 examples/sec; 0.040 sec/batch; 1h:37m:17s remains)
INFO - root - 2022-02-24 19:54:33.462528: step 55330, total loss = 0.61, batch loss = 0.33 (205.2 examples/sec; 0.039 sec/batch; 1h:33m:40s remains)
INFO - root - 2022-02-24 19:54:33.883356: step 55340, total loss = 0.73, batch loss = 0.46 (86.6 examples/sec; 0.092 sec/batch; 3h:42m:00s remains)
INFO - root - 2022-02-24 19:54:34.417111: step 55350, total loss = 0.69, batch loss = 0.42 (324.7 examples/sec; 0.025 sec/batch; 0h:59m:11s remains)
INFO - root - 2022-02-24 19:54:35.009962: step 55360, total loss = 0.57, batch loss = 0.29 (129.5 examples/sec; 0.062 sec/batch; 2h:28m:21s remains)
INFO - root - 2022-02-24 19:54:35.855550: step 55370, total loss = 0.46, batch loss = 0.18 (285.8 examples/sec; 0.028 sec/batch; 1h:07m:13s remains)
INFO - root - 2022-02-24 19:54:36.165494: step 55380, total loss = 0.54, batch loss = 0.26 (215.0 examples/sec; 0.037 sec/batch; 1h:29m:23s remains)
INFO - root - 2022-02-24 19:54:36.542696: step 55390, total loss = 0.51, batch loss = 0.24 (226.2 examples/sec; 0.035 sec/batch; 1h:24m:55s remains)
INFO - root - 2022-02-24 19:54:36.998398: step 55400, total loss = 0.57, batch loss = 0.30 (123.4 examples/sec; 0.065 sec/batch; 2h:35m:42s remains)
INFO - root - 2022-02-24 19:54:38.073073: step 55410, total loss = 0.62, batch loss = 0.35 (346.5 examples/sec; 0.023 sec/batch; 0h:55m:26s remains)
INFO - root - 2022-02-24 19:54:38.298810: step 55420, total loss = 0.71, batch loss = 0.43 (338.4 examples/sec; 0.024 sec/batch; 0h:56m:45s remains)
INFO - root - 2022-02-24 19:54:38.540801: step 55430, total loss = 0.64, batch loss = 0.37 (334.4 examples/sec; 0.024 sec/batch; 0h:57m:27s remains)
INFO - root - 2022-02-24 19:54:38.778062: step 55440, total loss = 0.68, batch loss = 0.41 (336.9 examples/sec; 0.024 sec/batch; 0h:57m:01s remains)
INFO - root - 2022-02-24 19:54:39.166735: step 55450, total loss = 0.58, batch loss = 0.31 (342.9 examples/sec; 0.023 sec/batch; 0h:56m:01s remains)
INFO - root - 2022-02-24 19:54:39.490905: step 55460, total loss = 0.69, batch loss = 0.42 (176.7 examples/sec; 0.045 sec/batch; 1h:48m:42s remains)
INFO - root - 2022-02-24 19:54:39.848614: step 55470, total loss = 0.59, batch loss = 0.32 (171.4 examples/sec; 0.047 sec/batch; 1h:52m:01s remains)
INFO - root - 2022-02-24 19:54:40.254172: step 55480, total loss = 0.68, batch loss = 0.40 (207.9 examples/sec; 0.038 sec/batch; 1h:32m:22s remains)
INFO - root - 2022-02-24 19:54:40.785887: step 55490, total loss = 0.53, batch loss = 0.26 (250.5 examples/sec; 0.032 sec/batch; 1h:16m:38s remains)
INFO - root - 2022-02-24 19:54:41.566309: step 55500, total loss = 0.70, batch loss = 0.42 (84.0 examples/sec; 0.095 sec/batch; 3h:48m:34s remains)
INFO - root - 2022-02-24 19:54:42.007516: step 55510, total loss = 0.62, batch loss = 0.34 (157.4 examples/sec; 0.051 sec/batch; 2h:01m:58s remains)
INFO - root - 2022-02-24 19:54:42.552647: step 55520, total loss = 0.55, batch loss = 0.28 (94.4 examples/sec; 0.085 sec/batch; 3h:23m:23s remains)
INFO - root - 2022-02-24 19:54:42.896507: step 55530, total loss = 0.61, batch loss = 0.34 (233.1 examples/sec; 0.034 sec/batch; 1h:22m:20s remains)
INFO - root - 2022-02-24 19:54:43.291017: step 55540, total loss = 0.49, batch loss = 0.22 (195.6 examples/sec; 0.041 sec/batch; 1h:38m:08s remains)
INFO - root - 2022-02-24 19:54:43.711038: step 55550, total loss = 0.52, batch loss = 0.24 (344.4 examples/sec; 0.023 sec/batch; 0h:55m:43s remains)
INFO - root - 2022-02-24 19:54:44.182808: step 55560, total loss = 0.51, batch loss = 0.24 (193.9 examples/sec; 0.041 sec/batch; 1h:38m:57s remains)
INFO - root - 2022-02-24 19:54:44.556220: step 55570, total loss = 0.60, batch loss = 0.33 (330.7 examples/sec; 0.024 sec/batch; 0h:58m:01s remains)
INFO - root - 2022-02-24 19:54:44.981107: step 55580, total loss = 0.61, batch loss = 0.33 (344.1 examples/sec; 0.023 sec/batch; 0h:55m:46s remains)
INFO - root - 2022-02-24 19:54:45.391766: step 55590, total loss = 0.66, batch loss = 0.39 (131.3 examples/sec; 0.061 sec/batch; 2h:26m:07s remains)
INFO - root - 2022-02-24 19:54:45.942163: step 55600, total loss = 0.54, batch loss = 0.27 (62.0 examples/sec; 0.129 sec/batch; 5h:09m:35s remains)
INFO - root - 2022-02-24 19:54:46.507311: step 55610, total loss = 0.67, batch loss = 0.39 (271.4 examples/sec; 0.029 sec/batch; 1h:10m:41s remains)
INFO - root - 2022-02-24 19:54:47.081421: step 55620, total loss = 0.60, batch loss = 0.33 (318.2 examples/sec; 0.025 sec/batch; 1h:00m:17s remains)
INFO - root - 2022-02-24 19:54:47.662089: step 55630, total loss = 0.57, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 6h:18m:13s remains)
INFO - root - 2022-02-24 19:54:48.112135: step 55640, total loss = 0.58, batch loss = 0.30 (360.9 examples/sec; 0.022 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 19:54:48.605156: step 55650, total loss = 0.58, batch loss = 0.31 (104.7 examples/sec; 0.076 sec/batch; 3h:03m:08s remains)
INFO - root - 2022-02-24 19:54:49.148121: step 55660, total loss = 0.56, batch loss = 0.28 (208.0 examples/sec; 0.038 sec/batch; 1h:32m:12s remains)
INFO - root - 2022-02-24 19:54:49.757998: step 55670, total loss = 0.52, batch loss = 0.25 (248.2 examples/sec; 0.032 sec/batch; 1h:17m:15s remains)
INFO - root - 2022-02-24 19:54:50.298827: step 55680, total loss = 0.62, batch loss = 0.35 (78.0 examples/sec; 0.103 sec/batch; 4h:05m:53s remains)
INFO - root - 2022-02-24 19:54:50.904903: step 55690, total loss = 0.61, batch loss = 0.33 (83.9 examples/sec; 0.095 sec/batch; 3h:48m:29s remains)
INFO - root - 2022-02-24 19:54:51.351581: step 55700, total loss = 0.49, batch loss = 0.22 (243.9 examples/sec; 0.033 sec/batch; 1h:18m:35s remains)
INFO - root - 2022-02-24 19:54:51.750906: step 55710, total loss = 0.58, batch loss = 0.30 (256.2 examples/sec; 0.031 sec/batch; 1h:14m:49s remains)
INFO - root - 2022-02-24 19:54:52.319146: step 55720, total loss = 0.56, batch loss = 0.29 (124.0 examples/sec; 0.065 sec/batch; 2h:34m:35s remains)
INFO - root - 2022-02-24 19:54:52.734617: step 55730, total loss = 0.57, batch loss = 0.30 (317.4 examples/sec; 0.025 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 19:54:53.212058: step 55740, total loss = 0.50, batch loss = 0.23 (315.8 examples/sec; 0.025 sec/batch; 1h:00m:41s remains)
INFO - root - 2022-02-24 19:54:53.616280: step 55750, total loss = 0.66, batch loss = 0.38 (379.6 examples/sec; 0.021 sec/batch; 0h:50m:29s remains)
INFO - root - 2022-02-24 19:54:54.079209: step 55760, total loss = 0.61, batch loss = 0.33 (252.1 examples/sec; 0.032 sec/batch; 1h:16m:00s remains)
INFO - root - 2022-02-24 19:54:54.527018: step 55770, total loss = 0.51, batch loss = 0.24 (235.7 examples/sec; 0.034 sec/batch; 1h:21m:18s remains)
INFO - root - 2022-02-24 19:54:54.916086: step 55780, total loss = 0.57, batch loss = 0.30 (302.1 examples/sec; 0.026 sec/batch; 1h:03m:25s remains)
INFO - root - 2022-02-24 19:54:55.379793: step 55790, total loss = 0.55, batch loss = 0.28 (199.0 examples/sec; 0.040 sec/batch; 1h:36m:16s remains)
INFO - root - 2022-02-24 19:54:55.749412: step 55800, total loss = 0.71, batch loss = 0.44 (179.4 examples/sec; 0.045 sec/batch; 1h:46m:46s remains)
INFO - root - 2022-02-24 19:54:56.217061: step 55810, total loss = 0.51, batch loss = 0.23 (183.1 examples/sec; 0.044 sec/batch; 1h:44m:38s remains)
INFO - root - 2022-02-24 19:54:56.687574: step 55820, total loss = 0.55, batch loss = 0.28 (200.1 examples/sec; 0.040 sec/batch; 1h:35m:43s remains)
INFO - root - 2022-02-24 19:54:57.099932: step 55830, total loss = 0.56, batch loss = 0.28 (138.4 examples/sec; 0.058 sec/batch; 2h:18m:27s remains)
INFO - root - 2022-02-24 19:54:57.505465: step 55840, total loss = 0.52, batch loss = 0.25 (299.5 examples/sec; 0.027 sec/batch; 1h:03m:57s remains)
INFO - root - 2022-02-24 19:54:57.956658: step 55850, total loss = 0.80, batch loss = 0.53 (165.4 examples/sec; 0.048 sec/batch; 1h:55m:47s remains)
INFO - root - 2022-02-24 19:54:58.536129: step 55860, total loss = 0.64, batch loss = 0.37 (116.4 examples/sec; 0.069 sec/batch; 2h:44m:35s remains)
INFO - root - 2022-02-24 19:54:59.020609: step 55870, total loss = 0.53, batch loss = 0.25 (360.4 examples/sec; 0.022 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 19:54:59.470063: step 55880, total loss = 0.57, batch loss = 0.29 (105.3 examples/sec; 0.076 sec/batch; 3h:01m:50s remains)
INFO - root - 2022-02-24 19:54:59.878466: step 55890, total loss = 0.63, batch loss = 0.35 (214.7 examples/sec; 0.037 sec/batch; 1h:29m:09s remains)
INFO - root - 2022-02-24 19:55:00.400581: step 55900, total loss = 0.50, batch loss = 0.22 (89.7 examples/sec; 0.089 sec/batch; 3h:33m:28s remains)
INFO - root - 2022-02-24 19:55:01.064729: step 55910, total loss = 0.57, batch loss = 0.30 (163.4 examples/sec; 0.049 sec/batch; 1h:57m:09s remains)
INFO - root - 2022-02-24 19:55:01.510701: step 55920, total loss = 0.75, batch loss = 0.48 (191.9 examples/sec; 0.042 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 19:55:02.013074: step 55930, total loss = 0.50, batch loss = 0.22 (187.5 examples/sec; 0.043 sec/batch; 1h:42m:04s remains)
INFO - root - 2022-02-24 19:55:02.562319: step 55940, total loss = 0.51, batch loss = 0.24 (115.7 examples/sec; 0.069 sec/batch; 2h:45m:23s remains)
INFO - root - 2022-02-24 19:55:03.010775: step 55950, total loss = 0.64, batch loss = 0.37 (290.9 examples/sec; 0.028 sec/batch; 1h:05m:48s remains)
INFO - root - 2022-02-24 19:55:03.388544: step 55960, total loss = 0.51, batch loss = 0.24 (341.7 examples/sec; 0.023 sec/batch; 0h:56m:00s remains)
INFO - root - 2022-02-24 19:55:03.933235: step 55970, total loss = 0.57, batch loss = 0.29 (122.0 examples/sec; 0.066 sec/batch; 2h:36m:50s remains)
INFO - root - 2022-02-24 19:55:04.440806: step 55980, total loss = 0.67, batch loss = 0.40 (242.0 examples/sec; 0.033 sec/batch; 1h:19m:04s remains)
INFO - root - 2022-02-24 19:55:04.924638: step 55990, total loss = 0.52, batch loss = 0.24 (281.1 examples/sec; 0.028 sec/batch; 1h:08m:03s remains)
INFO - root - 2022-02-24 19:55:05.323102: step 56000, total loss = 0.62, batch loss = 0.35 (294.9 examples/sec; 0.027 sec/batch; 1h:04m:53s remains)
INFO - root - 2022-02-24 19:55:05.898252: step 56010, total loss = 0.53, batch loss = 0.25 (268.0 examples/sec; 0.030 sec/batch; 1h:11m:23s remains)
INFO - root - 2022-02-24 19:55:06.319164: step 56020, total loss = 0.51, batch loss = 0.24 (226.8 examples/sec; 0.035 sec/batch; 1h:24m:20s remains)
INFO - root - 2022-02-24 19:55:06.720680: step 56030, total loss = 0.48, batch loss = 0.21 (135.7 examples/sec; 0.059 sec/batch; 2h:20m:55s remains)
INFO - root - 2022-02-24 19:55:07.133247: step 56040, total loss = 0.74, batch loss = 0.47 (177.4 examples/sec; 0.045 sec/batch; 1h:47m:49s remains)
INFO - root - 2022-02-24 19:55:07.589551: step 56050, total loss = 0.50, batch loss = 0.22 (294.3 examples/sec; 0.027 sec/batch; 1h:04m:59s remains)
INFO - root - 2022-02-24 19:55:08.047477: step 56060, total loss = 0.56, batch loss = 0.29 (223.2 examples/sec; 0.036 sec/batch; 1h:25m:41s remains)
INFO - root - 2022-02-24 19:55:08.561305: step 56070, total loss = 0.56, batch loss = 0.29 (96.4 examples/sec; 0.083 sec/batch; 3h:18m:23s remains)
INFO - root - 2022-02-24 19:55:08.957771: step 56080, total loss = 0.55, batch loss = 0.28 (296.6 examples/sec; 0.027 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 19:55:09.407858: step 56090, total loss = 0.62, batch loss = 0.35 (208.6 examples/sec; 0.038 sec/batch; 1h:31m:39s remains)
INFO - root - 2022-02-24 19:55:09.974069: step 56100, total loss = 0.68, batch loss = 0.41 (76.5 examples/sec; 0.105 sec/batch; 4h:09m:59s remains)
INFO - root - 2022-02-24 19:55:10.549268: step 56110, total loss = 0.58, batch loss = 0.31 (293.4 examples/sec; 0.027 sec/batch; 1h:05m:10s remains)
INFO - root - 2022-02-24 19:55:11.046791: step 56120, total loss = 0.58, batch loss = 0.31 (304.0 examples/sec; 0.026 sec/batch; 1h:02m:53s remains)
INFO - root - 2022-02-24 19:55:11.409435: step 56130, total loss = 0.58, batch loss = 0.31 (133.9 examples/sec; 0.060 sec/batch; 2h:22m:48s remains)
INFO - root - 2022-02-24 19:55:11.936328: step 56140, total loss = 0.60, batch loss = 0.33 (276.3 examples/sec; 0.029 sec/batch; 1h:09m:10s remains)
INFO - root - 2022-02-24 19:55:12.410912: step 56150, total loss = 0.55, batch loss = 0.28 (165.7 examples/sec; 0.048 sec/batch; 1h:55m:19s remains)
INFO - root - 2022-02-24 19:55:12.935881: step 56160, total loss = 0.51, batch loss = 0.24 (161.4 examples/sec; 0.050 sec/batch; 1h:58m:22s remains)
INFO - root - 2022-02-24 19:55:13.346277: step 56170, total loss = 0.56, batch loss = 0.29 (340.2 examples/sec; 0.024 sec/batch; 0h:56m:10s remains)
INFO - root - 2022-02-24 19:55:13.693998: step 56180, total loss = 0.55, batch loss = 0.28 (143.6 examples/sec; 0.056 sec/batch; 2h:13m:06s remains)
INFO - root - 2022-02-24 19:55:14.120703: step 56190, total loss = 0.55, batch loss = 0.28 (116.9 examples/sec; 0.068 sec/batch; 2h:43m:26s remains)
INFO - root - 2022-02-24 19:55:14.600965: step 56200, total loss = 0.66, batch loss = 0.38 (196.6 examples/sec; 0.041 sec/batch; 1h:37m:12s remains)
INFO - root - 2022-02-24 19:55:15.134415: step 56210, total loss = 0.67, batch loss = 0.40 (313.6 examples/sec; 0.026 sec/batch; 1h:00m:54s remains)
INFO - root - 2022-02-24 19:55:15.496366: step 56220, total loss = 0.61, batch loss = 0.34 (296.0 examples/sec; 0.027 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 19:55:15.905997: step 56230, total loss = 0.48, batch loss = 0.21 (259.6 examples/sec; 0.031 sec/batch; 1h:13m:34s remains)
INFO - root - 2022-02-24 19:55:16.464765: step 56240, total loss = 0.58, batch loss = 0.31 (90.1 examples/sec; 0.089 sec/batch; 3h:31m:54s remains)
INFO - root - 2022-02-24 19:55:16.906938: step 56250, total loss = 0.57, batch loss = 0.30 (341.5 examples/sec; 0.023 sec/batch; 0h:55m:55s remains)
INFO - root - 2022-02-24 19:55:17.431378: step 56260, total loss = 0.59, batch loss = 0.32 (248.8 examples/sec; 0.032 sec/batch; 1h:16m:45s remains)
INFO - root - 2022-02-24 19:55:17.790086: step 56270, total loss = 0.58, batch loss = 0.31 (336.2 examples/sec; 0.024 sec/batch; 0h:56m:47s remains)
INFO - root - 2022-02-24 19:55:18.273167: step 56280, total loss = 0.58, batch loss = 0.31 (112.7 examples/sec; 0.071 sec/batch; 2h:49m:24s remains)
INFO - root - 2022-02-24 19:55:18.788159: step 56290, total loss = 0.63, batch loss = 0.36 (204.1 examples/sec; 0.039 sec/batch; 1h:33m:34s remains)
INFO - root - 2022-02-24 19:55:19.285669: step 56300, total loss = 0.69, batch loss = 0.42 (310.8 examples/sec; 0.026 sec/batch; 1h:01m:25s remains)
INFO - root - 2022-02-24 19:55:19.685631: step 56310, total loss = 0.48, batch loss = 0.21 (312.2 examples/sec; 0.026 sec/batch; 1h:01m:08s remains)
INFO - root - 2022-02-24 19:55:20.204537: step 56320, total loss = 0.59, batch loss = 0.31 (255.4 examples/sec; 0.031 sec/batch; 1h:14m:44s remains)
INFO - root - 2022-02-24 19:55:20.567716: step 56330, total loss = 0.59, batch loss = 0.31 (364.2 examples/sec; 0.022 sec/batch; 0h:52m:24s remains)
INFO - root - 2022-02-24 19:55:20.997201: step 56340, total loss = 0.62, batch loss = 0.34 (283.0 examples/sec; 0.028 sec/batch; 1h:07m:27s remains)
INFO - root - 2022-02-24 19:55:21.394402: step 56350, total loss = 0.72, batch loss = 0.45 (345.3 examples/sec; 0.023 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 19:55:21.972091: step 56360, total loss = 0.57, batch loss = 0.29 (113.7 examples/sec; 0.070 sec/batch; 2h:47m:51s remains)
INFO - root - 2022-02-24 19:55:22.349074: step 56370, total loss = 0.58, batch loss = 0.31 (325.3 examples/sec; 0.025 sec/batch; 0h:58m:39s remains)
INFO - root - 2022-02-24 19:55:22.725051: step 56380, total loss = 0.59, batch loss = 0.32 (248.9 examples/sec; 0.032 sec/batch; 1h:16m:40s remains)
INFO - root - 2022-02-24 19:55:23.521398: step 56390, total loss = 0.53, batch loss = 0.26 (343.6 examples/sec; 0.023 sec/batch; 0h:55m:31s remains)
INFO - root - 2022-02-24 19:55:23.978666: step 56400, total loss = 0.58, batch loss = 0.30 (236.5 examples/sec; 0.034 sec/batch; 1h:20m:39s remains)
INFO - root - 2022-02-24 19:55:24.412483: step 56410, total loss = 0.63, batch loss = 0.36 (321.2 examples/sec; 0.025 sec/batch; 0h:59m:23s remains)
INFO - root - 2022-02-24 19:55:24.786296: step 56420, total loss = 0.55, batch loss = 0.28 (280.9 examples/sec; 0.028 sec/batch; 1h:07m:54s remains)
INFO - root - 2022-02-24 19:55:25.456772: step 56430, total loss = 0.60, batch loss = 0.32 (251.8 examples/sec; 0.032 sec/batch; 1h:15m:46s remains)
INFO - root - 2022-02-24 19:55:25.860007: step 56440, total loss = 0.52, batch loss = 0.25 (139.7 examples/sec; 0.057 sec/batch; 2h:16m:32s remains)
INFO - root - 2022-02-24 19:55:26.367133: step 56450, total loss = 0.61, batch loss = 0.34 (108.7 examples/sec; 0.074 sec/batch; 2h:55m:29s remains)
INFO - root - 2022-02-24 19:55:26.849712: step 56460, total loss = 0.55, batch loss = 0.28 (157.7 examples/sec; 0.051 sec/batch; 2h:00m:57s remains)
INFO - root - 2022-02-24 19:55:27.385226: step 56470, total loss = 0.53, batch loss = 0.25 (64.3 examples/sec; 0.124 sec/batch; 4h:56m:24s remains)
INFO - root - 2022-02-24 19:55:27.842839: step 56480, total loss = 0.62, batch loss = 0.35 (284.4 examples/sec; 0.028 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 19:55:28.282641: step 56490, total loss = 0.49, batch loss = 0.22 (298.5 examples/sec; 0.027 sec/batch; 1h:03m:53s remains)
INFO - root - 2022-02-24 19:55:28.885826: step 56500, total loss = 0.65, batch loss = 0.38 (144.8 examples/sec; 0.055 sec/batch; 2h:11m:40s remains)
INFO - root - 2022-02-24 19:55:29.292261: step 56510, total loss = 0.66, batch loss = 0.39 (136.4 examples/sec; 0.059 sec/batch; 2h:19m:47s remains)
INFO - root - 2022-02-24 19:55:29.678744: step 56520, total loss = 0.71, batch loss = 0.44 (95.3 examples/sec; 0.084 sec/batch; 3h:20m:01s remains)
INFO - root - 2022-02-24 19:55:30.238318: step 56530, total loss = 0.46, batch loss = 0.19 (335.2 examples/sec; 0.024 sec/batch; 0h:56m:52s remains)
INFO - root - 2022-02-24 19:55:30.826009: step 56540, total loss = 0.55, batch loss = 0.27 (127.7 examples/sec; 0.063 sec/batch; 2h:29m:17s remains)
INFO - root - 2022-02-24 19:55:31.292662: step 56550, total loss = 0.66, batch loss = 0.39 (214.3 examples/sec; 0.037 sec/batch; 1h:28m:55s remains)
INFO - root - 2022-02-24 19:55:31.975514: step 56560, total loss = 0.51, batch loss = 0.24 (137.7 examples/sec; 0.058 sec/batch; 2h:18m:26s remains)
INFO - root - 2022-02-24 19:55:32.429238: step 56570, total loss = 0.53, batch loss = 0.26 (313.7 examples/sec; 0.026 sec/batch; 1h:00m:45s remains)
INFO - root - 2022-02-24 19:55:32.792899: step 56580, total loss = 0.52, batch loss = 0.25 (338.5 examples/sec; 0.024 sec/batch; 0h:56m:17s remains)
INFO - root - 2022-02-24 19:55:33.316539: step 56590, total loss = 0.55, batch loss = 0.27 (48.6 examples/sec; 0.165 sec/batch; 6h:32m:04s remains)
INFO - root - 2022-02-24 19:55:33.854034: step 56600, total loss = 0.55, batch loss = 0.28 (252.4 examples/sec; 0.032 sec/batch; 1h:15m:30s remains)
INFO - root - 2022-02-24 19:55:34.386355: step 56610, total loss = 0.64, batch loss = 0.37 (289.9 examples/sec; 0.028 sec/batch; 1h:05m:42s remains)
INFO - root - 2022-02-24 19:55:34.867351: step 56620, total loss = 0.63, batch loss = 0.35 (229.4 examples/sec; 0.035 sec/batch; 1h:23m:02s remains)
INFO - root - 2022-02-24 19:55:35.312932: step 56630, total loss = 0.67, batch loss = 0.39 (217.8 examples/sec; 0.037 sec/batch; 1h:27m:26s remains)
INFO - root - 2022-02-24 19:55:35.838306: step 56640, total loss = 0.65, batch loss = 0.38 (218.4 examples/sec; 0.037 sec/batch; 1h:27m:13s remains)
INFO - root - 2022-02-24 19:55:36.408785: step 56650, total loss = 0.67, batch loss = 0.40 (302.3 examples/sec; 0.026 sec/batch; 1h:03m:00s remains)
INFO - root - 2022-02-24 19:55:36.832861: step 56660, total loss = 0.49, batch loss = 0.22 (226.5 examples/sec; 0.035 sec/batch; 1h:24m:05s remains)
INFO - root - 2022-02-24 19:55:37.257891: step 56670, total loss = 0.46, batch loss = 0.19 (141.5 examples/sec; 0.057 sec/batch; 2h:14m:34s remains)
INFO - root - 2022-02-24 19:55:37.780099: step 56680, total loss = 0.44, batch loss = 0.17 (280.3 examples/sec; 0.029 sec/batch; 1h:07m:56s remains)
INFO - root - 2022-02-24 19:55:38.167678: step 56690, total loss = 0.57, batch loss = 0.30 (112.9 examples/sec; 0.071 sec/batch; 2h:48m:41s remains)
INFO - root - 2022-02-24 19:55:38.579905: step 56700, total loss = 0.62, batch loss = 0.35 (219.5 examples/sec; 0.036 sec/batch; 1h:26m:44s remains)
INFO - root - 2022-02-24 19:55:39.446942: step 56710, total loss = 0.52, batch loss = 0.24 (76.5 examples/sec; 0.105 sec/batch; 4h:09m:00s remains)
INFO - root - 2022-02-24 19:55:39.918018: step 56720, total loss = 0.66, batch loss = 0.39 (173.0 examples/sec; 0.046 sec/batch; 1h:50m:01s remains)
INFO - root - 2022-02-24 19:55:40.266355: step 56730, total loss = 0.68, batch loss = 0.41 (257.0 examples/sec; 0.031 sec/batch; 1h:14m:04s remains)
INFO - root - 2022-02-24 19:55:40.614073: step 56740, total loss = 0.45, batch loss = 0.18 (252.5 examples/sec; 0.032 sec/batch; 1h:15m:23s remains)
INFO - root - 2022-02-24 19:55:40.951531: step 56750, total loss = 0.54, batch loss = 0.27 (187.2 examples/sec; 0.043 sec/batch; 1h:41m:39s remains)
INFO - root - 2022-02-24 19:55:41.298315: step 56760, total loss = 0.50, batch loss = 0.22 (184.0 examples/sec; 0.043 sec/batch; 1h:43m:25s remains)
INFO - root - 2022-02-24 19:55:41.672825: step 56770, total loss = 0.59, batch loss = 0.31 (129.8 examples/sec; 0.062 sec/batch; 2h:26m:38s remains)
INFO - root - 2022-02-24 19:55:42.080671: step 56780, total loss = 0.67, batch loss = 0.40 (226.5 examples/sec; 0.035 sec/batch; 1h:24m:00s remains)
INFO - root - 2022-02-24 19:55:42.396348: step 56790, total loss = 0.60, batch loss = 0.32 (238.3 examples/sec; 0.034 sec/batch; 1h:19m:51s remains)
INFO - root - 2022-02-24 19:55:42.760435: step 56800, total loss = 0.55, batch loss = 0.28 (330.7 examples/sec; 0.024 sec/batch; 0h:57m:31s remains)
INFO - root - 2022-02-24 19:55:43.095685: step 56810, total loss = 0.50, batch loss = 0.23 (319.5 examples/sec; 0.025 sec/batch; 0h:59m:32s remains)
INFO - root - 2022-02-24 19:55:43.415638: step 56820, total loss = 0.59, batch loss = 0.32 (152.6 examples/sec; 0.052 sec/batch; 2h:04m:38s remains)
INFO - root - 2022-02-24 19:55:43.895850: step 56830, total loss = 0.56, batch loss = 0.28 (120.9 examples/sec; 0.066 sec/batch; 2h:37m:20s remains)
INFO - root - 2022-02-24 19:55:44.317741: step 56840, total loss = 0.63, batch loss = 0.35 (184.2 examples/sec; 0.043 sec/batch; 1h:43m:15s remains)
INFO - root - 2022-02-24 19:55:44.661654: step 56850, total loss = 0.59, batch loss = 0.32 (349.7 examples/sec; 0.023 sec/batch; 0h:54m:23s remains)
INFO - root - 2022-02-24 19:55:44.977570: step 56860, total loss = 0.74, batch loss = 0.46 (341.6 examples/sec; 0.023 sec/batch; 0h:55m:40s remains)
INFO - root - 2022-02-24 19:55:45.310848: step 56870, total loss = 0.59, batch loss = 0.32 (322.0 examples/sec; 0.025 sec/batch; 0h:59m:03s remains)
INFO - root - 2022-02-24 19:55:45.721777: step 56880, total loss = 0.55, batch loss = 0.28 (287.7 examples/sec; 0.028 sec/batch; 1h:06m:05s remains)
INFO - root - 2022-02-24 19:55:46.152211: step 56890, total loss = 0.58, batch loss = 0.31 (353.6 examples/sec; 0.023 sec/batch; 0h:53m:46s remains)
INFO - root - 2022-02-24 19:55:46.461200: step 56900, total loss = 0.54, batch loss = 0.27 (336.2 examples/sec; 0.024 sec/batch; 0h:56m:33s remains)
INFO - root - 2022-02-24 19:55:46.939786: step 56910, total loss = 0.66, batch loss = 0.39 (283.0 examples/sec; 0.028 sec/batch; 1h:07m:11s remains)
INFO - root - 2022-02-24 19:55:47.269175: step 56920, total loss = 0.62, batch loss = 0.35 (326.6 examples/sec; 0.024 sec/batch; 0h:58m:12s remains)
INFO - root - 2022-02-24 19:55:47.609257: step 56930, total loss = 0.57, batch loss = 0.30 (110.0 examples/sec; 0.073 sec/batch; 2h:52m:50s remains)
INFO - root - 2022-02-24 19:55:48.042092: step 56940, total loss = 0.57, batch loss = 0.30 (302.3 examples/sec; 0.026 sec/batch; 1h:02m:52s remains)
INFO - root - 2022-02-24 19:55:48.375631: step 56950, total loss = 0.57, batch loss = 0.30 (294.9 examples/sec; 0.027 sec/batch; 1h:04m:27s remains)
INFO - root - 2022-02-24 19:55:48.736289: step 56960, total loss = 0.52, batch loss = 0.24 (184.2 examples/sec; 0.043 sec/batch; 1h:43m:11s remains)
INFO - root - 2022-02-24 19:55:49.080677: step 56970, total loss = 0.59, batch loss = 0.32 (280.0 examples/sec; 0.029 sec/batch; 1h:07m:52s remains)
INFO - root - 2022-02-24 19:55:49.449907: step 56980, total loss = 0.53, batch loss = 0.25 (323.8 examples/sec; 0.025 sec/batch; 0h:58m:41s remains)
INFO - root - 2022-02-24 19:55:49.861933: step 56990, total loss = 0.59, batch loss = 0.32 (360.4 examples/sec; 0.022 sec/batch; 0h:52m:43s remains)
INFO - root - 2022-02-24 19:55:50.270857: step 57000, total loss = 0.60, batch loss = 0.33 (226.3 examples/sec; 0.035 sec/batch; 1h:23m:56s remains)
INFO - root - 2022-02-24 19:55:50.623691: step 57010, total loss = 0.58, batch loss = 0.31 (228.4 examples/sec; 0.035 sec/batch; 1h:23m:11s remains)
INFO - root - 2022-02-24 19:55:50.917848: step 57020, total loss = 0.48, batch loss = 0.21 (289.7 examples/sec; 0.028 sec/batch; 1h:05m:34s remains)
INFO - root - 2022-02-24 19:55:51.182830: step 57030, total loss = 0.54, batch loss = 0.26 (164.1 examples/sec; 0.049 sec/batch; 1h:55m:44s remains)
INFO - root - 2022-02-24 19:55:51.560264: step 57040, total loss = 0.57, batch loss = 0.30 (248.3 examples/sec; 0.032 sec/batch; 1h:16m:30s remains)
INFO - root - 2022-02-24 19:55:51.978108: step 57050, total loss = 0.60, batch loss = 0.33 (199.7 examples/sec; 0.040 sec/batch; 1h:35m:07s remains)
INFO - root - 2022-02-24 19:55:52.385253: step 57060, total loss = 0.67, batch loss = 0.40 (171.5 examples/sec; 0.047 sec/batch; 1h:50m:45s remains)
INFO - root - 2022-02-24 19:55:52.664051: step 57070, total loss = 0.62, batch loss = 0.35 (335.3 examples/sec; 0.024 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 19:55:53.019978: step 57080, total loss = 0.69, batch loss = 0.42 (143.1 examples/sec; 0.056 sec/batch; 2h:12m:44s remains)
INFO - root - 2022-02-24 19:55:53.283624: step 57090, total loss = 0.65, batch loss = 0.38 (330.9 examples/sec; 0.024 sec/batch; 0h:57m:23s remains)
INFO - root - 2022-02-24 19:55:53.670288: step 57100, total loss = 0.69, batch loss = 0.42 (124.6 examples/sec; 0.064 sec/batch; 2h:32m:25s remains)
INFO - root - 2022-02-24 19:55:54.230666: step 57110, total loss = 0.55, batch loss = 0.28 (230.9 examples/sec; 0.035 sec/batch; 1h:22m:14s remains)
INFO - root - 2022-02-24 19:55:54.701783: step 57120, total loss = 0.48, batch loss = 0.21 (119.5 examples/sec; 0.067 sec/batch; 2h:38m:49s remains)
INFO - root - 2022-02-24 19:55:55.110861: step 57130, total loss = 0.48, batch loss = 0.21 (206.9 examples/sec; 0.039 sec/batch; 1h:31m:44s remains)
INFO - root - 2022-02-24 19:55:55.418118: step 57140, total loss = 0.61, batch loss = 0.34 (201.9 examples/sec; 0.040 sec/batch; 1h:34m:00s remains)
INFO - root - 2022-02-24 19:55:55.757315: step 57150, total loss = 0.64, batch loss = 0.37 (263.2 examples/sec; 0.030 sec/batch; 1h:12m:06s remains)
INFO - root - 2022-02-24 19:55:56.211451: step 57160, total loss = 0.57, batch loss = 0.30 (205.2 examples/sec; 0.039 sec/batch; 1h:32m:30s remains)
INFO - root - 2022-02-24 19:55:56.569587: step 57170, total loss = 0.61, batch loss = 0.34 (226.7 examples/sec; 0.035 sec/batch; 1h:23m:42s remains)
INFO - root - 2022-02-24 19:55:57.092370: step 57180, total loss = 0.57, batch loss = 0.29 (208.6 examples/sec; 0.038 sec/batch; 1h:30m:57s remains)
INFO - root - 2022-02-24 19:55:57.585120: step 57190, total loss = 0.54, batch loss = 0.26 (82.5 examples/sec; 0.097 sec/batch; 3h:50m:06s remains)
INFO - root - 2022-02-24 19:55:58.088078: step 57200, total loss = 0.46, batch loss = 0.18 (81.7 examples/sec; 0.098 sec/batch; 3h:52m:09s remains)
INFO - root - 2022-02-24 19:55:58.585058: step 57210, total loss = 0.64, batch loss = 0.37 (249.6 examples/sec; 0.032 sec/batch; 1h:16m:00s remains)
INFO - root - 2022-02-24 19:55:59.070813: step 57220, total loss = 0.58, batch loss = 0.31 (258.4 examples/sec; 0.031 sec/batch; 1h:13m:25s remains)
INFO - root - 2022-02-24 19:55:59.872887: step 57230, total loss = 0.67, batch loss = 0.39 (300.9 examples/sec; 0.027 sec/batch; 1h:03m:02s remains)
INFO - root - 2022-02-24 19:56:00.165450: step 57240, total loss = 0.62, batch loss = 0.34 (310.4 examples/sec; 0.026 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 19:56:00.413251: step 57250, total loss = 0.53, batch loss = 0.25 (337.5 examples/sec; 0.024 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 19:56:00.768873: step 57260, total loss = 0.61, batch loss = 0.33 (371.4 examples/sec; 0.022 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 19:56:01.202941: step 57270, total loss = 0.58, batch loss = 0.31 (296.9 examples/sec; 0.027 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 19:56:01.504289: step 57280, total loss = 0.64, batch loss = 0.37 (355.7 examples/sec; 0.022 sec/batch; 0h:53m:18s remains)
INFO - root - 2022-02-24 19:56:01.837820: step 57290, total loss = 0.55, batch loss = 0.28 (140.5 examples/sec; 0.057 sec/batch; 2h:14m:55s remains)
INFO - root - 2022-02-24 19:56:02.112019: step 57300, total loss = 0.62, batch loss = 0.34 (334.1 examples/sec; 0.024 sec/batch; 0h:56m:44s remains)
INFO - root - 2022-02-24 19:56:02.536762: step 57310, total loss = 0.59, batch loss = 0.32 (174.6 examples/sec; 0.046 sec/batch; 1h:48m:36s remains)
INFO - root - 2022-02-24 19:56:02.923010: step 57320, total loss = 0.75, batch loss = 0.48 (337.3 examples/sec; 0.024 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 19:56:03.391163: step 57330, total loss = 0.66, batch loss = 0.38 (124.7 examples/sec; 0.064 sec/batch; 2h:31m:59s remains)
INFO - root - 2022-02-24 19:56:03.803149: step 57340, total loss = 0.50, batch loss = 0.23 (83.6 examples/sec; 0.096 sec/batch; 3h:46m:47s remains)
INFO - root - 2022-02-24 19:56:04.606686: step 57350, total loss = 0.61, batch loss = 0.33 (105.4 examples/sec; 0.076 sec/batch; 2h:59m:52s remains)
INFO - root - 2022-02-24 19:56:05.035309: step 57360, total loss = 0.50, batch loss = 0.23 (119.8 examples/sec; 0.067 sec/batch; 2h:38m:13s remains)
INFO - root - 2022-02-24 19:56:05.394753: step 57370, total loss = 0.68, batch loss = 0.40 (227.2 examples/sec; 0.035 sec/batch; 1h:23m:24s remains)
INFO - root - 2022-02-24 19:56:05.778793: step 57380, total loss = 0.53, batch loss = 0.25 (339.5 examples/sec; 0.024 sec/batch; 0h:55m:49s remains)
INFO - root - 2022-02-24 19:56:06.195242: step 57390, total loss = 0.62, batch loss = 0.35 (177.3 examples/sec; 0.045 sec/batch; 1h:46m:50s remains)
INFO - root - 2022-02-24 19:56:06.509023: step 57400, total loss = 0.64, batch loss = 0.36 (371.4 examples/sec; 0.022 sec/batch; 0h:51m:01s remains)
INFO - root - 2022-02-24 19:56:07.138718: step 57410, total loss = 0.63, batch loss = 0.36 (134.8 examples/sec; 0.059 sec/batch; 2h:20m:35s remains)
INFO - root - 2022-02-24 19:56:07.545192: step 57420, total loss = 0.55, batch loss = 0.28 (276.4 examples/sec; 0.029 sec/batch; 1h:08m:31s remains)
INFO - root - 2022-02-24 19:56:07.865275: step 57430, total loss = 0.64, batch loss = 0.37 (331.9 examples/sec; 0.024 sec/batch; 0h:57m:04s remains)
INFO - root - 2022-02-24 19:56:08.239073: step 57440, total loss = 0.48, batch loss = 0.21 (333.1 examples/sec; 0.024 sec/batch; 0h:56m:51s remains)
INFO - root - 2022-02-24 19:56:08.619470: step 57450, total loss = 0.60, batch loss = 0.33 (143.7 examples/sec; 0.056 sec/batch; 2h:11m:47s remains)
INFO - root - 2022-02-24 19:56:08.979182: step 57460, total loss = 0.54, batch loss = 0.27 (273.1 examples/sec; 0.029 sec/batch; 1h:09m:20s remains)
INFO - root - 2022-02-24 19:56:09.300306: step 57470, total loss = 0.61, batch loss = 0.34 (169.6 examples/sec; 0.047 sec/batch; 1h:51m:40s remains)
INFO - root - 2022-02-24 19:56:09.679061: step 57480, total loss = 0.60, batch loss = 0.33 (325.5 examples/sec; 0.025 sec/batch; 0h:58m:10s remains)
INFO - root - 2022-02-24 19:56:10.260988: step 57490, total loss = 0.53, batch loss = 0.25 (343.7 examples/sec; 0.023 sec/batch; 0h:55m:05s remains)
INFO - root - 2022-02-24 19:56:11.146434: step 57500, total loss = 0.70, batch loss = 0.43 (63.0 examples/sec; 0.127 sec/batch; 5h:00m:32s remains)
INFO - root - 2022-02-24 19:56:12.158853: step 57510, total loss = 0.49, batch loss = 0.22 (33.7 examples/sec; 0.237 sec/batch; 9h:21m:59s remains)
INFO - root - 2022-02-24 19:56:12.954132: step 57520, total loss = 0.56, batch loss = 0.28 (153.4 examples/sec; 0.052 sec/batch; 2h:03m:23s remains)
INFO - root - 2022-02-24 19:56:13.522005: step 57530, total loss = 0.56, batch loss = 0.28 (70.6 examples/sec; 0.113 sec/batch; 4h:28m:05s remains)
INFO - root - 2022-02-24 19:56:14.068277: step 57540, total loss = 0.56, batch loss = 0.28 (72.7 examples/sec; 0.110 sec/batch; 4h:20m:21s remains)
INFO - root - 2022-02-24 19:56:14.836016: step 57550, total loss = 0.70, batch loss = 0.42 (315.0 examples/sec; 0.025 sec/batch; 1h:00m:04s remains)
INFO - root - 2022-02-24 19:56:15.433093: step 57560, total loss = 0.58, batch loss = 0.31 (328.3 examples/sec; 0.024 sec/batch; 0h:57m:38s remains)
INFO - root - 2022-02-24 19:56:15.998736: step 57570, total loss = 0.64, batch loss = 0.37 (341.7 examples/sec; 0.023 sec/batch; 0h:55m:23s remains)
INFO - root - 2022-02-24 19:56:16.481909: step 57580, total loss = 0.52, batch loss = 0.25 (209.0 examples/sec; 0.038 sec/batch; 1h:30m:33s remains)
INFO - root - 2022-02-24 19:56:17.091463: step 57590, total loss = 0.49, batch loss = 0.22 (32.6 examples/sec; 0.246 sec/batch; 9h:40m:44s remains)
INFO - root - 2022-02-24 19:56:17.614130: step 57600, total loss = 0.50, batch loss = 0.22 (328.1 examples/sec; 0.024 sec/batch; 0h:57m:39s remains)
INFO - root - 2022-02-24 19:56:18.189527: step 57610, total loss = 0.58, batch loss = 0.30 (339.8 examples/sec; 0.024 sec/batch; 0h:55m:40s remains)
INFO - root - 2022-02-24 19:56:18.723270: step 57620, total loss = 0.56, batch loss = 0.29 (158.8 examples/sec; 0.050 sec/batch; 1h:59m:07s remains)
INFO - root - 2022-02-24 19:56:19.198687: step 57630, total loss = 0.55, batch loss = 0.28 (261.1 examples/sec; 0.031 sec/batch; 1h:12m:27s remains)
INFO - root - 2022-02-24 19:56:19.509050: step 57640, total loss = 0.53, batch loss = 0.26 (280.7 examples/sec; 0.028 sec/batch; 1h:07m:22s remains)
INFO - root - 2022-02-24 19:56:19.858049: step 57650, total loss = 0.52, batch loss = 0.24 (272.9 examples/sec; 0.029 sec/batch; 1h:09m:18s remains)
INFO - root - 2022-02-24 19:56:20.297334: step 57660, total loss = 0.60, batch loss = 0.32 (370.0 examples/sec; 0.022 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 19:56:20.679858: step 57670, total loss = 0.55, batch loss = 0.28 (288.4 examples/sec; 0.028 sec/batch; 1h:05m:34s remains)
INFO - root - 2022-02-24 19:56:20.993227: step 57680, total loss = 0.46, batch loss = 0.19 (322.2 examples/sec; 0.025 sec/batch; 0h:58m:41s remains)
INFO - root - 2022-02-24 19:56:21.305756: step 57690, total loss = 0.53, batch loss = 0.26 (270.2 examples/sec; 0.030 sec/batch; 1h:09m:58s remains)
INFO - root - 2022-02-24 19:56:21.591168: step 57700, total loss = 0.58, batch loss = 0.30 (218.4 examples/sec; 0.037 sec/batch; 1h:26m:34s remains)
INFO - root - 2022-02-24 19:56:21.968576: step 57710, total loss = 0.69, batch loss = 0.42 (350.0 examples/sec; 0.023 sec/batch; 0h:54m:00s remains)
INFO - root - 2022-02-24 19:56:22.328499: step 57720, total loss = 0.47, batch loss = 0.20 (131.2 examples/sec; 0.061 sec/batch; 2h:24m:07s remains)
INFO - root - 2022-02-24 19:56:22.681672: step 57730, total loss = 0.53, batch loss = 0.25 (310.7 examples/sec; 0.026 sec/batch; 1h:00m:50s remains)
INFO - root - 2022-02-24 19:56:23.043787: step 57740, total loss = 0.55, batch loss = 0.28 (199.6 examples/sec; 0.040 sec/batch; 1h:34m:41s remains)
INFO - root - 2022-02-24 19:56:23.340654: step 57750, total loss = 0.60, batch loss = 0.33 (209.3 examples/sec; 0.038 sec/batch; 1h:30m:18s remains)
INFO - root - 2022-02-24 19:56:23.636075: step 57760, total loss = 0.64, batch loss = 0.37 (332.8 examples/sec; 0.024 sec/batch; 0h:56m:46s remains)
INFO - root - 2022-02-24 19:56:24.014627: step 57770, total loss = 0.61, batch loss = 0.33 (334.1 examples/sec; 0.024 sec/batch; 0h:56m:33s remains)
INFO - root - 2022-02-24 19:56:24.429605: step 57780, total loss = 0.69, batch loss = 0.42 (160.6 examples/sec; 0.050 sec/batch; 1h:57m:37s remains)
INFO - root - 2022-02-24 19:56:24.873377: step 57790, total loss = 0.76, batch loss = 0.49 (260.2 examples/sec; 0.031 sec/batch; 1h:12m:36s remains)
INFO - root - 2022-02-24 19:56:25.151613: step 57800, total loss = 0.57, batch loss = 0.30 (276.5 examples/sec; 0.029 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 19:56:25.527604: step 57810, total loss = 0.56, batch loss = 0.29 (287.6 examples/sec; 0.028 sec/batch; 1h:05m:41s remains)
INFO - root - 2022-02-24 19:56:25.853683: step 57820, total loss = 0.49, batch loss = 0.22 (300.3 examples/sec; 0.027 sec/batch; 1h:02m:54s remains)
INFO - root - 2022-02-24 19:56:26.159095: step 57830, total loss = 0.50, batch loss = 0.23 (253.8 examples/sec; 0.032 sec/batch; 1h:14m:26s remains)
INFO - root - 2022-02-24 19:56:26.563807: step 57840, total loss = 0.63, batch loss = 0.36 (221.1 examples/sec; 0.036 sec/batch; 1h:25m:25s remains)
INFO - root - 2022-02-24 19:56:27.005084: step 57850, total loss = 0.61, batch loss = 0.34 (211.9 examples/sec; 0.038 sec/batch; 1h:29m:07s remains)
INFO - root - 2022-02-24 19:56:27.350756: step 57860, total loss = 0.66, batch loss = 0.38 (194.2 examples/sec; 0.041 sec/batch; 1h:37m:14s remains)
INFO - root - 2022-02-24 19:56:27.661982: step 57870, total loss = 0.63, batch loss = 0.36 (224.1 examples/sec; 0.036 sec/batch; 1h:24m:16s remains)
INFO - root - 2022-02-24 19:56:27.975837: step 57880, total loss = 0.71, batch loss = 0.43 (336.4 examples/sec; 0.024 sec/batch; 0h:56m:07s remains)
INFO - root - 2022-02-24 19:56:28.335741: step 57890, total loss = 0.70, batch loss = 0.42 (228.0 examples/sec; 0.035 sec/batch; 1h:22m:48s remains)
INFO - root - 2022-02-24 19:56:28.779662: step 57900, total loss = 0.53, batch loss = 0.26 (153.5 examples/sec; 0.052 sec/batch; 2h:03m:01s remains)
INFO - root - 2022-02-24 19:56:29.215962: step 57910, total loss = 0.78, batch loss = 0.50 (271.7 examples/sec; 0.029 sec/batch; 1h:09m:28s remains)
INFO - root - 2022-02-24 19:56:29.547685: step 57920, total loss = 0.57, batch loss = 0.30 (336.2 examples/sec; 0.024 sec/batch; 0h:56m:09s remains)
INFO - root - 2022-02-24 19:56:29.913424: step 57930, total loss = 0.60, batch loss = 0.32 (344.9 examples/sec; 0.023 sec/batch; 0h:54m:44s remains)
INFO - root - 2022-02-24 19:56:30.243240: step 57940, total loss = 0.62, batch loss = 0.35 (320.9 examples/sec; 0.025 sec/batch; 0h:58m:48s remains)
INFO - root - 2022-02-24 19:56:30.578137: step 57950, total loss = 0.58, batch loss = 0.30 (333.7 examples/sec; 0.024 sec/batch; 0h:56m:33s remains)
INFO - root - 2022-02-24 19:56:30.967807: step 57960, total loss = 0.79, batch loss = 0.51 (215.5 examples/sec; 0.037 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 19:56:31.272766: step 57970, total loss = 0.56, batch loss = 0.28 (309.9 examples/sec; 0.026 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 19:56:31.636451: step 57980, total loss = 0.56, batch loss = 0.29 (163.2 examples/sec; 0.049 sec/batch; 1h:55m:36s remains)
INFO - root - 2022-02-24 19:56:31.933645: step 57990, total loss = 0.56, batch loss = 0.29 (188.5 examples/sec; 0.042 sec/batch; 1h:40m:04s remains)
INFO - root - 2022-02-24 19:56:32.273592: step 58000, total loss = 0.58, batch loss = 0.31 (115.5 examples/sec; 0.069 sec/batch; 2h:43m:19s remains)
INFO - root - 2022-02-24 19:56:32.658297: step 58010, total loss = 0.53, batch loss = 0.25 (381.0 examples/sec; 0.021 sec/batch; 0h:49m:30s remains)
INFO - root - 2022-02-24 19:56:33.084498: step 58020, total loss = 0.57, batch loss = 0.30 (208.4 examples/sec; 0.038 sec/batch; 1h:30m:29s remains)
INFO - root - 2022-02-24 19:56:33.387891: step 58030, total loss = 0.68, batch loss = 0.40 (353.6 examples/sec; 0.023 sec/batch; 0h:53m:21s remains)
INFO - root - 2022-02-24 19:56:33.715510: step 58040, total loss = 0.54, batch loss = 0.27 (147.3 examples/sec; 0.054 sec/batch; 2h:08m:02s remains)
INFO - root - 2022-02-24 19:56:34.029421: step 58050, total loss = 0.48, batch loss = 0.21 (299.6 examples/sec; 0.027 sec/batch; 1h:02m:57s remains)
INFO - root - 2022-02-24 19:56:34.361813: step 58060, total loss = 0.71, batch loss = 0.43 (364.1 examples/sec; 0.022 sec/batch; 0h:51m:47s remains)
INFO - root - 2022-02-24 19:56:34.865997: step 58070, total loss = 0.52, batch loss = 0.25 (377.1 examples/sec; 0.021 sec/batch; 0h:50m:00s remains)
INFO - root - 2022-02-24 19:56:35.361412: step 58080, total loss = 0.51, batch loss = 0.23 (154.9 examples/sec; 0.052 sec/batch; 2h:01m:44s remains)
INFO - root - 2022-02-24 19:56:35.667129: step 58090, total loss = 0.56, batch loss = 0.29 (177.1 examples/sec; 0.045 sec/batch; 1h:46m:26s remains)
INFO - root - 2022-02-24 19:56:35.965276: step 58100, total loss = 0.56, batch loss = 0.29 (335.6 examples/sec; 0.024 sec/batch; 0h:56m:10s remains)
INFO - root - 2022-02-24 19:56:36.372550: step 58110, total loss = 0.59, batch loss = 0.32 (220.7 examples/sec; 0.036 sec/batch; 1h:25m:24s remains)
INFO - root - 2022-02-24 19:56:36.682092: step 58120, total loss = 0.64, batch loss = 0.37 (391.7 examples/sec; 0.020 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 19:56:37.133622: step 58130, total loss = 0.50, batch loss = 0.23 (275.4 examples/sec; 0.029 sec/batch; 1h:08m:26s remains)
INFO - root - 2022-02-24 19:56:37.693379: step 58140, total loss = 0.50, batch loss = 0.23 (118.7 examples/sec; 0.067 sec/batch; 2h:38m:46s remains)
INFO - root - 2022-02-24 19:56:38.191605: step 58150, total loss = 0.52, batch loss = 0.25 (198.4 examples/sec; 0.040 sec/batch; 1h:35m:00s remains)
INFO - root - 2022-02-24 19:56:38.712242: step 58160, total loss = 0.53, batch loss = 0.26 (131.6 examples/sec; 0.061 sec/batch; 2h:23m:13s remains)
INFO - root - 2022-02-24 19:56:39.212788: step 58170, total loss = 0.66, batch loss = 0.38 (222.1 examples/sec; 0.036 sec/batch; 1h:24m:51s remains)
INFO - root - 2022-02-24 19:56:39.793940: step 58180, total loss = 0.65, batch loss = 0.38 (162.1 examples/sec; 0.049 sec/batch; 1h:56m:14s remains)
INFO - root - 2022-02-24 19:56:40.596013: step 58190, total loss = 0.71, batch loss = 0.44 (195.6 examples/sec; 0.041 sec/batch; 1h:36m:19s remains)
INFO - root - 2022-02-24 19:56:40.938063: step 58200, total loss = 0.48, batch loss = 0.21 (335.9 examples/sec; 0.024 sec/batch; 0h:56m:05s remains)
INFO - root - 2022-02-24 19:56:41.453105: step 58210, total loss = 0.53, batch loss = 0.26 (246.2 examples/sec; 0.032 sec/batch; 1h:16m:31s remains)
INFO - root - 2022-02-24 19:56:41.853483: step 58220, total loss = 0.50, batch loss = 0.22 (175.7 examples/sec; 0.046 sec/batch; 1h:47m:12s remains)
INFO - root - 2022-02-24 19:56:42.290814: step 58230, total loss = 0.65, batch loss = 0.38 (99.4 examples/sec; 0.081 sec/batch; 3h:09m:35s remains)
INFO - root - 2022-02-24 19:56:42.780645: step 58240, total loss = 0.62, batch loss = 0.34 (148.3 examples/sec; 0.054 sec/batch; 2h:07m:02s remains)
INFO - root - 2022-02-24 19:56:43.357065: step 58250, total loss = 0.55, batch loss = 0.28 (136.3 examples/sec; 0.059 sec/batch; 2h:18m:10s remains)
INFO - root - 2022-02-24 19:56:43.774137: step 58260, total loss = 0.57, batch loss = 0.29 (307.1 examples/sec; 0.026 sec/batch; 1h:01m:19s remains)
INFO - root - 2022-02-24 19:56:44.212091: step 58270, total loss = 0.54, batch loss = 0.27 (169.1 examples/sec; 0.047 sec/batch; 1h:51m:21s remains)
INFO - root - 2022-02-24 19:56:44.581442: step 58280, total loss = 0.50, batch loss = 0.22 (301.9 examples/sec; 0.026 sec/batch; 1h:02m:21s remains)
INFO - root - 2022-02-24 19:56:45.260475: step 58290, total loss = 0.60, batch loss = 0.32 (20.7 examples/sec; 0.386 sec/batch; 15h:09m:18s remains)
INFO - root - 2022-02-24 19:56:45.695532: step 58300, total loss = 0.64, batch loss = 0.37 (306.6 examples/sec; 0.026 sec/batch; 1h:01m:24s remains)
INFO - root - 2022-02-24 19:56:46.266393: step 58310, total loss = 0.64, batch loss = 0.37 (347.2 examples/sec; 0.023 sec/batch; 0h:54m:13s remains)
INFO - root - 2022-02-24 19:56:46.685637: step 58320, total loss = 0.55, batch loss = 0.28 (221.3 examples/sec; 0.036 sec/batch; 1h:25m:03s remains)
INFO - root - 2022-02-24 19:56:47.226141: step 58330, total loss = 0.47, batch loss = 0.20 (152.7 examples/sec; 0.052 sec/batch; 2h:03m:13s remains)
INFO - root - 2022-02-24 19:56:47.708016: step 58340, total loss = 0.50, batch loss = 0.23 (182.7 examples/sec; 0.044 sec/batch; 1h:43m:02s remains)
INFO - root - 2022-02-24 19:56:48.052143: step 58350, total loss = 0.53, batch loss = 0.25 (101.7 examples/sec; 0.079 sec/batch; 3h:05m:01s remains)
INFO - root - 2022-02-24 19:56:48.405158: step 58360, total loss = 0.49, batch loss = 0.22 (258.6 examples/sec; 0.031 sec/batch; 1h:12m:45s remains)
INFO - root - 2022-02-24 19:56:48.809261: step 58370, total loss = 0.62, batch loss = 0.35 (284.9 examples/sec; 0.028 sec/batch; 1h:06m:03s remains)
INFO - root - 2022-02-24 19:56:49.184729: step 58380, total loss = 0.59, batch loss = 0.31 (169.6 examples/sec; 0.047 sec/batch; 1h:50m:58s remains)
INFO - root - 2022-02-24 19:56:49.658949: step 58390, total loss = 0.58, batch loss = 0.31 (181.0 examples/sec; 0.044 sec/batch; 1h:43m:56s remains)
INFO - root - 2022-02-24 19:56:50.038845: step 58400, total loss = 0.53, batch loss = 0.25 (285.3 examples/sec; 0.028 sec/batch; 1h:05m:56s remains)
INFO - root - 2022-02-24 19:56:50.471373: step 58410, total loss = 0.63, batch loss = 0.36 (286.1 examples/sec; 0.028 sec/batch; 1h:05m:44s remains)
INFO - root - 2022-02-24 19:56:50.946791: step 58420, total loss = 0.59, batch loss = 0.32 (157.7 examples/sec; 0.051 sec/batch; 1h:59m:17s remains)
INFO - root - 2022-02-24 19:56:51.499565: step 58430, total loss = 0.49, batch loss = 0.21 (193.1 examples/sec; 0.041 sec/batch; 1h:37m:24s remains)
INFO - root - 2022-02-24 19:56:51.917137: step 58440, total loss = 0.58, batch loss = 0.31 (141.1 examples/sec; 0.057 sec/batch; 2h:13m:19s remains)
INFO - root - 2022-02-24 19:56:52.289459: step 58450, total loss = 0.58, batch loss = 0.31 (194.1 examples/sec; 0.041 sec/batch; 1h:36m:53s remains)
INFO - root - 2022-02-24 19:56:52.661962: step 58460, total loss = 0.49, batch loss = 0.22 (324.5 examples/sec; 0.025 sec/batch; 0h:57m:57s remains)
INFO - root - 2022-02-24 19:56:52.990378: step 58470, total loss = 0.51, batch loss = 0.24 (119.9 examples/sec; 0.067 sec/batch; 2h:36m:53s remains)
INFO - root - 2022-02-24 19:56:53.350474: step 58480, total loss = 0.60, batch loss = 0.33 (150.8 examples/sec; 0.053 sec/batch; 2h:04m:39s remains)
INFO - root - 2022-02-24 19:56:53.872713: step 58490, total loss = 0.63, batch loss = 0.35 (125.0 examples/sec; 0.064 sec/batch; 2h:30m:26s remains)
INFO - root - 2022-02-24 19:56:54.280422: step 58500, total loss = 0.53, batch loss = 0.26 (317.4 examples/sec; 0.025 sec/batch; 0h:59m:14s remains)
INFO - root - 2022-02-24 19:56:54.753090: step 58510, total loss = 0.58, batch loss = 0.31 (303.7 examples/sec; 0.026 sec/batch; 1h:01m:53s remains)
INFO - root - 2022-02-24 19:56:55.141994: step 58520, total loss = 0.49, batch loss = 0.21 (309.6 examples/sec; 0.026 sec/batch; 1h:00m:42s remains)
INFO - root - 2022-02-24 19:56:55.808708: step 58530, total loss = 0.58, batch loss = 0.31 (39.3 examples/sec; 0.203 sec/batch; 7h:57m:47s remains)
INFO - root - 2022-02-24 19:56:56.326230: step 58540, total loss = 0.53, batch loss = 0.25 (143.6 examples/sec; 0.056 sec/batch; 2h:10m:52s remains)
INFO - root - 2022-02-24 19:56:56.690917: step 58550, total loss = 0.51, batch loss = 0.23 (155.7 examples/sec; 0.051 sec/batch; 2h:00m:40s remains)
INFO - root - 2022-02-24 19:56:56.982594: step 58560, total loss = 0.65, batch loss = 0.38 (168.8 examples/sec; 0.047 sec/batch; 1h:51m:18s remains)
INFO - root - 2022-02-24 19:56:57.525079: step 58570, total loss = 0.47, batch loss = 0.20 (64.7 examples/sec; 0.124 sec/batch; 4h:50m:28s remains)
INFO - root - 2022-02-24 19:56:58.169630: step 58580, total loss = 0.57, batch loss = 0.29 (106.7 examples/sec; 0.075 sec/batch; 2h:56m:05s remains)
INFO - root - 2022-02-24 19:56:58.577630: step 58590, total loss = 0.63, batch loss = 0.35 (294.5 examples/sec; 0.027 sec/batch; 1h:03m:47s remains)
INFO - root - 2022-02-24 19:56:58.959910: step 58600, total loss = 0.68, batch loss = 0.41 (365.0 examples/sec; 0.022 sec/batch; 0h:51m:27s remains)
INFO - root - 2022-02-24 19:56:59.470298: step 58610, total loss = 0.47, batch loss = 0.20 (341.1 examples/sec; 0.023 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 19:56:59.895714: step 58620, total loss = 0.49, batch loss = 0.22 (198.9 examples/sec; 0.040 sec/batch; 1h:34m:26s remains)
INFO - root - 2022-02-24 19:57:00.575932: step 58630, total loss = 0.56, batch loss = 0.28 (252.1 examples/sec; 0.032 sec/batch; 1h:14m:30s remains)
INFO - root - 2022-02-24 19:57:01.108374: step 58640, total loss = 0.50, batch loss = 0.23 (165.8 examples/sec; 0.048 sec/batch; 1h:53m:17s remains)
INFO - root - 2022-02-24 19:57:01.450076: step 58650, total loss = 0.71, batch loss = 0.43 (366.2 examples/sec; 0.022 sec/batch; 0h:51m:16s remains)
INFO - root - 2022-02-24 19:57:01.928217: step 58660, total loss = 0.57, batch loss = 0.30 (138.8 examples/sec; 0.058 sec/batch; 2h:15m:14s remains)
INFO - root - 2022-02-24 19:57:02.703877: step 58670, total loss = 0.43, batch loss = 0.16 (207.9 examples/sec; 0.038 sec/batch; 1h:30m:20s remains)
INFO - root - 2022-02-24 19:57:03.617610: step 58680, total loss = 0.47, batch loss = 0.19 (123.0 examples/sec; 0.065 sec/batch; 2h:32m:38s remains)
INFO - root - 2022-02-24 19:57:04.043273: step 58690, total loss = 0.56, batch loss = 0.29 (331.4 examples/sec; 0.024 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 19:57:04.488913: step 58700, total loss = 0.60, batch loss = 0.33 (351.4 examples/sec; 0.023 sec/batch; 0h:53m:25s remains)
INFO - root - 2022-02-24 19:57:05.540599: step 58710, total loss = 0.54, batch loss = 0.27 (152.1 examples/sec; 0.053 sec/batch; 2h:03m:25s remains)
INFO - root - 2022-02-24 19:57:05.858647: step 58720, total loss = 0.64, batch loss = 0.36 (215.3 examples/sec; 0.037 sec/batch; 1h:27m:11s remains)
INFO - root - 2022-02-24 19:57:06.225439: step 58730, total loss = 0.56, batch loss = 0.28 (369.8 examples/sec; 0.022 sec/batch; 0h:50m:45s remains)
INFO - root - 2022-02-24 19:57:06.621383: step 58740, total loss = 0.54, batch loss = 0.27 (382.0 examples/sec; 0.021 sec/batch; 0h:49m:07s remains)
INFO - root - 2022-02-24 19:57:07.094674: step 58750, total loss = 0.52, batch loss = 0.24 (249.0 examples/sec; 0.032 sec/batch; 1h:15m:21s remains)
INFO - root - 2022-02-24 19:57:07.533218: step 58760, total loss = 0.56, batch loss = 0.29 (168.1 examples/sec; 0.048 sec/batch; 1h:51m:39s remains)
INFO - root - 2022-02-24 19:57:07.898772: step 58770, total loss = 0.57, batch loss = 0.29 (148.2 examples/sec; 0.054 sec/batch; 2h:06m:38s remains)
INFO - root - 2022-02-24 19:57:08.223060: step 58780, total loss = 0.63, batch loss = 0.35 (253.3 examples/sec; 0.032 sec/batch; 1h:14m:04s remains)
INFO - root - 2022-02-24 19:57:08.584268: step 58790, total loss = 0.48, batch loss = 0.21 (320.1 examples/sec; 0.025 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 19:57:08.996946: step 58800, total loss = 0.56, batch loss = 0.29 (146.6 examples/sec; 0.055 sec/batch; 2h:07m:56s remains)
INFO - root - 2022-02-24 19:57:09.455353: step 58810, total loss = 0.55, batch loss = 0.28 (286.5 examples/sec; 0.028 sec/batch; 1h:05m:27s remains)
INFO - root - 2022-02-24 19:57:09.744544: step 58820, total loss = 0.58, batch loss = 0.30 (306.8 examples/sec; 0.026 sec/batch; 1h:01m:08s remains)
INFO - root - 2022-02-24 19:57:10.079869: step 58830, total loss = 0.51, batch loss = 0.24 (86.1 examples/sec; 0.093 sec/batch; 3h:37m:55s remains)
INFO - root - 2022-02-24 19:57:10.386860: step 58840, total loss = 0.58, batch loss = 0.31 (206.6 examples/sec; 0.039 sec/batch; 1h:30m:47s remains)
INFO - root - 2022-02-24 19:57:10.714490: step 58850, total loss = 0.58, batch loss = 0.31 (124.1 examples/sec; 0.064 sec/batch; 2h:31m:10s remains)
INFO - root - 2022-02-24 19:57:11.071403: step 58860, total loss = 0.50, batch loss = 0.23 (338.6 examples/sec; 0.024 sec/batch; 0h:55m:22s remains)
INFO - root - 2022-02-24 19:57:11.482892: step 58870, total loss = 0.63, batch loss = 0.36 (281.1 examples/sec; 0.028 sec/batch; 1h:06m:41s remains)
INFO - root - 2022-02-24 19:57:11.863103: step 58880, total loss = 0.61, batch loss = 0.34 (352.3 examples/sec; 0.023 sec/batch; 0h:53m:13s remains)
INFO - root - 2022-02-24 19:57:12.172932: step 58890, total loss = 0.54, batch loss = 0.27 (229.4 examples/sec; 0.035 sec/batch; 1h:21m:43s remains)
INFO - root - 2022-02-24 19:57:12.474226: step 58900, total loss = 0.62, batch loss = 0.35 (287.3 examples/sec; 0.028 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 19:57:12.890228: step 58910, total loss = 0.59, batch loss = 0.32 (201.0 examples/sec; 0.040 sec/batch; 1h:33m:15s remains)
INFO - root - 2022-02-24 19:57:13.252853: step 58920, total loss = 0.58, batch loss = 0.30 (225.9 examples/sec; 0.035 sec/batch; 1h:22m:59s remains)
INFO - root - 2022-02-24 19:57:13.654008: step 58930, total loss = 0.51, batch loss = 0.24 (326.7 examples/sec; 0.024 sec/batch; 0h:57m:22s remains)
INFO - root - 2022-02-24 19:57:13.935446: step 58940, total loss = 0.51, batch loss = 0.24 (322.0 examples/sec; 0.025 sec/batch; 0h:58m:12s remains)
INFO - root - 2022-02-24 19:57:14.268336: step 58950, total loss = 0.57, batch loss = 0.30 (316.1 examples/sec; 0.025 sec/batch; 0h:59m:17s remains)
INFO - root - 2022-02-24 19:57:14.578355: step 58960, total loss = 0.58, batch loss = 0.31 (239.8 examples/sec; 0.033 sec/batch; 1h:18m:09s remains)
INFO - root - 2022-02-24 19:57:14.852111: step 58970, total loss = 0.56, batch loss = 0.29 (327.3 examples/sec; 0.024 sec/batch; 0h:57m:15s remains)
INFO - root - 2022-02-24 19:57:15.357872: step 58980, total loss = 0.62, batch loss = 0.35 (184.9 examples/sec; 0.043 sec/batch; 1h:41m:20s remains)
INFO - root - 2022-02-24 19:57:15.760548: step 58990, total loss = 0.49, batch loss = 0.22 (318.8 examples/sec; 0.025 sec/batch; 0h:58m:45s remains)
INFO - root - 2022-02-24 19:57:16.099562: step 59000, total loss = 0.67, batch loss = 0.40 (379.4 examples/sec; 0.021 sec/batch; 0h:49m:22s remains)
INFO - root - 2022-02-24 19:57:16.521603: step 59010, total loss = 0.45, batch loss = 0.18 (182.0 examples/sec; 0.044 sec/batch; 1h:42m:55s remains)
INFO - root - 2022-02-24 19:57:16.833690: step 59020, total loss = 0.58, batch loss = 0.31 (153.6 examples/sec; 0.052 sec/batch; 2h:01m:58s remains)
INFO - root - 2022-02-24 19:57:17.196184: step 59030, total loss = 0.47, batch loss = 0.20 (201.5 examples/sec; 0.040 sec/batch; 1h:32m:57s remains)
INFO - root - 2022-02-24 19:57:17.580002: step 59040, total loss = 0.61, batch loss = 0.34 (161.7 examples/sec; 0.049 sec/batch; 1h:55m:50s remains)
INFO - root - 2022-02-24 19:57:17.981901: step 59050, total loss = 0.51, batch loss = 0.24 (116.7 examples/sec; 0.069 sec/batch; 2h:40m:26s remains)
INFO - root - 2022-02-24 19:57:18.358807: step 59060, total loss = 0.63, batch loss = 0.35 (345.7 examples/sec; 0.023 sec/batch; 0h:54m:10s remains)
INFO - root - 2022-02-24 19:57:18.670486: step 59070, total loss = 0.70, batch loss = 0.42 (321.5 examples/sec; 0.025 sec/batch; 0h:58m:14s remains)
INFO - root - 2022-02-24 19:57:18.972255: step 59080, total loss = 0.54, batch loss = 0.27 (204.0 examples/sec; 0.039 sec/batch; 1h:31m:46s remains)
INFO - root - 2022-02-24 19:57:19.215203: step 59090, total loss = 0.56, batch loss = 0.28 (346.7 examples/sec; 0.023 sec/batch; 0h:53m:59s remains)
INFO - root - 2022-02-24 19:57:19.607234: step 59100, total loss = 0.53, batch loss = 0.25 (119.6 examples/sec; 0.067 sec/batch; 2h:36m:32s remains)
INFO - root - 2022-02-24 19:57:20.091614: step 59110, total loss = 0.57, batch loss = 0.30 (147.2 examples/sec; 0.054 sec/batch; 2h:07m:09s remains)
INFO - root - 2022-02-24 19:57:20.440248: step 59120, total loss = 0.63, batch loss = 0.36 (344.3 examples/sec; 0.023 sec/batch; 0h:54m:21s remains)
INFO - root - 2022-02-24 19:57:20.755168: step 59130, total loss = 0.52, batch loss = 0.24 (231.2 examples/sec; 0.035 sec/batch; 1h:20m:56s remains)
INFO - root - 2022-02-24 19:57:21.094927: step 59140, total loss = 0.53, batch loss = 0.26 (209.7 examples/sec; 0.038 sec/batch; 1h:29m:13s remains)
INFO - root - 2022-02-24 19:57:21.410495: step 59150, total loss = 0.55, batch loss = 0.27 (177.7 examples/sec; 0.045 sec/batch; 1h:45m:18s remains)
INFO - root - 2022-02-24 19:57:21.796231: step 59160, total loss = 0.51, batch loss = 0.24 (223.2 examples/sec; 0.036 sec/batch; 1h:23m:50s remains)
INFO - root - 2022-02-24 19:57:22.206884: step 59170, total loss = 0.59, batch loss = 0.32 (256.4 examples/sec; 0.031 sec/batch; 1h:12m:57s remains)
INFO - root - 2022-02-24 19:57:22.563840: step 59180, total loss = 0.55, batch loss = 0.28 (324.9 examples/sec; 0.025 sec/batch; 0h:57m:35s remains)
INFO - root - 2022-02-24 19:57:22.864062: step 59190, total loss = 0.57, batch loss = 0.30 (307.8 examples/sec; 0.026 sec/batch; 1h:00m:46s remains)
INFO - root - 2022-02-24 19:57:23.194483: step 59200, total loss = 0.66, batch loss = 0.39 (270.1 examples/sec; 0.030 sec/batch; 1h:09m:15s remains)
INFO - root - 2022-02-24 19:57:23.606048: step 59210, total loss = 0.55, batch loss = 0.28 (168.8 examples/sec; 0.047 sec/batch; 1h:50m:50s remains)
INFO - root - 2022-02-24 19:57:23.987067: step 59220, total loss = 0.71, batch loss = 0.44 (270.6 examples/sec; 0.030 sec/batch; 1h:09m:07s remains)
INFO - root - 2022-02-24 19:57:24.441950: step 59230, total loss = 0.82, batch loss = 0.55 (337.1 examples/sec; 0.024 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 19:57:24.935098: step 59240, total loss = 0.56, batch loss = 0.29 (345.0 examples/sec; 0.023 sec/batch; 0h:54m:12s remains)
INFO - root - 2022-02-24 19:57:25.763643: step 59250, total loss = 0.54, batch loss = 0.27 (223.8 examples/sec; 0.036 sec/batch; 1h:23m:34s remains)
INFO - root - 2022-02-24 19:57:26.167731: step 59260, total loss = 0.48, batch loss = 0.21 (143.4 examples/sec; 0.056 sec/batch; 2h:10m:21s remains)
INFO - root - 2022-02-24 19:57:26.597821: step 59270, total loss = 0.59, batch loss = 0.31 (222.0 examples/sec; 0.036 sec/batch; 1h:24m:13s remains)
INFO - root - 2022-02-24 19:57:26.910894: step 59280, total loss = 0.51, batch loss = 0.23 (203.4 examples/sec; 0.039 sec/batch; 1h:31m:54s remains)
INFO - root - 2022-02-24 19:57:27.260780: step 59290, total loss = 0.66, batch loss = 0.39 (234.6 examples/sec; 0.034 sec/batch; 1h:19m:42s remains)
INFO - root - 2022-02-24 19:57:27.625574: step 59300, total loss = 0.54, batch loss = 0.26 (360.9 examples/sec; 0.022 sec/batch; 0h:51m:47s remains)
INFO - root - 2022-02-24 19:57:28.847311: step 59310, total loss = 0.45, batch loss = 0.18 (361.6 examples/sec; 0.022 sec/batch; 0h:51m:41s remains)
INFO - root - 2022-02-24 19:57:29.085433: step 59320, total loss = 0.54, batch loss = 0.27 (356.9 examples/sec; 0.022 sec/batch; 0h:52m:21s remains)
INFO - root - 2022-02-24 19:57:29.321623: step 59330, total loss = 0.74, batch loss = 0.46 (333.0 examples/sec; 0.024 sec/batch; 0h:56m:07s remains)
INFO - root - 2022-02-24 19:57:29.558212: step 59340, total loss = 0.52, batch loss = 0.25 (353.0 examples/sec; 0.023 sec/batch; 0h:52m:56s remains)
INFO - root - 2022-02-24 19:57:29.794263: step 59350, total loss = 0.52, batch loss = 0.25 (349.3 examples/sec; 0.023 sec/batch; 0h:53m:29s remains)
INFO - root - 2022-02-24 19:57:30.051864: step 59360, total loss = 0.60, batch loss = 0.32 (210.3 examples/sec; 0.038 sec/batch; 1h:28m:52s remains)
INFO - root - 2022-02-24 19:57:30.805221: step 59370, total loss = 0.51, batch loss = 0.23 (223.2 examples/sec; 0.036 sec/batch; 1h:23m:42s remains)
INFO - root - 2022-02-24 19:57:31.223271: step 59380, total loss = 0.64, batch loss = 0.37 (215.6 examples/sec; 0.037 sec/batch; 1h:26m:39s remains)
INFO - root - 2022-02-24 19:57:31.533712: step 59390, total loss = 0.53, batch loss = 0.25 (317.4 examples/sec; 0.025 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 19:57:31.875353: step 59400, total loss = 0.60, batch loss = 0.33 (322.6 examples/sec; 0.025 sec/batch; 0h:57m:53s remains)
INFO - root - 2022-02-24 19:57:32.223781: step 59410, total loss = 0.59, batch loss = 0.32 (363.1 examples/sec; 0.022 sec/batch; 0h:51m:26s remains)
INFO - root - 2022-02-24 19:57:32.620606: step 59420, total loss = 0.62, batch loss = 0.35 (153.7 examples/sec; 0.052 sec/batch; 2h:01m:31s remains)
INFO - root - 2022-02-24 19:57:33.146387: step 59430, total loss = 0.56, batch loss = 0.28 (283.1 examples/sec; 0.028 sec/batch; 1h:05m:57s remains)
INFO - root - 2022-02-24 19:57:33.479954: step 59440, total loss = 0.49, batch loss = 0.22 (336.3 examples/sec; 0.024 sec/batch; 0h:55m:31s remains)
INFO - root - 2022-02-24 19:57:33.756737: step 59450, total loss = 0.53, batch loss = 0.26 (353.6 examples/sec; 0.023 sec/batch; 0h:52m:48s remains)
INFO - root - 2022-02-24 19:57:34.123395: step 59460, total loss = 0.55, batch loss = 0.27 (220.3 examples/sec; 0.036 sec/batch; 1h:24m:45s remains)
INFO - root - 2022-02-24 19:57:34.422623: step 59470, total loss = 0.50, batch loss = 0.22 (240.1 examples/sec; 0.033 sec/batch; 1h:17m:45s remains)
INFO - root - 2022-02-24 19:57:34.928034: step 59480, total loss = 0.64, batch loss = 0.37 (234.2 examples/sec; 0.034 sec/batch; 1h:19m:43s remains)
INFO - root - 2022-02-24 19:57:35.462192: step 59490, total loss = 0.50, batch loss = 0.23 (216.6 examples/sec; 0.037 sec/batch; 1h:26m:10s remains)
INFO - root - 2022-02-24 19:57:35.835775: step 59500, total loss = 0.51, batch loss = 0.23 (222.3 examples/sec; 0.036 sec/batch; 1h:23m:58s remains)
INFO - root - 2022-02-24 19:57:36.254857: step 59510, total loss = 0.54, batch loss = 0.26 (191.9 examples/sec; 0.042 sec/batch; 1h:37m:15s remains)
INFO - root - 2022-02-24 19:57:36.587121: step 59520, total loss = 0.53, batch loss = 0.26 (188.7 examples/sec; 0.042 sec/batch; 1h:38m:55s remains)
INFO - root - 2022-02-24 19:57:37.022547: step 59530, total loss = 0.59, batch loss = 0.32 (211.1 examples/sec; 0.038 sec/batch; 1h:28m:23s remains)
INFO - root - 2022-02-24 19:57:37.367146: step 59540, total loss = 0.63, batch loss = 0.35 (315.0 examples/sec; 0.025 sec/batch; 0h:59m:14s remains)
INFO - root - 2022-02-24 19:57:37.649405: step 59550, total loss = 0.62, batch loss = 0.34 (185.7 examples/sec; 0.043 sec/batch; 1h:40m:29s remains)
INFO - root - 2022-02-24 19:57:37.946263: step 59560, total loss = 0.60, batch loss = 0.33 (202.4 examples/sec; 0.040 sec/batch; 1h:32m:10s remains)
INFO - root - 2022-02-24 19:57:38.331771: step 59570, total loss = 0.67, batch loss = 0.40 (225.9 examples/sec; 0.035 sec/batch; 1h:22m:35s remains)
INFO - root - 2022-02-24 19:57:38.661316: step 59580, total loss = 0.49, batch loss = 0.21 (267.1 examples/sec; 0.030 sec/batch; 1h:09m:50s remains)
INFO - root - 2022-02-24 19:57:39.146767: step 59590, total loss = 0.50, batch loss = 0.23 (82.5 examples/sec; 0.097 sec/batch; 3h:46m:01s remains)
INFO - root - 2022-02-24 19:57:39.540249: step 59600, total loss = 0.66, batch loss = 0.39 (356.0 examples/sec; 0.022 sec/batch; 0h:52m:23s remains)
INFO - root - 2022-02-24 19:57:39.868485: step 59610, total loss = 0.56, batch loss = 0.29 (359.0 examples/sec; 0.022 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 19:57:40.196702: step 59620, total loss = 0.52, batch loss = 0.25 (152.3 examples/sec; 0.053 sec/batch; 2h:02m:25s remains)
INFO - root - 2022-02-24 19:57:40.547274: step 59630, total loss = 0.63, batch loss = 0.35 (289.2 examples/sec; 0.028 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 19:57:40.896312: step 59640, total loss = 0.54, batch loss = 0.27 (172.7 examples/sec; 0.046 sec/batch; 1h:47m:58s remains)
INFO - root - 2022-02-24 19:57:41.309248: step 59650, total loss = 0.56, batch loss = 0.29 (171.8 examples/sec; 0.047 sec/batch; 1h:48m:30s remains)
INFO - root - 2022-02-24 19:57:41.636804: step 59660, total loss = 0.56, batch loss = 0.29 (363.5 examples/sec; 0.022 sec/batch; 0h:51m:17s remains)
INFO - root - 2022-02-24 19:57:41.908829: step 59670, total loss = 0.57, batch loss = 0.29 (340.1 examples/sec; 0.024 sec/batch; 0h:54m:49s remains)
INFO - root - 2022-02-24 19:57:42.246895: step 59680, total loss = 0.74, batch loss = 0.47 (184.7 examples/sec; 0.043 sec/batch; 1h:40m:57s remains)
INFO - root - 2022-02-24 19:57:42.604713: step 59690, total loss = 0.53, batch loss = 0.26 (139.0 examples/sec; 0.058 sec/batch; 2h:14m:07s remains)
INFO - root - 2022-02-24 19:57:43.096302: step 59700, total loss = 0.55, batch loss = 0.27 (162.0 examples/sec; 0.049 sec/batch; 1h:55m:04s remains)
INFO - root - 2022-02-24 19:57:43.550350: step 59710, total loss = 0.53, batch loss = 0.25 (189.6 examples/sec; 0.042 sec/batch; 1h:38m:19s remains)
INFO - root - 2022-02-24 19:57:43.860612: step 59720, total loss = 0.58, batch loss = 0.30 (158.7 examples/sec; 0.050 sec/batch; 1h:57m:24s remains)
INFO - root - 2022-02-24 19:57:44.185741: step 59730, total loss = 0.64, batch loss = 0.36 (208.7 examples/sec; 0.038 sec/batch; 1h:29m:18s remains)
INFO - root - 2022-02-24 19:57:44.643815: step 59740, total loss = 0.60, batch loss = 0.33 (346.6 examples/sec; 0.023 sec/batch; 0h:53m:46s remains)
INFO - root - 2022-02-24 19:57:45.102373: step 59750, total loss = 0.56, batch loss = 0.29 (282.9 examples/sec; 0.028 sec/batch; 1h:05m:51s remains)
INFO - root - 2022-02-24 19:57:45.917737: step 59760, total loss = 0.54, batch loss = 0.27 (238.3 examples/sec; 0.034 sec/batch; 1h:18m:11s remains)
INFO - root - 2022-02-24 19:57:46.270250: step 59770, total loss = 0.58, batch loss = 0.31 (266.3 examples/sec; 0.030 sec/batch; 1h:09m:57s remains)
INFO - root - 2022-02-24 19:57:46.583727: step 59780, total loss = 0.75, batch loss = 0.48 (177.9 examples/sec; 0.045 sec/batch; 1h:44m:42s remains)
INFO - root - 2022-02-24 19:57:46.953592: step 59790, total loss = 0.46, batch loss = 0.18 (340.3 examples/sec; 0.024 sec/batch; 0h:54m:44s remains)
INFO - root - 2022-02-24 19:57:47.384946: step 59800, total loss = 0.63, batch loss = 0.35 (361.2 examples/sec; 0.022 sec/batch; 0h:51m:34s remains)
INFO - root - 2022-02-24 19:57:48.347634: step 59810, total loss = 0.63, batch loss = 0.36 (330.9 examples/sec; 0.024 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 19:57:48.577159: step 59820, total loss = 0.69, batch loss = 0.42 (372.4 examples/sec; 0.021 sec/batch; 0h:50m:00s remains)
INFO - root - 2022-02-24 19:57:48.813123: step 59830, total loss = 0.58, batch loss = 0.30 (323.3 examples/sec; 0.025 sec/batch; 0h:57m:35s remains)
INFO - root - 2022-02-24 19:57:49.048280: step 59840, total loss = 0.58, batch loss = 0.30 (334.7 examples/sec; 0.024 sec/batch; 0h:55m:38s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-59849 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-59849 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 19:57:49.803858: step 59850, total loss = 0.56, batch loss = 0.28 (331.9 examples/sec; 0.024 sec/batch; 0h:56m:06s remains)
INFO - root - 2022-02-24 19:57:50.028127: step 59860, total loss = 0.51, batch loss = 0.24 (360.7 examples/sec; 0.022 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 19:57:50.260407: step 59870, total loss = 0.59, batch loss = 0.32 (311.3 examples/sec; 0.026 sec/batch; 0h:59m:48s remains)
INFO - root - 2022-02-24 19:57:50.583717: step 59880, total loss = 0.51, batch loss = 0.23 (291.4 examples/sec; 0.027 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 19:57:51.213268: step 59890, total loss = 0.68, batch loss = 0.41 (234.1 examples/sec; 0.034 sec/batch; 1h:19m:30s remains)
INFO - root - 2022-02-24 19:57:51.625977: step 59900, total loss = 0.51, batch loss = 0.24 (137.0 examples/sec; 0.058 sec/batch; 2h:15m:52s remains)
INFO - root - 2022-02-24 19:57:52.026778: step 59910, total loss = 0.54, batch loss = 0.27 (168.1 examples/sec; 0.048 sec/batch; 1h:50m:41s remains)
INFO - root - 2022-02-24 19:57:52.399554: step 59920, total loss = 0.56, batch loss = 0.29 (223.0 examples/sec; 0.036 sec/batch; 1h:23m:27s remains)
INFO - root - 2022-02-24 19:57:52.703304: step 59930, total loss = 0.55, batch loss = 0.28 (325.8 examples/sec; 0.025 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 19:57:53.030592: step 59940, total loss = 0.61, batch loss = 0.33 (333.9 examples/sec; 0.024 sec/batch; 0h:55m:43s remains)
INFO - root - 2022-02-24 19:57:53.408616: step 59950, total loss = 0.51, batch loss = 0.24 (230.1 examples/sec; 0.035 sec/batch; 1h:20m:51s remains)
INFO - root - 2022-02-24 19:57:53.816316: step 59960, total loss = 0.53, batch loss = 0.26 (344.3 examples/sec; 0.023 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 19:57:54.235299: step 59970, total loss = 0.54, batch loss = 0.27 (285.3 examples/sec; 0.028 sec/batch; 1h:05m:11s remains)
INFO - root - 2022-02-24 19:57:54.544755: step 59980, total loss = 0.66, batch loss = 0.39 (277.4 examples/sec; 0.029 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 19:57:54.893267: step 59990, total loss = 0.54, batch loss = 0.27 (368.2 examples/sec; 0.022 sec/batch; 0h:50m:31s remains)
INFO - root - 2022-02-24 19:57:55.198302: step 60000, total loss = 0.69, batch loss = 0.42 (315.4 examples/sec; 0.025 sec/batch; 0h:58m:58s remains)
INFO - root - 2022-02-24 19:57:55.588464: step 60010, total loss = 0.53, batch loss = 0.26 (256.7 examples/sec; 0.031 sec/batch; 1h:12m:26s remains)
INFO - root - 2022-02-24 19:57:56.083990: step 60020, total loss = 0.56, batch loss = 0.29 (246.1 examples/sec; 0.033 sec/batch; 1h:15m:34s remains)
INFO - root - 2022-02-24 19:57:56.408409: step 60030, total loss = 0.70, batch loss = 0.42 (252.0 examples/sec; 0.032 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 19:57:56.794263: step 60040, total loss = 0.58, batch loss = 0.30 (220.6 examples/sec; 0.036 sec/batch; 1h:24m:17s remains)
INFO - root - 2022-02-24 19:57:57.061615: step 60050, total loss = 0.53, batch loss = 0.26 (334.7 examples/sec; 0.024 sec/batch; 0h:55m:33s remains)
INFO - root - 2022-02-24 19:57:57.369189: step 60060, total loss = 0.58, batch loss = 0.31 (224.7 examples/sec; 0.036 sec/batch; 1h:22m:45s remains)
INFO - root - 2022-02-24 19:57:57.823212: step 60070, total loss = 0.61, batch loss = 0.33 (248.0 examples/sec; 0.032 sec/batch; 1h:14m:57s remains)
INFO - root - 2022-02-24 19:57:58.292478: step 60080, total loss = 0.52, batch loss = 0.25 (103.3 examples/sec; 0.077 sec/batch; 2h:59m:55s remains)
INFO - root - 2022-02-24 19:57:58.638801: step 60090, total loss = 0.68, batch loss = 0.41 (298.9 examples/sec; 0.027 sec/batch; 1h:02m:10s remains)
INFO - root - 2022-02-24 19:57:58.986333: step 60100, total loss = 0.54, batch loss = 0.27 (242.8 examples/sec; 0.033 sec/batch; 1h:16m:32s remains)
INFO - root - 2022-02-24 19:57:59.402658: step 60110, total loss = 0.57, batch loss = 0.30 (320.5 examples/sec; 0.025 sec/batch; 0h:57m:59s remains)
INFO - root - 2022-02-24 19:57:59.798716: step 60120, total loss = 0.70, batch loss = 0.43 (361.6 examples/sec; 0.022 sec/batch; 0h:51m:23s remains)
INFO - root - 2022-02-24 19:58:00.166523: step 60130, total loss = 0.56, batch loss = 0.29 (236.8 examples/sec; 0.034 sec/batch; 1h:18m:28s remains)
INFO - root - 2022-02-24 19:58:00.566814: step 60140, total loss = 0.58, batch loss = 0.31 (338.2 examples/sec; 0.024 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 19:58:00.806285: step 60150, total loss = 0.68, batch loss = 0.41 (333.0 examples/sec; 0.024 sec/batch; 0h:55m:48s remains)
INFO - root - 2022-02-24 19:58:01.178525: step 60160, total loss = 0.52, batch loss = 0.24 (173.8 examples/sec; 0.046 sec/batch; 1h:46m:55s remains)
INFO - root - 2022-02-24 19:58:01.524917: step 60170, total loss = 0.51, batch loss = 0.24 (236.8 examples/sec; 0.034 sec/batch; 1h:18m:26s remains)
INFO - root - 2022-02-24 19:58:01.894806: step 60180, total loss = 0.57, batch loss = 0.30 (300.0 examples/sec; 0.027 sec/batch; 1h:01m:55s remains)
INFO - root - 2022-02-24 19:58:02.300019: step 60190, total loss = 0.55, batch loss = 0.28 (315.7 examples/sec; 0.025 sec/batch; 0h:58m:50s remains)
INFO - root - 2022-02-24 19:58:02.592757: step 60200, total loss = 0.56, batch loss = 0.29 (348.0 examples/sec; 0.023 sec/batch; 0h:53m:22s remains)
INFO - root - 2022-02-24 19:58:02.978304: step 60210, total loss = 0.58, batch loss = 0.31 (299.1 examples/sec; 0.027 sec/batch; 1h:02m:05s remains)
INFO - root - 2022-02-24 19:58:03.235841: step 60220, total loss = 0.53, batch loss = 0.25 (178.6 examples/sec; 0.045 sec/batch; 1h:44m:00s remains)
INFO - root - 2022-02-24 19:58:03.604272: step 60230, total loss = 0.60, batch loss = 0.32 (192.9 examples/sec; 0.041 sec/batch; 1h:36m:16s remains)
INFO - root - 2022-02-24 19:58:04.032319: step 60240, total loss = 0.54, batch loss = 0.27 (228.8 examples/sec; 0.035 sec/batch; 1h:21m:08s remains)
INFO - root - 2022-02-24 19:58:04.351417: step 60250, total loss = 0.61, batch loss = 0.33 (228.0 examples/sec; 0.035 sec/batch; 1h:21m:25s remains)
INFO - root - 2022-02-24 19:58:04.712734: step 60260, total loss = 0.58, batch loss = 0.30 (329.1 examples/sec; 0.024 sec/batch; 0h:56m:24s remains)
INFO - root - 2022-02-24 19:58:05.053802: step 60270, total loss = 0.63, batch loss = 0.36 (291.8 examples/sec; 0.027 sec/batch; 1h:03m:36s remains)
INFO - root - 2022-02-24 19:58:05.358340: step 60280, total loss = 0.55, batch loss = 0.28 (317.9 examples/sec; 0.025 sec/batch; 0h:58m:23s remains)
INFO - root - 2022-02-24 19:58:05.712425: step 60290, total loss = 0.50, batch loss = 0.22 (225.9 examples/sec; 0.035 sec/batch; 1h:22m:09s remains)
INFO - root - 2022-02-24 19:58:06.113431: step 60300, total loss = 0.69, batch loss = 0.42 (282.6 examples/sec; 0.028 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 19:58:06.565402: step 60310, total loss = 0.62, batch loss = 0.35 (255.1 examples/sec; 0.031 sec/batch; 1h:12m:44s remains)
INFO - root - 2022-02-24 19:58:06.927300: step 60320, total loss = 0.58, batch loss = 0.31 (233.0 examples/sec; 0.034 sec/batch; 1h:19m:38s remains)
INFO - root - 2022-02-24 19:58:07.204994: step 60330, total loss = 0.49, batch loss = 0.22 (341.0 examples/sec; 0.023 sec/batch; 0h:54m:24s remains)
INFO - root - 2022-02-24 19:58:07.530083: step 60340, total loss = 0.54, batch loss = 0.26 (218.1 examples/sec; 0.037 sec/batch; 1h:25m:05s remains)
INFO - root - 2022-02-24 19:58:08.053633: step 60350, total loss = 0.55, batch loss = 0.28 (230.6 examples/sec; 0.035 sec/batch; 1h:20m:28s remains)
INFO - root - 2022-02-24 19:58:08.603815: step 60360, total loss = 0.55, batch loss = 0.28 (186.5 examples/sec; 0.043 sec/batch; 1h:39m:28s remains)
INFO - root - 2022-02-24 19:58:08.999826: step 60370, total loss = 0.56, batch loss = 0.29 (336.9 examples/sec; 0.024 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 19:58:09.328223: step 60380, total loss = 0.62, batch loss = 0.34 (268.4 examples/sec; 0.030 sec/batch; 1h:09m:06s remains)
INFO - root - 2022-02-24 19:58:09.712942: step 60390, total loss = 0.55, batch loss = 0.28 (214.0 examples/sec; 0.037 sec/batch; 1h:26m:41s remains)
INFO - root - 2022-02-24 19:58:10.172343: step 60400, total loss = 0.63, batch loss = 0.36 (311.6 examples/sec; 0.026 sec/batch; 0h:59m:30s remains)
INFO - root - 2022-02-24 19:58:10.663347: step 60410, total loss = 0.64, batch loss = 0.37 (296.1 examples/sec; 0.027 sec/batch; 1h:02m:38s remains)
INFO - root - 2022-02-24 19:58:11.500136: step 60420, total loss = 0.59, batch loss = 0.31 (230.4 examples/sec; 0.035 sec/batch; 1h:20m:28s remains)
INFO - root - 2022-02-24 19:58:11.844553: step 60430, total loss = 0.64, batch loss = 0.37 (303.7 examples/sec; 0.026 sec/batch; 1h:01m:02s remains)
INFO - root - 2022-02-24 19:58:12.155753: step 60440, total loss = 0.61, batch loss = 0.33 (236.1 examples/sec; 0.034 sec/batch; 1h:18m:32s remains)
INFO - root - 2022-02-24 19:58:12.532494: step 60450, total loss = 0.61, batch loss = 0.33 (309.2 examples/sec; 0.026 sec/batch; 0h:59m:57s remains)
INFO - root - 2022-02-24 19:58:12.945204: step 60460, total loss = 0.55, batch loss = 0.28 (256.9 examples/sec; 0.031 sec/batch; 1h:12m:10s remains)
INFO - root - 2022-02-24 19:58:13.446618: step 60470, total loss = 0.54, batch loss = 0.27 (130.1 examples/sec; 0.061 sec/batch; 2h:22m:27s remains)
INFO - root - 2022-02-24 19:58:13.832777: step 60480, total loss = 0.53, batch loss = 0.25 (237.8 examples/sec; 0.034 sec/batch; 1h:17m:56s remains)
INFO - root - 2022-02-24 19:58:14.263858: step 60490, total loss = 0.49, batch loss = 0.22 (209.3 examples/sec; 0.038 sec/batch; 1h:28m:33s remains)
INFO - root - 2022-02-24 19:58:14.635691: step 60500, total loss = 0.58, batch loss = 0.31 (118.2 examples/sec; 0.068 sec/batch; 2h:36m:47s remains)
INFO - root - 2022-02-24 19:58:15.130476: step 60510, total loss = 0.53, batch loss = 0.26 (168.7 examples/sec; 0.047 sec/batch; 1h:49m:49s remains)
INFO - root - 2022-02-24 19:58:15.536503: step 60520, total loss = 0.66, batch loss = 0.38 (177.4 examples/sec; 0.045 sec/batch; 1h:44m:28s remains)
INFO - root - 2022-02-24 19:58:16.150564: step 60530, total loss = 0.59, batch loss = 0.32 (359.6 examples/sec; 0.022 sec/batch; 0h:51m:32s remains)
INFO - root - 2022-02-24 19:58:16.490670: step 60540, total loss = 0.58, batch loss = 0.31 (341.4 examples/sec; 0.023 sec/batch; 0h:54m:16s remains)
INFO - root - 2022-02-24 19:58:16.852043: step 60550, total loss = 0.58, batch loss = 0.31 (151.3 examples/sec; 0.053 sec/batch; 2h:02m:26s remains)
INFO - root - 2022-02-24 19:58:17.214854: step 60560, total loss = 0.55, batch loss = 0.27 (376.4 examples/sec; 0.021 sec/batch; 0h:49m:13s remains)
INFO - root - 2022-02-24 19:58:17.609901: step 60570, total loss = 0.58, batch loss = 0.31 (303.9 examples/sec; 0.026 sec/batch; 1h:00m:56s remains)
INFO - root - 2022-02-24 19:58:18.101726: step 60580, total loss = 0.65, batch loss = 0.38 (301.2 examples/sec; 0.027 sec/batch; 1h:01m:29s remains)
INFO - root - 2022-02-24 19:58:18.495249: step 60590, total loss = 0.56, batch loss = 0.29 (196.8 examples/sec; 0.041 sec/batch; 1h:34m:06s remains)
INFO - root - 2022-02-24 19:58:18.956304: step 60600, total loss = 0.53, batch loss = 0.25 (363.2 examples/sec; 0.022 sec/batch; 0h:50m:59s remains)
INFO - root - 2022-02-24 19:58:19.388462: step 60610, total loss = 0.51, batch loss = 0.23 (336.4 examples/sec; 0.024 sec/batch; 0h:55m:02s remains)
INFO - root - 2022-02-24 19:58:19.831061: step 60620, total loss = 0.51, batch loss = 0.24 (123.8 examples/sec; 0.065 sec/batch; 2h:29m:31s remains)
INFO - root - 2022-02-24 19:58:20.268392: step 60630, total loss = 0.58, batch loss = 0.31 (198.8 examples/sec; 0.040 sec/batch; 1h:33m:07s remains)
INFO - root - 2022-02-24 19:58:20.735351: step 60640, total loss = 0.57, batch loss = 0.29 (131.2 examples/sec; 0.061 sec/batch; 2h:21m:08s remains)
INFO - root - 2022-02-24 19:58:21.004467: step 60650, total loss = 0.52, batch loss = 0.25 (206.1 examples/sec; 0.039 sec/batch; 1h:29m:49s remains)
INFO - root - 2022-02-24 19:58:21.490249: step 60660, total loss = 0.62, batch loss = 0.35 (283.7 examples/sec; 0.028 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 19:58:21.906800: step 60670, total loss = 0.72, batch loss = 0.45 (268.2 examples/sec; 0.030 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 19:58:22.202149: step 60680, total loss = 0.57, batch loss = 0.29 (247.3 examples/sec; 0.032 sec/batch; 1h:14m:50s remains)
INFO - root - 2022-02-24 19:58:22.488626: step 60690, total loss = 0.56, batch loss = 0.29 (257.3 examples/sec; 0.031 sec/batch; 1h:11m:56s remains)
INFO - root - 2022-02-24 19:58:22.813691: step 60700, total loss = 0.56, batch loss = 0.29 (341.7 examples/sec; 0.023 sec/batch; 0h:54m:09s remains)
INFO - root - 2022-02-24 19:58:23.191988: step 60710, total loss = 0.78, batch loss = 0.50 (320.0 examples/sec; 0.025 sec/batch; 0h:57m:49s remains)
INFO - root - 2022-02-24 19:58:23.534584: step 60720, total loss = 0.60, batch loss = 0.33 (237.1 examples/sec; 0.034 sec/batch; 1h:18m:02s remains)
INFO - root - 2022-02-24 19:58:23.914112: step 60730, total loss = 0.60, batch loss = 0.32 (263.3 examples/sec; 0.030 sec/batch; 1h:10m:15s remains)
INFO - root - 2022-02-24 19:58:24.265060: step 60740, total loss = 0.58, batch loss = 0.31 (322.3 examples/sec; 0.025 sec/batch; 0h:57m:24s remains)
INFO - root - 2022-02-24 19:58:24.578801: step 60750, total loss = 0.59, batch loss = 0.32 (234.7 examples/sec; 0.034 sec/batch; 1h:18m:50s remains)
INFO - root - 2022-02-24 19:58:24.901636: step 60760, total loss = 0.62, batch loss = 0.35 (159.9 examples/sec; 0.050 sec/batch; 1h:55m:42s remains)
INFO - root - 2022-02-24 19:58:25.254305: step 60770, total loss = 0.58, batch loss = 0.30 (312.2 examples/sec; 0.026 sec/batch; 0h:59m:14s remains)
INFO - root - 2022-02-24 19:58:25.721277: step 60780, total loss = 0.60, batch loss = 0.33 (83.4 examples/sec; 0.096 sec/batch; 3h:41m:47s remains)
INFO - root - 2022-02-24 19:58:26.142035: step 60790, total loss = 0.46, batch loss = 0.19 (298.4 examples/sec; 0.027 sec/batch; 1h:01m:58s remains)
INFO - root - 2022-02-24 19:58:26.578034: step 60800, total loss = 0.51, batch loss = 0.23 (335.0 examples/sec; 0.024 sec/batch; 0h:55m:12s remains)
INFO - root - 2022-02-24 19:58:26.932882: step 60810, total loss = 0.51, batch loss = 0.24 (359.6 examples/sec; 0.022 sec/batch; 0h:51m:25s remains)
INFO - root - 2022-02-24 19:58:27.205492: step 60820, total loss = 0.58, batch loss = 0.31 (199.3 examples/sec; 0.040 sec/batch; 1h:32m:45s remains)
INFO - root - 2022-02-24 19:58:27.588344: step 60830, total loss = 0.60, batch loss = 0.33 (221.1 examples/sec; 0.036 sec/batch; 1h:23m:37s remains)
INFO - root - 2022-02-24 19:58:27.924833: step 60840, total loss = 0.59, batch loss = 0.32 (231.2 examples/sec; 0.035 sec/batch; 1h:19m:58s remains)
INFO - root - 2022-02-24 19:58:28.293249: step 60850, total loss = 0.53, batch loss = 0.26 (108.1 examples/sec; 0.074 sec/batch; 2h:51m:04s remains)
INFO - root - 2022-02-24 19:58:28.625561: step 60860, total loss = 0.61, batch loss = 0.34 (275.4 examples/sec; 0.029 sec/batch; 1h:07m:06s remains)
INFO - root - 2022-02-24 19:58:28.956330: step 60870, total loss = 0.67, batch loss = 0.40 (262.9 examples/sec; 0.030 sec/batch; 1h:10m:19s remains)
INFO - root - 2022-02-24 19:58:29.283641: step 60880, total loss = 0.58, batch loss = 0.31 (268.2 examples/sec; 0.030 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 19:58:29.551150: step 60890, total loss = 0.60, batch loss = 0.33 (305.9 examples/sec; 0.026 sec/batch; 1h:00m:24s remains)
INFO - root - 2022-02-24 19:58:29.892552: step 60900, total loss = 0.63, batch loss = 0.36 (155.0 examples/sec; 0.052 sec/batch; 1h:59m:13s remains)
INFO - root - 2022-02-24 19:58:30.388254: step 60910, total loss = 0.65, batch loss = 0.38 (174.1 examples/sec; 0.046 sec/batch; 1h:46m:06s remains)
INFO - root - 2022-02-24 19:58:30.779660: step 60920, total loss = 0.51, batch loss = 0.24 (226.2 examples/sec; 0.035 sec/batch; 1h:21m:40s remains)
INFO - root - 2022-02-24 19:58:31.104728: step 60930, total loss = 0.52, batch loss = 0.25 (330.1 examples/sec; 0.024 sec/batch; 0h:55m:58s remains)
INFO - root - 2022-02-24 19:58:31.426566: step 60940, total loss = 0.53, batch loss = 0.26 (335.2 examples/sec; 0.024 sec/batch; 0h:55m:06s remains)
INFO - root - 2022-02-24 19:58:31.716698: step 60950, total loss = 0.67, batch loss = 0.40 (319.4 examples/sec; 0.025 sec/batch; 0h:57m:50s remains)
INFO - root - 2022-02-24 19:58:32.042500: step 60960, total loss = 0.52, batch loss = 0.25 (331.8 examples/sec; 0.024 sec/batch; 0h:55m:40s remains)
INFO - root - 2022-02-24 19:58:32.549773: step 60970, total loss = 0.57, batch loss = 0.30 (312.7 examples/sec; 0.026 sec/batch; 0h:59m:04s remains)
INFO - root - 2022-02-24 19:58:32.863906: step 60980, total loss = 0.59, batch loss = 0.32 (346.6 examples/sec; 0.023 sec/batch; 0h:53m:17s remains)
INFO - root - 2022-02-24 19:58:33.179049: step 60990, total loss = 0.54, batch loss = 0.27 (271.0 examples/sec; 0.030 sec/batch; 1h:08m:08s remains)
INFO - root - 2022-02-24 19:58:33.543402: step 61000, total loss = 0.65, batch loss = 0.37 (211.1 examples/sec; 0.038 sec/batch; 1h:27m:29s remains)
INFO - root - 2022-02-24 19:58:34.019384: step 61010, total loss = 0.51, batch loss = 0.24 (302.7 examples/sec; 0.026 sec/batch; 1h:01m:00s remains)
INFO - root - 2022-02-24 19:58:34.407458: step 61020, total loss = 0.57, batch loss = 0.29 (374.0 examples/sec; 0.021 sec/batch; 0h:49m:21s remains)
INFO - root - 2022-02-24 19:58:34.736607: step 61030, total loss = 0.47, batch loss = 0.20 (354.1 examples/sec; 0.023 sec/batch; 0h:52m:08s remains)
INFO - root - 2022-02-24 19:58:35.044981: step 61040, total loss = 0.50, batch loss = 0.23 (334.7 examples/sec; 0.024 sec/batch; 0h:55m:09s remains)
INFO - root - 2022-02-24 19:58:35.341177: step 61050, total loss = 0.58, batch loss = 0.31 (337.4 examples/sec; 0.024 sec/batch; 0h:54m:42s remains)
INFO - root - 2022-02-24 19:58:35.672348: step 61060, total loss = 0.55, batch loss = 0.28 (345.4 examples/sec; 0.023 sec/batch; 0h:53m:26s remains)
INFO - root - 2022-02-24 19:58:36.033798: step 61070, total loss = 0.64, batch loss = 0.37 (83.8 examples/sec; 0.095 sec/batch; 3h:40m:17s remains)
INFO - root - 2022-02-24 19:58:36.507744: step 61080, total loss = 0.55, batch loss = 0.28 (219.7 examples/sec; 0.036 sec/batch; 1h:23m:59s remains)
INFO - root - 2022-02-24 19:58:36.923472: step 61090, total loss = 0.70, batch loss = 0.42 (159.6 examples/sec; 0.050 sec/batch; 1h:55m:37s remains)
INFO - root - 2022-02-24 19:58:37.228528: step 61100, total loss = 0.53, batch loss = 0.25 (347.3 examples/sec; 0.023 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 19:58:37.583336: step 61110, total loss = 0.66, batch loss = 0.38 (332.0 examples/sec; 0.024 sec/batch; 0h:55m:34s remains)
INFO - root - 2022-02-24 19:58:37.899988: step 61120, total loss = 0.53, batch loss = 0.26 (319.5 examples/sec; 0.025 sec/batch; 0h:57m:44s remains)
INFO - root - 2022-02-24 19:58:38.368949: step 61130, total loss = 0.55, batch loss = 0.28 (90.6 examples/sec; 0.088 sec/batch; 3h:23m:39s remains)
INFO - root - 2022-02-24 19:58:38.758258: step 61140, total loss = 0.58, batch loss = 0.31 (319.9 examples/sec; 0.025 sec/batch; 0h:57m:39s remains)
INFO - root - 2022-02-24 19:58:39.300315: step 61150, total loss = 0.61, batch loss = 0.33 (260.6 examples/sec; 0.031 sec/batch; 1h:10m:46s remains)
INFO - root - 2022-02-24 19:58:39.993765: step 61160, total loss = 0.61, batch loss = 0.33 (243.3 examples/sec; 0.033 sec/batch; 1h:15m:49s remains)
INFO - root - 2022-02-24 19:58:40.645923: step 61170, total loss = 0.60, batch loss = 0.33 (206.9 examples/sec; 0.039 sec/batch; 1h:29m:07s remains)
INFO - root - 2022-02-24 19:58:41.062773: step 61180, total loss = 0.53, batch loss = 0.26 (203.1 examples/sec; 0.039 sec/batch; 1h:30m:48s remains)
INFO - root - 2022-02-24 19:58:41.385145: step 61190, total loss = 0.67, batch loss = 0.40 (175.3 examples/sec; 0.046 sec/batch; 1h:45m:10s remains)
INFO - root - 2022-02-24 19:58:42.109377: step 61200, total loss = 0.50, batch loss = 0.23 (197.6 examples/sec; 0.040 sec/batch; 1h:33m:20s remains)
INFO - root - 2022-02-24 19:58:42.592886: step 61210, total loss = 0.51, batch loss = 0.23 (173.4 examples/sec; 0.046 sec/batch; 1h:46m:21s remains)
INFO - root - 2022-02-24 19:58:43.087961: step 61220, total loss = 0.59, batch loss = 0.32 (114.3 examples/sec; 0.070 sec/batch; 2h:41m:16s remains)
INFO - root - 2022-02-24 19:58:43.430616: step 61230, total loss = 0.64, batch loss = 0.37 (224.0 examples/sec; 0.036 sec/batch; 1h:22m:18s remains)
INFO - root - 2022-02-24 19:58:43.776317: step 61240, total loss = 0.56, batch loss = 0.29 (369.1 examples/sec; 0.022 sec/batch; 0h:49m:56s remains)
INFO - root - 2022-02-24 19:58:44.183298: step 61250, total loss = 0.56, batch loss = 0.28 (226.6 examples/sec; 0.035 sec/batch; 1h:21m:20s remains)
INFO - root - 2022-02-24 19:58:44.590105: step 61260, total loss = 0.44, batch loss = 0.17 (148.3 examples/sec; 0.054 sec/batch; 2h:04m:17s remains)
INFO - root - 2022-02-24 19:58:45.069143: step 61270, total loss = 0.71, batch loss = 0.43 (250.5 examples/sec; 0.032 sec/batch; 1h:13m:33s remains)
INFO - root - 2022-02-24 19:58:45.432656: step 61280, total loss = 0.49, batch loss = 0.22 (204.6 examples/sec; 0.039 sec/batch; 1h:30m:05s remains)
INFO - root - 2022-02-24 19:58:45.757365: step 61290, total loss = 0.65, batch loss = 0.38 (267.3 examples/sec; 0.030 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 19:58:46.131461: step 61300, total loss = 0.60, batch loss = 0.33 (286.3 examples/sec; 0.028 sec/batch; 1h:04m:21s remains)
INFO - root - 2022-02-24 19:58:46.568829: step 61310, total loss = 0.73, batch loss = 0.46 (106.9 examples/sec; 0.075 sec/batch; 2h:52m:17s remains)
INFO - root - 2022-02-24 19:58:47.023206: step 61320, total loss = 0.55, batch loss = 0.28 (322.2 examples/sec; 0.025 sec/batch; 0h:57m:11s remains)
INFO - root - 2022-02-24 19:58:47.381630: step 61330, total loss = 0.65, batch loss = 0.37 (305.4 examples/sec; 0.026 sec/batch; 1h:00m:19s remains)
INFO - root - 2022-02-24 19:58:47.719485: step 61340, total loss = 0.51, batch loss = 0.24 (246.9 examples/sec; 0.032 sec/batch; 1h:14m:36s remains)
INFO - root - 2022-02-24 19:58:48.130799: step 61350, total loss = 0.64, batch loss = 0.37 (166.4 examples/sec; 0.048 sec/batch; 1h:50m:41s remains)
INFO - root - 2022-02-24 19:58:48.522465: step 61360, total loss = 0.59, batch loss = 0.32 (194.9 examples/sec; 0.041 sec/batch; 1h:34m:30s remains)
INFO - root - 2022-02-24 19:58:48.906787: step 61370, total loss = 0.62, batch loss = 0.35 (137.4 examples/sec; 0.058 sec/batch; 2h:14m:05s remains)
INFO - root - 2022-02-24 19:58:49.295639: step 61380, total loss = 0.56, batch loss = 0.29 (348.8 examples/sec; 0.023 sec/batch; 0h:52m:48s remains)
INFO - root - 2022-02-24 19:58:49.655406: step 61390, total loss = 0.64, batch loss = 0.37 (140.0 examples/sec; 0.057 sec/batch; 2h:11m:34s remains)
INFO - root - 2022-02-24 19:58:50.045674: step 61400, total loss = 0.59, batch loss = 0.32 (186.9 examples/sec; 0.043 sec/batch; 1h:38m:29s remains)
INFO - root - 2022-02-24 19:58:50.533155: step 61410, total loss = 0.57, batch loss = 0.30 (348.3 examples/sec; 0.023 sec/batch; 0h:52m:52s remains)
INFO - root - 2022-02-24 19:58:51.002844: step 61420, total loss = 0.57, batch loss = 0.29 (123.4 examples/sec; 0.065 sec/batch; 2h:29m:13s remains)
INFO - root - 2022-02-24 19:58:51.436373: step 61430, total loss = 0.56, batch loss = 0.28 (338.9 examples/sec; 0.024 sec/batch; 0h:54m:18s remains)
INFO - root - 2022-02-24 19:58:51.749929: step 61440, total loss = 0.55, batch loss = 0.28 (260.9 examples/sec; 0.031 sec/batch; 1h:10m:32s remains)
INFO - root - 2022-02-24 19:58:52.059645: step 61450, total loss = 0.50, batch loss = 0.23 (286.6 examples/sec; 0.028 sec/batch; 1h:04m:13s remains)
INFO - root - 2022-02-24 19:58:52.363315: step 61460, total loss = 0.59, batch loss = 0.32 (208.4 examples/sec; 0.038 sec/batch; 1h:28m:19s remains)
INFO - root - 2022-02-24 19:58:52.682824: step 61470, total loss = 0.54, batch loss = 0.26 (304.7 examples/sec; 0.026 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 19:58:53.086171: step 61480, total loss = 0.67, batch loss = 0.40 (174.5 examples/sec; 0.046 sec/batch; 1h:45m:26s remains)
INFO - root - 2022-02-24 19:58:53.446890: step 61490, total loss = 0.59, batch loss = 0.31 (191.8 examples/sec; 0.042 sec/batch; 1h:35m:55s remains)
INFO - root - 2022-02-24 19:58:53.707497: step 61500, total loss = 0.63, batch loss = 0.35 (311.8 examples/sec; 0.026 sec/batch; 0h:59m:00s remains)
INFO - root - 2022-02-24 19:58:54.036267: step 61510, total loss = 0.51, batch loss = 0.24 (339.8 examples/sec; 0.024 sec/batch; 0h:54m:08s remains)
INFO - root - 2022-02-24 19:58:54.366837: step 61520, total loss = 0.59, batch loss = 0.32 (270.2 examples/sec; 0.030 sec/batch; 1h:08m:05s remains)
INFO - root - 2022-02-24 19:58:54.813077: step 61530, total loss = 0.62, batch loss = 0.35 (133.8 examples/sec; 0.060 sec/batch; 2h:17m:28s remains)
INFO - root - 2022-02-24 19:58:55.253263: step 61540, total loss = 0.54, batch loss = 0.27 (327.6 examples/sec; 0.024 sec/batch; 0h:56m:09s remains)
INFO - root - 2022-02-24 19:58:55.589224: step 61550, total loss = 0.52, batch loss = 0.25 (342.1 examples/sec; 0.023 sec/batch; 0h:53m:46s remains)
INFO - root - 2022-02-24 19:58:55.955763: step 61560, total loss = 0.51, batch loss = 0.24 (136.4 examples/sec; 0.059 sec/batch; 2h:14m:50s remains)
INFO - root - 2022-02-24 19:58:56.265772: step 61570, total loss = 0.58, batch loss = 0.31 (305.2 examples/sec; 0.026 sec/batch; 1h:00m:15s remains)
INFO - root - 2022-02-24 19:58:56.658436: step 61580, total loss = 0.67, batch loss = 0.40 (142.8 examples/sec; 0.056 sec/batch; 2h:08m:45s remains)
INFO - root - 2022-02-24 19:58:57.085086: step 61590, total loss = 0.62, batch loss = 0.34 (192.3 examples/sec; 0.042 sec/batch; 1h:35m:38s remains)
INFO - root - 2022-02-24 19:58:57.457616: step 61600, total loss = 0.61, batch loss = 0.34 (339.3 examples/sec; 0.024 sec/batch; 0h:54m:11s remains)
INFO - root - 2022-02-24 19:58:57.863853: step 61610, total loss = 0.59, batch loss = 0.32 (315.3 examples/sec; 0.025 sec/batch; 0h:58m:18s remains)
INFO - root - 2022-02-24 19:58:58.116358: step 61620, total loss = 0.62, batch loss = 0.35 (365.3 examples/sec; 0.022 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 19:58:58.530211: step 61630, total loss = 0.61, batch loss = 0.33 (178.6 examples/sec; 0.045 sec/batch; 1h:42m:56s remains)
INFO - root - 2022-02-24 19:58:59.019331: step 61640, total loss = 0.60, batch loss = 0.33 (69.8 examples/sec; 0.115 sec/batch; 4h:23m:19s remains)
INFO - root - 2022-02-24 19:58:59.387421: step 61650, total loss = 0.71, batch loss = 0.44 (231.5 examples/sec; 0.035 sec/batch; 1h:19m:23s remains)
INFO - root - 2022-02-24 19:58:59.701624: step 61660, total loss = 0.53, batch loss = 0.26 (244.6 examples/sec; 0.033 sec/batch; 1h:15m:08s remains)
INFO - root - 2022-02-24 19:59:00.008029: step 61670, total loss = 0.56, batch loss = 0.29 (320.9 examples/sec; 0.025 sec/batch; 0h:57m:16s remains)
INFO - root - 2022-02-24 19:59:00.332057: step 61680, total loss = 0.61, batch loss = 0.34 (315.3 examples/sec; 0.025 sec/batch; 0h:58m:17s remains)
INFO - root - 2022-02-24 19:59:00.739362: step 61690, total loss = 0.48, batch loss = 0.20 (115.9 examples/sec; 0.069 sec/batch; 2h:38m:30s remains)
INFO - root - 2022-02-24 19:59:01.098419: step 61700, total loss = 0.74, batch loss = 0.47 (210.8 examples/sec; 0.038 sec/batch; 1h:27m:08s remains)
INFO - root - 2022-02-24 19:59:01.480295: step 61710, total loss = 0.49, batch loss = 0.22 (235.7 examples/sec; 0.034 sec/batch; 1h:17m:55s remains)
INFO - root - 2022-02-24 19:59:01.873704: step 61720, total loss = 0.58, batch loss = 0.31 (162.9 examples/sec; 0.049 sec/batch; 1h:52m:47s remains)
INFO - root - 2022-02-24 19:59:02.236441: step 61730, total loss = 0.52, batch loss = 0.25 (350.2 examples/sec; 0.023 sec/batch; 0h:52m:27s remains)
INFO - root - 2022-02-24 19:59:02.803462: step 61740, total loss = 0.60, batch loss = 0.33 (94.8 examples/sec; 0.084 sec/batch; 3h:13m:44s remains)
INFO - root - 2022-02-24 19:59:03.297653: step 61750, total loss = 0.72, batch loss = 0.45 (139.1 examples/sec; 0.057 sec/batch; 2h:12m:00s remains)
INFO - root - 2022-02-24 19:59:03.787460: step 61760, total loss = 0.57, batch loss = 0.30 (180.7 examples/sec; 0.044 sec/batch; 1h:41m:37s remains)
INFO - root - 2022-02-24 19:59:04.223295: step 61770, total loss = 0.56, batch loss = 0.29 (226.7 examples/sec; 0.035 sec/batch; 1h:21m:01s remains)
INFO - root - 2022-02-24 19:59:04.722280: step 61780, total loss = 0.56, batch loss = 0.28 (210.5 examples/sec; 0.038 sec/batch; 1h:27m:14s remains)
INFO - root - 2022-02-24 19:59:05.141620: step 61790, total loss = 0.60, batch loss = 0.33 (181.0 examples/sec; 0.044 sec/batch; 1h:41m:27s remains)
INFO - root - 2022-02-24 19:59:05.753801: step 61800, total loss = 0.50, batch loss = 0.23 (124.6 examples/sec; 0.064 sec/batch; 2h:27m:21s remains)
INFO - root - 2022-02-24 19:59:06.242786: step 61810, total loss = 0.57, batch loss = 0.30 (260.0 examples/sec; 0.031 sec/batch; 1h:10m:36s remains)
INFO - root - 2022-02-24 19:59:07.109527: step 61820, total loss = 0.50, batch loss = 0.23 (223.7 examples/sec; 0.036 sec/batch; 1h:22m:04s remains)
INFO - root - 2022-02-24 19:59:07.585812: step 61830, total loss = 0.53, batch loss = 0.26 (127.2 examples/sec; 0.063 sec/batch; 2h:24m:21s remains)
INFO - root - 2022-02-24 19:59:08.006502: step 61840, total loss = 0.68, batch loss = 0.41 (306.7 examples/sec; 0.026 sec/batch; 0h:59m:51s remains)
INFO - root - 2022-02-24 19:59:08.344805: step 61850, total loss = 0.53, batch loss = 0.26 (307.0 examples/sec; 0.026 sec/batch; 0h:59m:46s remains)
INFO - root - 2022-02-24 19:59:08.675364: step 61860, total loss = 0.60, batch loss = 0.33 (233.6 examples/sec; 0.034 sec/batch; 1h:18m:32s remains)
INFO - root - 2022-02-24 19:59:09.028990: step 61870, total loss = 0.56, batch loss = 0.29 (300.3 examples/sec; 0.027 sec/batch; 1h:01m:06s remains)
INFO - root - 2022-02-24 19:59:09.474831: step 61880, total loss = 0.49, batch loss = 0.22 (233.4 examples/sec; 0.034 sec/batch; 1h:18m:37s remains)
INFO - root - 2022-02-24 19:59:09.974501: step 61890, total loss = 0.65, batch loss = 0.38 (208.3 examples/sec; 0.038 sec/batch; 1h:28m:04s remains)
INFO - root - 2022-02-24 19:59:10.289212: step 61900, total loss = 0.73, batch loss = 0.45 (344.5 examples/sec; 0.023 sec/batch; 0h:53m:15s remains)
INFO - root - 2022-02-24 19:59:10.635498: step 61910, total loss = 0.57, batch loss = 0.30 (330.5 examples/sec; 0.024 sec/batch; 0h:55m:30s remains)
INFO - root - 2022-02-24 19:59:11.044432: step 61920, total loss = 0.53, batch loss = 0.26 (84.5 examples/sec; 0.095 sec/batch; 3h:37m:02s remains)
INFO - root - 2022-02-24 19:59:11.502983: step 61930, total loss = 0.61, batch loss = 0.33 (148.4 examples/sec; 0.054 sec/batch; 2h:03m:36s remains)
INFO - root - 2022-02-24 19:59:11.941889: step 61940, total loss = 0.53, batch loss = 0.25 (216.1 examples/sec; 0.037 sec/batch; 1h:24m:52s remains)
INFO - root - 2022-02-24 19:59:12.347353: step 61950, total loss = 0.53, batch loss = 0.26 (294.6 examples/sec; 0.027 sec/batch; 1h:02m:14s remains)
INFO - root - 2022-02-24 19:59:12.647452: step 61960, total loss = 0.52, batch loss = 0.25 (236.0 examples/sec; 0.034 sec/batch; 1h:17m:42s remains)
INFO - root - 2022-02-24 19:59:12.947391: step 61970, total loss = 0.55, batch loss = 0.28 (155.4 examples/sec; 0.051 sec/batch; 1h:57m:59s remains)
INFO - root - 2022-02-24 19:59:13.367875: step 61980, total loss = 0.43, batch loss = 0.16 (289.7 examples/sec; 0.028 sec/batch; 1h:03m:17s remains)
INFO - root - 2022-02-24 19:59:13.798610: step 61990, total loss = 0.51, batch loss = 0.24 (204.1 examples/sec; 0.039 sec/batch; 1h:29m:50s remains)
INFO - root - 2022-02-24 19:59:14.204136: step 62000, total loss = 0.56, batch loss = 0.29 (304.0 examples/sec; 0.026 sec/batch; 1h:00m:18s remains)
INFO - root - 2022-02-24 19:59:14.561200: step 62010, total loss = 0.69, batch loss = 0.42 (302.4 examples/sec; 0.026 sec/batch; 1h:00m:37s remains)
INFO - root - 2022-02-24 19:59:14.857923: step 62020, total loss = 0.60, batch loss = 0.33 (285.3 examples/sec; 0.028 sec/batch; 1h:04m:15s remains)
INFO - root - 2022-02-24 19:59:15.111243: step 62030, total loss = 0.55, batch loss = 0.27 (321.1 examples/sec; 0.025 sec/batch; 0h:57m:04s remains)
INFO - root - 2022-02-24 19:59:15.525232: step 62040, total loss = 0.55, batch loss = 0.28 (115.3 examples/sec; 0.069 sec/batch; 2h:38m:57s remains)
INFO - root - 2022-02-24 19:59:15.915981: step 62050, total loss = 0.63, batch loss = 0.35 (277.6 examples/sec; 0.029 sec/batch; 1h:06m:00s remains)
INFO - root - 2022-02-24 19:59:16.183120: step 62060, total loss = 0.62, batch loss = 0.35 (261.3 examples/sec; 0.031 sec/batch; 1h:10m:07s remains)
INFO - root - 2022-02-24 19:59:16.514374: step 62070, total loss = 0.54, batch loss = 0.27 (220.9 examples/sec; 0.036 sec/batch; 1h:22m:56s remains)
INFO - root - 2022-02-24 19:59:16.838460: step 62080, total loss = 0.46, batch loss = 0.19 (177.8 examples/sec; 0.045 sec/batch; 1h:43m:02s remains)
INFO - root - 2022-02-24 19:59:17.285233: step 62090, total loss = 0.60, batch loss = 0.33 (135.3 examples/sec; 0.059 sec/batch; 2h:15m:27s remains)
INFO - root - 2022-02-24 19:59:17.614787: step 62100, total loss = 0.68, batch loss = 0.40 (335.4 examples/sec; 0.024 sec/batch; 0h:54m:37s remains)
INFO - root - 2022-02-24 19:59:18.032064: step 62110, total loss = 0.74, batch loss = 0.47 (171.4 examples/sec; 0.047 sec/batch; 1h:46m:54s remains)
INFO - root - 2022-02-24 19:59:18.368416: step 62120, total loss = 0.59, batch loss = 0.31 (199.8 examples/sec; 0.040 sec/batch; 1h:31m:40s remains)
INFO - root - 2022-02-24 19:59:18.686627: step 62130, total loss = 0.51, batch loss = 0.24 (199.6 examples/sec; 0.040 sec/batch; 1h:31m:45s remains)
INFO - root - 2022-02-24 19:59:19.001216: step 62140, total loss = 0.58, batch loss = 0.31 (346.0 examples/sec; 0.023 sec/batch; 0h:52m:56s remains)
INFO - root - 2022-02-24 19:59:19.413370: step 62150, total loss = 0.60, batch loss = 0.32 (341.4 examples/sec; 0.023 sec/batch; 0h:53m:38s remains)
INFO - root - 2022-02-24 19:59:19.839514: step 62160, total loss = 0.52, batch loss = 0.24 (197.3 examples/sec; 0.041 sec/batch; 1h:32m:48s remains)
INFO - root - 2022-02-24 19:59:20.253689: step 62170, total loss = 0.62, batch loss = 0.35 (269.1 examples/sec; 0.030 sec/batch; 1h:08m:03s remains)
INFO - root - 2022-02-24 19:59:20.583999: step 62180, total loss = 0.56, batch loss = 0.28 (330.3 examples/sec; 0.024 sec/batch; 0h:55m:26s remains)
INFO - root - 2022-02-24 19:59:20.850005: step 62190, total loss = 0.59, batch loss = 0.32 (361.5 examples/sec; 0.022 sec/batch; 0h:50m:38s remains)
INFO - root - 2022-02-24 19:59:21.197810: step 62200, total loss = 0.57, batch loss = 0.30 (300.4 examples/sec; 0.027 sec/batch; 1h:00m:55s remains)
INFO - root - 2022-02-24 19:59:21.671576: step 62210, total loss = 0.60, batch loss = 0.33 (98.1 examples/sec; 0.082 sec/batch; 3h:06m:30s remains)
INFO - root - 2022-02-24 19:59:22.109156: step 62220, total loss = 0.63, batch loss = 0.36 (261.9 examples/sec; 0.031 sec/batch; 1h:09m:53s remains)
INFO - root - 2022-02-24 19:59:22.516000: step 62230, total loss = 0.51, batch loss = 0.24 (133.9 examples/sec; 0.060 sec/batch; 2h:16m:38s remains)
INFO - root - 2022-02-24 19:59:23.042567: step 62240, total loss = 0.49, batch loss = 0.22 (97.5 examples/sec; 0.082 sec/batch; 3h:07m:40s remains)
INFO - root - 2022-02-24 19:59:23.533243: step 62250, total loss = 0.59, batch loss = 0.32 (198.5 examples/sec; 0.040 sec/batch; 1h:32m:11s remains)
INFO - root - 2022-02-24 19:59:24.073103: step 62260, total loss = 0.62, batch loss = 0.35 (344.6 examples/sec; 0.023 sec/batch; 0h:53m:06s remains)
INFO - root - 2022-02-24 19:59:24.612205: step 62270, total loss = 0.64, batch loss = 0.37 (315.8 examples/sec; 0.025 sec/batch; 0h:57m:56s remains)
INFO - root - 2022-02-24 19:59:25.047275: step 62280, total loss = 0.60, batch loss = 0.32 (220.2 examples/sec; 0.036 sec/batch; 1h:23m:04s remains)
INFO - root - 2022-02-24 19:59:25.377805: step 62290, total loss = 0.67, batch loss = 0.40 (229.3 examples/sec; 0.035 sec/batch; 1h:19m:46s remains)
INFO - root - 2022-02-24 19:59:25.748158: step 62300, total loss = 0.57, batch loss = 0.30 (218.9 examples/sec; 0.037 sec/batch; 1h:23m:33s remains)
INFO - root - 2022-02-24 19:59:26.242544: step 62310, total loss = 0.52, batch loss = 0.25 (253.9 examples/sec; 0.032 sec/batch; 1h:12m:03s remains)
INFO - root - 2022-02-24 19:59:26.635434: step 62320, total loss = 0.57, batch loss = 0.30 (187.5 examples/sec; 0.043 sec/batch; 1h:37m:34s remains)
INFO - root - 2022-02-24 19:59:27.358909: step 62330, total loss = 0.46, batch loss = 0.19 (386.9 examples/sec; 0.021 sec/batch; 0h:47m:16s remains)
INFO - root - 2022-02-24 19:59:27.708926: step 62340, total loss = 0.54, batch loss = 0.26 (289.4 examples/sec; 0.028 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 19:59:28.066674: step 62350, total loss = 0.59, batch loss = 0.31 (329.7 examples/sec; 0.024 sec/batch; 0h:55m:28s remains)
INFO - root - 2022-02-24 19:59:28.465618: step 62360, total loss = 0.49, batch loss = 0.22 (267.9 examples/sec; 0.030 sec/batch; 1h:08m:15s remains)
INFO - root - 2022-02-24 19:59:28.820362: step 62370, total loss = 0.47, batch loss = 0.20 (202.6 examples/sec; 0.039 sec/batch; 1h:30m:14s remains)
INFO - root - 2022-02-24 19:59:29.237321: step 62380, total loss = 0.61, batch loss = 0.34 (99.2 examples/sec; 0.081 sec/batch; 3h:04m:21s remains)
INFO - root - 2022-02-24 19:59:29.575308: step 62390, total loss = 0.56, batch loss = 0.29 (244.0 examples/sec; 0.033 sec/batch; 1h:14m:55s remains)
INFO - root - 2022-02-24 19:59:29.923860: step 62400, total loss = 0.57, batch loss = 0.30 (227.4 examples/sec; 0.035 sec/batch; 1h:20m:23s remains)
INFO - root - 2022-02-24 19:59:30.419177: step 62410, total loss = 0.53, batch loss = 0.25 (177.6 examples/sec; 0.045 sec/batch; 1h:42m:55s remains)
INFO - root - 2022-02-24 19:59:30.850602: step 62420, total loss = 0.56, batch loss = 0.29 (260.1 examples/sec; 0.031 sec/batch; 1h:10m:16s remains)
INFO - root - 2022-02-24 19:59:31.184067: step 62430, total loss = 0.62, batch loss = 0.35 (335.8 examples/sec; 0.024 sec/batch; 0h:54m:25s remains)
INFO - root - 2022-02-24 19:59:31.473657: step 62440, total loss = 0.50, batch loss = 0.23 (238.8 examples/sec; 0.033 sec/batch; 1h:16m:31s remains)
INFO - root - 2022-02-24 19:59:31.807864: step 62450, total loss = 0.55, batch loss = 0.28 (247.2 examples/sec; 0.032 sec/batch; 1h:13m:55s remains)
INFO - root - 2022-02-24 19:59:32.139100: step 62460, total loss = 0.54, batch loss = 0.27 (252.8 examples/sec; 0.032 sec/batch; 1h:12m:17s remains)
INFO - root - 2022-02-24 19:59:32.673892: step 62470, total loss = 0.50, batch loss = 0.23 (191.9 examples/sec; 0.042 sec/batch; 1h:35m:11s remains)
INFO - root - 2022-02-24 19:59:33.053329: step 62480, total loss = 0.57, batch loss = 0.30 (326.5 examples/sec; 0.025 sec/batch; 0h:55m:57s remains)
INFO - root - 2022-02-24 19:59:33.309080: step 62490, total loss = 0.64, batch loss = 0.37 (317.0 examples/sec; 0.025 sec/batch; 0h:57m:37s remains)
INFO - root - 2022-02-24 19:59:33.597477: step 62500, total loss = 0.50, batch loss = 0.23 (337.0 examples/sec; 0.024 sec/batch; 0h:54m:11s remains)
INFO - root - 2022-02-24 19:59:34.002922: step 62510, total loss = 0.59, batch loss = 0.31 (332.8 examples/sec; 0.024 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 19:59:34.237213: step 62520, total loss = 0.57, batch loss = 0.29 (360.0 examples/sec; 0.022 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 19:59:34.626807: step 62530, total loss = 0.48, batch loss = 0.21 (189.6 examples/sec; 0.042 sec/batch; 1h:36m:18s remains)
INFO - root - 2022-02-24 19:59:34.933195: step 62540, total loss = 0.65, batch loss = 0.38 (338.5 examples/sec; 0.024 sec/batch; 0h:53m:57s remains)
INFO - root - 2022-02-24 19:59:35.326235: step 62550, total loss = 0.61, batch loss = 0.34 (353.9 examples/sec; 0.023 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 19:59:35.643163: step 62560, total loss = 0.46, batch loss = 0.19 (290.6 examples/sec; 0.028 sec/batch; 1h:02m:49s remains)
INFO - root - 2022-02-24 19:59:35.918430: step 62570, total loss = 0.63, batch loss = 0.35 (316.8 examples/sec; 0.025 sec/batch; 0h:57m:37s remains)
INFO - root - 2022-02-24 19:59:36.301047: step 62580, total loss = 0.64, batch loss = 0.37 (270.5 examples/sec; 0.030 sec/batch; 1h:07m:29s remains)
INFO - root - 2022-02-24 19:59:36.701151: step 62590, total loss = 0.64, batch loss = 0.36 (152.5 examples/sec; 0.052 sec/batch; 1h:59m:43s remains)
INFO - root - 2022-02-24 19:59:37.064177: step 62600, total loss = 0.63, batch loss = 0.35 (319.7 examples/sec; 0.025 sec/batch; 0h:57m:05s remains)
INFO - root - 2022-02-24 19:59:37.435991: step 62610, total loss = 0.54, batch loss = 0.27 (293.0 examples/sec; 0.027 sec/batch; 1h:02m:17s remains)
INFO - root - 2022-02-24 19:59:37.796686: step 62620, total loss = 0.65, batch loss = 0.38 (232.0 examples/sec; 0.034 sec/batch; 1h:18m:40s remains)
INFO - root - 2022-02-24 19:59:38.088217: step 62630, total loss = 0.57, batch loss = 0.30 (322.3 examples/sec; 0.025 sec/batch; 0h:56m:37s remains)
INFO - root - 2022-02-24 19:59:38.477689: step 62640, total loss = 0.69, batch loss = 0.42 (295.2 examples/sec; 0.027 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 19:59:38.868211: step 62650, total loss = 0.55, batch loss = 0.28 (248.5 examples/sec; 0.032 sec/batch; 1h:13m:25s remains)
INFO - root - 2022-02-24 19:59:39.301805: step 62660, total loss = 0.54, batch loss = 0.27 (161.0 examples/sec; 0.050 sec/batch; 1h:53m:18s remains)
INFO - root - 2022-02-24 19:59:39.747105: step 62670, total loss = 0.60, batch loss = 0.33 (175.0 examples/sec; 0.046 sec/batch; 1h:44m:15s remains)
INFO - root - 2022-02-24 19:59:40.399442: step 62680, total loss = 0.52, batch loss = 0.25 (254.0 examples/sec; 0.031 sec/batch; 1h:11m:49s remains)
INFO - root - 2022-02-24 19:59:40.884210: step 62690, total loss = 0.59, batch loss = 0.31 (169.8 examples/sec; 0.047 sec/batch; 1h:47m:27s remains)
INFO - root - 2022-02-24 19:59:41.404904: step 62700, total loss = 0.61, batch loss = 0.34 (113.9 examples/sec; 0.070 sec/batch; 2h:40m:07s remains)
INFO - root - 2022-02-24 19:59:41.794087: step 62710, total loss = 0.63, batch loss = 0.36 (336.6 examples/sec; 0.024 sec/batch; 0h:54m:10s remains)
INFO - root - 2022-02-24 19:59:42.075872: step 62720, total loss = 0.62, batch loss = 0.35 (319.9 examples/sec; 0.025 sec/batch; 0h:57m:01s remains)
INFO - root - 2022-02-24 19:59:43.027685: step 62730, total loss = 0.54, batch loss = 0.26 (221.6 examples/sec; 0.036 sec/batch; 1h:22m:17s remains)
INFO - root - 2022-02-24 19:59:43.407727: step 62740, total loss = 0.53, batch loss = 0.26 (148.2 examples/sec; 0.054 sec/batch; 2h:03m:03s remains)
INFO - root - 2022-02-24 19:59:43.766701: step 62750, total loss = 0.57, batch loss = 0.29 (132.5 examples/sec; 0.060 sec/batch; 2h:17m:39s remains)
INFO - root - 2022-02-24 19:59:44.083662: step 62760, total loss = 0.50, batch loss = 0.23 (165.8 examples/sec; 0.048 sec/batch; 1h:49m:59s remains)
INFO - root - 2022-02-24 19:59:44.376697: step 62770, total loss = 0.65, batch loss = 0.38 (327.2 examples/sec; 0.024 sec/batch; 0h:55m:43s remains)
INFO - root - 2022-02-24 19:59:44.739795: step 62780, total loss = 0.59, batch loss = 0.32 (294.7 examples/sec; 0.027 sec/batch; 1h:01m:51s remains)
INFO - root - 2022-02-24 19:59:45.140925: step 62790, total loss = 0.63, batch loss = 0.35 (327.5 examples/sec; 0.024 sec/batch; 0h:55m:39s remains)
INFO - root - 2022-02-24 19:59:45.553452: step 62800, total loss = 0.69, batch loss = 0.42 (137.7 examples/sec; 0.058 sec/batch; 2h:12m:21s remains)
INFO - root - 2022-02-24 19:59:45.911062: step 62810, total loss = 0.55, batch loss = 0.28 (210.0 examples/sec; 0.038 sec/batch; 1h:26m:47s remains)
INFO - root - 2022-02-24 19:59:46.349767: step 62820, total loss = 0.65, batch loss = 0.37 (291.5 examples/sec; 0.027 sec/batch; 1h:02m:31s remains)
INFO - root - 2022-02-24 19:59:46.696509: step 62830, total loss = 0.53, batch loss = 0.26 (338.7 examples/sec; 0.024 sec/batch; 0h:53m:48s remains)
INFO - root - 2022-02-24 19:59:47.094112: step 62840, total loss = 0.58, batch loss = 0.31 (167.7 examples/sec; 0.048 sec/batch; 1h:48m:38s remains)
INFO - root - 2022-02-24 19:59:47.562729: step 62850, total loss = 0.58, batch loss = 0.30 (149.8 examples/sec; 0.053 sec/batch; 2h:01m:37s remains)
INFO - root - 2022-02-24 19:59:47.943473: step 62860, total loss = 0.53, batch loss = 0.26 (175.1 examples/sec; 0.046 sec/batch; 1h:44m:04s remains)
INFO - root - 2022-02-24 19:59:48.246917: step 62870, total loss = 0.58, batch loss = 0.31 (313.3 examples/sec; 0.026 sec/batch; 0h:58m:08s remains)
INFO - root - 2022-02-24 19:59:48.566738: step 62880, total loss = 0.48, batch loss = 0.21 (326.7 examples/sec; 0.024 sec/batch; 0h:55m:45s remains)
INFO - root - 2022-02-24 19:59:48.880091: step 62890, total loss = 0.56, batch loss = 0.29 (191.5 examples/sec; 0.042 sec/batch; 1h:35m:05s remains)
INFO - root - 2022-02-24 19:59:49.275212: step 62900, total loss = 0.54, batch loss = 0.26 (120.9 examples/sec; 0.066 sec/batch; 2h:30m:42s remains)
INFO - root - 2022-02-24 19:59:49.629623: step 62910, total loss = 0.56, batch loss = 0.28 (349.5 examples/sec; 0.023 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 19:59:49.976545: step 62920, total loss = 0.51, batch loss = 0.24 (152.8 examples/sec; 0.052 sec/batch; 1h:59m:12s remains)
INFO - root - 2022-02-24 19:59:50.265951: step 62930, total loss = 0.49, batch loss = 0.22 (312.6 examples/sec; 0.026 sec/batch; 0h:58m:15s remains)
INFO - root - 2022-02-24 19:59:50.605754: step 62940, total loss = 0.64, batch loss = 0.37 (352.3 examples/sec; 0.023 sec/batch; 0h:51m:41s remains)
INFO - root - 2022-02-24 19:59:50.898274: step 62950, total loss = 0.48, batch loss = 0.21 (298.2 examples/sec; 0.027 sec/batch; 1h:01m:03s remains)
INFO - root - 2022-02-24 19:59:51.231414: step 62960, total loss = 0.63, batch loss = 0.35 (243.9 examples/sec; 0.033 sec/batch; 1h:14m:39s remains)
INFO - root - 2022-02-24 19:59:51.704886: step 62970, total loss = 0.57, batch loss = 0.29 (132.4 examples/sec; 0.060 sec/batch; 2h:17m:29s remains)
INFO - root - 2022-02-24 19:59:52.061416: step 62980, total loss = 0.56, batch loss = 0.29 (211.3 examples/sec; 0.038 sec/batch; 1h:26m:09s remains)
INFO - root - 2022-02-24 19:59:52.346635: step 62990, total loss = 0.65, batch loss = 0.38 (313.0 examples/sec; 0.026 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 19:59:52.698616: step 63000, total loss = 0.63, batch loss = 0.36 (151.9 examples/sec; 0.053 sec/batch; 1h:59m:46s remains)
INFO - root - 2022-02-24 19:59:53.065429: step 63010, total loss = 0.71, batch loss = 0.44 (262.0 examples/sec; 0.031 sec/batch; 1h:09m:27s remains)
INFO - root - 2022-02-24 19:59:53.358025: step 63020, total loss = 0.59, batch loss = 0.32 (187.0 examples/sec; 0.043 sec/batch; 1h:37m:19s remains)
INFO - root - 2022-02-24 19:59:53.786451: step 63030, total loss = 0.53, batch loss = 0.26 (131.5 examples/sec; 0.061 sec/batch; 2h:18m:23s remains)
INFO - root - 2022-02-24 19:59:54.174894: step 63040, total loss = 0.58, batch loss = 0.30 (212.5 examples/sec; 0.038 sec/batch; 1h:25m:37s remains)
INFO - root - 2022-02-24 19:59:54.590006: step 63050, total loss = 0.53, batch loss = 0.26 (236.9 examples/sec; 0.034 sec/batch; 1h:16m:47s remains)
INFO - root - 2022-02-24 19:59:54.967457: step 63060, total loss = 0.50, batch loss = 0.23 (126.0 examples/sec; 0.064 sec/batch; 2h:24m:25s remains)
INFO - root - 2022-02-24 19:59:55.243098: step 63070, total loss = 0.50, batch loss = 0.23 (289.0 examples/sec; 0.028 sec/batch; 1h:02m:56s remains)
INFO - root - 2022-02-24 19:59:55.531792: step 63080, total loss = 0.53, batch loss = 0.26 (295.6 examples/sec; 0.027 sec/batch; 1h:01m:31s remains)
INFO - root - 2022-02-24 19:59:55.995286: step 63090, total loss = 0.60, batch loss = 0.33 (138.3 examples/sec; 0.058 sec/batch; 2h:11m:27s remains)
INFO - root - 2022-02-24 19:59:56.493124: step 63100, total loss = 0.69, batch loss = 0.41 (157.6 examples/sec; 0.051 sec/batch; 1h:55m:24s remains)
INFO - root - 2022-02-24 19:59:56.945462: step 63110, total loss = 0.52, batch loss = 0.25 (205.9 examples/sec; 0.039 sec/batch; 1h:28m:18s remains)
INFO - root - 2022-02-24 19:59:57.354131: step 63120, total loss = 0.56, batch loss = 0.29 (287.8 examples/sec; 0.028 sec/batch; 1h:03m:10s remains)
INFO - root - 2022-02-24 19:59:58.203341: step 63130, total loss = 0.53, batch loss = 0.26 (319.7 examples/sec; 0.025 sec/batch; 0h:56m:51s remains)
INFO - root - 2022-02-24 19:59:58.691228: step 63140, total loss = 0.59, batch loss = 0.32 (220.2 examples/sec; 0.036 sec/batch; 1h:22m:33s remains)
INFO - root - 2022-02-24 19:59:59.207574: step 63150, total loss = 0.57, batch loss = 0.30 (334.3 examples/sec; 0.024 sec/batch; 0h:54m:22s remains)
INFO - root - 2022-02-24 19:59:59.609407: step 63160, total loss = 0.44, batch loss = 0.16 (356.0 examples/sec; 0.022 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:00:00.012777: step 63170, total loss = 0.64, batch loss = 0.37 (175.7 examples/sec; 0.046 sec/batch; 1h:43m:25s remains)
INFO - root - 2022-02-24 20:00:00.454731: step 63180, total loss = 0.58, batch loss = 0.30 (278.3 examples/sec; 0.029 sec/batch; 1h:05m:18s remains)
INFO - root - 2022-02-24 20:00:00.753677: step 63190, total loss = 0.66, batch loss = 0.38 (187.1 examples/sec; 0.043 sec/batch; 1h:37m:08s remains)
INFO - root - 2022-02-24 20:00:01.101317: step 63200, total loss = 0.49, batch loss = 0.22 (216.2 examples/sec; 0.037 sec/batch; 1h:24m:03s remains)
INFO - root - 2022-02-24 20:00:01.564481: step 63210, total loss = 0.53, batch loss = 0.26 (172.3 examples/sec; 0.046 sec/batch; 1h:45m:28s remains)
INFO - root - 2022-02-24 20:00:01.979408: step 63220, total loss = 0.59, batch loss = 0.32 (379.4 examples/sec; 0.021 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:00:02.384363: step 63230, total loss = 0.57, batch loss = 0.30 (198.8 examples/sec; 0.040 sec/batch; 1h:31m:24s remains)
INFO - root - 2022-02-24 20:00:03.189933: step 63240, total loss = 0.55, batch loss = 0.28 (253.3 examples/sec; 0.032 sec/batch; 1h:11m:44s remains)
INFO - root - 2022-02-24 20:00:03.595770: step 63250, total loss = 0.52, batch loss = 0.25 (169.1 examples/sec; 0.047 sec/batch; 1h:47m:25s remains)
INFO - root - 2022-02-24 20:00:04.023828: step 63260, total loss = 0.59, batch loss = 0.32 (295.9 examples/sec; 0.027 sec/batch; 1h:01m:23s remains)
INFO - root - 2022-02-24 20:00:04.388027: step 63270, total loss = 0.56, batch loss = 0.29 (147.6 examples/sec; 0.054 sec/batch; 2h:03m:02s remains)
INFO - root - 2022-02-24 20:00:04.815384: step 63280, total loss = 0.63, batch loss = 0.36 (193.8 examples/sec; 0.041 sec/batch; 1h:33m:42s remains)
INFO - root - 2022-02-24 20:00:05.148866: step 63290, total loss = 0.65, batch loss = 0.38 (279.4 examples/sec; 0.029 sec/batch; 1h:04m:59s remains)
INFO - root - 2022-02-24 20:00:05.565646: step 63300, total loss = 0.55, batch loss = 0.28 (278.6 examples/sec; 0.029 sec/batch; 1h:05m:10s remains)
INFO - root - 2022-02-24 20:00:06.061544: step 63310, total loss = 0.63, batch loss = 0.35 (346.2 examples/sec; 0.023 sec/batch; 0h:52m:27s remains)
INFO - root - 2022-02-24 20:00:06.461457: step 63320, total loss = 0.70, batch loss = 0.43 (308.0 examples/sec; 0.026 sec/batch; 0h:58m:57s remains)
INFO - root - 2022-02-24 20:00:06.817755: step 63330, total loss = 0.54, batch loss = 0.27 (181.2 examples/sec; 0.044 sec/batch; 1h:40m:12s remains)
INFO - root - 2022-02-24 20:00:07.101500: step 63340, total loss = 0.53, batch loss = 0.26 (368.1 examples/sec; 0.022 sec/batch; 0h:49m:18s remains)
INFO - root - 2022-02-24 20:00:07.634492: step 63350, total loss = 0.57, batch loss = 0.30 (114.9 examples/sec; 0.070 sec/batch; 2h:37m:57s remains)
INFO - root - 2022-02-24 20:00:08.034162: step 63360, total loss = 0.54, batch loss = 0.27 (137.6 examples/sec; 0.058 sec/batch; 2h:11m:54s remains)
INFO - root - 2022-02-24 20:00:08.369520: step 63370, total loss = 0.54, batch loss = 0.27 (332.4 examples/sec; 0.024 sec/batch; 0h:54m:36s remains)
INFO - root - 2022-02-24 20:00:08.730999: step 63380, total loss = 0.57, batch loss = 0.30 (139.9 examples/sec; 0.057 sec/batch; 2h:09m:44s remains)
INFO - root - 2022-02-24 20:00:09.108598: step 63390, total loss = 0.55, batch loss = 0.28 (195.6 examples/sec; 0.041 sec/batch; 1h:32m:46s remains)
INFO - root - 2022-02-24 20:00:09.412013: step 63400, total loss = 0.49, batch loss = 0.22 (246.3 examples/sec; 0.032 sec/batch; 1h:13m:39s remains)
INFO - root - 2022-02-24 20:00:09.889438: step 63410, total loss = 0.62, batch loss = 0.35 (124.4 examples/sec; 0.064 sec/batch; 2h:25m:49s remains)
INFO - root - 2022-02-24 20:00:10.297994: step 63420, total loss = 0.60, batch loss = 0.32 (350.8 examples/sec; 0.023 sec/batch; 0h:51m:43s remains)
INFO - root - 2022-02-24 20:00:10.692398: step 63430, total loss = 0.51, batch loss = 0.24 (261.6 examples/sec; 0.031 sec/batch; 1h:09m:20s remains)
INFO - root - 2022-02-24 20:00:11.017535: step 63440, total loss = 0.61, batch loss = 0.34 (223.4 examples/sec; 0.036 sec/batch; 1h:21m:11s remains)
INFO - root - 2022-02-24 20:00:11.311424: step 63450, total loss = 0.72, batch loss = 0.44 (303.3 examples/sec; 0.026 sec/batch; 0h:59m:48s remains)
INFO - root - 2022-02-24 20:00:11.626999: step 63460, total loss = 0.58, batch loss = 0.30 (303.1 examples/sec; 0.026 sec/batch; 0h:59m:50s remains)
INFO - root - 2022-02-24 20:00:12.108911: step 63470, total loss = 0.52, batch loss = 0.24 (321.9 examples/sec; 0.025 sec/batch; 0h:56m:20s remains)
INFO - root - 2022-02-24 20:00:12.558093: step 63480, total loss = 0.55, batch loss = 0.27 (94.6 examples/sec; 0.085 sec/batch; 3h:11m:39s remains)
INFO - root - 2022-02-24 20:00:12.859126: step 63490, total loss = 0.54, batch loss = 0.27 (301.3 examples/sec; 0.027 sec/batch; 1h:00m:10s remains)
INFO - root - 2022-02-24 20:00:13.188222: step 63500, total loss = 0.59, batch loss = 0.32 (337.9 examples/sec; 0.024 sec/batch; 0h:53m:40s remains)
INFO - root - 2022-02-24 20:00:13.542425: step 63510, total loss = 0.79, batch loss = 0.52 (225.6 examples/sec; 0.035 sec/batch; 1h:20m:22s remains)
INFO - root - 2022-02-24 20:00:13.969487: step 63520, total loss = 0.54, batch loss = 0.27 (245.7 examples/sec; 0.033 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 20:00:14.332930: step 63530, total loss = 0.57, batch loss = 0.30 (411.9 examples/sec; 0.019 sec/batch; 0h:44m:01s remains)
INFO - root - 2022-02-24 20:00:14.605760: step 63540, total loss = 0.76, batch loss = 0.49 (340.6 examples/sec; 0.023 sec/batch; 0h:53m:13s remains)
INFO - root - 2022-02-24 20:00:14.935432: step 63550, total loss = 0.58, batch loss = 0.31 (331.6 examples/sec; 0.024 sec/batch; 0h:54m:40s remains)
INFO - root - 2022-02-24 20:00:15.194251: step 63560, total loss = 0.56, batch loss = 0.29 (306.0 examples/sec; 0.026 sec/batch; 0h:59m:13s remains)
INFO - root - 2022-02-24 20:00:15.583652: step 63570, total loss = 0.60, batch loss = 0.32 (179.3 examples/sec; 0.045 sec/batch; 1h:41m:03s remains)
INFO - root - 2022-02-24 20:00:15.959964: step 63580, total loss = 0.63, batch loss = 0.36 (311.0 examples/sec; 0.026 sec/batch; 0h:58m:15s remains)
INFO - root - 2022-02-24 20:00:16.349516: step 63590, total loss = 0.55, batch loss = 0.28 (350.1 examples/sec; 0.023 sec/batch; 0h:51m:45s remains)
INFO - root - 2022-02-24 20:00:16.684137: step 63600, total loss = 0.62, batch loss = 0.35 (184.7 examples/sec; 0.043 sec/batch; 1h:38m:06s remains)
INFO - root - 2022-02-24 20:00:17.054929: step 63610, total loss = 0.56, batch loss = 0.29 (268.3 examples/sec; 0.030 sec/batch; 1h:07m:31s remains)
INFO - root - 2022-02-24 20:00:17.359751: step 63620, total loss = 0.50, batch loss = 0.23 (237.9 examples/sec; 0.034 sec/batch; 1h:16m:08s remains)
INFO - root - 2022-02-24 20:00:17.968268: step 63630, total loss = 0.54, batch loss = 0.27 (152.4 examples/sec; 0.053 sec/batch; 1h:58m:54s remains)
INFO - root - 2022-02-24 20:00:18.409822: step 63640, total loss = 0.58, batch loss = 0.31 (224.7 examples/sec; 0.036 sec/batch; 1h:20m:37s remains)
INFO - root - 2022-02-24 20:00:18.780739: step 63650, total loss = 0.66, batch loss = 0.39 (346.2 examples/sec; 0.023 sec/batch; 0h:52m:19s remains)
INFO - root - 2022-02-24 20:00:19.153827: step 63660, total loss = 0.54, batch loss = 0.27 (196.4 examples/sec; 0.041 sec/batch; 1h:32m:13s remains)
INFO - root - 2022-02-24 20:00:19.548331: step 63670, total loss = 0.48, batch loss = 0.21 (355.3 examples/sec; 0.023 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:00:19.920827: step 63680, total loss = 0.58, batch loss = 0.31 (154.3 examples/sec; 0.052 sec/batch; 1h:57m:21s remains)
INFO - root - 2022-02-24 20:00:20.383166: step 63690, total loss = 0.63, batch loss = 0.36 (341.9 examples/sec; 0.023 sec/batch; 0h:52m:58s remains)
INFO - root - 2022-02-24 20:00:21.059814: step 63700, total loss = 0.55, batch loss = 0.28 (86.3 examples/sec; 0.093 sec/batch; 3h:29m:44s remains)
INFO - root - 2022-02-24 20:00:21.561187: step 63710, total loss = 0.51, batch loss = 0.24 (328.2 examples/sec; 0.024 sec/batch; 0h:55m:09s remains)
INFO - root - 2022-02-24 20:00:22.087815: step 63720, total loss = 0.62, batch loss = 0.35 (180.3 examples/sec; 0.044 sec/batch; 1h:40m:23s remains)
INFO - root - 2022-02-24 20:00:22.492544: step 63730, total loss = 0.58, batch loss = 0.31 (295.0 examples/sec; 0.027 sec/batch; 1h:01m:21s remains)
INFO - root - 2022-02-24 20:00:23.294037: step 63740, total loss = 0.62, batch loss = 0.35 (184.0 examples/sec; 0.043 sec/batch; 1h:38m:22s remains)
INFO - root - 2022-02-24 20:00:23.741941: step 63750, total loss = 0.60, batch loss = 0.33 (304.1 examples/sec; 0.026 sec/batch; 0h:59m:30s remains)
INFO - root - 2022-02-24 20:00:24.100397: step 63760, total loss = 0.56, batch loss = 0.29 (327.4 examples/sec; 0.024 sec/batch; 0h:55m:17s remains)
INFO - root - 2022-02-24 20:00:24.426327: step 63770, total loss = 0.73, batch loss = 0.46 (302.6 examples/sec; 0.026 sec/batch; 0h:59m:47s remains)
INFO - root - 2022-02-24 20:00:24.744834: step 63780, total loss = 0.63, batch loss = 0.36 (348.5 examples/sec; 0.023 sec/batch; 0h:51m:55s remains)
INFO - root - 2022-02-24 20:00:25.054539: step 63790, total loss = 0.63, batch loss = 0.36 (292.8 examples/sec; 0.027 sec/batch; 1h:01m:48s remains)
INFO - root - 2022-02-24 20:00:25.449432: step 63800, total loss = 0.52, batch loss = 0.24 (135.6 examples/sec; 0.059 sec/batch; 2h:13m:27s remains)
INFO - root - 2022-02-24 20:00:25.954738: step 63810, total loss = 0.56, batch loss = 0.29 (351.2 examples/sec; 0.023 sec/batch; 0h:51m:30s remains)
INFO - root - 2022-02-24 20:00:26.239308: step 63820, total loss = 0.54, batch loss = 0.27 (181.9 examples/sec; 0.044 sec/batch; 1h:39m:26s remains)
INFO - root - 2022-02-24 20:00:26.565994: step 63830, total loss = 0.54, batch loss = 0.26 (182.0 examples/sec; 0.044 sec/batch; 1h:39m:23s remains)
INFO - root - 2022-02-24 20:00:26.934131: step 63840, total loss = 0.52, batch loss = 0.25 (211.7 examples/sec; 0.038 sec/batch; 1h:25m:25s remains)
INFO - root - 2022-02-24 20:00:27.326325: step 63850, total loss = 0.52, batch loss = 0.25 (149.6 examples/sec; 0.053 sec/batch; 2h:00m:53s remains)
INFO - root - 2022-02-24 20:00:27.909944: step 63860, total loss = 0.60, batch loss = 0.33 (203.1 examples/sec; 0.039 sec/batch; 1h:29m:02s remains)
INFO - root - 2022-02-24 20:00:28.254566: step 63870, total loss = 0.52, batch loss = 0.25 (157.0 examples/sec; 0.051 sec/batch; 1h:55m:11s remains)
INFO - root - 2022-02-24 20:00:28.525182: step 63880, total loss = 0.66, batch loss = 0.39 (349.0 examples/sec; 0.023 sec/batch; 0h:51m:48s remains)
INFO - root - 2022-02-24 20:00:28.868882: step 63890, total loss = 0.60, batch loss = 0.33 (247.2 examples/sec; 0.032 sec/batch; 1h:13m:08s remains)
INFO - root - 2022-02-24 20:00:29.178246: step 63900, total loss = 0.64, batch loss = 0.37 (257.6 examples/sec; 0.031 sec/batch; 1h:10m:11s remains)
INFO - root - 2022-02-24 20:00:29.568601: step 63910, total loss = 0.69, batch loss = 0.42 (210.9 examples/sec; 0.038 sec/batch; 1h:25m:42s remains)
INFO - root - 2022-02-24 20:00:29.973977: step 63920, total loss = 0.56, batch loss = 0.29 (112.2 examples/sec; 0.071 sec/batch; 2h:41m:08s remains)
INFO - root - 2022-02-24 20:00:30.339370: step 63930, total loss = 0.82, batch loss = 0.55 (256.1 examples/sec; 0.031 sec/batch; 1h:10m:35s remains)
INFO - root - 2022-02-24 20:00:30.661424: step 63940, total loss = 0.52, batch loss = 0.25 (185.7 examples/sec; 0.043 sec/batch; 1h:37m:20s remains)
INFO - root - 2022-02-24 20:00:31.026394: step 63950, total loss = 0.55, batch loss = 0.28 (275.2 examples/sec; 0.029 sec/batch; 1h:05m:40s remains)
INFO - root - 2022-02-24 20:00:31.330340: step 63960, total loss = 0.61, batch loss = 0.34 (252.2 examples/sec; 0.032 sec/batch; 1h:11m:38s remains)
INFO - root - 2022-02-24 20:00:31.781313: step 63970, total loss = 0.56, batch loss = 0.29 (217.3 examples/sec; 0.037 sec/batch; 1h:23m:08s remains)
INFO - root - 2022-02-24 20:00:32.205412: step 63980, total loss = 0.56, batch loss = 0.29 (222.2 examples/sec; 0.036 sec/batch; 1h:21m:19s remains)
INFO - root - 2022-02-24 20:00:32.529785: step 63990, total loss = 0.60, batch loss = 0.33 (349.6 examples/sec; 0.023 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:00:32.867715: step 64000, total loss = 0.62, batch loss = 0.35 (359.6 examples/sec; 0.022 sec/batch; 0h:50m:14s remains)
INFO - root - 2022-02-24 20:00:33.262840: step 64010, total loss = 0.56, batch loss = 0.29 (101.5 examples/sec; 0.079 sec/batch; 2h:57m:54s remains)
INFO - root - 2022-02-24 20:00:33.733123: step 64020, total loss = 0.66, batch loss = 0.39 (120.1 examples/sec; 0.067 sec/batch; 2h:30m:27s remains)
INFO - root - 2022-02-24 20:00:34.125324: step 64030, total loss = 0.55, batch loss = 0.27 (198.1 examples/sec; 0.040 sec/batch; 1h:31m:10s remains)
INFO - root - 2022-02-24 20:00:34.472193: step 64040, total loss = 0.49, batch loss = 0.22 (338.6 examples/sec; 0.024 sec/batch; 0h:53m:20s remains)
INFO - root - 2022-02-24 20:00:34.715864: step 64050, total loss = 0.54, batch loss = 0.27 (320.1 examples/sec; 0.025 sec/batch; 0h:56m:25s remains)
INFO - root - 2022-02-24 20:00:35.026754: step 64060, total loss = 0.68, batch loss = 0.41 (303.3 examples/sec; 0.026 sec/batch; 0h:59m:32s remains)
INFO - root - 2022-02-24 20:00:35.350827: step 64070, total loss = 0.47, batch loss = 0.20 (347.2 examples/sec; 0.023 sec/batch; 0h:52m:00s remains)
INFO - root - 2022-02-24 20:00:35.668048: step 64080, total loss = 0.58, batch loss = 0.30 (209.9 examples/sec; 0.038 sec/batch; 1h:26m:00s remains)
INFO - root - 2022-02-24 20:00:36.033239: step 64090, total loss = 0.60, batch loss = 0.33 (335.6 examples/sec; 0.024 sec/batch; 0h:53m:47s remains)
INFO - root - 2022-02-24 20:00:36.391374: step 64100, total loss = 0.68, batch loss = 0.40 (357.7 examples/sec; 0.022 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 20:00:36.738207: step 64110, total loss = 0.61, batch loss = 0.33 (354.3 examples/sec; 0.023 sec/batch; 0h:50m:57s remains)
INFO - root - 2022-02-24 20:00:37.094648: step 64120, total loss = 0.51, batch loss = 0.24 (261.8 examples/sec; 0.031 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 20:00:37.416451: step 64130, total loss = 0.51, batch loss = 0.24 (332.0 examples/sec; 0.024 sec/batch; 0h:54m:21s remains)
INFO - root - 2022-02-24 20:00:38.252870: step 64140, total loss = 0.50, batch loss = 0.23 (358.2 examples/sec; 0.022 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 20:00:38.655993: step 64150, total loss = 0.56, batch loss = 0.28 (121.0 examples/sec; 0.066 sec/batch; 2h:29m:11s remains)
INFO - root - 2022-02-24 20:00:38.979898: step 64160, total loss = 0.51, batch loss = 0.24 (244.5 examples/sec; 0.033 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 20:00:39.357022: step 64170, total loss = 0.57, batch loss = 0.30 (346.0 examples/sec; 0.023 sec/batch; 0h:52m:09s remains)
INFO - root - 2022-02-24 20:00:39.772861: step 64180, total loss = 0.53, batch loss = 0.26 (327.8 examples/sec; 0.024 sec/batch; 0h:55m:02s remains)
INFO - root - 2022-02-24 20:00:40.091306: step 64190, total loss = 0.57, batch loss = 0.30 (270.4 examples/sec; 0.030 sec/batch; 1h:06m:43s remains)
INFO - root - 2022-02-24 20:00:40.518146: step 64200, total loss = 0.67, batch loss = 0.40 (304.2 examples/sec; 0.026 sec/batch; 0h:59m:18s remains)
INFO - root - 2022-02-24 20:00:40.966672: step 64210, total loss = 0.53, batch loss = 0.26 (342.2 examples/sec; 0.023 sec/batch; 0h:52m:42s remains)
INFO - root - 2022-02-24 20:00:41.344279: step 64220, total loss = 0.52, batch loss = 0.25 (255.9 examples/sec; 0.031 sec/batch; 1h:10m:29s remains)
INFO - root - 2022-02-24 20:00:41.726105: step 64230, total loss = 0.58, batch loss = 0.31 (216.2 examples/sec; 0.037 sec/batch; 1h:23m:26s remains)
INFO - root - 2022-02-24 20:00:42.106567: step 64240, total loss = 0.60, batch loss = 0.32 (213.0 examples/sec; 0.038 sec/batch; 1h:24m:40s remains)
INFO - root - 2022-02-24 20:00:42.590377: step 64250, total loss = 0.53, batch loss = 0.26 (92.1 examples/sec; 0.087 sec/batch; 3h:15m:53s remains)
INFO - root - 2022-02-24 20:00:42.972267: step 64260, total loss = 0.57, batch loss = 0.30 (343.6 examples/sec; 0.023 sec/batch; 0h:52m:28s remains)
INFO - root - 2022-02-24 20:00:43.781727: step 64270, total loss = 0.52, batch loss = 0.25 (337.4 examples/sec; 0.024 sec/batch; 0h:53m:26s remains)
INFO - root - 2022-02-24 20:00:44.117916: step 64280, total loss = 0.58, batch loss = 0.31 (356.4 examples/sec; 0.022 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:00:44.549324: step 64290, total loss = 0.57, batch loss = 0.30 (240.1 examples/sec; 0.033 sec/batch; 1h:15m:04s remains)
INFO - root - 2022-02-24 20:00:44.883687: step 64300, total loss = 0.50, batch loss = 0.23 (333.0 examples/sec; 0.024 sec/batch; 0h:54m:08s remains)
INFO - root - 2022-02-24 20:00:45.310343: step 64310, total loss = 0.70, batch loss = 0.43 (186.7 examples/sec; 0.043 sec/batch; 1h:36m:33s remains)
INFO - root - 2022-02-24 20:00:45.657214: step 64320, total loss = 0.65, batch loss = 0.38 (249.1 examples/sec; 0.032 sec/batch; 1h:12m:21s remains)
INFO - root - 2022-02-24 20:00:45.949506: step 64330, total loss = 0.48, batch loss = 0.21 (171.9 examples/sec; 0.047 sec/batch; 1h:44m:49s remains)
INFO - root - 2022-02-24 20:00:46.230827: step 64340, total loss = 0.47, batch loss = 0.20 (293.1 examples/sec; 0.027 sec/batch; 1h:01m:28s remains)
INFO - root - 2022-02-24 20:00:46.599756: step 64350, total loss = 0.53, batch loss = 0.26 (375.8 examples/sec; 0.021 sec/batch; 0h:47m:56s remains)
INFO - root - 2022-02-24 20:00:47.007591: step 64360, total loss = 0.52, batch loss = 0.25 (302.3 examples/sec; 0.026 sec/batch; 0h:59m:36s remains)
INFO - root - 2022-02-24 20:00:47.381983: step 64370, total loss = 0.60, batch loss = 0.32 (162.5 examples/sec; 0.049 sec/batch; 1h:50m:54s remains)
INFO - root - 2022-02-24 20:00:47.641423: step 64380, total loss = 0.49, batch loss = 0.22 (336.9 examples/sec; 0.024 sec/batch; 0h:53m:28s remains)
INFO - root - 2022-02-24 20:00:47.945738: step 64390, total loss = 0.52, batch loss = 0.25 (255.3 examples/sec; 0.031 sec/batch; 1h:10m:33s remains)
INFO - root - 2022-02-24 20:00:48.259636: step 64400, total loss = 0.51, batch loss = 0.24 (353.8 examples/sec; 0.023 sec/batch; 0h:50m:54s remains)
INFO - root - 2022-02-24 20:00:48.646334: step 64410, total loss = 0.55, batch loss = 0.27 (318.9 examples/sec; 0.025 sec/batch; 0h:56m:28s remains)
INFO - root - 2022-02-24 20:00:49.098911: step 64420, total loss = 0.58, batch loss = 0.31 (369.8 examples/sec; 0.022 sec/batch; 0h:48m:42s remains)
INFO - root - 2022-02-24 20:00:49.518938: step 64430, total loss = 0.75, batch loss = 0.48 (293.7 examples/sec; 0.027 sec/batch; 1h:01m:19s remains)
INFO - root - 2022-02-24 20:00:49.792436: step 64440, total loss = 0.63, batch loss = 0.36 (345.7 examples/sec; 0.023 sec/batch; 0h:52m:05s remains)
INFO - root - 2022-02-24 20:00:50.075474: step 64450, total loss = 0.75, batch loss = 0.48 (331.3 examples/sec; 0.024 sec/batch; 0h:54m:21s remains)
INFO - root - 2022-02-24 20:00:50.344825: step 64460, total loss = 0.50, batch loss = 0.22 (267.0 examples/sec; 0.030 sec/batch; 1h:07m:26s remains)
INFO - root - 2022-02-24 20:00:50.634016: step 64470, total loss = 0.57, batch loss = 0.30 (319.9 examples/sec; 0.025 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 20:00:51.032545: step 64480, total loss = 0.50, batch loss = 0.23 (226.0 examples/sec; 0.035 sec/batch; 1h:19m:40s remains)
INFO - root - 2022-02-24 20:00:51.445300: step 64490, total loss = 0.65, batch loss = 0.38 (338.8 examples/sec; 0.024 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 20:00:51.794866: step 64500, total loss = 0.67, batch loss = 0.40 (328.5 examples/sec; 0.024 sec/batch; 0h:54m:47s remains)
INFO - root - 2022-02-24 20:00:52.191777: step 64510, total loss = 0.53, batch loss = 0.26 (163.3 examples/sec; 0.049 sec/batch; 1h:50m:13s remains)
INFO - root - 2022-02-24 20:00:52.514152: step 64520, total loss = 0.53, batch loss = 0.26 (313.9 examples/sec; 0.025 sec/batch; 0h:57m:20s remains)
INFO - root - 2022-02-24 20:00:52.795198: step 64530, total loss = 0.53, batch loss = 0.26 (333.1 examples/sec; 0.024 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 20:00:53.166511: step 64540, total loss = 0.74, batch loss = 0.47 (319.6 examples/sec; 0.025 sec/batch; 0h:56m:17s remains)
INFO - root - 2022-02-24 20:00:53.511825: step 64550, total loss = 0.56, batch loss = 0.28 (163.1 examples/sec; 0.049 sec/batch; 1h:50m:18s remains)
INFO - root - 2022-02-24 20:00:54.038740: step 64560, total loss = 0.62, batch loss = 0.35 (91.7 examples/sec; 0.087 sec/batch; 3h:16m:09s remains)
INFO - root - 2022-02-24 20:00:54.406098: step 64570, total loss = 0.51, batch loss = 0.24 (293.8 examples/sec; 0.027 sec/batch; 1h:01m:13s remains)
INFO - root - 2022-02-24 20:00:54.827351: step 64580, total loss = 0.54, batch loss = 0.27 (210.8 examples/sec; 0.038 sec/batch; 1h:25m:20s remains)
INFO - root - 2022-02-24 20:00:55.311332: step 64590, total loss = 0.54, batch loss = 0.27 (125.9 examples/sec; 0.064 sec/batch; 2h:22m:52s remains)
INFO - root - 2022-02-24 20:00:55.650856: step 64600, total loss = 0.53, batch loss = 0.26 (238.3 examples/sec; 0.034 sec/batch; 1h:15m:28s remains)
INFO - root - 2022-02-24 20:00:56.011859: step 64610, total loss = 0.54, batch loss = 0.27 (282.9 examples/sec; 0.028 sec/batch; 1h:03m:34s remains)
INFO - root - 2022-02-24 20:00:56.295123: step 64620, total loss = 0.61, batch loss = 0.34 (191.4 examples/sec; 0.042 sec/batch; 1h:33m:56s remains)
INFO - root - 2022-02-24 20:00:56.734335: step 64630, total loss = 0.52, batch loss = 0.25 (111.0 examples/sec; 0.072 sec/batch; 2h:41m:57s remains)
INFO - root - 2022-02-24 20:00:57.241152: step 64640, total loss = 0.51, batch loss = 0.24 (244.0 examples/sec; 0.033 sec/batch; 1h:13m:41s remains)
INFO - root - 2022-02-24 20:00:57.796469: step 64650, total loss = 0.53, batch loss = 0.26 (298.1 examples/sec; 0.027 sec/batch; 1h:00m:19s remains)
INFO - root - 2022-02-24 20:00:58.374961: step 64660, total loss = 0.57, batch loss = 0.30 (124.1 examples/sec; 0.064 sec/batch; 2h:24m:49s remains)
INFO - root - 2022-02-24 20:00:59.458713: step 64670, total loss = 0.57, batch loss = 0.29 (231.9 examples/sec; 0.034 sec/batch; 1h:17m:30s remains)
INFO - root - 2022-02-24 20:00:59.879659: step 64680, total loss = 0.69, batch loss = 0.41 (144.0 examples/sec; 0.056 sec/batch; 2h:04m:52s remains)
INFO - root - 2022-02-24 20:01:00.284219: step 64690, total loss = 0.65, batch loss = 0.38 (240.1 examples/sec; 0.033 sec/batch; 1h:14m:51s remains)
INFO - root - 2022-02-24 20:01:00.596428: step 64700, total loss = 0.50, batch loss = 0.23 (254.7 examples/sec; 0.031 sec/batch; 1h:10m:34s remains)
INFO - root - 2022-02-24 20:01:00.975030: step 64710, total loss = 0.50, batch loss = 0.23 (179.3 examples/sec; 0.045 sec/batch; 1h:40m:14s remains)
INFO - root - 2022-02-24 20:01:01.274578: step 64720, total loss = 0.56, batch loss = 0.29 (347.9 examples/sec; 0.023 sec/batch; 0h:51m:39s remains)
INFO - root - 2022-02-24 20:01:01.633928: step 64730, total loss = 0.57, batch loss = 0.30 (335.2 examples/sec; 0.024 sec/batch; 0h:53m:36s remains)
INFO - root - 2022-02-24 20:01:01.992421: step 64740, total loss = 0.66, batch loss = 0.39 (215.8 examples/sec; 0.037 sec/batch; 1h:23m:15s remains)
INFO - root - 2022-02-24 20:01:02.287025: step 64750, total loss = 0.58, batch loss = 0.30 (366.4 examples/sec; 0.022 sec/batch; 0h:49m:01s remains)
INFO - root - 2022-02-24 20:01:02.618100: step 64760, total loss = 0.54, batch loss = 0.27 (277.5 examples/sec; 0.029 sec/batch; 1h:04m:43s remains)
INFO - root - 2022-02-24 20:01:02.988268: step 64770, total loss = 0.48, batch loss = 0.21 (167.0 examples/sec; 0.048 sec/batch; 1h:47m:32s remains)
INFO - root - 2022-02-24 20:01:03.475830: step 64780, total loss = 0.51, batch loss = 0.24 (198.7 examples/sec; 0.040 sec/batch; 1h:30m:25s remains)
INFO - root - 2022-02-24 20:01:04.004742: step 64790, total loss = 0.52, batch loss = 0.24 (65.4 examples/sec; 0.122 sec/batch; 4h:34m:27s remains)
INFO - root - 2022-02-24 20:01:04.336512: step 64800, total loss = 0.52, batch loss = 0.25 (325.1 examples/sec; 0.025 sec/batch; 0h:55m:14s remains)
INFO - root - 2022-02-24 20:01:04.803585: step 64810, total loss = 0.58, batch loss = 0.31 (326.2 examples/sec; 0.025 sec/batch; 0h:55m:03s remains)
INFO - root - 2022-02-24 20:01:05.087729: step 64820, total loss = 0.63, batch loss = 0.36 (339.5 examples/sec; 0.024 sec/batch; 0h:52m:53s remains)
INFO - root - 2022-02-24 20:01:05.373669: step 64830, total loss = 0.63, batch loss = 0.36 (244.8 examples/sec; 0.033 sec/batch; 1h:13m:20s remains)
INFO - root - 2022-02-24 20:01:05.733383: step 64840, total loss = 0.58, batch loss = 0.31 (304.8 examples/sec; 0.026 sec/batch; 0h:58m:54s remains)
INFO - root - 2022-02-24 20:01:06.134146: step 64850, total loss = 0.65, batch loss = 0.38 (247.2 examples/sec; 0.032 sec/batch; 1h:12m:37s remains)
INFO - root - 2022-02-24 20:01:06.454557: step 64860, total loss = 0.55, batch loss = 0.28 (194.4 examples/sec; 0.041 sec/batch; 1h:32m:21s remains)
INFO - root - 2022-02-24 20:01:06.741968: step 64870, total loss = 0.58, batch loss = 0.30 (342.0 examples/sec; 0.023 sec/batch; 0h:52m:29s remains)
INFO - root - 2022-02-24 20:01:07.100666: step 64880, total loss = 0.60, batch loss = 0.33 (347.8 examples/sec; 0.023 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:01:07.443156: step 64890, total loss = 0.57, batch loss = 0.30 (149.2 examples/sec; 0.054 sec/batch; 2h:00m:15s remains)
INFO - root - 2022-02-24 20:01:07.903400: step 64900, total loss = 0.64, batch loss = 0.37 (355.2 examples/sec; 0.023 sec/batch; 0h:50m:31s remains)
INFO - root - 2022-02-24 20:01:08.284961: step 64910, total loss = 0.61, batch loss = 0.34 (323.4 examples/sec; 0.025 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 20:01:08.539226: step 64920, total loss = 0.59, batch loss = 0.32 (362.6 examples/sec; 0.022 sec/batch; 0h:49m:29s remains)
INFO - root - 2022-02-24 20:01:08.848466: step 64930, total loss = 0.52, batch loss = 0.25 (273.4 examples/sec; 0.029 sec/batch; 1h:05m:37s remains)
INFO - root - 2022-02-24 20:01:09.263341: step 64940, total loss = 0.56, batch loss = 0.29 (169.2 examples/sec; 0.047 sec/batch; 1h:46m:01s remains)
INFO - root - 2022-02-24 20:01:09.641035: step 64950, total loss = 0.52, batch loss = 0.24 (175.0 examples/sec; 0.046 sec/batch; 1h:42m:29s remains)
INFO - root - 2022-02-24 20:01:10.037422: step 64960, total loss = 0.50, batch loss = 0.23 (323.7 examples/sec; 0.025 sec/batch; 0h:55m:24s remains)
INFO - root - 2022-02-24 20:01:10.363153: step 64970, total loss = 0.62, batch loss = 0.35 (161.6 examples/sec; 0.049 sec/batch; 1h:50m:59s remains)
INFO - root - 2022-02-24 20:01:10.667202: step 64980, total loss = 0.52, batch loss = 0.24 (343.6 examples/sec; 0.023 sec/batch; 0h:52m:12s remains)
INFO - root - 2022-02-24 20:01:10.996037: step 64990, total loss = 0.60, batch loss = 0.33 (213.7 examples/sec; 0.037 sec/batch; 1h:23m:54s remains)
INFO - root - 2022-02-24 20:01:11.459692: step 65000, total loss = 0.54, batch loss = 0.27 (269.4 examples/sec; 0.030 sec/batch; 1h:06m:34s remains)
INFO - root - 2022-02-24 20:01:11.948312: step 65010, total loss = 0.54, batch loss = 0.27 (169.9 examples/sec; 0.047 sec/batch; 1h:45m:34s remains)
INFO - root - 2022-02-24 20:01:12.289024: step 65020, total loss = 0.53, batch loss = 0.26 (351.0 examples/sec; 0.023 sec/batch; 0h:51m:05s remains)
INFO - root - 2022-02-24 20:01:12.691707: step 65030, total loss = 0.70, batch loss = 0.43 (164.0 examples/sec; 0.049 sec/batch; 1h:49m:17s remains)
INFO - root - 2022-02-24 20:01:12.941498: step 65040, total loss = 0.58, batch loss = 0.30 (297.1 examples/sec; 0.027 sec/batch; 1h:00m:20s remains)
INFO - root - 2022-02-24 20:01:13.243116: step 65050, total loss = 0.60, batch loss = 0.33 (220.5 examples/sec; 0.036 sec/batch; 1h:21m:17s remains)
INFO - root - 2022-02-24 20:01:13.722058: step 65060, total loss = 0.47, batch loss = 0.20 (102.6 examples/sec; 0.078 sec/batch; 2h:54m:39s remains)
INFO - root - 2022-02-24 20:01:14.081404: step 65070, total loss = 0.56, batch loss = 0.29 (342.1 examples/sec; 0.023 sec/batch; 0h:52m:23s remains)
INFO - root - 2022-02-24 20:01:14.804871: step 65080, total loss = 0.65, batch loss = 0.38 (250.4 examples/sec; 0.032 sec/batch; 1h:11m:35s remains)
INFO - root - 2022-02-24 20:01:15.171153: step 65090, total loss = 0.54, batch loss = 0.27 (321.0 examples/sec; 0.025 sec/batch; 0h:55m:49s remains)
INFO - root - 2022-02-24 20:01:15.636502: step 65100, total loss = 0.58, batch loss = 0.31 (220.0 examples/sec; 0.036 sec/batch; 1h:21m:28s remains)
INFO - root - 2022-02-24 20:01:16.229960: step 65110, total loss = 0.53, batch loss = 0.25 (161.5 examples/sec; 0.050 sec/batch; 1h:50m:56s remains)
INFO - root - 2022-02-24 20:01:16.695271: step 65120, total loss = 0.56, batch loss = 0.29 (116.1 examples/sec; 0.069 sec/batch; 2h:34m:22s remains)
INFO - root - 2022-02-24 20:01:17.028663: step 65130, total loss = 0.67, batch loss = 0.40 (248.4 examples/sec; 0.032 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 20:01:17.416460: step 65140, total loss = 0.49, batch loss = 0.22 (155.6 examples/sec; 0.051 sec/batch; 1h:55m:07s remains)
INFO - root - 2022-02-24 20:01:17.813036: step 65150, total loss = 0.52, batch loss = 0.24 (272.9 examples/sec; 0.029 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:01:18.318378: step 65160, total loss = 0.59, batch loss = 0.32 (221.5 examples/sec; 0.036 sec/batch; 1h:20m:52s remains)
INFO - root - 2022-02-24 20:01:18.645237: step 65170, total loss = 0.52, batch loss = 0.25 (339.4 examples/sec; 0.024 sec/batch; 0h:52m:45s remains)
INFO - root - 2022-02-24 20:01:18.919400: step 65180, total loss = 0.49, batch loss = 0.22 (336.0 examples/sec; 0.024 sec/batch; 0h:53m:17s remains)
INFO - root - 2022-02-24 20:01:19.706636: step 65190, total loss = 0.50, batch loss = 0.23 (259.2 examples/sec; 0.031 sec/batch; 1h:09m:05s remains)
INFO - root - 2022-02-24 20:01:20.220074: step 65200, total loss = 0.52, batch loss = 0.25 (133.5 examples/sec; 0.060 sec/batch; 2h:14m:08s remains)
INFO - root - 2022-02-24 20:01:20.602916: step 65210, total loss = 0.62, batch loss = 0.35 (294.6 examples/sec; 0.027 sec/batch; 1h:00m:47s remains)
INFO - root - 2022-02-24 20:01:20.955016: step 65220, total loss = 0.50, batch loss = 0.23 (157.1 examples/sec; 0.051 sec/batch; 1h:53m:57s remains)
INFO - root - 2022-02-24 20:01:21.313905: step 65230, total loss = 0.58, batch loss = 0.31 (192.6 examples/sec; 0.042 sec/batch; 1h:32m:56s remains)
INFO - root - 2022-02-24 20:01:21.687017: step 65240, total loss = 0.59, batch loss = 0.31 (302.1 examples/sec; 0.026 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 20:01:22.142398: step 65250, total loss = 0.57, batch loss = 0.30 (254.5 examples/sec; 0.031 sec/batch; 1h:10m:19s remains)
INFO - root - 2022-02-24 20:01:22.602597: step 65260, total loss = 0.67, batch loss = 0.40 (309.4 examples/sec; 0.026 sec/batch; 0h:57m:50s remains)
INFO - root - 2022-02-24 20:01:22.970816: step 65270, total loss = 0.61, batch loss = 0.34 (354.2 examples/sec; 0.023 sec/batch; 0h:50m:31s remains)
INFO - root - 2022-02-24 20:01:23.309818: step 65280, total loss = 0.52, batch loss = 0.25 (158.3 examples/sec; 0.051 sec/batch; 1h:53m:02s remains)
INFO - root - 2022-02-24 20:01:23.605521: step 65290, total loss = 0.59, batch loss = 0.31 (356.5 examples/sec; 0.022 sec/batch; 0h:50m:11s remains)
INFO - root - 2022-02-24 20:01:23.980132: step 65300, total loss = 0.51, batch loss = 0.24 (241.1 examples/sec; 0.033 sec/batch; 1h:14m:12s remains)
INFO - root - 2022-02-24 20:01:24.468544: step 65310, total loss = 0.57, batch loss = 0.30 (330.7 examples/sec; 0.024 sec/batch; 0h:54m:05s remains)
INFO - root - 2022-02-24 20:01:24.890798: step 65320, total loss = 0.55, batch loss = 0.28 (289.9 examples/sec; 0.028 sec/batch; 1h:01m:43s remains)
INFO - root - 2022-02-24 20:01:25.234949: step 65330, total loss = 0.51, batch loss = 0.24 (182.3 examples/sec; 0.044 sec/batch; 1h:38m:08s remains)
INFO - root - 2022-02-24 20:01:25.614878: step 65340, total loss = 0.59, batch loss = 0.32 (321.3 examples/sec; 0.025 sec/batch; 0h:55m:40s remains)
INFO - root - 2022-02-24 20:01:25.958100: step 65350, total loss = 0.50, batch loss = 0.23 (335.6 examples/sec; 0.024 sec/batch; 0h:53m:17s remains)
INFO - root - 2022-02-24 20:01:26.348331: step 65360, total loss = 0.54, batch loss = 0.27 (349.2 examples/sec; 0.023 sec/batch; 0h:51m:13s remains)
INFO - root - 2022-02-24 20:01:26.763256: step 65370, total loss = 0.48, batch loss = 0.21 (198.1 examples/sec; 0.040 sec/batch; 1h:30m:15s remains)
INFO - root - 2022-02-24 20:01:27.169156: step 65380, total loss = 0.64, batch loss = 0.37 (238.0 examples/sec; 0.034 sec/batch; 1h:15m:07s remains)
INFO - root - 2022-02-24 20:01:27.515143: step 65390, total loss = 0.53, batch loss = 0.26 (323.5 examples/sec; 0.025 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:01:27.834727: step 65400, total loss = 0.58, batch loss = 0.31 (224.2 examples/sec; 0.036 sec/batch; 1h:19m:46s remains)
INFO - root - 2022-02-24 20:01:28.201626: step 65410, total loss = 0.54, batch loss = 0.26 (327.4 examples/sec; 0.024 sec/batch; 0h:54m:36s remains)
INFO - root - 2022-02-24 20:01:28.575589: step 65420, total loss = 0.52, batch loss = 0.25 (129.6 examples/sec; 0.062 sec/batch; 2h:17m:54s remains)
INFO - root - 2022-02-24 20:01:29.039297: step 65430, total loss = 0.54, batch loss = 0.27 (336.0 examples/sec; 0.024 sec/batch; 0h:53m:12s remains)
INFO - root - 2022-02-24 20:01:29.355453: step 65440, total loss = 0.59, batch loss = 0.32 (408.9 examples/sec; 0.020 sec/batch; 0h:43m:42s remains)
INFO - root - 2022-02-24 20:01:29.663042: step 65450, total loss = 0.62, batch loss = 0.35 (309.7 examples/sec; 0.026 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:01:30.000860: step 65460, total loss = 0.60, batch loss = 0.33 (247.5 examples/sec; 0.032 sec/batch; 1h:12m:12s remains)
INFO - root - 2022-02-24 20:01:30.428953: step 65470, total loss = 0.66, batch loss = 0.39 (239.6 examples/sec; 0.033 sec/batch; 1h:14m:35s remains)
INFO - root - 2022-02-24 20:01:30.878151: step 65480, total loss = 0.69, batch loss = 0.42 (83.4 examples/sec; 0.096 sec/batch; 3h:34m:18s remains)
INFO - root - 2022-02-24 20:01:31.254349: step 65490, total loss = 0.68, batch loss = 0.40 (330.3 examples/sec; 0.024 sec/batch; 0h:54m:05s remains)
INFO - root - 2022-02-24 20:01:31.606375: step 65500, total loss = 0.52, batch loss = 0.25 (310.4 examples/sec; 0.026 sec/batch; 0h:57m:33s remains)
INFO - root - 2022-02-24 20:01:32.185271: step 65510, total loss = 0.55, batch loss = 0.28 (236.2 examples/sec; 0.034 sec/batch; 1h:15m:38s remains)
INFO - root - 2022-02-24 20:01:32.656139: step 65520, total loss = 0.59, batch loss = 0.32 (202.6 examples/sec; 0.039 sec/batch; 1h:28m:11s remains)
INFO - root - 2022-02-24 20:01:33.130907: step 65530, total loss = 0.71, batch loss = 0.44 (358.2 examples/sec; 0.022 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:01:33.447753: step 65540, total loss = 0.64, batch loss = 0.37 (326.6 examples/sec; 0.024 sec/batch; 0h:54m:41s remains)
INFO - root - 2022-02-24 20:01:33.801417: step 65550, total loss = 0.56, batch loss = 0.29 (343.2 examples/sec; 0.023 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:01:34.226529: step 65560, total loss = 0.46, batch loss = 0.19 (92.4 examples/sec; 0.087 sec/batch; 3h:13m:17s remains)
INFO - root - 2022-02-24 20:01:34.663272: step 65570, total loss = 0.65, batch loss = 0.38 (364.3 examples/sec; 0.022 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 20:01:35.111222: step 65580, total loss = 0.57, batch loss = 0.30 (143.1 examples/sec; 0.056 sec/batch; 2h:04m:45s remains)
INFO - root - 2022-02-24 20:01:35.532972: step 65590, total loss = 0.58, batch loss = 0.30 (349.8 examples/sec; 0.023 sec/batch; 0h:51m:02s remains)
INFO - root - 2022-02-24 20:01:36.391261: step 65600, total loss = 0.62, batch loss = 0.35 (18.1 examples/sec; 0.442 sec/batch; 16h:26m:03s remains)
INFO - root - 2022-02-24 20:01:36.846225: step 65610, total loss = 0.51, batch loss = 0.24 (147.1 examples/sec; 0.054 sec/batch; 2h:01m:23s remains)
INFO - root - 2022-02-24 20:01:37.301273: step 65620, total loss = 0.50, batch loss = 0.23 (124.1 examples/sec; 0.064 sec/batch; 2h:23m:53s remains)
INFO - root - 2022-02-24 20:01:37.630163: step 65630, total loss = 0.71, batch loss = 0.44 (316.4 examples/sec; 0.025 sec/batch; 0h:56m:24s remains)
INFO - root - 2022-02-24 20:01:37.975229: step 65640, total loss = 0.53, batch loss = 0.26 (220.4 examples/sec; 0.036 sec/batch; 1h:20m:59s remains)
INFO - root - 2022-02-24 20:01:38.277896: step 65650, total loss = 0.62, batch loss = 0.35 (311.7 examples/sec; 0.026 sec/batch; 0h:57m:15s remains)
INFO - root - 2022-02-24 20:01:38.660495: step 65660, total loss = 0.66, batch loss = 0.39 (347.4 examples/sec; 0.023 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:01:39.035458: step 65670, total loss = 0.62, batch loss = 0.35 (292.3 examples/sec; 0.027 sec/batch; 1h:01m:03s remains)
INFO - root - 2022-02-24 20:01:39.383789: step 65680, total loss = 0.82, batch loss = 0.55 (322.7 examples/sec; 0.025 sec/batch; 0h:55m:17s remains)
INFO - root - 2022-02-24 20:01:39.713083: step 65690, total loss = 0.48, batch loss = 0.21 (327.9 examples/sec; 0.024 sec/batch; 0h:54m:24s remains)
INFO - root - 2022-02-24 20:01:40.032790: step 65700, total loss = 0.59, batch loss = 0.32 (340.0 examples/sec; 0.024 sec/batch; 0h:52m:27s remains)
INFO - root - 2022-02-24 20:01:40.524908: step 65710, total loss = 0.56, batch loss = 0.29 (231.7 examples/sec; 0.035 sec/batch; 1h:16m:59s remains)
INFO - root - 2022-02-24 20:01:40.898444: step 65720, total loss = 0.51, batch loss = 0.24 (229.0 examples/sec; 0.035 sec/batch; 1h:17m:52s remains)
INFO - root - 2022-02-24 20:01:41.356794: step 65730, total loss = 0.49, batch loss = 0.22 (315.7 examples/sec; 0.025 sec/batch; 0h:56m:29s remains)
INFO - root - 2022-02-24 20:01:41.696051: step 65740, total loss = 0.63, batch loss = 0.36 (298.0 examples/sec; 0.027 sec/batch; 0h:59m:50s remains)
INFO - root - 2022-02-24 20:01:42.098354: step 65750, total loss = 0.50, batch loss = 0.23 (205.5 examples/sec; 0.039 sec/batch; 1h:26m:45s remains)
INFO - root - 2022-02-24 20:01:42.428535: step 65760, total loss = 0.65, batch loss = 0.38 (331.9 examples/sec; 0.024 sec/batch; 0h:53m:43s remains)
INFO - root - 2022-02-24 20:01:42.891197: step 65770, total loss = 0.62, batch loss = 0.35 (96.8 examples/sec; 0.083 sec/batch; 3h:04m:15s remains)
INFO - root - 2022-02-24 20:01:43.166908: step 65780, total loss = 0.57, batch loss = 0.29 (341.3 examples/sec; 0.023 sec/batch; 0h:52m:14s remains)
INFO - root - 2022-02-24 20:01:43.506063: step 65790, total loss = 0.60, batch loss = 0.33 (362.1 examples/sec; 0.022 sec/batch; 0h:49m:14s remains)
INFO - root - 2022-02-24 20:01:43.831446: step 65800, total loss = 0.50, batch loss = 0.23 (371.5 examples/sec; 0.022 sec/batch; 0h:47m:58s remains)
INFO - root - 2022-02-24 20:01:44.204824: step 65810, total loss = 0.72, batch loss = 0.45 (334.5 examples/sec; 0.024 sec/batch; 0h:53m:17s remains)
INFO - root - 2022-02-24 20:01:44.573950: step 65820, total loss = 0.57, batch loss = 0.30 (149.0 examples/sec; 0.054 sec/batch; 1h:59m:37s remains)
INFO - root - 2022-02-24 20:01:44.959007: step 65830, total loss = 0.58, batch loss = 0.30 (220.9 examples/sec; 0.036 sec/batch; 1h:20m:40s remains)
INFO - root - 2022-02-24 20:01:45.367252: step 65840, total loss = 0.58, batch loss = 0.31 (126.5 examples/sec; 0.063 sec/batch; 2h:20m:50s remains)
INFO - root - 2022-02-24 20:01:45.777185: step 65850, total loss = 0.69, batch loss = 0.42 (328.7 examples/sec; 0.024 sec/batch; 0h:54m:12s remains)
INFO - root - 2022-02-24 20:01:46.046150: step 65860, total loss = 0.53, batch loss = 0.26 (166.1 examples/sec; 0.048 sec/batch; 1h:47m:15s remains)
INFO - root - 2022-02-24 20:01:46.358245: step 65870, total loss = 0.50, batch loss = 0.23 (321.5 examples/sec; 0.025 sec/batch; 0h:55m:25s remains)
INFO - root - 2022-02-24 20:01:46.719539: step 65880, total loss = 0.53, batch loss = 0.26 (241.1 examples/sec; 0.033 sec/batch; 1h:13m:54s remains)
INFO - root - 2022-02-24 20:01:47.048039: step 65890, total loss = 0.64, batch loss = 0.37 (282.3 examples/sec; 0.028 sec/batch; 1h:03m:06s remains)
INFO - root - 2022-02-24 20:01:47.384169: step 65900, total loss = 0.66, batch loss = 0.39 (148.0 examples/sec; 0.054 sec/batch; 2h:00m:22s remains)
INFO - root - 2022-02-24 20:01:47.848237: step 65910, total loss = 0.54, batch loss = 0.27 (261.4 examples/sec; 0.031 sec/batch; 1h:08m:09s remains)
INFO - root - 2022-02-24 20:01:48.215282: step 65920, total loss = 0.56, batch loss = 0.29 (205.4 examples/sec; 0.039 sec/batch; 1h:26m:42s remains)
INFO - root - 2022-02-24 20:01:48.591510: step 65930, total loss = 0.48, batch loss = 0.21 (198.9 examples/sec; 0.040 sec/batch; 1h:29m:32s remains)
INFO - root - 2022-02-24 20:01:49.023632: step 65940, total loss = 0.52, batch loss = 0.25 (92.9 examples/sec; 0.086 sec/batch; 3h:11m:40s remains)
INFO - root - 2022-02-24 20:01:49.403705: step 65950, total loss = 0.64, batch loss = 0.37 (291.5 examples/sec; 0.027 sec/batch; 1h:01m:04s remains)
INFO - root - 2022-02-24 20:01:49.825737: step 65960, total loss = 0.54, batch loss = 0.27 (274.4 examples/sec; 0.029 sec/batch; 1h:04m:53s remains)
INFO - root - 2022-02-24 20:01:50.127661: step 65970, total loss = 0.55, batch loss = 0.28 (223.5 examples/sec; 0.036 sec/batch; 1h:19m:40s remains)
INFO - root - 2022-02-24 20:01:50.418559: step 65980, total loss = 0.52, batch loss = 0.24 (343.1 examples/sec; 0.023 sec/batch; 0h:51m:53s remains)
INFO - root - 2022-02-24 20:01:50.686660: step 65990, total loss = 0.57, batch loss = 0.30 (135.0 examples/sec; 0.059 sec/batch; 2h:11m:53s remains)
INFO - root - 2022-02-24 20:01:50.983122: step 66000, total loss = 0.69, batch loss = 0.42 (232.4 examples/sec; 0.034 sec/batch; 1h:16m:36s remains)
INFO - root - 2022-02-24 20:01:51.548340: step 66010, total loss = 0.54, batch loss = 0.27 (223.8 examples/sec; 0.036 sec/batch; 1h:19m:30s remains)
INFO - root - 2022-02-24 20:01:51.906868: step 66020, total loss = 0.52, batch loss = 0.25 (362.0 examples/sec; 0.022 sec/batch; 0h:49m:09s remains)
INFO - root - 2022-02-24 20:01:52.356277: step 66030, total loss = 0.54, batch loss = 0.27 (209.6 examples/sec; 0.038 sec/batch; 1h:24m:53s remains)
INFO - root - 2022-02-24 20:01:52.744549: step 66040, total loss = 0.53, batch loss = 0.26 (357.4 examples/sec; 0.022 sec/batch; 0h:49m:47s remains)
INFO - root - 2022-02-24 20:01:53.734052: step 66050, total loss = 0.52, batch loss = 0.25 (300.8 examples/sec; 0.027 sec/batch; 0h:59m:09s remains)
INFO - root - 2022-02-24 20:01:54.150674: step 66060, total loss = 0.58, batch loss = 0.31 (204.7 examples/sec; 0.039 sec/batch; 1h:26m:55s remains)
INFO - root - 2022-02-24 20:01:54.472835: step 66070, total loss = 0.53, batch loss = 0.26 (264.8 examples/sec; 0.030 sec/batch; 1h:07m:10s remains)
INFO - root - 2022-02-24 20:01:54.817916: step 66080, total loss = 0.61, batch loss = 0.34 (345.6 examples/sec; 0.023 sec/batch; 0h:51m:28s remains)
INFO - root - 2022-02-24 20:01:55.190538: step 66090, total loss = 0.60, batch loss = 0.33 (302.3 examples/sec; 0.026 sec/batch; 0h:58m:50s remains)
INFO - root - 2022-02-24 20:01:55.449656: step 66100, total loss = 0.69, batch loss = 0.42 (358.2 examples/sec; 0.022 sec/batch; 0h:49m:39s remains)
INFO - root - 2022-02-24 20:01:55.999626: step 66110, total loss = 0.59, batch loss = 0.32 (202.1 examples/sec; 0.040 sec/batch; 1h:28m:00s remains)
INFO - root - 2022-02-24 20:01:56.374162: step 66120, total loss = 0.48, batch loss = 0.20 (277.9 examples/sec; 0.029 sec/batch; 1h:03m:59s remains)
INFO - root - 2022-02-24 20:01:57.064001: step 66130, total loss = 0.58, batch loss = 0.31 (353.5 examples/sec; 0.023 sec/batch; 0h:50m:18s remains)
INFO - root - 2022-02-24 20:01:57.394356: step 66140, total loss = 0.54, batch loss = 0.27 (275.8 examples/sec; 0.029 sec/batch; 1h:04m:27s remains)
INFO - root - 2022-02-24 20:01:57.887053: step 66150, total loss = 0.61, batch loss = 0.34 (206.0 examples/sec; 0.039 sec/batch; 1h:26m:17s remains)
INFO - root - 2022-02-24 20:01:58.382050: step 66160, total loss = 0.53, batch loss = 0.26 (69.9 examples/sec; 0.115 sec/batch; 4h:14m:31s remains)
INFO - root - 2022-02-24 20:01:58.679007: step 66170, total loss = 0.58, batch loss = 0.31 (187.5 examples/sec; 0.043 sec/batch; 1h:34m:47s remains)
INFO - root - 2022-02-24 20:01:59.024054: step 66180, total loss = 0.58, batch loss = 0.31 (186.7 examples/sec; 0.043 sec/batch; 1h:35m:14s remains)
INFO - root - 2022-02-24 20:01:59.333622: step 66190, total loss = 0.70, batch loss = 0.43 (321.0 examples/sec; 0.025 sec/batch; 0h:55m:22s remains)
INFO - root - 2022-02-24 20:01:59.790012: step 66200, total loss = 0.65, batch loss = 0.38 (148.4 examples/sec; 0.054 sec/batch; 1h:59m:47s remains)
INFO - root - 2022-02-24 20:02:00.215702: step 66210, total loss = 0.56, batch loss = 0.29 (161.6 examples/sec; 0.050 sec/batch; 1h:50m:00s remains)
INFO - root - 2022-02-24 20:02:00.531119: step 66220, total loss = 0.65, batch loss = 0.38 (337.9 examples/sec; 0.024 sec/batch; 0h:52m:35s remains)
INFO - root - 2022-02-24 20:02:00.905841: step 66230, total loss = 0.55, batch loss = 0.28 (239.4 examples/sec; 0.033 sec/batch; 1h:14m:13s remains)
INFO - root - 2022-02-24 20:02:01.245986: step 66240, total loss = 0.54, batch loss = 0.26 (148.7 examples/sec; 0.054 sec/batch; 1h:59m:27s remains)
INFO - root - 2022-02-24 20:02:01.644449: step 66250, total loss = 0.61, batch loss = 0.34 (172.1 examples/sec; 0.046 sec/batch; 1h:43m:13s remains)
INFO - root - 2022-02-24 20:02:01.997044: step 66260, total loss = 0.65, batch loss = 0.38 (319.8 examples/sec; 0.025 sec/batch; 0h:55m:32s remains)
INFO - root - 2022-02-24 20:02:02.446792: step 66270, total loss = 0.60, batch loss = 0.33 (170.2 examples/sec; 0.047 sec/batch; 1h:44m:24s remains)
INFO - root - 2022-02-24 20:02:02.759516: step 66280, total loss = 0.56, batch loss = 0.29 (239.3 examples/sec; 0.033 sec/batch; 1h:14m:14s remains)
INFO - root - 2022-02-24 20:02:03.112819: step 66290, total loss = 0.51, batch loss = 0.24 (286.8 examples/sec; 0.028 sec/batch; 1h:01m:55s remains)
INFO - root - 2022-02-24 20:02:03.365765: step 66300, total loss = 0.57, batch loss = 0.30 (344.4 examples/sec; 0.023 sec/batch; 0h:51m:34s remains)
INFO - root - 2022-02-24 20:02:03.777397: step 66310, total loss = 0.55, batch loss = 0.28 (187.0 examples/sec; 0.043 sec/batch; 1h:34m:59s remains)
INFO - root - 2022-02-24 20:02:04.141272: step 66320, total loss = 0.64, batch loss = 0.37 (136.2 examples/sec; 0.059 sec/batch; 2h:10m:23s remains)
INFO - root - 2022-02-24 20:02:04.556909: step 66330, total loss = 0.55, batch loss = 0.28 (178.0 examples/sec; 0.045 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 20:02:04.824585: step 66340, total loss = 0.66, batch loss = 0.39 (225.2 examples/sec; 0.036 sec/batch; 1h:18m:50s remains)
INFO - root - 2022-02-24 20:02:05.053243: step 66350, total loss = 0.63, batch loss = 0.35 (395.3 examples/sec; 0.020 sec/batch; 0h:44m:54s remains)
INFO - root - 2022-02-24 20:02:05.410402: step 66360, total loss = 0.61, batch loss = 0.34 (310.9 examples/sec; 0.026 sec/batch; 0h:57m:05s remains)
INFO - root - 2022-02-24 20:02:05.715556: step 66370, total loss = 0.55, batch loss = 0.28 (177.7 examples/sec; 0.045 sec/batch; 1h:39m:52s remains)
INFO - root - 2022-02-24 20:02:06.091930: step 66380, total loss = 0.65, batch loss = 0.38 (93.4 examples/sec; 0.086 sec/batch; 3h:10m:04s remains)
INFO - root - 2022-02-24 20:02:06.557593: step 66390, total loss = 0.71, batch loss = 0.44 (149.0 examples/sec; 0.054 sec/batch; 1h:59m:07s remains)
INFO - root - 2022-02-24 20:02:06.834583: step 66400, total loss = 0.56, batch loss = 0.29 (350.8 examples/sec; 0.023 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:02:07.300687: step 66410, total loss = 0.61, batch loss = 0.34 (91.4 examples/sec; 0.088 sec/batch; 3h:14m:10s remains)
INFO - root - 2022-02-24 20:02:07.616416: step 66420, total loss = 0.60, batch loss = 0.33 (246.4 examples/sec; 0.032 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 20:02:08.034941: step 66430, total loss = 0.55, batch loss = 0.28 (141.9 examples/sec; 0.056 sec/batch; 2h:05m:04s remains)
INFO - root - 2022-02-24 20:02:08.401910: step 66440, total loss = 0.52, batch loss = 0.25 (340.4 examples/sec; 0.023 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 20:02:08.789975: step 66450, total loss = 0.49, batch loss = 0.22 (214.0 examples/sec; 0.037 sec/batch; 1h:22m:54s remains)
INFO - root - 2022-02-24 20:02:09.070163: step 66460, total loss = 0.51, batch loss = 0.24 (237.3 examples/sec; 0.034 sec/batch; 1h:14m:45s remains)
INFO - root - 2022-02-24 20:02:09.433292: step 66470, total loss = 0.56, batch loss = 0.29 (195.5 examples/sec; 0.041 sec/batch; 1h:30m:43s remains)
INFO - root - 2022-02-24 20:02:09.857110: step 66480, total loss = 0.57, batch loss = 0.30 (277.1 examples/sec; 0.029 sec/batch; 1h:04m:00s remains)
INFO - root - 2022-02-24 20:02:10.342903: step 66490, total loss = 0.49, batch loss = 0.22 (316.6 examples/sec; 0.025 sec/batch; 0h:56m:01s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-66499 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-66499 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:02:11.462264: step 66500, total loss = 0.71, batch loss = 0.44 (311.1 examples/sec; 0.026 sec/batch; 0h:56m:59s remains)
INFO - root - 2022-02-24 20:02:12.273238: step 66510, total loss = 0.54, batch loss = 0.27 (207.7 examples/sec; 0.039 sec/batch; 1h:25m:23s remains)
INFO - root - 2022-02-24 20:02:12.609093: step 66520, total loss = 0.54, batch loss = 0.27 (228.8 examples/sec; 0.035 sec/batch; 1h:17m:28s remains)
INFO - root - 2022-02-24 20:02:12.998751: step 66530, total loss = 0.59, batch loss = 0.31 (194.5 examples/sec; 0.041 sec/batch; 1h:31m:08s remains)
INFO - root - 2022-02-24 20:02:13.396230: step 66540, total loss = 0.66, batch loss = 0.39 (193.5 examples/sec; 0.041 sec/batch; 1h:31m:37s remains)
INFO - root - 2022-02-24 20:02:13.717951: step 66550, total loss = 0.60, batch loss = 0.33 (232.9 examples/sec; 0.034 sec/batch; 1h:16m:07s remains)
INFO - root - 2022-02-24 20:02:14.020455: step 66560, total loss = 0.43, batch loss = 0.16 (298.0 examples/sec; 0.027 sec/batch; 0h:59m:28s remains)
INFO - root - 2022-02-24 20:02:14.318562: step 66570, total loss = 0.67, batch loss = 0.40 (304.8 examples/sec; 0.026 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 20:02:14.660743: step 66580, total loss = 0.66, batch loss = 0.39 (151.6 examples/sec; 0.053 sec/batch; 1h:56m:54s remains)
INFO - root - 2022-02-24 20:02:15.042990: step 66590, total loss = 0.55, batch loss = 0.28 (245.1 examples/sec; 0.033 sec/batch; 1h:12m:18s remains)
INFO - root - 2022-02-24 20:02:15.468487: step 66600, total loss = 0.55, batch loss = 0.28 (279.3 examples/sec; 0.029 sec/batch; 1h:03m:26s remains)
INFO - root - 2022-02-24 20:02:15.864363: step 66610, total loss = 0.60, batch loss = 0.32 (221.2 examples/sec; 0.036 sec/batch; 1h:20m:06s remains)
INFO - root - 2022-02-24 20:02:16.172929: step 66620, total loss = 0.69, batch loss = 0.42 (348.0 examples/sec; 0.023 sec/batch; 0h:50m:54s remains)
INFO - root - 2022-02-24 20:02:16.469339: step 66630, total loss = 0.67, batch loss = 0.40 (207.7 examples/sec; 0.039 sec/batch; 1h:25m:16s remains)
INFO - root - 2022-02-24 20:02:17.064975: step 66640, total loss = 0.46, batch loss = 0.19 (303.2 examples/sec; 0.026 sec/batch; 0h:58m:25s remains)
INFO - root - 2022-02-24 20:02:17.518748: step 66650, total loss = 0.59, batch loss = 0.32 (176.3 examples/sec; 0.045 sec/batch; 1h:40m:28s remains)
INFO - root - 2022-02-24 20:02:17.865158: step 66660, total loss = 0.50, batch loss = 0.23 (351.5 examples/sec; 0.023 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 20:02:18.134694: step 66670, total loss = 0.68, batch loss = 0.41 (282.8 examples/sec; 0.028 sec/batch; 1h:02m:37s remains)
INFO - root - 2022-02-24 20:02:18.463305: step 66680, total loss = 0.66, batch loss = 0.38 (338.3 examples/sec; 0.024 sec/batch; 0h:52m:20s remains)
INFO - root - 2022-02-24 20:02:18.774923: step 66690, total loss = 0.61, batch loss = 0.34 (326.7 examples/sec; 0.024 sec/batch; 0h:54m:12s remains)
INFO - root - 2022-02-24 20:02:19.173921: step 66700, total loss = 0.55, batch loss = 0.28 (132.6 examples/sec; 0.060 sec/batch; 2h:13m:33s remains)
INFO - root - 2022-02-24 20:02:19.681063: step 66710, total loss = 0.54, batch loss = 0.27 (180.7 examples/sec; 0.044 sec/batch; 1h:37m:59s remains)
INFO - root - 2022-02-24 20:02:19.988949: step 66720, total loss = 0.57, batch loss = 0.30 (251.6 examples/sec; 0.032 sec/batch; 1h:10m:21s remains)
INFO - root - 2022-02-24 20:02:20.330100: step 66730, total loss = 0.55, batch loss = 0.27 (273.0 examples/sec; 0.029 sec/batch; 1h:04m:50s remains)
INFO - root - 2022-02-24 20:02:20.634264: step 66740, total loss = 0.60, batch loss = 0.33 (346.5 examples/sec; 0.023 sec/batch; 0h:51m:05s remains)
INFO - root - 2022-02-24 20:02:20.974268: step 66750, total loss = 0.55, batch loss = 0.28 (161.9 examples/sec; 0.049 sec/batch; 1h:49m:20s remains)
INFO - root - 2022-02-24 20:02:21.370347: step 66760, total loss = 0.52, batch loss = 0.25 (351.4 examples/sec; 0.023 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:02:21.813461: step 66770, total loss = 0.62, batch loss = 0.35 (252.1 examples/sec; 0.032 sec/batch; 1h:10m:11s remains)
INFO - root - 2022-02-24 20:02:22.153124: step 66780, total loss = 0.58, batch loss = 0.31 (323.2 examples/sec; 0.025 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:02:22.487608: step 66790, total loss = 0.58, batch loss = 0.31 (217.0 examples/sec; 0.037 sec/batch; 1h:21m:31s remains)
INFO - root - 2022-02-24 20:02:22.764007: step 66800, total loss = 0.66, batch loss = 0.39 (333.0 examples/sec; 0.024 sec/batch; 0h:53m:07s remains)
INFO - root - 2022-02-24 20:02:23.255611: step 66810, total loss = 0.60, batch loss = 0.33 (122.5 examples/sec; 0.065 sec/batch; 2h:24m:27s remains)
INFO - root - 2022-02-24 20:02:23.712230: step 66820, total loss = 0.52, batch loss = 0.25 (260.6 examples/sec; 0.031 sec/batch; 1h:07m:53s remains)
INFO - root - 2022-02-24 20:02:24.081945: step 66830, total loss = 0.58, batch loss = 0.31 (349.8 examples/sec; 0.023 sec/batch; 0h:50m:33s remains)
INFO - root - 2022-02-24 20:02:24.422946: step 66840, total loss = 0.56, batch loss = 0.29 (282.6 examples/sec; 0.028 sec/batch; 1h:02m:35s remains)
INFO - root - 2022-02-24 20:02:24.814062: step 66850, total loss = 0.54, batch loss = 0.27 (207.7 examples/sec; 0.039 sec/batch; 1h:25m:09s remains)
INFO - root - 2022-02-24 20:02:25.210476: step 66860, total loss = 0.49, batch loss = 0.22 (139.5 examples/sec; 0.057 sec/batch; 2h:06m:45s remains)
INFO - root - 2022-02-24 20:02:25.594974: step 66870, total loss = 0.57, batch loss = 0.30 (227.4 examples/sec; 0.035 sec/batch; 1h:17m:45s remains)
INFO - root - 2022-02-24 20:02:25.876695: step 66880, total loss = 0.49, batch loss = 0.22 (338.7 examples/sec; 0.024 sec/batch; 0h:52m:12s remains)
INFO - root - 2022-02-24 20:02:26.172324: step 66890, total loss = 0.55, batch loss = 0.28 (320.5 examples/sec; 0.025 sec/batch; 0h:55m:10s remains)
INFO - root - 2022-02-24 20:02:26.523206: step 66900, total loss = 0.53, batch loss = 0.26 (211.2 examples/sec; 0.038 sec/batch; 1h:23m:43s remains)
INFO - root - 2022-02-24 20:02:26.920856: step 66910, total loss = 0.58, batch loss = 0.31 (240.9 examples/sec; 0.033 sec/batch; 1h:13m:22s remains)
INFO - root - 2022-02-24 20:02:27.339326: step 66920, total loss = 0.47, batch loss = 0.20 (142.8 examples/sec; 0.056 sec/batch; 2h:03m:49s remains)
INFO - root - 2022-02-24 20:02:27.793246: step 66930, total loss = 0.60, batch loss = 0.33 (139.1 examples/sec; 0.057 sec/batch; 2h:07m:01s remains)
INFO - root - 2022-02-24 20:02:28.088854: step 66940, total loss = 0.66, batch loss = 0.38 (362.9 examples/sec; 0.022 sec/batch; 0h:48m:42s remains)
INFO - root - 2022-02-24 20:02:28.985296: step 66950, total loss = 0.50, batch loss = 0.23 (272.8 examples/sec; 0.029 sec/batch; 1h:04m:46s remains)
INFO - root - 2022-02-24 20:02:29.337344: step 66960, total loss = 0.55, batch loss = 0.28 (280.5 examples/sec; 0.029 sec/batch; 1h:03m:00s remains)
INFO - root - 2022-02-24 20:02:29.802576: step 66970, total loss = 0.60, batch loss = 0.33 (118.5 examples/sec; 0.068 sec/batch; 2h:29m:10s remains)
INFO - root - 2022-02-24 20:02:30.051622: step 66980, total loss = 0.59, batch loss = 0.32 (323.0 examples/sec; 0.025 sec/batch; 0h:54m:41s remains)
INFO - root - 2022-02-24 20:02:30.380219: step 66990, total loss = 0.49, batch loss = 0.22 (327.9 examples/sec; 0.024 sec/batch; 0h:53m:53s remains)
INFO - root - 2022-02-24 20:02:30.668360: step 67000, total loss = 0.56, batch loss = 0.29 (329.4 examples/sec; 0.024 sec/batch; 0h:53m:38s remains)
INFO - root - 2022-02-24 20:02:31.528792: step 67010, total loss = 0.60, batch loss = 0.33 (354.0 examples/sec; 0.023 sec/batch; 0h:49m:54s remains)
INFO - root - 2022-02-24 20:02:31.755844: step 67020, total loss = 0.70, batch loss = 0.43 (336.6 examples/sec; 0.024 sec/batch; 0h:52m:28s remains)
INFO - root - 2022-02-24 20:02:31.994964: step 67030, total loss = 0.58, batch loss = 0.31 (303.0 examples/sec; 0.026 sec/batch; 0h:58m:17s remains)
INFO - root - 2022-02-24 20:02:32.417175: step 67040, total loss = 0.56, batch loss = 0.29 (115.7 examples/sec; 0.069 sec/batch; 2h:32m:40s remains)
INFO - root - 2022-02-24 20:02:32.761058: step 67050, total loss = 0.64, batch loss = 0.37 (310.2 examples/sec; 0.026 sec/batch; 0h:56m:55s remains)
INFO - root - 2022-02-24 20:02:33.612828: step 67060, total loss = 0.60, batch loss = 0.33 (344.7 examples/sec; 0.023 sec/batch; 0h:51m:13s remains)
INFO - root - 2022-02-24 20:02:34.018516: step 67070, total loss = 0.58, batch loss = 0.31 (266.7 examples/sec; 0.030 sec/batch; 1h:06m:12s remains)
INFO - root - 2022-02-24 20:02:34.422861: step 67080, total loss = 0.63, batch loss = 0.36 (192.3 examples/sec; 0.042 sec/batch; 1h:31m:48s remains)
INFO - root - 2022-02-24 20:02:34.707022: step 67090, total loss = 0.50, batch loss = 0.23 (348.1 examples/sec; 0.023 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 20:02:34.980852: step 67100, total loss = 0.56, batch loss = 0.29 (245.5 examples/sec; 0.033 sec/batch; 1h:11m:53s remains)
INFO - root - 2022-02-24 20:02:35.350732: step 67110, total loss = 0.56, batch loss = 0.29 (174.3 examples/sec; 0.046 sec/batch; 1h:41m:14s remains)
INFO - root - 2022-02-24 20:02:35.680185: step 67120, total loss = 0.59, batch loss = 0.32 (271.1 examples/sec; 0.030 sec/batch; 1h:05m:06s remains)
INFO - root - 2022-02-24 20:02:36.098578: step 67130, total loss = 0.51, batch loss = 0.24 (294.7 examples/sec; 0.027 sec/batch; 0h:59m:53s remains)
INFO - root - 2022-02-24 20:02:36.600696: step 67140, total loss = 0.56, batch loss = 0.29 (96.8 examples/sec; 0.083 sec/batch; 3h:02m:14s remains)
INFO - root - 2022-02-24 20:02:36.984910: step 67150, total loss = 0.56, batch loss = 0.29 (180.7 examples/sec; 0.044 sec/batch; 1h:37m:39s remains)
INFO - root - 2022-02-24 20:02:37.330713: step 67160, total loss = 0.62, batch loss = 0.35 (310.1 examples/sec; 0.026 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 20:02:37.761048: step 67170, total loss = 0.55, batch loss = 0.28 (273.6 examples/sec; 0.029 sec/batch; 1h:04m:29s remains)
INFO - root - 2022-02-24 20:02:38.208333: step 67180, total loss = 0.50, batch loss = 0.23 (313.3 examples/sec; 0.026 sec/batch; 0h:56m:18s remains)
INFO - root - 2022-02-24 20:02:38.545574: step 67190, total loss = 0.58, batch loss = 0.31 (276.1 examples/sec; 0.029 sec/batch; 1h:03m:53s remains)
INFO - root - 2022-02-24 20:02:38.938536: step 67200, total loss = 0.55, batch loss = 0.28 (191.0 examples/sec; 0.042 sec/batch; 1h:32m:21s remains)
INFO - root - 2022-02-24 20:02:39.292680: step 67210, total loss = 0.53, batch loss = 0.26 (277.5 examples/sec; 0.029 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 20:02:39.641381: step 67220, total loss = 0.54, batch loss = 0.27 (152.2 examples/sec; 0.053 sec/batch; 1h:55m:52s remains)
INFO - root - 2022-02-24 20:02:40.051201: step 67230, total loss = 0.51, batch loss = 0.24 (178.4 examples/sec; 0.045 sec/batch; 1h:38m:52s remains)
INFO - root - 2022-02-24 20:02:40.368964: step 67240, total loss = 0.55, batch loss = 0.28 (327.9 examples/sec; 0.024 sec/batch; 0h:53m:47s remains)
INFO - root - 2022-02-24 20:02:40.691279: step 67250, total loss = 0.52, batch loss = 0.25 (180.0 examples/sec; 0.044 sec/batch; 1h:37m:58s remains)
INFO - root - 2022-02-24 20:02:40.999234: step 67260, total loss = 0.49, batch loss = 0.22 (346.1 examples/sec; 0.023 sec/batch; 0h:50m:56s remains)
INFO - root - 2022-02-24 20:02:41.313990: step 67270, total loss = 0.55, batch loss = 0.28 (342.5 examples/sec; 0.023 sec/batch; 0h:51m:28s remains)
INFO - root - 2022-02-24 20:02:41.605529: step 67280, total loss = 0.60, batch loss = 0.33 (282.0 examples/sec; 0.028 sec/batch; 1h:02m:31s remains)
INFO - root - 2022-02-24 20:02:41.984531: step 67290, total loss = 0.67, batch loss = 0.40 (341.6 examples/sec; 0.023 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:02:42.308172: step 67300, total loss = 0.50, batch loss = 0.23 (377.4 examples/sec; 0.021 sec/batch; 0h:46m:42s remains)
INFO - root - 2022-02-24 20:02:42.726645: step 67310, total loss = 0.51, batch loss = 0.24 (334.8 examples/sec; 0.024 sec/batch; 0h:52m:38s remains)
INFO - root - 2022-02-24 20:02:43.016747: step 67320, total loss = 0.85, batch loss = 0.58 (328.3 examples/sec; 0.024 sec/batch; 0h:53m:40s remains)
INFO - root - 2022-02-24 20:02:43.335848: step 67330, total loss = 0.57, batch loss = 0.29 (327.6 examples/sec; 0.024 sec/batch; 0h:53m:47s remains)
INFO - root - 2022-02-24 20:02:43.671053: step 67340, total loss = 0.55, batch loss = 0.28 (219.7 examples/sec; 0.036 sec/batch; 1h:20m:12s remains)
INFO - root - 2022-02-24 20:02:44.092226: step 67350, total loss = 0.56, batch loss = 0.29 (109.4 examples/sec; 0.073 sec/batch; 2h:40m:59s remains)
INFO - root - 2022-02-24 20:02:44.494207: step 67360, total loss = 0.59, batch loss = 0.32 (325.1 examples/sec; 0.025 sec/batch; 0h:54m:11s remains)
INFO - root - 2022-02-24 20:02:44.864137: step 67370, total loss = 0.57, batch loss = 0.30 (187.6 examples/sec; 0.043 sec/batch; 1h:33m:53s remains)
INFO - root - 2022-02-24 20:02:45.143461: step 67380, total loss = 0.65, batch loss = 0.38 (348.9 examples/sec; 0.023 sec/batch; 0h:50m:29s remains)
INFO - root - 2022-02-24 20:02:45.398370: step 67390, total loss = 0.54, batch loss = 0.27 (193.2 examples/sec; 0.041 sec/batch; 1h:31m:11s remains)
INFO - root - 2022-02-24 20:02:45.716861: step 67400, total loss = 0.57, batch loss = 0.30 (338.0 examples/sec; 0.024 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 20:02:46.149046: step 67410, total loss = 0.68, batch loss = 0.41 (131.5 examples/sec; 0.061 sec/batch; 2h:13m:56s remains)
INFO - root - 2022-02-24 20:02:46.617173: step 67420, total loss = 0.66, batch loss = 0.39 (133.2 examples/sec; 0.060 sec/batch; 2h:12m:09s remains)
INFO - root - 2022-02-24 20:02:46.982048: step 67430, total loss = 0.55, batch loss = 0.28 (192.6 examples/sec; 0.042 sec/batch; 1h:31m:27s remains)
INFO - root - 2022-02-24 20:02:47.290218: step 67440, total loss = 0.65, batch loss = 0.38 (251.0 examples/sec; 0.032 sec/batch; 1h:10m:08s remains)
INFO - root - 2022-02-24 20:02:47.590894: step 67450, total loss = 0.60, batch loss = 0.33 (338.6 examples/sec; 0.024 sec/batch; 0h:52m:00s remains)
INFO - root - 2022-02-24 20:02:47.920879: step 67460, total loss = 0.58, batch loss = 0.31 (194.5 examples/sec; 0.041 sec/batch; 1h:30m:31s remains)
INFO - root - 2022-02-24 20:02:48.321846: step 67470, total loss = 0.55, batch loss = 0.28 (154.3 examples/sec; 0.052 sec/batch; 1h:54m:04s remains)
INFO - root - 2022-02-24 20:02:48.747285: step 67480, total loss = 0.64, batch loss = 0.37 (211.3 examples/sec; 0.038 sec/batch; 1h:23m:18s remains)
INFO - root - 2022-02-24 20:02:49.171721: step 67490, total loss = 0.52, batch loss = 0.25 (143.9 examples/sec; 0.056 sec/batch; 2h:02m:17s remains)
INFO - root - 2022-02-24 20:02:49.494783: step 67500, total loss = 0.54, batch loss = 0.27 (276.5 examples/sec; 0.029 sec/batch; 1h:03m:38s remains)
INFO - root - 2022-02-24 20:02:49.895597: step 67510, total loss = 0.52, batch loss = 0.25 (317.4 examples/sec; 0.025 sec/batch; 0h:55m:26s remains)
INFO - root - 2022-02-24 20:02:50.254822: step 67520, total loss = 0.63, batch loss = 0.36 (339.7 examples/sec; 0.024 sec/batch; 0h:51m:48s remains)
INFO - root - 2022-02-24 20:02:50.658254: step 67530, total loss = 0.65, batch loss = 0.38 (139.7 examples/sec; 0.057 sec/batch; 2h:05m:57s remains)
INFO - root - 2022-02-24 20:02:51.103925: step 67540, total loss = 0.50, batch loss = 0.23 (175.6 examples/sec; 0.046 sec/batch; 1h:40m:12s remains)
INFO - root - 2022-02-24 20:02:51.520097: step 67550, total loss = 0.49, batch loss = 0.22 (221.8 examples/sec; 0.036 sec/batch; 1h:19m:18s remains)
INFO - root - 2022-02-24 20:02:52.015674: step 67560, total loss = 0.52, batch loss = 0.25 (79.1 examples/sec; 0.101 sec/batch; 3h:42m:29s remains)
INFO - root - 2022-02-24 20:02:52.540097: step 67570, total loss = 0.53, batch loss = 0.26 (230.4 examples/sec; 0.035 sec/batch; 1h:16m:21s remains)
INFO - root - 2022-02-24 20:02:52.898682: step 67580, total loss = 0.57, batch loss = 0.30 (137.7 examples/sec; 0.058 sec/batch; 2h:07m:46s remains)
INFO - root - 2022-02-24 20:02:53.801602: step 67590, total loss = 0.52, batch loss = 0.25 (256.2 examples/sec; 0.031 sec/batch; 1h:08m:39s remains)
INFO - root - 2022-02-24 20:02:54.213842: step 67600, total loss = 0.55, batch loss = 0.28 (189.7 examples/sec; 0.042 sec/batch; 1h:32m:41s remains)
INFO - root - 2022-02-24 20:02:54.696704: step 67610, total loss = 0.60, batch loss = 0.33 (288.4 examples/sec; 0.028 sec/batch; 1h:00m:58s remains)
INFO - root - 2022-02-24 20:02:55.065630: step 67620, total loss = 0.56, batch loss = 0.29 (313.6 examples/sec; 0.026 sec/batch; 0h:56m:04s remains)
INFO - root - 2022-02-24 20:02:55.372190: step 67630, total loss = 0.52, batch loss = 0.25 (304.3 examples/sec; 0.026 sec/batch; 0h:57m:47s remains)
INFO - root - 2022-02-24 20:02:55.742307: step 67640, total loss = 0.55, batch loss = 0.28 (142.5 examples/sec; 0.056 sec/batch; 2h:03m:22s remains)
INFO - root - 2022-02-24 20:02:56.074653: step 67650, total loss = 0.54, batch loss = 0.27 (337.4 examples/sec; 0.024 sec/batch; 0h:52m:05s remains)
INFO - root - 2022-02-24 20:02:56.513165: step 67660, total loss = 0.61, batch loss = 0.34 (114.5 examples/sec; 0.070 sec/batch; 2h:33m:32s remains)
INFO - root - 2022-02-24 20:02:56.893095: step 67670, total loss = 0.62, batch loss = 0.35 (136.1 examples/sec; 0.059 sec/batch; 2h:09m:10s remains)
INFO - root - 2022-02-24 20:02:57.246568: step 67680, total loss = 0.64, batch loss = 0.37 (134.7 examples/sec; 0.059 sec/batch; 2h:10m:29s remains)
INFO - root - 2022-02-24 20:02:57.619612: step 67690, total loss = 0.69, batch loss = 0.42 (247.8 examples/sec; 0.032 sec/batch; 1h:10m:55s remains)
INFO - root - 2022-02-24 20:02:57.986527: step 67700, total loss = 0.71, batch loss = 0.44 (257.0 examples/sec; 0.031 sec/batch; 1h:08m:22s remains)
INFO - root - 2022-02-24 20:02:58.478421: step 67710, total loss = 0.60, batch loss = 0.33 (154.6 examples/sec; 0.052 sec/batch; 1h:53m:39s remains)
INFO - root - 2022-02-24 20:02:59.085500: step 67720, total loss = 0.57, batch loss = 0.30 (46.6 examples/sec; 0.172 sec/batch; 6h:16m:51s remains)
INFO - root - 2022-02-24 20:02:59.435788: step 67730, total loss = 0.59, batch loss = 0.32 (274.5 examples/sec; 0.029 sec/batch; 1h:04m:00s remains)
INFO - root - 2022-02-24 20:02:59.790224: step 67740, total loss = 0.59, batch loss = 0.32 (260.8 examples/sec; 0.031 sec/batch; 1h:07m:21s remains)
INFO - root - 2022-02-24 20:03:00.129357: step 67750, total loss = 0.67, batch loss = 0.40 (337.9 examples/sec; 0.024 sec/batch; 0h:51m:58s remains)
INFO - root - 2022-02-24 20:03:00.400384: step 67760, total loss = 0.51, batch loss = 0.24 (319.8 examples/sec; 0.025 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 20:03:00.804445: step 67770, total loss = 0.66, batch loss = 0.39 (373.7 examples/sec; 0.021 sec/batch; 0h:47m:00s remains)
INFO - root - 2022-02-24 20:03:01.222947: step 67780, total loss = 0.63, batch loss = 0.36 (313.4 examples/sec; 0.026 sec/batch; 0h:56m:02s remains)
INFO - root - 2022-02-24 20:03:01.510228: step 67790, total loss = 0.57, batch loss = 0.30 (300.5 examples/sec; 0.027 sec/batch; 0h:58m:26s remains)
INFO - root - 2022-02-24 20:03:01.850516: step 67800, total loss = 0.54, batch loss = 0.27 (291.5 examples/sec; 0.027 sec/batch; 1h:00m:14s remains)
INFO - root - 2022-02-24 20:03:02.215414: step 67810, total loss = 0.54, batch loss = 0.27 (254.4 examples/sec; 0.031 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 20:03:02.566839: step 67820, total loss = 0.61, batch loss = 0.34 (148.9 examples/sec; 0.054 sec/batch; 1h:57m:54s remains)
INFO - root - 2022-02-24 20:03:02.991080: step 67830, total loss = 0.54, batch loss = 0.27 (188.0 examples/sec; 0.043 sec/batch; 1h:33m:23s remains)
INFO - root - 2022-02-24 20:03:03.296835: step 67840, total loss = 0.59, batch loss = 0.32 (279.3 examples/sec; 0.029 sec/batch; 1h:02m:51s remains)
INFO - root - 2022-02-24 20:03:03.673900: step 67850, total loss = 0.54, batch loss = 0.26 (169.7 examples/sec; 0.047 sec/batch; 1h:43m:26s remains)
INFO - root - 2022-02-24 20:03:03.954359: step 67860, total loss = 0.64, batch loss = 0.36 (204.5 examples/sec; 0.039 sec/batch; 1h:25m:50s remains)
INFO - root - 2022-02-24 20:03:04.258455: step 67870, total loss = 0.54, batch loss = 0.27 (292.7 examples/sec; 0.027 sec/batch; 0h:59m:58s remains)
INFO - root - 2022-02-24 20:03:04.720361: step 67880, total loss = 0.65, batch loss = 0.38 (113.5 examples/sec; 0.070 sec/batch; 2h:34m:36s remains)
INFO - root - 2022-02-24 20:03:05.107793: step 67890, total loss = 0.54, batch loss = 0.27 (305.6 examples/sec; 0.026 sec/batch; 0h:57m:24s remains)
INFO - root - 2022-02-24 20:03:05.466340: step 67900, total loss = 0.54, batch loss = 0.27 (179.7 examples/sec; 0.045 sec/batch; 1h:37m:37s remains)
INFO - root - 2022-02-24 20:03:05.910165: step 67910, total loss = 0.62, batch loss = 0.35 (116.3 examples/sec; 0.069 sec/batch; 2h:30m:51s remains)
INFO - root - 2022-02-24 20:03:06.174157: step 67920, total loss = 0.56, batch loss = 0.29 (281.8 examples/sec; 0.028 sec/batch; 1h:02m:15s remains)
INFO - root - 2022-02-24 20:03:06.509820: step 67930, total loss = 0.56, batch loss = 0.29 (206.4 examples/sec; 0.039 sec/batch; 1h:24m:59s remains)
INFO - root - 2022-02-24 20:03:06.882601: step 67940, total loss = 0.56, batch loss = 0.29 (235.2 examples/sec; 0.034 sec/batch; 1h:14m:35s remains)
INFO - root - 2022-02-24 20:03:07.269089: step 67950, total loss = 0.51, batch loss = 0.24 (347.5 examples/sec; 0.023 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 20:03:07.609873: step 67960, total loss = 0.54, batch loss = 0.27 (364.4 examples/sec; 0.022 sec/batch; 0h:48m:08s remains)
INFO - root - 2022-02-24 20:03:07.980305: step 67970, total loss = 0.55, batch loss = 0.27 (320.2 examples/sec; 0.025 sec/batch; 0h:54m:46s remains)
INFO - root - 2022-02-24 20:03:08.410314: step 67980, total loss = 0.61, batch loss = 0.34 (75.0 examples/sec; 0.107 sec/batch; 3h:53m:39s remains)
INFO - root - 2022-02-24 20:03:08.894079: step 67990, total loss = 0.58, batch loss = 0.31 (129.9 examples/sec; 0.062 sec/batch; 2h:15m:00s remains)
INFO - root - 2022-02-24 20:03:09.474964: step 68000, total loss = 0.55, batch loss = 0.28 (143.0 examples/sec; 0.056 sec/batch; 2h:02m:37s remains)
INFO - root - 2022-02-24 20:03:10.126376: step 68010, total loss = 0.60, batch loss = 0.33 (107.8 examples/sec; 0.074 sec/batch; 2h:42m:37s remains)
INFO - root - 2022-02-24 20:03:10.483526: step 68020, total loss = 0.52, batch loss = 0.25 (343.2 examples/sec; 0.023 sec/batch; 0h:51m:04s remains)
INFO - root - 2022-02-24 20:03:10.884966: step 68030, total loss = 0.56, batch loss = 0.29 (334.0 examples/sec; 0.024 sec/batch; 0h:52m:29s remains)
INFO - root - 2022-02-24 20:03:11.337979: step 68040, total loss = 0.55, batch loss = 0.28 (293.9 examples/sec; 0.027 sec/batch; 0h:59m:38s remains)
INFO - root - 2022-02-24 20:03:11.788438: step 68050, total loss = 0.45, batch loss = 0.18 (144.1 examples/sec; 0.056 sec/batch; 2h:01m:37s remains)
INFO - root - 2022-02-24 20:03:12.171424: step 68060, total loss = 0.51, batch loss = 0.23 (130.3 examples/sec; 0.061 sec/batch; 2h:14m:29s remains)
INFO - root - 2022-02-24 20:03:12.600902: step 68070, total loss = 0.48, batch loss = 0.21 (146.0 examples/sec; 0.055 sec/batch; 1h:59m:59s remains)
INFO - root - 2022-02-24 20:03:13.054153: step 68080, total loss = 0.60, batch loss = 0.33 (205.3 examples/sec; 0.039 sec/batch; 1h:25m:22s remains)
INFO - root - 2022-02-24 20:03:13.894260: step 68090, total loss = 0.58, batch loss = 0.31 (250.1 examples/sec; 0.032 sec/batch; 1h:10m:03s remains)
INFO - root - 2022-02-24 20:03:14.219377: step 68100, total loss = 0.57, batch loss = 0.30 (341.2 examples/sec; 0.023 sec/batch; 0h:51m:20s remains)
INFO - root - 2022-02-24 20:03:14.627697: step 68110, total loss = 0.57, batch loss = 0.30 (207.7 examples/sec; 0.039 sec/batch; 1h:24m:19s remains)
INFO - root - 2022-02-24 20:03:15.051218: step 68120, total loss = 0.55, batch loss = 0.28 (131.2 examples/sec; 0.061 sec/batch; 2h:13m:31s remains)
INFO - root - 2022-02-24 20:03:15.397185: step 68130, total loss = 0.52, batch loss = 0.25 (285.1 examples/sec; 0.028 sec/batch; 1h:01m:26s remains)
INFO - root - 2022-02-24 20:03:15.706463: step 68140, total loss = 0.50, batch loss = 0.23 (163.7 examples/sec; 0.049 sec/batch; 1h:46m:59s remains)
INFO - root - 2022-02-24 20:03:16.043040: step 68150, total loss = 0.63, batch loss = 0.36 (206.1 examples/sec; 0.039 sec/batch; 1h:24m:58s remains)
INFO - root - 2022-02-24 20:03:16.326011: step 68160, total loss = 0.57, batch loss = 0.30 (192.5 examples/sec; 0.042 sec/batch; 1h:30m:57s remains)
INFO - root - 2022-02-24 20:03:16.661892: step 68170, total loss = 0.57, batch loss = 0.30 (339.7 examples/sec; 0.024 sec/batch; 0h:51m:33s remains)
INFO - root - 2022-02-24 20:03:17.167686: step 68180, total loss = 0.50, batch loss = 0.23 (171.3 examples/sec; 0.047 sec/batch; 1h:42m:13s remains)
INFO - root - 2022-02-24 20:03:17.610816: step 68190, total loss = 0.51, batch loss = 0.24 (248.5 examples/sec; 0.032 sec/batch; 1h:10m:27s remains)
INFO - root - 2022-02-24 20:03:17.968673: step 68200, total loss = 0.55, batch loss = 0.28 (212.7 examples/sec; 0.038 sec/batch; 1h:22m:17s remains)
INFO - root - 2022-02-24 20:03:18.392268: step 68210, total loss = 0.68, batch loss = 0.41 (341.9 examples/sec; 0.023 sec/batch; 0h:51m:11s remains)
INFO - root - 2022-02-24 20:03:18.760145: step 68220, total loss = 0.50, batch loss = 0.23 (274.3 examples/sec; 0.029 sec/batch; 1h:03m:48s remains)
INFO - root - 2022-02-24 20:03:19.131328: step 68230, total loss = 0.59, batch loss = 0.32 (233.2 examples/sec; 0.034 sec/batch; 1h:15m:03s remains)
INFO - root - 2022-02-24 20:03:19.523080: step 68240, total loss = 0.50, batch loss = 0.23 (337.1 examples/sec; 0.024 sec/batch; 0h:51m:55s remains)
INFO - root - 2022-02-24 20:03:19.838796: step 68250, total loss = 0.60, batch loss = 0.33 (286.4 examples/sec; 0.028 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 20:03:20.189896: step 68260, total loss = 0.58, batch loss = 0.30 (318.2 examples/sec; 0.025 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:03:20.473159: step 68270, total loss = 0.53, batch loss = 0.26 (335.0 examples/sec; 0.024 sec/batch; 0h:52m:13s remains)
INFO - root - 2022-02-24 20:03:20.813452: step 68280, total loss = 0.70, batch loss = 0.43 (236.1 examples/sec; 0.034 sec/batch; 1h:14m:05s remains)
INFO - root - 2022-02-24 20:03:21.295958: step 68290, total loss = 0.55, batch loss = 0.28 (335.7 examples/sec; 0.024 sec/batch; 0h:52m:07s remains)
INFO - root - 2022-02-24 20:03:21.581956: step 68300, total loss = 0.51, batch loss = 0.24 (270.6 examples/sec; 0.030 sec/batch; 1h:04m:38s remains)
INFO - root - 2022-02-24 20:03:21.945032: step 68310, total loss = 0.53, batch loss = 0.26 (341.2 examples/sec; 0.023 sec/batch; 0h:51m:15s remains)
INFO - root - 2022-02-24 20:03:22.208634: step 68320, total loss = 0.54, batch loss = 0.27 (336.2 examples/sec; 0.024 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:03:22.583258: step 68330, total loss = 0.44, batch loss = 0.17 (121.0 examples/sec; 0.066 sec/batch; 2h:24m:29s remains)
INFO - root - 2022-02-24 20:03:22.979911: step 68340, total loss = 0.45, batch loss = 0.18 (221.1 examples/sec; 0.036 sec/batch; 1h:19m:05s remains)
INFO - root - 2022-02-24 20:03:23.487284: step 68350, total loss = 0.51, batch loss = 0.24 (144.8 examples/sec; 0.055 sec/batch; 2h:00m:45s remains)
INFO - root - 2022-02-24 20:03:24.370905: step 68360, total loss = 0.53, batch loss = 0.25 (360.2 examples/sec; 0.022 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:03:24.755630: step 68370, total loss = 0.60, batch loss = 0.33 (117.9 examples/sec; 0.068 sec/batch; 2h:28m:19s remains)
INFO - root - 2022-02-24 20:03:25.190737: step 68380, total loss = 0.63, batch loss = 0.36 (211.4 examples/sec; 0.038 sec/batch; 1h:22m:42s remains)
INFO - root - 2022-02-24 20:03:25.572241: step 68390, total loss = 0.60, batch loss = 0.33 (299.5 examples/sec; 0.027 sec/batch; 0h:58m:22s remains)
INFO - root - 2022-02-24 20:03:25.943822: step 68400, total loss = 0.58, batch loss = 0.31 (311.9 examples/sec; 0.026 sec/batch; 0h:56m:02s remains)
INFO - root - 2022-02-24 20:03:26.297572: step 68410, total loss = 0.48, batch loss = 0.21 (342.2 examples/sec; 0.023 sec/batch; 0h:51m:04s remains)
INFO - root - 2022-02-24 20:03:26.615815: step 68420, total loss = 0.49, batch loss = 0.22 (190.0 examples/sec; 0.042 sec/batch; 1h:31m:59s remains)
INFO - root - 2022-02-24 20:03:27.061723: step 68430, total loss = 0.47, batch loss = 0.20 (120.7 examples/sec; 0.066 sec/batch; 2h:24m:49s remains)
INFO - root - 2022-02-24 20:03:27.498098: step 68440, total loss = 0.62, batch loss = 0.35 (229.7 examples/sec; 0.035 sec/batch; 1h:16m:05s remains)
INFO - root - 2022-02-24 20:03:27.805777: step 68450, total loss = 0.62, batch loss = 0.35 (190.1 examples/sec; 0.042 sec/batch; 1h:31m:54s remains)
INFO - root - 2022-02-24 20:03:28.232163: step 68460, total loss = 0.66, batch loss = 0.39 (321.0 examples/sec; 0.025 sec/batch; 0h:54m:26s remains)
INFO - root - 2022-02-24 20:03:28.606245: step 68470, total loss = 0.50, batch loss = 0.23 (235.2 examples/sec; 0.034 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 20:03:29.030973: step 68480, total loss = 0.62, batch loss = 0.35 (342.4 examples/sec; 0.023 sec/batch; 0h:51m:01s remains)
INFO - root - 2022-02-24 20:03:29.502662: step 68490, total loss = 0.52, batch loss = 0.25 (398.7 examples/sec; 0.020 sec/batch; 0h:43m:48s remains)
INFO - root - 2022-02-24 20:03:29.861208: step 68500, total loss = 0.60, batch loss = 0.33 (222.4 examples/sec; 0.036 sec/batch; 1h:18m:32s remains)
INFO - root - 2022-02-24 20:03:30.236627: step 68510, total loss = 0.50, batch loss = 0.23 (335.6 examples/sec; 0.024 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:03:30.533280: step 68520, total loss = 0.54, batch loss = 0.27 (305.2 examples/sec; 0.026 sec/batch; 0h:57m:13s remains)
INFO - root - 2022-02-24 20:03:30.845104: step 68530, total loss = 0.58, batch loss = 0.31 (318.2 examples/sec; 0.025 sec/batch; 0h:54m:53s remains)
INFO - root - 2022-02-24 20:03:31.214040: step 68540, total loss = 0.50, batch loss = 0.23 (282.4 examples/sec; 0.028 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 20:03:31.587970: step 68550, total loss = 0.51, batch loss = 0.24 (335.7 examples/sec; 0.024 sec/batch; 0h:52m:00s remains)
INFO - root - 2022-02-24 20:03:31.866293: step 68560, total loss = 0.57, batch loss = 0.30 (184.4 examples/sec; 0.043 sec/batch; 1h:34m:42s remains)
INFO - root - 2022-02-24 20:03:32.168067: step 68570, total loss = 0.54, batch loss = 0.27 (293.6 examples/sec; 0.027 sec/batch; 0h:59m:28s remains)
INFO - root - 2022-02-24 20:03:32.435185: step 68580, total loss = 0.50, batch loss = 0.23 (341.1 examples/sec; 0.023 sec/batch; 0h:51m:10s remains)
INFO - root - 2022-02-24 20:03:32.745353: step 68590, total loss = 0.50, batch loss = 0.23 (185.7 examples/sec; 0.043 sec/batch; 1h:33m:59s remains)
INFO - root - 2022-02-24 20:03:33.203632: step 68600, total loss = 0.46, batch loss = 0.19 (108.8 examples/sec; 0.074 sec/batch; 2h:40m:29s remains)
INFO - root - 2022-02-24 20:03:33.758206: step 68610, total loss = 0.69, batch loss = 0.42 (231.1 examples/sec; 0.035 sec/batch; 1h:15m:31s remains)
INFO - root - 2022-02-24 20:03:34.165063: step 68620, total loss = 0.47, batch loss = 0.20 (297.2 examples/sec; 0.027 sec/batch; 0h:58m:43s remains)
INFO - root - 2022-02-24 20:03:34.514207: step 68630, total loss = 0.55, batch loss = 0.28 (185.0 examples/sec; 0.043 sec/batch; 1h:34m:17s remains)
INFO - root - 2022-02-24 20:03:34.844117: step 68640, total loss = 0.60, batch loss = 0.33 (171.3 examples/sec; 0.047 sec/batch; 1h:41m:50s remains)
INFO - root - 2022-02-24 20:03:35.220844: step 68650, total loss = 0.53, batch loss = 0.26 (195.7 examples/sec; 0.041 sec/batch; 1h:29m:08s remains)
INFO - root - 2022-02-24 20:03:35.619132: step 68660, total loss = 0.71, batch loss = 0.44 (256.6 examples/sec; 0.031 sec/batch; 1h:07m:58s remains)
INFO - root - 2022-02-24 20:03:35.944683: step 68670, total loss = 0.48, batch loss = 0.21 (213.8 examples/sec; 0.037 sec/batch; 1h:21m:35s remains)
INFO - root - 2022-02-24 20:03:36.238529: step 68680, total loss = 0.59, batch loss = 0.32 (341.6 examples/sec; 0.023 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:03:36.527602: step 68690, total loss = 0.54, batch loss = 0.27 (318.4 examples/sec; 0.025 sec/batch; 0h:54m:46s remains)
INFO - root - 2022-02-24 20:03:36.831546: step 68700, total loss = 0.56, batch loss = 0.29 (334.2 examples/sec; 0.024 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:03:37.301537: step 68710, total loss = 0.57, batch loss = 0.30 (214.3 examples/sec; 0.037 sec/batch; 1h:21m:21s remains)
INFO - root - 2022-02-24 20:03:37.741189: step 68720, total loss = 0.58, batch loss = 0.31 (288.0 examples/sec; 0.028 sec/batch; 1h:00m:32s remains)
INFO - root - 2022-02-24 20:03:38.062986: step 68730, total loss = 0.54, batch loss = 0.27 (281.2 examples/sec; 0.028 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:03:38.391132: step 68740, total loss = 0.51, batch loss = 0.24 (319.7 examples/sec; 0.025 sec/batch; 0h:54m:32s remains)
INFO - root - 2022-02-24 20:03:39.225737: step 68750, total loss = 0.64, batch loss = 0.37 (254.0 examples/sec; 0.032 sec/batch; 1h:08m:38s remains)
INFO - root - 2022-02-24 20:03:39.711068: step 68760, total loss = 0.59, batch loss = 0.32 (214.6 examples/sec; 0.037 sec/batch; 1h:21m:14s remains)
INFO - root - 2022-02-24 20:03:40.139689: step 68770, total loss = 0.64, batch loss = 0.37 (334.1 examples/sec; 0.024 sec/batch; 0h:52m:10s remains)
INFO - root - 2022-02-24 20:03:40.512532: step 68780, total loss = 0.59, batch loss = 0.32 (241.2 examples/sec; 0.033 sec/batch; 1h:12m:16s remains)
INFO - root - 2022-02-24 20:03:40.893931: step 68790, total loss = 0.72, batch loss = 0.45 (203.1 examples/sec; 0.039 sec/batch; 1h:25m:49s remains)
INFO - root - 2022-02-24 20:03:41.296870: step 68800, total loss = 0.58, batch loss = 0.31 (184.0 examples/sec; 0.043 sec/batch; 1h:34m:41s remains)
INFO - root - 2022-02-24 20:03:41.803694: step 68810, total loss = 0.50, batch loss = 0.23 (346.0 examples/sec; 0.023 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:03:42.238244: step 68820, total loss = 0.51, batch loss = 0.24 (172.1 examples/sec; 0.046 sec/batch; 1h:41m:12s remains)
INFO - root - 2022-02-24 20:03:42.586573: step 68830, total loss = 0.58, batch loss = 0.31 (199.4 examples/sec; 0.040 sec/batch; 1h:27m:21s remains)
INFO - root - 2022-02-24 20:03:42.894061: step 68840, total loss = 0.56, batch loss = 0.29 (342.0 examples/sec; 0.023 sec/batch; 0h:50m:56s remains)
INFO - root - 2022-02-24 20:03:43.246288: step 68850, total loss = 0.61, batch loss = 0.34 (178.6 examples/sec; 0.045 sec/batch; 1h:37m:31s remains)
INFO - root - 2022-02-24 20:03:43.671808: step 68860, total loss = 0.52, batch loss = 0.25 (170.8 examples/sec; 0.047 sec/batch; 1h:41m:59s remains)
INFO - root - 2022-02-24 20:03:44.059795: step 68870, total loss = 0.54, batch loss = 0.27 (242.9 examples/sec; 0.033 sec/batch; 1h:11m:41s remains)
INFO - root - 2022-02-24 20:03:44.681104: step 68880, total loss = 0.57, batch loss = 0.30 (327.1 examples/sec; 0.024 sec/batch; 0h:53m:14s remains)
INFO - root - 2022-02-24 20:03:44.987993: step 68890, total loss = 0.54, batch loss = 0.27 (287.5 examples/sec; 0.028 sec/batch; 1h:00m:34s remains)
INFO - root - 2022-02-24 20:03:45.304643: step 68900, total loss = 0.60, batch loss = 0.32 (346.2 examples/sec; 0.023 sec/batch; 0h:50m:17s remains)
INFO - root - 2022-02-24 20:03:45.773141: step 68910, total loss = 0.56, batch loss = 0.29 (350.5 examples/sec; 0.023 sec/batch; 0h:49m:40s remains)
INFO - root - 2022-02-24 20:03:46.149402: step 68920, total loss = 0.58, batch loss = 0.31 (285.7 examples/sec; 0.028 sec/batch; 1h:00m:56s remains)
INFO - root - 2022-02-24 20:03:46.508165: step 68930, total loss = 0.58, batch loss = 0.31 (199.7 examples/sec; 0.040 sec/batch; 1h:27m:10s remains)
INFO - root - 2022-02-24 20:03:46.845250: step 68940, total loss = 0.57, batch loss = 0.30 (265.7 examples/sec; 0.030 sec/batch; 1h:05m:31s remains)
INFO - root - 2022-02-24 20:03:47.201054: step 68950, total loss = 0.48, batch loss = 0.21 (314.4 examples/sec; 0.025 sec/batch; 0h:55m:22s remains)
INFO - root - 2022-02-24 20:03:47.649806: step 68960, total loss = 0.56, batch loss = 0.29 (193.0 examples/sec; 0.041 sec/batch; 1h:30m:11s remains)
INFO - root - 2022-02-24 20:03:48.029227: step 68970, total loss = 0.48, batch loss = 0.21 (259.1 examples/sec; 0.031 sec/batch; 1h:07m:10s remains)
INFO - root - 2022-02-24 20:03:48.344923: step 68980, total loss = 0.58, batch loss = 0.31 (358.2 examples/sec; 0.022 sec/batch; 0h:48m:35s remains)
INFO - root - 2022-02-24 20:03:48.659937: step 68990, total loss = 0.55, batch loss = 0.28 (282.3 examples/sec; 0.028 sec/batch; 1h:01m:38s remains)
INFO - root - 2022-02-24 20:03:49.034566: step 69000, total loss = 0.53, batch loss = 0.26 (267.7 examples/sec; 0.030 sec/batch; 1h:04m:59s remains)
INFO - root - 2022-02-24 20:03:49.476432: step 69010, total loss = 0.63, batch loss = 0.36 (373.6 examples/sec; 0.021 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:03:50.331816: step 69020, total loss = 0.70, batch loss = 0.43 (339.0 examples/sec; 0.024 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:03:50.718946: step 69030, total loss = 0.56, batch loss = 0.29 (301.5 examples/sec; 0.027 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:03:51.043073: step 69040, total loss = 0.48, batch loss = 0.21 (227.3 examples/sec; 0.035 sec/batch; 1h:16m:31s remains)
INFO - root - 2022-02-24 20:03:51.356819: step 69050, total loss = 0.56, batch loss = 0.29 (328.1 examples/sec; 0.024 sec/batch; 0h:53m:00s remains)
INFO - root - 2022-02-24 20:03:51.618360: step 69060, total loss = 0.59, batch loss = 0.32 (214.0 examples/sec; 0.037 sec/batch; 1h:21m:15s remains)
INFO - root - 2022-02-24 20:03:52.063628: step 69070, total loss = 0.49, batch loss = 0.22 (128.1 examples/sec; 0.062 sec/batch; 2h:15m:48s remains)
INFO - root - 2022-02-24 20:03:52.501097: step 69080, total loss = 0.58, batch loss = 0.31 (161.3 examples/sec; 0.050 sec/batch; 1h:47m:50s remains)
INFO - root - 2022-02-24 20:03:52.848338: step 69090, total loss = 0.55, batch loss = 0.28 (299.8 examples/sec; 0.027 sec/batch; 0h:57m:59s remains)
INFO - root - 2022-02-24 20:03:53.230565: step 69100, total loss = 0.58, batch loss = 0.31 (247.5 examples/sec; 0.032 sec/batch; 1h:10m:14s remains)
INFO - root - 2022-02-24 20:03:53.581472: step 69110, total loss = 0.62, batch loss = 0.35 (333.1 examples/sec; 0.024 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:03:53.995630: step 69120, total loss = 0.52, batch loss = 0.25 (327.2 examples/sec; 0.024 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 20:03:54.523835: step 69130, total loss = 0.62, batch loss = 0.35 (239.8 examples/sec; 0.033 sec/batch; 1h:12m:29s remains)
INFO - root - 2022-02-24 20:03:54.901814: step 69140, total loss = 0.66, batch loss = 0.39 (325.7 examples/sec; 0.025 sec/batch; 0h:53m:21s remains)
INFO - root - 2022-02-24 20:03:55.170791: step 69150, total loss = 0.51, batch loss = 0.24 (348.8 examples/sec; 0.023 sec/batch; 0h:49m:49s remains)
INFO - root - 2022-02-24 20:03:55.493985: step 69160, total loss = 0.52, batch loss = 0.25 (309.3 examples/sec; 0.026 sec/batch; 0h:56m:11s remains)
INFO - root - 2022-02-24 20:03:55.924626: step 69170, total loss = 0.55, batch loss = 0.28 (222.8 examples/sec; 0.036 sec/batch; 1h:18m:00s remains)
INFO - root - 2022-02-24 20:03:56.324437: step 69180, total loss = 0.51, batch loss = 0.24 (285.8 examples/sec; 0.028 sec/batch; 1h:00m:47s remains)
INFO - root - 2022-02-24 20:03:56.666380: step 69190, total loss = 0.55, batch loss = 0.28 (313.3 examples/sec; 0.026 sec/batch; 0h:55m:27s remains)
INFO - root - 2022-02-24 20:03:57.021525: step 69200, total loss = 0.53, batch loss = 0.26 (187.9 examples/sec; 0.043 sec/batch; 1h:32m:27s remains)
INFO - root - 2022-02-24 20:03:57.449368: step 69210, total loss = 0.53, batch loss = 0.26 (276.8 examples/sec; 0.029 sec/batch; 1h:02m:45s remains)
INFO - root - 2022-02-24 20:03:57.846185: step 69220, total loss = 0.55, batch loss = 0.28 (124.8 examples/sec; 0.064 sec/batch; 2h:19m:08s remains)
INFO - root - 2022-02-24 20:03:58.200445: step 69230, total loss = 0.60, batch loss = 0.33 (380.2 examples/sec; 0.021 sec/batch; 0h:45m:41s remains)
INFO - root - 2022-02-24 20:03:58.610437: step 69240, total loss = 0.54, batch loss = 0.27 (317.2 examples/sec; 0.025 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:03:58.964646: step 69250, total loss = 0.49, batch loss = 0.22 (110.8 examples/sec; 0.072 sec/batch; 2h:36m:45s remains)
INFO - root - 2022-02-24 20:03:59.250351: step 69260, total loss = 0.66, batch loss = 0.39 (226.6 examples/sec; 0.035 sec/batch; 1h:16m:38s remains)
INFO - root - 2022-02-24 20:03:59.576305: step 69270, total loss = 0.60, batch loss = 0.33 (302.0 examples/sec; 0.026 sec/batch; 0h:57m:29s remains)
INFO - root - 2022-02-24 20:04:00.131548: step 69280, total loss = 0.52, batch loss = 0.25 (104.1 examples/sec; 0.077 sec/batch; 2h:46m:43s remains)
INFO - root - 2022-02-24 20:04:00.507229: step 69290, total loss = 0.46, batch loss = 0.19 (283.5 examples/sec; 0.028 sec/batch; 1h:01m:14s remains)
INFO - root - 2022-02-24 20:04:00.769641: step 69300, total loss = 0.58, batch loss = 0.31 (288.3 examples/sec; 0.028 sec/batch; 1h:00m:12s remains)
INFO - root - 2022-02-24 20:04:01.187706: step 69310, total loss = 0.74, batch loss = 0.47 (251.6 examples/sec; 0.032 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 20:04:01.558442: step 69320, total loss = 0.53, batch loss = 0.26 (167.0 examples/sec; 0.048 sec/batch; 1h:43m:57s remains)
INFO - root - 2022-02-24 20:04:02.059063: step 69330, total loss = 0.58, batch loss = 0.31 (163.0 examples/sec; 0.049 sec/batch; 1h:46m:28s remains)
INFO - root - 2022-02-24 20:04:02.442571: step 69340, total loss = 0.49, batch loss = 0.22 (174.6 examples/sec; 0.046 sec/batch; 1h:39m:22s remains)
INFO - root - 2022-02-24 20:04:02.770692: step 69350, total loss = 0.58, batch loss = 0.31 (212.7 examples/sec; 0.038 sec/batch; 1h:21m:36s remains)
INFO - root - 2022-02-24 20:04:03.259053: step 69360, total loss = 0.49, batch loss = 0.22 (89.6 examples/sec; 0.089 sec/batch; 3h:13m:44s remains)
INFO - root - 2022-02-24 20:04:03.877124: step 69370, total loss = 0.60, batch loss = 0.33 (226.0 examples/sec; 0.035 sec/batch; 1h:16m:46s remains)
INFO - root - 2022-02-24 20:04:04.431095: step 69380, total loss = 0.66, batch loss = 0.39 (87.1 examples/sec; 0.092 sec/batch; 3h:19m:05s remains)
INFO - root - 2022-02-24 20:04:04.768884: step 69390, total loss = 0.60, batch loss = 0.33 (328.5 examples/sec; 0.024 sec/batch; 0h:52m:48s remains)
INFO - root - 2022-02-24 20:04:05.489644: step 69400, total loss = 0.65, batch loss = 0.38 (295.5 examples/sec; 0.027 sec/batch; 0h:58m:42s remains)
INFO - root - 2022-02-24 20:04:05.972290: step 69410, total loss = 0.52, batch loss = 0.25 (281.5 examples/sec; 0.028 sec/batch; 1h:01m:37s remains)
INFO - root - 2022-02-24 20:04:06.460295: step 69420, total loss = 0.53, batch loss = 0.26 (355.1 examples/sec; 0.023 sec/batch; 0h:48m:50s remains)
INFO - root - 2022-02-24 20:04:06.813291: step 69430, total loss = 0.57, batch loss = 0.30 (320.5 examples/sec; 0.025 sec/batch; 0h:54m:06s remains)
INFO - root - 2022-02-24 20:04:07.142907: step 69440, total loss = 0.60, batch loss = 0.33 (242.0 examples/sec; 0.033 sec/batch; 1h:11m:39s remains)
INFO - root - 2022-02-24 20:04:07.457752: step 69450, total loss = 0.61, batch loss = 0.34 (175.3 examples/sec; 0.046 sec/batch; 1h:38m:54s remains)
INFO - root - 2022-02-24 20:04:07.841789: step 69460, total loss = 0.55, batch loss = 0.28 (159.4 examples/sec; 0.050 sec/batch; 1h:48m:45s remains)
INFO - root - 2022-02-24 20:04:08.219328: step 69470, total loss = 0.64, batch loss = 0.37 (213.5 examples/sec; 0.037 sec/batch; 1h:21m:12s remains)
INFO - root - 2022-02-24 20:04:08.602954: step 69480, total loss = 0.58, batch loss = 0.31 (330.5 examples/sec; 0.024 sec/batch; 0h:52m:27s remains)
INFO - root - 2022-02-24 20:04:08.923693: step 69490, total loss = 0.51, batch loss = 0.24 (317.5 examples/sec; 0.025 sec/batch; 0h:54m:35s remains)
INFO - root - 2022-02-24 20:04:09.212053: step 69500, total loss = 0.57, batch loss = 0.30 (320.5 examples/sec; 0.025 sec/batch; 0h:54m:04s remains)
INFO - root - 2022-02-24 20:04:09.563229: step 69510, total loss = 0.58, batch loss = 0.30 (307.8 examples/sec; 0.026 sec/batch; 0h:56m:18s remains)
INFO - root - 2022-02-24 20:04:10.001694: step 69520, total loss = 0.55, batch loss = 0.28 (116.4 examples/sec; 0.069 sec/batch; 2h:28m:54s remains)
INFO - root - 2022-02-24 20:04:10.369378: step 69530, total loss = 0.54, batch loss = 0.27 (228.3 examples/sec; 0.035 sec/batch; 1h:15m:53s remains)
INFO - root - 2022-02-24 20:04:10.792663: step 69540, total loss = 0.53, batch loss = 0.26 (207.9 examples/sec; 0.038 sec/batch; 1h:23m:21s remains)
INFO - root - 2022-02-24 20:04:11.135548: step 69550, total loss = 0.68, batch loss = 0.41 (109.1 examples/sec; 0.073 sec/batch; 2h:38m:46s remains)
INFO - root - 2022-02-24 20:04:11.463560: step 69560, total loss = 0.55, batch loss = 0.28 (337.6 examples/sec; 0.024 sec/batch; 0h:51m:19s remains)
INFO - root - 2022-02-24 20:04:11.807101: step 69570, total loss = 0.75, batch loss = 0.48 (245.9 examples/sec; 0.033 sec/batch; 1h:10m:27s remains)
INFO - root - 2022-02-24 20:04:12.207845: step 69580, total loss = 0.46, batch loss = 0.19 (246.5 examples/sec; 0.032 sec/batch; 1h:10m:17s remains)
INFO - root - 2022-02-24 20:04:12.576427: step 69590, total loss = 0.54, batch loss = 0.27 (357.8 examples/sec; 0.022 sec/batch; 0h:48m:24s remains)
INFO - root - 2022-02-24 20:04:12.901111: step 69600, total loss = 0.56, batch loss = 0.29 (217.7 examples/sec; 0.037 sec/batch; 1h:19m:32s remains)
INFO - root - 2022-02-24 20:04:13.261872: step 69610, total loss = 0.55, batch loss = 0.28 (311.9 examples/sec; 0.026 sec/batch; 0h:55m:31s remains)
INFO - root - 2022-02-24 20:04:13.519714: step 69620, total loss = 0.64, batch loss = 0.37 (313.3 examples/sec; 0.026 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:04:13.887436: step 69630, total loss = 0.49, batch loss = 0.22 (384.7 examples/sec; 0.021 sec/batch; 0h:45m:00s remains)
INFO - root - 2022-02-24 20:04:14.357727: step 69640, total loss = 0.61, batch loss = 0.34 (135.0 examples/sec; 0.059 sec/batch; 2h:08m:14s remains)
INFO - root - 2022-02-24 20:04:14.841462: step 69650, total loss = 0.52, batch loss = 0.25 (321.2 examples/sec; 0.025 sec/batch; 0h:53m:53s remains)
INFO - root - 2022-02-24 20:04:15.689094: step 69660, total loss = 0.60, batch loss = 0.33 (115.3 examples/sec; 0.069 sec/batch; 2h:30m:07s remains)
INFO - root - 2022-02-24 20:04:16.111620: step 69670, total loss = 0.46, batch loss = 0.19 (218.2 examples/sec; 0.037 sec/batch; 1h:19m:20s remains)
INFO - root - 2022-02-24 20:04:16.469752: step 69680, total loss = 0.58, batch loss = 0.31 (149.8 examples/sec; 0.053 sec/batch; 1h:55m:32s remains)
INFO - root - 2022-02-24 20:04:16.858907: step 69690, total loss = 0.68, batch loss = 0.41 (163.6 examples/sec; 0.049 sec/batch; 1h:45m:46s remains)
INFO - root - 2022-02-24 20:04:17.237966: step 69700, total loss = 0.75, batch loss = 0.48 (204.3 examples/sec; 0.039 sec/batch; 1h:24m:42s remains)
INFO - root - 2022-02-24 20:04:17.607932: step 69710, total loss = 0.74, batch loss = 0.47 (308.2 examples/sec; 0.026 sec/batch; 0h:56m:08s remains)
INFO - root - 2022-02-24 20:04:17.946504: step 69720, total loss = 0.63, batch loss = 0.36 (307.6 examples/sec; 0.026 sec/batch; 0h:56m:15s remains)
INFO - root - 2022-02-24 20:04:18.347295: step 69730, total loss = 0.58, batch loss = 0.31 (181.0 examples/sec; 0.044 sec/batch; 1h:35m:36s remains)
INFO - root - 2022-02-24 20:04:18.759164: step 69740, total loss = 0.50, batch loss = 0.23 (329.3 examples/sec; 0.024 sec/batch; 0h:52m:32s remains)
INFO - root - 2022-02-24 20:04:19.125439: step 69750, total loss = 0.51, batch loss = 0.24 (332.4 examples/sec; 0.024 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:04:19.434532: step 69760, total loss = 0.61, batch loss = 0.34 (268.1 examples/sec; 0.030 sec/batch; 1h:04m:31s remains)
INFO - root - 2022-02-24 20:04:19.724193: step 69770, total loss = 0.62, batch loss = 0.35 (346.0 examples/sec; 0.023 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:04:20.317501: step 69780, total loss = 0.60, batch loss = 0.33 (114.0 examples/sec; 0.070 sec/batch; 2h:31m:42s remains)
INFO - root - 2022-02-24 20:04:20.769838: step 69790, total loss = 0.59, batch loss = 0.32 (153.5 examples/sec; 0.052 sec/batch; 1h:52m:39s remains)
INFO - root - 2022-02-24 20:04:21.020174: step 69800, total loss = 0.63, batch loss = 0.36 (266.0 examples/sec; 0.030 sec/batch; 1h:05m:00s remains)
INFO - root - 2022-02-24 20:04:21.430276: step 69810, total loss = 0.54, batch loss = 0.27 (291.9 examples/sec; 0.027 sec/batch; 0h:59m:14s remains)
INFO - root - 2022-02-24 20:04:21.693846: step 69820, total loss = 0.49, batch loss = 0.22 (332.2 examples/sec; 0.024 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:04:22.132660: step 69830, total loss = 0.56, batch loss = 0.29 (91.7 examples/sec; 0.087 sec/batch; 3h:08m:30s remains)
INFO - root - 2022-02-24 20:04:22.617093: step 69840, total loss = 0.52, batch loss = 0.25 (88.7 examples/sec; 0.090 sec/batch; 3h:14m:57s remains)
INFO - root - 2022-02-24 20:04:23.013305: step 69850, total loss = 0.50, batch loss = 0.23 (301.4 examples/sec; 0.027 sec/batch; 0h:57m:20s remains)
INFO - root - 2022-02-24 20:04:23.352033: step 69860, total loss = 0.64, batch loss = 0.37 (313.9 examples/sec; 0.025 sec/batch; 0h:55m:03s remains)
INFO - root - 2022-02-24 20:04:23.677823: step 69870, total loss = 0.63, batch loss = 0.36 (310.7 examples/sec; 0.026 sec/batch; 0h:55m:37s remains)
INFO - root - 2022-02-24 20:04:23.953229: step 69880, total loss = 0.58, batch loss = 0.31 (203.7 examples/sec; 0.039 sec/batch; 1h:24m:51s remains)
INFO - root - 2022-02-24 20:04:24.371500: step 69890, total loss = 0.50, batch loss = 0.23 (222.8 examples/sec; 0.036 sec/batch; 1h:17m:34s remains)
INFO - root - 2022-02-24 20:04:24.752142: step 69900, total loss = 0.53, batch loss = 0.26 (162.6 examples/sec; 0.049 sec/batch; 1h:46m:17s remains)
INFO - root - 2022-02-24 20:04:25.260147: step 69910, total loss = 0.61, batch loss = 0.34 (362.0 examples/sec; 0.022 sec/batch; 0h:47m:43s remains)
INFO - root - 2022-02-24 20:04:25.548193: step 69920, total loss = 0.68, batch loss = 0.41 (335.2 examples/sec; 0.024 sec/batch; 0h:51m:33s remains)
INFO - root - 2022-02-24 20:04:25.873462: step 69930, total loss = 0.54, batch loss = 0.27 (257.2 examples/sec; 0.031 sec/batch; 1h:07m:10s remains)
INFO - root - 2022-02-24 20:04:26.121160: step 69940, total loss = 0.60, batch loss = 0.33 (343.0 examples/sec; 0.023 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:04:26.502678: step 69950, total loss = 0.59, batch loss = 0.32 (129.1 examples/sec; 0.062 sec/batch; 2h:13m:48s remains)
INFO - root - 2022-02-24 20:04:26.899943: step 69960, total loss = 0.53, batch loss = 0.26 (177.1 examples/sec; 0.045 sec/batch; 1h:37m:30s remains)
INFO - root - 2022-02-24 20:04:27.313212: step 69970, total loss = 0.52, batch loss = 0.25 (226.0 examples/sec; 0.035 sec/batch; 1h:16m:25s remains)
INFO - root - 2022-02-24 20:04:27.661601: step 69980, total loss = 0.59, batch loss = 0.32 (286.0 examples/sec; 0.028 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 20:04:28.033317: step 69990, total loss = 0.56, batch loss = 0.29 (357.2 examples/sec; 0.022 sec/batch; 0h:48m:20s remains)
INFO - root - 2022-02-24 20:04:28.325301: step 70000, total loss = 0.72, batch loss = 0.45 (190.7 examples/sec; 0.042 sec/batch; 1h:30m:32s remains)
INFO - root - 2022-02-24 20:04:28.743184: step 70010, total loss = 0.52, batch loss = 0.25 (132.8 examples/sec; 0.060 sec/batch; 2h:10m:01s remains)
INFO - root - 2022-02-24 20:04:29.110848: step 70020, total loss = 0.51, batch loss = 0.24 (199.7 examples/sec; 0.040 sec/batch; 1h:26m:26s remains)
INFO - root - 2022-02-24 20:04:29.537523: step 70030, total loss = 0.66, batch loss = 0.39 (153.0 examples/sec; 0.052 sec/batch; 1h:52m:47s remains)
INFO - root - 2022-02-24 20:04:29.815561: step 70040, total loss = 0.53, batch loss = 0.26 (293.9 examples/sec; 0.027 sec/batch; 0h:58m:43s remains)
INFO - root - 2022-02-24 20:04:30.532361: step 70050, total loss = 0.57, batch loss = 0.30 (222.2 examples/sec; 0.036 sec/batch; 1h:17m:40s remains)
INFO - root - 2022-02-24 20:04:31.065693: step 70060, total loss = 0.57, batch loss = 0.30 (203.6 examples/sec; 0.039 sec/batch; 1h:24m:46s remains)
INFO - root - 2022-02-24 20:04:31.431355: step 70070, total loss = 0.60, batch loss = 0.33 (252.8 examples/sec; 0.032 sec/batch; 1h:08m:15s remains)
INFO - root - 2022-02-24 20:04:31.772637: step 70080, total loss = 0.61, batch loss = 0.34 (282.3 examples/sec; 0.028 sec/batch; 1h:01m:06s remains)
INFO - root - 2022-02-24 20:04:32.089990: step 70090, total loss = 0.58, batch loss = 0.31 (230.9 examples/sec; 0.035 sec/batch; 1h:14m:43s remains)
INFO - root - 2022-02-24 20:04:32.526961: step 70100, total loss = 0.57, batch loss = 0.30 (242.4 examples/sec; 0.033 sec/batch; 1h:11m:10s remains)
INFO - root - 2022-02-24 20:04:33.086168: step 70110, total loss = 0.56, batch loss = 0.29 (56.8 examples/sec; 0.141 sec/batch; 5h:03m:59s remains)
INFO - root - 2022-02-24 20:04:33.654764: step 70120, total loss = 0.47, batch loss = 0.20 (106.0 examples/sec; 0.075 sec/batch; 2h:42m:40s remains)
INFO - root - 2022-02-24 20:04:34.016875: step 70130, total loss = 0.51, batch loss = 0.24 (314.1 examples/sec; 0.025 sec/batch; 0h:54m:55s remains)
INFO - root - 2022-02-24 20:04:34.400288: step 70140, total loss = 0.70, batch loss = 0.43 (305.8 examples/sec; 0.026 sec/batch; 0h:56m:23s remains)
INFO - root - 2022-02-24 20:04:34.713990: step 70150, total loss = 0.63, batch loss = 0.36 (141.0 examples/sec; 0.057 sec/batch; 2h:02m:17s remains)
INFO - root - 2022-02-24 20:04:35.535121: step 70160, total loss = 0.61, batch loss = 0.34 (96.0 examples/sec; 0.083 sec/batch; 2h:59m:43s remains)
INFO - root - 2022-02-24 20:04:36.013068: step 70170, total loss = 0.61, batch loss = 0.34 (361.4 examples/sec; 0.022 sec/batch; 0h:47m:42s remains)
INFO - root - 2022-02-24 20:04:36.276850: step 70180, total loss = 0.60, batch loss = 0.33 (339.5 examples/sec; 0.024 sec/batch; 0h:50m:47s remains)
INFO - root - 2022-02-24 20:04:36.586040: step 70190, total loss = 0.59, batch loss = 0.32 (314.5 examples/sec; 0.025 sec/batch; 0h:54m:48s remains)
INFO - root - 2022-02-24 20:04:36.839757: step 70200, total loss = 0.69, batch loss = 0.42 (381.6 examples/sec; 0.021 sec/batch; 0h:45m:10s remains)
INFO - root - 2022-02-24 20:04:37.342824: step 70210, total loss = 0.49, batch loss = 0.22 (279.8 examples/sec; 0.029 sec/batch; 1h:01m:36s remains)
INFO - root - 2022-02-24 20:04:37.746014: step 70220, total loss = 0.62, batch loss = 0.35 (263.6 examples/sec; 0.030 sec/batch; 1h:05m:23s remains)
INFO - root - 2022-02-24 20:04:38.169055: step 70230, total loss = 0.60, batch loss = 0.33 (131.5 examples/sec; 0.061 sec/batch; 2h:11m:02s remains)
INFO - root - 2022-02-24 20:04:38.528538: step 70240, total loss = 0.59, batch loss = 0.32 (226.5 examples/sec; 0.035 sec/batch; 1h:16m:05s remains)
INFO - root - 2022-02-24 20:04:38.822915: step 70250, total loss = 0.63, batch loss = 0.36 (333.0 examples/sec; 0.024 sec/batch; 0h:51m:45s remains)
INFO - root - 2022-02-24 20:04:39.076345: step 70260, total loss = 0.53, batch loss = 0.26 (247.3 examples/sec; 0.032 sec/batch; 1h:09m:41s remains)
INFO - root - 2022-02-24 20:04:39.398852: step 70270, total loss = 0.65, batch loss = 0.38 (132.9 examples/sec; 0.060 sec/batch; 2h:09m:36s remains)
INFO - root - 2022-02-24 20:04:39.828859: step 70280, total loss = 0.69, batch loss = 0.42 (124.8 examples/sec; 0.064 sec/batch; 2h:18m:00s remains)
INFO - root - 2022-02-24 20:04:40.153953: step 70290, total loss = 0.60, batch loss = 0.33 (238.3 examples/sec; 0.034 sec/batch; 1h:12m:18s remains)
INFO - root - 2022-02-24 20:04:40.433989: step 70300, total loss = 0.54, batch loss = 0.27 (364.7 examples/sec; 0.022 sec/batch; 0h:47m:14s remains)
INFO - root - 2022-02-24 20:04:40.898362: step 70310, total loss = 0.66, batch loss = 0.39 (257.1 examples/sec; 0.031 sec/batch; 1h:06m:59s remains)
INFO - root - 2022-02-24 20:04:41.206822: step 70320, total loss = 0.53, batch loss = 0.26 (180.9 examples/sec; 0.044 sec/batch; 1h:35m:14s remains)
INFO - root - 2022-02-24 20:04:41.568945: step 70330, total loss = 0.54, batch loss = 0.27 (332.7 examples/sec; 0.024 sec/batch; 0h:51m:45s remains)
INFO - root - 2022-02-24 20:04:41.944008: step 70340, total loss = 0.55, batch loss = 0.28 (185.1 examples/sec; 0.043 sec/batch; 1h:33m:01s remains)
INFO - root - 2022-02-24 20:04:42.273833: step 70350, total loss = 0.58, batch loss = 0.31 (182.5 examples/sec; 0.044 sec/batch; 1h:34m:21s remains)
INFO - root - 2022-02-24 20:04:42.608443: step 70360, total loss = 0.64, batch loss = 0.37 (313.7 examples/sec; 0.026 sec/batch; 0h:54m:53s remains)
INFO - root - 2022-02-24 20:04:42.992953: step 70370, total loss = 0.66, batch loss = 0.39 (188.7 examples/sec; 0.042 sec/batch; 1h:31m:14s remains)
INFO - root - 2022-02-24 20:04:43.398701: step 70380, total loss = 0.50, batch loss = 0.23 (245.4 examples/sec; 0.033 sec/batch; 1h:10m:09s remains)
INFO - root - 2022-02-24 20:04:43.776885: step 70390, total loss = 0.55, batch loss = 0.28 (200.4 examples/sec; 0.040 sec/batch; 1h:25m:54s remains)
INFO - root - 2022-02-24 20:04:44.091498: step 70400, total loss = 0.64, batch loss = 0.37 (295.6 examples/sec; 0.027 sec/batch; 0h:58m:14s remains)
INFO - root - 2022-02-24 20:04:44.468230: step 70410, total loss = 0.83, batch loss = 0.56 (330.0 examples/sec; 0.024 sec/batch; 0h:52m:09s remains)
INFO - root - 2022-02-24 20:04:44.773188: step 70420, total loss = 0.57, batch loss = 0.30 (289.0 examples/sec; 0.028 sec/batch; 0h:59m:33s remains)
INFO - root - 2022-02-24 20:04:45.077535: step 70430, total loss = 0.51, batch loss = 0.24 (235.4 examples/sec; 0.034 sec/batch; 1h:13m:07s remains)
INFO - root - 2022-02-24 20:04:45.496123: step 70440, total loss = 0.55, batch loss = 0.28 (311.9 examples/sec; 0.026 sec/batch; 0h:55m:09s remains)
INFO - root - 2022-02-24 20:04:45.986729: step 70450, total loss = 0.50, batch loss = 0.23 (131.5 examples/sec; 0.061 sec/batch; 2h:10m:49s remains)
INFO - root - 2022-02-24 20:04:46.272344: step 70460, total loss = 0.53, batch loss = 0.26 (240.4 examples/sec; 0.033 sec/batch; 1h:11m:34s remains)
INFO - root - 2022-02-24 20:04:46.574553: step 70470, total loss = 0.61, batch loss = 0.34 (261.3 examples/sec; 0.031 sec/batch; 1h:05m:50s remains)
INFO - root - 2022-02-24 20:04:46.860692: step 70480, total loss = 0.79, batch loss = 0.52 (334.9 examples/sec; 0.024 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:04:47.168149: step 70490, total loss = 0.55, batch loss = 0.28 (339.4 examples/sec; 0.024 sec/batch; 0h:50m:40s remains)
INFO - root - 2022-02-24 20:04:47.560727: step 70500, total loss = 0.57, batch loss = 0.30 (147.5 examples/sec; 0.054 sec/batch; 1h:56m:34s remains)
INFO - root - 2022-02-24 20:04:47.993731: step 70510, total loss = 0.49, batch loss = 0.22 (134.8 examples/sec; 0.059 sec/batch; 2h:07m:37s remains)
INFO - root - 2022-02-24 20:04:48.283939: step 70520, total loss = 0.61, batch loss = 0.34 (342.4 examples/sec; 0.023 sec/batch; 0h:50m:13s remains)
INFO - root - 2022-02-24 20:04:48.633127: step 70530, total loss = 0.74, batch loss = 0.47 (262.6 examples/sec; 0.030 sec/batch; 1h:05m:28s remains)
INFO - root - 2022-02-24 20:04:49.270509: step 70540, total loss = 0.53, batch loss = 0.26 (68.4 examples/sec; 0.117 sec/batch; 4h:11m:19s remains)
INFO - root - 2022-02-24 20:04:49.851947: step 70550, total loss = 0.56, batch loss = 0.29 (264.6 examples/sec; 0.030 sec/batch; 1h:04m:59s remains)
INFO - root - 2022-02-24 20:04:50.353098: step 70560, total loss = 0.53, batch loss = 0.26 (218.4 examples/sec; 0.037 sec/batch; 1h:18m:43s remains)
INFO - root - 2022-02-24 20:04:51.228524: step 70570, total loss = 0.58, batch loss = 0.31 (14.5 examples/sec; 0.551 sec/batch; 19h:44m:28s remains)
INFO - root - 2022-02-24 20:04:51.628138: step 70580, total loss = 0.71, batch loss = 0.44 (273.5 examples/sec; 0.029 sec/batch; 1h:02m:51s remains)
INFO - root - 2022-02-24 20:04:52.056908: step 70590, total loss = 0.68, batch loss = 0.41 (258.9 examples/sec; 0.031 sec/batch; 1h:06m:22s remains)
INFO - root - 2022-02-24 20:04:52.374962: step 70600, total loss = 0.51, batch loss = 0.25 (319.1 examples/sec; 0.025 sec/batch; 0h:53m:51s remains)
INFO - root - 2022-02-24 20:04:52.735802: step 70610, total loss = 0.51, batch loss = 0.24 (333.3 examples/sec; 0.024 sec/batch; 0h:51m:33s remains)
INFO - root - 2022-02-24 20:04:53.062125: step 70620, total loss = 0.59, batch loss = 0.32 (90.6 examples/sec; 0.088 sec/batch; 3h:09m:41s remains)
INFO - root - 2022-02-24 20:04:53.440814: step 70630, total loss = 0.58, batch loss = 0.31 (145.8 examples/sec; 0.055 sec/batch; 1h:57m:51s remains)
INFO - root - 2022-02-24 20:04:53.893150: step 70640, total loss = 0.56, batch loss = 0.29 (135.7 examples/sec; 0.059 sec/batch; 2h:06m:34s remains)
INFO - root - 2022-02-24 20:04:54.240865: step 70650, total loss = 0.49, batch loss = 0.22 (166.7 examples/sec; 0.048 sec/batch; 1h:43m:02s remains)
INFO - root - 2022-02-24 20:04:54.549279: step 70660, total loss = 0.60, batch loss = 0.33 (232.5 examples/sec; 0.034 sec/batch; 1h:13m:52s remains)
INFO - root - 2022-02-24 20:04:54.985292: step 70670, total loss = 0.59, batch loss = 0.32 (316.4 examples/sec; 0.025 sec/batch; 0h:54m:17s remains)
INFO - root - 2022-02-24 20:04:55.380202: step 70680, total loss = 0.56, batch loss = 0.29 (275.1 examples/sec; 0.029 sec/batch; 1h:02m:26s remains)
INFO - root - 2022-02-24 20:04:55.825757: step 70690, total loss = 0.57, batch loss = 0.30 (156.6 examples/sec; 0.051 sec/batch; 1h:49m:39s remains)
INFO - root - 2022-02-24 20:04:56.076680: step 70700, total loss = 0.68, batch loss = 0.41 (329.7 examples/sec; 0.024 sec/batch; 0h:52m:05s remains)
INFO - root - 2022-02-24 20:04:56.498498: step 70710, total loss = 0.49, batch loss = 0.22 (303.9 examples/sec; 0.026 sec/batch; 0h:56m:30s remains)
INFO - root - 2022-02-24 20:04:56.764307: step 70720, total loss = 0.61, batch loss = 0.34 (352.3 examples/sec; 0.023 sec/batch; 0h:48m:44s remains)
INFO - root - 2022-02-24 20:04:57.098577: step 70730, total loss = 0.52, batch loss = 0.25 (141.0 examples/sec; 0.057 sec/batch; 2h:01m:46s remains)
INFO - root - 2022-02-24 20:04:57.492893: step 70740, total loss = 0.50, batch loss = 0.23 (200.0 examples/sec; 0.040 sec/batch; 1h:25m:51s remains)
INFO - root - 2022-02-24 20:04:57.872977: step 70750, total loss = 0.55, batch loss = 0.28 (271.6 examples/sec; 0.029 sec/batch; 1h:03m:12s remains)
INFO - root - 2022-02-24 20:04:58.215443: step 70760, total loss = 0.55, batch loss = 0.28 (142.5 examples/sec; 0.056 sec/batch; 2h:00m:27s remains)
INFO - root - 2022-02-24 20:04:58.546403: step 70770, total loss = 0.62, batch loss = 0.35 (343.0 examples/sec; 0.023 sec/batch; 0h:50m:02s remains)
INFO - root - 2022-02-24 20:04:58.901177: step 70780, total loss = 0.50, batch loss = 0.23 (206.0 examples/sec; 0.039 sec/batch; 1h:23m:19s remains)
INFO - root - 2022-02-24 20:04:59.218558: step 70790, total loss = 0.51, batch loss = 0.24 (145.9 examples/sec; 0.055 sec/batch; 1h:57m:39s remains)
INFO - root - 2022-02-24 20:04:59.557776: step 70800, total loss = 0.47, batch loss = 0.20 (205.5 examples/sec; 0.039 sec/batch; 1h:23m:29s remains)
INFO - root - 2022-02-24 20:04:59.915134: step 70810, total loss = 0.52, batch loss = 0.26 (238.2 examples/sec; 0.034 sec/batch; 1h:12m:02s remains)
INFO - root - 2022-02-24 20:05:00.229595: step 70820, total loss = 0.66, batch loss = 0.40 (212.6 examples/sec; 0.038 sec/batch; 1h:20m:41s remains)
INFO - root - 2022-02-24 20:05:00.744342: step 70830, total loss = 0.57, batch loss = 0.30 (82.1 examples/sec; 0.097 sec/batch; 3h:28m:55s remains)
INFO - root - 2022-02-24 20:05:01.295224: step 70840, total loss = 0.59, batch loss = 0.32 (94.1 examples/sec; 0.085 sec/batch; 3h:02m:15s remains)
INFO - root - 2022-02-24 20:05:02.426511: step 70850, total loss = 0.52, batch loss = 0.25 (349.8 examples/sec; 0.023 sec/batch; 0h:49m:01s remains)
INFO - root - 2022-02-24 20:05:02.917359: step 70860, total loss = 0.59, batch loss = 0.32 (80.2 examples/sec; 0.100 sec/batch; 3h:33m:49s remains)
INFO - root - 2022-02-24 20:05:03.429195: step 70870, total loss = 0.52, batch loss = 0.25 (166.5 examples/sec; 0.048 sec/batch; 1h:43m:00s remains)
INFO - root - 2022-02-24 20:05:04.018861: step 70880, total loss = 0.50, batch loss = 0.23 (315.2 examples/sec; 0.025 sec/batch; 0h:54m:24s remains)
INFO - root - 2022-02-24 20:05:04.382292: step 70890, total loss = 0.59, batch loss = 0.32 (234.4 examples/sec; 0.034 sec/batch; 1h:13m:09s remains)
INFO - root - 2022-02-24 20:05:04.871081: step 70900, total loss = 0.58, batch loss = 0.31 (99.5 examples/sec; 0.080 sec/batch; 2h:52m:15s remains)
INFO - root - 2022-02-24 20:05:05.618507: step 70910, total loss = 0.55, batch loss = 0.28 (116.6 examples/sec; 0.069 sec/batch; 2h:27m:00s remains)
INFO - root - 2022-02-24 20:05:06.103172: step 70920, total loss = 0.75, batch loss = 0.48 (352.4 examples/sec; 0.023 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 20:05:06.701047: step 70930, total loss = 0.48, batch loss = 0.21 (158.4 examples/sec; 0.051 sec/batch; 1h:48m:14s remains)
INFO - root - 2022-02-24 20:05:07.246432: step 70940, total loss = 0.57, batch loss = 0.30 (106.4 examples/sec; 0.075 sec/batch; 2h:41m:07s remains)
INFO - root - 2022-02-24 20:05:08.804728: step 70950, total loss = 0.57, batch loss = 0.30 (203.8 examples/sec; 0.039 sec/batch; 1h:24m:06s remains)
INFO - root - 2022-02-24 20:05:09.364360: step 70960, total loss = 0.66, batch loss = 0.39 (232.3 examples/sec; 0.034 sec/batch; 1h:13m:45s remains)
INFO - root - 2022-02-24 20:05:09.746272: step 70970, total loss = 0.67, batch loss = 0.40 (337.3 examples/sec; 0.024 sec/batch; 0h:50m:48s remains)
INFO - root - 2022-02-24 20:05:10.077161: step 70980, total loss = 0.77, batch loss = 0.50 (357.8 examples/sec; 0.022 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:05:10.390633: step 70990, total loss = 0.51, batch loss = 0.24 (191.0 examples/sec; 0.042 sec/batch; 1h:29m:42s remains)
INFO - root - 2022-02-24 20:05:10.717425: step 71000, total loss = 0.55, batch loss = 0.28 (222.4 examples/sec; 0.036 sec/batch; 1h:17m:02s remains)
INFO - root - 2022-02-24 20:05:11.210760: step 71010, total loss = 0.58, batch loss = 0.31 (238.1 examples/sec; 0.034 sec/batch; 1h:11m:57s remains)
INFO - root - 2022-02-24 20:05:11.634475: step 71020, total loss = 0.46, batch loss = 0.19 (361.8 examples/sec; 0.022 sec/batch; 0h:47m:21s remains)
INFO - root - 2022-02-24 20:05:11.934691: step 71030, total loss = 0.63, batch loss = 0.36 (260.9 examples/sec; 0.031 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:05:12.262504: step 71040, total loss = 0.52, batch loss = 0.25 (341.3 examples/sec; 0.023 sec/batch; 0h:50m:11s remains)
INFO - root - 2022-02-24 20:05:12.593659: step 71050, total loss = 0.48, batch loss = 0.21 (361.9 examples/sec; 0.022 sec/batch; 0h:47m:19s remains)
INFO - root - 2022-02-24 20:05:12.921957: step 71060, total loss = 0.52, batch loss = 0.25 (131.4 examples/sec; 0.061 sec/batch; 2h:10m:18s remains)
INFO - root - 2022-02-24 20:05:13.387476: step 71070, total loss = 0.53, batch loss = 0.26 (112.9 examples/sec; 0.071 sec/batch; 2h:31m:40s remains)
INFO - root - 2022-02-24 20:05:13.836011: step 71080, total loss = 0.59, batch loss = 0.32 (253.8 examples/sec; 0.032 sec/batch; 1h:07m:27s remains)
INFO - root - 2022-02-24 20:05:14.133960: step 71090, total loss = 0.62, batch loss = 0.35 (362.1 examples/sec; 0.022 sec/batch; 0h:47m:17s remains)
INFO - root - 2022-02-24 20:05:14.455288: step 71100, total loss = 0.57, batch loss = 0.30 (258.9 examples/sec; 0.031 sec/batch; 1h:06m:08s remains)
INFO - root - 2022-02-24 20:05:14.853620: step 71110, total loss = 0.50, batch loss = 0.23 (168.1 examples/sec; 0.048 sec/batch; 1h:41m:48s remains)
INFO - root - 2022-02-24 20:05:15.249351: step 71120, total loss = 0.54, batch loss = 0.27 (353.7 examples/sec; 0.023 sec/batch; 0h:48m:23s remains)
INFO - root - 2022-02-24 20:05:15.594472: step 71130, total loss = 0.61, batch loss = 0.34 (216.9 examples/sec; 0.037 sec/batch; 1h:18m:53s remains)
INFO - root - 2022-02-24 20:05:15.918992: step 71140, total loss = 0.73, batch loss = 0.46 (327.9 examples/sec; 0.024 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:05:16.202135: step 71150, total loss = 0.54, batch loss = 0.27 (211.6 examples/sec; 0.038 sec/batch; 1h:20m:52s remains)
INFO - root - 2022-02-24 20:05:16.668549: step 71160, total loss = 0.50, batch loss = 0.23 (93.7 examples/sec; 0.085 sec/batch; 3h:02m:35s remains)
INFO - root - 2022-02-24 20:05:16.986694: step 71170, total loss = 0.55, batch loss = 0.28 (224.8 examples/sec; 0.036 sec/batch; 1h:16m:07s remains)
INFO - root - 2022-02-24 20:05:17.329625: step 71180, total loss = 0.56, batch loss = 0.29 (348.1 examples/sec; 0.023 sec/batch; 0h:49m:09s remains)
INFO - root - 2022-02-24 20:05:17.757921: step 71190, total loss = 0.54, batch loss = 0.27 (317.8 examples/sec; 0.025 sec/batch; 0h:53m:50s remains)
INFO - root - 2022-02-24 20:05:18.107035: step 71200, total loss = 0.62, batch loss = 0.35 (361.7 examples/sec; 0.022 sec/batch; 0h:47m:17s remains)
INFO - root - 2022-02-24 20:05:18.479519: step 71210, total loss = 0.59, batch loss = 0.32 (324.1 examples/sec; 0.025 sec/batch; 0h:52m:46s remains)
INFO - root - 2022-02-24 20:05:18.823811: step 71220, total loss = 0.53, batch loss = 0.26 (287.4 examples/sec; 0.028 sec/batch; 0h:59m:30s remains)
INFO - root - 2022-02-24 20:05:19.198913: step 71230, total loss = 0.49, batch loss = 0.22 (353.9 examples/sec; 0.023 sec/batch; 0h:48m:19s remains)
INFO - root - 2022-02-24 20:05:19.694856: step 71240, total loss = 0.57, batch loss = 0.30 (137.0 examples/sec; 0.058 sec/batch; 2h:04m:48s remains)
INFO - root - 2022-02-24 20:05:19.981621: step 71250, total loss = 0.60, batch loss = 0.33 (370.3 examples/sec; 0.022 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:05:20.231603: step 71260, total loss = 0.54, batch loss = 0.27 (341.1 examples/sec; 0.023 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:05:20.554910: step 71270, total loss = 0.55, batch loss = 0.28 (319.2 examples/sec; 0.025 sec/batch; 0h:53m:33s remains)
INFO - root - 2022-02-24 20:05:20.857953: step 71280, total loss = 0.64, batch loss = 0.37 (339.7 examples/sec; 0.024 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 20:05:21.255942: step 71290, total loss = 0.54, batch loss = 0.27 (181.3 examples/sec; 0.044 sec/batch; 1h:34m:16s remains)
INFO - root - 2022-02-24 20:05:21.642764: step 71300, total loss = 0.56, batch loss = 0.29 (151.2 examples/sec; 0.053 sec/batch; 1h:53m:04s remains)
INFO - root - 2022-02-24 20:05:22.093954: step 71310, total loss = 0.59, batch loss = 0.32 (325.0 examples/sec; 0.025 sec/batch; 0h:52m:35s remains)
INFO - root - 2022-02-24 20:05:22.426122: step 71320, total loss = 0.57, batch loss = 0.30 (269.3 examples/sec; 0.030 sec/batch; 1h:03m:28s remains)
INFO - root - 2022-02-24 20:05:22.702928: step 71330, total loss = 0.53, batch loss = 0.26 (362.6 examples/sec; 0.022 sec/batch; 0h:47m:08s remains)
INFO - root - 2022-02-24 20:05:22.995215: step 71340, total loss = 0.54, batch loss = 0.27 (314.2 examples/sec; 0.025 sec/batch; 0h:54m:22s remains)
INFO - root - 2022-02-24 20:05:23.380558: step 71350, total loss = 0.52, batch loss = 0.25 (267.3 examples/sec; 0.030 sec/batch; 1h:03m:54s remains)
INFO - root - 2022-02-24 20:05:23.815303: step 71360, total loss = 0.64, batch loss = 0.37 (216.5 examples/sec; 0.037 sec/batch; 1h:18m:54s remains)
INFO - root - 2022-02-24 20:05:24.247408: step 71370, total loss = 0.46, batch loss = 0.19 (213.8 examples/sec; 0.037 sec/batch; 1h:19m:54s remains)
INFO - root - 2022-02-24 20:05:24.512915: step 71380, total loss = 0.61, batch loss = 0.34 (181.2 examples/sec; 0.044 sec/batch; 1h:34m:16s remains)
INFO - root - 2022-02-24 20:05:24.862379: step 71390, total loss = 0.51, batch loss = 0.24 (197.8 examples/sec; 0.040 sec/batch; 1h:26m:22s remains)
INFO - root - 2022-02-24 20:05:25.183510: step 71400, total loss = 0.59, batch loss = 0.32 (222.7 examples/sec; 0.036 sec/batch; 1h:16m:42s remains)
INFO - root - 2022-02-24 20:05:25.546351: step 71410, total loss = 0.56, batch loss = 0.29 (344.2 examples/sec; 0.023 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 20:05:25.895060: step 71420, total loss = 0.50, batch loss = 0.23 (160.4 examples/sec; 0.050 sec/batch; 1h:46m:28s remains)
INFO - root - 2022-02-24 20:05:26.317720: step 71430, total loss = 0.53, batch loss = 0.26 (340.6 examples/sec; 0.023 sec/batch; 0h:50m:08s remains)
INFO - root - 2022-02-24 20:05:26.689683: step 71440, total loss = 0.52, batch loss = 0.25 (258.0 examples/sec; 0.031 sec/batch; 1h:06m:10s remains)
INFO - root - 2022-02-24 20:05:27.344675: step 71450, total loss = 0.52, batch loss = 0.25 (349.0 examples/sec; 0.023 sec/batch; 0h:48m:54s remains)
INFO - root - 2022-02-24 20:05:27.683147: step 71460, total loss = 0.51, batch loss = 0.24 (143.2 examples/sec; 0.056 sec/batch; 1h:59m:11s remains)
INFO - root - 2022-02-24 20:05:28.168819: step 71470, total loss = 0.50, batch loss = 0.23 (130.3 examples/sec; 0.061 sec/batch; 2h:10m:59s remains)
INFO - root - 2022-02-24 20:05:28.484512: step 71480, total loss = 0.62, batch loss = 0.35 (310.0 examples/sec; 0.026 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:05:28.803084: step 71490, total loss = 0.50, batch loss = 0.23 (142.7 examples/sec; 0.056 sec/batch; 1h:59m:38s remains)
INFO - root - 2022-02-24 20:05:29.176103: step 71500, total loss = 0.60, batch loss = 0.33 (359.3 examples/sec; 0.022 sec/batch; 0h:47m:29s remains)
INFO - root - 2022-02-24 20:05:29.719183: step 71510, total loss = 0.49, batch loss = 0.22 (118.9 examples/sec; 0.067 sec/batch; 2h:23m:34s remains)
INFO - root - 2022-02-24 20:05:30.132551: step 71520, total loss = 0.59, batch loss = 0.32 (357.7 examples/sec; 0.022 sec/batch; 0h:47m:42s remains)
INFO - root - 2022-02-24 20:05:30.609339: step 71530, total loss = 0.81, batch loss = 0.54 (102.0 examples/sec; 0.078 sec/batch; 2h:47m:18s remains)
INFO - root - 2022-02-24 20:05:31.166897: step 71540, total loss = 0.56, batch loss = 0.29 (287.9 examples/sec; 0.028 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 20:05:31.752226: step 71550, total loss = 0.53, batch loss = 0.26 (172.4 examples/sec; 0.046 sec/batch; 1h:38m:55s remains)
INFO - root - 2022-02-24 20:05:32.584662: step 71560, total loss = 0.56, batch loss = 0.29 (281.9 examples/sec; 0.028 sec/batch; 1h:00m:30s remains)
INFO - root - 2022-02-24 20:05:32.948987: step 71570, total loss = 0.56, batch loss = 0.29 (296.5 examples/sec; 0.027 sec/batch; 0h:57m:32s remains)
INFO - root - 2022-02-24 20:05:33.291187: step 71580, total loss = 0.62, batch loss = 0.35 (141.6 examples/sec; 0.057 sec/batch; 2h:00m:28s remains)
INFO - root - 2022-02-24 20:05:33.615531: step 71590, total loss = 0.51, batch loss = 0.24 (187.2 examples/sec; 0.043 sec/batch; 1h:31m:05s remains)
INFO - root - 2022-02-24 20:05:34.027750: step 71600, total loss = 0.52, batch loss = 0.25 (133.3 examples/sec; 0.060 sec/batch; 2h:07m:58s remains)
INFO - root - 2022-02-24 20:05:34.538534: step 71610, total loss = 0.58, batch loss = 0.32 (328.2 examples/sec; 0.024 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 20:05:34.916739: step 71620, total loss = 0.67, batch loss = 0.40 (270.5 examples/sec; 0.030 sec/batch; 1h:03m:01s remains)
INFO - root - 2022-02-24 20:05:35.317140: step 71630, total loss = 0.67, batch loss = 0.40 (217.2 examples/sec; 0.037 sec/batch; 1h:18m:30s remains)
INFO - root - 2022-02-24 20:05:35.719951: step 71640, total loss = 0.67, batch loss = 0.40 (140.1 examples/sec; 0.057 sec/batch; 2h:01m:40s remains)
INFO - root - 2022-02-24 20:05:36.158075: step 71650, total loss = 0.60, batch loss = 0.33 (189.1 examples/sec; 0.042 sec/batch; 1h:30m:09s remains)
INFO - root - 2022-02-24 20:05:36.648136: step 71660, total loss = 0.60, batch loss = 0.33 (147.6 examples/sec; 0.054 sec/batch; 1h:55m:30s remains)
INFO - root - 2022-02-24 20:05:37.071824: step 71670, total loss = 0.54, batch loss = 0.27 (323.6 examples/sec; 0.025 sec/batch; 0h:52m:39s remains)
INFO - root - 2022-02-24 20:05:37.377895: step 71680, total loss = 0.48, batch loss = 0.21 (307.8 examples/sec; 0.026 sec/batch; 0h:55m:22s remains)
INFO - root - 2022-02-24 20:05:37.758603: step 71690, total loss = 0.49, batch loss = 0.22 (148.5 examples/sec; 0.054 sec/batch; 1h:54m:44s remains)
INFO - root - 2022-02-24 20:05:38.131148: step 71700, total loss = 0.58, batch loss = 0.31 (352.5 examples/sec; 0.023 sec/batch; 0h:48m:20s remains)
INFO - root - 2022-02-24 20:05:38.626132: step 71710, total loss = 0.58, batch loss = 0.31 (130.9 examples/sec; 0.061 sec/batch; 2h:10m:12s remains)
INFO - root - 2022-02-24 20:05:39.028757: step 71720, total loss = 0.69, batch loss = 0.42 (251.2 examples/sec; 0.032 sec/batch; 1h:07m:48s remains)
INFO - root - 2022-02-24 20:05:39.354095: step 71730, total loss = 0.74, batch loss = 0.47 (320.3 examples/sec; 0.025 sec/batch; 0h:53m:11s remains)
INFO - root - 2022-02-24 20:05:39.652644: step 71740, total loss = 0.56, batch loss = 0.29 (353.0 examples/sec; 0.023 sec/batch; 0h:48m:15s remains)
INFO - root - 2022-02-24 20:05:39.990492: step 71750, total loss = 0.56, batch loss = 0.29 (306.5 examples/sec; 0.026 sec/batch; 0h:55m:34s remains)
INFO - root - 2022-02-24 20:05:40.327140: step 71760, total loss = 0.58, batch loss = 0.31 (197.6 examples/sec; 0.040 sec/batch; 1h:26m:12s remains)
INFO - root - 2022-02-24 20:05:40.735229: step 71770, total loss = 0.62, batch loss = 0.35 (152.0 examples/sec; 0.053 sec/batch; 1h:52m:01s remains)
INFO - root - 2022-02-24 20:05:41.053509: step 71780, total loss = 0.53, batch loss = 0.26 (189.1 examples/sec; 0.042 sec/batch; 1h:30m:04s remains)
INFO - root - 2022-02-24 20:05:41.376662: step 71790, total loss = 0.63, batch loss = 0.36 (288.4 examples/sec; 0.028 sec/batch; 0h:59m:02s remains)
INFO - root - 2022-02-24 20:05:41.731483: step 71800, total loss = 0.63, batch loss = 0.36 (138.5 examples/sec; 0.058 sec/batch; 2h:02m:57s remains)
INFO - root - 2022-02-24 20:05:42.263420: step 71810, total loss = 0.65, batch loss = 0.38 (145.3 examples/sec; 0.055 sec/batch; 1h:57m:11s remains)
INFO - root - 2022-02-24 20:05:42.661348: step 71820, total loss = 0.56, batch loss = 0.29 (293.3 examples/sec; 0.027 sec/batch; 0h:58m:02s remains)
INFO - root - 2022-02-24 20:05:43.065849: step 71830, total loss = 0.58, batch loss = 0.31 (147.2 examples/sec; 0.054 sec/batch; 1h:55m:37s remains)
INFO - root - 2022-02-24 20:05:43.386685: step 71840, total loss = 0.55, batch loss = 0.28 (200.6 examples/sec; 0.040 sec/batch; 1h:24m:51s remains)
INFO - root - 2022-02-24 20:05:43.698718: step 71850, total loss = 0.47, batch loss = 0.20 (335.4 examples/sec; 0.024 sec/batch; 0h:50m:44s remains)
INFO - root - 2022-02-24 20:05:44.042063: step 71860, total loss = 0.51, batch loss = 0.24 (138.5 examples/sec; 0.058 sec/batch; 2h:02m:52s remains)
INFO - root - 2022-02-24 20:05:44.409950: step 71870, total loss = 0.46, batch loss = 0.19 (133.7 examples/sec; 0.060 sec/batch; 2h:07m:14s remains)
INFO - root - 2022-02-24 20:05:44.836684: step 71880, total loss = 0.50, batch loss = 0.23 (272.7 examples/sec; 0.029 sec/batch; 1h:02m:23s remains)
INFO - root - 2022-02-24 20:05:45.263943: step 71890, total loss = 0.62, batch loss = 0.35 (269.5 examples/sec; 0.030 sec/batch; 1h:03m:08s remains)
INFO - root - 2022-02-24 20:05:45.528493: step 71900, total loss = 0.51, batch loss = 0.24 (300.4 examples/sec; 0.027 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 20:05:45.888376: step 71910, total loss = 0.49, batch loss = 0.22 (336.2 examples/sec; 0.024 sec/batch; 0h:50m:36s remains)
INFO - root - 2022-02-24 20:05:46.206989: step 71920, total loss = 0.55, batch loss = 0.28 (167.3 examples/sec; 0.048 sec/batch; 1h:41m:42s remains)
INFO - root - 2022-02-24 20:05:46.550591: step 71930, total loss = 0.72, batch loss = 0.45 (140.4 examples/sec; 0.057 sec/batch; 2h:01m:06s remains)
INFO - root - 2022-02-24 20:05:46.952898: step 71940, total loss = 0.62, batch loss = 0.35 (169.8 examples/sec; 0.047 sec/batch; 1h:40m:09s remains)
INFO - root - 2022-02-24 20:05:47.386202: step 71950, total loss = 0.56, batch loss = 0.29 (284.0 examples/sec; 0.028 sec/batch; 0h:59m:52s remains)
INFO - root - 2022-02-24 20:05:47.744861: step 71960, total loss = 0.67, batch loss = 0.40 (159.0 examples/sec; 0.050 sec/batch; 1h:46m:57s remains)
INFO - root - 2022-02-24 20:05:48.042643: step 71970, total loss = 0.53, batch loss = 0.26 (255.1 examples/sec; 0.031 sec/batch; 1h:06m:39s remains)
INFO - root - 2022-02-24 20:05:48.475706: step 71980, total loss = 0.53, batch loss = 0.26 (133.0 examples/sec; 0.060 sec/batch; 2h:07m:52s remains)
INFO - root - 2022-02-24 20:05:48.911826: step 71990, total loss = 0.47, batch loss = 0.20 (115.2 examples/sec; 0.069 sec/batch; 2h:27m:34s remains)
INFO - root - 2022-02-24 20:05:49.352061: step 72000, total loss = 0.54, batch loss = 0.27 (132.8 examples/sec; 0.060 sec/batch; 2h:07m:59s remains)
INFO - root - 2022-02-24 20:05:49.752390: step 72010, total loss = 0.62, batch loss = 0.35 (218.9 examples/sec; 0.037 sec/batch; 1h:17m:38s remains)
INFO - root - 2022-02-24 20:05:50.159635: step 72020, total loss = 0.55, batch loss = 0.28 (142.9 examples/sec; 0.056 sec/batch; 1h:58m:57s remains)
INFO - root - 2022-02-24 20:05:50.646344: step 72030, total loss = 0.47, batch loss = 0.20 (161.3 examples/sec; 0.050 sec/batch; 1h:45m:20s remains)
INFO - root - 2022-02-24 20:05:51.169097: step 72040, total loss = 0.57, batch loss = 0.30 (253.4 examples/sec; 0.032 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:05:51.566810: step 72050, total loss = 0.54, batch loss = 0.27 (133.4 examples/sec; 0.060 sec/batch; 2h:07m:21s remains)
INFO - root - 2022-02-24 20:05:52.031077: step 72060, total loss = 0.62, batch loss = 0.35 (102.6 examples/sec; 0.078 sec/batch; 2h:45m:32s remains)
INFO - root - 2022-02-24 20:05:52.979301: step 72070, total loss = 0.67, batch loss = 0.40 (125.8 examples/sec; 0.064 sec/batch; 2h:15m:01s remains)
INFO - root - 2022-02-24 20:05:53.460813: step 72080, total loss = 0.56, batch loss = 0.29 (240.0 examples/sec; 0.033 sec/batch; 1h:10m:47s remains)
INFO - root - 2022-02-24 20:05:53.820926: step 72090, total loss = 0.60, batch loss = 0.33 (195.9 examples/sec; 0.041 sec/batch; 1h:26m:43s remains)
INFO - root - 2022-02-24 20:05:54.203662: step 72100, total loss = 0.62, batch loss = 0.35 (255.8 examples/sec; 0.031 sec/batch; 1h:06m:23s remains)
INFO - root - 2022-02-24 20:05:54.618318: step 72110, total loss = 0.51, batch loss = 0.24 (326.5 examples/sec; 0.024 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:05:54.999024: step 72120, total loss = 0.66, batch loss = 0.39 (242.9 examples/sec; 0.033 sec/batch; 1h:09m:55s remains)
INFO - root - 2022-02-24 20:05:55.502004: step 72130, total loss = 0.57, batch loss = 0.30 (150.7 examples/sec; 0.053 sec/batch; 1h:52m:41s remains)
INFO - root - 2022-02-24 20:05:55.818757: step 72140, total loss = 0.57, batch loss = 0.30 (227.3 examples/sec; 0.035 sec/batch; 1h:14m:41s remains)
INFO - root - 2022-02-24 20:05:56.194620: step 72150, total loss = 0.53, batch loss = 0.26 (273.4 examples/sec; 0.029 sec/batch; 1h:02m:07s remains)
INFO - root - 2022-02-24 20:05:56.573227: step 72160, total loss = 0.54, batch loss = 0.27 (173.8 examples/sec; 0.046 sec/batch; 1h:37m:40s remains)
INFO - root - 2022-02-24 20:05:56.935210: step 72170, total loss = 0.47, batch loss = 0.20 (150.4 examples/sec; 0.053 sec/batch; 1h:52m:52s remains)
INFO - root - 2022-02-24 20:05:57.606262: step 72180, total loss = 0.56, batch loss = 0.29 (151.6 examples/sec; 0.053 sec/batch; 1h:52m:00s remains)
INFO - root - 2022-02-24 20:05:58.042728: step 72190, total loss = 0.70, batch loss = 0.43 (233.1 examples/sec; 0.034 sec/batch; 1h:12m:48s remains)
INFO - root - 2022-02-24 20:05:58.376466: step 72200, total loss = 0.51, batch loss = 0.24 (136.5 examples/sec; 0.059 sec/batch; 2h:04m:19s remains)
INFO - root - 2022-02-24 20:05:58.703618: step 72210, total loss = 0.56, batch loss = 0.29 (352.2 examples/sec; 0.023 sec/batch; 0h:48m:11s remains)
INFO - root - 2022-02-24 20:05:59.045793: step 72220, total loss = 0.51, batch loss = 0.24 (365.9 examples/sec; 0.022 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:05:59.634420: step 72230, total loss = 0.59, batch loss = 0.32 (318.7 examples/sec; 0.025 sec/batch; 0h:53m:15s remains)
INFO - root - 2022-02-24 20:06:00.039495: step 72240, total loss = 0.54, batch loss = 0.27 (328.7 examples/sec; 0.024 sec/batch; 0h:51m:37s remains)
INFO - root - 2022-02-24 20:06:00.359934: step 72250, total loss = 0.66, batch loss = 0.39 (347.9 examples/sec; 0.023 sec/batch; 0h:48m:45s remains)
INFO - root - 2022-02-24 20:06:00.691410: step 72260, total loss = 0.55, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 0h:51m:24s remains)
INFO - root - 2022-02-24 20:06:01.072133: step 72270, total loss = 0.71, batch loss = 0.44 (154.2 examples/sec; 0.052 sec/batch; 1h:50m:01s remains)
INFO - root - 2022-02-24 20:06:01.511643: step 72280, total loss = 0.59, batch loss = 0.32 (158.0 examples/sec; 0.051 sec/batch; 1h:47m:20s remains)
INFO - root - 2022-02-24 20:06:01.920255: step 72290, total loss = 0.53, batch loss = 0.26 (118.0 examples/sec; 0.068 sec/batch; 2h:23m:47s remains)
INFO - root - 2022-02-24 20:06:02.232900: step 72300, total loss = 0.60, batch loss = 0.33 (241.3 examples/sec; 0.033 sec/batch; 1h:10m:17s remains)
INFO - root - 2022-02-24 20:06:02.621583: step 72310, total loss = 0.58, batch loss = 0.31 (201.4 examples/sec; 0.040 sec/batch; 1h:24m:12s remains)
INFO - root - 2022-02-24 20:06:02.929508: step 72320, total loss = 0.51, batch loss = 0.24 (322.2 examples/sec; 0.025 sec/batch; 0h:52m:37s remains)
INFO - root - 2022-02-24 20:06:03.334508: step 72330, total loss = 0.67, batch loss = 0.40 (198.2 examples/sec; 0.040 sec/batch; 1h:25m:34s remains)
INFO - root - 2022-02-24 20:06:03.738246: step 72340, total loss = 0.58, batch loss = 0.31 (298.4 examples/sec; 0.027 sec/batch; 0h:56m:49s remains)
INFO - root - 2022-02-24 20:06:04.126289: step 72350, total loss = 0.56, batch loss = 0.29 (294.0 examples/sec; 0.027 sec/batch; 0h:57m:39s remains)
INFO - root - 2022-02-24 20:06:04.395018: step 72360, total loss = 0.60, batch loss = 0.33 (189.8 examples/sec; 0.042 sec/batch; 1h:29m:19s remains)
INFO - root - 2022-02-24 20:06:04.729360: step 72370, total loss = 0.59, batch loss = 0.32 (202.7 examples/sec; 0.039 sec/batch; 1h:23m:37s remains)
INFO - root - 2022-02-24 20:06:05.043249: step 72380, total loss = 0.55, batch loss = 0.28 (306.7 examples/sec; 0.026 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:06:05.407070: step 72390, total loss = 0.48, batch loss = 0.21 (331.0 examples/sec; 0.024 sec/batch; 0h:51m:12s remains)
INFO - root - 2022-02-24 20:06:05.775634: step 72400, total loss = 0.53, batch loss = 0.26 (326.3 examples/sec; 0.025 sec/batch; 0h:51m:56s remains)
INFO - root - 2022-02-24 20:06:06.207461: step 72410, total loss = 0.63, batch loss = 0.36 (149.0 examples/sec; 0.054 sec/batch; 1h:53m:44s remains)
INFO - root - 2022-02-24 20:06:06.494010: step 72420, total loss = 0.50, batch loss = 0.23 (324.8 examples/sec; 0.025 sec/batch; 0h:52m:09s remains)
INFO - root - 2022-02-24 20:06:06.773000: step 72430, total loss = 0.58, batch loss = 0.31 (213.9 examples/sec; 0.037 sec/batch; 1h:19m:12s remains)
INFO - root - 2022-02-24 20:06:07.073159: step 72440, total loss = 0.57, batch loss = 0.30 (331.0 examples/sec; 0.024 sec/batch; 0h:51m:11s remains)
INFO - root - 2022-02-24 20:06:07.376248: step 72450, total loss = 0.50, batch loss = 0.23 (205.6 examples/sec; 0.039 sec/batch; 1h:22m:23s remains)
INFO - root - 2022-02-24 20:06:07.789491: step 72460, total loss = 0.62, batch loss = 0.35 (241.7 examples/sec; 0.033 sec/batch; 1h:10m:04s remains)
INFO - root - 2022-02-24 20:06:08.176948: step 72470, total loss = 0.56, batch loss = 0.29 (363.6 examples/sec; 0.022 sec/batch; 0h:46m:34s remains)
INFO - root - 2022-02-24 20:06:08.594379: step 72480, total loss = 0.73, batch loss = 0.46 (291.2 examples/sec; 0.027 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 20:06:08.892550: step 72490, total loss = 0.53, batch loss = 0.26 (344.9 examples/sec; 0.023 sec/batch; 0h:49m:06s remains)
INFO - root - 2022-02-24 20:06:09.154984: step 72500, total loss = 0.57, batch loss = 0.30 (349.5 examples/sec; 0.023 sec/batch; 0h:48m:26s remains)
INFO - root - 2022-02-24 20:06:09.513173: step 72510, total loss = 0.53, batch loss = 0.27 (366.8 examples/sec; 0.022 sec/batch; 0h:46m:09s remains)
INFO - root - 2022-02-24 20:06:09.867611: step 72520, total loss = 0.62, batch loss = 0.36 (397.7 examples/sec; 0.020 sec/batch; 0h:42m:34s remains)
INFO - root - 2022-02-24 20:06:10.263283: step 72530, total loss = 0.51, batch loss = 0.24 (358.8 examples/sec; 0.022 sec/batch; 0h:47m:10s remains)
INFO - root - 2022-02-24 20:06:10.642393: step 72540, total loss = 0.53, batch loss = 0.26 (276.0 examples/sec; 0.029 sec/batch; 1h:01m:20s remains)
INFO - root - 2022-02-24 20:06:11.024080: step 72550, total loss = 0.67, batch loss = 0.40 (366.4 examples/sec; 0.022 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:06:11.283629: step 72560, total loss = 0.56, batch loss = 0.29 (266.0 examples/sec; 0.030 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 20:06:11.546511: step 72570, total loss = 0.56, batch loss = 0.29 (348.7 examples/sec; 0.023 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:06:11.819074: step 72580, total loss = 0.51, batch loss = 0.24 (241.4 examples/sec; 0.033 sec/batch; 1h:10m:06s remains)
INFO - root - 2022-02-24 20:06:12.224446: step 72590, total loss = 0.52, batch loss = 0.25 (254.9 examples/sec; 0.031 sec/batch; 1h:06m:22s remains)
INFO - root - 2022-02-24 20:06:12.645985: step 72600, total loss = 0.49, batch loss = 0.22 (331.4 examples/sec; 0.024 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:06:13.016035: step 72610, total loss = 0.60, batch loss = 0.33 (334.2 examples/sec; 0.024 sec/batch; 0h:50m:37s remains)
INFO - root - 2022-02-24 20:06:13.395542: step 72620, total loss = 0.57, batch loss = 0.30 (209.6 examples/sec; 0.038 sec/batch; 1h:20m:42s remains)
INFO - root - 2022-02-24 20:06:13.753702: step 72630, total loss = 0.50, batch loss = 0.23 (338.8 examples/sec; 0.024 sec/batch; 0h:49m:55s remains)
INFO - root - 2022-02-24 20:06:14.207071: step 72640, total loss = 0.52, batch loss = 0.25 (360.1 examples/sec; 0.022 sec/batch; 0h:46m:58s remains)
INFO - root - 2022-02-24 20:06:14.567495: step 72650, total loss = 0.60, batch loss = 0.33 (335.4 examples/sec; 0.024 sec/batch; 0h:50m:25s remains)
INFO - root - 2022-02-24 20:06:14.937127: step 72660, total loss = 0.54, batch loss = 0.27 (327.3 examples/sec; 0.024 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:06:15.471729: step 72670, total loss = 0.55, batch loss = 0.28 (193.9 examples/sec; 0.041 sec/batch; 1h:27m:14s remains)
INFO - root - 2022-02-24 20:06:15.950711: step 72680, total loss = 0.54, batch loss = 0.27 (360.2 examples/sec; 0.022 sec/batch; 0h:46m:56s remains)
INFO - root - 2022-02-24 20:06:16.471003: step 72690, total loss = 0.77, batch loss = 0.50 (142.1 examples/sec; 0.056 sec/batch; 1h:58m:58s remains)
INFO - root - 2022-02-24 20:06:16.890503: step 72700, total loss = 0.62, batch loss = 0.35 (324.8 examples/sec; 0.025 sec/batch; 0h:52m:03s remains)
INFO - root - 2022-02-24 20:06:17.316357: step 72710, total loss = 0.56, batch loss = 0.29 (356.6 examples/sec; 0.022 sec/batch; 0h:47m:24s remains)
INFO - root - 2022-02-24 20:06:18.144470: step 72720, total loss = 0.55, batch loss = 0.28 (213.1 examples/sec; 0.038 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 20:06:18.617376: step 72730, total loss = 0.58, batch loss = 0.31 (168.6 examples/sec; 0.047 sec/batch; 1h:40m:13s remains)
INFO - root - 2022-02-24 20:06:18.912871: step 72740, total loss = 0.70, batch loss = 0.43 (299.8 examples/sec; 0.027 sec/batch; 0h:56m:22s remains)
INFO - root - 2022-02-24 20:06:19.221307: step 72750, total loss = 0.62, batch loss = 0.35 (203.7 examples/sec; 0.039 sec/batch; 1h:22m:57s remains)
INFO - root - 2022-02-24 20:06:19.587961: step 72760, total loss = 0.47, batch loss = 0.20 (182.9 examples/sec; 0.044 sec/batch; 1h:32m:23s remains)
INFO - root - 2022-02-24 20:06:20.061409: step 72770, total loss = 0.53, batch loss = 0.26 (261.9 examples/sec; 0.031 sec/batch; 1h:04m:30s remains)
INFO - root - 2022-02-24 20:06:20.412103: step 72780, total loss = 0.51, batch loss = 0.24 (284.3 examples/sec; 0.028 sec/batch; 0h:59m:25s remains)
INFO - root - 2022-02-24 20:06:20.810774: step 72790, total loss = 0.61, batch loss = 0.34 (321.1 examples/sec; 0.025 sec/batch; 0h:52m:37s remains)
INFO - root - 2022-02-24 20:06:21.207336: step 72800, total loss = 0.51, batch loss = 0.25 (345.6 examples/sec; 0.023 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:06:21.570157: step 72810, total loss = 0.51, batch loss = 0.24 (332.4 examples/sec; 0.024 sec/batch; 0h:50m:49s remains)
INFO - root - 2022-02-24 20:06:21.920850: step 72820, total loss = 0.50, batch loss = 0.23 (124.4 examples/sec; 0.064 sec/batch; 2h:15m:48s remains)
INFO - root - 2022-02-24 20:06:22.294200: step 72830, total loss = 0.63, batch loss = 0.36 (147.1 examples/sec; 0.054 sec/batch; 1h:54m:47s remains)
INFO - root - 2022-02-24 20:06:22.836034: step 72840, total loss = 0.49, batch loss = 0.22 (276.7 examples/sec; 0.029 sec/batch; 1h:01m:01s remains)
INFO - root - 2022-02-24 20:06:23.206493: step 72850, total loss = 0.54, batch loss = 0.27 (328.3 examples/sec; 0.024 sec/batch; 0h:51m:26s remains)
INFO - root - 2022-02-24 20:06:23.492464: step 72860, total loss = 0.65, batch loss = 0.38 (362.7 examples/sec; 0.022 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:06:23.836261: step 72870, total loss = 0.66, batch loss = 0.39 (304.2 examples/sec; 0.026 sec/batch; 0h:55m:30s remains)
INFO - root - 2022-02-24 20:06:24.171325: step 72880, total loss = 0.65, batch loss = 0.38 (177.5 examples/sec; 0.045 sec/batch; 1h:35m:07s remains)
INFO - root - 2022-02-24 20:06:24.604542: step 72890, total loss = 0.54, batch loss = 0.28 (192.5 examples/sec; 0.042 sec/batch; 1h:27m:42s remains)
INFO - root - 2022-02-24 20:06:25.011405: step 72900, total loss = 0.55, batch loss = 0.28 (159.9 examples/sec; 0.050 sec/batch; 1h:45m:34s remains)
INFO - root - 2022-02-24 20:06:25.446380: step 72910, total loss = 0.54, batch loss = 0.27 (350.2 examples/sec; 0.023 sec/batch; 0h:48m:11s remains)
INFO - root - 2022-02-24 20:06:25.728947: step 72920, total loss = 0.44, batch loss = 0.17 (325.9 examples/sec; 0.025 sec/batch; 0h:51m:47s remains)
INFO - root - 2022-02-24 20:06:26.010888: step 72930, total loss = 0.61, batch loss = 0.34 (244.3 examples/sec; 0.033 sec/batch; 1h:09m:03s remains)
INFO - root - 2022-02-24 20:06:26.364704: step 72940, total loss = 0.62, batch loss = 0.36 (161.2 examples/sec; 0.050 sec/batch; 1h:44m:39s remains)
INFO - root - 2022-02-24 20:06:26.832506: step 72950, total loss = 0.60, batch loss = 0.33 (201.2 examples/sec; 0.040 sec/batch; 1h:23m:50s remains)
INFO - root - 2022-02-24 20:06:27.201533: step 72960, total loss = 0.53, batch loss = 0.26 (168.9 examples/sec; 0.047 sec/batch; 1h:39m:53s remains)
INFO - root - 2022-02-24 20:06:27.484846: step 72970, total loss = 0.68, batch loss = 0.41 (321.7 examples/sec; 0.025 sec/batch; 0h:52m:26s remains)
INFO - root - 2022-02-24 20:06:27.752777: step 72980, total loss = 0.59, batch loss = 0.32 (341.9 examples/sec; 0.023 sec/batch; 0h:49m:20s remains)
INFO - root - 2022-02-24 20:06:28.069176: step 72990, total loss = 0.70, batch loss = 0.43 (345.3 examples/sec; 0.023 sec/batch; 0h:48m:50s remains)
INFO - root - 2022-02-24 20:06:28.404753: step 73000, total loss = 0.53, batch loss = 0.26 (148.2 examples/sec; 0.054 sec/batch; 1h:53m:50s remains)
INFO - root - 2022-02-24 20:06:28.838921: step 73010, total loss = 0.56, batch loss = 0.29 (275.0 examples/sec; 0.029 sec/batch; 1h:01m:20s remains)
INFO - root - 2022-02-24 20:06:29.227537: step 73020, total loss = 0.60, batch loss = 0.34 (213.9 examples/sec; 0.037 sec/batch; 1h:18m:50s remains)
INFO - root - 2022-02-24 20:06:29.561164: step 73030, total loss = 0.85, batch loss = 0.59 (322.9 examples/sec; 0.025 sec/batch; 0h:52m:12s remains)
INFO - root - 2022-02-24 20:06:29.902343: step 73040, total loss = 0.57, batch loss = 0.30 (215.3 examples/sec; 0.037 sec/batch; 1h:18m:18s remains)
INFO - root - 2022-02-24 20:06:30.203741: step 73050, total loss = 0.64, batch loss = 0.37 (202.9 examples/sec; 0.039 sec/batch; 1h:23m:06s remains)
INFO - root - 2022-02-24 20:06:30.547564: step 73060, total loss = 0.55, batch loss = 0.28 (187.5 examples/sec; 0.043 sec/batch; 1h:29m:55s remains)
INFO - root - 2022-02-24 20:06:30.916161: step 73070, total loss = 0.57, batch loss = 0.30 (223.2 examples/sec; 0.036 sec/batch; 1h:15m:32s remains)
INFO - root - 2022-02-24 20:06:31.302365: step 73080, total loss = 0.48, batch loss = 0.21 (162.3 examples/sec; 0.049 sec/batch; 1h:43m:51s remains)
INFO - root - 2022-02-24 20:06:31.671531: step 73090, total loss = 0.56, batch loss = 0.29 (251.6 examples/sec; 0.032 sec/batch; 1h:06m:58s remains)
INFO - root - 2022-02-24 20:06:31.983799: step 73100, total loss = 0.96, batch loss = 0.69 (166.1 examples/sec; 0.048 sec/batch; 1h:41m:27s remains)
INFO - root - 2022-02-24 20:06:32.360571: step 73110, total loss = 0.67, batch loss = 0.40 (310.6 examples/sec; 0.026 sec/batch; 0h:54m:15s remains)
INFO - root - 2022-02-24 20:06:32.613711: step 73120, total loss = 0.53, batch loss = 0.27 (217.1 examples/sec; 0.037 sec/batch; 1h:17m:36s remains)
INFO - root - 2022-02-24 20:06:33.015280: step 73130, total loss = 0.49, batch loss = 0.22 (192.0 examples/sec; 0.042 sec/batch; 1h:27m:44s remains)
INFO - root - 2022-02-24 20:06:33.435224: step 73140, total loss = 0.75, batch loss = 0.48 (124.9 examples/sec; 0.064 sec/batch; 2h:14m:51s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-73149 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-73149 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:06:34.257211: step 73150, total loss = 0.55, batch loss = 0.28 (318.4 examples/sec; 0.025 sec/batch; 0h:52m:54s remains)
INFO - root - 2022-02-24 20:06:34.601443: step 73160, total loss = 0.54, batch loss = 0.27 (231.9 examples/sec; 0.034 sec/batch; 1h:12m:37s remains)
INFO - root - 2022-02-24 20:06:34.969427: step 73170, total loss = 0.57, batch loss = 0.30 (340.1 examples/sec; 0.024 sec/batch; 0h:49m:31s remains)
INFO - root - 2022-02-24 20:06:35.453892: step 73180, total loss = 0.49, batch loss = 0.22 (101.8 examples/sec; 0.079 sec/batch; 2h:45m:26s remains)
INFO - root - 2022-02-24 20:06:36.008499: step 73190, total loss = 0.49, batch loss = 0.22 (76.5 examples/sec; 0.105 sec/batch; 3h:40m:05s remains)
INFO - root - 2022-02-24 20:06:36.514827: step 73200, total loss = 0.52, batch loss = 0.25 (301.0 examples/sec; 0.027 sec/batch; 0h:55m:56s remains)
INFO - root - 2022-02-24 20:06:36.974910: step 73210, total loss = 0.49, batch loss = 0.22 (356.8 examples/sec; 0.022 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:06:37.354631: step 73220, total loss = 0.61, batch loss = 0.35 (249.6 examples/sec; 0.032 sec/batch; 1h:07m:26s remains)
INFO - root - 2022-02-24 20:06:37.874553: step 73230, total loss = 0.54, batch loss = 0.28 (354.1 examples/sec; 0.023 sec/batch; 0h:47m:32s remains)
INFO - root - 2022-02-24 20:06:38.783299: step 73240, total loss = 0.54, batch loss = 0.27 (241.5 examples/sec; 0.033 sec/batch; 1h:09m:43s remains)
INFO - root - 2022-02-24 20:06:39.113799: step 73250, total loss = 0.61, batch loss = 0.34 (333.6 examples/sec; 0.024 sec/batch; 0h:50m:27s remains)
INFO - root - 2022-02-24 20:06:39.408253: step 73260, total loss = 0.56, batch loss = 0.29 (316.7 examples/sec; 0.025 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 20:06:39.684507: step 73270, total loss = 0.54, batch loss = 0.27 (324.2 examples/sec; 0.025 sec/batch; 0h:51m:54s remains)
INFO - root - 2022-02-24 20:06:40.000704: step 73280, total loss = 0.53, batch loss = 0.26 (243.0 examples/sec; 0.033 sec/batch; 1h:09m:16s remains)
INFO - root - 2022-02-24 20:06:40.454353: step 73290, total loss = 0.53, batch loss = 0.26 (214.5 examples/sec; 0.037 sec/batch; 1h:18m:27s remains)
INFO - root - 2022-02-24 20:06:40.859936: step 73300, total loss = 0.66, batch loss = 0.39 (368.1 examples/sec; 0.022 sec/batch; 0h:45m:43s remains)
INFO - root - 2022-02-24 20:06:41.212241: step 73310, total loss = 0.59, batch loss = 0.32 (213.7 examples/sec; 0.037 sec/batch; 1h:18m:44s remains)
INFO - root - 2022-02-24 20:06:41.536636: step 73320, total loss = 0.49, batch loss = 0.22 (179.0 examples/sec; 0.045 sec/batch; 1h:33m:58s remains)
INFO - root - 2022-02-24 20:06:41.831634: step 73330, total loss = 0.53, batch loss = 0.26 (321.1 examples/sec; 0.025 sec/batch; 0h:52m:23s remains)
INFO - root - 2022-02-24 20:06:42.376374: step 73340, total loss = 0.62, batch loss = 0.35 (183.0 examples/sec; 0.044 sec/batch; 1h:31m:54s remains)
INFO - root - 2022-02-24 20:06:42.783994: step 73350, total loss = 0.52, batch loss = 0.25 (177.5 examples/sec; 0.045 sec/batch; 1h:34m:44s remains)
INFO - root - 2022-02-24 20:06:43.265096: step 73360, total loss = 0.46, batch loss = 0.19 (246.8 examples/sec; 0.032 sec/batch; 1h:08m:09s remains)
INFO - root - 2022-02-24 20:06:43.611871: step 73370, total loss = 0.52, batch loss = 0.26 (337.6 examples/sec; 0.024 sec/batch; 0h:49m:49s remains)
INFO - root - 2022-02-24 20:06:43.959632: step 73380, total loss = 0.50, batch loss = 0.23 (341.7 examples/sec; 0.023 sec/batch; 0h:49m:12s remains)
INFO - root - 2022-02-24 20:06:44.332199: step 73390, total loss = 0.58, batch loss = 0.31 (298.6 examples/sec; 0.027 sec/batch; 0h:56m:19s remains)
INFO - root - 2022-02-24 20:06:44.791069: step 73400, total loss = 0.63, batch loss = 0.37 (142.9 examples/sec; 0.056 sec/batch; 1h:57m:41s remains)
INFO - root - 2022-02-24 20:06:45.142519: step 73410, total loss = 0.63, batch loss = 0.37 (361.6 examples/sec; 0.022 sec/batch; 0h:46m:29s remains)
INFO - root - 2022-02-24 20:06:45.467965: step 73420, total loss = 0.52, batch loss = 0.25 (354.9 examples/sec; 0.023 sec/batch; 0h:47m:22s remains)
INFO - root - 2022-02-24 20:06:45.761913: step 73430, total loss = 0.59, batch loss = 0.32 (323.0 examples/sec; 0.025 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:06:46.142993: step 73440, total loss = 0.64, batch loss = 0.37 (173.0 examples/sec; 0.046 sec/batch; 1h:37m:07s remains)
INFO - root - 2022-02-24 20:06:46.591291: step 73450, total loss = 0.54, batch loss = 0.27 (126.3 examples/sec; 0.063 sec/batch; 2h:13m:06s remains)
INFO - root - 2022-02-24 20:06:46.919529: step 73460, total loss = 0.67, batch loss = 0.40 (150.3 examples/sec; 0.053 sec/batch; 1h:51m:50s remains)
INFO - root - 2022-02-24 20:06:47.188522: step 73470, total loss = 0.60, batch loss = 0.34 (365.0 examples/sec; 0.022 sec/batch; 0h:46m:01s remains)
INFO - root - 2022-02-24 20:06:47.524008: step 73480, total loss = 0.58, batch loss = 0.31 (237.5 examples/sec; 0.034 sec/batch; 1h:10m:44s remains)
INFO - root - 2022-02-24 20:06:47.872301: step 73490, total loss = 0.49, batch loss = 0.22 (129.3 examples/sec; 0.062 sec/batch; 2h:09m:54s remains)
INFO - root - 2022-02-24 20:06:48.204480: step 73500, total loss = 0.49, batch loss = 0.22 (166.5 examples/sec; 0.048 sec/batch; 1h:40m:53s remains)
INFO - root - 2022-02-24 20:06:48.734181: step 73510, total loss = 0.68, batch loss = 0.41 (229.9 examples/sec; 0.035 sec/batch; 1h:13m:04s remains)
INFO - root - 2022-02-24 20:06:49.053432: step 73520, total loss = 0.55, batch loss = 0.28 (263.0 examples/sec; 0.030 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 20:06:49.348504: step 73530, total loss = 0.57, batch loss = 0.30 (273.0 examples/sec; 0.029 sec/batch; 1h:01m:31s remains)
INFO - root - 2022-02-24 20:06:49.683048: step 73540, total loss = 0.54, batch loss = 0.27 (202.0 examples/sec; 0.040 sec/batch; 1h:23m:08s remains)
INFO - root - 2022-02-24 20:06:50.027279: step 73550, total loss = 0.59, batch loss = 0.32 (171.9 examples/sec; 0.047 sec/batch; 1h:37m:41s remains)
INFO - root - 2022-02-24 20:06:50.432563: step 73560, total loss = 0.61, batch loss = 0.34 (117.2 examples/sec; 0.068 sec/batch; 2h:23m:19s remains)
INFO - root - 2022-02-24 20:06:50.741616: step 73570, total loss = 0.55, batch loss = 0.28 (232.9 examples/sec; 0.034 sec/batch; 1h:12m:06s remains)
INFO - root - 2022-02-24 20:06:51.032487: step 73580, total loss = 0.58, batch loss = 0.31 (304.1 examples/sec; 0.026 sec/batch; 0h:55m:13s remains)
INFO - root - 2022-02-24 20:06:51.352776: step 73590, total loss = 0.61, batch loss = 0.35 (289.3 examples/sec; 0.028 sec/batch; 0h:58m:01s remains)
INFO - root - 2022-02-24 20:06:51.662972: step 73600, total loss = 0.63, batch loss = 0.36 (367.3 examples/sec; 0.022 sec/batch; 0h:45m:42s remains)
INFO - root - 2022-02-24 20:06:52.112167: step 73610, total loss = 0.52, batch loss = 0.25 (154.6 examples/sec; 0.052 sec/batch; 1h:48m:33s remains)
INFO - root - 2022-02-24 20:06:52.520707: step 73620, total loss = 0.51, batch loss = 0.24 (277.9 examples/sec; 0.029 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 20:06:52.880457: step 73630, total loss = 0.49, batch loss = 0.23 (337.2 examples/sec; 0.024 sec/batch; 0h:49m:46s remains)
INFO - root - 2022-02-24 20:06:53.199202: step 73640, total loss = 0.61, batch loss = 0.34 (365.8 examples/sec; 0.022 sec/batch; 0h:45m:52s remains)
INFO - root - 2022-02-24 20:06:53.570158: step 73650, total loss = 0.47, batch loss = 0.20 (332.5 examples/sec; 0.024 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 20:06:53.882870: step 73660, total loss = 0.53, batch loss = 0.26 (310.5 examples/sec; 0.026 sec/batch; 0h:54m:02s remains)
INFO - root - 2022-02-24 20:06:54.234492: step 73670, total loss = 0.57, batch loss = 0.30 (286.6 examples/sec; 0.028 sec/batch; 0h:58m:32s remains)
INFO - root - 2022-02-24 20:06:54.681180: step 73680, total loss = 0.58, batch loss = 0.31 (199.2 examples/sec; 0.040 sec/batch; 1h:24m:13s remains)
INFO - root - 2022-02-24 20:06:55.043941: step 73690, total loss = 0.63, batch loss = 0.36 (217.8 examples/sec; 0.037 sec/batch; 1h:17m:01s remains)
INFO - root - 2022-02-24 20:06:55.384512: step 73700, total loss = 0.58, batch loss = 0.31 (134.2 examples/sec; 0.060 sec/batch; 2h:04m:56s remains)
INFO - root - 2022-02-24 20:06:55.763881: step 73710, total loss = 0.57, batch loss = 0.31 (266.5 examples/sec; 0.030 sec/batch; 1h:02m:56s remains)
INFO - root - 2022-02-24 20:06:56.153979: step 73720, total loss = 0.58, batch loss = 0.31 (81.5 examples/sec; 0.098 sec/batch; 3h:25m:50s remains)
INFO - root - 2022-02-24 20:06:56.528894: step 73730, total loss = 0.51, batch loss = 0.24 (117.5 examples/sec; 0.068 sec/batch; 2h:22m:44s remains)
INFO - root - 2022-02-24 20:06:56.826121: step 73740, total loss = 0.50, batch loss = 0.23 (249.3 examples/sec; 0.032 sec/batch; 1h:07m:15s remains)
INFO - root - 2022-02-24 20:06:57.182136: step 73750, total loss = 0.50, batch loss = 0.24 (315.9 examples/sec; 0.025 sec/batch; 0h:53m:04s remains)
INFO - root - 2022-02-24 20:06:57.469336: step 73760, total loss = 0.55, batch loss = 0.28 (330.2 examples/sec; 0.024 sec/batch; 0h:50m:46s remains)
INFO - root - 2022-02-24 20:06:57.795999: step 73770, total loss = 0.54, batch loss = 0.27 (281.5 examples/sec; 0.028 sec/batch; 0h:59m:32s remains)
INFO - root - 2022-02-24 20:06:58.137884: step 73780, total loss = 0.54, batch loss = 0.27 (185.2 examples/sec; 0.043 sec/batch; 1h:30m:29s remains)
INFO - root - 2022-02-24 20:06:58.675018: step 73790, total loss = 0.56, batch loss = 0.29 (121.8 examples/sec; 0.066 sec/batch; 2h:17m:39s remains)
INFO - root - 2022-02-24 20:06:59.048888: step 73800, total loss = 0.56, batch loss = 0.29 (354.0 examples/sec; 0.023 sec/batch; 0h:47m:20s remains)
INFO - root - 2022-02-24 20:06:59.418688: step 73810, total loss = 0.60, batch loss = 0.33 (331.1 examples/sec; 0.024 sec/batch; 0h:50m:36s remains)
INFO - root - 2022-02-24 20:06:59.734139: step 73820, total loss = 0.51, batch loss = 0.24 (296.2 examples/sec; 0.027 sec/batch; 0h:56m:34s remains)
INFO - root - 2022-02-24 20:07:00.219357: step 73830, total loss = 0.59, batch loss = 0.32 (190.9 examples/sec; 0.042 sec/batch; 1h:27m:46s remains)
INFO - root - 2022-02-24 20:07:00.644602: step 73840, total loss = 0.58, batch loss = 0.31 (310.3 examples/sec; 0.026 sec/batch; 0h:53m:59s remains)
INFO - root - 2022-02-24 20:07:00.972542: step 73850, total loss = 0.57, batch loss = 0.31 (211.7 examples/sec; 0.038 sec/batch; 1h:19m:08s remains)
INFO - root - 2022-02-24 20:07:01.291740: step 73860, total loss = 0.45, batch loss = 0.18 (253.7 examples/sec; 0.032 sec/batch; 1h:06m:01s remains)
INFO - root - 2022-02-24 20:07:01.636406: step 73870, total loss = 0.54, batch loss = 0.27 (259.5 examples/sec; 0.031 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 20:07:01.959440: step 73880, total loss = 0.57, batch loss = 0.30 (290.3 examples/sec; 0.028 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:07:02.337408: step 73890, total loss = 0.56, batch loss = 0.29 (260.5 examples/sec; 0.031 sec/batch; 1h:04m:17s remains)
INFO - root - 2022-02-24 20:07:02.791310: step 73900, total loss = 0.54, batch loss = 0.27 (203.5 examples/sec; 0.039 sec/batch; 1h:22m:17s remains)
INFO - root - 2022-02-24 20:07:03.247220: step 73910, total loss = 0.62, batch loss = 0.36 (208.8 examples/sec; 0.038 sec/batch; 1h:20m:11s remains)
INFO - root - 2022-02-24 20:07:03.832286: step 73920, total loss = 0.51, batch loss = 0.24 (185.4 examples/sec; 0.043 sec/batch; 1h:30m:19s remains)
INFO - root - 2022-02-24 20:07:04.155693: step 73930, total loss = 0.56, batch loss = 0.30 (237.1 examples/sec; 0.034 sec/batch; 1h:10m:36s remains)
INFO - root - 2022-02-24 20:07:04.563948: step 73940, total loss = 0.54, batch loss = 0.27 (148.1 examples/sec; 0.054 sec/batch; 1h:53m:03s remains)
INFO - root - 2022-02-24 20:07:05.142267: step 73950, total loss = 0.53, batch loss = 0.27 (89.5 examples/sec; 0.089 sec/batch; 3h:07m:03s remains)
INFO - root - 2022-02-24 20:07:05.601806: step 73960, total loss = 0.74, batch loss = 0.48 (233.1 examples/sec; 0.034 sec/batch; 1h:11m:49s remains)
INFO - root - 2022-02-24 20:07:06.046476: step 73970, total loss = 0.60, batch loss = 0.33 (141.8 examples/sec; 0.056 sec/batch; 1h:58m:00s remains)
INFO - root - 2022-02-24 20:07:06.503328: step 73980, total loss = 0.56, batch loss = 0.29 (319.5 examples/sec; 0.025 sec/batch; 0h:52m:22s remains)
INFO - root - 2022-02-24 20:07:07.087220: step 73990, total loss = 0.63, batch loss = 0.36 (111.9 examples/sec; 0.071 sec/batch; 2h:29m:32s remains)
INFO - root - 2022-02-24 20:07:07.598904: step 74000, total loss = 0.56, batch loss = 0.30 (205.4 examples/sec; 0.039 sec/batch; 1h:21m:27s remains)
INFO - root - 2022-02-24 20:07:07.969285: step 74010, total loss = 0.62, batch loss = 0.35 (313.2 examples/sec; 0.026 sec/batch; 0h:53m:25s remains)
INFO - root - 2022-02-24 20:07:08.341435: step 74020, total loss = 0.64, batch loss = 0.37 (165.8 examples/sec; 0.048 sec/batch; 1h:40m:56s remains)
INFO - root - 2022-02-24 20:07:09.039531: step 74030, total loss = 0.50, batch loss = 0.23 (261.0 examples/sec; 0.031 sec/batch; 1h:04m:06s remains)
INFO - root - 2022-02-24 20:07:09.414940: step 74040, total loss = 0.50, batch loss = 0.23 (372.7 examples/sec; 0.021 sec/batch; 0h:44m:53s remains)
INFO - root - 2022-02-24 20:07:09.768209: step 74050, total loss = 0.61, batch loss = 0.34 (296.6 examples/sec; 0.027 sec/batch; 0h:56m:23s remains)
INFO - root - 2022-02-24 20:07:10.080648: step 74060, total loss = 0.79, batch loss = 0.52 (330.2 examples/sec; 0.024 sec/batch; 0h:50m:39s remains)
INFO - root - 2022-02-24 20:07:10.381083: step 74070, total loss = 0.56, batch loss = 0.29 (354.2 examples/sec; 0.023 sec/batch; 0h:47m:12s remains)
INFO - root - 2022-02-24 20:07:10.699371: step 74080, total loss = 0.51, batch loss = 0.24 (281.8 examples/sec; 0.028 sec/batch; 0h:59m:20s remains)
INFO - root - 2022-02-24 20:07:11.105590: step 74090, total loss = 0.57, batch loss = 0.31 (205.9 examples/sec; 0.039 sec/batch; 1h:21m:11s remains)
INFO - root - 2022-02-24 20:07:11.530760: step 74100, total loss = 0.53, batch loss = 0.26 (223.0 examples/sec; 0.036 sec/batch; 1h:14m:58s remains)
INFO - root - 2022-02-24 20:07:11.876219: step 74110, total loss = 0.55, batch loss = 0.28 (284.2 examples/sec; 0.028 sec/batch; 0h:58m:49s remains)
INFO - root - 2022-02-24 20:07:12.263097: step 74120, total loss = 0.57, batch loss = 0.30 (289.7 examples/sec; 0.028 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:07:12.610172: step 74130, total loss = 0.50, batch loss = 0.23 (260.2 examples/sec; 0.031 sec/batch; 1h:04m:15s remains)
INFO - root - 2022-02-24 20:07:13.036800: step 74140, total loss = 0.51, batch loss = 0.24 (211.2 examples/sec; 0.038 sec/batch; 1h:19m:07s remains)
INFO - root - 2022-02-24 20:07:13.500341: step 74150, total loss = 0.51, batch loss = 0.24 (147.4 examples/sec; 0.054 sec/batch; 1h:53m:25s remains)
INFO - root - 2022-02-24 20:07:13.945418: step 74160, total loss = 0.61, batch loss = 0.34 (314.9 examples/sec; 0.025 sec/batch; 0h:53m:04s remains)
INFO - root - 2022-02-24 20:07:14.247807: step 74170, total loss = 0.50, batch loss = 0.23 (352.0 examples/sec; 0.023 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:07:14.588237: step 74180, total loss = 0.64, batch loss = 0.37 (225.0 examples/sec; 0.036 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 20:07:15.081465: step 74190, total loss = 0.60, batch loss = 0.33 (374.1 examples/sec; 0.021 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 20:07:15.456980: step 74200, total loss = 0.63, batch loss = 0.36 (242.8 examples/sec; 0.033 sec/batch; 1h:08m:49s remains)
INFO - root - 2022-02-24 20:07:15.800038: step 74210, total loss = 0.52, batch loss = 0.25 (354.5 examples/sec; 0.023 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:07:16.071130: step 74220, total loss = 0.57, batch loss = 0.30 (190.4 examples/sec; 0.042 sec/batch; 1h:27m:44s remains)
INFO - root - 2022-02-24 20:07:16.362867: step 74230, total loss = 0.49, batch loss = 0.22 (342.1 examples/sec; 0.023 sec/batch; 0h:48m:49s remains)
INFO - root - 2022-02-24 20:07:16.626554: step 74240, total loss = 0.60, batch loss = 0.33 (278.8 examples/sec; 0.029 sec/batch; 0h:59m:54s remains)
INFO - root - 2022-02-24 20:07:17.050450: step 74250, total loss = 0.55, batch loss = 0.28 (366.0 examples/sec; 0.022 sec/batch; 0h:45m:37s remains)
INFO - root - 2022-02-24 20:07:17.473394: step 74260, total loss = 0.57, batch loss = 0.30 (354.4 examples/sec; 0.023 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:07:17.800268: step 74270, total loss = 0.55, batch loss = 0.28 (317.6 examples/sec; 0.025 sec/batch; 0h:52m:34s remains)
INFO - root - 2022-02-24 20:07:18.115891: step 74280, total loss = 0.58, batch loss = 0.31 (273.2 examples/sec; 0.029 sec/batch; 1h:01m:06s remains)
INFO - root - 2022-02-24 20:07:18.415607: step 74290, total loss = 0.55, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:07:18.697740: step 74300, total loss = 0.69, batch loss = 0.42 (327.9 examples/sec; 0.024 sec/batch; 0h:50m:54s remains)
INFO - root - 2022-02-24 20:07:19.247966: step 74310, total loss = 0.65, batch loss = 0.39 (233.8 examples/sec; 0.034 sec/batch; 1h:11m:24s remains)
INFO - root - 2022-02-24 20:07:19.611656: step 74320, total loss = 0.50, batch loss = 0.24 (368.5 examples/sec; 0.022 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 20:07:19.952762: step 74330, total loss = 0.52, batch loss = 0.25 (158.5 examples/sec; 0.050 sec/batch; 1h:45m:17s remains)
INFO - root - 2022-02-24 20:07:20.338310: step 74340, total loss = 0.55, batch loss = 0.28 (219.6 examples/sec; 0.036 sec/batch; 1h:16m:00s remains)
INFO - root - 2022-02-24 20:07:20.619626: step 74350, total loss = 0.53, batch loss = 0.26 (269.9 examples/sec; 0.030 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 20:07:20.998736: step 74360, total loss = 0.77, batch loss = 0.50 (289.4 examples/sec; 0.028 sec/batch; 0h:57m:39s remains)
INFO - root - 2022-02-24 20:07:21.481328: step 74370, total loss = 0.53, batch loss = 0.26 (303.4 examples/sec; 0.026 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:07:21.824255: step 74380, total loss = 0.56, batch loss = 0.30 (303.7 examples/sec; 0.026 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 20:07:22.142999: step 74390, total loss = 0.70, batch loss = 0.44 (225.5 examples/sec; 0.035 sec/batch; 1h:13m:58s remains)
INFO - root - 2022-02-24 20:07:22.584739: step 74400, total loss = 0.60, batch loss = 0.33 (257.8 examples/sec; 0.031 sec/batch; 1h:04m:41s remains)
INFO - root - 2022-02-24 20:07:23.162549: step 74410, total loss = 0.46, batch loss = 0.19 (346.6 examples/sec; 0.023 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:07:23.640277: step 74420, total loss = 0.62, batch loss = 0.35 (243.2 examples/sec; 0.033 sec/batch; 1h:08m:33s remains)
INFO - root - 2022-02-24 20:07:24.546363: step 74430, total loss = 0.57, batch loss = 0.30 (263.4 examples/sec; 0.030 sec/batch; 1h:03m:18s remains)
INFO - root - 2022-02-24 20:07:24.820029: step 74440, total loss = 0.58, batch loss = 0.31 (231.8 examples/sec; 0.035 sec/batch; 1h:11m:56s remains)
INFO - root - 2022-02-24 20:07:25.205873: step 74450, total loss = 0.59, batch loss = 0.32 (250.4 examples/sec; 0.032 sec/batch; 1h:06m:35s remains)
INFO - root - 2022-02-24 20:07:25.542454: step 74460, total loss = 0.57, batch loss = 0.30 (248.7 examples/sec; 0.032 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 20:07:25.978046: step 74470, total loss = 0.58, batch loss = 0.31 (106.0 examples/sec; 0.075 sec/batch; 2h:37m:13s remains)
INFO - root - 2022-02-24 20:07:26.321628: step 74480, total loss = 0.51, batch loss = 0.25 (269.4 examples/sec; 0.030 sec/batch; 1h:01m:52s remains)
INFO - root - 2022-02-24 20:07:26.689764: step 74490, total loss = 0.52, batch loss = 0.25 (231.6 examples/sec; 0.035 sec/batch; 1h:11m:59s remains)
INFO - root - 2022-02-24 20:07:26.999189: step 74500, total loss = 0.57, batch loss = 0.31 (217.3 examples/sec; 0.037 sec/batch; 1h:16m:42s remains)
INFO - root - 2022-02-24 20:07:27.372791: step 74510, total loss = 0.68, batch loss = 0.41 (337.3 examples/sec; 0.024 sec/batch; 0h:49m:24s remains)
INFO - root - 2022-02-24 20:07:27.635922: step 74520, total loss = 0.50, batch loss = 0.24 (228.4 examples/sec; 0.035 sec/batch; 1h:12m:58s remains)
INFO - root - 2022-02-24 20:07:28.082989: step 74530, total loss = 0.61, batch loss = 0.34 (109.9 examples/sec; 0.073 sec/batch; 2h:31m:40s remains)
INFO - root - 2022-02-24 20:07:28.509872: step 74540, total loss = 0.56, batch loss = 0.29 (185.5 examples/sec; 0.043 sec/batch; 1h:29m:47s remains)
INFO - root - 2022-02-24 20:07:28.851548: step 74550, total loss = 0.63, batch loss = 0.37 (333.3 examples/sec; 0.024 sec/batch; 0h:49m:58s remains)
INFO - root - 2022-02-24 20:07:29.166298: step 74560, total loss = 0.65, batch loss = 0.38 (326.9 examples/sec; 0.024 sec/batch; 0h:50m:57s remains)
INFO - root - 2022-02-24 20:07:29.450928: step 74570, total loss = 0.70, batch loss = 0.43 (353.4 examples/sec; 0.023 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:07:29.795374: step 74580, total loss = 0.60, batch loss = 0.33 (195.6 examples/sec; 0.041 sec/batch; 1h:25m:09s remains)
INFO - root - 2022-02-24 20:07:30.233752: step 74590, total loss = 0.57, batch loss = 0.30 (154.5 examples/sec; 0.052 sec/batch; 1h:47m:48s remains)
INFO - root - 2022-02-24 20:07:30.554484: step 74600, total loss = 0.55, batch loss = 0.28 (346.1 examples/sec; 0.023 sec/batch; 0h:48m:06s remains)
INFO - root - 2022-02-24 20:07:30.914297: step 74610, total loss = 0.57, batch loss = 0.30 (210.3 examples/sec; 0.038 sec/batch; 1h:19m:09s remains)
INFO - root - 2022-02-24 20:07:31.221408: step 74620, total loss = 0.59, batch loss = 0.32 (261.2 examples/sec; 0.031 sec/batch; 1h:03m:44s remains)
INFO - root - 2022-02-24 20:07:31.550162: step 74630, total loss = 0.47, batch loss = 0.20 (119.9 examples/sec; 0.067 sec/batch; 2h:18m:52s remains)
INFO - root - 2022-02-24 20:07:31.966654: step 74640, total loss = 0.59, batch loss = 0.32 (155.7 examples/sec; 0.051 sec/batch; 1h:46m:56s remains)
INFO - root - 2022-02-24 20:07:32.364423: step 74650, total loss = 0.61, batch loss = 0.34 (307.2 examples/sec; 0.026 sec/batch; 0h:54m:11s remains)
INFO - root - 2022-02-24 20:07:32.667488: step 74660, total loss = 0.57, batch loss = 0.30 (255.8 examples/sec; 0.031 sec/batch; 1h:05m:03s remains)
INFO - root - 2022-02-24 20:07:32.962641: step 74670, total loss = 0.55, batch loss = 0.28 (338.2 examples/sec; 0.024 sec/batch; 0h:49m:12s remains)
INFO - root - 2022-02-24 20:07:33.211840: step 74680, total loss = 0.56, batch loss = 0.29 (346.6 examples/sec; 0.023 sec/batch; 0h:48m:00s remains)
INFO - root - 2022-02-24 20:07:33.527151: step 74690, total loss = 0.54, batch loss = 0.27 (329.7 examples/sec; 0.024 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 20:07:34.007819: step 74700, total loss = 0.54, batch loss = 0.28 (182.1 examples/sec; 0.044 sec/batch; 1h:31m:23s remains)
INFO - root - 2022-02-24 20:07:34.452355: step 74710, total loss = 0.62, batch loss = 0.35 (168.6 examples/sec; 0.047 sec/batch; 1h:38m:40s remains)
INFO - root - 2022-02-24 20:07:34.787971: step 74720, total loss = 0.57, batch loss = 0.30 (129.1 examples/sec; 0.062 sec/batch; 2h:08m:50s remains)
INFO - root - 2022-02-24 20:07:35.050692: step 74730, total loss = 0.60, batch loss = 0.33 (368.0 examples/sec; 0.022 sec/batch; 0h:45m:12s remains)
INFO - root - 2022-02-24 20:07:35.334057: step 74740, total loss = 0.59, batch loss = 0.32 (147.8 examples/sec; 0.054 sec/batch; 1h:52m:33s remains)
INFO - root - 2022-02-24 20:07:35.708010: step 74750, total loss = 0.55, batch loss = 0.28 (335.1 examples/sec; 0.024 sec/batch; 0h:49m:38s remains)
INFO - root - 2022-02-24 20:07:36.151686: step 74760, total loss = 0.60, batch loss = 0.34 (143.5 examples/sec; 0.056 sec/batch; 1h:55m:56s remains)
INFO - root - 2022-02-24 20:07:36.578539: step 74770, total loss = 0.54, batch loss = 0.27 (148.1 examples/sec; 0.054 sec/batch; 1h:52m:15s remains)
INFO - root - 2022-02-24 20:07:36.899021: step 74780, total loss = 0.64, batch loss = 0.38 (241.0 examples/sec; 0.033 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 20:07:37.194408: step 74790, total loss = 0.56, batch loss = 0.30 (348.3 examples/sec; 0.023 sec/batch; 0h:47m:44s remains)
INFO - root - 2022-02-24 20:07:37.506954: step 74800, total loss = 0.65, batch loss = 0.38 (270.5 examples/sec; 0.030 sec/batch; 1h:01m:28s remains)
INFO - root - 2022-02-24 20:07:37.920857: step 74810, total loss = 0.59, batch loss = 0.32 (253.0 examples/sec; 0.032 sec/batch; 1h:05m:42s remains)
INFO - root - 2022-02-24 20:07:38.320898: step 74820, total loss = 0.57, batch loss = 0.30 (193.7 examples/sec; 0.041 sec/batch; 1h:25m:48s remains)
INFO - root - 2022-02-24 20:07:38.680671: step 74830, total loss = 0.74, batch loss = 0.48 (323.5 examples/sec; 0.025 sec/batch; 0h:51m:22s remains)
INFO - root - 2022-02-24 20:07:39.310368: step 74840, total loss = 0.56, batch loss = 0.29 (22.5 examples/sec; 0.356 sec/batch; 12h:18m:59s remains)
INFO - root - 2022-02-24 20:07:39.739089: step 74850, total loss = 0.50, batch loss = 0.23 (276.7 examples/sec; 0.029 sec/batch; 1h:00m:03s remains)
INFO - root - 2022-02-24 20:07:40.070538: step 74860, total loss = 0.59, batch loss = 0.32 (343.2 examples/sec; 0.023 sec/batch; 0h:48m:25s remains)
INFO - root - 2022-02-24 20:07:40.443744: step 74870, total loss = 0.54, batch loss = 0.27 (198.2 examples/sec; 0.040 sec/batch; 1h:23m:49s remains)
INFO - root - 2022-02-24 20:07:40.916702: step 74880, total loss = 0.56, batch loss = 0.29 (243.1 examples/sec; 0.033 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 20:07:41.451611: step 74890, total loss = 0.62, batch loss = 0.35 (101.6 examples/sec; 0.079 sec/batch; 2h:43m:33s remains)
INFO - root - 2022-02-24 20:07:41.959538: step 74900, total loss = 0.54, batch loss = 0.28 (256.1 examples/sec; 0.031 sec/batch; 1h:04m:52s remains)
INFO - root - 2022-02-24 20:07:42.414380: step 74910, total loss = 0.55, batch loss = 0.29 (268.0 examples/sec; 0.030 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:07:42.738901: step 74920, total loss = 0.52, batch loss = 0.25 (314.6 examples/sec; 0.025 sec/batch; 0h:52m:47s remains)
INFO - root - 2022-02-24 20:07:43.120134: step 74930, total loss = 0.85, batch loss = 0.58 (300.8 examples/sec; 0.027 sec/batch; 0h:55m:12s remains)
INFO - root - 2022-02-24 20:07:43.522628: step 74940, total loss = 0.57, batch loss = 0.30 (213.7 examples/sec; 0.037 sec/batch; 1h:17m:42s remains)
INFO - root - 2022-02-24 20:07:43.961041: step 74950, total loss = 0.56, batch loss = 0.29 (289.2 examples/sec; 0.028 sec/batch; 0h:57m:25s remains)
INFO - root - 2022-02-24 20:07:44.789064: step 74960, total loss = 0.56, batch loss = 0.29 (326.9 examples/sec; 0.024 sec/batch; 0h:50m:47s remains)
INFO - root - 2022-02-24 20:07:45.146230: step 74970, total loss = 0.55, batch loss = 0.28 (184.7 examples/sec; 0.043 sec/batch; 1h:29m:53s remains)
INFO - root - 2022-02-24 20:07:45.551822: step 74980, total loss = 0.71, batch loss = 0.44 (335.6 examples/sec; 0.024 sec/batch; 0h:49m:28s remains)
INFO - root - 2022-02-24 20:07:46.023153: step 74990, total loss = 0.51, batch loss = 0.24 (340.6 examples/sec; 0.023 sec/batch; 0h:48m:44s remains)
INFO - root - 2022-02-24 20:07:46.274778: step 75000, total loss = 0.53, batch loss = 0.27 (339.0 examples/sec; 0.024 sec/batch; 0h:48m:57s remains)
INFO - root - 2022-02-24 20:07:46.653534: step 75010, total loss = 0.48, batch loss = 0.21 (331.6 examples/sec; 0.024 sec/batch; 0h:50m:03s remains)
INFO - root - 2022-02-24 20:07:46.922658: step 75020, total loss = 0.46, batch loss = 0.19 (267.8 examples/sec; 0.030 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:07:47.291790: step 75030, total loss = 0.58, batch loss = 0.31 (128.8 examples/sec; 0.062 sec/batch; 2h:08m:53s remains)
INFO - root - 2022-02-24 20:07:47.613989: step 75040, total loss = 0.46, batch loss = 0.19 (370.0 examples/sec; 0.022 sec/batch; 0h:44m:51s remains)
INFO - root - 2022-02-24 20:07:47.935804: step 75050, total loss = 0.57, batch loss = 0.31 (118.4 examples/sec; 0.068 sec/batch; 2h:20m:11s remains)
INFO - root - 2022-02-24 20:07:48.363030: step 75060, total loss = 0.70, batch loss = 0.43 (326.1 examples/sec; 0.025 sec/batch; 0h:50m:53s remains)
INFO - root - 2022-02-24 20:07:48.684400: step 75070, total loss = 0.56, batch loss = 0.30 (324.8 examples/sec; 0.025 sec/batch; 0h:51m:04s remains)
INFO - root - 2022-02-24 20:07:49.008685: step 75080, total loss = 0.61, batch loss = 0.34 (344.4 examples/sec; 0.023 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:07:49.410035: step 75090, total loss = 0.57, batch loss = 0.31 (95.5 examples/sec; 0.084 sec/batch; 2h:53m:40s remains)
INFO - root - 2022-02-24 20:07:49.849786: step 75100, total loss = 0.57, batch loss = 0.30 (343.2 examples/sec; 0.023 sec/batch; 0h:48m:19s remains)
INFO - root - 2022-02-24 20:07:50.223560: step 75110, total loss = 0.55, batch loss = 0.29 (342.4 examples/sec; 0.023 sec/batch; 0h:48m:26s remains)
INFO - root - 2022-02-24 20:07:50.596765: step 75120, total loss = 0.49, batch loss = 0.22 (112.3 examples/sec; 0.071 sec/batch; 2h:27m:41s remains)
INFO - root - 2022-02-24 20:07:50.922807: step 75130, total loss = 0.56, batch loss = 0.29 (274.6 examples/sec; 0.029 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 20:07:51.327033: step 75140, total loss = 0.58, batch loss = 0.32 (249.3 examples/sec; 0.032 sec/batch; 1h:06m:30s remains)
INFO - root - 2022-02-24 20:07:51.742799: step 75150, total loss = 0.55, batch loss = 0.28 (303.3 examples/sec; 0.026 sec/batch; 0h:54m:39s remains)
INFO - root - 2022-02-24 20:07:52.068646: step 75160, total loss = 0.45, batch loss = 0.18 (349.5 examples/sec; 0.023 sec/batch; 0h:47m:26s remains)
INFO - root - 2022-02-24 20:07:52.323220: step 75170, total loss = 0.54, batch loss = 0.27 (265.4 examples/sec; 0.030 sec/batch; 1h:02m:27s remains)
INFO - root - 2022-02-24 20:07:52.656414: step 75180, total loss = 0.53, batch loss = 0.26 (177.2 examples/sec; 0.045 sec/batch; 1h:33m:32s remains)
INFO - root - 2022-02-24 20:07:52.957892: step 75190, total loss = 0.58, batch loss = 0.31 (174.3 examples/sec; 0.046 sec/batch; 1h:35m:05s remains)
INFO - root - 2022-02-24 20:07:53.377312: step 75200, total loss = 0.51, batch loss = 0.24 (192.2 examples/sec; 0.042 sec/batch; 1h:26m:15s remains)
INFO - root - 2022-02-24 20:07:53.725025: step 75210, total loss = 0.53, batch loss = 0.26 (369.3 examples/sec; 0.022 sec/batch; 0h:44m:52s remains)
INFO - root - 2022-02-24 20:07:54.009523: step 75220, total loss = 0.64, batch loss = 0.37 (214.4 examples/sec; 0.037 sec/batch; 1h:17m:16s remains)
INFO - root - 2022-02-24 20:07:54.313492: step 75230, total loss = 0.63, batch loss = 0.36 (332.5 examples/sec; 0.024 sec/batch; 0h:49m:49s remains)
INFO - root - 2022-02-24 20:07:54.638817: step 75240, total loss = 0.61, batch loss = 0.35 (216.4 examples/sec; 0.037 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 20:07:55.039063: step 75250, total loss = 0.67, batch loss = 0.40 (278.5 examples/sec; 0.029 sec/batch; 0h:59m:29s remains)
INFO - root - 2022-02-24 20:07:55.417925: step 75260, total loss = 0.68, batch loss = 0.41 (227.8 examples/sec; 0.035 sec/batch; 1h:12m:42s remains)
INFO - root - 2022-02-24 20:07:55.729501: step 75270, total loss = 0.54, batch loss = 0.27 (330.3 examples/sec; 0.024 sec/batch; 0h:50m:08s remains)
INFO - root - 2022-02-24 20:07:56.072272: step 75280, total loss = 0.53, batch loss = 0.26 (265.2 examples/sec; 0.030 sec/batch; 1h:02m:27s remains)
INFO - root - 2022-02-24 20:07:56.369995: step 75290, total loss = 0.51, batch loss = 0.24 (286.8 examples/sec; 0.028 sec/batch; 0h:57m:44s remains)
INFO - root - 2022-02-24 20:07:56.766946: step 75300, total loss = 0.53, batch loss = 0.26 (93.3 examples/sec; 0.086 sec/batch; 2h:57m:31s remains)
INFO - root - 2022-02-24 20:07:57.252671: step 75310, total loss = 0.60, batch loss = 0.33 (123.0 examples/sec; 0.065 sec/batch; 2h:14m:40s remains)
INFO - root - 2022-02-24 20:07:57.599673: step 75320, total loss = 0.65, batch loss = 0.38 (353.0 examples/sec; 0.023 sec/batch; 0h:46m:53s remains)
INFO - root - 2022-02-24 20:07:58.075918: step 75330, total loss = 0.64, batch loss = 0.38 (210.9 examples/sec; 0.038 sec/batch; 1h:18m:30s remains)
INFO - root - 2022-02-24 20:07:58.630622: step 75340, total loss = 0.49, batch loss = 0.22 (363.9 examples/sec; 0.022 sec/batch; 0h:45m:29s remains)
INFO - root - 2022-02-24 20:07:59.821180: step 75350, total loss = 0.58, batch loss = 0.31 (320.9 examples/sec; 0.025 sec/batch; 0h:51m:35s remains)
INFO - root - 2022-02-24 20:08:00.223859: step 75360, total loss = 0.57, batch loss = 0.31 (312.8 examples/sec; 0.026 sec/batch; 0h:52m:55s remains)
INFO - root - 2022-02-24 20:08:00.513427: step 75370, total loss = 0.50, batch loss = 0.24 (266.3 examples/sec; 0.030 sec/batch; 1h:02m:08s remains)
INFO - root - 2022-02-24 20:08:00.842965: step 75380, total loss = 0.61, batch loss = 0.34 (350.0 examples/sec; 0.023 sec/batch; 0h:47m:17s remains)
INFO - root - 2022-02-24 20:08:01.160520: step 75390, total loss = 0.58, batch loss = 0.31 (242.6 examples/sec; 0.033 sec/batch; 1h:08m:13s remains)
INFO - root - 2022-02-24 20:08:01.498287: step 75400, total loss = 0.52, batch loss = 0.25 (150.9 examples/sec; 0.053 sec/batch; 1h:49m:40s remains)
INFO - root - 2022-02-24 20:08:01.918324: step 75410, total loss = 0.56, batch loss = 0.29 (183.6 examples/sec; 0.044 sec/batch; 1h:30m:07s remains)
INFO - root - 2022-02-24 20:08:02.286314: step 75420, total loss = 0.52, batch loss = 0.25 (247.2 examples/sec; 0.032 sec/batch; 1h:06m:54s remains)
INFO - root - 2022-02-24 20:08:02.606207: step 75430, total loss = 0.56, batch loss = 0.29 (243.1 examples/sec; 0.033 sec/batch; 1h:08m:02s remains)
INFO - root - 2022-02-24 20:08:02.895892: step 75440, total loss = 0.58, batch loss = 0.31 (344.0 examples/sec; 0.023 sec/batch; 0h:48m:05s remains)
INFO - root - 2022-02-24 20:08:03.190803: step 75450, total loss = 0.58, batch loss = 0.31 (309.8 examples/sec; 0.026 sec/batch; 0h:53m:23s remains)
INFO - root - 2022-02-24 20:08:03.559809: step 75460, total loss = 0.55, batch loss = 0.28 (362.6 examples/sec; 0.022 sec/batch; 0h:45m:36s remains)
INFO - root - 2022-02-24 20:08:04.016194: step 75470, total loss = 0.54, batch loss = 0.27 (240.4 examples/sec; 0.033 sec/batch; 1h:08m:47s remains)
INFO - root - 2022-02-24 20:08:04.379214: step 75480, total loss = 0.55, batch loss = 0.28 (331.6 examples/sec; 0.024 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:08:04.710315: step 75490, total loss = 0.51, batch loss = 0.24 (299.9 examples/sec; 0.027 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 20:08:05.075920: step 75500, total loss = 0.64, batch loss = 0.37 (339.1 examples/sec; 0.024 sec/batch; 0h:48m:45s remains)
INFO - root - 2022-02-24 20:08:05.449912: step 75510, total loss = 0.56, batch loss = 0.29 (118.6 examples/sec; 0.067 sec/batch; 2h:19m:23s remains)
INFO - root - 2022-02-24 20:08:05.917890: step 75520, total loss = 0.56, batch loss = 0.29 (93.3 examples/sec; 0.086 sec/batch; 2h:57m:07s remains)
INFO - root - 2022-02-24 20:08:06.277106: step 75530, total loss = 0.55, batch loss = 0.28 (184.1 examples/sec; 0.043 sec/batch; 1h:29m:46s remains)
INFO - root - 2022-02-24 20:08:06.584487: step 75540, total loss = 0.63, batch loss = 0.36 (319.1 examples/sec; 0.025 sec/batch; 0h:51m:47s remains)
INFO - root - 2022-02-24 20:08:06.945887: step 75550, total loss = 0.65, batch loss = 0.38 (203.3 examples/sec; 0.039 sec/batch; 1h:21m:16s remains)
INFO - root - 2022-02-24 20:08:07.282194: step 75560, total loss = 0.55, batch loss = 0.28 (322.1 examples/sec; 0.025 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:08:07.553975: step 75570, total loss = 0.53, batch loss = 0.26 (178.7 examples/sec; 0.045 sec/batch; 1h:32m:29s remains)
INFO - root - 2022-02-24 20:08:07.862841: step 75580, total loss = 0.54, batch loss = 0.27 (327.8 examples/sec; 0.024 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:08:08.254366: step 75590, total loss = 0.81, batch loss = 0.54 (87.0 examples/sec; 0.092 sec/batch; 3h:09m:48s remains)
INFO - root - 2022-02-24 20:08:08.602407: step 75600, total loss = 0.60, batch loss = 0.33 (165.1 examples/sec; 0.048 sec/batch; 1h:40m:03s remains)
INFO - root - 2022-02-24 20:08:08.956457: step 75610, total loss = 0.63, batch loss = 0.36 (325.1 examples/sec; 0.025 sec/batch; 0h:50m:49s remains)
INFO - root - 2022-02-24 20:08:09.225630: step 75620, total loss = 0.55, batch loss = 0.28 (168.9 examples/sec; 0.047 sec/batch; 1h:37m:48s remains)
INFO - root - 2022-02-24 20:08:09.562292: step 75630, total loss = 0.56, batch loss = 0.29 (189.0 examples/sec; 0.042 sec/batch; 1h:27m:22s remains)
INFO - root - 2022-02-24 20:08:10.046034: step 75640, total loss = 0.49, batch loss = 0.23 (115.3 examples/sec; 0.069 sec/batch; 2h:23m:11s remains)
INFO - root - 2022-02-24 20:08:10.385169: step 75650, total loss = 0.57, batch loss = 0.30 (388.2 examples/sec; 0.021 sec/batch; 0h:42m:32s remains)
INFO - root - 2022-02-24 20:08:10.786854: step 75660, total loss = 0.52, batch loss = 0.25 (237.6 examples/sec; 0.034 sec/batch; 1h:09m:28s remains)
INFO - root - 2022-02-24 20:08:11.138631: step 75670, total loss = 0.59, batch loss = 0.33 (206.0 examples/sec; 0.039 sec/batch; 1h:20m:09s remains)
INFO - root - 2022-02-24 20:08:11.434610: step 75680, total loss = 0.51, batch loss = 0.24 (184.5 examples/sec; 0.043 sec/batch; 1h:29m:29s remains)
INFO - root - 2022-02-24 20:08:11.760069: step 75690, total loss = 0.50, batch loss = 0.24 (285.8 examples/sec; 0.028 sec/batch; 0h:57m:46s remains)
INFO - root - 2022-02-24 20:08:12.137617: step 75700, total loss = 0.56, batch loss = 0.30 (126.2 examples/sec; 0.063 sec/batch; 2h:10m:49s remains)
INFO - root - 2022-02-24 20:08:12.618356: step 75710, total loss = 0.51, batch loss = 0.24 (351.4 examples/sec; 0.023 sec/batch; 0h:46m:58s remains)
INFO - root - 2022-02-24 20:08:13.053863: step 75720, total loss = 0.47, batch loss = 0.20 (172.7 examples/sec; 0.046 sec/batch; 1h:35m:35s remains)
INFO - root - 2022-02-24 20:08:13.523797: step 75730, total loss = 0.52, batch loss = 0.26 (337.0 examples/sec; 0.024 sec/batch; 0h:48m:57s remains)
INFO - root - 2022-02-24 20:08:13.924862: step 75740, total loss = 0.80, batch loss = 0.53 (307.2 examples/sec; 0.026 sec/batch; 0h:53m:43s remains)
INFO - root - 2022-02-24 20:08:14.425608: step 75750, total loss = 0.59, batch loss = 0.32 (309.9 examples/sec; 0.026 sec/batch; 0h:53m:14s remains)
INFO - root - 2022-02-24 20:08:14.932053: step 75760, total loss = 0.55, batch loss = 0.28 (133.9 examples/sec; 0.060 sec/batch; 2h:03m:13s remains)
INFO - root - 2022-02-24 20:08:15.373001: step 75770, total loss = 0.68, batch loss = 0.41 (145.2 examples/sec; 0.055 sec/batch; 1h:53m:37s remains)
INFO - root - 2022-02-24 20:08:15.687214: step 75780, total loss = 0.60, batch loss = 0.33 (338.3 examples/sec; 0.024 sec/batch; 0h:48m:46s remains)
INFO - root - 2022-02-24 20:08:16.441957: step 75790, total loss = 0.72, batch loss = 0.45 (19.0 examples/sec; 0.422 sec/batch; 14h:29m:41s remains)
INFO - root - 2022-02-24 20:08:16.878411: step 75800, total loss = 0.56, batch loss = 0.29 (208.6 examples/sec; 0.038 sec/batch; 1h:19m:03s remains)
INFO - root - 2022-02-24 20:08:17.277644: step 75810, total loss = 0.62, batch loss = 0.35 (359.8 examples/sec; 0.022 sec/batch; 0h:45m:50s remains)
INFO - root - 2022-02-24 20:08:17.647581: step 75820, total loss = 0.53, batch loss = 0.26 (334.6 examples/sec; 0.024 sec/batch; 0h:49m:16s remains)
INFO - root - 2022-02-24 20:08:18.007610: step 75830, total loss = 0.72, batch loss = 0.45 (325.4 examples/sec; 0.025 sec/batch; 0h:50m:39s remains)
INFO - root - 2022-02-24 20:08:18.339499: step 75840, total loss = 0.53, batch loss = 0.26 (119.3 examples/sec; 0.067 sec/batch; 2h:18m:12s remains)
INFO - root - 2022-02-24 20:08:18.715429: step 75850, total loss = 0.49, batch loss = 0.22 (316.9 examples/sec; 0.025 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:08:19.137415: step 75860, total loss = 0.56, batch loss = 0.29 (333.7 examples/sec; 0.024 sec/batch; 0h:49m:24s remains)
INFO - root - 2022-02-24 20:08:19.460414: step 75870, total loss = 0.70, batch loss = 0.43 (265.1 examples/sec; 0.030 sec/batch; 1h:02m:10s remains)
INFO - root - 2022-02-24 20:08:19.808203: step 75880, total loss = 0.59, batch loss = 0.32 (179.7 examples/sec; 0.045 sec/batch; 1h:31m:42s remains)
INFO - root - 2022-02-24 20:08:20.744347: step 75890, total loss = 0.45, batch loss = 0.19 (132.5 examples/sec; 0.060 sec/batch; 2h:04m:22s remains)
INFO - root - 2022-02-24 20:08:21.139421: step 75900, total loss = 0.64, batch loss = 0.37 (345.5 examples/sec; 0.023 sec/batch; 0h:47m:41s remains)
INFO - root - 2022-02-24 20:08:21.612763: step 75910, total loss = 0.51, batch loss = 0.24 (217.0 examples/sec; 0.037 sec/batch; 1h:15m:57s remains)
INFO - root - 2022-02-24 20:08:21.865189: step 75920, total loss = 0.56, batch loss = 0.29 (332.9 examples/sec; 0.024 sec/batch; 0h:49m:29s remains)
INFO - root - 2022-02-24 20:08:22.194666: step 75930, total loss = 0.51, batch loss = 0.24 (280.8 examples/sec; 0.028 sec/batch; 0h:58m:40s remains)
INFO - root - 2022-02-24 20:08:22.537040: step 75940, total loss = 0.54, batch loss = 0.28 (348.6 examples/sec; 0.023 sec/batch; 0h:47m:15s remains)
INFO - root - 2022-02-24 20:08:22.918974: step 75950, total loss = 0.50, batch loss = 0.23 (168.5 examples/sec; 0.047 sec/batch; 1h:37m:46s remains)
INFO - root - 2022-02-24 20:08:23.307284: step 75960, total loss = 0.72, batch loss = 0.45 (165.4 examples/sec; 0.048 sec/batch; 1h:39m:34s remains)
INFO - root - 2022-02-24 20:08:23.660005: step 75970, total loss = 0.57, batch loss = 0.31 (312.3 examples/sec; 0.026 sec/batch; 0h:52m:44s remains)
INFO - root - 2022-02-24 20:08:23.911608: step 75980, total loss = 0.60, batch loss = 0.33 (307.1 examples/sec; 0.026 sec/batch; 0h:53m:37s remains)
INFO - root - 2022-02-24 20:08:24.209281: step 75990, total loss = 0.49, batch loss = 0.23 (368.0 examples/sec; 0.022 sec/batch; 0h:44m:44s remains)
INFO - root - 2022-02-24 20:08:24.598935: step 76000, total loss = 0.52, batch loss = 0.26 (282.6 examples/sec; 0.028 sec/batch; 0h:58m:15s remains)
INFO - root - 2022-02-24 20:08:25.094670: step 76010, total loss = 0.52, batch loss = 0.25 (351.0 examples/sec; 0.023 sec/batch; 0h:46m:54s remains)
INFO - root - 2022-02-24 20:08:25.419153: step 76020, total loss = 0.53, batch loss = 0.26 (329.7 examples/sec; 0.024 sec/batch; 0h:49m:56s remains)
INFO - root - 2022-02-24 20:08:25.721212: step 76030, total loss = 0.63, batch loss = 0.36 (326.0 examples/sec; 0.025 sec/batch; 0h:50m:29s remains)
INFO - root - 2022-02-24 20:08:26.011268: step 76040, total loss = 0.57, batch loss = 0.30 (225.1 examples/sec; 0.036 sec/batch; 1h:13m:07s remains)
INFO - root - 2022-02-24 20:08:26.341063: step 76050, total loss = 0.67, batch loss = 0.40 (315.9 examples/sec; 0.025 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 20:08:26.707177: step 76060, total loss = 0.68, batch loss = 0.41 (356.8 examples/sec; 0.022 sec/batch; 0h:46m:07s remains)
INFO - root - 2022-02-24 20:08:27.031159: step 76070, total loss = 0.62, batch loss = 0.35 (340.9 examples/sec; 0.023 sec/batch; 0h:48m:16s remains)
INFO - root - 2022-02-24 20:08:27.395037: step 76080, total loss = 0.58, batch loss = 0.31 (307.5 examples/sec; 0.026 sec/batch; 0h:53m:30s remains)
INFO - root - 2022-02-24 20:08:27.728194: step 76090, total loss = 0.57, batch loss = 0.30 (243.8 examples/sec; 0.033 sec/batch; 1h:07m:30s remains)
INFO - root - 2022-02-24 20:08:28.020004: step 76100, total loss = 0.54, batch loss = 0.28 (330.5 examples/sec; 0.024 sec/batch; 0h:49m:47s remains)
INFO - root - 2022-02-24 20:08:28.425118: step 76110, total loss = 0.63, batch loss = 0.36 (369.4 examples/sec; 0.022 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:08:28.907844: step 76120, total loss = 0.62, batch loss = 0.36 (115.9 examples/sec; 0.069 sec/batch; 2h:21m:53s remains)
INFO - root - 2022-02-24 20:08:29.300628: step 76130, total loss = 0.54, batch loss = 0.27 (266.4 examples/sec; 0.030 sec/batch; 1h:01m:44s remains)
INFO - root - 2022-02-24 20:08:29.624561: step 76140, total loss = 0.52, batch loss = 0.25 (346.9 examples/sec; 0.023 sec/batch; 0h:47m:24s remains)
INFO - root - 2022-02-24 20:08:29.891058: step 76150, total loss = 0.54, batch loss = 0.27 (287.9 examples/sec; 0.028 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 20:08:30.230876: step 76160, total loss = 0.60, batch loss = 0.33 (334.2 examples/sec; 0.024 sec/batch; 0h:49m:12s remains)
INFO - root - 2022-02-24 20:08:30.546929: step 76170, total loss = 0.50, batch loss = 0.24 (271.8 examples/sec; 0.029 sec/batch; 1h:00m:30s remains)
INFO - root - 2022-02-24 20:08:30.932300: step 76180, total loss = 0.66, batch loss = 0.39 (352.0 examples/sec; 0.023 sec/batch; 0h:46m:42s remains)
INFO - root - 2022-02-24 20:08:31.354988: step 76190, total loss = 0.69, batch loss = 0.42 (161.9 examples/sec; 0.049 sec/batch; 1h:41m:32s remains)
INFO - root - 2022-02-24 20:08:31.714610: step 76200, total loss = 0.61, batch loss = 0.34 (281.5 examples/sec; 0.028 sec/batch; 0h:58m:24s remains)
INFO - root - 2022-02-24 20:08:32.139737: step 76210, total loss = 0.54, batch loss = 0.27 (313.2 examples/sec; 0.026 sec/batch; 0h:52m:29s remains)
INFO - root - 2022-02-24 20:08:32.462709: step 76220, total loss = 0.61, batch loss = 0.34 (329.7 examples/sec; 0.024 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:08:32.826448: step 76230, total loss = 0.57, batch loss = 0.30 (338.9 examples/sec; 0.024 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:08:33.151042: step 76240, total loss = 0.59, batch loss = 0.32 (336.2 examples/sec; 0.024 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:08:33.557600: step 76250, total loss = 0.77, batch loss = 0.51 (141.1 examples/sec; 0.057 sec/batch; 1h:56m:29s remains)
INFO - root - 2022-02-24 20:08:34.190146: step 76260, total loss = 0.48, batch loss = 0.21 (150.3 examples/sec; 0.053 sec/batch; 1h:49m:18s remains)
INFO - root - 2022-02-24 20:08:34.788891: step 76270, total loss = 0.48, batch loss = 0.21 (83.7 examples/sec; 0.096 sec/batch; 3h:16m:22s remains)
INFO - root - 2022-02-24 20:08:35.899891: step 76280, total loss = 0.56, batch loss = 0.30 (313.1 examples/sec; 0.026 sec/batch; 0h:52m:28s remains)
INFO - root - 2022-02-24 20:08:36.198489: step 76290, total loss = 0.62, batch loss = 0.35 (175.3 examples/sec; 0.046 sec/batch; 1h:33m:42s remains)
INFO - root - 2022-02-24 20:08:36.560130: step 76300, total loss = 0.61, batch loss = 0.34 (167.5 examples/sec; 0.048 sec/batch; 1h:38m:05s remains)
INFO - root - 2022-02-24 20:08:36.939544: step 76310, total loss = 0.69, batch loss = 0.42 (242.3 examples/sec; 0.033 sec/batch; 1h:07m:47s remains)
INFO - root - 2022-02-24 20:08:37.418835: step 76320, total loss = 0.56, batch loss = 0.29 (157.8 examples/sec; 0.051 sec/batch; 1h:44m:04s remains)
INFO - root - 2022-02-24 20:08:37.799475: step 76330, total loss = 0.66, batch loss = 0.39 (198.7 examples/sec; 0.040 sec/batch; 1h:22m:39s remains)
INFO - root - 2022-02-24 20:08:38.119861: step 76340, total loss = 0.52, batch loss = 0.25 (201.8 examples/sec; 0.040 sec/batch; 1h:21m:21s remains)
INFO - root - 2022-02-24 20:08:38.460615: step 76350, total loss = 0.61, batch loss = 0.34 (362.9 examples/sec; 0.022 sec/batch; 0h:45m:14s remains)
INFO - root - 2022-02-24 20:08:38.745197: step 76360, total loss = 0.60, batch loss = 0.33 (201.6 examples/sec; 0.040 sec/batch; 1h:21m:25s remains)
INFO - root - 2022-02-24 20:08:39.122423: step 76370, total loss = 0.48, batch loss = 0.22 (232.0 examples/sec; 0.034 sec/batch; 1h:10m:45s remains)
INFO - root - 2022-02-24 20:08:39.446846: step 76380, total loss = 0.56, batch loss = 0.30 (334.4 examples/sec; 0.024 sec/batch; 0h:49m:05s remains)
INFO - root - 2022-02-24 20:08:39.736386: step 76390, total loss = 0.49, batch loss = 0.23 (299.8 examples/sec; 0.027 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:08:40.043015: step 76400, total loss = 0.70, batch loss = 0.43 (199.3 examples/sec; 0.040 sec/batch; 1h:22m:22s remains)
INFO - root - 2022-02-24 20:08:40.562519: step 76410, total loss = 0.54, batch loss = 0.28 (181.8 examples/sec; 0.044 sec/batch; 1h:30m:17s remains)
INFO - root - 2022-02-24 20:08:40.934728: step 76420, total loss = 0.62, batch loss = 0.35 (187.0 examples/sec; 0.043 sec/batch; 1h:27m:45s remains)
INFO - root - 2022-02-24 20:08:41.382738: step 76430, total loss = 0.54, batch loss = 0.27 (188.3 examples/sec; 0.042 sec/batch; 1h:27m:09s remains)
INFO - root - 2022-02-24 20:08:41.804045: step 76440, total loss = 0.48, batch loss = 0.21 (258.5 examples/sec; 0.031 sec/batch; 1h:03m:28s remains)
INFO - root - 2022-02-24 20:08:42.132191: step 76450, total loss = 0.57, batch loss = 0.30 (339.1 examples/sec; 0.024 sec/batch; 0h:48m:23s remains)
INFO - root - 2022-02-24 20:08:42.458810: step 76460, total loss = 0.57, batch loss = 0.30 (317.5 examples/sec; 0.025 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:08:42.835520: step 76470, total loss = 0.65, batch loss = 0.38 (210.7 examples/sec; 0.038 sec/batch; 1h:17m:52s remains)
INFO - root - 2022-02-24 20:08:43.270462: step 76480, total loss = 0.59, batch loss = 0.33 (333.3 examples/sec; 0.024 sec/batch; 0h:49m:12s remains)
INFO - root - 2022-02-24 20:08:43.610448: step 76490, total loss = 0.65, batch loss = 0.38 (277.1 examples/sec; 0.029 sec/batch; 0h:59m:11s remains)
INFO - root - 2022-02-24 20:08:43.896205: step 76500, total loss = 0.58, batch loss = 0.31 (325.9 examples/sec; 0.025 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 20:08:44.288889: step 76510, total loss = 0.57, batch loss = 0.30 (327.2 examples/sec; 0.024 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:08:44.574500: step 76520, total loss = 0.59, batch loss = 0.33 (197.7 examples/sec; 0.040 sec/batch; 1h:22m:55s remains)
INFO - root - 2022-02-24 20:08:44.929988: step 76530, total loss = 0.54, batch loss = 0.27 (113.5 examples/sec; 0.070 sec/batch; 2h:24m:25s remains)
INFO - root - 2022-02-24 20:08:45.378726: step 76540, total loss = 0.57, batch loss = 0.30 (94.3 examples/sec; 0.085 sec/batch; 2h:53m:48s remains)
INFO - root - 2022-02-24 20:08:45.747219: step 76550, total loss = 0.56, batch loss = 0.29 (236.3 examples/sec; 0.034 sec/batch; 1h:09m:21s remains)
INFO - root - 2022-02-24 20:08:46.002927: step 76560, total loss = 0.63, batch loss = 0.36 (351.3 examples/sec; 0.023 sec/batch; 0h:46m:39s remains)
INFO - root - 2022-02-24 20:08:46.362430: step 76570, total loss = 0.51, batch loss = 0.24 (197.6 examples/sec; 0.040 sec/batch; 1h:22m:57s remains)
INFO - root - 2022-02-24 20:08:46.680687: step 76580, total loss = 0.58, batch loss = 0.31 (169.5 examples/sec; 0.047 sec/batch; 1h:36m:40s remains)
INFO - root - 2022-02-24 20:08:47.079254: step 76590, total loss = 0.42, batch loss = 0.15 (265.5 examples/sec; 0.030 sec/batch; 1h:01m:43s remains)
INFO - root - 2022-02-24 20:08:47.561268: step 76600, total loss = 0.56, batch loss = 0.29 (96.5 examples/sec; 0.083 sec/batch; 2h:49m:45s remains)
INFO - root - 2022-02-24 20:08:47.950921: step 76610, total loss = 0.48, batch loss = 0.21 (317.5 examples/sec; 0.025 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:08:48.297029: step 76620, total loss = 0.53, batch loss = 0.26 (318.3 examples/sec; 0.025 sec/batch; 0h:51m:28s remains)
INFO - root - 2022-02-24 20:08:48.562710: step 76630, total loss = 0.58, batch loss = 0.31 (305.9 examples/sec; 0.026 sec/batch; 0h:53m:33s remains)
INFO - root - 2022-02-24 20:08:48.949872: step 76640, total loss = 0.59, batch loss = 0.32 (116.7 examples/sec; 0.069 sec/batch; 2h:20m:24s remains)
INFO - root - 2022-02-24 20:08:49.321989: step 76650, total loss = 0.54, batch loss = 0.27 (129.4 examples/sec; 0.062 sec/batch; 2h:06m:36s remains)
INFO - root - 2022-02-24 20:08:49.790722: step 76660, total loss = 0.60, batch loss = 0.33 (97.0 examples/sec; 0.082 sec/batch; 2h:48m:49s remains)
INFO - root - 2022-02-24 20:08:50.064272: step 76670, total loss = 0.58, batch loss = 0.32 (304.4 examples/sec; 0.026 sec/batch; 0h:53m:48s remains)
INFO - root - 2022-02-24 20:08:50.401804: step 76680, total loss = 0.50, batch loss = 0.23 (157.4 examples/sec; 0.051 sec/batch; 1h:44m:04s remains)
INFO - root - 2022-02-24 20:08:50.891821: step 76690, total loss = 0.58, batch loss = 0.31 (366.5 examples/sec; 0.022 sec/batch; 0h:44m:40s remains)
INFO - root - 2022-02-24 20:08:51.324256: step 76700, total loss = 0.54, batch loss = 0.27 (263.3 examples/sec; 0.030 sec/batch; 1h:02m:11s remains)
INFO - root - 2022-02-24 20:08:51.886269: step 76710, total loss = 0.56, batch loss = 0.29 (216.4 examples/sec; 0.037 sec/batch; 1h:15m:40s remains)
INFO - root - 2022-02-24 20:08:52.185840: step 76720, total loss = 0.55, batch loss = 0.28 (333.9 examples/sec; 0.024 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:08:52.796234: step 76730, total loss = 0.63, batch loss = 0.37 (68.1 examples/sec; 0.118 sec/batch; 4h:00m:32s remains)
INFO - root - 2022-02-24 20:08:53.388848: step 76740, total loss = 0.51, batch loss = 0.24 (233.1 examples/sec; 0.034 sec/batch; 1h:10m:13s remains)
INFO - root - 2022-02-24 20:08:53.755403: step 76750, total loss = 0.54, batch loss = 0.27 (360.6 examples/sec; 0.022 sec/batch; 0h:45m:23s remains)
INFO - root - 2022-02-24 20:08:54.136307: step 76760, total loss = 0.54, batch loss = 0.27 (275.4 examples/sec; 0.029 sec/batch; 0h:59m:25s remains)
INFO - root - 2022-02-24 20:08:54.460970: step 76770, total loss = 0.70, batch loss = 0.43 (329.1 examples/sec; 0.024 sec/batch; 0h:49m:43s remains)
INFO - root - 2022-02-24 20:08:54.754351: step 76780, total loss = 0.52, batch loss = 0.25 (304.8 examples/sec; 0.026 sec/batch; 0h:53m:41s remains)
INFO - root - 2022-02-24 20:08:55.090290: step 76790, total loss = 0.57, batch loss = 0.31 (198.9 examples/sec; 0.040 sec/batch; 1h:22m:15s remains)
INFO - root - 2022-02-24 20:08:55.863741: step 76800, total loss = 0.53, batch loss = 0.27 (151.0 examples/sec; 0.053 sec/batch; 1h:48m:19s remains)
INFO - root - 2022-02-24 20:08:56.303836: step 76810, total loss = 0.65, batch loss = 0.38 (370.2 examples/sec; 0.022 sec/batch; 0h:44m:11s remains)
INFO - root - 2022-02-24 20:08:56.718975: step 76820, total loss = 0.60, batch loss = 0.33 (327.6 examples/sec; 0.024 sec/batch; 0h:49m:55s remains)
INFO - root - 2022-02-24 20:08:57.059173: step 76830, total loss = 0.50, batch loss = 0.23 (336.7 examples/sec; 0.024 sec/batch; 0h:48m:34s remains)
INFO - root - 2022-02-24 20:08:57.379973: step 76840, total loss = 0.57, batch loss = 0.30 (244.0 examples/sec; 0.033 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 20:08:57.773986: step 76850, total loss = 0.58, batch loss = 0.32 (236.8 examples/sec; 0.034 sec/batch; 1h:09m:03s remains)
INFO - root - 2022-02-24 20:08:58.123349: step 76860, total loss = 0.59, batch loss = 0.32 (124.4 examples/sec; 0.064 sec/batch; 2h:11m:27s remains)
INFO - root - 2022-02-24 20:08:58.594718: step 76870, total loss = 0.55, batch loss = 0.28 (335.7 examples/sec; 0.024 sec/batch; 0h:48m:42s remains)
INFO - root - 2022-02-24 20:08:58.891441: step 76880, total loss = 0.61, batch loss = 0.34 (278.4 examples/sec; 0.029 sec/batch; 0h:58m:44s remains)
INFO - root - 2022-02-24 20:08:59.193240: step 76890, total loss = 0.54, batch loss = 0.27 (186.1 examples/sec; 0.043 sec/batch; 1h:27m:51s remains)
INFO - root - 2022-02-24 20:08:59.549761: step 76900, total loss = 0.51, batch loss = 0.24 (203.1 examples/sec; 0.039 sec/batch; 1h:20m:29s remains)
INFO - root - 2022-02-24 20:09:00.119770: step 76910, total loss = 0.62, batch loss = 0.35 (301.3 examples/sec; 0.027 sec/batch; 0h:54m:15s remains)
INFO - root - 2022-02-24 20:09:00.500842: step 76920, total loss = 0.72, batch loss = 0.46 (163.7 examples/sec; 0.049 sec/batch; 1h:39m:49s remains)
INFO - root - 2022-02-24 20:09:00.823238: step 76930, total loss = 0.48, batch loss = 0.21 (321.7 examples/sec; 0.025 sec/batch; 0h:50m:47s remains)
INFO - root - 2022-02-24 20:09:01.126170: step 76940, total loss = 0.51, batch loss = 0.24 (344.2 examples/sec; 0.023 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:09:01.412033: step 76950, total loss = 0.57, batch loss = 0.30 (329.3 examples/sec; 0.024 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 20:09:01.711377: step 76960, total loss = 0.61, batch loss = 0.34 (332.6 examples/sec; 0.024 sec/batch; 0h:49m:07s remains)
INFO - root - 2022-02-24 20:09:02.039843: step 76970, total loss = 0.49, batch loss = 0.22 (276.3 examples/sec; 0.029 sec/batch; 0h:59m:07s remains)
INFO - root - 2022-02-24 20:09:02.508788: step 76980, total loss = 0.48, batch loss = 0.21 (344.2 examples/sec; 0.023 sec/batch; 0h:47m:27s remains)
INFO - root - 2022-02-24 20:09:02.829598: step 76990, total loss = 0.58, batch loss = 0.31 (342.9 examples/sec; 0.023 sec/batch; 0h:47m:37s remains)
INFO - root - 2022-02-24 20:09:03.182738: step 77000, total loss = 0.63, batch loss = 0.36 (280.7 examples/sec; 0.028 sec/batch; 0h:58m:11s remains)
INFO - root - 2022-02-24 20:09:03.589515: step 77010, total loss = 0.59, batch loss = 0.32 (223.3 examples/sec; 0.036 sec/batch; 1h:13m:08s remains)
INFO - root - 2022-02-24 20:09:03.990235: step 77020, total loss = 0.50, batch loss = 0.23 (108.1 examples/sec; 0.074 sec/batch; 2h:31m:03s remains)
INFO - root - 2022-02-24 20:09:04.338303: step 77030, total loss = 0.54, batch loss = 0.27 (228.7 examples/sec; 0.035 sec/batch; 1h:11m:23s remains)
INFO - root - 2022-02-24 20:09:04.640777: step 77040, total loss = 0.61, batch loss = 0.34 (343.1 examples/sec; 0.023 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:09:04.946187: step 77050, total loss = 0.66, batch loss = 0.39 (205.8 examples/sec; 0.039 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 20:09:05.248589: step 77060, total loss = 0.58, batch loss = 0.31 (358.6 examples/sec; 0.022 sec/batch; 0h:45m:31s remains)
INFO - root - 2022-02-24 20:09:05.652765: step 77070, total loss = 0.54, batch loss = 0.27 (320.2 examples/sec; 0.025 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:09:06.070940: step 77080, total loss = 0.68, batch loss = 0.41 (116.1 examples/sec; 0.069 sec/batch; 2h:20m:32s remains)
INFO - root - 2022-02-24 20:09:06.512535: step 77090, total loss = 0.61, batch loss = 0.35 (324.0 examples/sec; 0.025 sec/batch; 0h:50m:22s remains)
INFO - root - 2022-02-24 20:09:06.848090: step 77100, total loss = 0.59, batch loss = 0.32 (211.7 examples/sec; 0.038 sec/batch; 1h:17m:06s remains)
INFO - root - 2022-02-24 20:09:07.198887: step 77110, total loss = 0.70, batch loss = 0.43 (278.7 examples/sec; 0.029 sec/batch; 0h:58m:33s remains)
INFO - root - 2022-02-24 20:09:07.466796: step 77120, total loss = 0.52, batch loss = 0.25 (338.4 examples/sec; 0.024 sec/batch; 0h:48m:12s remains)
INFO - root - 2022-02-24 20:09:07.761178: step 77130, total loss = 0.65, batch loss = 0.38 (327.9 examples/sec; 0.024 sec/batch; 0h:49m:45s remains)
INFO - root - 2022-02-24 20:09:08.146887: step 77140, total loss = 0.52, batch loss = 0.26 (357.2 examples/sec; 0.022 sec/batch; 0h:45m:40s remains)
INFO - root - 2022-02-24 20:09:08.480016: step 77150, total loss = 0.46, batch loss = 0.20 (349.5 examples/sec; 0.023 sec/batch; 0h:46m:40s remains)
INFO - root - 2022-02-24 20:09:08.843045: step 77160, total loss = 0.68, batch loss = 0.41 (178.8 examples/sec; 0.045 sec/batch; 1h:31m:14s remains)
INFO - root - 2022-02-24 20:09:09.330389: step 77170, total loss = 0.63, batch loss = 0.36 (230.1 examples/sec; 0.035 sec/batch; 1h:10m:52s remains)
INFO - root - 2022-02-24 20:09:09.835918: step 77180, total loss = 0.48, batch loss = 0.21 (199.5 examples/sec; 0.040 sec/batch; 1h:21m:46s remains)
INFO - root - 2022-02-24 20:09:10.837732: step 77190, total loss = 0.52, batch loss = 0.25 (15.7 examples/sec; 0.508 sec/batch; 17h:15m:30s remains)
INFO - root - 2022-02-24 20:09:11.210099: step 77200, total loss = 0.65, batch loss = 0.38 (244.6 examples/sec; 0.033 sec/batch; 1h:06m:40s remains)
INFO - root - 2022-02-24 20:09:11.693138: step 77210, total loss = 0.57, batch loss = 0.31 (150.1 examples/sec; 0.053 sec/batch; 1h:48m:35s remains)
INFO - root - 2022-02-24 20:09:12.054573: step 77220, total loss = 0.60, batch loss = 0.34 (311.9 examples/sec; 0.026 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:09:12.477983: step 77230, total loss = 0.54, batch loss = 0.27 (176.1 examples/sec; 0.045 sec/batch; 1h:32m:35s remains)
INFO - root - 2022-02-24 20:09:12.783844: step 77240, total loss = 0.60, batch loss = 0.33 (330.7 examples/sec; 0.024 sec/batch; 0h:49m:17s remains)
INFO - root - 2022-02-24 20:09:13.112163: step 77250, total loss = 0.59, batch loss = 0.32 (358.2 examples/sec; 0.022 sec/batch; 0h:45m:30s remains)
INFO - root - 2022-02-24 20:09:13.415007: step 77260, total loss = 0.58, batch loss = 0.31 (270.6 examples/sec; 0.030 sec/batch; 1h:00m:14s remains)
INFO - root - 2022-02-24 20:09:13.707738: step 77270, total loss = 0.53, batch loss = 0.26 (335.8 examples/sec; 0.024 sec/batch; 0h:48m:31s remains)
INFO - root - 2022-02-24 20:09:13.969214: step 77280, total loss = 0.59, batch loss = 0.33 (294.1 examples/sec; 0.027 sec/batch; 0h:55m:24s remains)
INFO - root - 2022-02-24 20:09:14.330378: step 77290, total loss = 0.58, batch loss = 0.32 (284.1 examples/sec; 0.028 sec/batch; 0h:57m:21s remains)
INFO - root - 2022-02-24 20:09:14.712561: step 77300, total loss = 0.59, batch loss = 0.32 (127.2 examples/sec; 0.063 sec/batch; 2h:08m:03s remains)
INFO - root - 2022-02-24 20:09:15.130597: step 77310, total loss = 0.76, batch loss = 0.50 (197.2 examples/sec; 0.041 sec/batch; 1h:22m:37s remains)
INFO - root - 2022-02-24 20:09:15.476192: step 77320, total loss = 0.51, batch loss = 0.24 (347.1 examples/sec; 0.023 sec/batch; 0h:46m:55s remains)
INFO - root - 2022-02-24 20:09:15.862588: step 77330, total loss = 0.51, batch loss = 0.24 (259.3 examples/sec; 0.031 sec/batch; 1h:02m:48s remains)
INFO - root - 2022-02-24 20:09:16.319717: step 77340, total loss = 0.58, batch loss = 0.31 (339.1 examples/sec; 0.024 sec/batch; 0h:48m:02s remains)
INFO - root - 2022-02-24 20:09:16.744666: step 77350, total loss = 0.60, batch loss = 0.33 (125.8 examples/sec; 0.064 sec/batch; 2h:09m:28s remains)
INFO - root - 2022-02-24 20:09:17.157275: step 77360, total loss = 0.60, batch loss = 0.33 (335.4 examples/sec; 0.024 sec/batch; 0h:48m:33s remains)
INFO - root - 2022-02-24 20:09:17.506599: step 77370, total loss = 0.50, batch loss = 0.23 (211.7 examples/sec; 0.038 sec/batch; 1h:16m:54s remains)
INFO - root - 2022-02-24 20:09:17.762525: step 77380, total loss = 0.59, batch loss = 0.32 (330.1 examples/sec; 0.024 sec/batch; 0h:49m:19s remains)
INFO - root - 2022-02-24 20:09:18.049362: step 77390, total loss = 0.68, batch loss = 0.41 (248.1 examples/sec; 0.032 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:09:18.380532: step 77400, total loss = 0.60, batch loss = 0.33 (285.4 examples/sec; 0.028 sec/batch; 0h:57m:02s remains)
INFO - root - 2022-02-24 20:09:18.842355: step 77410, total loss = 0.76, batch loss = 0.49 (342.1 examples/sec; 0.023 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:09:19.230866: step 77420, total loss = 0.49, batch loss = 0.23 (190.7 examples/sec; 0.042 sec/batch; 1h:25m:22s remains)
INFO - root - 2022-02-24 20:09:19.533667: step 77430, total loss = 0.65, batch loss = 0.39 (310.9 examples/sec; 0.026 sec/batch; 0h:52m:21s remains)
INFO - root - 2022-02-24 20:09:19.776582: step 77440, total loss = 0.51, batch loss = 0.24 (343.1 examples/sec; 0.023 sec/batch; 0h:47m:26s remains)
INFO - root - 2022-02-24 20:09:20.049358: step 77450, total loss = 0.48, batch loss = 0.21 (168.3 examples/sec; 0.048 sec/batch; 1h:36m:42s remains)
INFO - root - 2022-02-24 20:09:20.353899: step 77460, total loss = 0.48, batch loss = 0.22 (310.9 examples/sec; 0.026 sec/batch; 0h:52m:19s remains)
INFO - root - 2022-02-24 20:09:20.726286: step 77470, total loss = 0.60, batch loss = 0.33 (362.1 examples/sec; 0.022 sec/batch; 0h:44m:56s remains)
INFO - root - 2022-02-24 20:09:21.174620: step 77480, total loss = 0.49, batch loss = 0.22 (126.6 examples/sec; 0.063 sec/batch; 2h:08m:31s remains)
INFO - root - 2022-02-24 20:09:21.476833: step 77490, total loss = 0.54, batch loss = 0.27 (340.0 examples/sec; 0.024 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:09:21.802277: step 77500, total loss = 0.52, batch loss = 0.25 (182.0 examples/sec; 0.044 sec/batch; 1h:29m:21s remains)
INFO - root - 2022-02-24 20:09:22.174527: step 77510, total loss = 0.50, batch loss = 0.23 (383.4 examples/sec; 0.021 sec/batch; 0h:42m:25s remains)
INFO - root - 2022-02-24 20:09:22.489342: step 77520, total loss = 0.63, batch loss = 0.37 (331.4 examples/sec; 0.024 sec/batch; 0h:49m:04s remains)
INFO - root - 2022-02-24 20:09:22.848799: step 77530, total loss = 0.62, batch loss = 0.35 (162.4 examples/sec; 0.049 sec/batch; 1h:40m:06s remains)
INFO - root - 2022-02-24 20:09:23.250082: step 77540, total loss = 0.49, batch loss = 0.23 (181.1 examples/sec; 0.044 sec/batch; 1h:29m:48s remains)
INFO - root - 2022-02-24 20:09:23.604870: step 77550, total loss = 0.59, batch loss = 0.32 (309.1 examples/sec; 0.026 sec/batch; 0h:52m:36s remains)
INFO - root - 2022-02-24 20:09:23.935642: step 77560, total loss = 0.68, batch loss = 0.41 (288.0 examples/sec; 0.028 sec/batch; 0h:56m:27s remains)
INFO - root - 2022-02-24 20:09:24.302698: step 77570, total loss = 0.58, batch loss = 0.31 (254.7 examples/sec; 0.031 sec/batch; 1h:03m:49s remains)
INFO - root - 2022-02-24 20:09:24.740128: step 77580, total loss = 0.57, batch loss = 0.30 (136.3 examples/sec; 0.059 sec/batch; 1h:59m:16s remains)
INFO - root - 2022-02-24 20:09:25.098768: step 77590, total loss = 0.58, batch loss = 0.31 (340.1 examples/sec; 0.024 sec/batch; 0h:47m:47s remains)
INFO - root - 2022-02-24 20:09:25.394750: step 77600, total loss = 0.61, batch loss = 0.34 (344.4 examples/sec; 0.023 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:09:25.771393: step 77610, total loss = 0.61, batch loss = 0.35 (215.8 examples/sec; 0.037 sec/batch; 1h:15m:19s remains)
INFO - root - 2022-02-24 20:09:26.345463: step 77620, total loss = 0.53, batch loss = 0.26 (205.4 examples/sec; 0.039 sec/batch; 1h:19m:08s remains)
INFO - root - 2022-02-24 20:09:26.757596: step 77630, total loss = 0.67, batch loss = 0.41 (308.3 examples/sec; 0.026 sec/batch; 0h:52m:42s remains)
INFO - root - 2022-02-24 20:09:27.150542: step 77640, total loss = 0.53, batch loss = 0.26 (301.1 examples/sec; 0.027 sec/batch; 0h:53m:57s remains)
INFO - root - 2022-02-24 20:09:27.491418: step 77650, total loss = 0.57, batch loss = 0.30 (189.4 examples/sec; 0.042 sec/batch; 1h:25m:45s remains)
INFO - root - 2022-02-24 20:09:27.908436: step 77660, total loss = 0.60, batch loss = 0.33 (104.6 examples/sec; 0.076 sec/batch; 2h:35m:14s remains)
INFO - root - 2022-02-24 20:09:28.452432: step 77670, total loss = 0.56, batch loss = 0.29 (267.5 examples/sec; 0.030 sec/batch; 1h:00m:42s remains)
INFO - root - 2022-02-24 20:09:28.904048: step 77680, total loss = 0.62, batch loss = 0.36 (366.9 examples/sec; 0.022 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:09:29.460681: step 77690, total loss = 0.61, batch loss = 0.34 (332.9 examples/sec; 0.024 sec/batch; 0h:48m:47s remains)
INFO - root - 2022-02-24 20:09:29.911047: step 77700, total loss = 0.51, batch loss = 0.25 (306.8 examples/sec; 0.026 sec/batch; 0h:52m:55s remains)
INFO - root - 2022-02-24 20:09:30.254463: step 77710, total loss = 0.54, batch loss = 0.27 (297.9 examples/sec; 0.027 sec/batch; 0h:54m:31s remains)
INFO - root - 2022-02-24 20:09:30.726298: step 77720, total loss = 0.46, batch loss = 0.19 (123.8 examples/sec; 0.065 sec/batch; 2h:11m:12s remains)
INFO - root - 2022-02-24 20:09:31.523022: step 77730, total loss = 0.52, batch loss = 0.26 (225.3 examples/sec; 0.036 sec/batch; 1h:12m:03s remains)
INFO - root - 2022-02-24 20:09:31.854830: step 77740, total loss = 0.59, batch loss = 0.32 (348.7 examples/sec; 0.023 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:09:32.151282: step 77750, total loss = 0.52, batch loss = 0.26 (320.7 examples/sec; 0.025 sec/batch; 0h:50m:36s remains)
INFO - root - 2022-02-24 20:09:32.483361: step 77760, total loss = 0.62, batch loss = 0.35 (330.0 examples/sec; 0.024 sec/batch; 0h:49m:11s remains)
INFO - root - 2022-02-24 20:09:32.746853: step 77770, total loss = 0.59, batch loss = 0.33 (338.4 examples/sec; 0.024 sec/batch; 0h:47m:57s remains)
INFO - root - 2022-02-24 20:09:33.193780: step 77780, total loss = 0.66, batch loss = 0.39 (367.3 examples/sec; 0.022 sec/batch; 0h:44m:10s remains)
INFO - root - 2022-02-24 20:09:33.515826: step 77790, total loss = 0.53, batch loss = 0.26 (303.7 examples/sec; 0.026 sec/batch; 0h:53m:26s remains)
INFO - root - 2022-02-24 20:09:33.877310: step 77800, total loss = 0.54, batch loss = 0.27 (178.8 examples/sec; 0.045 sec/batch; 1h:30m:45s remains)
INFO - root - 2022-02-24 20:09:34.243644: step 77810, total loss = 0.57, batch loss = 0.31 (334.5 examples/sec; 0.024 sec/batch; 0h:48m:30s remains)
INFO - root - 2022-02-24 20:09:34.707988: step 77820, total loss = 0.49, batch loss = 0.22 (109.8 examples/sec; 0.073 sec/batch; 2h:27m:47s remains)
INFO - root - 2022-02-24 20:09:35.165174: step 77830, total loss = 0.58, batch loss = 0.31 (257.3 examples/sec; 0.031 sec/batch; 1h:03m:03s remains)
INFO - root - 2022-02-24 20:09:35.525741: step 77840, total loss = 0.63, batch loss = 0.36 (360.6 examples/sec; 0.022 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 20:09:36.154847: step 77850, total loss = 0.55, batch loss = 0.28 (148.2 examples/sec; 0.054 sec/batch; 1h:49m:26s remains)
INFO - root - 2022-02-24 20:09:37.193335: step 77860, total loss = 0.51, batch loss = 0.25 (149.8 examples/sec; 0.053 sec/batch; 1h:48m:16s remains)
INFO - root - 2022-02-24 20:09:37.693110: step 77870, total loss = 0.52, batch loss = 0.25 (310.4 examples/sec; 0.026 sec/batch; 0h:52m:15s remains)
INFO - root - 2022-02-24 20:09:38.036501: step 77880, total loss = 0.56, batch loss = 0.29 (324.4 examples/sec; 0.025 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:09:38.300729: step 77890, total loss = 0.61, batch loss = 0.34 (240.5 examples/sec; 0.033 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 20:09:38.630367: step 77900, total loss = 0.52, batch loss = 0.25 (328.5 examples/sec; 0.024 sec/batch; 0h:49m:21s remains)
INFO - root - 2022-02-24 20:09:38.992399: step 77910, total loss = 0.55, batch loss = 0.28 (278.5 examples/sec; 0.029 sec/batch; 0h:58m:12s remains)
INFO - root - 2022-02-24 20:09:39.327866: step 77920, total loss = 0.56, batch loss = 0.30 (194.6 examples/sec; 0.041 sec/batch; 1h:23m:18s remains)
INFO - root - 2022-02-24 20:09:39.627248: step 77930, total loss = 0.52, batch loss = 0.25 (323.2 examples/sec; 0.025 sec/batch; 0h:50m:09s remains)
INFO - root - 2022-02-24 20:09:39.951835: step 77940, total loss = 0.50, batch loss = 0.23 (330.1 examples/sec; 0.024 sec/batch; 0h:49m:05s remains)
INFO - root - 2022-02-24 20:09:40.205218: step 77950, total loss = 0.60, batch loss = 0.33 (334.2 examples/sec; 0.024 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:09:40.509802: step 77960, total loss = 0.76, batch loss = 0.49 (274.1 examples/sec; 0.029 sec/batch; 0h:59m:07s remains)
INFO - root - 2022-02-24 20:09:40.831756: step 77970, total loss = 0.64, batch loss = 0.37 (377.7 examples/sec; 0.021 sec/batch; 0h:42m:53s remains)
INFO - root - 2022-02-24 20:09:41.137166: step 77980, total loss = 0.59, batch loss = 0.33 (185.1 examples/sec; 0.043 sec/batch; 1h:27m:33s remains)
INFO - root - 2022-02-24 20:09:41.541185: step 77990, total loss = 0.61, batch loss = 0.35 (119.7 examples/sec; 0.067 sec/batch; 2h:15m:23s remains)
INFO - root - 2022-02-24 20:09:42.002191: step 78000, total loss = 0.50, batch loss = 0.23 (306.8 examples/sec; 0.026 sec/batch; 0h:52m:48s remains)
INFO - root - 2022-02-24 20:09:42.400455: step 78010, total loss = 0.69, batch loss = 0.42 (264.7 examples/sec; 0.030 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 20:09:42.719437: step 78020, total loss = 0.60, batch loss = 0.33 (194.2 examples/sec; 0.041 sec/batch; 1h:23m:23s remains)
INFO - root - 2022-02-24 20:09:43.026787: step 78030, total loss = 0.57, batch loss = 0.31 (333.9 examples/sec; 0.024 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:09:43.435447: step 78040, total loss = 0.53, batch loss = 0.26 (272.7 examples/sec; 0.029 sec/batch; 0h:59m:22s remains)
INFO - root - 2022-02-24 20:09:43.808824: step 78050, total loss = 0.50, batch loss = 0.23 (255.9 examples/sec; 0.031 sec/batch; 1h:03m:16s remains)
INFO - root - 2022-02-24 20:09:44.140263: step 78060, total loss = 0.52, batch loss = 0.25 (360.2 examples/sec; 0.022 sec/batch; 0h:44m:57s remains)
INFO - root - 2022-02-24 20:09:44.417961: step 78070, total loss = 0.53, batch loss = 0.26 (242.4 examples/sec; 0.033 sec/batch; 1h:06m:47s remains)
INFO - root - 2022-02-24 20:09:44.710677: step 78080, total loss = 0.57, batch loss = 0.30 (241.5 examples/sec; 0.033 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 20:09:45.029773: step 78090, total loss = 0.68, batch loss = 0.41 (317.4 examples/sec; 0.025 sec/batch; 0h:50m:59s remains)
INFO - root - 2022-02-24 20:09:45.381799: step 78100, total loss = 0.57, batch loss = 0.30 (226.6 examples/sec; 0.035 sec/batch; 1h:11m:26s remains)
INFO - root - 2022-02-24 20:09:45.861304: step 78110, total loss = 0.56, batch loss = 0.29 (355.3 examples/sec; 0.023 sec/batch; 0h:45m:33s remains)
INFO - root - 2022-02-24 20:09:46.193834: step 78120, total loss = 0.53, batch loss = 0.26 (219.3 examples/sec; 0.036 sec/batch; 1h:13m:48s remains)
INFO - root - 2022-02-24 20:09:46.532926: step 78130, total loss = 0.54, batch loss = 0.28 (266.7 examples/sec; 0.030 sec/batch; 1h:00m:40s remains)
INFO - root - 2022-02-24 20:09:46.951100: step 78140, total loss = 0.56, batch loss = 0.29 (183.2 examples/sec; 0.044 sec/batch; 1h:28m:19s remains)
INFO - root - 2022-02-24 20:09:47.249779: step 78150, total loss = 0.48, batch loss = 0.21 (333.8 examples/sec; 0.024 sec/batch; 0h:48m:28s remains)
INFO - root - 2022-02-24 20:09:47.586916: step 78160, total loss = 0.54, batch loss = 0.27 (203.3 examples/sec; 0.039 sec/batch; 1h:19m:34s remains)
INFO - root - 2022-02-24 20:09:48.051816: step 78170, total loss = 0.50, batch loss = 0.23 (143.0 examples/sec; 0.056 sec/batch; 1h:53m:07s remains)
INFO - root - 2022-02-24 20:09:48.408519: step 78180, total loss = 0.74, batch loss = 0.47 (347.1 examples/sec; 0.023 sec/batch; 0h:46m:36s remains)
INFO - root - 2022-02-24 20:09:48.696471: step 78190, total loss = 0.53, batch loss = 0.26 (218.7 examples/sec; 0.037 sec/batch; 1h:13m:57s remains)
INFO - root - 2022-02-24 20:09:49.124776: step 78200, total loss = 0.57, batch loss = 0.30 (334.3 examples/sec; 0.024 sec/batch; 0h:48m:22s remains)
INFO - root - 2022-02-24 20:09:49.569741: step 78210, total loss = 0.49, batch loss = 0.22 (126.1 examples/sec; 0.063 sec/batch; 2h:08m:13s remains)
INFO - root - 2022-02-24 20:09:50.018201: step 78220, total loss = 0.47, batch loss = 0.21 (222.2 examples/sec; 0.036 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 20:09:50.380040: step 78230, total loss = 0.55, batch loss = 0.28 (171.5 examples/sec; 0.047 sec/batch; 1h:34m:15s remains)
INFO - root - 2022-02-24 20:09:50.724632: step 78240, total loss = 0.60, batch loss = 0.33 (319.1 examples/sec; 0.025 sec/batch; 0h:50m:39s remains)
INFO - root - 2022-02-24 20:09:51.009768: step 78250, total loss = 0.62, batch loss = 0.35 (348.2 examples/sec; 0.023 sec/batch; 0h:46m:25s remains)
INFO - root - 2022-02-24 20:09:51.289159: step 78260, total loss = 0.57, batch loss = 0.31 (361.5 examples/sec; 0.022 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:09:51.568245: step 78270, total loss = 0.62, batch loss = 0.35 (310.4 examples/sec; 0.026 sec/batch; 0h:52m:04s remains)
INFO - root - 2022-02-24 20:09:51.983709: step 78280, total loss = 0.61, batch loss = 0.34 (125.3 examples/sec; 0.064 sec/batch; 2h:08m:57s remains)
INFO - root - 2022-02-24 20:09:52.367179: step 78290, total loss = 0.57, batch loss = 0.30 (364.4 examples/sec; 0.022 sec/batch; 0h:44m:21s remains)
INFO - root - 2022-02-24 20:09:52.711502: step 78300, total loss = 0.54, batch loss = 0.27 (223.7 examples/sec; 0.036 sec/batch; 1h:12m:14s remains)
INFO - root - 2022-02-24 20:09:53.078556: step 78310, total loss = 0.67, batch loss = 0.40 (323.3 examples/sec; 0.025 sec/batch; 0h:49m:58s remains)
INFO - root - 2022-02-24 20:09:53.384417: step 78320, total loss = 0.60, batch loss = 0.33 (316.9 examples/sec; 0.025 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:09:53.663917: step 78330, total loss = 0.53, batch loss = 0.26 (355.0 examples/sec; 0.023 sec/batch; 0h:45m:30s remains)
INFO - root - 2022-02-24 20:09:54.038352: step 78340, total loss = 0.59, batch loss = 0.32 (275.9 examples/sec; 0.029 sec/batch; 0h:58m:33s remains)
INFO - root - 2022-02-24 20:09:54.403408: step 78350, total loss = 0.62, batch loss = 0.35 (344.1 examples/sec; 0.023 sec/batch; 0h:46m:56s remains)
INFO - root - 2022-02-24 20:09:54.730895: step 78360, total loss = 0.54, batch loss = 0.27 (248.1 examples/sec; 0.032 sec/batch; 1h:05m:06s remains)
INFO - root - 2022-02-24 20:09:55.032677: step 78370, total loss = 0.62, batch loss = 0.35 (255.8 examples/sec; 0.031 sec/batch; 1h:03m:07s remains)
INFO - root - 2022-02-24 20:09:55.350281: step 78380, total loss = 0.53, batch loss = 0.26 (339.0 examples/sec; 0.024 sec/batch; 0h:47m:38s remains)
INFO - root - 2022-02-24 20:09:55.676133: step 78390, total loss = 0.63, batch loss = 0.36 (331.8 examples/sec; 0.024 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 20:09:56.070328: step 78400, total loss = 0.53, batch loss = 0.26 (308.9 examples/sec; 0.026 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:09:56.489589: step 78410, total loss = 0.47, batch loss = 0.20 (165.3 examples/sec; 0.048 sec/batch; 1h:37m:39s remains)
INFO - root - 2022-02-24 20:09:56.864523: step 78420, total loss = 0.65, batch loss = 0.39 (308.4 examples/sec; 0.026 sec/batch; 0h:52m:20s remains)
INFO - root - 2022-02-24 20:09:57.182934: step 78430, total loss = 0.53, batch loss = 0.26 (195.7 examples/sec; 0.041 sec/batch; 1h:22m:29s remains)
INFO - root - 2022-02-24 20:09:57.854532: step 78440, total loss = 0.60, batch loss = 0.33 (130.9 examples/sec; 0.061 sec/batch; 2h:03m:17s remains)
INFO - root - 2022-02-24 20:09:58.291330: step 78450, total loss = 0.62, batch loss = 0.35 (276.0 examples/sec; 0.029 sec/batch; 0h:58m:28s remains)
INFO - root - 2022-02-24 20:09:58.767264: step 78460, total loss = 0.54, batch loss = 0.27 (169.6 examples/sec; 0.047 sec/batch; 1h:35m:09s remains)
INFO - root - 2022-02-24 20:09:59.144805: step 78470, total loss = 0.59, batch loss = 0.32 (192.9 examples/sec; 0.041 sec/batch; 1h:23m:38s remains)
INFO - root - 2022-02-24 20:09:59.555598: step 78480, total loss = 0.56, batch loss = 0.29 (195.4 examples/sec; 0.041 sec/batch; 1h:22m:33s remains)
INFO - root - 2022-02-24 20:10:00.040022: step 78490, total loss = 0.54, batch loss = 0.27 (179.5 examples/sec; 0.045 sec/batch; 1h:29m:54s remains)
INFO - root - 2022-02-24 20:10:00.468976: step 78500, total loss = 0.55, batch loss = 0.28 (173.7 examples/sec; 0.046 sec/batch; 1h:32m:53s remains)
INFO - root - 2022-02-24 20:10:00.972834: step 78510, total loss = 0.53, batch loss = 0.26 (293.6 examples/sec; 0.027 sec/batch; 0h:54m:57s remains)
INFO - root - 2022-02-24 20:10:01.430843: step 78520, total loss = 0.50, batch loss = 0.23 (282.4 examples/sec; 0.028 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 20:10:01.791318: step 78530, total loss = 0.74, batch loss = 0.47 (306.3 examples/sec; 0.026 sec/batch; 0h:52m:39s remains)
INFO - root - 2022-02-24 20:10:02.665580: step 78540, total loss = 0.50, batch loss = 0.23 (118.4 examples/sec; 0.068 sec/batch; 2h:16m:15s remains)
INFO - root - 2022-02-24 20:10:03.044954: step 78550, total loss = 0.50, batch loss = 0.23 (287.3 examples/sec; 0.028 sec/batch; 0h:56m:07s remains)
INFO - root - 2022-02-24 20:10:03.430339: step 78560, total loss = 0.55, batch loss = 0.28 (217.5 examples/sec; 0.037 sec/batch; 1h:14m:07s remains)
INFO - root - 2022-02-24 20:10:03.755484: step 78570, total loss = 0.57, batch loss = 0.30 (315.4 examples/sec; 0.025 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:10:04.092486: step 78580, total loss = 0.56, batch loss = 0.29 (350.9 examples/sec; 0.023 sec/batch; 0h:45m:57s remains)
INFO - root - 2022-02-24 20:10:04.553767: step 78590, total loss = 0.52, batch loss = 0.25 (97.5 examples/sec; 0.082 sec/batch; 2h:45m:23s remains)
INFO - root - 2022-02-24 20:10:04.863836: step 78600, total loss = 0.62, batch loss = 0.35 (306.4 examples/sec; 0.026 sec/batch; 0h:52m:36s remains)
INFO - root - 2022-02-24 20:10:05.215093: step 78610, total loss = 0.64, batch loss = 0.37 (338.7 examples/sec; 0.024 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:10:05.507927: step 78620, total loss = 0.56, batch loss = 0.29 (330.2 examples/sec; 0.024 sec/batch; 0h:48m:48s remains)
INFO - root - 2022-02-24 20:10:05.825903: step 78630, total loss = 0.52, batch loss = 0.25 (328.6 examples/sec; 0.024 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:10:06.078469: step 78640, total loss = 0.56, batch loss = 0.29 (335.4 examples/sec; 0.024 sec/batch; 0h:48m:02s remains)
INFO - root - 2022-02-24 20:10:06.430448: step 78650, total loss = 0.53, batch loss = 0.26 (166.8 examples/sec; 0.048 sec/batch; 1h:36m:37s remains)
INFO - root - 2022-02-24 20:10:06.846034: step 78660, total loss = 0.61, batch loss = 0.34 (208.9 examples/sec; 0.038 sec/batch; 1h:17m:07s remains)
INFO - root - 2022-02-24 20:10:07.276899: step 78670, total loss = 0.61, batch loss = 0.34 (141.9 examples/sec; 0.056 sec/batch; 1h:53m:34s remains)
INFO - root - 2022-02-24 20:10:07.581892: step 78680, total loss = 0.58, batch loss = 0.31 (340.4 examples/sec; 0.024 sec/batch; 0h:47m:19s remains)
INFO - root - 2022-02-24 20:10:08.174871: step 78690, total loss = 0.53, batch loss = 0.26 (310.1 examples/sec; 0.026 sec/batch; 0h:51m:56s remains)
INFO - root - 2022-02-24 20:10:08.547620: step 78700, total loss = 0.65, batch loss = 0.38 (294.2 examples/sec; 0.027 sec/batch; 0h:54m:44s remains)
INFO - root - 2022-02-24 20:10:08.968753: step 78710, total loss = 0.56, batch loss = 0.29 (282.3 examples/sec; 0.028 sec/batch; 0h:57m:02s remains)
INFO - root - 2022-02-24 20:10:09.271481: step 78720, total loss = 0.49, batch loss = 0.22 (246.8 examples/sec; 0.032 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 20:10:09.598500: step 78730, total loss = 0.53, batch loss = 0.26 (199.7 examples/sec; 0.040 sec/batch; 1h:20m:37s remains)
INFO - root - 2022-02-24 20:10:09.964033: step 78740, total loss = 0.69, batch loss = 0.42 (299.5 examples/sec; 0.027 sec/batch; 0h:53m:45s remains)
INFO - root - 2022-02-24 20:10:10.224854: step 78750, total loss = 0.56, batch loss = 0.29 (247.1 examples/sec; 0.032 sec/batch; 1h:05m:08s remains)
INFO - root - 2022-02-24 20:10:10.642972: step 78760, total loss = 0.59, batch loss = 0.33 (139.7 examples/sec; 0.057 sec/batch; 1h:55m:12s remains)
INFO - root - 2022-02-24 20:10:11.037269: step 78770, total loss = 0.78, batch loss = 0.51 (342.9 examples/sec; 0.023 sec/batch; 0h:46m:56s remains)
INFO - root - 2022-02-24 20:10:11.455825: step 78780, total loss = 0.59, batch loss = 0.32 (162.0 examples/sec; 0.049 sec/batch; 1h:39m:19s remains)
INFO - root - 2022-02-24 20:10:11.785224: step 78790, total loss = 0.46, batch loss = 0.20 (218.4 examples/sec; 0.037 sec/batch; 1h:13m:41s remains)
INFO - root - 2022-02-24 20:10:12.100370: step 78800, total loss = 0.53, batch loss = 0.26 (351.2 examples/sec; 0.023 sec/batch; 0h:45m:49s remains)
INFO - root - 2022-02-24 20:10:12.429644: step 78810, total loss = 0.51, batch loss = 0.24 (244.8 examples/sec; 0.033 sec/batch; 1h:05m:44s remains)
INFO - root - 2022-02-24 20:10:12.806338: step 78820, total loss = 0.61, batch loss = 0.34 (288.7 examples/sec; 0.028 sec/batch; 0h:55m:44s remains)
INFO - root - 2022-02-24 20:10:13.245232: step 78830, total loss = 0.63, batch loss = 0.37 (190.9 examples/sec; 0.042 sec/batch; 1h:24m:17s remains)
INFO - root - 2022-02-24 20:10:13.586616: step 78840, total loss = 0.68, batch loss = 0.42 (323.2 examples/sec; 0.025 sec/batch; 0h:49m:46s remains)
INFO - root - 2022-02-24 20:10:13.846572: step 78850, total loss = 0.56, batch loss = 0.29 (339.5 examples/sec; 0.024 sec/batch; 0h:47m:22s remains)
INFO - root - 2022-02-24 20:10:14.125605: step 78860, total loss = 0.59, batch loss = 0.33 (317.3 examples/sec; 0.025 sec/batch; 0h:50m:41s remains)
INFO - root - 2022-02-24 20:10:14.422586: step 78870, total loss = 0.62, batch loss = 0.35 (262.6 examples/sec; 0.030 sec/batch; 1h:01m:15s remains)
INFO - root - 2022-02-24 20:10:14.753306: step 78880, total loss = 0.56, batch loss = 0.29 (307.5 examples/sec; 0.026 sec/batch; 0h:52m:17s remains)
INFO - root - 2022-02-24 20:10:15.093234: step 78890, total loss = 0.64, batch loss = 0.37 (235.3 examples/sec; 0.034 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 20:10:15.480690: step 78900, total loss = 0.66, batch loss = 0.39 (325.7 examples/sec; 0.025 sec/batch; 0h:49m:22s remains)
INFO - root - 2022-02-24 20:10:15.822799: step 78910, total loss = 0.52, batch loss = 0.25 (348.4 examples/sec; 0.023 sec/batch; 0h:46m:09s remains)
INFO - root - 2022-02-24 20:10:16.123837: step 78920, total loss = 0.57, batch loss = 0.31 (253.1 examples/sec; 0.032 sec/batch; 1h:03m:30s remains)
INFO - root - 2022-02-24 20:10:16.428579: step 78930, total loss = 0.56, batch loss = 0.30 (325.7 examples/sec; 0.025 sec/batch; 0h:49m:21s remains)
INFO - root - 2022-02-24 20:10:16.725388: step 78940, total loss = 0.70, batch loss = 0.43 (223.1 examples/sec; 0.036 sec/batch; 1h:12m:03s remains)
INFO - root - 2022-02-24 20:10:17.200843: step 78950, total loss = 0.53, batch loss = 0.27 (132.8 examples/sec; 0.060 sec/batch; 2h:01m:02s remains)
INFO - root - 2022-02-24 20:10:17.635204: step 78960, total loss = 0.56, batch loss = 0.29 (83.2 examples/sec; 0.096 sec/batch; 3h:13m:14s remains)
INFO - root - 2022-02-24 20:10:17.943056: step 78970, total loss = 0.49, batch loss = 0.22 (196.9 examples/sec; 0.041 sec/batch; 1h:21m:37s remains)
INFO - root - 2022-02-24 20:10:18.270008: step 78980, total loss = 0.63, batch loss = 0.36 (249.2 examples/sec; 0.032 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 20:10:18.616088: step 78990, total loss = 0.63, batch loss = 0.36 (346.0 examples/sec; 0.023 sec/batch; 0h:46m:26s remains)
INFO - root - 2022-02-24 20:10:19.019141: step 79000, total loss = 0.57, batch loss = 0.30 (349.6 examples/sec; 0.023 sec/batch; 0h:45m:57s remains)
INFO - root - 2022-02-24 20:10:19.394747: step 79010, total loss = 0.57, batch loss = 0.30 (322.2 examples/sec; 0.025 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:10:19.687095: step 79020, total loss = 0.58, batch loss = 0.31 (351.9 examples/sec; 0.023 sec/batch; 0h:45m:38s remains)
INFO - root - 2022-02-24 20:10:19.996649: step 79030, total loss = 0.68, batch loss = 0.41 (317.3 examples/sec; 0.025 sec/batch; 0h:50m:37s remains)
INFO - root - 2022-02-24 20:10:20.290448: step 79040, total loss = 0.58, batch loss = 0.31 (251.5 examples/sec; 0.032 sec/batch; 1h:03m:51s remains)
INFO - root - 2022-02-24 20:10:20.619229: step 79050, total loss = 0.51, batch loss = 0.24 (362.0 examples/sec; 0.022 sec/batch; 0h:44m:21s remains)
INFO - root - 2022-02-24 20:10:21.032237: step 79060, total loss = 0.55, batch loss = 0.28 (246.4 examples/sec; 0.032 sec/batch; 1h:05m:10s remains)
INFO - root - 2022-02-24 20:10:21.353350: step 79070, total loss = 0.53, batch loss = 0.26 (354.3 examples/sec; 0.023 sec/batch; 0h:45m:19s remains)
INFO - root - 2022-02-24 20:10:21.645400: step 79080, total loss = 0.58, batch loss = 0.31 (334.1 examples/sec; 0.024 sec/batch; 0h:48m:03s remains)
INFO - root - 2022-02-24 20:10:21.955813: step 79090, total loss = 0.50, batch loss = 0.23 (290.6 examples/sec; 0.028 sec/batch; 0h:55m:14s remains)
INFO - root - 2022-02-24 20:10:22.264198: step 79100, total loss = 0.54, batch loss = 0.27 (370.0 examples/sec; 0.022 sec/batch; 0h:43m:23s remains)
INFO - root - 2022-02-24 20:10:22.687997: step 79110, total loss = 0.54, batch loss = 0.28 (170.9 examples/sec; 0.047 sec/batch; 1h:33m:55s remains)
INFO - root - 2022-02-24 20:10:23.403392: step 79120, total loss = 0.58, batch loss = 0.31 (144.3 examples/sec; 0.055 sec/batch; 1h:51m:15s remains)
INFO - root - 2022-02-24 20:10:23.834399: step 79130, total loss = 0.46, batch loss = 0.19 (151.0 examples/sec; 0.053 sec/batch; 1h:46m:18s remains)
INFO - root - 2022-02-24 20:10:24.181783: step 79140, total loss = 0.57, batch loss = 0.30 (290.1 examples/sec; 0.028 sec/batch; 0h:55m:18s remains)
INFO - root - 2022-02-24 20:10:24.537459: step 79150, total loss = 0.68, batch loss = 0.41 (367.7 examples/sec; 0.022 sec/batch; 0h:43m:38s remains)
INFO - root - 2022-02-24 20:10:25.000530: step 79160, total loss = 0.48, batch loss = 0.21 (180.6 examples/sec; 0.044 sec/batch; 1h:28m:50s remains)
INFO - root - 2022-02-24 20:10:25.488608: step 79170, total loss = 0.53, batch loss = 0.26 (272.3 examples/sec; 0.029 sec/batch; 0h:58m:55s remains)
INFO - root - 2022-02-24 20:10:26.048602: step 79180, total loss = 0.50, batch loss = 0.24 (84.0 examples/sec; 0.095 sec/batch; 3h:10m:53s remains)
INFO - root - 2022-02-24 20:10:26.537669: step 79190, total loss = 0.64, batch loss = 0.37 (344.2 examples/sec; 0.023 sec/batch; 0h:46m:36s remains)
INFO - root - 2022-02-24 20:10:26.986855: step 79200, total loss = 0.46, batch loss = 0.19 (331.1 examples/sec; 0.024 sec/batch; 0h:48m:26s remains)
INFO - root - 2022-02-24 20:10:27.479289: step 79210, total loss = 0.53, batch loss = 0.26 (190.8 examples/sec; 0.042 sec/batch; 1h:24m:04s remains)
INFO - root - 2022-02-24 20:10:28.047834: step 79220, total loss = 0.61, batch loss = 0.35 (193.0 examples/sec; 0.041 sec/batch; 1h:23m:04s remains)
INFO - root - 2022-02-24 20:10:28.835378: step 79230, total loss = 0.58, batch loss = 0.31 (309.0 examples/sec; 0.026 sec/batch; 0h:51m:53s remains)
INFO - root - 2022-02-24 20:10:29.150601: step 79240, total loss = 0.49, batch loss = 0.22 (332.9 examples/sec; 0.024 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:10:29.534637: step 79250, total loss = 0.59, batch loss = 0.32 (214.4 examples/sec; 0.037 sec/batch; 1h:14m:47s remains)
INFO - root - 2022-02-24 20:10:29.903846: step 79260, total loss = 0.54, batch loss = 0.28 (306.8 examples/sec; 0.026 sec/batch; 0h:52m:15s remains)
INFO - root - 2022-02-24 20:10:30.207950: step 79270, total loss = 0.55, batch loss = 0.28 (300.1 examples/sec; 0.027 sec/batch; 0h:53m:25s remains)
INFO - root - 2022-02-24 20:10:30.495631: step 79280, total loss = 0.58, batch loss = 0.32 (228.4 examples/sec; 0.035 sec/batch; 1h:10m:10s remains)
INFO - root - 2022-02-24 20:10:30.959020: step 79290, total loss = 0.51, batch loss = 0.24 (109.9 examples/sec; 0.073 sec/batch; 2h:25m:50s remains)
INFO - root - 2022-02-24 20:10:31.337836: step 79300, total loss = 0.55, batch loss = 0.28 (129.0 examples/sec; 0.062 sec/batch; 2h:04m:17s remains)
INFO - root - 2022-02-24 20:10:31.775993: step 79310, total loss = 0.54, batch loss = 0.28 (332.4 examples/sec; 0.024 sec/batch; 0h:48m:13s remains)
INFO - root - 2022-02-24 20:10:32.107112: step 79320, total loss = 0.51, batch loss = 0.24 (314.9 examples/sec; 0.025 sec/batch; 0h:50m:53s remains)
INFO - root - 2022-02-24 20:10:32.478203: step 79330, total loss = 0.52, batch loss = 0.25 (273.3 examples/sec; 0.029 sec/batch; 0h:58m:37s remains)
INFO - root - 2022-02-24 20:10:33.020085: step 79340, total loss = 0.55, batch loss = 0.28 (252.3 examples/sec; 0.032 sec/batch; 1h:03m:29s remains)
INFO - root - 2022-02-24 20:10:33.447981: step 79350, total loss = 0.51, batch loss = 0.24 (177.9 examples/sec; 0.045 sec/batch; 1h:30m:04s remains)
INFO - root - 2022-02-24 20:10:33.963599: step 79360, total loss = 0.55, batch loss = 0.28 (352.3 examples/sec; 0.023 sec/batch; 0h:45m:28s remains)
INFO - root - 2022-02-24 20:10:34.299105: step 79370, total loss = 0.56, batch loss = 0.29 (360.0 examples/sec; 0.022 sec/batch; 0h:44m:29s remains)
INFO - root - 2022-02-24 20:10:34.576117: step 79380, total loss = 0.58, batch loss = 0.32 (149.5 examples/sec; 0.053 sec/batch; 1h:47m:06s remains)
INFO - root - 2022-02-24 20:10:34.913703: step 79390, total loss = 0.73, batch loss = 0.46 (187.6 examples/sec; 0.043 sec/batch; 1h:25m:23s remains)
INFO - root - 2022-02-24 20:10:35.307497: step 79400, total loss = 0.49, batch loss = 0.22 (237.8 examples/sec; 0.034 sec/batch; 1h:07m:20s remains)
INFO - root - 2022-02-24 20:10:35.815357: step 79410, total loss = 0.51, batch loss = 0.25 (120.0 examples/sec; 0.067 sec/batch; 2h:13m:27s remains)
INFO - root - 2022-02-24 20:10:36.262063: step 79420, total loss = 0.53, batch loss = 0.26 (101.3 examples/sec; 0.079 sec/batch; 2h:38m:02s remains)
INFO - root - 2022-02-24 20:10:36.582371: step 79430, total loss = 0.49, batch loss = 0.23 (180.6 examples/sec; 0.044 sec/batch; 1h:28m:39s remains)
INFO - root - 2022-02-24 20:10:36.858692: step 79440, total loss = 0.63, batch loss = 0.36 (349.6 examples/sec; 0.023 sec/batch; 0h:45m:47s remains)
INFO - root - 2022-02-24 20:10:37.157247: step 79450, total loss = 0.55, batch loss = 0.29 (341.7 examples/sec; 0.023 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:10:37.515120: step 79460, total loss = 0.58, batch loss = 0.31 (332.1 examples/sec; 0.024 sec/batch; 0h:48m:11s remains)
INFO - root - 2022-02-24 20:10:37.944925: step 79470, total loss = 0.65, batch loss = 0.38 (211.1 examples/sec; 0.038 sec/batch; 1h:15m:47s remains)
INFO - root - 2022-02-24 20:10:38.366402: step 79480, total loss = 0.47, batch loss = 0.21 (289.6 examples/sec; 0.028 sec/batch; 0h:55m:14s remains)
INFO - root - 2022-02-24 20:10:38.632483: step 79490, total loss = 0.63, batch loss = 0.36 (315.2 examples/sec; 0.025 sec/batch; 0h:50m:45s remains)
INFO - root - 2022-02-24 20:10:38.903140: step 79500, total loss = 0.52, batch loss = 0.26 (208.2 examples/sec; 0.038 sec/batch; 1h:16m:52s remains)
INFO - root - 2022-02-24 20:10:39.279309: step 79510, total loss = 0.50, batch loss = 0.23 (191.3 examples/sec; 0.042 sec/batch; 1h:23m:38s remains)
INFO - root - 2022-02-24 20:10:39.643934: step 79520, total loss = 0.51, batch loss = 0.24 (363.3 examples/sec; 0.022 sec/batch; 0h:44m:01s remains)
INFO - root - 2022-02-24 20:10:40.111204: step 79530, total loss = 0.56, batch loss = 0.30 (361.0 examples/sec; 0.022 sec/batch; 0h:44m:18s remains)
INFO - root - 2022-02-24 20:10:40.438281: step 79540, total loss = 0.69, batch loss = 0.42 (229.5 examples/sec; 0.035 sec/batch; 1h:09m:41s remains)
INFO - root - 2022-02-24 20:10:40.772017: step 79550, total loss = 0.52, batch loss = 0.25 (265.7 examples/sec; 0.030 sec/batch; 1h:00m:11s remains)
INFO - root - 2022-02-24 20:10:41.059049: step 79560, total loss = 0.59, batch loss = 0.32 (321.1 examples/sec; 0.025 sec/batch; 0h:49m:48s remains)
INFO - root - 2022-02-24 20:10:41.380421: step 79570, total loss = 0.62, batch loss = 0.35 (309.7 examples/sec; 0.026 sec/batch; 0h:51m:38s remains)
INFO - root - 2022-02-24 20:10:41.840760: step 79580, total loss = 0.55, batch loss = 0.28 (116.8 examples/sec; 0.068 sec/batch; 2h:16m:50s remains)
INFO - root - 2022-02-24 20:10:42.211709: step 79590, total loss = 0.58, batch loss = 0.31 (250.5 examples/sec; 0.032 sec/batch; 1h:03m:49s remains)
INFO - root - 2022-02-24 20:10:42.556808: step 79600, total loss = 0.56, batch loss = 0.30 (215.5 examples/sec; 0.037 sec/batch; 1h:14m:11s remains)
INFO - root - 2022-02-24 20:10:42.974611: step 79610, total loss = 0.59, batch loss = 0.33 (218.6 examples/sec; 0.037 sec/batch; 1h:13m:08s remains)
INFO - root - 2022-02-24 20:10:43.363759: step 79620, total loss = 0.53, batch loss = 0.26 (172.8 examples/sec; 0.046 sec/batch; 1h:32m:30s remains)
INFO - root - 2022-02-24 20:10:43.694159: step 79630, total loss = 0.62, batch loss = 0.35 (342.0 examples/sec; 0.023 sec/batch; 0h:46m:43s remains)
INFO - root - 2022-02-24 20:10:44.106772: step 79640, total loss = 0.53, batch loss = 0.27 (135.7 examples/sec; 0.059 sec/batch; 1h:57m:46s remains)
INFO - root - 2022-02-24 20:10:44.502555: step 79650, total loss = 0.49, batch loss = 0.22 (333.2 examples/sec; 0.024 sec/batch; 0h:47m:57s remains)
INFO - root - 2022-02-24 20:10:44.788700: step 79660, total loss = 0.51, batch loss = 0.24 (351.4 examples/sec; 0.023 sec/batch; 0h:45m:28s remains)
INFO - root - 2022-02-24 20:10:45.082762: step 79670, total loss = 0.55, batch loss = 0.29 (307.2 examples/sec; 0.026 sec/batch; 0h:52m:00s remains)
INFO - root - 2022-02-24 20:10:45.368675: step 79680, total loss = 0.54, batch loss = 0.27 (271.5 examples/sec; 0.029 sec/batch; 0h:58m:50s remains)
INFO - root - 2022-02-24 20:10:45.761681: step 79690, total loss = 0.54, batch loss = 0.27 (351.7 examples/sec; 0.023 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:10:46.090496: step 79700, total loss = 0.53, batch loss = 0.27 (350.6 examples/sec; 0.023 sec/batch; 0h:45m:33s remains)
INFO - root - 2022-02-24 20:10:46.551347: step 79710, total loss = 0.53, batch loss = 0.26 (336.4 examples/sec; 0.024 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:10:46.834033: step 79720, total loss = 0.54, batch loss = 0.28 (364.0 examples/sec; 0.022 sec/batch; 0h:43m:52s remains)
INFO - root - 2022-02-24 20:10:47.144631: step 79730, total loss = 0.64, batch loss = 0.37 (326.1 examples/sec; 0.025 sec/batch; 0h:48m:58s remains)
INFO - root - 2022-02-24 20:10:47.488572: step 79740, total loss = 0.58, batch loss = 0.31 (340.4 examples/sec; 0.024 sec/batch; 0h:46m:54s remains)
INFO - root - 2022-02-24 20:10:48.363547: step 79750, total loss = 0.54, batch loss = 0.27 (21.4 examples/sec; 0.373 sec/batch; 12h:24m:39s remains)
INFO - root - 2022-02-24 20:10:48.736115: step 79760, total loss = 0.52, batch loss = 0.25 (317.1 examples/sec; 0.025 sec/batch; 0h:50m:20s remains)
INFO - root - 2022-02-24 20:10:49.079304: step 79770, total loss = 0.49, batch loss = 0.22 (357.0 examples/sec; 0.022 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:10:49.411188: step 79780, total loss = 0.53, batch loss = 0.26 (319.0 examples/sec; 0.025 sec/batch; 0h:50m:02s remains)
INFO - root - 2022-02-24 20:10:49.773336: step 79790, total loss = 0.60, batch loss = 0.33 (130.0 examples/sec; 0.062 sec/batch; 2h:02m:46s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-79799 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-79799 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:10:50.989210: step 79800, total loss = 0.56, batch loss = 0.29 (347.6 examples/sec; 0.023 sec/batch; 0h:45m:54s remains)
INFO - root - 2022-02-24 20:10:51.603179: step 79810, total loss = 0.63, batch loss = 0.36 (326.7 examples/sec; 0.024 sec/batch; 0h:48m:51s remains)
INFO - root - 2022-02-24 20:10:51.849732: step 79820, total loss = 0.59, batch loss = 0.32 (305.3 examples/sec; 0.026 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:10:52.093980: step 79830, total loss = 0.59, batch loss = 0.32 (357.4 examples/sec; 0.022 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:10:52.377883: step 79840, total loss = 0.54, batch loss = 0.27 (144.2 examples/sec; 0.055 sec/batch; 1h:50m:38s remains)
INFO - root - 2022-02-24 20:10:52.761946: step 79850, total loss = 0.59, batch loss = 0.32 (249.5 examples/sec; 0.032 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 20:10:53.524827: step 79860, total loss = 0.56, batch loss = 0.29 (249.5 examples/sec; 0.032 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 20:10:53.895858: step 79870, total loss = 0.54, batch loss = 0.27 (233.5 examples/sec; 0.034 sec/batch; 1h:08m:17s remains)
INFO - root - 2022-02-24 20:10:54.232910: step 79880, total loss = 0.52, batch loss = 0.26 (180.9 examples/sec; 0.044 sec/batch; 1h:28m:11s remains)
INFO - root - 2022-02-24 20:10:54.618480: step 79890, total loss = 0.63, batch loss = 0.37 (170.9 examples/sec; 0.047 sec/batch; 1h:33m:20s remains)
INFO - root - 2022-02-24 20:10:55.040111: step 79900, total loss = 0.53, batch loss = 0.26 (316.8 examples/sec; 0.025 sec/batch; 0h:50m:20s remains)
INFO - root - 2022-02-24 20:10:55.442911: step 79910, total loss = 0.52, batch loss = 0.26 (357.5 examples/sec; 0.022 sec/batch; 0h:44m:35s remains)
INFO - root - 2022-02-24 20:10:55.701158: step 79920, total loss = 0.53, batch loss = 0.26 (358.2 examples/sec; 0.022 sec/batch; 0h:44m:30s remains)
INFO - root - 2022-02-24 20:10:56.115012: step 79930, total loss = 0.52, batch loss = 0.25 (154.6 examples/sec; 0.052 sec/batch; 1h:43m:05s remains)
INFO - root - 2022-02-24 20:10:56.633859: step 79940, total loss = 0.54, batch loss = 0.27 (339.7 examples/sec; 0.024 sec/batch; 0h:46m:55s remains)
INFO - root - 2022-02-24 20:10:57.036535: step 79950, total loss = 0.67, batch loss = 0.40 (332.0 examples/sec; 0.024 sec/batch; 0h:48m:00s remains)
INFO - root - 2022-02-24 20:10:57.361804: step 79960, total loss = 0.53, batch loss = 0.26 (193.3 examples/sec; 0.041 sec/batch; 1h:22m:27s remains)
INFO - root - 2022-02-24 20:10:57.722255: step 79970, total loss = 0.46, batch loss = 0.19 (271.8 examples/sec; 0.029 sec/batch; 0h:58m:38s remains)
INFO - root - 2022-02-24 20:10:58.040569: step 79980, total loss = 0.56, batch loss = 0.30 (175.3 examples/sec; 0.046 sec/batch; 1h:30m:55s remains)
INFO - root - 2022-02-24 20:10:59.056594: step 79990, total loss = 0.61, batch loss = 0.34 (192.9 examples/sec; 0.041 sec/batch; 1h:22m:37s remains)
INFO - root - 2022-02-24 20:10:59.421889: step 80000, total loss = 0.45, batch loss = 0.19 (202.5 examples/sec; 0.040 sec/batch; 1h:18m:41s remains)
INFO - root - 2022-02-24 20:10:59.847216: step 80010, total loss = 0.55, batch loss = 0.29 (169.2 examples/sec; 0.047 sec/batch; 1h:34m:10s remains)
INFO - root - 2022-02-24 20:11:00.172929: step 80020, total loss = 0.65, batch loss = 0.39 (162.1 examples/sec; 0.049 sec/batch; 1h:38m:15s remains)
INFO - root - 2022-02-24 20:11:00.484091: step 80030, total loss = 0.57, batch loss = 0.30 (349.8 examples/sec; 0.023 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:11:00.907876: step 80040, total loss = 0.63, batch loss = 0.36 (354.5 examples/sec; 0.023 sec/batch; 0h:44m:56s remains)
INFO - root - 2022-02-24 20:11:01.411381: step 80050, total loss = 0.60, batch loss = 0.33 (54.9 examples/sec; 0.146 sec/batch; 4h:49m:53s remains)
INFO - root - 2022-02-24 20:11:01.780237: step 80060, total loss = 0.57, batch loss = 0.30 (196.3 examples/sec; 0.041 sec/batch; 1h:21m:06s remains)
INFO - root - 2022-02-24 20:11:02.059047: step 80070, total loss = 0.55, batch loss = 0.28 (284.5 examples/sec; 0.028 sec/batch; 0h:55m:57s remains)
INFO - root - 2022-02-24 20:11:02.377084: step 80080, total loss = 0.44, batch loss = 0.17 (349.9 examples/sec; 0.023 sec/batch; 0h:45m:30s remains)
INFO - root - 2022-02-24 20:11:02.795927: step 80090, total loss = 0.46, batch loss = 0.19 (87.8 examples/sec; 0.091 sec/batch; 3h:01m:21s remains)
INFO - root - 2022-02-24 20:11:03.194082: step 80100, total loss = 0.53, batch loss = 0.27 (115.0 examples/sec; 0.070 sec/batch; 2h:18m:29s remains)
INFO - root - 2022-02-24 20:11:03.571227: step 80110, total loss = 0.53, batch loss = 0.26 (342.1 examples/sec; 0.023 sec/batch; 0h:46m:31s remains)
INFO - root - 2022-02-24 20:11:03.839118: step 80120, total loss = 0.61, batch loss = 0.34 (299.6 examples/sec; 0.027 sec/batch; 0h:53m:07s remains)
INFO - root - 2022-02-24 20:11:04.191967: step 80130, total loss = 0.63, batch loss = 0.36 (196.0 examples/sec; 0.041 sec/batch; 1h:21m:11s remains)
INFO - root - 2022-02-24 20:11:04.507083: step 80140, total loss = 0.60, batch loss = 0.34 (326.7 examples/sec; 0.024 sec/batch; 0h:48m:42s remains)
INFO - root - 2022-02-24 20:11:04.965229: step 80150, total loss = 0.58, batch loss = 0.32 (138.3 examples/sec; 0.058 sec/batch; 1h:55m:02s remains)
INFO - root - 2022-02-24 20:11:05.343489: step 80160, total loss = 0.62, batch loss = 0.35 (185.2 examples/sec; 0.043 sec/batch; 1h:25m:55s remains)
INFO - root - 2022-02-24 20:11:05.730544: step 80170, total loss = 0.51, batch loss = 0.24 (232.0 examples/sec; 0.034 sec/batch; 1h:08m:35s remains)
INFO - root - 2022-02-24 20:11:06.009292: step 80180, total loss = 0.51, batch loss = 0.24 (343.6 examples/sec; 0.023 sec/batch; 0h:46m:17s remains)
INFO - root - 2022-02-24 20:11:06.303857: step 80190, total loss = 0.62, batch loss = 0.35 (324.0 examples/sec; 0.025 sec/batch; 0h:49m:06s remains)
INFO - root - 2022-02-24 20:11:06.628736: step 80200, total loss = 0.63, batch loss = 0.36 (323.7 examples/sec; 0.025 sec/batch; 0h:49m:08s remains)
INFO - root - 2022-02-24 20:11:07.094410: step 80210, total loss = 0.62, batch loss = 0.35 (253.1 examples/sec; 0.032 sec/batch; 1h:02m:50s remains)
INFO - root - 2022-02-24 20:11:07.445409: step 80220, total loss = 0.56, batch loss = 0.29 (312.0 examples/sec; 0.026 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:11:07.711334: step 80230, total loss = 0.52, batch loss = 0.25 (325.0 examples/sec; 0.025 sec/batch; 0h:48m:55s remains)
INFO - root - 2022-02-24 20:11:08.032934: step 80240, total loss = 0.60, batch loss = 0.33 (145.4 examples/sec; 0.055 sec/batch; 1h:49m:21s remains)
INFO - root - 2022-02-24 20:11:08.357955: step 80250, total loss = 0.64, batch loss = 0.37 (344.1 examples/sec; 0.023 sec/batch; 0h:46m:12s remains)
INFO - root - 2022-02-24 20:11:08.686050: step 80260, total loss = 0.48, batch loss = 0.21 (218.4 examples/sec; 0.037 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 20:11:09.132646: step 80270, total loss = 0.62, batch loss = 0.35 (237.4 examples/sec; 0.034 sec/batch; 1h:06m:57s remains)
INFO - root - 2022-02-24 20:11:09.518604: step 80280, total loss = 0.51, batch loss = 0.25 (330.0 examples/sec; 0.024 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:11:09.844475: step 80290, total loss = 0.57, batch loss = 0.30 (210.3 examples/sec; 0.038 sec/batch; 1h:15m:35s remains)
INFO - root - 2022-02-24 20:11:10.147937: step 80300, total loss = 0.59, batch loss = 0.33 (341.4 examples/sec; 0.023 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:11:10.538390: step 80310, total loss = 0.48, batch loss = 0.22 (148.6 examples/sec; 0.054 sec/batch; 1h:46m:57s remains)
INFO - root - 2022-02-24 20:11:11.020324: step 80320, total loss = 0.70, batch loss = 0.43 (309.0 examples/sec; 0.026 sec/batch; 0h:51m:25s remains)
INFO - root - 2022-02-24 20:11:11.353975: step 80330, total loss = 0.56, batch loss = 0.30 (302.5 examples/sec; 0.026 sec/batch; 0h:52m:32s remains)
INFO - root - 2022-02-24 20:11:11.677694: step 80340, total loss = 0.55, batch loss = 0.28 (331.3 examples/sec; 0.024 sec/batch; 0h:47m:57s remains)
INFO - root - 2022-02-24 20:11:12.002064: step 80350, total loss = 0.51, batch loss = 0.24 (133.3 examples/sec; 0.060 sec/batch; 1h:59m:13s remains)
INFO - root - 2022-02-24 20:11:12.318802: step 80360, total loss = 0.55, batch loss = 0.28 (325.6 examples/sec; 0.025 sec/batch; 0h:48m:47s remains)
INFO - root - 2022-02-24 20:11:12.628975: step 80370, total loss = 0.57, batch loss = 0.31 (239.3 examples/sec; 0.033 sec/batch; 1h:06m:23s remains)
INFO - root - 2022-02-24 20:11:13.032843: step 80380, total loss = 0.52, batch loss = 0.25 (214.5 examples/sec; 0.037 sec/batch; 1h:14m:02s remains)
INFO - root - 2022-02-24 20:11:13.486377: step 80390, total loss = 0.62, batch loss = 0.35 (277.6 examples/sec; 0.029 sec/batch; 0h:57m:12s remains)
INFO - root - 2022-02-24 20:11:13.816388: step 80400, total loss = 0.60, batch loss = 0.33 (301.6 examples/sec; 0.027 sec/batch; 0h:52m:38s remains)
INFO - root - 2022-02-24 20:11:14.214224: step 80410, total loss = 0.52, batch loss = 0.25 (303.8 examples/sec; 0.026 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:11:14.575001: step 80420, total loss = 0.64, batch loss = 0.38 (349.7 examples/sec; 0.023 sec/batch; 0h:45m:23s remains)
INFO - root - 2022-02-24 20:11:14.925651: step 80430, total loss = 0.63, batch loss = 0.36 (279.2 examples/sec; 0.029 sec/batch; 0h:56m:52s remains)
INFO - root - 2022-02-24 20:11:15.349891: step 80440, total loss = 0.61, batch loss = 0.34 (326.6 examples/sec; 0.024 sec/batch; 0h:48m:36s remains)
INFO - root - 2022-02-24 20:11:15.746459: step 80450, total loss = 0.54, batch loss = 0.27 (346.8 examples/sec; 0.023 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:11:16.059770: step 80460, total loss = 0.64, batch loss = 0.37 (299.3 examples/sec; 0.027 sec/batch; 0h:53m:01s remains)
INFO - root - 2022-02-24 20:11:16.354832: step 80470, total loss = 0.51, batch loss = 0.24 (303.1 examples/sec; 0.026 sec/batch; 0h:52m:21s remains)
INFO - root - 2022-02-24 20:11:16.620497: step 80480, total loss = 0.58, batch loss = 0.32 (195.2 examples/sec; 0.041 sec/batch; 1h:21m:17s remains)
INFO - root - 2022-02-24 20:11:17.024192: step 80490, total loss = 0.56, batch loss = 0.29 (181.2 examples/sec; 0.044 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 20:11:17.454299: step 80500, total loss = 0.52, batch loss = 0.26 (147.0 examples/sec; 0.054 sec/batch; 1h:47m:58s remains)
INFO - root - 2022-02-24 20:11:18.260981: step 80510, total loss = 0.59, batch loss = 0.32 (89.2 examples/sec; 0.090 sec/batch; 2h:57m:53s remains)
INFO - root - 2022-02-24 20:11:19.206722: step 80520, total loss = 0.53, batch loss = 0.26 (110.0 examples/sec; 0.073 sec/batch; 2h:24m:14s remains)
INFO - root - 2022-02-24 20:11:19.638471: step 80530, total loss = 0.59, batch loss = 0.32 (265.4 examples/sec; 0.030 sec/batch; 0h:59m:46s remains)
INFO - root - 2022-02-24 20:11:19.934965: step 80540, total loss = 0.59, batch loss = 0.32 (377.8 examples/sec; 0.021 sec/batch; 0h:41m:59s remains)
INFO - root - 2022-02-24 20:11:20.173802: step 80550, total loss = 0.57, batch loss = 0.31 (345.3 examples/sec; 0.023 sec/batch; 0h:45m:56s remains)
INFO - root - 2022-02-24 20:11:20.531993: step 80560, total loss = 0.62, batch loss = 0.35 (161.0 examples/sec; 0.050 sec/batch; 1h:38m:29s remains)
INFO - root - 2022-02-24 20:11:20.910501: step 80570, total loss = 0.53, batch loss = 0.26 (294.5 examples/sec; 0.027 sec/batch; 0h:53m:50s remains)
INFO - root - 2022-02-24 20:11:21.354357: step 80580, total loss = 0.54, batch loss = 0.28 (210.7 examples/sec; 0.038 sec/batch; 1h:15m:16s remains)
INFO - root - 2022-02-24 20:11:21.765859: step 80590, total loss = 0.57, batch loss = 0.30 (375.9 examples/sec; 0.021 sec/batch; 0h:42m:10s remains)
INFO - root - 2022-02-24 20:11:22.128445: step 80600, total loss = 0.50, batch loss = 0.23 (164.8 examples/sec; 0.049 sec/batch; 1h:36m:10s remains)
INFO - root - 2022-02-24 20:11:22.536514: step 80610, total loss = 0.53, batch loss = 0.26 (321.8 examples/sec; 0.025 sec/batch; 0h:49m:15s remains)
INFO - root - 2022-02-24 20:11:22.862287: step 80620, total loss = 0.54, batch loss = 0.28 (257.5 examples/sec; 0.031 sec/batch; 1h:01m:32s remains)
INFO - root - 2022-02-24 20:11:23.311743: step 80630, total loss = 0.55, batch loss = 0.28 (150.7 examples/sec; 0.053 sec/batch; 1h:45m:11s remains)
INFO - root - 2022-02-24 20:11:23.937175: step 80640, total loss = 0.56, batch loss = 0.30 (173.8 examples/sec; 0.046 sec/batch; 1h:31m:10s remains)
INFO - root - 2022-02-24 20:11:24.246881: step 80650, total loss = 0.55, batch loss = 0.28 (190.1 examples/sec; 0.042 sec/batch; 1h:23m:20s remains)
INFO - root - 2022-02-24 20:11:24.554922: step 80660, total loss = 0.52, batch loss = 0.25 (267.2 examples/sec; 0.030 sec/batch; 0h:59m:17s remains)
INFO - root - 2022-02-24 20:11:24.927813: step 80670, total loss = 0.57, batch loss = 0.30 (131.2 examples/sec; 0.061 sec/batch; 2h:00m:46s remains)
INFO - root - 2022-02-24 20:11:25.378014: step 80680, total loss = 0.60, batch loss = 0.33 (108.7 examples/sec; 0.074 sec/batch; 2h:25m:48s remains)
INFO - root - 2022-02-24 20:11:25.704194: step 80690, total loss = 0.49, batch loss = 0.22 (249.0 examples/sec; 0.032 sec/batch; 1h:03m:37s remains)
INFO - root - 2022-02-24 20:11:26.059438: step 80700, total loss = 0.59, batch loss = 0.33 (150.0 examples/sec; 0.053 sec/batch; 1h:45m:36s remains)
INFO - root - 2022-02-24 20:11:26.434825: step 80710, total loss = 0.50, batch loss = 0.23 (242.6 examples/sec; 0.033 sec/batch; 1h:05m:16s remains)
INFO - root - 2022-02-24 20:11:26.811486: step 80720, total loss = 0.54, batch loss = 0.27 (338.0 examples/sec; 0.024 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 20:11:27.187130: step 80730, total loss = 0.51, batch loss = 0.24 (344.0 examples/sec; 0.023 sec/batch; 0h:46m:02s remains)
INFO - root - 2022-02-24 20:11:27.588332: step 80740, total loss = 0.59, batch loss = 0.32 (350.3 examples/sec; 0.023 sec/batch; 0h:45m:12s remains)
INFO - root - 2022-02-24 20:11:27.896441: step 80750, total loss = 0.61, batch loss = 0.34 (320.1 examples/sec; 0.025 sec/batch; 0h:49m:28s remains)
INFO - root - 2022-02-24 20:11:28.221420: step 80760, total loss = 0.74, batch loss = 0.47 (330.5 examples/sec; 0.024 sec/batch; 0h:47m:54s remains)
INFO - root - 2022-02-24 20:11:28.558875: step 80770, total loss = 0.52, batch loss = 0.26 (173.7 examples/sec; 0.046 sec/batch; 1h:31m:07s remains)
INFO - root - 2022-02-24 20:11:28.994904: step 80780, total loss = 0.49, batch loss = 0.22 (130.3 examples/sec; 0.061 sec/batch; 2h:01m:29s remains)
INFO - root - 2022-02-24 20:11:29.414614: step 80790, total loss = 0.51, batch loss = 0.24 (290.2 examples/sec; 0.028 sec/batch; 0h:54m:32s remains)
INFO - root - 2022-02-24 20:11:29.803173: step 80800, total loss = 0.47, batch loss = 0.20 (339.0 examples/sec; 0.024 sec/batch; 0h:46m:41s remains)
INFO - root - 2022-02-24 20:11:30.176982: step 80810, total loss = 0.62, batch loss = 0.36 (322.5 examples/sec; 0.025 sec/batch; 0h:49m:03s remains)
INFO - root - 2022-02-24 20:11:30.424665: step 80820, total loss = 0.51, batch loss = 0.24 (282.9 examples/sec; 0.028 sec/batch; 0h:55m:55s remains)
INFO - root - 2022-02-24 20:11:30.858732: step 80830, total loss = 0.59, batch loss = 0.32 (130.6 examples/sec; 0.061 sec/batch; 2h:01m:10s remains)
INFO - root - 2022-02-24 20:11:31.258236: step 80840, total loss = 0.55, batch loss = 0.28 (163.9 examples/sec; 0.049 sec/batch; 1h:36m:31s remains)
INFO - root - 2022-02-24 20:11:31.644090: step 80850, total loss = 0.49, batch loss = 0.22 (327.8 examples/sec; 0.024 sec/batch; 0h:48m:15s remains)
INFO - root - 2022-02-24 20:11:31.954489: step 80860, total loss = 0.60, batch loss = 0.33 (286.9 examples/sec; 0.028 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 20:11:32.270954: step 80870, total loss = 0.56, batch loss = 0.29 (346.3 examples/sec; 0.023 sec/batch; 0h:45m:40s remains)
INFO - root - 2022-02-24 20:11:32.625790: step 80880, total loss = 0.70, batch loss = 0.43 (147.9 examples/sec; 0.054 sec/batch; 1h:46m:57s remains)
INFO - root - 2022-02-24 20:11:32.922357: step 80890, total loss = 0.57, batch loss = 0.30 (325.0 examples/sec; 0.025 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 20:11:33.352694: step 80900, total loss = 0.56, batch loss = 0.30 (208.1 examples/sec; 0.038 sec/batch; 1h:15m:58s remains)
INFO - root - 2022-02-24 20:11:33.853390: step 80910, total loss = 0.57, batch loss = 0.31 (178.3 examples/sec; 0.045 sec/batch; 1h:28m:40s remains)
INFO - root - 2022-02-24 20:11:34.156830: step 80920, total loss = 0.53, batch loss = 0.26 (251.3 examples/sec; 0.032 sec/batch; 1h:02m:55s remains)
INFO - root - 2022-02-24 20:11:34.465563: step 80930, total loss = 0.50, batch loss = 0.24 (332.9 examples/sec; 0.024 sec/batch; 0h:47m:29s remains)
INFO - root - 2022-02-24 20:11:34.773678: step 80940, total loss = 0.70, batch loss = 0.43 (323.4 examples/sec; 0.025 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:11:35.116549: step 80950, total loss = 0.56, batch loss = 0.29 (255.9 examples/sec; 0.031 sec/batch; 1h:01m:46s remains)
INFO - root - 2022-02-24 20:11:35.424816: step 80960, total loss = 0.59, batch loss = 0.32 (217.3 examples/sec; 0.037 sec/batch; 1h:12m:43s remains)
INFO - root - 2022-02-24 20:11:35.871772: step 80970, total loss = 0.63, batch loss = 0.36 (90.3 examples/sec; 0.089 sec/batch; 2h:55m:03s remains)
INFO - root - 2022-02-24 20:11:36.177755: step 80980, total loss = 0.52, batch loss = 0.26 (342.2 examples/sec; 0.023 sec/batch; 0h:46m:10s remains)
INFO - root - 2022-02-24 20:11:36.495077: step 80990, total loss = 0.55, batch loss = 0.28 (303.4 examples/sec; 0.026 sec/batch; 0h:52m:04s remains)
INFO - root - 2022-02-24 20:11:36.869971: step 81000, total loss = 0.63, batch loss = 0.36 (246.4 examples/sec; 0.032 sec/batch; 1h:04m:07s remains)
INFO - root - 2022-02-24 20:11:37.276404: step 81010, total loss = 0.57, batch loss = 0.30 (168.0 examples/sec; 0.048 sec/batch; 1h:34m:03s remains)
INFO - root - 2022-02-24 20:11:37.645120: step 81020, total loss = 0.56, batch loss = 0.29 (130.5 examples/sec; 0.061 sec/batch; 2h:01m:01s remains)
INFO - root - 2022-02-24 20:11:38.046808: step 81030, total loss = 0.57, batch loss = 0.31 (311.3 examples/sec; 0.026 sec/batch; 0h:50m:44s remains)
INFO - root - 2022-02-24 20:11:38.436432: step 81040, total loss = 0.66, batch loss = 0.39 (360.5 examples/sec; 0.022 sec/batch; 0h:43m:48s remains)
INFO - root - 2022-02-24 20:11:38.832523: step 81050, total loss = 0.62, batch loss = 0.35 (226.0 examples/sec; 0.035 sec/batch; 1h:09m:52s remains)
INFO - root - 2022-02-24 20:11:39.099777: step 81060, total loss = 0.48, batch loss = 0.21 (336.5 examples/sec; 0.024 sec/batch; 0h:46m:56s remains)
INFO - root - 2022-02-24 20:11:39.387412: step 81070, total loss = 0.72, batch loss = 0.45 (238.3 examples/sec; 0.034 sec/batch; 1h:06m:16s remains)
INFO - root - 2022-02-24 20:11:39.704116: step 81080, total loss = 0.50, batch loss = 0.23 (136.6 examples/sec; 0.059 sec/batch; 1h:55m:37s remains)
INFO - root - 2022-02-24 20:11:40.070532: step 81090, total loss = 0.60, batch loss = 0.33 (307.1 examples/sec; 0.026 sec/batch; 0h:51m:24s remains)
INFO - root - 2022-02-24 20:11:40.488581: step 81100, total loss = 0.55, batch loss = 0.28 (336.9 examples/sec; 0.024 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 20:11:40.938812: step 81110, total loss = 0.57, batch loss = 0.30 (268.7 examples/sec; 0.030 sec/batch; 0h:58m:45s remains)
INFO - root - 2022-02-24 20:11:41.582281: step 81120, total loss = 0.54, batch loss = 0.27 (252.2 examples/sec; 0.032 sec/batch; 1h:02m:35s remains)
INFO - root - 2022-02-24 20:11:42.077667: step 81130, total loss = 0.60, batch loss = 0.33 (181.1 examples/sec; 0.044 sec/batch; 1h:27m:08s remains)
INFO - root - 2022-02-24 20:11:42.643728: step 81140, total loss = 0.55, batch loss = 0.28 (175.5 examples/sec; 0.046 sec/batch; 1h:29m:55s remains)
INFO - root - 2022-02-24 20:11:43.129128: step 81150, total loss = 0.68, batch loss = 0.42 (264.8 examples/sec; 0.030 sec/batch; 0h:59m:35s remains)
INFO - root - 2022-02-24 20:11:43.624601: step 81160, total loss = 0.69, batch loss = 0.42 (99.0 examples/sec; 0.081 sec/batch; 2h:39m:22s remains)
INFO - root - 2022-02-24 20:11:44.538602: step 81170, total loss = 0.56, batch loss = 0.30 (171.8 examples/sec; 0.047 sec/batch; 1h:31m:49s remains)
INFO - root - 2022-02-24 20:11:45.030878: step 81180, total loss = 0.74, batch loss = 0.47 (131.6 examples/sec; 0.061 sec/batch; 1h:59m:53s remains)
INFO - root - 2022-02-24 20:11:45.390828: step 81190, total loss = 0.48, batch loss = 0.22 (332.9 examples/sec; 0.024 sec/batch; 0h:47m:23s remains)
INFO - root - 2022-02-24 20:11:45.701978: step 81200, total loss = 0.63, batch loss = 0.36 (330.8 examples/sec; 0.024 sec/batch; 0h:47m:41s remains)
INFO - root - 2022-02-24 20:11:46.115306: step 81210, total loss = 0.51, batch loss = 0.24 (266.7 examples/sec; 0.030 sec/batch; 0h:59m:07s remains)
INFO - root - 2022-02-24 20:11:46.387276: step 81220, total loss = 0.58, batch loss = 0.32 (285.5 examples/sec; 0.028 sec/batch; 0h:55m:14s remains)
INFO - root - 2022-02-24 20:11:46.812339: step 81230, total loss = 0.49, batch loss = 0.23 (168.7 examples/sec; 0.047 sec/batch; 1h:33m:29s remains)
INFO - root - 2022-02-24 20:11:47.165275: step 81240, total loss = 0.50, batch loss = 0.24 (264.1 examples/sec; 0.030 sec/batch; 0h:59m:41s remains)
INFO - root - 2022-02-24 20:11:47.482601: step 81250, total loss = 0.55, batch loss = 0.28 (184.6 examples/sec; 0.043 sec/batch; 1h:25m:24s remains)
INFO - root - 2022-02-24 20:11:47.773955: step 81260, total loss = 0.62, batch loss = 0.35 (321.7 examples/sec; 0.025 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 20:11:48.072868: step 81270, total loss = 0.58, batch loss = 0.31 (318.6 examples/sec; 0.025 sec/batch; 0h:49m:28s remains)
INFO - root - 2022-02-24 20:11:48.459640: step 81280, total loss = 0.72, batch loss = 0.45 (120.7 examples/sec; 0.066 sec/batch; 2h:10m:32s remains)
INFO - root - 2022-02-24 20:11:48.859023: step 81290, total loss = 0.60, batch loss = 0.33 (253.2 examples/sec; 0.032 sec/batch; 1h:02m:14s remains)
INFO - root - 2022-02-24 20:11:49.401804: step 81300, total loss = 0.62, batch loss = 0.36 (159.1 examples/sec; 0.050 sec/batch; 1h:39m:01s remains)
INFO - root - 2022-02-24 20:11:49.841817: step 81310, total loss = 0.74, batch loss = 0.47 (193.7 examples/sec; 0.041 sec/batch; 1h:21m:21s remains)
INFO - root - 2022-02-24 20:11:50.139859: step 81320, total loss = 0.53, batch loss = 0.26 (319.5 examples/sec; 0.025 sec/batch; 0h:49m:19s remains)
INFO - root - 2022-02-24 20:11:50.446413: step 81330, total loss = 0.64, batch loss = 0.37 (179.2 examples/sec; 0.045 sec/batch; 1h:27m:56s remains)
INFO - root - 2022-02-24 20:11:50.862591: step 81340, total loss = 0.54, batch loss = 0.28 (324.6 examples/sec; 0.025 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:11:51.170668: step 81350, total loss = 0.58, batch loss = 0.32 (321.1 examples/sec; 0.025 sec/batch; 0h:49m:03s remains)
INFO - root - 2022-02-24 20:11:51.525040: step 81360, total loss = 0.54, batch loss = 0.27 (251.1 examples/sec; 0.032 sec/batch; 1h:02m:43s remains)
INFO - root - 2022-02-24 20:11:51.827213: step 81370, total loss = 0.58, batch loss = 0.31 (268.8 examples/sec; 0.030 sec/batch; 0h:58m:35s remains)
INFO - root - 2022-02-24 20:11:52.133870: step 81380, total loss = 0.61, batch loss = 0.34 (332.5 examples/sec; 0.024 sec/batch; 0h:47m:22s remains)
INFO - root - 2022-02-24 20:11:52.494369: step 81390, total loss = 0.58, batch loss = 0.31 (357.5 examples/sec; 0.022 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:11:52.944540: step 81400, total loss = 0.68, batch loss = 0.41 (332.7 examples/sec; 0.024 sec/batch; 0h:47m:19s remains)
INFO - root - 2022-02-24 20:11:53.415142: step 81410, total loss = 0.52, batch loss = 0.26 (346.9 examples/sec; 0.023 sec/batch; 0h:45m:23s remains)
INFO - root - 2022-02-24 20:11:53.708050: step 81420, total loss = 0.57, batch loss = 0.30 (248.7 examples/sec; 0.032 sec/batch; 1h:03m:18s remains)
INFO - root - 2022-02-24 20:11:53.973740: step 81430, total loss = 0.65, batch loss = 0.38 (388.8 examples/sec; 0.021 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:11:54.256350: step 81440, total loss = 0.51, batch loss = 0.24 (326.4 examples/sec; 0.025 sec/batch; 0h:48m:13s remains)
INFO - root - 2022-02-24 20:11:54.633355: step 81450, total loss = 0.50, batch loss = 0.23 (225.6 examples/sec; 0.035 sec/batch; 1h:09m:46s remains)
INFO - root - 2022-02-24 20:11:55.058756: step 81460, total loss = 0.55, batch loss = 0.28 (345.5 examples/sec; 0.023 sec/batch; 0h:45m:33s remains)
INFO - root - 2022-02-24 20:11:55.407529: step 81470, total loss = 0.56, batch loss = 0.29 (195.9 examples/sec; 0.041 sec/batch; 1h:20m:19s remains)
INFO - root - 2022-02-24 20:11:55.727532: step 81480, total loss = 0.50, batch loss = 0.23 (367.0 examples/sec; 0.022 sec/batch; 0h:42m:52s remains)
INFO - root - 2022-02-24 20:11:56.009134: step 81490, total loss = 0.57, batch loss = 0.31 (317.7 examples/sec; 0.025 sec/batch; 0h:49m:31s remains)
INFO - root - 2022-02-24 20:11:56.285248: step 81500, total loss = 0.57, batch loss = 0.30 (309.8 examples/sec; 0.026 sec/batch; 0h:50m:46s remains)
INFO - root - 2022-02-24 20:11:56.752633: step 81510, total loss = 0.53, batch loss = 0.26 (163.0 examples/sec; 0.049 sec/batch; 1h:36m:31s remains)
INFO - root - 2022-02-24 20:11:57.112214: step 81520, total loss = 0.52, batch loss = 0.25 (151.2 examples/sec; 0.053 sec/batch; 1h:44m:00s remains)
INFO - root - 2022-02-24 20:11:57.359337: step 81530, total loss = 0.58, batch loss = 0.31 (324.8 examples/sec; 0.025 sec/batch; 0h:48m:25s remains)
INFO - root - 2022-02-24 20:11:57.647115: step 81540, total loss = 0.62, batch loss = 0.36 (241.9 examples/sec; 0.033 sec/batch; 1h:05m:00s remains)
INFO - root - 2022-02-24 20:11:57.959037: step 81550, total loss = 0.71, batch loss = 0.44 (216.4 examples/sec; 0.037 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 20:11:58.264087: step 81560, total loss = 0.56, batch loss = 0.29 (190.8 examples/sec; 0.042 sec/batch; 1h:22m:23s remains)
INFO - root - 2022-02-24 20:11:58.787432: step 81570, total loss = 0.56, batch loss = 0.29 (114.1 examples/sec; 0.070 sec/batch; 2h:17m:44s remains)
INFO - root - 2022-02-24 20:11:59.206944: step 81580, total loss = 0.56, batch loss = 0.30 (129.6 examples/sec; 0.062 sec/batch; 2h:01m:18s remains)
INFO - root - 2022-02-24 20:11:59.562968: step 81590, total loss = 0.63, batch loss = 0.36 (344.0 examples/sec; 0.023 sec/batch; 0h:45m:42s remains)
INFO - root - 2022-02-24 20:11:59.888628: step 81600, total loss = 0.69, batch loss = 0.42 (239.5 examples/sec; 0.033 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:12:00.264729: step 81610, total loss = 0.59, batch loss = 0.32 (250.3 examples/sec; 0.032 sec/batch; 1h:02m:47s remains)
INFO - root - 2022-02-24 20:12:00.724218: step 81620, total loss = 0.50, batch loss = 0.24 (306.4 examples/sec; 0.026 sec/batch; 0h:51m:17s remains)
INFO - root - 2022-02-24 20:12:01.057983: step 81630, total loss = 0.56, batch loss = 0.29 (302.4 examples/sec; 0.026 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 20:12:01.414887: step 81640, total loss = 0.57, batch loss = 0.30 (217.9 examples/sec; 0.037 sec/batch; 1h:12m:07s remains)
INFO - root - 2022-02-24 20:12:01.690287: step 81650, total loss = 0.60, batch loss = 0.34 (319.0 examples/sec; 0.025 sec/batch; 0h:49m:15s remains)
INFO - root - 2022-02-24 20:12:02.016089: step 81660, total loss = 0.53, batch loss = 0.26 (372.9 examples/sec; 0.021 sec/batch; 0h:42m:08s remains)
INFO - root - 2022-02-24 20:12:02.335359: step 81670, total loss = 0.51, batch loss = 0.24 (218.1 examples/sec; 0.037 sec/batch; 1h:12m:01s remains)
INFO - root - 2022-02-24 20:12:02.732888: step 81680, total loss = 0.64, batch loss = 0.37 (243.6 examples/sec; 0.033 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 20:12:03.130271: step 81690, total loss = 0.56, batch loss = 0.29 (212.5 examples/sec; 0.038 sec/batch; 1h:13m:56s remains)
INFO - root - 2022-02-24 20:12:03.456899: step 81700, total loss = 0.50, batch loss = 0.23 (193.3 examples/sec; 0.041 sec/batch; 1h:21m:16s remains)
INFO - root - 2022-02-24 20:12:03.773265: step 81710, total loss = 0.55, batch loss = 0.29 (325.6 examples/sec; 0.025 sec/batch; 0h:48m:13s remains)
INFO - root - 2022-02-24 20:12:04.034124: step 81720, total loss = 0.61, batch loss = 0.34 (234.3 examples/sec; 0.034 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 20:12:04.368823: step 81730, total loss = 0.59, batch loss = 0.33 (227.9 examples/sec; 0.035 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 20:12:05.085494: step 81740, total loss = 0.60, batch loss = 0.33 (364.5 examples/sec; 0.022 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:12:05.507593: step 81750, total loss = 0.52, batch loss = 0.25 (365.0 examples/sec; 0.022 sec/batch; 0h:43m:00s remains)
INFO - root - 2022-02-24 20:12:05.910147: step 81760, total loss = 0.52, batch loss = 0.25 (201.3 examples/sec; 0.040 sec/batch; 1h:17m:59s remains)
INFO - root - 2022-02-24 20:12:06.188130: step 81770, total loss = 0.47, batch loss = 0.21 (237.2 examples/sec; 0.034 sec/batch; 1h:06m:11s remains)
INFO - root - 2022-02-24 20:12:06.483350: step 81780, total loss = 0.57, batch loss = 0.30 (263.3 examples/sec; 0.030 sec/batch; 0h:59m:37s remains)
INFO - root - 2022-02-24 20:12:06.982410: step 81790, total loss = 0.60, batch loss = 0.33 (323.9 examples/sec; 0.025 sec/batch; 0h:48m:27s remains)
INFO - root - 2022-02-24 20:12:07.388942: step 81800, total loss = 0.49, batch loss = 0.22 (187.6 examples/sec; 0.043 sec/batch; 1h:23m:39s remains)
INFO - root - 2022-02-24 20:12:07.949527: step 81810, total loss = 0.54, batch loss = 0.28 (83.9 examples/sec; 0.095 sec/batch; 3h:06m:55s remains)
INFO - root - 2022-02-24 20:12:08.390751: step 81820, total loss = 0.61, batch loss = 0.34 (121.7 examples/sec; 0.066 sec/batch; 2h:08m:56s remains)
INFO - root - 2022-02-24 20:12:08.764358: step 81830, total loss = 0.72, batch loss = 0.45 (142.1 examples/sec; 0.056 sec/batch; 1h:50m:24s remains)
INFO - root - 2022-02-24 20:12:09.195376: step 81840, total loss = 0.53, batch loss = 0.26 (113.2 examples/sec; 0.071 sec/batch; 2h:18m:35s remains)
INFO - root - 2022-02-24 20:12:09.671131: step 81850, total loss = 0.68, batch loss = 0.41 (189.1 examples/sec; 0.042 sec/batch; 1h:22m:56s remains)
INFO - root - 2022-02-24 20:12:09.951984: step 81860, total loss = 0.63, batch loss = 0.36 (326.5 examples/sec; 0.025 sec/batch; 0h:48m:02s remains)
INFO - root - 2022-02-24 20:12:10.695773: step 81870, total loss = 0.57, batch loss = 0.30 (301.7 examples/sec; 0.027 sec/batch; 0h:51m:58s remains)
INFO - root - 2022-02-24 20:12:10.960989: step 81880, total loss = 0.50, batch loss = 0.24 (215.2 examples/sec; 0.037 sec/batch; 1h:12m:52s remains)
INFO - root - 2022-02-24 20:12:11.374116: step 81890, total loss = 0.54, batch loss = 0.27 (179.6 examples/sec; 0.045 sec/batch; 1h:27m:19s remains)
INFO - root - 2022-02-24 20:12:11.725862: step 81900, total loss = 0.55, batch loss = 0.28 (204.0 examples/sec; 0.039 sec/batch; 1h:16m:52s remains)
INFO - root - 2022-02-24 20:12:12.069873: step 81910, total loss = 0.56, batch loss = 0.29 (342.2 examples/sec; 0.023 sec/batch; 0h:45m:48s remains)
INFO - root - 2022-02-24 20:12:12.382549: step 81920, total loss = 0.63, batch loss = 0.37 (382.6 examples/sec; 0.021 sec/batch; 0h:40m:58s remains)
INFO - root - 2022-02-24 20:12:12.750353: step 81930, total loss = 0.62, batch loss = 0.36 (120.1 examples/sec; 0.067 sec/batch; 2h:10m:30s remains)
INFO - root - 2022-02-24 20:12:13.093959: step 81940, total loss = 0.71, batch loss = 0.44 (176.6 examples/sec; 0.045 sec/batch; 1h:28m:45s remains)
INFO - root - 2022-02-24 20:12:13.602832: step 81950, total loss = 0.59, batch loss = 0.32 (143.4 examples/sec; 0.056 sec/batch; 1h:49m:16s remains)
INFO - root - 2022-02-24 20:12:13.937972: step 81960, total loss = 0.54, batch loss = 0.27 (168.7 examples/sec; 0.047 sec/batch; 1h:32m:55s remains)
INFO - root - 2022-02-24 20:12:14.225185: step 81970, total loss = 0.61, batch loss = 0.34 (148.7 examples/sec; 0.054 sec/batch; 1h:45m:23s remains)
INFO - root - 2022-02-24 20:12:14.529333: step 81980, total loss = 0.58, batch loss = 0.31 (292.2 examples/sec; 0.027 sec/batch; 0h:53m:37s remains)
INFO - root - 2022-02-24 20:12:14.853636: step 81990, total loss = 0.59, batch loss = 0.32 (353.0 examples/sec; 0.023 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:12:15.191690: step 82000, total loss = 0.48, batch loss = 0.22 (178.5 examples/sec; 0.045 sec/batch; 1h:27m:46s remains)
INFO - root - 2022-02-24 20:12:15.671300: step 82010, total loss = 0.50, batch loss = 0.23 (215.7 examples/sec; 0.037 sec/batch; 1h:12m:37s remains)
INFO - root - 2022-02-24 20:12:16.067094: step 82020, total loss = 0.56, batch loss = 0.30 (309.3 examples/sec; 0.026 sec/batch; 0h:50m:38s remains)
INFO - root - 2022-02-24 20:12:16.371286: step 82030, total loss = 0.55, batch loss = 0.28 (106.3 examples/sec; 0.075 sec/batch; 2h:27m:19s remains)
INFO - root - 2022-02-24 20:12:16.625414: step 82040, total loss = 0.52, batch loss = 0.25 (210.9 examples/sec; 0.038 sec/batch; 1h:14m:15s remains)
INFO - root - 2022-02-24 20:12:16.989641: step 82050, total loss = 0.54, batch loss = 0.28 (131.6 examples/sec; 0.061 sec/batch; 1h:59m:01s remains)
INFO - root - 2022-02-24 20:12:17.317345: step 82060, total loss = 0.57, batch loss = 0.31 (314.1 examples/sec; 0.025 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:12:17.749768: step 82070, total loss = 0.57, batch loss = 0.30 (95.7 examples/sec; 0.084 sec/batch; 2h:43m:41s remains)
INFO - root - 2022-02-24 20:12:18.066302: step 82080, total loss = 0.59, batch loss = 0.32 (352.7 examples/sec; 0.023 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:12:18.375803: step 82090, total loss = 0.60, batch loss = 0.34 (148.8 examples/sec; 0.054 sec/batch; 1h:45m:10s remains)
INFO - root - 2022-02-24 20:12:18.698059: step 82100, total loss = 0.48, batch loss = 0.22 (355.4 examples/sec; 0.023 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:12:19.077776: step 82110, total loss = 0.59, batch loss = 0.32 (178.3 examples/sec; 0.045 sec/batch; 1h:27m:47s remains)
INFO - root - 2022-02-24 20:12:19.563006: step 82120, total loss = 0.54, batch loss = 0.28 (83.6 examples/sec; 0.096 sec/batch; 3h:07m:16s remains)
INFO - root - 2022-02-24 20:12:19.956084: step 82130, total loss = 0.65, batch loss = 0.38 (243.0 examples/sec; 0.033 sec/batch; 1h:04m:24s remains)
INFO - root - 2022-02-24 20:12:20.244484: step 82140, total loss = 0.48, batch loss = 0.22 (362.3 examples/sec; 0.022 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:12:20.527876: step 82150, total loss = 0.59, batch loss = 0.33 (319.0 examples/sec; 0.025 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:12:20.878355: step 82160, total loss = 0.57, batch loss = 0.30 (203.3 examples/sec; 0.039 sec/batch; 1h:16m:57s remains)
INFO - root - 2022-02-24 20:12:21.240734: step 82170, total loss = 0.49, batch loss = 0.22 (269.0 examples/sec; 0.030 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 20:12:21.665853: step 82180, total loss = 0.53, batch loss = 0.26 (111.1 examples/sec; 0.072 sec/batch; 2h:20m:46s remains)
INFO - root - 2022-02-24 20:12:21.998938: step 82190, total loss = 0.70, batch loss = 0.43 (226.8 examples/sec; 0.035 sec/batch; 1h:08m:57s remains)
INFO - root - 2022-02-24 20:12:22.344670: step 82200, total loss = 0.73, batch loss = 0.46 (215.8 examples/sec; 0.037 sec/batch; 1h:12m:28s remains)
INFO - root - 2022-02-24 20:12:22.716212: step 82210, total loss = 0.62, batch loss = 0.35 (363.4 examples/sec; 0.022 sec/batch; 0h:43m:01s remains)
INFO - root - 2022-02-24 20:12:23.024094: step 82220, total loss = 0.58, batch loss = 0.32 (338.6 examples/sec; 0.024 sec/batch; 0h:46m:10s remains)
INFO - root - 2022-02-24 20:12:23.422820: step 82230, total loss = 0.52, batch loss = 0.25 (141.8 examples/sec; 0.056 sec/batch; 1h:50m:16s remains)
INFO - root - 2022-02-24 20:12:23.828987: step 82240, total loss = 0.53, batch loss = 0.26 (352.1 examples/sec; 0.023 sec/batch; 0h:44m:24s remains)
INFO - root - 2022-02-24 20:12:24.164424: step 82250, total loss = 0.55, batch loss = 0.28 (217.6 examples/sec; 0.037 sec/batch; 1h:11m:50s remains)
INFO - root - 2022-02-24 20:12:24.487459: step 82260, total loss = 0.55, batch loss = 0.28 (357.5 examples/sec; 0.022 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:12:24.793045: step 82270, total loss = 0.52, batch loss = 0.25 (192.9 examples/sec; 0.041 sec/batch; 1h:21m:02s remains)
INFO - root - 2022-02-24 20:12:25.173409: step 82280, total loss = 0.58, batch loss = 0.31 (110.7 examples/sec; 0.072 sec/batch; 2h:21m:13s remains)
INFO - root - 2022-02-24 20:12:25.635029: step 82290, total loss = 0.52, batch loss = 0.25 (359.7 examples/sec; 0.022 sec/batch; 0h:43m:27s remains)
INFO - root - 2022-02-24 20:12:25.952722: step 82300, total loss = 0.52, batch loss = 0.25 (324.6 examples/sec; 0.025 sec/batch; 0h:48m:08s remains)
INFO - root - 2022-02-24 20:12:26.432364: step 82310, total loss = 0.47, batch loss = 0.20 (341.9 examples/sec; 0.023 sec/batch; 0h:45m:42s remains)
INFO - root - 2022-02-24 20:12:26.719256: step 82320, total loss = 0.61, batch loss = 0.35 (115.4 examples/sec; 0.069 sec/batch; 2h:15m:26s remains)
INFO - root - 2022-02-24 20:12:27.060421: step 82330, total loss = 0.60, batch loss = 0.33 (334.0 examples/sec; 0.024 sec/batch; 0h:46m:46s remains)
INFO - root - 2022-02-24 20:12:27.525597: step 82340, total loss = 0.53, batch loss = 0.26 (180.4 examples/sec; 0.044 sec/batch; 1h:26m:34s remains)
INFO - root - 2022-02-24 20:12:27.795593: step 82350, total loss = 0.53, batch loss = 0.26 (336.5 examples/sec; 0.024 sec/batch; 0h:46m:25s remains)
INFO - root - 2022-02-24 20:12:28.076926: step 82360, total loss = 0.52, batch loss = 0.26 (342.7 examples/sec; 0.023 sec/batch; 0h:45m:34s remains)
INFO - root - 2022-02-24 20:12:28.341103: step 82370, total loss = 0.65, batch loss = 0.38 (314.0 examples/sec; 0.025 sec/batch; 0h:49m:43s remains)
INFO - root - 2022-02-24 20:12:28.706310: step 82380, total loss = 0.66, batch loss = 0.39 (360.0 examples/sec; 0.022 sec/batch; 0h:43m:22s remains)
INFO - root - 2022-02-24 20:12:29.150184: step 82390, total loss = 0.57, batch loss = 0.30 (124.0 examples/sec; 0.065 sec/batch; 2h:05m:55s remains)
INFO - root - 2022-02-24 20:12:29.739810: step 82400, total loss = 0.47, batch loss = 0.20 (85.7 examples/sec; 0.093 sec/batch; 3h:02m:11s remains)
INFO - root - 2022-02-24 20:12:30.162169: step 82410, total loss = 0.66, batch loss = 0.39 (88.2 examples/sec; 0.091 sec/batch; 2h:57m:02s remains)
INFO - root - 2022-02-24 20:12:31.219477: step 82420, total loss = 0.55, batch loss = 0.28 (283.5 examples/sec; 0.028 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:12:31.578587: step 82430, total loss = 0.49, batch loss = 0.22 (245.7 examples/sec; 0.033 sec/batch; 1h:03m:32s remains)
INFO - root - 2022-02-24 20:12:31.973521: step 82440, total loss = 0.67, batch loss = 0.40 (302.2 examples/sec; 0.026 sec/batch; 0h:51m:38s remains)
INFO - root - 2022-02-24 20:12:32.335888: step 82450, total loss = 0.53, batch loss = 0.26 (329.3 examples/sec; 0.024 sec/batch; 0h:47m:23s remains)
INFO - root - 2022-02-24 20:12:32.689642: step 82460, total loss = 0.67, batch loss = 0.40 (184.4 examples/sec; 0.043 sec/batch; 1h:24m:37s remains)
INFO - root - 2022-02-24 20:12:33.022438: step 82470, total loss = 0.61, batch loss = 0.34 (187.5 examples/sec; 0.043 sec/batch; 1h:23m:12s remains)
INFO - root - 2022-02-24 20:12:33.410090: step 82480, total loss = 0.69, batch loss = 0.43 (241.0 examples/sec; 0.033 sec/batch; 1h:04m:44s remains)
INFO - root - 2022-02-24 20:12:33.842924: step 82490, total loss = 0.52, batch loss = 0.25 (264.8 examples/sec; 0.030 sec/batch; 0h:58m:54s remains)
INFO - root - 2022-02-24 20:12:34.158059: step 82500, total loss = 0.61, batch loss = 0.34 (331.3 examples/sec; 0.024 sec/batch; 0h:47m:05s remains)
INFO - root - 2022-02-24 20:12:34.614823: step 82510, total loss = 0.62, batch loss = 0.35 (339.0 examples/sec; 0.024 sec/batch; 0h:46m:00s remains)
INFO - root - 2022-02-24 20:12:34.973701: step 82520, total loss = 0.59, batch loss = 0.33 (300.2 examples/sec; 0.027 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 20:12:35.371990: step 82530, total loss = 0.65, batch loss = 0.39 (151.3 examples/sec; 0.053 sec/batch; 1h:43m:06s remains)
INFO - root - 2022-02-24 20:12:35.743871: step 82540, total loss = 0.56, batch loss = 0.29 (176.2 examples/sec; 0.045 sec/batch; 1h:28m:30s remains)
INFO - root - 2022-02-24 20:12:36.107289: step 82550, total loss = 0.55, batch loss = 0.28 (305.9 examples/sec; 0.026 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:12:36.591103: step 82560, total loss = 0.70, batch loss = 0.43 (233.0 examples/sec; 0.034 sec/batch; 1h:06m:54s remains)
INFO - root - 2022-02-24 20:12:36.947122: step 82570, total loss = 0.66, batch loss = 0.39 (304.1 examples/sec; 0.026 sec/batch; 0h:51m:16s remains)
INFO - root - 2022-02-24 20:12:37.280123: step 82580, total loss = 0.68, batch loss = 0.41 (353.7 examples/sec; 0.023 sec/batch; 0h:44m:04s remains)
INFO - root - 2022-02-24 20:12:37.700111: step 82590, total loss = 0.53, batch loss = 0.26 (174.8 examples/sec; 0.046 sec/batch; 1h:29m:10s remains)
INFO - root - 2022-02-24 20:12:38.040412: step 82600, total loss = 0.52, batch loss = 0.25 (360.8 examples/sec; 0.022 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:12:38.428402: step 82610, total loss = 0.48, batch loss = 0.21 (324.1 examples/sec; 0.025 sec/batch; 0h:48m:05s remains)
INFO - root - 2022-02-24 20:12:38.775919: step 82620, total loss = 0.51, batch loss = 0.24 (304.2 examples/sec; 0.026 sec/batch; 0h:51m:13s remains)
INFO - root - 2022-02-24 20:12:39.177363: step 82630, total loss = 0.51, batch loss = 0.24 (335.0 examples/sec; 0.024 sec/batch; 0h:46m:30s remains)
INFO - root - 2022-02-24 20:12:39.615065: step 82640, total loss = 0.60, batch loss = 0.33 (203.9 examples/sec; 0.039 sec/batch; 1h:16m:25s remains)
INFO - root - 2022-02-24 20:12:39.948500: step 82650, total loss = 0.56, batch loss = 0.29 (181.1 examples/sec; 0.044 sec/batch; 1h:26m:00s remains)
INFO - root - 2022-02-24 20:12:40.278381: step 82660, total loss = 0.49, batch loss = 0.22 (202.4 examples/sec; 0.040 sec/batch; 1h:16m:58s remains)
INFO - root - 2022-02-24 20:12:40.571061: step 82670, total loss = 0.59, batch loss = 0.32 (318.4 examples/sec; 0.025 sec/batch; 0h:48m:54s remains)
INFO - root - 2022-02-24 20:12:40.918183: step 82680, total loss = 0.51, batch loss = 0.24 (374.0 examples/sec; 0.021 sec/batch; 0h:41m:38s remains)
INFO - root - 2022-02-24 20:12:41.384653: step 82690, total loss = 0.52, batch loss = 0.25 (212.4 examples/sec; 0.038 sec/batch; 1h:13m:19s remains)
INFO - root - 2022-02-24 20:12:41.744912: step 82700, total loss = 0.49, batch loss = 0.22 (329.9 examples/sec; 0.024 sec/batch; 0h:47m:12s remains)
INFO - root - 2022-02-24 20:12:42.155095: step 82710, total loss = 0.52, batch loss = 0.25 (325.9 examples/sec; 0.025 sec/batch; 0h:47m:46s remains)
INFO - root - 2022-02-24 20:12:42.461369: step 82720, total loss = 0.48, batch loss = 0.21 (353.4 examples/sec; 0.023 sec/batch; 0h:44m:03s remains)
INFO - root - 2022-02-24 20:12:42.759729: step 82730, total loss = 0.57, batch loss = 0.31 (321.2 examples/sec; 0.025 sec/batch; 0h:48m:28s remains)
INFO - root - 2022-02-24 20:12:43.140424: step 82740, total loss = 0.54, batch loss = 0.27 (358.3 examples/sec; 0.022 sec/batch; 0h:43m:26s remains)
INFO - root - 2022-02-24 20:12:43.479620: step 82750, total loss = 0.58, batch loss = 0.31 (310.7 examples/sec; 0.026 sec/batch; 0h:50m:06s remains)
INFO - root - 2022-02-24 20:12:43.810457: step 82760, total loss = 0.71, batch loss = 0.44 (162.6 examples/sec; 0.049 sec/batch; 1h:35m:43s remains)
INFO - root - 2022-02-24 20:12:44.121782: step 82770, total loss = 0.58, batch loss = 0.31 (240.6 examples/sec; 0.033 sec/batch; 1h:04m:40s remains)
INFO - root - 2022-02-24 20:12:44.385341: step 82780, total loss = 0.58, batch loss = 0.32 (310.0 examples/sec; 0.026 sec/batch; 0h:50m:12s remains)
INFO - root - 2022-02-24 20:12:44.701147: step 82790, total loss = 0.59, batch loss = 0.32 (356.5 examples/sec; 0.022 sec/batch; 0h:43m:38s remains)
INFO - root - 2022-02-24 20:12:44.996179: step 82800, total loss = 0.61, batch loss = 0.34 (326.7 examples/sec; 0.024 sec/batch; 0h:47m:37s remains)
INFO - root - 2022-02-24 20:12:45.514862: step 82810, total loss = 0.62, batch loss = 0.35 (132.4 examples/sec; 0.060 sec/batch; 1h:57m:31s remains)
INFO - root - 2022-02-24 20:12:45.899072: step 82820, total loss = 0.51, batch loss = 0.24 (350.8 examples/sec; 0.023 sec/batch; 0h:44m:20s remains)
INFO - root - 2022-02-24 20:12:46.213218: step 82830, total loss = 0.50, batch loss = 0.23 (295.0 examples/sec; 0.027 sec/batch; 0h:52m:43s remains)
INFO - root - 2022-02-24 20:12:46.546433: step 82840, total loss = 0.61, batch loss = 0.34 (190.2 examples/sec; 0.042 sec/batch; 1h:21m:46s remains)
INFO - root - 2022-02-24 20:12:46.871107: step 82850, total loss = 0.53, batch loss = 0.26 (136.9 examples/sec; 0.058 sec/batch; 1h:53m:36s remains)
INFO - root - 2022-02-24 20:12:47.191234: step 82860, total loss = 0.55, batch loss = 0.29 (116.7 examples/sec; 0.069 sec/batch; 2h:13m:12s remains)
INFO - root - 2022-02-24 20:12:47.631273: step 82870, total loss = 0.55, batch loss = 0.28 (130.7 examples/sec; 0.061 sec/batch; 1h:59m:01s remains)
INFO - root - 2022-02-24 20:12:47.943953: step 82880, total loss = 0.53, batch loss = 0.26 (128.4 examples/sec; 0.062 sec/batch; 2h:01m:06s remains)
INFO - root - 2022-02-24 20:12:48.334132: step 82890, total loss = 0.58, batch loss = 0.31 (260.5 examples/sec; 0.031 sec/batch; 0h:59m:41s remains)
INFO - root - 2022-02-24 20:12:48.964726: step 82900, total loss = 0.54, batch loss = 0.28 (104.7 examples/sec; 0.076 sec/batch; 2h:28m:28s remains)
INFO - root - 2022-02-24 20:12:49.504905: step 82910, total loss = 0.68, batch loss = 0.41 (227.3 examples/sec; 0.035 sec/batch; 1h:08m:22s remains)
INFO - root - 2022-02-24 20:12:50.000205: step 82920, total loss = 0.49, batch loss = 0.23 (276.0 examples/sec; 0.029 sec/batch; 0h:56m:18s remains)
INFO - root - 2022-02-24 20:12:50.583868: step 82930, total loss = 0.58, batch loss = 0.31 (197.7 examples/sec; 0.040 sec/batch; 1h:18m:36s remains)
INFO - root - 2022-02-24 20:12:50.865210: step 82940, total loss = 0.59, batch loss = 0.32 (298.5 examples/sec; 0.027 sec/batch; 0h:52m:04s remains)
INFO - root - 2022-02-24 20:12:51.166930: step 82950, total loss = 0.53, batch loss = 0.27 (250.4 examples/sec; 0.032 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 20:12:52.010496: step 82960, total loss = 0.63, batch loss = 0.36 (158.3 examples/sec; 0.051 sec/batch; 1h:38m:09s remains)
INFO - root - 2022-02-24 20:12:52.366411: step 82970, total loss = 0.48, batch loss = 0.22 (193.9 examples/sec; 0.041 sec/batch; 1h:20m:08s remains)
INFO - root - 2022-02-24 20:12:52.718075: step 82980, total loss = 0.63, batch loss = 0.36 (341.8 examples/sec; 0.023 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:12:53.006487: step 82990, total loss = 0.49, batch loss = 0.23 (362.1 examples/sec; 0.022 sec/batch; 0h:42m:54s remains)
INFO - root - 2022-02-24 20:12:53.303252: step 83000, total loss = 0.59, batch loss = 0.32 (335.0 examples/sec; 0.024 sec/batch; 0h:46m:22s remains)
INFO - root - 2022-02-24 20:12:53.664909: step 83010, total loss = 0.49, batch loss = 0.22 (311.6 examples/sec; 0.026 sec/batch; 0h:49m:50s remains)
INFO - root - 2022-02-24 20:12:54.028633: step 83020, total loss = 0.51, batch loss = 0.24 (234.5 examples/sec; 0.034 sec/batch; 1h:06m:13s remains)
INFO - root - 2022-02-24 20:12:54.466902: step 83030, total loss = 0.56, batch loss = 0.30 (133.1 examples/sec; 0.060 sec/batch; 1h:56m:42s remains)
INFO - root - 2022-02-24 20:12:54.800522: step 83040, total loss = 0.52, batch loss = 0.26 (353.6 examples/sec; 0.023 sec/batch; 0h:43m:55s remains)
INFO - root - 2022-02-24 20:12:55.128254: step 83050, total loss = 0.65, batch loss = 0.38 (268.3 examples/sec; 0.030 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 20:12:55.490944: step 83060, total loss = 0.62, batch loss = 0.36 (157.0 examples/sec; 0.051 sec/batch; 1h:38m:51s remains)
INFO - root - 2022-02-24 20:12:55.778738: step 83070, total loss = 0.55, batch loss = 0.28 (328.3 examples/sec; 0.024 sec/batch; 0h:47m:17s remains)
INFO - root - 2022-02-24 20:12:56.051296: step 83080, total loss = 0.56, batch loss = 0.29 (301.4 examples/sec; 0.027 sec/batch; 0h:51m:29s remains)
INFO - root - 2022-02-24 20:12:56.525557: step 83090, total loss = 0.58, batch loss = 0.31 (232.5 examples/sec; 0.034 sec/batch; 1h:06m:46s remains)
INFO - root - 2022-02-24 20:12:56.977267: step 83100, total loss = 0.56, batch loss = 0.30 (239.4 examples/sec; 0.033 sec/batch; 1h:04m:50s remains)
INFO - root - 2022-02-24 20:12:57.395325: step 83110, total loss = 0.60, batch loss = 0.33 (343.6 examples/sec; 0.023 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:12:57.681164: step 83120, total loss = 0.66, batch loss = 0.40 (321.2 examples/sec; 0.025 sec/batch; 0h:48m:18s remains)
INFO - root - 2022-02-24 20:12:57.980154: step 83130, total loss = 0.53, batch loss = 0.26 (208.9 examples/sec; 0.038 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 20:12:58.312440: step 83140, total loss = 0.51, batch loss = 0.25 (242.6 examples/sec; 0.033 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 20:12:58.753659: step 83150, total loss = 0.64, batch loss = 0.38 (261.9 examples/sec; 0.031 sec/batch; 0h:59m:14s remains)
INFO - root - 2022-02-24 20:12:59.111142: step 83160, total loss = 0.63, batch loss = 0.36 (229.3 examples/sec; 0.035 sec/batch; 1h:07m:39s remains)
INFO - root - 2022-02-24 20:12:59.441207: step 83170, total loss = 0.51, batch loss = 0.24 (335.8 examples/sec; 0.024 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:12:59.722210: step 83180, total loss = 0.56, batch loss = 0.29 (224.9 examples/sec; 0.036 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 20:13:00.043871: step 83190, total loss = 0.53, batch loss = 0.27 (330.2 examples/sec; 0.024 sec/batch; 0h:46m:58s remains)
INFO - root - 2022-02-24 20:13:00.480911: step 83200, total loss = 0.51, batch loss = 0.25 (173.3 examples/sec; 0.046 sec/batch; 1h:29m:27s remains)
INFO - root - 2022-02-24 20:13:00.926396: step 83210, total loss = 0.44, batch loss = 0.18 (174.0 examples/sec; 0.046 sec/batch; 1h:29m:05s remains)
INFO - root - 2022-02-24 20:13:01.329302: step 83220, total loss = 0.54, batch loss = 0.27 (345.9 examples/sec; 0.023 sec/batch; 0h:44m:49s remains)
INFO - root - 2022-02-24 20:13:01.641534: step 83230, total loss = 0.55, batch loss = 0.28 (334.8 examples/sec; 0.024 sec/batch; 0h:46m:18s remains)
INFO - root - 2022-02-24 20:13:01.943496: step 83240, total loss = 0.58, batch loss = 0.32 (229.2 examples/sec; 0.035 sec/batch; 1h:07m:38s remains)
INFO - root - 2022-02-24 20:13:02.343335: step 83250, total loss = 0.53, batch loss = 0.26 (334.1 examples/sec; 0.024 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:13:02.711382: step 83260, total loss = 0.67, batch loss = 0.40 (150.5 examples/sec; 0.053 sec/batch; 1h:42m:57s remains)
INFO - root - 2022-02-24 20:13:03.081800: step 83270, total loss = 0.59, batch loss = 0.33 (254.4 examples/sec; 0.031 sec/batch; 1h:00m:54s remains)
INFO - root - 2022-02-24 20:13:03.447722: step 83280, total loss = 0.53, batch loss = 0.27 (353.4 examples/sec; 0.023 sec/batch; 0h:43m:50s remains)
INFO - root - 2022-02-24 20:13:03.744598: step 83290, total loss = 0.55, batch loss = 0.29 (169.4 examples/sec; 0.047 sec/batch; 1h:31m:26s remains)
INFO - root - 2022-02-24 20:13:04.148781: step 83300, total loss = 0.49, batch loss = 0.23 (137.5 examples/sec; 0.058 sec/batch; 1h:52m:39s remains)
INFO - root - 2022-02-24 20:13:04.499788: step 83310, total loss = 0.48, batch loss = 0.22 (188.0 examples/sec; 0.043 sec/batch; 1h:22m:23s remains)
INFO - root - 2022-02-24 20:13:04.884663: step 83320, total loss = 0.68, batch loss = 0.41 (107.3 examples/sec; 0.075 sec/batch; 2h:24m:25s remains)
INFO - root - 2022-02-24 20:13:05.322080: step 83330, total loss = 0.49, batch loss = 0.23 (255.0 examples/sec; 0.031 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:13:05.610262: step 83340, total loss = 0.52, batch loss = 0.25 (201.7 examples/sec; 0.040 sec/batch; 1h:16m:46s remains)
INFO - root - 2022-02-24 20:13:05.948669: step 83350, total loss = 0.61, batch loss = 0.34 (328.5 examples/sec; 0.024 sec/batch; 0h:47m:08s remains)
INFO - root - 2022-02-24 20:13:06.286367: step 83360, total loss = 0.54, batch loss = 0.27 (150.9 examples/sec; 0.053 sec/batch; 1h:42m:38s remains)
INFO - root - 2022-02-24 20:13:06.636273: step 83370, total loss = 0.54, batch loss = 0.28 (331.8 examples/sec; 0.024 sec/batch; 0h:46m:40s remains)
INFO - root - 2022-02-24 20:13:07.003157: step 83380, total loss = 0.57, batch loss = 0.30 (333.6 examples/sec; 0.024 sec/batch; 0h:46m:24s remains)
INFO - root - 2022-02-24 20:13:07.376771: step 83390, total loss = 0.54, batch loss = 0.27 (323.6 examples/sec; 0.025 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:13:07.682008: step 83400, total loss = 0.53, batch loss = 0.27 (298.0 examples/sec; 0.027 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 20:13:08.051151: step 83410, total loss = 0.54, batch loss = 0.27 (323.9 examples/sec; 0.025 sec/batch; 0h:47m:47s remains)
INFO - root - 2022-02-24 20:13:08.381783: step 83420, total loss = 0.56, batch loss = 0.30 (92.6 examples/sec; 0.086 sec/batch; 2h:47m:04s remains)
INFO - root - 2022-02-24 20:13:08.789944: step 83430, total loss = 0.51, batch loss = 0.25 (115.0 examples/sec; 0.070 sec/batch; 2h:14m:31s remains)
INFO - root - 2022-02-24 20:13:09.239687: step 83440, total loss = 0.57, batch loss = 0.30 (324.7 examples/sec; 0.025 sec/batch; 0h:47m:39s remains)
INFO - root - 2022-02-24 20:13:09.584350: step 83450, total loss = 0.53, batch loss = 0.27 (217.4 examples/sec; 0.037 sec/batch; 1h:11m:10s remains)
INFO - root - 2022-02-24 20:13:09.863558: step 83460, total loss = 0.54, batch loss = 0.28 (340.2 examples/sec; 0.024 sec/batch; 0h:45m:28s remains)
INFO - root - 2022-02-24 20:13:10.142820: step 83470, total loss = 0.59, batch loss = 0.33 (319.7 examples/sec; 0.025 sec/batch; 0h:48m:23s remains)
INFO - root - 2022-02-24 20:13:10.433366: step 83480, total loss = 0.67, batch loss = 0.40 (188.9 examples/sec; 0.042 sec/batch; 1h:21m:53s remains)
INFO - root - 2022-02-24 20:13:10.917857: step 83490, total loss = 0.58, batch loss = 0.32 (229.7 examples/sec; 0.035 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 20:13:11.383431: step 83500, total loss = 0.55, batch loss = 0.28 (281.9 examples/sec; 0.028 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 20:13:11.916369: step 83510, total loss = 0.60, batch loss = 0.33 (83.0 examples/sec; 0.096 sec/batch; 3h:06m:20s remains)
INFO - root - 2022-02-24 20:13:12.784231: step 83520, total loss = 0.47, batch loss = 0.21 (245.0 examples/sec; 0.033 sec/batch; 1h:03m:07s remains)
INFO - root - 2022-02-24 20:13:13.176651: step 83530, total loss = 0.66, batch loss = 0.39 (104.0 examples/sec; 0.077 sec/batch; 2h:28m:39s remains)
INFO - root - 2022-02-24 20:13:13.582926: step 83540, total loss = 0.67, batch loss = 0.41 (213.1 examples/sec; 0.038 sec/batch; 1h:12m:32s remains)
INFO - root - 2022-02-24 20:13:13.952010: step 83550, total loss = 0.66, batch loss = 0.39 (227.2 examples/sec; 0.035 sec/batch; 1h:08m:03s remains)
INFO - root - 2022-02-24 20:13:14.378876: step 83560, total loss = 0.59, batch loss = 0.32 (219.7 examples/sec; 0.036 sec/batch; 1h:10m:22s remains)
INFO - root - 2022-02-24 20:13:14.800302: step 83570, total loss = 0.47, batch loss = 0.20 (181.4 examples/sec; 0.044 sec/batch; 1h:25m:13s remains)
INFO - root - 2022-02-24 20:13:15.258121: step 83580, total loss = 0.53, batch loss = 0.27 (96.4 examples/sec; 0.083 sec/batch; 2h:40m:16s remains)
INFO - root - 2022-02-24 20:13:15.585195: step 83590, total loss = 0.60, batch loss = 0.33 (364.4 examples/sec; 0.022 sec/batch; 0h:42m:24s remains)
INFO - root - 2022-02-24 20:13:15.970614: step 83600, total loss = 0.67, batch loss = 0.40 (142.7 examples/sec; 0.056 sec/batch; 1h:48m:17s remains)
INFO - root - 2022-02-24 20:13:16.369326: step 83610, total loss = 0.50, batch loss = 0.23 (375.9 examples/sec; 0.021 sec/batch; 0h:41m:06s remains)
INFO - root - 2022-02-24 20:13:16.694442: step 83620, total loss = 0.54, batch loss = 0.27 (212.2 examples/sec; 0.038 sec/batch; 1h:12m:48s remains)
INFO - root - 2022-02-24 20:13:17.000959: step 83630, total loss = 0.56, batch loss = 0.29 (373.9 examples/sec; 0.021 sec/batch; 0h:41m:19s remains)
INFO - root - 2022-02-24 20:13:17.670034: step 83640, total loss = 0.57, batch loss = 0.31 (197.5 examples/sec; 0.041 sec/batch; 1h:18m:12s remains)
INFO - root - 2022-02-24 20:13:18.003153: step 83650, total loss = 0.64, batch loss = 0.37 (226.9 examples/sec; 0.035 sec/batch; 1h:08m:04s remains)
INFO - root - 2022-02-24 20:13:18.282922: step 83660, total loss = 0.50, batch loss = 0.23 (357.6 examples/sec; 0.022 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:13:18.588010: step 83670, total loss = 0.52, batch loss = 0.26 (240.0 examples/sec; 0.033 sec/batch; 1h:04m:20s remains)
INFO - root - 2022-02-24 20:13:18.895456: step 83680, total loss = 0.53, batch loss = 0.27 (279.4 examples/sec; 0.029 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:13:19.343589: step 83690, total loss = 0.48, batch loss = 0.22 (169.7 examples/sec; 0.047 sec/batch; 1h:30m:59s remains)
INFO - root - 2022-02-24 20:13:19.829884: step 83700, total loss = 0.55, batch loss = 0.29 (154.7 examples/sec; 0.052 sec/batch; 1h:39m:48s remains)
INFO - root - 2022-02-24 20:13:20.167942: step 83710, total loss = 0.53, batch loss = 0.27 (325.2 examples/sec; 0.025 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:13:20.419005: step 83720, total loss = 0.52, batch loss = 0.25 (342.3 examples/sec; 0.023 sec/batch; 0h:45m:05s remains)
INFO - root - 2022-02-24 20:13:20.730496: step 83730, total loss = 0.57, batch loss = 0.30 (329.6 examples/sec; 0.024 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:13:21.055168: step 83740, total loss = 0.51, batch loss = 0.24 (141.2 examples/sec; 0.057 sec/batch; 1h:49m:17s remains)
INFO - root - 2022-02-24 20:13:21.468169: step 83750, total loss = 0.45, batch loss = 0.19 (338.6 examples/sec; 0.024 sec/batch; 0h:45m:34s remains)
INFO - root - 2022-02-24 20:13:21.834442: step 83760, total loss = 0.47, batch loss = 0.21 (322.7 examples/sec; 0.025 sec/batch; 0h:47m:48s remains)
INFO - root - 2022-02-24 20:13:22.208771: step 83770, total loss = 0.52, batch loss = 0.25 (182.6 examples/sec; 0.044 sec/batch; 1h:24m:29s remains)
INFO - root - 2022-02-24 20:13:22.507858: step 83780, total loss = 0.62, batch loss = 0.35 (222.4 examples/sec; 0.036 sec/batch; 1h:09m:23s remains)
INFO - root - 2022-02-24 20:13:22.931378: step 83790, total loss = 0.71, batch loss = 0.44 (197.1 examples/sec; 0.041 sec/batch; 1h:18m:16s remains)
INFO - root - 2022-02-24 20:13:23.282617: step 83800, total loss = 0.48, batch loss = 0.22 (177.8 examples/sec; 0.045 sec/batch; 1h:26m:46s remains)
INFO - root - 2022-02-24 20:13:23.755179: step 83810, total loss = 0.65, batch loss = 0.39 (334.9 examples/sec; 0.024 sec/batch; 0h:46m:03s remains)
INFO - root - 2022-02-24 20:13:24.076383: step 83820, total loss = 0.59, batch loss = 0.32 (359.6 examples/sec; 0.022 sec/batch; 0h:42m:53s remains)
INFO - root - 2022-02-24 20:13:24.414735: step 83830, total loss = 0.55, batch loss = 0.29 (205.2 examples/sec; 0.039 sec/batch; 1h:15m:09s remains)
INFO - root - 2022-02-24 20:13:24.698335: step 83840, total loss = 0.62, batch loss = 0.35 (215.0 examples/sec; 0.037 sec/batch; 1h:11m:42s remains)
INFO - root - 2022-02-24 20:13:24.946282: step 83850, total loss = 0.51, batch loss = 0.24 (311.1 examples/sec; 0.026 sec/batch; 0h:49m:33s remains)
INFO - root - 2022-02-24 20:13:25.320215: step 83860, total loss = 0.60, batch loss = 0.33 (235.4 examples/sec; 0.034 sec/batch; 1h:05m:29s remains)
INFO - root - 2022-02-24 20:13:25.747535: step 83870, total loss = 0.47, batch loss = 0.21 (301.6 examples/sec; 0.027 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:13:26.076686: step 83880, total loss = 0.53, batch loss = 0.27 (181.6 examples/sec; 0.044 sec/batch; 1h:24m:53s remains)
INFO - root - 2022-02-24 20:13:26.416635: step 83890, total loss = 0.63, batch loss = 0.36 (168.8 examples/sec; 0.047 sec/batch; 1h:31m:19s remains)
INFO - root - 2022-02-24 20:13:26.744005: step 83900, total loss = 0.61, batch loss = 0.35 (356.8 examples/sec; 0.022 sec/batch; 0h:43m:12s remains)
INFO - root - 2022-02-24 20:13:27.175622: step 83910, total loss = 0.61, batch loss = 0.34 (351.0 examples/sec; 0.023 sec/batch; 0h:43m:54s remains)
INFO - root - 2022-02-24 20:13:27.574972: step 83920, total loss = 0.62, batch loss = 0.35 (181.7 examples/sec; 0.044 sec/batch; 1h:24m:48s remains)
INFO - root - 2022-02-24 20:13:28.012309: step 83930, total loss = 0.59, batch loss = 0.32 (272.2 examples/sec; 0.029 sec/batch; 0h:56m:36s remains)
INFO - root - 2022-02-24 20:13:28.275931: step 83940, total loss = 0.62, batch loss = 0.36 (332.0 examples/sec; 0.024 sec/batch; 0h:46m:24s remains)
INFO - root - 2022-02-24 20:13:28.580023: step 83950, total loss = 0.60, batch loss = 0.33 (336.8 examples/sec; 0.024 sec/batch; 0h:45m:44s remains)
INFO - root - 2022-02-24 20:13:28.888947: step 83960, total loss = 0.59, batch loss = 0.33 (186.3 examples/sec; 0.043 sec/batch; 1h:22m:42s remains)
INFO - root - 2022-02-24 20:13:29.144268: step 83970, total loss = 0.59, batch loss = 0.32 (344.6 examples/sec; 0.023 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:13:29.496893: step 83980, total loss = 0.56, batch loss = 0.29 (143.9 examples/sec; 0.056 sec/batch; 1h:47m:00s remains)
INFO - root - 2022-02-24 20:13:29.966773: step 83990, total loss = 0.52, batch loss = 0.25 (346.5 examples/sec; 0.023 sec/batch; 0h:44m:26s remains)
INFO - root - 2022-02-24 20:13:30.632061: step 84000, total loss = 0.47, batch loss = 0.20 (118.8 examples/sec; 0.067 sec/batch; 2h:09m:37s remains)
INFO - root - 2022-02-24 20:13:31.246521: step 84010, total loss = 0.51, batch loss = 0.24 (134.4 examples/sec; 0.060 sec/batch; 1h:54m:34s remains)
INFO - root - 2022-02-24 20:13:31.724273: step 84020, total loss = 0.57, batch loss = 0.30 (86.6 examples/sec; 0.092 sec/batch; 2h:57m:53s remains)
INFO - root - 2022-02-24 20:13:32.173199: step 84030, total loss = 0.57, batch loss = 0.31 (167.0 examples/sec; 0.048 sec/batch; 1h:32m:12s remains)
INFO - root - 2022-02-24 20:13:32.582834: step 84040, total loss = 0.50, batch loss = 0.23 (332.1 examples/sec; 0.024 sec/batch; 0h:46m:21s remains)
INFO - root - 2022-02-24 20:13:33.392806: step 84050, total loss = 0.62, batch loss = 0.35 (347.1 examples/sec; 0.023 sec/batch; 0h:44m:20s remains)
INFO - root - 2022-02-24 20:13:33.849370: step 84060, total loss = 0.52, batch loss = 0.26 (264.4 examples/sec; 0.030 sec/batch; 0h:58m:12s remains)
INFO - root - 2022-02-24 20:13:34.165939: step 84070, total loss = 0.62, batch loss = 0.35 (333.8 examples/sec; 0.024 sec/batch; 0h:46m:06s remains)
INFO - root - 2022-02-24 20:13:34.484129: step 84080, total loss = 0.53, batch loss = 0.27 (300.5 examples/sec; 0.027 sec/batch; 0h:51m:12s remains)
INFO - root - 2022-02-24 20:13:34.777297: step 84090, total loss = 0.55, batch loss = 0.28 (348.5 examples/sec; 0.023 sec/batch; 0h:44m:09s remains)
INFO - root - 2022-02-24 20:13:35.066392: step 84100, total loss = 0.55, batch loss = 0.28 (301.0 examples/sec; 0.027 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:13:35.455136: step 84110, total loss = 0.53, batch loss = 0.27 (349.4 examples/sec; 0.023 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:13:35.783139: step 84120, total loss = 0.60, batch loss = 0.33 (363.2 examples/sec; 0.022 sec/batch; 0h:42m:21s remains)
INFO - root - 2022-02-24 20:13:36.226512: step 84130, total loss = 0.50, batch loss = 0.23 (285.7 examples/sec; 0.028 sec/batch; 0h:53m:50s remains)
INFO - root - 2022-02-24 20:13:36.555791: step 84140, total loss = 0.61, batch loss = 0.35 (327.2 examples/sec; 0.024 sec/batch; 0h:47m:00s remains)
INFO - root - 2022-02-24 20:13:36.973092: step 84150, total loss = 0.65, batch loss = 0.39 (321.1 examples/sec; 0.025 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:13:37.271524: step 84160, total loss = 0.57, batch loss = 0.31 (315.2 examples/sec; 0.025 sec/batch; 0h:48m:47s remains)
INFO - root - 2022-02-24 20:13:37.683557: step 84170, total loss = 0.64, batch loss = 0.37 (193.1 examples/sec; 0.041 sec/batch; 1h:19m:39s remains)
INFO - root - 2022-02-24 20:13:38.077455: step 84180, total loss = 0.54, batch loss = 0.27 (163.7 examples/sec; 0.049 sec/batch; 1h:33m:55s remains)
INFO - root - 2022-02-24 20:13:38.420757: step 84190, total loss = 0.56, batch loss = 0.30 (197.5 examples/sec; 0.040 sec/batch; 1h:17m:49s remains)
INFO - root - 2022-02-24 20:13:38.742051: step 84200, total loss = 0.51, batch loss = 0.24 (263.5 examples/sec; 0.030 sec/batch; 0h:58m:20s remains)
INFO - root - 2022-02-24 20:13:39.124052: step 84210, total loss = 0.56, batch loss = 0.29 (325.2 examples/sec; 0.025 sec/batch; 0h:47m:16s remains)
INFO - root - 2022-02-24 20:13:39.546670: step 84220, total loss = 0.68, batch loss = 0.41 (107.9 examples/sec; 0.074 sec/batch; 2h:22m:30s remains)
INFO - root - 2022-02-24 20:13:39.966842: step 84230, total loss = 0.61, batch loss = 0.35 (250.0 examples/sec; 0.032 sec/batch; 1h:01m:28s remains)
INFO - root - 2022-02-24 20:13:40.340459: step 84240, total loss = 0.72, batch loss = 0.45 (167.0 examples/sec; 0.048 sec/batch; 1h:32m:01s remains)
INFO - root - 2022-02-24 20:13:40.727765: step 84250, total loss = 0.47, batch loss = 0.21 (207.7 examples/sec; 0.039 sec/batch; 1h:13m:58s remains)
INFO - root - 2022-02-24 20:13:41.080651: step 84260, total loss = 0.54, batch loss = 0.27 (225.4 examples/sec; 0.035 sec/batch; 1h:08m:10s remains)
INFO - root - 2022-02-24 20:13:41.365479: step 84270, total loss = 0.54, batch loss = 0.28 (336.3 examples/sec; 0.024 sec/batch; 0h:45m:41s remains)
INFO - root - 2022-02-24 20:13:41.687739: step 84280, total loss = 0.59, batch loss = 0.33 (274.3 examples/sec; 0.029 sec/batch; 0h:56m:00s remains)
INFO - root - 2022-02-24 20:13:42.056420: step 84290, total loss = 0.60, batch loss = 0.33 (234.7 examples/sec; 0.034 sec/batch; 1h:05m:27s remains)
INFO - root - 2022-02-24 20:13:42.452425: step 84300, total loss = 0.50, batch loss = 0.24 (114.4 examples/sec; 0.070 sec/batch; 2h:14m:14s remains)
INFO - root - 2022-02-24 20:13:42.884779: step 84310, total loss = 0.51, batch loss = 0.24 (352.3 examples/sec; 0.023 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 20:13:43.178515: step 84320, total loss = 0.51, batch loss = 0.25 (342.3 examples/sec; 0.023 sec/batch; 0h:44m:51s remains)
INFO - root - 2022-02-24 20:13:43.545704: step 84330, total loss = 0.55, batch loss = 0.29 (331.8 examples/sec; 0.024 sec/batch; 0h:46m:17s remains)
INFO - root - 2022-02-24 20:13:43.910274: step 84340, total loss = 0.49, batch loss = 0.23 (243.7 examples/sec; 0.033 sec/batch; 1h:03m:00s remains)
INFO - root - 2022-02-24 20:13:44.333260: step 84350, total loss = 0.56, batch loss = 0.29 (218.1 examples/sec; 0.037 sec/batch; 1h:10m:23s remains)
INFO - root - 2022-02-24 20:13:44.737957: step 84360, total loss = 0.59, batch loss = 0.33 (198.8 examples/sec; 0.040 sec/batch; 1h:17m:13s remains)
INFO - root - 2022-02-24 20:13:45.014959: step 84370, total loss = 0.50, batch loss = 0.24 (363.1 examples/sec; 0.022 sec/batch; 0h:42m:16s remains)
INFO - root - 2022-02-24 20:13:45.302639: step 84380, total loss = 0.51, batch loss = 0.24 (371.5 examples/sec; 0.022 sec/batch; 0h:41m:18s remains)
INFO - root - 2022-02-24 20:13:45.589625: step 84390, total loss = 0.51, batch loss = 0.24 (280.1 examples/sec; 0.029 sec/batch; 0h:54m:47s remains)
INFO - root - 2022-02-24 20:13:45.923957: step 84400, total loss = 0.53, batch loss = 0.27 (336.3 examples/sec; 0.024 sec/batch; 0h:45m:38s remains)
INFO - root - 2022-02-24 20:13:46.303280: step 84410, total loss = 0.62, batch loss = 0.35 (327.3 examples/sec; 0.024 sec/batch; 0h:46m:52s remains)
INFO - root - 2022-02-24 20:13:46.583335: step 84420, total loss = 0.64, batch loss = 0.37 (330.9 examples/sec; 0.024 sec/batch; 0h:46m:22s remains)
INFO - root - 2022-02-24 20:13:46.905663: step 84430, total loss = 0.56, batch loss = 0.29 (324.3 examples/sec; 0.025 sec/batch; 0h:47m:18s remains)
INFO - root - 2022-02-24 20:13:47.597564: step 84440, total loss = 0.58, batch loss = 0.31 (227.7 examples/sec; 0.035 sec/batch; 1h:07m:22s remains)
INFO - root - 2022-02-24 20:13:48.136738: step 84450, total loss = 0.64, batch loss = 0.37 (227.8 examples/sec; 0.035 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 20:13:48.708660: step 84460, total loss = 0.51, batch loss = 0.25 (174.9 examples/sec; 0.046 sec/batch; 1h:27m:42s remains)
INFO - root - 2022-02-24 20:13:49.035933: step 84470, total loss = 0.62, batch loss = 0.35 (161.3 examples/sec; 0.050 sec/batch; 1h:35m:05s remains)
INFO - root - 2022-02-24 20:13:49.371558: step 84480, total loss = 0.56, batch loss = 0.30 (351.8 examples/sec; 0.023 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 20:13:49.709891: step 84490, total loss = 0.56, batch loss = 0.30 (391.8 examples/sec; 0.020 sec/batch; 0h:39m:08s remains)
INFO - root - 2022-02-24 20:13:51.215862: step 84500, total loss = 0.58, batch loss = 0.31 (152.7 examples/sec; 0.052 sec/batch; 1h:40m:24s remains)
INFO - root - 2022-02-24 20:13:51.774449: step 84510, total loss = 0.62, batch loss = 0.36 (121.9 examples/sec; 0.066 sec/batch; 2h:05m:46s remains)
INFO - root - 2022-02-24 20:13:52.326874: step 84520, total loss = 0.53, batch loss = 0.27 (232.0 examples/sec; 0.034 sec/batch; 1h:06m:04s remains)
INFO - root - 2022-02-24 20:13:52.854043: step 84530, total loss = 0.56, batch loss = 0.29 (207.7 examples/sec; 0.039 sec/batch; 1h:13m:47s remains)
INFO - root - 2022-02-24 20:13:53.351782: step 84540, total loss = 0.56, batch loss = 0.29 (120.7 examples/sec; 0.066 sec/batch; 2h:07m:00s remains)
INFO - root - 2022-02-24 20:13:54.290826: step 84550, total loss = 0.59, batch loss = 0.32 (317.2 examples/sec; 0.025 sec/batch; 0h:48m:18s remains)
INFO - root - 2022-02-24 20:13:54.606959: step 84560, total loss = 0.52, batch loss = 0.25 (211.8 examples/sec; 0.038 sec/batch; 1h:12m:20s remains)
INFO - root - 2022-02-24 20:13:55.227583: step 84570, total loss = 0.65, batch loss = 0.39 (53.2 examples/sec; 0.150 sec/batch; 4h:48m:02s remains)
INFO - root - 2022-02-24 20:13:55.668978: step 84580, total loss = 0.51, batch loss = 0.24 (333.3 examples/sec; 0.024 sec/batch; 0h:45m:57s remains)
INFO - root - 2022-02-24 20:13:56.182390: step 84590, total loss = 0.64, batch loss = 0.37 (239.2 examples/sec; 0.033 sec/batch; 1h:04m:02s remains)
INFO - root - 2022-02-24 20:13:56.686914: step 84600, total loss = 0.60, batch loss = 0.33 (119.8 examples/sec; 0.067 sec/batch; 2h:07m:49s remains)
INFO - root - 2022-02-24 20:13:57.137411: step 84610, total loss = 0.65, batch loss = 0.38 (372.2 examples/sec; 0.021 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:13:57.803376: step 84620, total loss = 0.45, batch loss = 0.18 (96.0 examples/sec; 0.083 sec/batch; 2h:39m:37s remains)
INFO - root - 2022-02-24 20:13:58.221741: step 84630, total loss = 0.52, batch loss = 0.25 (327.0 examples/sec; 0.024 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:13:58.943417: step 84640, total loss = 0.62, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 4h:59m:04s remains)
INFO - root - 2022-02-24 20:13:59.375963: step 84650, total loss = 0.51, batch loss = 0.25 (329.4 examples/sec; 0.024 sec/batch; 0h:46m:29s remains)
INFO - root - 2022-02-24 20:13:59.769339: step 84660, total loss = 0.60, batch loss = 0.34 (334.9 examples/sec; 0.024 sec/batch; 0h:45m:43s remains)
INFO - root - 2022-02-24 20:14:00.076746: step 84670, total loss = 0.58, batch loss = 0.32 (331.5 examples/sec; 0.024 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:14:00.341793: step 84680, total loss = 0.57, batch loss = 0.31 (272.8 examples/sec; 0.029 sec/batch; 0h:56m:07s remains)
INFO - root - 2022-02-24 20:14:00.660949: step 84690, total loss = 0.61, batch loss = 0.35 (273.5 examples/sec; 0.029 sec/batch; 0h:55m:58s remains)
INFO - root - 2022-02-24 20:14:00.946141: step 84700, total loss = 0.51, batch loss = 0.24 (279.2 examples/sec; 0.029 sec/batch; 0h:54m:48s remains)
INFO - root - 2022-02-24 20:14:01.422075: step 84710, total loss = 0.46, batch loss = 0.19 (262.7 examples/sec; 0.030 sec/batch; 0h:58m:15s remains)
INFO - root - 2022-02-24 20:14:01.814248: step 84720, total loss = 0.76, batch loss = 0.49 (321.8 examples/sec; 0.025 sec/batch; 0h:47m:33s remains)
INFO - root - 2022-02-24 20:14:02.166758: step 84730, total loss = 0.61, batch loss = 0.34 (174.7 examples/sec; 0.046 sec/batch; 1h:27m:35s remains)
INFO - root - 2022-02-24 20:14:02.476876: step 84740, total loss = 0.63, batch loss = 0.36 (325.5 examples/sec; 0.025 sec/batch; 0h:47m:00s remains)
INFO - root - 2022-02-24 20:14:02.801450: step 84750, total loss = 0.64, batch loss = 0.37 (217.1 examples/sec; 0.037 sec/batch; 1h:10m:29s remains)
INFO - root - 2022-02-24 20:14:03.201595: step 84760, total loss = 0.50, batch loss = 0.23 (372.9 examples/sec; 0.021 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:14:03.620229: step 84770, total loss = 0.61, batch loss = 0.34 (178.7 examples/sec; 0.045 sec/batch; 1h:25m:36s remains)
INFO - root - 2022-02-24 20:14:03.957101: step 84780, total loss = 0.69, batch loss = 0.42 (324.5 examples/sec; 0.025 sec/batch; 0h:47m:08s remains)
INFO - root - 2022-02-24 20:14:04.273813: step 84790, total loss = 0.62, batch loss = 0.36 (272.3 examples/sec; 0.029 sec/batch; 0h:56m:09s remains)
INFO - root - 2022-02-24 20:14:04.601358: step 84800, total loss = 0.53, batch loss = 0.26 (342.6 examples/sec; 0.023 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:14:04.990504: step 84810, total loss = 0.61, batch loss = 0.34 (331.3 examples/sec; 0.024 sec/batch; 0h:46m:09s remains)
INFO - root - 2022-02-24 20:14:05.320092: step 84820, total loss = 0.45, batch loss = 0.18 (176.1 examples/sec; 0.045 sec/batch; 1h:26m:49s remains)
INFO - root - 2022-02-24 20:14:05.742822: step 84830, total loss = 0.54, batch loss = 0.28 (161.4 examples/sec; 0.050 sec/batch; 1h:34m:43s remains)
INFO - root - 2022-02-24 20:14:06.021084: step 84840, total loss = 0.63, batch loss = 0.36 (159.3 examples/sec; 0.050 sec/batch; 1h:35m:59s remains)
INFO - root - 2022-02-24 20:14:06.383377: step 84850, total loss = 0.60, batch loss = 0.33 (314.6 examples/sec; 0.025 sec/batch; 0h:48m:35s remains)
INFO - root - 2022-02-24 20:14:06.740398: step 84860, total loss = 0.56, batch loss = 0.30 (310.8 examples/sec; 0.026 sec/batch; 0h:49m:10s remains)
INFO - root - 2022-02-24 20:14:07.131269: step 84870, total loss = 0.52, batch loss = 0.26 (219.3 examples/sec; 0.036 sec/batch; 1h:09m:40s remains)
INFO - root - 2022-02-24 20:14:07.594473: step 84880, total loss = 0.52, batch loss = 0.26 (277.2 examples/sec; 0.029 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 20:14:07.958199: step 84890, total loss = 0.45, batch loss = 0.18 (351.8 examples/sec; 0.023 sec/batch; 0h:43m:26s remains)
INFO - root - 2022-02-24 20:14:08.329538: step 84900, total loss = 0.53, batch loss = 0.26 (247.5 examples/sec; 0.032 sec/batch; 1h:01m:43s remains)
INFO - root - 2022-02-24 20:14:08.715753: step 84910, total loss = 0.48, batch loss = 0.22 (176.0 examples/sec; 0.045 sec/batch; 1h:26m:47s remains)
INFO - root - 2022-02-24 20:14:09.136679: step 84920, total loss = 0.45, batch loss = 0.18 (320.7 examples/sec; 0.025 sec/batch; 0h:47m:38s remains)
INFO - root - 2022-02-24 20:14:09.517664: step 84930, total loss = 0.49, batch loss = 0.22 (323.8 examples/sec; 0.025 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:14:09.849792: step 84940, total loss = 0.52, batch loss = 0.25 (306.4 examples/sec; 0.026 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:14:10.159761: step 84950, total loss = 0.52, batch loss = 0.26 (298.5 examples/sec; 0.027 sec/batch; 0h:51m:10s remains)
INFO - root - 2022-02-24 20:14:10.470906: step 84960, total loss = 0.56, batch loss = 0.30 (328.4 examples/sec; 0.024 sec/batch; 0h:46m:30s remains)
INFO - root - 2022-02-24 20:14:10.845660: step 84970, total loss = 0.47, batch loss = 0.21 (128.0 examples/sec; 0.062 sec/batch; 1h:59m:17s remains)
INFO - root - 2022-02-24 20:14:11.191034: step 84980, total loss = 0.52, batch loss = 0.25 (374.2 examples/sec; 0.021 sec/batch; 0h:40m:48s remains)
INFO - root - 2022-02-24 20:14:11.510811: step 84990, total loss = 0.61, batch loss = 0.35 (360.0 examples/sec; 0.022 sec/batch; 0h:42m:24s remains)
INFO - root - 2022-02-24 20:14:11.770185: step 85000, total loss = 0.61, batch loss = 0.34 (275.1 examples/sec; 0.029 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 20:14:12.198771: step 85010, total loss = 0.66, batch loss = 0.40 (344.0 examples/sec; 0.023 sec/batch; 0h:44m:22s remains)
INFO - root - 2022-02-24 20:14:12.540644: step 85020, total loss = 0.56, batch loss = 0.29 (166.2 examples/sec; 0.048 sec/batch; 1h:31m:49s remains)
INFO - root - 2022-02-24 20:14:12.919942: step 85030, total loss = 0.61, batch loss = 0.35 (255.4 examples/sec; 0.031 sec/batch; 0h:59m:45s remains)
INFO - root - 2022-02-24 20:14:13.327182: step 85040, total loss = 0.49, batch loss = 0.22 (212.4 examples/sec; 0.038 sec/batch; 1h:11m:50s remains)
INFO - root - 2022-02-24 20:14:13.618911: step 85050, total loss = 0.54, batch loss = 0.27 (199.6 examples/sec; 0.040 sec/batch; 1h:16m:28s remains)
INFO - root - 2022-02-24 20:14:13.913159: step 85060, total loss = 0.72, batch loss = 0.46 (330.3 examples/sec; 0.024 sec/batch; 0h:46m:12s remains)
INFO - root - 2022-02-24 20:14:14.208875: step 85070, total loss = 0.52, batch loss = 0.25 (212.7 examples/sec; 0.038 sec/batch; 1h:11m:44s remains)
INFO - root - 2022-02-24 20:14:14.541901: step 85080, total loss = 0.62, batch loss = 0.35 (299.5 examples/sec; 0.027 sec/batch; 0h:50m:55s remains)
INFO - root - 2022-02-24 20:14:14.985990: step 85090, total loss = 0.56, batch loss = 0.30 (189.1 examples/sec; 0.042 sec/batch; 1h:20m:39s remains)
INFO - root - 2022-02-24 20:14:15.381507: step 85100, total loss = 0.50, batch loss = 0.24 (241.4 examples/sec; 0.033 sec/batch; 1h:03m:10s remains)
INFO - root - 2022-02-24 20:14:15.751415: step 85110, total loss = 0.52, batch loss = 0.25 (285.0 examples/sec; 0.028 sec/batch; 0h:53m:30s remains)
INFO - root - 2022-02-24 20:14:16.051213: step 85120, total loss = 0.63, batch loss = 0.37 (300.4 examples/sec; 0.027 sec/batch; 0h:50m:45s remains)
INFO - root - 2022-02-24 20:14:16.333251: step 85130, total loss = 0.61, batch loss = 0.34 (294.6 examples/sec; 0.027 sec/batch; 0h:51m:45s remains)
INFO - root - 2022-02-24 20:14:16.656147: step 85140, total loss = 0.53, batch loss = 0.26 (153.3 examples/sec; 0.052 sec/batch; 1h:39m:27s remains)
INFO - root - 2022-02-24 20:14:17.019087: step 85150, total loss = 0.58, batch loss = 0.32 (350.8 examples/sec; 0.023 sec/batch; 0h:43m:27s remains)
INFO - root - 2022-02-24 20:14:17.358731: step 85160, total loss = 0.59, batch loss = 0.33 (321.5 examples/sec; 0.025 sec/batch; 0h:47m:25s remains)
INFO - root - 2022-02-24 20:14:17.647708: step 85170, total loss = 0.65, batch loss = 0.39 (340.5 examples/sec; 0.023 sec/batch; 0h:44m:46s remains)
INFO - root - 2022-02-24 20:14:17.991395: step 85180, total loss = 0.57, batch loss = 0.31 (273.0 examples/sec; 0.029 sec/batch; 0h:55m:50s remains)
INFO - root - 2022-02-24 20:14:18.338595: step 85190, total loss = 0.67, batch loss = 0.40 (198.5 examples/sec; 0.040 sec/batch; 1h:16m:47s remains)
INFO - root - 2022-02-24 20:14:18.749676: step 85200, total loss = 0.57, batch loss = 0.30 (229.9 examples/sec; 0.035 sec/batch; 1h:06m:17s remains)
INFO - root - 2022-02-24 20:14:19.244921: step 85210, total loss = 0.68, batch loss = 0.41 (192.7 examples/sec; 0.042 sec/batch; 1h:19m:03s remains)
INFO - root - 2022-02-24 20:14:19.583736: step 85220, total loss = 0.74, batch loss = 0.47 (178.8 examples/sec; 0.045 sec/batch; 1h:25m:14s remains)
INFO - root - 2022-02-24 20:14:19.907085: step 85230, total loss = 0.59, batch loss = 0.32 (347.2 examples/sec; 0.023 sec/batch; 0h:43m:52s remains)
INFO - root - 2022-02-24 20:14:20.221399: step 85240, total loss = 0.68, batch loss = 0.42 (264.0 examples/sec; 0.030 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:14:20.593818: step 85250, total loss = 0.59, batch loss = 0.32 (312.1 examples/sec; 0.026 sec/batch; 0h:48m:48s remains)
INFO - root - 2022-02-24 20:14:20.976428: step 85260, total loss = 0.55, batch loss = 0.28 (333.9 examples/sec; 0.024 sec/batch; 0h:45m:36s remains)
INFO - root - 2022-02-24 20:14:21.300925: step 85270, total loss = 0.57, batch loss = 0.30 (317.1 examples/sec; 0.025 sec/batch; 0h:48m:01s remains)
INFO - root - 2022-02-24 20:14:21.616730: step 85280, total loss = 0.49, batch loss = 0.22 (336.8 examples/sec; 0.024 sec/batch; 0h:45m:13s remains)
INFO - root - 2022-02-24 20:14:21.966779: step 85290, total loss = 0.62, batch loss = 0.35 (198.3 examples/sec; 0.040 sec/batch; 1h:16m:48s remains)
INFO - root - 2022-02-24 20:14:22.358731: step 85300, total loss = 0.54, batch loss = 0.27 (162.4 examples/sec; 0.049 sec/batch; 1h:33m:44s remains)
INFO - root - 2022-02-24 20:14:22.821047: step 85310, total loss = 0.53, batch loss = 0.27 (286.3 examples/sec; 0.028 sec/batch; 0h:53m:11s remains)
INFO - root - 2022-02-24 20:14:23.148734: step 85320, total loss = 0.63, batch loss = 0.37 (276.3 examples/sec; 0.029 sec/batch; 0h:55m:05s remains)
INFO - root - 2022-02-24 20:14:23.547203: step 85330, total loss = 0.52, batch loss = 0.25 (136.8 examples/sec; 0.058 sec/batch; 1h:51m:17s remains)
INFO - root - 2022-02-24 20:14:23.898157: step 85340, total loss = 0.51, batch loss = 0.24 (344.7 examples/sec; 0.023 sec/batch; 0h:44m:09s remains)
INFO - root - 2022-02-24 20:14:24.207666: step 85350, total loss = 0.61, batch loss = 0.34 (314.9 examples/sec; 0.025 sec/batch; 0h:48m:20s remains)
INFO - root - 2022-02-24 20:14:24.682139: step 85360, total loss = 0.59, batch loss = 0.33 (291.1 examples/sec; 0.027 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:14:25.094763: step 85370, total loss = 0.55, batch loss = 0.29 (220.1 examples/sec; 0.036 sec/batch; 1h:09m:08s remains)
INFO - root - 2022-02-24 20:14:25.559925: step 85380, total loss = 0.64, batch loss = 0.38 (282.0 examples/sec; 0.028 sec/batch; 0h:53m:57s remains)
INFO - root - 2022-02-24 20:14:26.054452: step 85390, total loss = 0.51, batch loss = 0.24 (324.8 examples/sec; 0.025 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:14:26.497889: step 85400, total loss = 0.51, batch loss = 0.25 (56.8 examples/sec; 0.141 sec/batch; 4h:27m:55s remains)
INFO - root - 2022-02-24 20:14:27.010817: step 85410, total loss = 0.63, batch loss = 0.36 (185.8 examples/sec; 0.043 sec/batch; 1h:21m:51s remains)
INFO - root - 2022-02-24 20:14:27.401444: step 85420, total loss = 0.50, batch loss = 0.23 (270.0 examples/sec; 0.030 sec/batch; 0h:56m:19s remains)
INFO - root - 2022-02-24 20:14:27.746004: step 85430, total loss = 0.68, batch loss = 0.42 (293.3 examples/sec; 0.027 sec/batch; 0h:51m:51s remains)
INFO - root - 2022-02-24 20:14:28.244360: step 85440, total loss = 0.43, batch loss = 0.17 (157.0 examples/sec; 0.051 sec/batch; 1h:36m:53s remains)
INFO - root - 2022-02-24 20:14:28.575605: step 85450, total loss = 0.56, batch loss = 0.29 (320.7 examples/sec; 0.025 sec/batch; 0h:47m:25s remains)
INFO - root - 2022-02-24 20:14:28.997785: step 85460, total loss = 0.54, batch loss = 0.27 (258.1 examples/sec; 0.031 sec/batch; 0h:58m:55s remains)
INFO - root - 2022-02-24 20:14:29.829933: step 85470, total loss = 0.56, batch loss = 0.30 (188.1 examples/sec; 0.043 sec/batch; 1h:20m:49s remains)
INFO - root - 2022-02-24 20:14:30.177835: step 85480, total loss = 0.60, batch loss = 0.33 (216.2 examples/sec; 0.037 sec/batch; 1h:10m:19s remains)
INFO - root - 2022-02-24 20:14:30.691897: step 85490, total loss = 0.72, batch loss = 0.45 (272.3 examples/sec; 0.029 sec/batch; 0h:55m:49s remains)
INFO - root - 2022-02-24 20:14:31.087106: step 85500, total loss = 0.55, batch loss = 0.28 (305.5 examples/sec; 0.026 sec/batch; 0h:49m:45s remains)
INFO - root - 2022-02-24 20:14:31.525452: step 85510, total loss = 0.59, batch loss = 0.33 (338.4 examples/sec; 0.024 sec/batch; 0h:44m:55s remains)
INFO - root - 2022-02-24 20:14:31.990585: step 85520, total loss = 0.50, batch loss = 0.24 (239.2 examples/sec; 0.033 sec/batch; 1h:03m:32s remains)
INFO - root - 2022-02-24 20:14:32.379867: step 85530, total loss = 0.61, batch loss = 0.35 (275.4 examples/sec; 0.029 sec/batch; 0h:55m:10s remains)
INFO - root - 2022-02-24 20:14:32.778528: step 85540, total loss = 0.59, batch loss = 0.33 (247.6 examples/sec; 0.032 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 20:14:33.232655: step 85550, total loss = 0.62, batch loss = 0.35 (188.2 examples/sec; 0.043 sec/batch; 1h:20m:44s remains)
INFO - root - 2022-02-24 20:14:33.773766: step 85560, total loss = 0.52, batch loss = 0.25 (286.0 examples/sec; 0.028 sec/batch; 0h:53m:07s remains)
INFO - root - 2022-02-24 20:14:34.165672: step 85570, total loss = 0.51, batch loss = 0.24 (256.7 examples/sec; 0.031 sec/batch; 0h:59m:10s remains)
INFO - root - 2022-02-24 20:14:34.449653: step 85580, total loss = 0.52, batch loss = 0.26 (316.2 examples/sec; 0.025 sec/batch; 0h:48m:02s remains)
INFO - root - 2022-02-24 20:14:34.762886: step 85590, total loss = 0.53, batch loss = 0.26 (178.6 examples/sec; 0.045 sec/batch; 1h:25m:01s remains)
INFO - root - 2022-02-24 20:14:35.149548: step 85600, total loss = 0.57, batch loss = 0.30 (162.2 examples/sec; 0.049 sec/batch; 1h:33m:37s remains)
INFO - root - 2022-02-24 20:14:35.550509: step 85610, total loss = 0.55, batch loss = 0.28 (112.2 examples/sec; 0.071 sec/batch; 2h:15m:17s remains)
INFO - root - 2022-02-24 20:14:35.981383: step 85620, total loss = 0.62, batch loss = 0.35 (165.8 examples/sec; 0.048 sec/batch; 1h:31m:36s remains)
INFO - root - 2022-02-24 20:14:36.325481: step 85630, total loss = 0.50, batch loss = 0.23 (365.1 examples/sec; 0.022 sec/batch; 0h:41m:35s remains)
INFO - root - 2022-02-24 20:14:36.638623: step 85640, total loss = 0.60, batch loss = 0.33 (219.7 examples/sec; 0.036 sec/batch; 1h:09m:05s remains)
INFO - root - 2022-02-24 20:14:36.990306: step 85650, total loss = 0.69, batch loss = 0.42 (247.6 examples/sec; 0.032 sec/batch; 1h:01m:18s remains)
INFO - root - 2022-02-24 20:14:37.360500: step 85660, total loss = 0.52, batch loss = 0.25 (197.5 examples/sec; 0.041 sec/batch; 1h:16m:51s remains)
INFO - root - 2022-02-24 20:14:37.731286: step 85670, total loss = 0.63, batch loss = 0.37 (294.4 examples/sec; 0.027 sec/batch; 0h:51m:33s remains)
INFO - root - 2022-02-24 20:14:38.066542: step 85680, total loss = 0.71, batch loss = 0.45 (275.8 examples/sec; 0.029 sec/batch; 0h:55m:01s remains)
INFO - root - 2022-02-24 20:14:38.368636: step 85690, total loss = 0.56, batch loss = 0.29 (158.0 examples/sec; 0.051 sec/batch; 1h:36m:01s remains)
INFO - root - 2022-02-24 20:14:38.700309: step 85700, total loss = 0.62, batch loss = 0.35 (253.4 examples/sec; 0.032 sec/batch; 0h:59m:52s remains)
INFO - root - 2022-02-24 20:14:39.098263: step 85710, total loss = 0.59, batch loss = 0.32 (359.2 examples/sec; 0.022 sec/batch; 0h:42m:14s remains)
INFO - root - 2022-02-24 20:14:39.557783: step 85720, total loss = 0.53, batch loss = 0.26 (356.1 examples/sec; 0.022 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 20:14:39.920017: step 85730, total loss = 0.55, batch loss = 0.28 (247.6 examples/sec; 0.032 sec/batch; 1h:01m:16s remains)
INFO - root - 2022-02-24 20:14:40.229575: step 85740, total loss = 0.55, batch loss = 0.29 (364.0 examples/sec; 0.022 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:14:40.511260: step 85750, total loss = 0.64, batch loss = 0.38 (287.5 examples/sec; 0.028 sec/batch; 0h:52m:45s remains)
INFO - root - 2022-02-24 20:14:40.804998: step 85760, total loss = 0.58, batch loss = 0.31 (318.4 examples/sec; 0.025 sec/batch; 0h:47m:38s remains)
INFO - root - 2022-02-24 20:14:41.192147: step 85770, total loss = 0.50, batch loss = 0.23 (237.6 examples/sec; 0.034 sec/batch; 1h:03m:48s remains)
INFO - root - 2022-02-24 20:14:41.550643: step 85780, total loss = 0.56, batch loss = 0.29 (307.4 examples/sec; 0.026 sec/batch; 0h:49m:19s remains)
INFO - root - 2022-02-24 20:14:41.881675: step 85790, total loss = 0.52, batch loss = 0.25 (347.9 examples/sec; 0.023 sec/batch; 0h:43m:34s remains)
INFO - root - 2022-02-24 20:14:42.163747: step 85800, total loss = 0.59, batch loss = 0.32 (308.5 examples/sec; 0.026 sec/batch; 0h:49m:08s remains)
INFO - root - 2022-02-24 20:14:42.525945: step 85810, total loss = 0.59, batch loss = 0.32 (325.4 examples/sec; 0.025 sec/batch; 0h:46m:34s remains)
INFO - root - 2022-02-24 20:14:42.772989: step 85820, total loss = 0.51, batch loss = 0.24 (361.4 examples/sec; 0.022 sec/batch; 0h:41m:56s remains)
INFO - root - 2022-02-24 20:14:43.040288: step 85830, total loss = 0.59, batch loss = 0.32 (302.5 examples/sec; 0.026 sec/batch; 0h:50m:06s remains)
INFO - root - 2022-02-24 20:14:43.409252: step 85840, total loss = 0.57, batch loss = 0.31 (275.9 examples/sec; 0.029 sec/batch; 0h:54m:55s remains)
INFO - root - 2022-02-24 20:14:43.871764: step 85850, total loss = 0.56, batch loss = 0.29 (182.3 examples/sec; 0.044 sec/batch; 1h:23m:06s remains)
INFO - root - 2022-02-24 20:14:44.149970: step 85860, total loss = 0.62, batch loss = 0.35 (304.6 examples/sec; 0.026 sec/batch; 0h:49m:44s remains)
INFO - root - 2022-02-24 20:14:44.434927: step 85870, total loss = 0.50, batch loss = 0.24 (319.5 examples/sec; 0.025 sec/batch; 0h:47m:24s remains)
INFO - root - 2022-02-24 20:14:44.754602: step 85880, total loss = 0.48, batch loss = 0.22 (351.0 examples/sec; 0.023 sec/batch; 0h:43m:09s remains)
INFO - root - 2022-02-24 20:14:45.140214: step 85890, total loss = 0.51, batch loss = 0.25 (112.1 examples/sec; 0.071 sec/batch; 2h:15m:06s remains)
INFO - root - 2022-02-24 20:14:45.473026: step 85900, total loss = 0.57, batch loss = 0.30 (223.0 examples/sec; 0.036 sec/batch; 1h:07m:55s remains)
INFO - root - 2022-02-24 20:14:45.946148: step 85910, total loss = 0.55, batch loss = 0.29 (83.9 examples/sec; 0.095 sec/batch; 3h:00m:26s remains)
INFO - root - 2022-02-24 20:14:46.262904: step 85920, total loss = 0.51, batch loss = 0.25 (311.8 examples/sec; 0.026 sec/batch; 0h:48m:33s remains)
INFO - root - 2022-02-24 20:14:46.754863: step 85930, total loss = 0.65, batch loss = 0.39 (79.5 examples/sec; 0.101 sec/batch; 3h:10m:30s remains)
INFO - root - 2022-02-24 20:14:47.292704: step 85940, total loss = 0.60, batch loss = 0.34 (148.2 examples/sec; 0.054 sec/batch; 1h:42m:10s remains)
INFO - root - 2022-02-24 20:14:47.847495: step 85950, total loss = 0.54, batch loss = 0.27 (309.4 examples/sec; 0.026 sec/batch; 0h:48m:55s remains)
INFO - root - 2022-02-24 20:14:48.392436: step 85960, total loss = 0.57, batch loss = 0.31 (145.5 examples/sec; 0.055 sec/batch; 1h:44m:02s remains)
INFO - root - 2022-02-24 20:14:49.299236: step 85970, total loss = 0.60, batch loss = 0.33 (251.6 examples/sec; 0.032 sec/batch; 1h:00m:10s remains)
INFO - root - 2022-02-24 20:14:49.789512: step 85980, total loss = 0.59, batch loss = 0.32 (192.1 examples/sec; 0.042 sec/batch; 1h:18m:48s remains)
INFO - root - 2022-02-24 20:14:50.250686: step 85990, total loss = 0.62, batch loss = 0.35 (226.2 examples/sec; 0.035 sec/batch; 1h:06m:54s remains)
INFO - root - 2022-02-24 20:14:50.589235: step 86000, total loss = 0.57, batch loss = 0.30 (244.6 examples/sec; 0.033 sec/batch; 1h:01m:51s remains)
INFO - root - 2022-02-24 20:14:51.038076: step 86010, total loss = 0.55, batch loss = 0.29 (286.3 examples/sec; 0.028 sec/batch; 0h:52m:51s remains)
INFO - root - 2022-02-24 20:14:51.270366: step 86020, total loss = 0.56, batch loss = 0.29 (308.5 examples/sec; 0.026 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:14:51.575772: step 86030, total loss = 0.59, batch loss = 0.32 (277.0 examples/sec; 0.029 sec/batch; 0h:54m:36s remains)
INFO - root - 2022-02-24 20:14:52.035555: step 86040, total loss = 0.58, batch loss = 0.31 (176.2 examples/sec; 0.045 sec/batch; 1h:25m:50s remains)
INFO - root - 2022-02-24 20:14:52.454269: step 86050, total loss = 0.57, batch loss = 0.30 (139.2 examples/sec; 0.057 sec/batch; 1h:48m:40s remains)
INFO - root - 2022-02-24 20:14:52.870614: step 86060, total loss = 0.56, batch loss = 0.30 (348.9 examples/sec; 0.023 sec/batch; 0h:43m:21s remains)
INFO - root - 2022-02-24 20:14:53.168846: step 86070, total loss = 0.51, batch loss = 0.24 (205.3 examples/sec; 0.039 sec/batch; 1h:13m:40s remains)
INFO - root - 2022-02-24 20:14:53.482663: step 86080, total loss = 0.43, batch loss = 0.17 (299.1 examples/sec; 0.027 sec/batch; 0h:50m:34s remains)
INFO - root - 2022-02-24 20:14:53.791741: step 86090, total loss = 0.52, batch loss = 0.26 (321.3 examples/sec; 0.025 sec/batch; 0h:47m:03s remains)
INFO - root - 2022-02-24 20:14:54.154708: step 86100, total loss = 0.68, batch loss = 0.42 (145.3 examples/sec; 0.055 sec/batch; 1h:44m:01s remains)
INFO - root - 2022-02-24 20:14:54.611179: step 86110, total loss = 0.66, batch loss = 0.39 (224.5 examples/sec; 0.036 sec/batch; 1h:07m:20s remains)
INFO - root - 2022-02-24 20:14:55.003733: step 86120, total loss = 0.53, batch loss = 0.27 (208.0 examples/sec; 0.038 sec/batch; 1h:12m:41s remains)
INFO - root - 2022-02-24 20:14:55.271427: step 86130, total loss = 0.61, batch loss = 0.35 (183.6 examples/sec; 0.044 sec/batch; 1h:22m:19s remains)
INFO - root - 2022-02-24 20:14:55.605620: step 86140, total loss = 0.60, batch loss = 0.33 (222.8 examples/sec; 0.036 sec/batch; 1h:07m:49s remains)
INFO - root - 2022-02-24 20:14:55.948953: step 86150, total loss = 0.57, batch loss = 0.30 (195.4 examples/sec; 0.041 sec/batch; 1h:17m:20s remains)
INFO - root - 2022-02-24 20:14:56.368296: step 86160, total loss = 0.46, batch loss = 0.19 (331.5 examples/sec; 0.024 sec/batch; 0h:45m:35s remains)
INFO - root - 2022-02-24 20:14:56.789333: step 86170, total loss = 0.55, batch loss = 0.29 (210.5 examples/sec; 0.038 sec/batch; 1h:11m:48s remains)
INFO - root - 2022-02-24 20:14:57.210822: step 86180, total loss = 0.59, batch loss = 0.32 (210.0 examples/sec; 0.038 sec/batch; 1h:11m:57s remains)
INFO - root - 2022-02-24 20:14:57.546527: step 86190, total loss = 0.69, batch loss = 0.43 (348.6 examples/sec; 0.023 sec/batch; 0h:43m:20s remains)
INFO - root - 2022-02-24 20:14:57.869509: step 86200, total loss = 0.54, batch loss = 0.27 (319.5 examples/sec; 0.025 sec/batch; 0h:47m:17s remains)
INFO - root - 2022-02-24 20:14:58.219742: step 86210, total loss = 0.73, batch loss = 0.46 (341.0 examples/sec; 0.023 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:14:58.478232: step 86220, total loss = 0.57, batch loss = 0.30 (291.4 examples/sec; 0.027 sec/batch; 0h:51m:49s remains)
INFO - root - 2022-02-24 20:14:58.997737: step 86230, total loss = 0.59, batch loss = 0.32 (165.5 examples/sec; 0.048 sec/batch; 1h:31m:13s remains)
INFO - root - 2022-02-24 20:14:59.365231: step 86240, total loss = 0.56, batch loss = 0.29 (316.3 examples/sec; 0.025 sec/batch; 0h:47m:44s remains)
INFO - root - 2022-02-24 20:14:59.733908: step 86250, total loss = 0.53, batch loss = 0.26 (341.1 examples/sec; 0.023 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:15:00.020145: step 86260, total loss = 0.60, batch loss = 0.33 (282.2 examples/sec; 0.028 sec/batch; 0h:53m:29s remains)
INFO - root - 2022-02-24 20:15:00.323106: step 86270, total loss = 0.51, batch loss = 0.24 (185.2 examples/sec; 0.043 sec/batch; 1h:21m:29s remains)
INFO - root - 2022-02-24 20:15:00.626646: step 86280, total loss = 0.53, batch loss = 0.27 (244.3 examples/sec; 0.033 sec/batch; 1h:01m:46s remains)
INFO - root - 2022-02-24 20:15:00.979271: step 86290, total loss = 0.68, batch loss = 0.41 (353.7 examples/sec; 0.023 sec/batch; 0h:42m:40s remains)
INFO - root - 2022-02-24 20:15:01.404899: step 86300, total loss = 0.58, batch loss = 0.31 (352.1 examples/sec; 0.023 sec/batch; 0h:42m:51s remains)
INFO - root - 2022-02-24 20:15:01.784921: step 86310, total loss = 0.62, batch loss = 0.36 (345.2 examples/sec; 0.023 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:15:02.076985: step 86320, total loss = 0.49, batch loss = 0.22 (377.8 examples/sec; 0.021 sec/batch; 0h:39m:56s remains)
INFO - root - 2022-02-24 20:15:02.383937: step 86330, total loss = 0.66, batch loss = 0.39 (227.0 examples/sec; 0.035 sec/batch; 1h:06m:28s remains)
INFO - root - 2022-02-24 20:15:02.749451: step 86340, total loss = 0.48, batch loss = 0.21 (200.0 examples/sec; 0.040 sec/batch; 1h:15m:25s remains)
INFO - root - 2022-02-24 20:15:03.106665: step 86350, total loss = 0.55, batch loss = 0.29 (260.1 examples/sec; 0.031 sec/batch; 0h:57m:59s remains)
INFO - root - 2022-02-24 20:15:03.469300: step 86360, total loss = 0.53, batch loss = 0.27 (324.4 examples/sec; 0.025 sec/batch; 0h:46m:30s remains)
INFO - root - 2022-02-24 20:15:03.878073: step 86370, total loss = 0.57, batch loss = 0.30 (221.1 examples/sec; 0.036 sec/batch; 1h:08m:12s remains)
INFO - root - 2022-02-24 20:15:04.486014: step 86380, total loss = 0.55, batch loss = 0.28 (306.4 examples/sec; 0.026 sec/batch; 0h:49m:13s remains)
INFO - root - 2022-02-24 20:15:05.009924: step 86390, total loss = 0.50, batch loss = 0.24 (249.7 examples/sec; 0.032 sec/batch; 1h:00m:24s remains)
INFO - root - 2022-02-24 20:15:05.587997: step 86400, total loss = 0.50, batch loss = 0.23 (95.0 examples/sec; 0.084 sec/batch; 2h:38m:49s remains)
INFO - root - 2022-02-24 20:15:06.004039: step 86410, total loss = 0.56, batch loss = 0.30 (106.2 examples/sec; 0.075 sec/batch; 2h:22m:00s remains)
INFO - root - 2022-02-24 20:15:06.919101: step 86420, total loss = 0.52, batch loss = 0.25 (349.8 examples/sec; 0.023 sec/batch; 0h:43m:06s remains)
INFO - root - 2022-02-24 20:15:07.282994: step 86430, total loss = 0.74, batch loss = 0.48 (141.9 examples/sec; 0.056 sec/batch; 1h:46m:12s remains)
INFO - root - 2022-02-24 20:15:07.688659: step 86440, total loss = 0.63, batch loss = 0.36 (226.4 examples/sec; 0.035 sec/batch; 1h:06m:35s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-86449 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-86449 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:15:08.338693: step 86450, total loss = 0.61, batch loss = 0.34 (325.0 examples/sec; 0.025 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:15:08.587021: step 86460, total loss = 0.50, batch loss = 0.23 (332.4 examples/sec; 0.024 sec/batch; 0h:45m:20s remains)
INFO - root - 2022-02-24 20:15:08.893055: step 86470, total loss = 0.58, batch loss = 0.31 (310.6 examples/sec; 0.026 sec/batch; 0h:48m:31s remains)
INFO - root - 2022-02-24 20:15:09.322249: step 86480, total loss = 0.55, batch loss = 0.29 (301.9 examples/sec; 0.026 sec/batch; 0h:49m:54s remains)
INFO - root - 2022-02-24 20:15:09.685220: step 86490, total loss = 0.53, batch loss = 0.26 (310.1 examples/sec; 0.026 sec/batch; 0h:48m:35s remains)
INFO - root - 2022-02-24 20:15:09.987257: step 86500, total loss = 0.56, batch loss = 0.30 (352.6 examples/sec; 0.023 sec/batch; 0h:42m:43s remains)
INFO - root - 2022-02-24 20:15:10.369413: step 86510, total loss = 0.51, batch loss = 0.24 (271.4 examples/sec; 0.029 sec/batch; 0h:55m:30s remains)
INFO - root - 2022-02-24 20:15:10.649129: step 86520, total loss = 0.64, batch loss = 0.37 (316.2 examples/sec; 0.025 sec/batch; 0h:47m:38s remains)
INFO - root - 2022-02-24 20:15:11.020707: step 86530, total loss = 0.53, batch loss = 0.26 (289.5 examples/sec; 0.028 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:15:11.373158: step 86540, total loss = 0.54, batch loss = 0.28 (106.5 examples/sec; 0.075 sec/batch; 2h:21m:28s remains)
INFO - root - 2022-02-24 20:15:11.786283: step 86550, total loss = 0.59, batch loss = 0.32 (393.4 examples/sec; 0.020 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 20:15:12.072553: step 86560, total loss = 0.44, batch loss = 0.17 (329.1 examples/sec; 0.024 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:15:12.398520: step 86570, total loss = 0.59, batch loss = 0.33 (176.2 examples/sec; 0.045 sec/batch; 1h:25m:28s remains)
INFO - root - 2022-02-24 20:15:12.764392: step 86580, total loss = 0.53, batch loss = 0.27 (321.0 examples/sec; 0.025 sec/batch; 0h:46m:53s remains)
INFO - root - 2022-02-24 20:15:13.163566: step 86590, total loss = 0.63, batch loss = 0.37 (245.3 examples/sec; 0.033 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 20:15:13.532011: step 86600, total loss = 0.50, batch loss = 0.23 (342.4 examples/sec; 0.023 sec/batch; 0h:43m:57s remains)
INFO - root - 2022-02-24 20:15:14.204081: step 86610, total loss = 0.61, batch loss = 0.34 (225.0 examples/sec; 0.036 sec/batch; 1h:06m:53s remains)
INFO - root - 2022-02-24 20:15:15.339268: step 86620, total loss = 0.61, batch loss = 0.35 (268.0 examples/sec; 0.030 sec/batch; 0h:56m:09s remains)
INFO - root - 2022-02-24 20:15:15.958242: step 86630, total loss = 0.60, batch loss = 0.33 (140.5 examples/sec; 0.057 sec/batch; 1h:47m:09s remains)
INFO - root - 2022-02-24 20:15:16.787668: step 86640, total loss = 0.54, batch loss = 0.28 (48.0 examples/sec; 0.167 sec/batch; 5h:13m:42s remains)
INFO - root - 2022-02-24 20:15:17.223284: step 86650, total loss = 0.53, batch loss = 0.27 (202.0 examples/sec; 0.040 sec/batch; 1h:14m:29s remains)
INFO - root - 2022-02-24 20:15:17.692834: step 86660, total loss = 0.62, batch loss = 0.35 (109.8 examples/sec; 0.073 sec/batch; 2h:17m:03s remains)
INFO - root - 2022-02-24 20:15:18.074811: step 86670, total loss = 0.55, batch loss = 0.28 (307.0 examples/sec; 0.026 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 20:15:18.452079: step 86680, total loss = 0.55, batch loss = 0.29 (187.3 examples/sec; 0.043 sec/batch; 1h:20m:17s remains)
INFO - root - 2022-02-24 20:15:18.809166: step 86690, total loss = 0.49, batch loss = 0.23 (270.0 examples/sec; 0.030 sec/batch; 0h:55m:42s remains)
INFO - root - 2022-02-24 20:15:19.111926: step 86700, total loss = 0.53, batch loss = 0.27 (357.2 examples/sec; 0.022 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 20:15:19.451984: step 86710, total loss = 0.77, batch loss = 0.50 (224.3 examples/sec; 0.036 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:15:19.846766: step 86720, total loss = 0.54, batch loss = 0.28 (148.5 examples/sec; 0.054 sec/batch; 1h:41m:14s remains)
INFO - root - 2022-02-24 20:15:20.245637: step 86730, total loss = 0.54, batch loss = 0.27 (197.4 examples/sec; 0.041 sec/batch; 1h:16m:10s remains)
INFO - root - 2022-02-24 20:15:20.605897: step 86740, total loss = 0.60, batch loss = 0.33 (324.1 examples/sec; 0.025 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:15:20.926534: step 86750, total loss = 0.50, batch loss = 0.24 (318.2 examples/sec; 0.025 sec/batch; 0h:47m:14s remains)
INFO - root - 2022-02-24 20:15:21.221025: step 86760, total loss = 0.55, batch loss = 0.28 (268.8 examples/sec; 0.030 sec/batch; 0h:55m:55s remains)
INFO - root - 2022-02-24 20:15:21.592065: step 86770, total loss = 0.57, batch loss = 0.31 (117.7 examples/sec; 0.068 sec/batch; 2h:07m:45s remains)
INFO - root - 2022-02-24 20:15:22.012548: step 86780, total loss = 0.54, batch loss = 0.28 (202.9 examples/sec; 0.039 sec/batch; 1h:14m:05s remains)
INFO - root - 2022-02-24 20:15:22.326837: step 86790, total loss = 0.54, batch loss = 0.27 (327.7 examples/sec; 0.024 sec/batch; 0h:45m:51s remains)
INFO - root - 2022-02-24 20:15:22.620945: step 86800, total loss = 0.63, batch loss = 0.36 (169.5 examples/sec; 0.047 sec/batch; 1h:28m:39s remains)
INFO - root - 2022-02-24 20:15:22.954445: step 86810, total loss = 0.57, batch loss = 0.30 (340.5 examples/sec; 0.023 sec/batch; 0h:44m:07s remains)
INFO - root - 2022-02-24 20:15:23.331028: step 86820, total loss = 0.60, batch loss = 0.33 (142.9 examples/sec; 0.056 sec/batch; 1h:45m:06s remains)
INFO - root - 2022-02-24 20:15:23.665086: step 86830, total loss = 0.56, batch loss = 0.30 (176.9 examples/sec; 0.045 sec/batch; 1h:24m:54s remains)
INFO - root - 2022-02-24 20:15:24.057063: step 86840, total loss = 0.52, batch loss = 0.26 (293.9 examples/sec; 0.027 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:15:24.476045: step 86850, total loss = 0.52, batch loss = 0.25 (151.7 examples/sec; 0.053 sec/batch; 1h:39m:01s remains)
INFO - root - 2022-02-24 20:15:24.765355: step 86860, total loss = 0.59, batch loss = 0.33 (324.8 examples/sec; 0.025 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 20:15:25.096063: step 86870, total loss = 0.53, batch loss = 0.26 (133.7 examples/sec; 0.060 sec/batch; 1h:52m:19s remains)
INFO - root - 2022-02-24 20:15:25.465906: step 86880, total loss = 0.73, batch loss = 0.47 (345.8 examples/sec; 0.023 sec/batch; 0h:43m:25s remains)
INFO - root - 2022-02-24 20:15:25.846044: step 86890, total loss = 0.51, batch loss = 0.25 (202.7 examples/sec; 0.039 sec/batch; 1h:14m:04s remains)
INFO - root - 2022-02-24 20:15:26.346301: step 86900, total loss = 0.51, batch loss = 0.25 (211.7 examples/sec; 0.038 sec/batch; 1h:10m:54s remains)
INFO - root - 2022-02-24 20:15:26.716955: step 86910, total loss = 0.58, batch loss = 0.31 (338.0 examples/sec; 0.024 sec/batch; 0h:44m:24s remains)
INFO - root - 2022-02-24 20:15:27.048277: step 86920, total loss = 0.61, batch loss = 0.35 (100.6 examples/sec; 0.080 sec/batch; 2h:29m:13s remains)
INFO - root - 2022-02-24 20:15:27.352734: step 86930, total loss = 0.56, batch loss = 0.29 (322.4 examples/sec; 0.025 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:15:27.641619: step 86940, total loss = 0.52, batch loss = 0.25 (259.8 examples/sec; 0.031 sec/batch; 0h:57m:46s remains)
INFO - root - 2022-02-24 20:15:27.987441: step 86950, total loss = 0.63, batch loss = 0.36 (107.6 examples/sec; 0.074 sec/batch; 2h:19m:28s remains)
INFO - root - 2022-02-24 20:15:28.454001: step 86960, total loss = 0.53, batch loss = 0.26 (220.3 examples/sec; 0.036 sec/batch; 1h:08m:06s remains)
INFO - root - 2022-02-24 20:15:28.687548: step 86970, total loss = 0.56, batch loss = 0.29 (318.5 examples/sec; 0.025 sec/batch; 0h:47m:06s remains)
INFO - root - 2022-02-24 20:15:28.947051: step 86980, total loss = 0.60, batch loss = 0.33 (362.7 examples/sec; 0.022 sec/batch; 0h:41m:21s remains)
INFO - root - 2022-02-24 20:15:29.251089: step 86990, total loss = 0.53, batch loss = 0.27 (349.4 examples/sec; 0.023 sec/batch; 0h:42m:56s remains)
INFO - root - 2022-02-24 20:15:29.531894: step 87000, total loss = 0.66, batch loss = 0.39 (321.7 examples/sec; 0.025 sec/batch; 0h:46m:37s remains)
INFO - root - 2022-02-24 20:15:29.958546: step 87010, total loss = 0.63, batch loss = 0.37 (214.3 examples/sec; 0.037 sec/batch; 1h:09m:59s remains)
INFO - root - 2022-02-24 20:15:30.409398: step 87020, total loss = 0.57, batch loss = 0.30 (245.1 examples/sec; 0.033 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 20:15:30.821867: step 87030, total loss = 0.51, batch loss = 0.24 (143.4 examples/sec; 0.056 sec/batch; 1h:44m:32s remains)
INFO - root - 2022-02-24 20:15:31.152960: step 87040, total loss = 0.58, batch loss = 0.32 (294.6 examples/sec; 0.027 sec/batch; 0h:50m:53s remains)
INFO - root - 2022-02-24 20:15:31.453322: step 87050, total loss = 0.55, batch loss = 0.29 (384.6 examples/sec; 0.021 sec/batch; 0h:38m:59s remains)
INFO - root - 2022-02-24 20:15:31.787434: step 87060, total loss = 0.51, batch loss = 0.24 (236.5 examples/sec; 0.034 sec/batch; 1h:03m:24s remains)
INFO - root - 2022-02-24 20:15:32.154045: step 87070, total loss = 0.53, batch loss = 0.26 (369.1 examples/sec; 0.022 sec/batch; 0h:40m:36s remains)
INFO - root - 2022-02-24 20:15:32.554950: step 87080, total loss = 0.62, batch loss = 0.35 (361.2 examples/sec; 0.022 sec/batch; 0h:41m:29s remains)
INFO - root - 2022-02-24 20:15:32.896643: step 87090, total loss = 0.58, batch loss = 0.31 (327.6 examples/sec; 0.024 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:15:33.224177: step 87100, total loss = 0.58, batch loss = 0.32 (336.3 examples/sec; 0.024 sec/batch; 0h:44m:33s remains)
INFO - root - 2022-02-24 20:15:33.577896: step 87110, total loss = 0.60, batch loss = 0.33 (255.5 examples/sec; 0.031 sec/batch; 0h:58m:38s remains)
INFO - root - 2022-02-24 20:15:33.896717: step 87120, total loss = 0.60, batch loss = 0.33 (231.8 examples/sec; 0.035 sec/batch; 1h:04m:38s remains)
INFO - root - 2022-02-24 20:15:34.307056: step 87130, total loss = 0.55, batch loss = 0.28 (148.9 examples/sec; 0.054 sec/batch; 1h:40m:38s remains)
INFO - root - 2022-02-24 20:15:34.652750: step 87140, total loss = 0.44, batch loss = 0.17 (351.3 examples/sec; 0.023 sec/batch; 0h:42m:38s remains)
INFO - root - 2022-02-24 20:15:34.974941: step 87150, total loss = 0.54, batch loss = 0.27 (300.5 examples/sec; 0.027 sec/batch; 0h:49m:50s remains)
INFO - root - 2022-02-24 20:15:35.350230: step 87160, total loss = 0.57, batch loss = 0.30 (317.5 examples/sec; 0.025 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:15:35.652905: step 87170, total loss = 0.57, batch loss = 0.30 (324.0 examples/sec; 0.025 sec/batch; 0h:46m:13s remains)
INFO - root - 2022-02-24 20:15:35.992521: step 87180, total loss = 0.54, batch loss = 0.28 (206.6 examples/sec; 0.039 sec/batch; 1h:12m:30s remains)
INFO - root - 2022-02-24 20:15:36.368727: step 87190, total loss = 0.61, batch loss = 0.34 (370.8 examples/sec; 0.022 sec/batch; 0h:40m:23s remains)
INFO - root - 2022-02-24 20:15:36.727434: step 87200, total loss = 0.64, batch loss = 0.37 (259.0 examples/sec; 0.031 sec/batch; 0h:57m:48s remains)
INFO - root - 2022-02-24 20:15:37.167172: step 87210, total loss = 0.59, batch loss = 0.32 (249.3 examples/sec; 0.032 sec/batch; 1h:00m:02s remains)
INFO - root - 2022-02-24 20:15:37.637537: step 87220, total loss = 0.52, batch loss = 0.26 (68.0 examples/sec; 0.118 sec/batch; 3h:40m:18s remains)
INFO - root - 2022-02-24 20:15:38.193751: step 87230, total loss = 0.53, batch loss = 0.27 (137.3 examples/sec; 0.058 sec/batch; 1h:49m:01s remains)
INFO - root - 2022-02-24 20:15:38.633370: step 87240, total loss = 0.60, batch loss = 0.34 (101.1 examples/sec; 0.079 sec/batch; 2h:28m:00s remains)
INFO - root - 2022-02-24 20:15:38.994688: step 87250, total loss = 0.55, batch loss = 0.28 (194.1 examples/sec; 0.041 sec/batch; 1h:17m:06s remains)
INFO - root - 2022-02-24 20:15:39.411986: step 87260, total loss = 0.51, batch loss = 0.24 (125.1 examples/sec; 0.064 sec/batch; 1h:59m:39s remains)
INFO - root - 2022-02-24 20:15:39.738998: step 87270, total loss = 0.57, batch loss = 0.31 (161.5 examples/sec; 0.050 sec/batch; 1h:32m:39s remains)
INFO - root - 2022-02-24 20:15:40.209105: step 87280, total loss = 0.64, batch loss = 0.37 (99.0 examples/sec; 0.081 sec/batch; 2h:31m:05s remains)
INFO - root - 2022-02-24 20:15:41.050267: step 87290, total loss = 0.60, batch loss = 0.33 (388.3 examples/sec; 0.021 sec/batch; 0h:38m:32s remains)
INFO - root - 2022-02-24 20:15:41.432594: step 87300, total loss = 0.59, batch loss = 0.32 (346.7 examples/sec; 0.023 sec/batch; 0h:43m:09s remains)
INFO - root - 2022-02-24 20:15:41.821464: step 87310, total loss = 0.55, batch loss = 0.29 (134.2 examples/sec; 0.060 sec/batch; 1h:51m:25s remains)
INFO - root - 2022-02-24 20:15:42.144212: step 87320, total loss = 0.55, batch loss = 0.29 (212.5 examples/sec; 0.038 sec/batch; 1h:10m:22s remains)
INFO - root - 2022-02-24 20:15:42.549461: step 87330, total loss = 0.60, batch loss = 0.33 (125.7 examples/sec; 0.064 sec/batch; 1h:59m:01s remains)
INFO - root - 2022-02-24 20:15:43.027075: step 87340, total loss = 0.54, batch loss = 0.27 (151.4 examples/sec; 0.053 sec/batch; 1h:38m:47s remains)
INFO - root - 2022-02-24 20:15:43.430704: step 87350, total loss = 0.54, batch loss = 0.27 (300.0 examples/sec; 0.027 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:15:43.791161: step 87360, total loss = 0.61, batch loss = 0.34 (312.6 examples/sec; 0.026 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:15:44.165438: step 87370, total loss = 0.49, batch loss = 0.22 (337.0 examples/sec; 0.024 sec/batch; 0h:44m:22s remains)
INFO - root - 2022-02-24 20:15:44.479677: step 87380, total loss = 0.58, batch loss = 0.31 (191.1 examples/sec; 0.042 sec/batch; 1h:18m:13s remains)
INFO - root - 2022-02-24 20:15:44.894105: step 87390, total loss = 0.54, batch loss = 0.27 (250.4 examples/sec; 0.032 sec/batch; 0h:59m:42s remains)
INFO - root - 2022-02-24 20:15:45.280415: step 87400, total loss = 0.54, batch loss = 0.28 (236.2 examples/sec; 0.034 sec/batch; 1h:03m:16s remains)
INFO - root - 2022-02-24 20:15:45.723262: step 87410, total loss = 0.52, batch loss = 0.25 (332.2 examples/sec; 0.024 sec/batch; 0h:44m:59s remains)
INFO - root - 2022-02-24 20:15:46.084721: step 87420, total loss = 0.54, batch loss = 0.27 (205.5 examples/sec; 0.039 sec/batch; 1h:12m:42s remains)
INFO - root - 2022-02-24 20:15:46.397688: step 87430, total loss = 0.52, batch loss = 0.26 (371.4 examples/sec; 0.022 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:15:46.695351: step 87440, total loss = 0.53, batch loss = 0.26 (204.0 examples/sec; 0.039 sec/batch; 1h:13m:14s remains)
INFO - root - 2022-02-24 20:15:47.091116: step 87450, total loss = 0.49, batch loss = 0.23 (227.2 examples/sec; 0.035 sec/batch; 1h:05m:46s remains)
INFO - root - 2022-02-24 20:15:47.477787: step 87460, total loss = 0.56, batch loss = 0.30 (154.1 examples/sec; 0.052 sec/batch; 1h:36m:58s remains)
INFO - root - 2022-02-24 20:15:47.752026: step 87470, total loss = 0.51, batch loss = 0.24 (270.7 examples/sec; 0.030 sec/batch; 0h:55m:11s remains)
INFO - root - 2022-02-24 20:15:48.041975: step 87480, total loss = 0.60, batch loss = 0.33 (327.8 examples/sec; 0.024 sec/batch; 0h:45m:33s remains)
INFO - root - 2022-02-24 20:15:48.308431: step 87490, total loss = 0.64, batch loss = 0.37 (305.3 examples/sec; 0.026 sec/batch; 0h:48m:55s remains)
INFO - root - 2022-02-24 20:15:48.630294: step 87500, total loss = 0.45, batch loss = 0.18 (304.6 examples/sec; 0.026 sec/batch; 0h:49m:01s remains)
INFO - root - 2022-02-24 20:15:49.017743: step 87510, total loss = 0.58, batch loss = 0.32 (173.2 examples/sec; 0.046 sec/batch; 1h:26m:11s remains)
INFO - root - 2022-02-24 20:15:49.400684: step 87520, total loss = 0.55, batch loss = 0.29 (190.7 examples/sec; 0.042 sec/batch; 1h:18m:17s remains)
INFO - root - 2022-02-24 20:15:49.757092: step 87530, total loss = 0.59, batch loss = 0.32 (242.7 examples/sec; 0.033 sec/batch; 1h:01m:31s remains)
INFO - root - 2022-02-24 20:15:50.079069: step 87540, total loss = 0.64, batch loss = 0.38 (354.9 examples/sec; 0.023 sec/batch; 0h:42m:03s remains)
INFO - root - 2022-02-24 20:15:50.373942: step 87550, total loss = 0.67, batch loss = 0.41 (321.8 examples/sec; 0.025 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:15:50.680771: step 87560, total loss = 0.54, batch loss = 0.27 (330.4 examples/sec; 0.024 sec/batch; 0h:45m:10s remains)
INFO - root - 2022-02-24 20:15:51.123333: step 87570, total loss = 0.57, batch loss = 0.31 (124.2 examples/sec; 0.064 sec/batch; 2h:00m:08s remains)
INFO - root - 2022-02-24 20:15:51.863541: step 87580, total loss = 0.50, batch loss = 0.23 (166.9 examples/sec; 0.048 sec/batch; 1h:29m:25s remains)
INFO - root - 2022-02-24 20:15:52.205938: step 87590, total loss = 0.60, batch loss = 0.34 (324.7 examples/sec; 0.025 sec/batch; 0h:45m:57s remains)
INFO - root - 2022-02-24 20:15:52.564360: step 87600, total loss = 0.51, batch loss = 0.24 (368.9 examples/sec; 0.022 sec/batch; 0h:40m:26s remains)
INFO - root - 2022-02-24 20:15:52.984894: step 87610, total loss = 0.57, batch loss = 0.30 (138.4 examples/sec; 0.058 sec/batch; 1h:47m:49s remains)
INFO - root - 2022-02-24 20:15:53.273238: step 87620, total loss = 0.54, batch loss = 0.27 (296.0 examples/sec; 0.027 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 20:15:53.694157: step 87630, total loss = 0.63, batch loss = 0.36 (140.6 examples/sec; 0.057 sec/batch; 1h:46m:05s remains)
INFO - root - 2022-02-24 20:15:54.091329: step 87640, total loss = 0.56, batch loss = 0.29 (328.1 examples/sec; 0.024 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:15:54.494385: step 87650, total loss = 0.53, batch loss = 0.27 (340.4 examples/sec; 0.024 sec/batch; 0h:43m:49s remains)
INFO - root - 2022-02-24 20:15:54.793440: step 87660, total loss = 0.49, batch loss = 0.23 (270.3 examples/sec; 0.030 sec/batch; 0h:55m:09s remains)
INFO - root - 2022-02-24 20:15:55.062865: step 87670, total loss = 0.62, batch loss = 0.36 (323.9 examples/sec; 0.025 sec/batch; 0h:46m:02s remains)
INFO - root - 2022-02-24 20:15:55.479012: step 87680, total loss = 0.59, batch loss = 0.32 (171.5 examples/sec; 0.047 sec/batch; 1h:26m:57s remains)
INFO - root - 2022-02-24 20:15:55.862398: step 87690, total loss = 0.60, batch loss = 0.33 (153.4 examples/sec; 0.052 sec/batch; 1h:37m:09s remains)
INFO - root - 2022-02-24 20:15:56.549227: step 87700, total loss = 0.47, batch loss = 0.20 (355.0 examples/sec; 0.023 sec/batch; 0h:41m:59s remains)
INFO - root - 2022-02-24 20:15:56.917600: step 87710, total loss = 0.70, batch loss = 0.43 (324.3 examples/sec; 0.025 sec/batch; 0h:45m:57s remains)
INFO - root - 2022-02-24 20:15:57.207938: step 87720, total loss = 0.50, batch loss = 0.24 (310.9 examples/sec; 0.026 sec/batch; 0h:47m:55s remains)
INFO - root - 2022-02-24 20:15:57.483389: step 87730, total loss = 0.47, batch loss = 0.20 (336.4 examples/sec; 0.024 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:15:57.804251: step 87740, total loss = 0.53, batch loss = 0.27 (163.1 examples/sec; 0.049 sec/batch; 1h:31m:23s remains)
INFO - root - 2022-02-24 20:15:58.256722: step 87750, total loss = 0.60, batch loss = 0.33 (257.3 examples/sec; 0.031 sec/batch; 0h:57m:54s remains)
INFO - root - 2022-02-24 20:15:58.594982: step 87760, total loss = 0.55, batch loss = 0.29 (357.6 examples/sec; 0.022 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:15:58.869168: step 87770, total loss = 0.54, batch loss = 0.27 (356.9 examples/sec; 0.022 sec/batch; 0h:41m:44s remains)
INFO - root - 2022-02-24 20:15:59.154837: step 87780, total loss = 0.54, batch loss = 0.27 (158.8 examples/sec; 0.050 sec/batch; 1h:33m:47s remains)
INFO - root - 2022-02-24 20:15:59.487653: step 87790, total loss = 0.52, batch loss = 0.26 (365.0 examples/sec; 0.022 sec/batch; 0h:40m:48s remains)
INFO - root - 2022-02-24 20:15:59.774869: step 87800, total loss = 0.54, batch loss = 0.28 (279.1 examples/sec; 0.029 sec/batch; 0h:53m:21s remains)
INFO - root - 2022-02-24 20:16:00.235834: step 87810, total loss = 0.62, batch loss = 0.36 (134.2 examples/sec; 0.060 sec/batch; 1h:50m:55s remains)
INFO - root - 2022-02-24 20:16:00.715898: step 87820, total loss = 0.62, batch loss = 0.35 (67.0 examples/sec; 0.119 sec/batch; 3h:42m:17s remains)
INFO - root - 2022-02-24 20:16:01.104960: step 87830, total loss = 0.47, batch loss = 0.21 (101.6 examples/sec; 0.079 sec/batch; 2h:26m:31s remains)
INFO - root - 2022-02-24 20:16:01.390439: step 87840, total loss = 0.61, batch loss = 0.34 (336.1 examples/sec; 0.024 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:16:01.783941: step 87850, total loss = 0.63, batch loss = 0.37 (206.5 examples/sec; 0.039 sec/batch; 1h:12m:04s remains)
INFO - root - 2022-02-24 20:16:02.154406: step 87860, total loss = 0.70, batch loss = 0.43 (152.1 examples/sec; 0.053 sec/batch; 1h:37m:52s remains)
INFO - root - 2022-02-24 20:16:02.474351: step 87870, total loss = 0.74, batch loss = 0.47 (349.0 examples/sec; 0.023 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:16:02.851998: step 87880, total loss = 0.51, batch loss = 0.24 (331.3 examples/sec; 0.024 sec/batch; 0h:44m:55s remains)
INFO - root - 2022-02-24 20:16:03.180255: step 87890, total loss = 0.58, batch loss = 0.31 (287.2 examples/sec; 0.028 sec/batch; 0h:51m:48s remains)
INFO - root - 2022-02-24 20:16:03.477305: step 87900, total loss = 0.51, batch loss = 0.24 (262.6 examples/sec; 0.030 sec/batch; 0h:56m:39s remains)
INFO - root - 2022-02-24 20:16:03.971851: step 87910, total loss = 0.60, batch loss = 0.34 (82.2 examples/sec; 0.097 sec/batch; 3h:00m:58s remains)
INFO - root - 2022-02-24 20:16:04.432259: step 87920, total loss = 0.49, batch loss = 0.22 (279.8 examples/sec; 0.029 sec/batch; 0h:53m:09s remains)
INFO - root - 2022-02-24 20:16:04.830875: step 87930, total loss = 0.57, batch loss = 0.30 (189.6 examples/sec; 0.042 sec/batch; 1h:18m:28s remains)
INFO - root - 2022-02-24 20:16:05.152289: step 87940, total loss = 0.54, batch loss = 0.27 (211.3 examples/sec; 0.038 sec/batch; 1h:10m:23s remains)
INFO - root - 2022-02-24 20:16:05.566837: step 87950, total loss = 0.63, batch loss = 0.37 (332.7 examples/sec; 0.024 sec/batch; 0h:44m:41s remains)
INFO - root - 2022-02-24 20:16:05.934782: step 87960, total loss = 0.50, batch loss = 0.23 (326.6 examples/sec; 0.024 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:16:06.834275: step 87970, total loss = 0.56, batch loss = 0.29 (128.3 examples/sec; 0.062 sec/batch; 1h:55m:56s remains)
INFO - root - 2022-02-24 20:16:07.200876: step 87980, total loss = 0.78, batch loss = 0.52 (389.1 examples/sec; 0.021 sec/batch; 0h:38m:12s remains)
INFO - root - 2022-02-24 20:16:07.454329: step 87990, total loss = 0.54, batch loss = 0.27 (320.9 examples/sec; 0.025 sec/batch; 0h:46m:20s remains)
INFO - root - 2022-02-24 20:16:07.756141: step 88000, total loss = 0.54, batch loss = 0.27 (359.4 examples/sec; 0.022 sec/batch; 0h:41m:21s remains)
INFO - root - 2022-02-24 20:16:08.140537: step 88010, total loss = 0.51, batch loss = 0.25 (175.9 examples/sec; 0.045 sec/batch; 1h:24m:30s remains)
INFO - root - 2022-02-24 20:16:08.550223: step 88020, total loss = 0.53, batch loss = 0.26 (315.6 examples/sec; 0.025 sec/batch; 0h:47m:05s remains)
INFO - root - 2022-02-24 20:16:08.953715: step 88030, total loss = 0.68, batch loss = 0.41 (347.8 examples/sec; 0.023 sec/batch; 0h:42m:44s remains)
INFO - root - 2022-02-24 20:16:09.365026: step 88040, total loss = 0.53, batch loss = 0.26 (347.8 examples/sec; 0.023 sec/batch; 0h:42m:43s remains)
INFO - root - 2022-02-24 20:16:09.680504: step 88050, total loss = 0.57, batch loss = 0.30 (348.6 examples/sec; 0.023 sec/batch; 0h:42m:37s remains)
INFO - root - 2022-02-24 20:16:10.023839: step 88060, total loss = 0.48, batch loss = 0.21 (377.9 examples/sec; 0.021 sec/batch; 0h:39m:19s remains)
INFO - root - 2022-02-24 20:16:10.350237: step 88070, total loss = 0.45, batch loss = 0.19 (286.2 examples/sec; 0.028 sec/batch; 0h:51m:54s remains)
INFO - root - 2022-02-24 20:16:10.739930: step 88080, total loss = 0.52, batch loss = 0.26 (164.0 examples/sec; 0.049 sec/batch; 1h:30m:36s remains)
INFO - root - 2022-02-24 20:16:11.172534: step 88090, total loss = 0.65, batch loss = 0.39 (269.8 examples/sec; 0.030 sec/batch; 0h:55m:03s remains)
INFO - root - 2022-02-24 20:16:11.457541: step 88100, total loss = 0.54, batch loss = 0.28 (330.1 examples/sec; 0.024 sec/batch; 0h:44m:59s remains)
INFO - root - 2022-02-24 20:16:11.799399: step 88110, total loss = 0.59, batch loss = 0.33 (305.6 examples/sec; 0.026 sec/batch; 0h:48m:35s remains)
INFO - root - 2022-02-24 20:16:12.107236: step 88120, total loss = 0.51, batch loss = 0.24 (247.6 examples/sec; 0.032 sec/batch; 0h:59m:58s remains)
INFO - root - 2022-02-24 20:16:12.516138: step 88130, total loss = 0.57, batch loss = 0.30 (303.4 examples/sec; 0.026 sec/batch; 0h:48m:56s remains)
INFO - root - 2022-02-24 20:16:12.899538: step 88140, total loss = 0.65, batch loss = 0.39 (331.0 examples/sec; 0.024 sec/batch; 0h:44m:51s remains)
INFO - root - 2022-02-24 20:16:13.177307: step 88150, total loss = 0.56, batch loss = 0.29 (301.5 examples/sec; 0.027 sec/batch; 0h:49m:14s remains)
INFO - root - 2022-02-24 20:16:13.436062: step 88160, total loss = 0.61, batch loss = 0.35 (196.0 examples/sec; 0.041 sec/batch; 1h:15m:44s remains)
INFO - root - 2022-02-24 20:16:13.774085: step 88170, total loss = 0.60, batch loss = 0.34 (254.3 examples/sec; 0.031 sec/batch; 0h:58m:22s remains)
INFO - root - 2022-02-24 20:16:14.105684: step 88180, total loss = 0.58, batch loss = 0.31 (192.3 examples/sec; 0.042 sec/batch; 1h:17m:10s remains)
INFO - root - 2022-02-24 20:16:14.570551: step 88190, total loss = 0.52, batch loss = 0.25 (188.0 examples/sec; 0.043 sec/batch; 1h:18m:56s remains)
INFO - root - 2022-02-24 20:16:14.904587: step 88200, total loss = 0.59, batch loss = 0.32 (343.7 examples/sec; 0.023 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:16:15.272912: step 88210, total loss = 0.51, batch loss = 0.25 (207.6 examples/sec; 0.039 sec/batch; 1h:11m:27s remains)
INFO - root - 2022-02-24 20:16:15.544127: step 88220, total loss = 0.53, batch loss = 0.27 (328.4 examples/sec; 0.024 sec/batch; 0h:45m:11s remains)
INFO - root - 2022-02-24 20:16:15.844271: step 88230, total loss = 0.51, batch loss = 0.24 (206.8 examples/sec; 0.039 sec/batch; 1h:11m:44s remains)
INFO - root - 2022-02-24 20:16:16.239863: step 88240, total loss = 0.60, batch loss = 0.34 (155.7 examples/sec; 0.051 sec/batch; 1h:35m:16s remains)
INFO - root - 2022-02-24 20:16:16.594216: step 88250, total loss = 0.48, batch loss = 0.21 (244.2 examples/sec; 0.033 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:16:17.044883: step 88260, total loss = 0.64, batch loss = 0.37 (205.7 examples/sec; 0.039 sec/batch; 1h:12m:07s remains)
INFO - root - 2022-02-24 20:16:17.369538: step 88270, total loss = 0.52, batch loss = 0.26 (267.5 examples/sec; 0.030 sec/batch; 0h:55m:26s remains)
INFO - root - 2022-02-24 20:16:17.690726: step 88280, total loss = 0.74, batch loss = 0.47 (303.5 examples/sec; 0.026 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:16:17.949932: step 88290, total loss = 0.64, batch loss = 0.37 (290.7 examples/sec; 0.028 sec/batch; 0h:51m:00s remains)
INFO - root - 2022-02-24 20:16:18.258316: step 88300, total loss = 0.55, batch loss = 0.28 (255.4 examples/sec; 0.031 sec/batch; 0h:58m:02s remains)
INFO - root - 2022-02-24 20:16:18.755526: step 88310, total loss = 0.52, batch loss = 0.25 (335.9 examples/sec; 0.024 sec/batch; 0h:44m:07s remains)
INFO - root - 2022-02-24 20:16:19.139987: step 88320, total loss = 0.54, batch loss = 0.27 (256.2 examples/sec; 0.031 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 20:16:19.675588: step 88330, total loss = 0.61, batch loss = 0.34 (190.7 examples/sec; 0.042 sec/batch; 1h:17m:44s remains)
INFO - root - 2022-02-24 20:16:20.070787: step 88340, total loss = 0.52, batch loss = 0.25 (221.1 examples/sec; 0.036 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 20:16:20.480252: step 88350, total loss = 0.50, batch loss = 0.23 (173.8 examples/sec; 0.046 sec/batch; 1h:25m:16s remains)
INFO - root - 2022-02-24 20:16:20.936048: step 88360, total loss = 0.55, batch loss = 0.28 (291.9 examples/sec; 0.027 sec/batch; 0h:50m:46s remains)
INFO - root - 2022-02-24 20:16:21.527901: step 88370, total loss = 0.45, batch loss = 0.19 (182.7 examples/sec; 0.044 sec/batch; 1h:21m:06s remains)
INFO - root - 2022-02-24 20:16:21.935460: step 88380, total loss = 0.64, batch loss = 0.37 (151.2 examples/sec; 0.053 sec/batch; 1h:37m:57s remains)
INFO - root - 2022-02-24 20:16:22.322576: step 88390, total loss = 0.54, batch loss = 0.27 (323.8 examples/sec; 0.025 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:16:22.893519: step 88400, total loss = 0.52, batch loss = 0.25 (112.2 examples/sec; 0.071 sec/batch; 2h:12m:02s remains)
INFO - root - 2022-02-24 20:16:23.367939: step 88410, total loss = 0.56, batch loss = 0.29 (243.2 examples/sec; 0.033 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 20:16:23.875100: step 88420, total loss = 0.62, batch loss = 0.35 (272.2 examples/sec; 0.029 sec/batch; 0h:54m:24s remains)
INFO - root - 2022-02-24 20:16:24.347215: step 88430, total loss = 0.58, batch loss = 0.31 (119.4 examples/sec; 0.067 sec/batch; 2h:04m:02s remains)
INFO - root - 2022-02-24 20:16:24.818366: step 88440, total loss = 0.52, batch loss = 0.26 (140.5 examples/sec; 0.057 sec/batch; 1h:45m:24s remains)
INFO - root - 2022-02-24 20:16:25.205579: step 88450, total loss = 0.60, batch loss = 0.33 (161.1 examples/sec; 0.050 sec/batch; 1h:31m:53s remains)
INFO - root - 2022-02-24 20:16:25.567468: step 88460, total loss = 0.53, batch loss = 0.26 (200.2 examples/sec; 0.040 sec/batch; 1h:13m:56s remains)
INFO - root - 2022-02-24 20:16:25.973758: step 88470, total loss = 0.54, batch loss = 0.28 (191.9 examples/sec; 0.042 sec/batch; 1h:17m:08s remains)
INFO - root - 2022-02-24 20:16:26.861531: step 88480, total loss = 0.56, batch loss = 0.29 (329.7 examples/sec; 0.024 sec/batch; 0h:44m:53s remains)
INFO - root - 2022-02-24 20:16:27.190097: step 88490, total loss = 0.56, batch loss = 0.30 (158.7 examples/sec; 0.050 sec/batch; 1h:33m:16s remains)
INFO - root - 2022-02-24 20:16:27.503337: step 88500, total loss = 0.56, batch loss = 0.29 (332.6 examples/sec; 0.024 sec/batch; 0h:44m:29s remains)
INFO - root - 2022-02-24 20:16:27.967218: step 88510, total loss = 0.51, batch loss = 0.24 (124.5 examples/sec; 0.064 sec/batch; 1h:58m:50s remains)
INFO - root - 2022-02-24 20:16:28.263511: step 88520, total loss = 0.60, batch loss = 0.33 (214.7 examples/sec; 0.037 sec/batch; 1h:08m:54s remains)
INFO - root - 2022-02-24 20:16:28.647079: step 88530, total loss = 0.60, batch loss = 0.33 (199.0 examples/sec; 0.040 sec/batch; 1h:14m:20s remains)
INFO - root - 2022-02-24 20:16:29.019227: step 88540, total loss = 0.52, batch loss = 0.26 (364.0 examples/sec; 0.022 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:16:29.284374: step 88550, total loss = 0.55, batch loss = 0.28 (182.0 examples/sec; 0.044 sec/batch; 1h:21m:17s remains)
INFO - root - 2022-02-24 20:16:29.579937: step 88560, total loss = 0.54, batch loss = 0.28 (311.9 examples/sec; 0.026 sec/batch; 0h:47m:25s remains)
INFO - root - 2022-02-24 20:16:29.927992: step 88570, total loss = 0.73, batch loss = 0.47 (280.5 examples/sec; 0.029 sec/batch; 0h:52m:43s remains)
INFO - root - 2022-02-24 20:16:30.299881: step 88580, total loss = 0.68, batch loss = 0.41 (156.6 examples/sec; 0.051 sec/batch; 1h:34m:26s remains)
INFO - root - 2022-02-24 20:16:30.654123: step 88590, total loss = 0.56, batch loss = 0.30 (274.6 examples/sec; 0.029 sec/batch; 0h:53m:50s remains)
INFO - root - 2022-02-24 20:16:31.057677: step 88600, total loss = 0.52, batch loss = 0.25 (193.4 examples/sec; 0.041 sec/batch; 1h:16m:27s remains)
INFO - root - 2022-02-24 20:16:31.468846: step 88610, total loss = 0.46, batch loss = 0.19 (235.8 examples/sec; 0.034 sec/batch; 1h:02m:42s remains)
INFO - root - 2022-02-24 20:16:31.779848: step 88620, total loss = 0.61, batch loss = 0.35 (215.0 examples/sec; 0.037 sec/batch; 1h:08m:44s remains)
INFO - root - 2022-02-24 20:16:32.076311: step 88630, total loss = 0.54, batch loss = 0.27 (326.7 examples/sec; 0.024 sec/batch; 0h:45m:15s remains)
INFO - root - 2022-02-24 20:16:32.371974: step 88640, total loss = 0.55, batch loss = 0.28 (266.7 examples/sec; 0.030 sec/batch; 0h:55m:25s remains)
INFO - root - 2022-02-24 20:16:32.757558: step 88650, total loss = 0.51, batch loss = 0.24 (170.4 examples/sec; 0.047 sec/batch; 1h:26m:45s remains)
INFO - root - 2022-02-24 20:16:33.153758: step 88660, total loss = 0.58, batch loss = 0.31 (175.8 examples/sec; 0.046 sec/batch; 1h:24m:04s remains)
INFO - root - 2022-02-24 20:16:33.402485: step 88670, total loss = 0.56, batch loss = 0.30 (324.5 examples/sec; 0.025 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:16:33.665339: step 88680, total loss = 0.51, batch loss = 0.25 (216.3 examples/sec; 0.037 sec/batch; 1h:08m:18s remains)
INFO - root - 2022-02-24 20:16:33.932665: step 88690, total loss = 0.64, batch loss = 0.37 (350.6 examples/sec; 0.023 sec/batch; 0h:42m:08s remains)
INFO - root - 2022-02-24 20:16:34.276642: step 88700, total loss = 0.61, batch loss = 0.34 (102.7 examples/sec; 0.078 sec/batch; 2h:23m:55s remains)
INFO - root - 2022-02-24 20:16:34.651900: step 88710, total loss = 0.58, batch loss = 0.32 (365.4 examples/sec; 0.022 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:16:34.988379: step 88720, total loss = 0.52, batch loss = 0.25 (277.8 examples/sec; 0.029 sec/batch; 0h:53m:10s remains)
INFO - root - 2022-02-24 20:16:35.281076: step 88730, total loss = 0.55, batch loss = 0.28 (221.7 examples/sec; 0.036 sec/batch; 1h:06m:36s remains)
INFO - root - 2022-02-24 20:16:35.533669: step 88740, total loss = 0.54, batch loss = 0.27 (349.2 examples/sec; 0.023 sec/batch; 0h:42m:17s remains)
INFO - root - 2022-02-24 20:16:35.853662: step 88750, total loss = 0.73, batch loss = 0.46 (173.4 examples/sec; 0.046 sec/batch; 1h:25m:10s remains)
INFO - root - 2022-02-24 20:16:36.160105: step 88760, total loss = 0.51, batch loss = 0.25 (122.4 examples/sec; 0.065 sec/batch; 2h:00m:35s remains)
INFO - root - 2022-02-24 20:16:36.524926: step 88770, total loss = 0.51, batch loss = 0.24 (197.3 examples/sec; 0.041 sec/batch; 1h:14m:49s remains)
INFO - root - 2022-02-24 20:16:36.876511: step 88780, total loss = 0.51, batch loss = 0.24 (345.9 examples/sec; 0.023 sec/batch; 0h:42m:40s remains)
INFO - root - 2022-02-24 20:16:37.207806: step 88790, total loss = 0.53, batch loss = 0.27 (302.3 examples/sec; 0.026 sec/batch; 0h:48m:49s remains)
INFO - root - 2022-02-24 20:16:37.512370: step 88800, total loss = 0.56, batch loss = 0.30 (310.9 examples/sec; 0.026 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:16:37.854901: step 88810, total loss = 0.62, batch loss = 0.35 (296.8 examples/sec; 0.027 sec/batch; 0h:49m:43s remains)
INFO - root - 2022-02-24 20:16:38.148483: step 88820, total loss = 0.61, batch loss = 0.34 (335.1 examples/sec; 0.024 sec/batch; 0h:44m:01s remains)
INFO - root - 2022-02-24 20:16:38.479551: step 88830, total loss = 0.61, batch loss = 0.34 (116.2 examples/sec; 0.069 sec/batch; 2h:07m:01s remains)
INFO - root - 2022-02-24 20:16:38.878370: step 88840, total loss = 0.52, batch loss = 0.25 (123.7 examples/sec; 0.065 sec/batch; 1h:59m:18s remains)
INFO - root - 2022-02-24 20:16:39.191195: step 88850, total loss = 0.55, batch loss = 0.28 (218.6 examples/sec; 0.037 sec/batch; 1h:07m:29s remains)
INFO - root - 2022-02-24 20:16:39.518259: step 88860, total loss = 0.54, batch loss = 0.27 (347.6 examples/sec; 0.023 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:16:39.836943: step 88870, total loss = 0.60, batch loss = 0.34 (386.4 examples/sec; 0.021 sec/batch; 0h:38m:10s remains)
INFO - root - 2022-02-24 20:16:40.156849: step 88880, total loss = 0.61, batch loss = 0.35 (279.6 examples/sec; 0.029 sec/batch; 0h:52m:45s remains)
INFO - root - 2022-02-24 20:16:40.508401: step 88890, total loss = 0.50, batch loss = 0.24 (198.1 examples/sec; 0.040 sec/batch; 1h:14m:26s remains)
INFO - root - 2022-02-24 20:16:40.897955: step 88900, total loss = 0.72, batch loss = 0.45 (228.7 examples/sec; 0.035 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 20:16:41.489872: step 88910, total loss = 0.53, batch loss = 0.27 (251.1 examples/sec; 0.032 sec/batch; 0h:58m:43s remains)
INFO - root - 2022-02-24 20:16:41.888878: step 88920, total loss = 0.49, batch loss = 0.22 (190.2 examples/sec; 0.042 sec/batch; 1h:17m:31s remains)
INFO - root - 2022-02-24 20:16:42.296521: step 88930, total loss = 0.52, batch loss = 0.26 (283.6 examples/sec; 0.028 sec/batch; 0h:51m:59s remains)
INFO - root - 2022-02-24 20:16:42.734329: step 88940, total loss = 0.57, batch loss = 0.30 (98.6 examples/sec; 0.081 sec/batch; 2h:29m:31s remains)
INFO - root - 2022-02-24 20:16:43.113425: step 88950, total loss = 0.64, batch loss = 0.38 (142.7 examples/sec; 0.056 sec/batch; 1h:43m:16s remains)
INFO - root - 2022-02-24 20:16:43.492589: step 88960, total loss = 0.58, batch loss = 0.31 (314.8 examples/sec; 0.025 sec/batch; 0h:46m:49s remains)
INFO - root - 2022-02-24 20:16:44.005382: step 88970, total loss = 0.51, batch loss = 0.25 (297.8 examples/sec; 0.027 sec/batch; 0h:49m:28s remains)
INFO - root - 2022-02-24 20:16:44.379885: step 88980, total loss = 0.51, batch loss = 0.25 (225.7 examples/sec; 0.035 sec/batch; 1h:05m:18s remains)
INFO - root - 2022-02-24 20:16:44.745161: step 88990, total loss = 0.50, batch loss = 0.23 (282.5 examples/sec; 0.028 sec/batch; 0h:52m:09s remains)
INFO - root - 2022-02-24 20:16:45.134341: step 89000, total loss = 0.56, batch loss = 0.29 (163.2 examples/sec; 0.049 sec/batch; 1h:30m:16s remains)
INFO - root - 2022-02-24 20:16:45.574939: step 89010, total loss = 0.60, batch loss = 0.33 (219.5 examples/sec; 0.036 sec/batch; 1h:07m:06s remains)
INFO - root - 2022-02-24 20:16:45.941227: step 89020, total loss = 0.51, batch loss = 0.25 (177.7 examples/sec; 0.045 sec/batch; 1h:22m:55s remains)
INFO - root - 2022-02-24 20:16:46.844373: step 89030, total loss = 0.67, batch loss = 0.41 (151.1 examples/sec; 0.053 sec/batch; 1h:37m:30s remains)
INFO - root - 2022-02-24 20:16:47.277288: step 89040, total loss = 0.64, batch loss = 0.37 (288.1 examples/sec; 0.028 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:16:47.584365: step 89050, total loss = 0.55, batch loss = 0.28 (260.6 examples/sec; 0.031 sec/batch; 0h:56m:30s remains)
INFO - root - 2022-02-24 20:16:47.903226: step 89060, total loss = 0.57, batch loss = 0.30 (206.0 examples/sec; 0.039 sec/batch; 1h:11m:29s remains)
INFO - root - 2022-02-24 20:16:48.304160: step 89070, total loss = 0.57, batch loss = 0.30 (192.3 examples/sec; 0.042 sec/batch; 1h:16m:33s remains)
INFO - root - 2022-02-24 20:16:48.642731: step 89080, total loss = 0.57, batch loss = 0.31 (103.5 examples/sec; 0.077 sec/batch; 2h:22m:17s remains)
INFO - root - 2022-02-24 20:16:49.052267: step 89090, total loss = 0.61, batch loss = 0.34 (139.4 examples/sec; 0.057 sec/batch; 1h:45m:34s remains)
INFO - root - 2022-02-24 20:16:49.474948: step 89100, total loss = 0.61, batch loss = 0.34 (330.1 examples/sec; 0.024 sec/batch; 0h:44m:35s remains)
INFO - root - 2022-02-24 20:16:49.874694: step 89110, total loss = 0.62, batch loss = 0.35 (184.9 examples/sec; 0.043 sec/batch; 1h:19m:35s remains)
INFO - root - 2022-02-24 20:16:50.137084: step 89120, total loss = 0.52, batch loss = 0.26 (284.7 examples/sec; 0.028 sec/batch; 0h:51m:41s remains)
INFO - root - 2022-02-24 20:16:50.426159: step 89130, total loss = 0.56, batch loss = 0.29 (340.2 examples/sec; 0.024 sec/batch; 0h:43m:15s remains)
INFO - root - 2022-02-24 20:16:50.796640: step 89140, total loss = 0.48, batch loss = 0.21 (233.5 examples/sec; 0.034 sec/batch; 1h:03m:00s remains)
INFO - root - 2022-02-24 20:16:51.208187: step 89150, total loss = 0.57, batch loss = 0.31 (130.9 examples/sec; 0.061 sec/batch; 1h:52m:26s remains)
INFO - root - 2022-02-24 20:16:51.536837: step 89160, total loss = 0.47, batch loss = 0.21 (341.4 examples/sec; 0.023 sec/batch; 0h:43m:05s remains)
INFO - root - 2022-02-24 20:16:51.876227: step 89170, total loss = 0.64, batch loss = 0.38 (322.4 examples/sec; 0.025 sec/batch; 0h:45m:37s remains)
INFO - root - 2022-02-24 20:16:52.390819: step 89180, total loss = 0.50, batch loss = 0.24 (44.7 examples/sec; 0.179 sec/batch; 5h:29m:24s remains)
INFO - root - 2022-02-24 20:16:53.056808: step 89190, total loss = 0.48, batch loss = 0.22 (194.1 examples/sec; 0.041 sec/batch; 1h:15m:46s remains)
INFO - root - 2022-02-24 20:16:53.479447: step 89200, total loss = 0.53, batch loss = 0.26 (346.8 examples/sec; 0.023 sec/batch; 0h:42m:24s remains)
INFO - root - 2022-02-24 20:16:53.818190: step 89210, total loss = 0.57, batch loss = 0.30 (348.3 examples/sec; 0.023 sec/batch; 0h:42m:13s remains)
INFO - root - 2022-02-24 20:16:54.159674: step 89220, total loss = 0.61, batch loss = 0.34 (169.6 examples/sec; 0.047 sec/batch; 1h:26m:42s remains)
INFO - root - 2022-02-24 20:16:54.527359: step 89230, total loss = 0.58, batch loss = 0.31 (319.3 examples/sec; 0.025 sec/batch; 0h:46m:02s remains)
INFO - root - 2022-02-24 20:16:54.824925: step 89240, total loss = 0.49, batch loss = 0.22 (364.1 examples/sec; 0.022 sec/batch; 0h:40m:22s remains)
INFO - root - 2022-02-24 20:16:55.215978: step 89250, total loss = 0.71, batch loss = 0.45 (336.0 examples/sec; 0.024 sec/batch; 0h:43m:45s remains)
INFO - root - 2022-02-24 20:16:55.658158: step 89260, total loss = 0.51, batch loss = 0.24 (297.6 examples/sec; 0.027 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:16:55.939740: step 89270, total loss = 0.56, batch loss = 0.29 (140.5 examples/sec; 0.057 sec/batch; 1h:44m:35s remains)
INFO - root - 2022-02-24 20:16:56.670419: step 89280, total loss = 0.67, batch loss = 0.40 (368.5 examples/sec; 0.022 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 20:16:57.055047: step 89290, total loss = 0.50, batch loss = 0.24 (119.9 examples/sec; 0.067 sec/batch; 2h:02m:35s remains)
INFO - root - 2022-02-24 20:16:57.433930: step 89300, total loss = 0.55, batch loss = 0.29 (244.8 examples/sec; 0.033 sec/batch; 1h:00m:01s remains)
INFO - root - 2022-02-24 20:16:57.917168: step 89310, total loss = 0.48, batch loss = 0.22 (159.5 examples/sec; 0.050 sec/batch; 1h:32m:05s remains)
INFO - root - 2022-02-24 20:16:58.203305: step 89320, total loss = 0.53, batch loss = 0.27 (311.7 examples/sec; 0.026 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:16:58.497589: step 89330, total loss = 0.62, batch loss = 0.35 (339.0 examples/sec; 0.024 sec/batch; 0h:43m:19s remains)
INFO - root - 2022-02-24 20:16:58.877122: step 89340, total loss = 0.57, batch loss = 0.31 (237.2 examples/sec; 0.034 sec/batch; 1h:01m:55s remains)
INFO - root - 2022-02-24 20:16:59.238924: step 89350, total loss = 0.52, batch loss = 0.25 (195.1 examples/sec; 0.041 sec/batch; 1h:15m:16s remains)
INFO - root - 2022-02-24 20:16:59.643312: step 89360, total loss = 0.54, batch loss = 0.27 (234.7 examples/sec; 0.034 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 20:16:59.991165: step 89370, total loss = 0.56, batch loss = 0.30 (231.3 examples/sec; 0.035 sec/batch; 1h:03m:29s remains)
INFO - root - 2022-02-24 20:17:00.319853: step 89380, total loss = 0.58, batch loss = 0.32 (127.6 examples/sec; 0.063 sec/batch; 1h:55m:06s remains)
INFO - root - 2022-02-24 20:17:00.617881: step 89390, total loss = 0.56, batch loss = 0.29 (283.6 examples/sec; 0.028 sec/batch; 0h:51m:46s remains)
INFO - root - 2022-02-24 20:17:00.886810: step 89400, total loss = 0.59, batch loss = 0.32 (314.5 examples/sec; 0.025 sec/batch; 0h:46m:41s remains)
INFO - root - 2022-02-24 20:17:01.258134: step 89410, total loss = 0.54, batch loss = 0.28 (321.8 examples/sec; 0.025 sec/batch; 0h:45m:36s remains)
INFO - root - 2022-02-24 20:17:01.753293: step 89420, total loss = 0.57, batch loss = 0.30 (114.8 examples/sec; 0.070 sec/batch; 2h:07m:48s remains)
INFO - root - 2022-02-24 20:17:02.139266: step 89430, total loss = 0.51, batch loss = 0.24 (161.1 examples/sec; 0.050 sec/batch; 1h:31m:05s remains)
INFO - root - 2022-02-24 20:17:02.397383: step 89440, total loss = 0.58, batch loss = 0.32 (373.3 examples/sec; 0.021 sec/batch; 0h:39m:18s remains)
INFO - root - 2022-02-24 20:17:02.700315: step 89450, total loss = 0.53, batch loss = 0.26 (215.8 examples/sec; 0.037 sec/batch; 1h:07m:59s remains)
INFO - root - 2022-02-24 20:17:03.197726: step 89460, total loss = 0.66, batch loss = 0.39 (106.0 examples/sec; 0.075 sec/batch; 2h:18m:26s remains)
INFO - root - 2022-02-24 20:17:03.656992: step 89470, total loss = 0.61, batch loss = 0.34 (322.9 examples/sec; 0.025 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:17:04.069435: step 89480, total loss = 0.57, batch loss = 0.31 (189.0 examples/sec; 0.042 sec/batch; 1h:17m:37s remains)
INFO - root - 2022-02-24 20:17:04.376336: step 89490, total loss = 0.52, batch loss = 0.26 (231.2 examples/sec; 0.035 sec/batch; 1h:03m:26s remains)
INFO - root - 2022-02-24 20:17:04.736966: step 89500, total loss = 0.64, batch loss = 0.37 (323.1 examples/sec; 0.025 sec/batch; 0h:45m:23s remains)
INFO - root - 2022-02-24 20:17:05.102487: step 89510, total loss = 0.59, batch loss = 0.32 (309.0 examples/sec; 0.026 sec/batch; 0h:47m:27s remains)
INFO - root - 2022-02-24 20:17:05.520866: step 89520, total loss = 0.56, batch loss = 0.29 (182.7 examples/sec; 0.044 sec/batch; 1h:20m:15s remains)
INFO - root - 2022-02-24 20:17:05.871108: step 89530, total loss = 0.51, batch loss = 0.24 (224.4 examples/sec; 0.036 sec/batch; 1h:05m:20s remains)
INFO - root - 2022-02-24 20:17:06.227869: step 89540, total loss = 0.54, batch loss = 0.27 (337.1 examples/sec; 0.024 sec/batch; 0h:43m:29s remains)
INFO - root - 2022-02-24 20:17:06.526889: step 89550, total loss = 0.49, batch loss = 0.23 (274.1 examples/sec; 0.029 sec/batch; 0h:53m:28s remains)
INFO - root - 2022-02-24 20:17:07.258835: step 89560, total loss = 0.49, batch loss = 0.23 (289.1 examples/sec; 0.028 sec/batch; 0h:50m:42s remains)
INFO - root - 2022-02-24 20:17:07.665298: step 89570, total loss = 0.51, batch loss = 0.24 (340.4 examples/sec; 0.024 sec/batch; 0h:43m:03s remains)
INFO - root - 2022-02-24 20:17:08.095042: step 89580, total loss = 0.53, batch loss = 0.26 (361.6 examples/sec; 0.022 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:17:08.409066: step 89590, total loss = 0.50, batch loss = 0.23 (310.4 examples/sec; 0.026 sec/batch; 0h:47m:12s remains)
INFO - root - 2022-02-24 20:17:08.751691: step 89600, total loss = 0.50, batch loss = 0.23 (371.7 examples/sec; 0.022 sec/batch; 0h:39m:25s remains)
INFO - root - 2022-02-24 20:17:09.116719: step 89610, total loss = 0.52, batch loss = 0.25 (241.9 examples/sec; 0.033 sec/batch; 1h:00m:34s remains)
INFO - root - 2022-02-24 20:17:09.476433: step 89620, total loss = 0.68, batch loss = 0.41 (361.1 examples/sec; 0.022 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:17:09.816678: step 89630, total loss = 0.70, batch loss = 0.43 (310.1 examples/sec; 0.026 sec/batch; 0h:47m:14s remains)
INFO - root - 2022-02-24 20:17:10.159146: step 89640, total loss = 0.50, batch loss = 0.24 (220.5 examples/sec; 0.036 sec/batch; 1h:06m:26s remains)
INFO - root - 2022-02-24 20:17:10.508600: step 89650, total loss = 0.51, batch loss = 0.25 (323.3 examples/sec; 0.025 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 20:17:10.881398: step 89660, total loss = 0.55, batch loss = 0.29 (167.5 examples/sec; 0.048 sec/batch; 1h:27m:25s remains)
INFO - root - 2022-02-24 20:17:11.160929: step 89670, total loss = 0.51, batch loss = 0.24 (342.0 examples/sec; 0.023 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:17:11.437277: step 89680, total loss = 0.52, batch loss = 0.26 (370.5 examples/sec; 0.022 sec/batch; 0h:39m:31s remains)
INFO - root - 2022-02-24 20:17:11.884755: step 89690, total loss = 0.53, batch loss = 0.27 (140.7 examples/sec; 0.057 sec/batch; 1h:44m:04s remains)
INFO - root - 2022-02-24 20:17:12.270832: step 89700, total loss = 0.42, batch loss = 0.16 (213.5 examples/sec; 0.037 sec/batch; 1h:08m:35s remains)
INFO - root - 2022-02-24 20:17:12.685709: step 89710, total loss = 0.65, batch loss = 0.38 (227.9 examples/sec; 0.035 sec/batch; 1h:04m:14s remains)
INFO - root - 2022-02-24 20:17:13.050780: step 89720, total loss = 0.56, batch loss = 0.30 (354.1 examples/sec; 0.023 sec/batch; 0h:41m:20s remains)
INFO - root - 2022-02-24 20:17:13.393893: step 89730, total loss = 0.56, batch loss = 0.29 (136.6 examples/sec; 0.059 sec/batch; 1h:47m:07s remains)
INFO - root - 2022-02-24 20:17:13.762065: step 89740, total loss = 0.54, batch loss = 0.28 (163.3 examples/sec; 0.049 sec/batch; 1h:29m:38s remains)
INFO - root - 2022-02-24 20:17:14.138979: step 89750, total loss = 0.51, batch loss = 0.25 (184.3 examples/sec; 0.043 sec/batch; 1h:19m:23s remains)
INFO - root - 2022-02-24 20:17:14.602453: step 89760, total loss = 0.74, batch loss = 0.48 (87.1 examples/sec; 0.092 sec/batch; 2h:48m:02s remains)
INFO - root - 2022-02-24 20:17:15.021903: step 89770, total loss = 0.49, batch loss = 0.23 (316.9 examples/sec; 0.025 sec/batch; 0h:46m:10s remains)
INFO - root - 2022-02-24 20:17:15.384123: step 89780, total loss = 0.50, batch loss = 0.23 (321.8 examples/sec; 0.025 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:17:15.770935: step 89790, total loss = 0.69, batch loss = 0.42 (84.2 examples/sec; 0.095 sec/batch; 2h:53m:41s remains)
INFO - root - 2022-02-24 20:17:16.154028: step 89800, total loss = 0.51, batch loss = 0.25 (185.2 examples/sec; 0.043 sec/batch; 1h:18m:59s remains)
INFO - root - 2022-02-24 20:17:16.602169: step 89810, total loss = 0.52, batch loss = 0.26 (149.5 examples/sec; 0.053 sec/batch; 1h:37m:47s remains)
INFO - root - 2022-02-24 20:17:17.457509: step 89820, total loss = 0.62, batch loss = 0.36 (251.5 examples/sec; 0.032 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 20:17:17.761622: step 89830, total loss = 0.50, batch loss = 0.24 (344.5 examples/sec; 0.023 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:17:18.331600: step 89840, total loss = 0.57, batch loss = 0.31 (84.0 examples/sec; 0.095 sec/batch; 2h:54m:07s remains)
INFO - root - 2022-02-24 20:17:18.628092: step 89850, total loss = 0.58, batch loss = 0.32 (279.3 examples/sec; 0.029 sec/batch; 0h:52m:21s remains)
INFO - root - 2022-02-24 20:17:19.025633: step 89860, total loss = 0.66, batch loss = 0.40 (183.1 examples/sec; 0.044 sec/batch; 1h:19m:49s remains)
INFO - root - 2022-02-24 20:17:19.334779: step 89870, total loss = 0.59, batch loss = 0.33 (354.2 examples/sec; 0.023 sec/batch; 0h:41m:15s remains)
INFO - root - 2022-02-24 20:17:19.637826: step 89880, total loss = 0.57, batch loss = 0.31 (329.3 examples/sec; 0.024 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:17:19.954158: step 89890, total loss = 0.56, batch loss = 0.29 (156.3 examples/sec; 0.051 sec/batch; 1h:33m:30s remains)
INFO - root - 2022-02-24 20:17:20.411392: step 89900, total loss = 0.51, batch loss = 0.25 (216.9 examples/sec; 0.037 sec/batch; 1h:07m:21s remains)
INFO - root - 2022-02-24 20:17:20.860453: step 89910, total loss = 0.62, batch loss = 0.35 (260.7 examples/sec; 0.031 sec/batch; 0h:56m:02s remains)
INFO - root - 2022-02-24 20:17:21.185421: step 89920, total loss = 0.65, batch loss = 0.39 (311.8 examples/sec; 0.026 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 20:17:21.531309: step 89930, total loss = 0.55, batch loss = 0.28 (193.7 examples/sec; 0.041 sec/batch; 1h:15m:25s remains)
INFO - root - 2022-02-24 20:17:21.895841: step 89940, total loss = 0.77, batch loss = 0.50 (290.9 examples/sec; 0.027 sec/batch; 0h:50m:12s remains)
INFO - root - 2022-02-24 20:17:22.310853: step 89950, total loss = 0.48, batch loss = 0.22 (303.8 examples/sec; 0.026 sec/batch; 0h:48m:04s remains)
INFO - root - 2022-02-24 20:17:22.742542: step 89960, total loss = 0.61, batch loss = 0.35 (121.0 examples/sec; 0.066 sec/batch; 2h:00m:43s remains)
INFO - root - 2022-02-24 20:17:23.005072: step 89970, total loss = 0.57, batch loss = 0.30 (315.8 examples/sec; 0.025 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 20:17:23.298133: step 89980, total loss = 0.55, batch loss = 0.28 (265.5 examples/sec; 0.030 sec/batch; 0h:55m:00s remains)
INFO - root - 2022-02-24 20:17:23.602023: step 89990, total loss = 0.59, batch loss = 0.32 (361.5 examples/sec; 0.022 sec/batch; 0h:40m:23s remains)
INFO - root - 2022-02-24 20:17:23.890207: step 90000, total loss = 0.53, batch loss = 0.26 (256.4 examples/sec; 0.031 sec/batch; 0h:56m:56s remains)
INFO - root - 2022-02-24 20:17:24.326854: step 90010, total loss = 0.51, batch loss = 0.24 (149.4 examples/sec; 0.054 sec/batch; 1h:37m:44s remains)
INFO - root - 2022-02-24 20:17:24.767072: step 90020, total loss = 0.66, batch loss = 0.39 (204.4 examples/sec; 0.039 sec/batch; 1h:11m:25s remains)
INFO - root - 2022-02-24 20:17:25.101523: step 90030, total loss = 0.48, batch loss = 0.22 (337.4 examples/sec; 0.024 sec/batch; 0h:43m:15s remains)
INFO - root - 2022-02-24 20:17:25.477168: step 90040, total loss = 0.67, batch loss = 0.40 (319.0 examples/sec; 0.025 sec/batch; 0h:45m:44s remains)
INFO - root - 2022-02-24 20:17:25.864345: step 90050, total loss = 0.51, batch loss = 0.24 (114.8 examples/sec; 0.070 sec/batch; 2h:07m:07s remains)
INFO - root - 2022-02-24 20:17:26.282952: step 90060, total loss = 0.49, batch loss = 0.22 (345.2 examples/sec; 0.023 sec/batch; 0h:42m:15s remains)
INFO - root - 2022-02-24 20:17:26.763660: step 90070, total loss = 0.76, batch loss = 0.49 (207.8 examples/sec; 0.038 sec/batch; 1h:10m:11s remains)
INFO - root - 2022-02-24 20:17:27.668979: step 90080, total loss = 0.52, batch loss = 0.25 (304.5 examples/sec; 0.026 sec/batch; 0h:47m:54s remains)
INFO - root - 2022-02-24 20:17:27.952327: step 90090, total loss = 0.60, batch loss = 0.34 (354.5 examples/sec; 0.023 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:17:28.215855: step 90100, total loss = 0.54, batch loss = 0.28 (325.2 examples/sec; 0.025 sec/batch; 0h:44m:50s remains)
INFO - root - 2022-02-24 20:17:28.596642: step 90110, total loss = 0.60, batch loss = 0.34 (322.3 examples/sec; 0.025 sec/batch; 0h:45m:15s remains)
INFO - root - 2022-02-24 20:17:28.887283: step 90120, total loss = 0.66, batch loss = 0.39 (337.3 examples/sec; 0.024 sec/batch; 0h:43m:13s remains)
INFO - root - 2022-02-24 20:17:29.246825: step 90130, total loss = 0.68, batch loss = 0.42 (355.3 examples/sec; 0.023 sec/batch; 0h:41m:02s remains)
INFO - root - 2022-02-24 20:17:29.634939: step 90140, total loss = 0.48, batch loss = 0.22 (259.5 examples/sec; 0.031 sec/batch; 0h:56m:11s remains)
INFO - root - 2022-02-24 20:17:29.961096: step 90150, total loss = 0.60, batch loss = 0.33 (185.5 examples/sec; 0.043 sec/batch; 1h:18m:35s remains)
INFO - root - 2022-02-24 20:17:30.346596: step 90160, total loss = 0.55, batch loss = 0.28 (221.5 examples/sec; 0.036 sec/batch; 1h:05m:49s remains)
INFO - root - 2022-02-24 20:17:30.695574: step 90170, total loss = 0.52, batch loss = 0.25 (349.7 examples/sec; 0.023 sec/batch; 0h:41m:40s remains)
INFO - root - 2022-02-24 20:17:31.103022: step 90180, total loss = 0.61, batch loss = 0.35 (349.6 examples/sec; 0.023 sec/batch; 0h:41m:41s remains)
INFO - root - 2022-02-24 20:17:31.506168: step 90190, total loss = 0.56, batch loss = 0.29 (226.1 examples/sec; 0.035 sec/batch; 1h:04m:27s remains)
INFO - root - 2022-02-24 20:17:31.833714: step 90200, total loss = 0.48, batch loss = 0.22 (331.6 examples/sec; 0.024 sec/batch; 0h:43m:56s remains)
INFO - root - 2022-02-24 20:17:32.202591: step 90210, total loss = 0.52, batch loss = 0.25 (342.0 examples/sec; 0.023 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 20:17:32.556451: step 90220, total loss = 0.64, batch loss = 0.37 (320.5 examples/sec; 0.025 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:17:32.852441: step 90230, total loss = 0.53, batch loss = 0.26 (284.1 examples/sec; 0.028 sec/batch; 0h:51m:17s remains)
INFO - root - 2022-02-24 20:17:33.234130: step 90240, total loss = 0.53, batch loss = 0.26 (216.3 examples/sec; 0.037 sec/batch; 1h:07m:21s remains)
INFO - root - 2022-02-24 20:17:33.725970: step 90250, total loss = 0.54, batch loss = 0.27 (215.6 examples/sec; 0.037 sec/batch; 1h:07m:33s remains)
INFO - root - 2022-02-24 20:17:34.103640: step 90260, total loss = 0.51, batch loss = 0.25 (335.9 examples/sec; 0.024 sec/batch; 0h:43m:21s remains)
INFO - root - 2022-02-24 20:17:34.382277: step 90270, total loss = 0.56, batch loss = 0.30 (174.5 examples/sec; 0.046 sec/batch; 1h:23m:27s remains)
INFO - root - 2022-02-24 20:17:34.708103: step 90280, total loss = 0.50, batch loss = 0.24 (338.4 examples/sec; 0.024 sec/batch; 0h:43m:02s remains)
INFO - root - 2022-02-24 20:17:35.055523: step 90290, total loss = 0.65, batch loss = 0.39 (284.7 examples/sec; 0.028 sec/batch; 0h:51m:09s remains)
INFO - root - 2022-02-24 20:17:35.479456: step 90300, total loss = 0.56, batch loss = 0.29 (159.5 examples/sec; 0.050 sec/batch; 1h:31m:16s remains)
INFO - root - 2022-02-24 20:17:35.902213: step 90310, total loss = 0.60, batch loss = 0.34 (221.2 examples/sec; 0.036 sec/batch; 1h:05m:49s remains)
INFO - root - 2022-02-24 20:17:36.260147: step 90320, total loss = 0.50, batch loss = 0.23 (235.4 examples/sec; 0.034 sec/batch; 1h:01m:51s remains)
INFO - root - 2022-02-24 20:17:36.599340: step 90330, total loss = 0.53, batch loss = 0.26 (174.1 examples/sec; 0.046 sec/batch; 1h:23m:35s remains)
INFO - root - 2022-02-24 20:17:37.019517: step 90340, total loss = 0.52, batch loss = 0.26 (113.3 examples/sec; 0.071 sec/batch; 2h:08m:31s remains)
INFO - root - 2022-02-24 20:17:37.452799: step 90350, total loss = 0.48, batch loss = 0.22 (133.4 examples/sec; 0.060 sec/batch; 1h:49m:04s remains)
INFO - root - 2022-02-24 20:17:38.325080: step 90360, total loss = 0.57, batch loss = 0.30 (322.2 examples/sec; 0.025 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:17:38.622791: step 90370, total loss = 0.54, batch loss = 0.28 (308.0 examples/sec; 0.026 sec/batch; 0h:47m:14s remains)
INFO - root - 2022-02-24 20:17:38.973052: step 90380, total loss = 0.49, batch loss = 0.23 (241.7 examples/sec; 0.033 sec/batch; 1h:00m:11s remains)
INFO - root - 2022-02-24 20:17:39.283031: step 90390, total loss = 0.58, batch loss = 0.32 (308.1 examples/sec; 0.026 sec/batch; 0h:47m:13s remains)
INFO - root - 2022-02-24 20:17:39.592541: step 90400, total loss = 0.58, batch loss = 0.32 (313.5 examples/sec; 0.026 sec/batch; 0h:46m:24s remains)
INFO - root - 2022-02-24 20:17:39.949742: step 90410, total loss = 0.50, batch loss = 0.23 (276.1 examples/sec; 0.029 sec/batch; 0h:52m:40s remains)
INFO - root - 2022-02-24 20:17:40.267392: step 90420, total loss = 0.54, batch loss = 0.27 (262.9 examples/sec; 0.030 sec/batch; 0h:55m:18s remains)
INFO - root - 2022-02-24 20:17:40.606360: step 90430, total loss = 0.47, batch loss = 0.20 (270.3 examples/sec; 0.030 sec/batch; 0h:53m:48s remains)
INFO - root - 2022-02-24 20:17:40.921185: step 90440, total loss = 0.52, batch loss = 0.25 (327.9 examples/sec; 0.024 sec/batch; 0h:44m:20s remains)
INFO - root - 2022-02-24 20:17:41.206394: step 90450, total loss = 0.50, batch loss = 0.24 (325.7 examples/sec; 0.025 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:17:41.504183: step 90460, total loss = 0.64, batch loss = 0.37 (329.1 examples/sec; 0.024 sec/batch; 0h:44m:10s remains)
INFO - root - 2022-02-24 20:17:41.770038: step 90470, total loss = 0.52, batch loss = 0.26 (353.3 examples/sec; 0.023 sec/batch; 0h:41m:08s remains)
INFO - root - 2022-02-24 20:17:42.216909: step 90480, total loss = 0.44, batch loss = 0.17 (197.7 examples/sec; 0.040 sec/batch; 1h:13m:32s remains)
INFO - root - 2022-02-24 20:17:42.607972: step 90490, total loss = 0.57, batch loss = 0.30 (141.1 examples/sec; 0.057 sec/batch; 1h:43m:00s remains)
INFO - root - 2022-02-24 20:17:43.434322: step 90500, total loss = 0.58, batch loss = 0.32 (218.7 examples/sec; 0.037 sec/batch; 1h:06m:27s remains)
INFO - root - 2022-02-24 20:17:43.915537: step 90510, total loss = 0.62, batch loss = 0.35 (120.3 examples/sec; 0.067 sec/batch; 2h:00m:50s remains)
INFO - root - 2022-02-24 20:17:44.346081: step 90520, total loss = 0.59, batch loss = 0.32 (233.9 examples/sec; 0.034 sec/batch; 1h:02m:07s remains)
INFO - root - 2022-02-24 20:17:44.693321: step 90530, total loss = 0.62, batch loss = 0.36 (286.8 examples/sec; 0.028 sec/batch; 0h:50m:39s remains)
INFO - root - 2022-02-24 20:17:44.969974: step 90540, total loss = 0.55, batch loss = 0.29 (338.5 examples/sec; 0.024 sec/batch; 0h:42m:54s remains)
INFO - root - 2022-02-24 20:17:45.280244: step 90550, total loss = 0.61, batch loss = 0.35 (339.6 examples/sec; 0.024 sec/batch; 0h:42m:46s remains)
INFO - root - 2022-02-24 20:17:45.700646: step 90560, total loss = 0.50, batch loss = 0.23 (171.5 examples/sec; 0.047 sec/batch; 1h:24m:40s remains)
INFO - root - 2022-02-24 20:17:46.090295: step 90570, total loss = 0.57, batch loss = 0.30 (230.0 examples/sec; 0.035 sec/batch; 1h:03m:09s remains)
INFO - root - 2022-02-24 20:17:46.415321: step 90580, total loss = 0.57, batch loss = 0.30 (366.7 examples/sec; 0.022 sec/batch; 0h:39m:36s remains)
INFO - root - 2022-02-24 20:17:46.752764: step 90590, total loss = 0.54, batch loss = 0.27 (240.6 examples/sec; 0.033 sec/batch; 1h:00m:20s remains)
INFO - root - 2022-02-24 20:17:47.072167: step 90600, total loss = 0.71, batch loss = 0.45 (316.4 examples/sec; 0.025 sec/batch; 0h:45m:53s remains)
INFO - root - 2022-02-24 20:17:47.457025: step 90610, total loss = 0.53, batch loss = 0.26 (247.1 examples/sec; 0.032 sec/batch; 0h:58m:45s remains)
INFO - root - 2022-02-24 20:17:47.866209: step 90620, total loss = 0.47, batch loss = 0.21 (186.7 examples/sec; 0.043 sec/batch; 1h:17m:44s remains)
INFO - root - 2022-02-24 20:17:48.208370: step 90630, total loss = 0.61, batch loss = 0.35 (202.6 examples/sec; 0.039 sec/batch; 1h:11m:38s remains)
INFO - root - 2022-02-24 20:17:48.614571: step 90640, total loss = 0.52, batch loss = 0.26 (258.2 examples/sec; 0.031 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 20:17:48.943415: step 90650, total loss = 0.46, batch loss = 0.19 (126.3 examples/sec; 0.063 sec/batch; 1h:54m:57s remains)
INFO - root - 2022-02-24 20:17:49.204394: step 90660, total loss = 0.76, batch loss = 0.49 (329.3 examples/sec; 0.024 sec/batch; 0h:44m:04s remains)
INFO - root - 2022-02-24 20:17:49.590648: step 90670, total loss = 0.52, batch loss = 0.25 (281.1 examples/sec; 0.028 sec/batch; 0h:51m:37s remains)
INFO - root - 2022-02-24 20:17:49.987476: step 90680, total loss = 0.54, batch loss = 0.27 (239.2 examples/sec; 0.033 sec/batch; 1h:00m:40s remains)
INFO - root - 2022-02-24 20:17:50.419999: step 90690, total loss = 0.53, batch loss = 0.27 (122.2 examples/sec; 0.065 sec/batch; 1h:58m:43s remains)
INFO - root - 2022-02-24 20:17:50.773755: step 90700, total loss = 0.57, batch loss = 0.31 (164.3 examples/sec; 0.049 sec/batch; 1h:28m:16s remains)
INFO - root - 2022-02-24 20:17:51.131252: step 90710, total loss = 0.71, batch loss = 0.44 (173.2 examples/sec; 0.046 sec/batch; 1h:23m:46s remains)
INFO - root - 2022-02-24 20:17:51.413850: step 90720, total loss = 0.51, batch loss = 0.25 (235.4 examples/sec; 0.034 sec/batch; 1h:01m:36s remains)
INFO - root - 2022-02-24 20:17:51.685089: step 90730, total loss = 0.50, batch loss = 0.23 (337.3 examples/sec; 0.024 sec/batch; 0h:42m:59s remains)
INFO - root - 2022-02-24 20:17:51.998627: step 90740, total loss = 0.50, batch loss = 0.24 (221.6 examples/sec; 0.036 sec/batch; 1h:05m:26s remains)
INFO - root - 2022-02-24 20:17:52.390805: step 90750, total loss = 0.62, batch loss = 0.36 (117.6 examples/sec; 0.068 sec/batch; 2h:03m:18s remains)
INFO - root - 2022-02-24 20:17:52.751308: step 90760, total loss = 0.56, batch loss = 0.30 (299.5 examples/sec; 0.027 sec/batch; 0h:48m:24s remains)
INFO - root - 2022-02-24 20:17:53.194902: step 90770, total loss = 0.64, batch loss = 0.38 (90.9 examples/sec; 0.088 sec/batch; 2h:39m:24s remains)
INFO - root - 2022-02-24 20:17:53.636018: step 90780, total loss = 0.73, batch loss = 0.46 (258.9 examples/sec; 0.031 sec/batch; 0h:55m:59s remains)
INFO - root - 2022-02-24 20:17:53.978879: step 90790, total loss = 0.57, batch loss = 0.30 (217.0 examples/sec; 0.037 sec/batch; 1h:06m:47s remains)
INFO - root - 2022-02-24 20:17:54.400958: step 90800, total loss = 0.57, batch loss = 0.30 (135.2 examples/sec; 0.059 sec/batch; 1h:47m:13s remains)
INFO - root - 2022-02-24 20:17:55.373913: step 90810, total loss = 0.55, batch loss = 0.28 (321.7 examples/sec; 0.025 sec/batch; 0h:45m:02s remains)
INFO - root - 2022-02-24 20:17:55.731225: step 90820, total loss = 0.67, batch loss = 0.40 (197.7 examples/sec; 0.040 sec/batch; 1h:13m:17s remains)
INFO - root - 2022-02-24 20:17:56.021616: step 90830, total loss = 0.64, batch loss = 0.37 (246.3 examples/sec; 0.032 sec/batch; 0h:58m:49s remains)
INFO - root - 2022-02-24 20:17:56.319060: step 90840, total loss = 0.54, batch loss = 0.27 (340.3 examples/sec; 0.024 sec/batch; 0h:42m:34s remains)
INFO - root - 2022-02-24 20:17:56.686354: step 90850, total loss = 0.53, batch loss = 0.26 (194.1 examples/sec; 0.041 sec/batch; 1h:14m:37s remains)
INFO - root - 2022-02-24 20:17:57.045028: step 90860, total loss = 0.63, batch loss = 0.36 (188.5 examples/sec; 0.042 sec/batch; 1h:16m:49s remains)
INFO - root - 2022-02-24 20:17:57.429360: step 90870, total loss = 0.61, batch loss = 0.35 (337.4 examples/sec; 0.024 sec/batch; 0h:42m:55s remains)
INFO - root - 2022-02-24 20:17:57.681595: step 90880, total loss = 0.56, batch loss = 0.30 (296.1 examples/sec; 0.027 sec/batch; 0h:48m:54s remains)
INFO - root - 2022-02-24 20:17:57.936695: step 90890, total loss = 0.58, batch loss = 0.32 (195.9 examples/sec; 0.041 sec/batch; 1h:13m:54s remains)
INFO - root - 2022-02-24 20:17:58.194931: step 90900, total loss = 0.60, batch loss = 0.34 (352.7 examples/sec; 0.023 sec/batch; 0h:41m:03s remains)
INFO - root - 2022-02-24 20:17:58.558754: step 90910, total loss = 0.50, batch loss = 0.23 (326.9 examples/sec; 0.024 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:17:59.036509: step 90920, total loss = 0.61, batch loss = 0.34 (195.0 examples/sec; 0.041 sec/batch; 1h:14m:14s remains)
INFO - root - 2022-02-24 20:17:59.380491: step 90930, total loss = 0.59, batch loss = 0.33 (319.6 examples/sec; 0.025 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 20:18:00.166239: step 90940, total loss = 0.56, batch loss = 0.29 (312.7 examples/sec; 0.026 sec/batch; 0h:46m:17s remains)
INFO - root - 2022-02-24 20:18:00.444316: step 90950, total loss = 0.48, batch loss = 0.21 (176.1 examples/sec; 0.045 sec/batch; 1h:22m:11s remains)
INFO - root - 2022-02-24 20:18:00.885934: step 90960, total loss = 0.48, batch loss = 0.22 (68.5 examples/sec; 0.117 sec/batch; 3h:31m:20s remains)
INFO - root - 2022-02-24 20:18:01.268286: step 90970, total loss = 0.62, batch loss = 0.36 (283.5 examples/sec; 0.028 sec/batch; 0h:51m:02s remains)
INFO - root - 2022-02-24 20:18:01.700437: step 90980, total loss = 0.63, batch loss = 0.37 (254.6 examples/sec; 0.031 sec/batch; 0h:56m:50s remains)
INFO - root - 2022-02-24 20:18:02.020525: step 90990, total loss = 0.58, batch loss = 0.32 (161.3 examples/sec; 0.050 sec/batch; 1h:29m:41s remains)
INFO - root - 2022-02-24 20:18:02.289769: step 91000, total loss = 0.65, batch loss = 0.39 (327.2 examples/sec; 0.024 sec/batch; 0h:44m:12s remains)
INFO - root - 2022-02-24 20:18:02.763695: step 91010, total loss = 0.53, batch loss = 0.26 (358.0 examples/sec; 0.022 sec/batch; 0h:40m:24s remains)
INFO - root - 2022-02-24 20:18:03.356367: step 91020, total loss = 0.54, batch loss = 0.27 (64.5 examples/sec; 0.124 sec/batch; 3h:44m:14s remains)
INFO - root - 2022-02-24 20:18:03.653689: step 91030, total loss = 0.66, batch loss = 0.39 (330.6 examples/sec; 0.024 sec/batch; 0h:43m:44s remains)
INFO - root - 2022-02-24 20:18:03.963010: step 91040, total loss = 0.52, batch loss = 0.25 (336.4 examples/sec; 0.024 sec/batch; 0h:42m:58s remains)
INFO - root - 2022-02-24 20:18:04.242499: step 91050, total loss = 0.55, batch loss = 0.28 (183.8 examples/sec; 0.044 sec/batch; 1h:18m:39s remains)
INFO - root - 2022-02-24 20:18:04.571431: step 91060, total loss = 0.51, batch loss = 0.25 (191.7 examples/sec; 0.042 sec/batch; 1h:15m:25s remains)
INFO - root - 2022-02-24 20:18:05.008141: step 91070, total loss = 0.51, batch loss = 0.25 (168.9 examples/sec; 0.047 sec/batch; 1h:25m:36s remains)
INFO - root - 2022-02-24 20:18:05.400940: step 91080, total loss = 0.55, batch loss = 0.29 (321.4 examples/sec; 0.025 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 20:18:05.720944: step 91090, total loss = 0.65, batch loss = 0.39 (371.6 examples/sec; 0.022 sec/batch; 0h:38m:53s remains)
INFO - root - 2022-02-24 20:18:06.009059: step 91100, total loss = 0.62, batch loss = 0.36 (178.0 examples/sec; 0.045 sec/batch; 1h:21m:13s remains)
INFO - root - 2022-02-24 20:18:06.424091: step 91110, total loss = 0.67, batch loss = 0.40 (192.1 examples/sec; 0.042 sec/batch; 1h:15m:12s remains)
INFO - root - 2022-02-24 20:18:06.835262: step 91120, total loss = 0.64, batch loss = 0.38 (102.6 examples/sec; 0.078 sec/batch; 2h:20m:47s remains)
INFO - root - 2022-02-24 20:18:07.247993: step 91130, total loss = 0.58, batch loss = 0.31 (91.3 examples/sec; 0.088 sec/batch; 2h:38m:17s remains)
INFO - root - 2022-02-24 20:18:07.538683: step 91140, total loss = 0.53, batch loss = 0.26 (323.2 examples/sec; 0.025 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:18:07.819564: step 91150, total loss = 0.53, batch loss = 0.27 (350.5 examples/sec; 0.023 sec/batch; 0h:41m:12s remains)
INFO - root - 2022-02-24 20:18:08.120991: step 91160, total loss = 0.62, batch loss = 0.36 (234.6 examples/sec; 0.034 sec/batch; 1h:01m:34s remains)
INFO - root - 2022-02-24 20:18:08.601527: step 91170, total loss = 0.52, batch loss = 0.25 (230.2 examples/sec; 0.035 sec/batch; 1h:02m:45s remains)
INFO - root - 2022-02-24 20:18:08.971851: step 91180, total loss = 0.66, batch loss = 0.40 (257.8 examples/sec; 0.031 sec/batch; 0h:56m:01s remains)
INFO - root - 2022-02-24 20:18:09.307157: step 91190, total loss = 0.55, batch loss = 0.28 (125.7 examples/sec; 0.064 sec/batch; 1h:54m:50s remains)
INFO - root - 2022-02-24 20:18:09.635818: step 91200, total loss = 0.58, batch loss = 0.32 (157.3 examples/sec; 0.051 sec/batch; 1h:31m:46s remains)
INFO - root - 2022-02-24 20:18:10.494028: step 91210, total loss = 0.62, batch loss = 0.36 (356.3 examples/sec; 0.022 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:18:11.017107: step 91220, total loss = 0.51, batch loss = 0.24 (94.3 examples/sec; 0.085 sec/batch; 2h:33m:10s remains)
INFO - root - 2022-02-24 20:18:11.397304: step 91230, total loss = 0.57, batch loss = 0.30 (233.2 examples/sec; 0.034 sec/batch; 1h:01m:54s remains)
INFO - root - 2022-02-24 20:18:11.744101: step 91240, total loss = 0.63, batch loss = 0.36 (221.9 examples/sec; 0.036 sec/batch; 1h:05m:03s remains)
INFO - root - 2022-02-24 20:18:12.108989: step 91250, total loss = 0.53, batch loss = 0.26 (329.9 examples/sec; 0.024 sec/batch; 0h:43m:44s remains)
INFO - root - 2022-02-24 20:18:12.402847: step 91260, total loss = 0.50, batch loss = 0.24 (322.7 examples/sec; 0.025 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:18:12.770399: step 91270, total loss = 0.52, batch loss = 0.26 (98.0 examples/sec; 0.082 sec/batch; 2h:27m:14s remains)
INFO - root - 2022-02-24 20:18:13.203875: step 91280, total loss = 0.54, batch loss = 0.28 (146.4 examples/sec; 0.055 sec/batch; 1h:38m:32s remains)
INFO - root - 2022-02-24 20:18:14.046816: step 91290, total loss = 0.65, batch loss = 0.38 (246.6 examples/sec; 0.032 sec/batch; 0h:58m:30s remains)
INFO - root - 2022-02-24 20:18:14.329620: step 91300, total loss = 0.57, batch loss = 0.30 (258.5 examples/sec; 0.031 sec/batch; 0h:55m:48s remains)
INFO - root - 2022-02-24 20:18:14.851461: step 91310, total loss = 0.61, batch loss = 0.35 (125.7 examples/sec; 0.064 sec/batch; 1h:54m:47s remains)
INFO - root - 2022-02-24 20:18:15.278183: step 91320, total loss = 0.59, batch loss = 0.32 (160.4 examples/sec; 0.050 sec/batch; 1h:29m:55s remains)
INFO - root - 2022-02-24 20:18:15.575561: step 91330, total loss = 0.59, batch loss = 0.32 (278.3 examples/sec; 0.029 sec/batch; 0h:51m:48s remains)
INFO - root - 2022-02-24 20:18:15.863468: step 91340, total loss = 0.73, batch loss = 0.46 (301.8 examples/sec; 0.027 sec/batch; 0h:47m:46s remains)
INFO - root - 2022-02-24 20:18:16.195563: step 91350, total loss = 0.55, batch loss = 0.29 (149.4 examples/sec; 0.054 sec/batch; 1h:36m:32s remains)
INFO - root - 2022-02-24 20:18:16.591319: step 91360, total loss = 0.62, batch loss = 0.35 (111.1 examples/sec; 0.072 sec/batch; 2h:09m:49s remains)
INFO - root - 2022-02-24 20:18:16.939426: step 91370, total loss = 0.61, batch loss = 0.34 (330.6 examples/sec; 0.024 sec/batch; 0h:43m:36s remains)
INFO - root - 2022-02-24 20:18:17.269250: step 91380, total loss = 0.61, batch loss = 0.35 (278.0 examples/sec; 0.029 sec/batch; 0h:51m:51s remains)
INFO - root - 2022-02-24 20:18:17.612814: step 91390, total loss = 0.52, batch loss = 0.25 (213.6 examples/sec; 0.037 sec/batch; 1h:07m:29s remains)
INFO - root - 2022-02-24 20:18:17.950979: step 91400, total loss = 0.48, batch loss = 0.21 (314.9 examples/sec; 0.025 sec/batch; 0h:45m:46s remains)
INFO - root - 2022-02-24 20:18:18.308323: step 91410, total loss = 0.59, batch loss = 0.33 (348.4 examples/sec; 0.023 sec/batch; 0h:41m:22s remains)
INFO - root - 2022-02-24 20:18:18.656533: step 91420, total loss = 0.60, batch loss = 0.34 (141.7 examples/sec; 0.056 sec/batch; 1h:41m:40s remains)
INFO - root - 2022-02-24 20:18:19.119546: step 91430, total loss = 0.45, batch loss = 0.18 (105.2 examples/sec; 0.076 sec/batch; 2h:16m:56s remains)
INFO - root - 2022-02-24 20:18:19.507568: step 91440, total loss = 0.52, batch loss = 0.26 (187.0 examples/sec; 0.043 sec/batch; 1h:17m:01s remains)
INFO - root - 2022-02-24 20:18:19.864143: step 91450, total loss = 0.54, batch loss = 0.27 (256.4 examples/sec; 0.031 sec/batch; 0h:56m:10s remains)
INFO - root - 2022-02-24 20:18:20.154264: step 91460, total loss = 0.56, batch loss = 0.29 (299.3 examples/sec; 0.027 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:18:20.421368: step 91470, total loss = 0.53, batch loss = 0.27 (322.9 examples/sec; 0.025 sec/batch; 0h:44m:36s remains)
INFO - root - 2022-02-24 20:18:20.723690: step 91480, total loss = 0.57, batch loss = 0.31 (186.2 examples/sec; 0.043 sec/batch; 1h:17m:20s remains)
INFO - root - 2022-02-24 20:18:21.099475: step 91490, total loss = 0.52, batch loss = 0.25 (349.9 examples/sec; 0.023 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:18:21.467863: step 91500, total loss = 0.62, batch loss = 0.36 (204.8 examples/sec; 0.039 sec/batch; 1h:10m:18s remains)
INFO - root - 2022-02-24 20:18:21.945003: step 91510, total loss = 0.69, batch loss = 0.43 (131.0 examples/sec; 0.061 sec/batch; 1h:49m:54s remains)
INFO - root - 2022-02-24 20:18:22.539821: step 91520, total loss = 0.58, batch loss = 0.31 (230.9 examples/sec; 0.035 sec/batch; 1h:02m:20s remains)
INFO - root - 2022-02-24 20:18:22.924881: step 91530, total loss = 0.49, batch loss = 0.22 (133.0 examples/sec; 0.060 sec/batch; 1h:48m:13s remains)
INFO - root - 2022-02-24 20:18:23.250675: step 91540, total loss = 0.60, batch loss = 0.33 (346.7 examples/sec; 0.023 sec/batch; 0h:41m:30s remains)
INFO - root - 2022-02-24 20:18:23.668545: step 91550, total loss = 0.51, batch loss = 0.25 (247.9 examples/sec; 0.032 sec/batch; 0h:58m:03s remains)
INFO - root - 2022-02-24 20:18:23.988158: step 91560, total loss = 0.48, batch loss = 0.22 (312.5 examples/sec; 0.026 sec/batch; 0h:46m:03s remains)
INFO - root - 2022-02-24 20:18:24.831859: step 91570, total loss = 0.57, batch loss = 0.30 (170.5 examples/sec; 0.047 sec/batch; 1h:24m:25s remains)
INFO - root - 2022-02-24 20:18:25.232641: step 91580, total loss = 0.50, batch loss = 0.23 (148.0 examples/sec; 0.054 sec/batch; 1h:37m:13s remains)
INFO - root - 2022-02-24 20:18:25.606335: step 91590, total loss = 0.56, batch loss = 0.29 (235.9 examples/sec; 0.034 sec/batch; 1h:00m:59s remains)
INFO - root - 2022-02-24 20:18:26.034213: step 91600, total loss = 0.65, batch loss = 0.38 (229.9 examples/sec; 0.035 sec/batch; 1h:02m:34s remains)
INFO - root - 2022-02-24 20:18:26.404209: step 91610, total loss = 0.60, batch loss = 0.33 (392.1 examples/sec; 0.020 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:18:26.775500: step 91620, total loss = 0.50, batch loss = 0.24 (334.6 examples/sec; 0.024 sec/batch; 0h:42m:59s remains)
INFO - root - 2022-02-24 20:18:27.034402: step 91630, total loss = 0.51, batch loss = 0.24 (237.2 examples/sec; 0.034 sec/batch; 1h:00m:37s remains)
INFO - root - 2022-02-24 20:18:27.419430: step 91640, total loss = 0.56, batch loss = 0.29 (177.8 examples/sec; 0.045 sec/batch; 1h:20m:53s remains)
INFO - root - 2022-02-24 20:18:27.938879: step 91650, total loss = 0.56, batch loss = 0.30 (59.2 examples/sec; 0.135 sec/batch; 4h:03m:02s remains)
INFO - root - 2022-02-24 20:18:28.295296: step 91660, total loss = 0.54, batch loss = 0.28 (168.6 examples/sec; 0.047 sec/batch; 1h:25m:17s remains)
INFO - root - 2022-02-24 20:18:28.723704: step 91670, total loss = 0.48, batch loss = 0.22 (239.9 examples/sec; 0.033 sec/batch; 0h:59m:55s remains)
INFO - root - 2022-02-24 20:18:29.173434: step 91680, total loss = 0.46, batch loss = 0.20 (142.9 examples/sec; 0.056 sec/batch; 1h:40m:36s remains)
INFO - root - 2022-02-24 20:18:29.534287: step 91690, total loss = 0.55, batch loss = 0.28 (209.2 examples/sec; 0.038 sec/batch; 1h:08m:42s remains)
INFO - root - 2022-02-24 20:18:29.971479: step 91700, total loss = 0.53, batch loss = 0.27 (346.3 examples/sec; 0.023 sec/batch; 0h:41m:30s remains)
INFO - root - 2022-02-24 20:18:30.403357: step 91710, total loss = 0.49, batch loss = 0.22 (200.7 examples/sec; 0.040 sec/batch; 1h:11m:36s remains)
INFO - root - 2022-02-24 20:18:30.671769: step 91720, total loss = 0.58, batch loss = 0.32 (333.6 examples/sec; 0.024 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:18:31.082754: step 91730, total loss = 0.55, batch loss = 0.29 (173.1 examples/sec; 0.046 sec/batch; 1h:23m:00s remains)
INFO - root - 2022-02-24 20:18:31.630603: step 91740, total loss = 0.66, batch loss = 0.39 (71.5 examples/sec; 0.112 sec/batch; 3h:21m:04s remains)
INFO - root - 2022-02-24 20:18:32.051914: step 91750, total loss = 0.54, batch loss = 0.27 (319.5 examples/sec; 0.025 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 20:18:32.461667: step 91760, total loss = 0.52, batch loss = 0.26 (299.6 examples/sec; 0.027 sec/batch; 0h:47m:56s remains)
INFO - root - 2022-02-24 20:18:32.805833: step 91770, total loss = 0.62, batch loss = 0.36 (319.3 examples/sec; 0.025 sec/batch; 0h:44m:59s remains)
INFO - root - 2022-02-24 20:18:33.150352: step 91780, total loss = 0.57, batch loss = 0.30 (118.5 examples/sec; 0.068 sec/batch; 2h:01m:13s remains)
INFO - root - 2022-02-24 20:18:33.644431: step 91790, total loss = 0.53, batch loss = 0.27 (231.3 examples/sec; 0.035 sec/batch; 1h:02m:06s remains)
INFO - root - 2022-02-24 20:18:34.140586: step 91800, total loss = 0.50, batch loss = 0.23 (161.9 examples/sec; 0.049 sec/batch; 1h:28m:43s remains)
INFO - root - 2022-02-24 20:18:35.150306: step 91810, total loss = 0.47, batch loss = 0.21 (261.4 examples/sec; 0.031 sec/batch; 0h:54m:55s remains)
INFO - root - 2022-02-24 20:18:35.597263: step 91820, total loss = 0.53, batch loss = 0.27 (222.4 examples/sec; 0.036 sec/batch; 1h:04m:33s remains)
INFO - root - 2022-02-24 20:18:35.975146: step 91830, total loss = 0.54, batch loss = 0.28 (358.2 examples/sec; 0.022 sec/batch; 0h:40m:04s remains)
INFO - root - 2022-02-24 20:18:36.394592: step 91840, total loss = 0.53, batch loss = 0.27 (129.8 examples/sec; 0.062 sec/batch; 1h:50m:35s remains)
INFO - root - 2022-02-24 20:18:36.719905: step 91850, total loss = 0.54, batch loss = 0.28 (254.9 examples/sec; 0.031 sec/batch; 0h:56m:18s remains)
INFO - root - 2022-02-24 20:18:37.033806: step 91860, total loss = 0.60, batch loss = 0.34 (247.7 examples/sec; 0.032 sec/batch; 0h:57m:56s remains)
INFO - root - 2022-02-24 20:18:37.455979: step 91870, total loss = 0.49, batch loss = 0.23 (198.9 examples/sec; 0.040 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 20:18:37.830026: step 91880, total loss = 0.59, batch loss = 0.33 (162.9 examples/sec; 0.049 sec/batch; 1h:28m:06s remains)
INFO - root - 2022-02-24 20:18:38.233183: step 91890, total loss = 0.59, batch loss = 0.32 (141.2 examples/sec; 0.057 sec/batch; 1h:41m:35s remains)
INFO - root - 2022-02-24 20:18:38.535210: step 91900, total loss = 0.54, batch loss = 0.27 (328.3 examples/sec; 0.024 sec/batch; 0h:43m:41s remains)
INFO - root - 2022-02-24 20:18:39.017207: step 91910, total loss = 0.53, batch loss = 0.27 (328.4 examples/sec; 0.024 sec/batch; 0h:43m:41s remains)
INFO - root - 2022-02-24 20:18:39.295416: step 91920, total loss = 0.63, batch loss = 0.36 (288.1 examples/sec; 0.028 sec/batch; 0h:49m:47s remains)
INFO - root - 2022-02-24 20:18:39.625425: step 91930, total loss = 0.55, batch loss = 0.28 (291.3 examples/sec; 0.027 sec/batch; 0h:49m:14s remains)
INFO - root - 2022-02-24 20:18:39.913569: step 91940, total loss = 0.52, batch loss = 0.25 (282.6 examples/sec; 0.028 sec/batch; 0h:50m:45s remains)
INFO - root - 2022-02-24 20:18:40.302671: step 91950, total loss = 0.48, batch loss = 0.22 (84.1 examples/sec; 0.095 sec/batch; 2h:50m:29s remains)
INFO - root - 2022-02-24 20:18:40.741770: step 91960, total loss = 0.57, batch loss = 0.31 (151.0 examples/sec; 0.053 sec/batch; 1h:34m:56s remains)
INFO - root - 2022-02-24 20:18:41.100258: step 91970, total loss = 0.68, batch loss = 0.42 (194.7 examples/sec; 0.041 sec/batch; 1h:13m:38s remains)
INFO - root - 2022-02-24 20:18:41.423815: step 91980, total loss = 0.56, batch loss = 0.30 (190.9 examples/sec; 0.042 sec/batch; 1h:15m:06s remains)
INFO - root - 2022-02-24 20:18:41.718112: step 91990, total loss = 0.59, batch loss = 0.32 (321.5 examples/sec; 0.025 sec/batch; 0h:44m:35s remains)
INFO - root - 2022-02-24 20:18:42.048102: step 92000, total loss = 0.64, batch loss = 0.37 (136.7 examples/sec; 0.059 sec/batch; 1h:44m:52s remains)
INFO - root - 2022-02-24 20:18:42.510546: step 92010, total loss = 0.58, batch loss = 0.31 (309.9 examples/sec; 0.026 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 20:18:42.899714: step 92020, total loss = 0.53, batch loss = 0.27 (227.8 examples/sec; 0.035 sec/batch; 1h:02m:54s remains)
INFO - root - 2022-02-24 20:18:43.318230: step 92030, total loss = 0.49, batch loss = 0.23 (153.6 examples/sec; 0.052 sec/batch; 1h:33m:17s remains)
INFO - root - 2022-02-24 20:18:43.809819: step 92040, total loss = 0.47, batch loss = 0.21 (125.5 examples/sec; 0.064 sec/batch; 1h:54m:07s remains)
INFO - root - 2022-02-24 20:18:44.156658: step 92050, total loss = 0.53, batch loss = 0.26 (132.7 examples/sec; 0.060 sec/batch; 1h:47m:57s remains)
INFO - root - 2022-02-24 20:18:45.082716: step 92060, total loss = 0.55, batch loss = 0.28 (234.7 examples/sec; 0.034 sec/batch; 1h:01m:02s remains)
INFO - root - 2022-02-24 20:18:45.474940: step 92070, total loss = 0.50, batch loss = 0.24 (339.1 examples/sec; 0.024 sec/batch; 0h:42m:14s remains)
INFO - root - 2022-02-24 20:18:45.728586: step 92080, total loss = 0.59, batch loss = 0.33 (320.3 examples/sec; 0.025 sec/batch; 0h:44m:43s remains)
INFO - root - 2022-02-24 20:18:45.978801: step 92090, total loss = 0.62, batch loss = 0.35 (340.2 examples/sec; 0.024 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 20:18:46.284092: step 92100, total loss = 0.56, batch loss = 0.30 (126.7 examples/sec; 0.063 sec/batch; 1h:53m:03s remains)
INFO - root - 2022-02-24 20:18:46.666725: step 92110, total loss = 0.57, batch loss = 0.31 (382.2 examples/sec; 0.021 sec/batch; 0h:37m:27s remains)
INFO - root - 2022-02-24 20:18:47.010573: step 92120, total loss = 0.49, batch loss = 0.22 (268.1 examples/sec; 0.030 sec/batch; 0h:53m:23s remains)
INFO - root - 2022-02-24 20:18:47.390351: step 92130, total loss = 0.54, batch loss = 0.27 (338.7 examples/sec; 0.024 sec/batch; 0h:42m:15s remains)
INFO - root - 2022-02-24 20:18:47.734954: step 92140, total loss = 0.71, batch loss = 0.44 (272.0 examples/sec; 0.029 sec/batch; 0h:52m:37s remains)
INFO - root - 2022-02-24 20:18:48.027856: step 92150, total loss = 0.55, batch loss = 0.28 (343.3 examples/sec; 0.023 sec/batch; 0h:41m:41s remains)
INFO - root - 2022-02-24 20:18:48.337447: step 92160, total loss = 0.65, batch loss = 0.38 (235.7 examples/sec; 0.034 sec/batch; 1h:00m:43s remains)
INFO - root - 2022-02-24 20:18:48.656011: step 92170, total loss = 0.62, batch loss = 0.35 (196.7 examples/sec; 0.041 sec/batch; 1h:12m:44s remains)
INFO - root - 2022-02-24 20:18:48.991457: step 92180, total loss = 0.59, batch loss = 0.33 (216.2 examples/sec; 0.037 sec/batch; 1h:06m:10s remains)
INFO - root - 2022-02-24 20:18:49.415193: step 92190, total loss = 0.64, batch loss = 0.38 (75.8 examples/sec; 0.106 sec/batch; 3h:08m:51s remains)
INFO - root - 2022-02-24 20:18:49.801181: step 92200, total loss = 0.73, batch loss = 0.47 (204.6 examples/sec; 0.039 sec/batch; 1h:09m:55s remains)
INFO - root - 2022-02-24 20:18:50.216051: step 92210, total loss = 0.59, batch loss = 0.32 (168.6 examples/sec; 0.047 sec/batch; 1h:24m:50s remains)
INFO - root - 2022-02-24 20:18:50.588049: step 92220, total loss = 0.48, batch loss = 0.22 (197.1 examples/sec; 0.041 sec/batch; 1h:12m:33s remains)
INFO - root - 2022-02-24 20:18:50.931613: step 92230, total loss = 0.55, batch loss = 0.29 (144.0 examples/sec; 0.056 sec/batch; 1h:39m:21s remains)
INFO - root - 2022-02-24 20:18:51.340165: step 92240, total loss = 0.53, batch loss = 0.26 (374.9 examples/sec; 0.021 sec/batch; 0h:38m:09s remains)
INFO - root - 2022-02-24 20:18:51.796681: step 92250, total loss = 0.78, batch loss = 0.51 (210.8 examples/sec; 0.038 sec/batch; 1h:07m:50s remains)
INFO - root - 2022-02-24 20:18:52.117825: step 92260, total loss = 0.52, batch loss = 0.25 (355.9 examples/sec; 0.022 sec/batch; 0h:40m:10s remains)
INFO - root - 2022-02-24 20:18:52.458381: step 92270, total loss = 0.60, batch loss = 0.34 (260.1 examples/sec; 0.031 sec/batch; 0h:54m:58s remains)
INFO - root - 2022-02-24 20:18:52.802745: step 92280, total loss = 0.51, batch loss = 0.24 (373.6 examples/sec; 0.021 sec/batch; 0h:38m:16s remains)
INFO - root - 2022-02-24 20:18:53.181208: step 92290, total loss = 0.52, batch loss = 0.25 (121.2 examples/sec; 0.066 sec/batch; 1h:57m:59s remains)
INFO - root - 2022-02-24 20:18:53.607055: step 92300, total loss = 0.51, batch loss = 0.24 (90.5 examples/sec; 0.088 sec/batch; 2h:38m:00s remains)
INFO - root - 2022-02-24 20:18:54.053508: step 92310, total loss = 0.54, batch loss = 0.28 (341.5 examples/sec; 0.023 sec/batch; 0h:41m:50s remains)
INFO - root - 2022-02-24 20:18:54.729491: step 92320, total loss = 0.54, batch loss = 0.27 (188.2 examples/sec; 0.043 sec/batch; 1h:15m:56s remains)
INFO - root - 2022-02-24 20:18:55.087628: step 92330, total loss = 0.61, batch loss = 0.34 (247.4 examples/sec; 0.032 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 20:18:55.521143: step 92340, total loss = 0.58, batch loss = 0.32 (100.7 examples/sec; 0.079 sec/batch; 2h:21m:55s remains)
INFO - root - 2022-02-24 20:18:55.902379: step 92350, total loss = 0.60, batch loss = 0.34 (346.9 examples/sec; 0.023 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:18:56.214938: step 92360, total loss = 0.54, batch loss = 0.28 (177.6 examples/sec; 0.045 sec/batch; 1h:20m:26s remains)
INFO - root - 2022-02-24 20:18:56.559360: step 92370, total loss = 0.52, batch loss = 0.26 (187.3 examples/sec; 0.043 sec/batch; 1h:16m:16s remains)
INFO - root - 2022-02-24 20:18:56.925071: step 92380, total loss = 0.77, batch loss = 0.51 (150.1 examples/sec; 0.053 sec/batch; 1h:35m:09s remains)
INFO - root - 2022-02-24 20:18:57.322899: step 92390, total loss = 0.51, batch loss = 0.24 (220.7 examples/sec; 0.036 sec/batch; 1h:04m:41s remains)
INFO - root - 2022-02-24 20:18:57.819442: step 92400, total loss = 0.69, batch loss = 0.42 (348.2 examples/sec; 0.023 sec/batch; 0h:41m:00s remains)
INFO - root - 2022-02-24 20:18:58.214276: step 92410, total loss = 0.53, batch loss = 0.26 (284.9 examples/sec; 0.028 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:18:58.569222: step 92420, total loss = 0.52, batch loss = 0.26 (270.8 examples/sec; 0.030 sec/batch; 0h:52m:43s remains)
INFO - root - 2022-02-24 20:18:58.896956: step 92430, total loss = 0.50, batch loss = 0.23 (107.7 examples/sec; 0.074 sec/batch; 2h:12m:36s remains)
INFO - root - 2022-02-24 20:18:59.314043: step 92440, total loss = 0.54, batch loss = 0.28 (329.2 examples/sec; 0.024 sec/batch; 0h:43m:21s remains)
INFO - root - 2022-02-24 20:19:00.170431: step 92450, total loss = 0.44, batch loss = 0.18 (219.3 examples/sec; 0.036 sec/batch; 1h:05m:05s remains)
INFO - root - 2022-02-24 20:19:00.483835: step 92460, total loss = 0.61, batch loss = 0.34 (331.8 examples/sec; 0.024 sec/batch; 0h:43m:01s remains)
INFO - root - 2022-02-24 20:19:00.847383: step 92470, total loss = 0.56, batch loss = 0.30 (198.5 examples/sec; 0.040 sec/batch; 1h:11m:54s remains)
INFO - root - 2022-02-24 20:19:01.160019: step 92480, total loss = 0.50, batch loss = 0.23 (127.2 examples/sec; 0.063 sec/batch; 1h:52m:09s remains)
INFO - root - 2022-02-24 20:19:01.479947: step 92490, total loss = 0.61, batch loss = 0.34 (304.7 examples/sec; 0.026 sec/batch; 0h:46m:49s remains)
INFO - root - 2022-02-24 20:19:02.018061: step 92500, total loss = 0.52, batch loss = 0.26 (122.6 examples/sec; 0.065 sec/batch; 1h:56m:21s remains)
INFO - root - 2022-02-24 20:19:02.470547: step 92510, total loss = 0.48, batch loss = 0.22 (214.1 examples/sec; 0.037 sec/batch; 1h:06m:37s remains)
INFO - root - 2022-02-24 20:19:02.907421: step 92520, total loss = 0.54, batch loss = 0.28 (205.0 examples/sec; 0.039 sec/batch; 1h:09m:34s remains)
INFO - root - 2022-02-24 20:19:03.236541: step 92530, total loss = 0.46, batch loss = 0.20 (226.5 examples/sec; 0.035 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 20:19:03.511133: step 92540, total loss = 0.72, batch loss = 0.45 (325.7 examples/sec; 0.025 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:19:03.879465: step 92550, total loss = 0.70, batch loss = 0.44 (285.3 examples/sec; 0.028 sec/batch; 0h:49m:58s remains)
INFO - root - 2022-02-24 20:19:04.222878: step 92560, total loss = 0.54, batch loss = 0.27 (258.5 examples/sec; 0.031 sec/batch; 0h:55m:09s remains)
INFO - root - 2022-02-24 20:19:05.135486: step 92570, total loss = 0.54, batch loss = 0.28 (14.0 examples/sec; 0.570 sec/batch; 16h:54m:59s remains)
INFO - root - 2022-02-24 20:19:05.490021: step 92580, total loss = 0.64, batch loss = 0.38 (324.8 examples/sec; 0.025 sec/batch; 0h:43m:53s remains)
INFO - root - 2022-02-24 20:19:05.786490: step 92590, total loss = 0.49, batch loss = 0.23 (250.2 examples/sec; 0.032 sec/batch; 0h:56m:58s remains)
INFO - root - 2022-02-24 20:19:06.055263: step 92600, total loss = 0.54, batch loss = 0.27 (244.0 examples/sec; 0.033 sec/batch; 0h:58m:24s remains)
INFO - root - 2022-02-24 20:19:06.526235: step 92610, total loss = 0.51, batch loss = 0.25 (156.9 examples/sec; 0.051 sec/batch; 1h:30m:48s remains)
INFO - root - 2022-02-24 20:19:06.998075: step 92620, total loss = 0.54, batch loss = 0.27 (110.1 examples/sec; 0.073 sec/batch; 2h:09m:28s remains)
INFO - root - 2022-02-24 20:19:07.347967: step 92630, total loss = 0.66, batch loss = 0.40 (342.7 examples/sec; 0.023 sec/batch; 0h:41m:35s remains)
INFO - root - 2022-02-24 20:19:07.613246: step 92640, total loss = 0.50, batch loss = 0.24 (342.7 examples/sec; 0.023 sec/batch; 0h:41m:34s remains)
INFO - root - 2022-02-24 20:19:07.924149: step 92650, total loss = 0.58, batch loss = 0.31 (222.1 examples/sec; 0.036 sec/batch; 1h:04m:09s remains)
INFO - root - 2022-02-24 20:19:08.257556: step 92660, total loss = 0.54, batch loss = 0.27 (322.2 examples/sec; 0.025 sec/batch; 0h:44m:12s remains)
INFO - root - 2022-02-24 20:19:08.511188: step 92670, total loss = 0.53, batch loss = 0.26 (347.1 examples/sec; 0.023 sec/batch; 0h:41m:02s remains)
INFO - root - 2022-02-24 20:19:08.927315: step 92680, total loss = 0.60, batch loss = 0.33 (169.6 examples/sec; 0.047 sec/batch; 1h:23m:59s remains)
INFO - root - 2022-02-24 20:19:09.347189: step 92690, total loss = 0.63, batch loss = 0.36 (261.3 examples/sec; 0.031 sec/batch; 0h:54m:30s remains)
INFO - root - 2022-02-24 20:19:09.628611: step 92700, total loss = 0.52, batch loss = 0.25 (327.1 examples/sec; 0.024 sec/batch; 0h:43m:32s remains)
INFO - root - 2022-02-24 20:19:10.027895: step 92710, total loss = 0.49, batch loss = 0.22 (250.6 examples/sec; 0.032 sec/batch; 0h:56m:48s remains)
INFO - root - 2022-02-24 20:19:10.325669: step 92720, total loss = 0.67, batch loss = 0.40 (245.0 examples/sec; 0.033 sec/batch; 0h:58m:06s remains)
INFO - root - 2022-02-24 20:19:10.723676: step 92730, total loss = 0.74, batch loss = 0.48 (174.3 examples/sec; 0.046 sec/batch; 1h:21m:40s remains)
INFO - root - 2022-02-24 20:19:11.108294: step 92740, total loss = 0.53, batch loss = 0.27 (307.6 examples/sec; 0.026 sec/batch; 0h:46m:16s remains)
INFO - root - 2022-02-24 20:19:11.460465: step 92750, total loss = 0.53, batch loss = 0.26 (306.9 examples/sec; 0.026 sec/batch; 0h:46m:22s remains)
INFO - root - 2022-02-24 20:19:11.853244: step 92760, total loss = 0.55, batch loss = 0.28 (261.9 examples/sec; 0.031 sec/batch; 0h:54m:19s remains)
INFO - root - 2022-02-24 20:19:12.194623: step 92770, total loss = 0.50, batch loss = 0.24 (347.5 examples/sec; 0.023 sec/batch; 0h:40m:56s remains)
INFO - root - 2022-02-24 20:19:12.490778: step 92780, total loss = 0.48, batch loss = 0.22 (339.8 examples/sec; 0.024 sec/batch; 0h:41m:52s remains)
INFO - root - 2022-02-24 20:19:12.992698: step 92790, total loss = 0.60, batch loss = 0.33 (99.3 examples/sec; 0.081 sec/batch; 2h:23m:18s remains)
INFO - root - 2022-02-24 20:19:13.506418: step 92800, total loss = 0.48, batch loss = 0.22 (117.1 examples/sec; 0.068 sec/batch; 2h:01m:28s remains)
INFO - root - 2022-02-24 20:19:14.037746: step 92810, total loss = 0.63, batch loss = 0.36 (321.5 examples/sec; 0.025 sec/batch; 0h:44m:14s remains)
INFO - root - 2022-02-24 20:19:14.276133: step 92820, total loss = 0.59, batch loss = 0.33 (348.2 examples/sec; 0.023 sec/batch; 0h:40m:51s remains)
INFO - root - 2022-02-24 20:19:14.605266: step 92830, total loss = 0.54, batch loss = 0.28 (122.9 examples/sec; 0.065 sec/batch; 1h:55m:41s remains)
INFO - root - 2022-02-24 20:19:14.947923: step 92840, total loss = 0.48, batch loss = 0.22 (256.7 examples/sec; 0.031 sec/batch; 0h:55m:23s remains)
INFO - root - 2022-02-24 20:19:15.936933: step 92850, total loss = 0.56, batch loss = 0.30 (92.8 examples/sec; 0.086 sec/batch; 2h:33m:15s remains)
INFO - root - 2022-02-24 20:19:16.304498: step 92860, total loss = 0.52, batch loss = 0.25 (253.9 examples/sec; 0.032 sec/batch; 0h:55m:59s remains)
INFO - root - 2022-02-24 20:19:16.611944: step 92870, total loss = 0.58, batch loss = 0.32 (214.9 examples/sec; 0.037 sec/batch; 1h:06m:10s remains)
INFO - root - 2022-02-24 20:19:16.927722: step 92880, total loss = 0.48, batch loss = 0.21 (166.9 examples/sec; 0.048 sec/batch; 1h:25m:10s remains)
INFO - root - 2022-02-24 20:19:17.235546: step 92890, total loss = 0.58, batch loss = 0.32 (182.4 examples/sec; 0.044 sec/batch; 1h:17m:55s remains)
INFO - root - 2022-02-24 20:19:17.567165: step 92900, total loss = 0.59, batch loss = 0.33 (325.3 examples/sec; 0.025 sec/batch; 0h:43m:41s remains)
INFO - root - 2022-02-24 20:19:17.915049: step 92910, total loss = 0.51, batch loss = 0.24 (291.4 examples/sec; 0.027 sec/batch; 0h:48m:46s remains)
INFO - root - 2022-02-24 20:19:18.265724: step 92920, total loss = 0.65, batch loss = 0.38 (335.2 examples/sec; 0.024 sec/batch; 0h:42m:23s remains)
INFO - root - 2022-02-24 20:19:18.548795: step 92930, total loss = 0.51, batch loss = 0.24 (353.3 examples/sec; 0.023 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:19:18.794208: step 92940, total loss = 0.55, batch loss = 0.28 (311.0 examples/sec; 0.026 sec/batch; 0h:45m:41s remains)
INFO - root - 2022-02-24 20:19:19.091233: step 92950, total loss = 0.54, batch loss = 0.27 (226.9 examples/sec; 0.035 sec/batch; 1h:02m:36s remains)
INFO - root - 2022-02-24 20:19:19.389949: step 92960, total loss = 0.60, batch loss = 0.33 (203.0 examples/sec; 0.039 sec/batch; 1h:09m:58s remains)
INFO - root - 2022-02-24 20:19:19.819356: step 92970, total loss = 0.56, batch loss = 0.30 (112.4 examples/sec; 0.071 sec/batch; 2h:06m:20s remains)
INFO - root - 2022-02-24 20:19:20.301563: step 92980, total loss = 0.62, batch loss = 0.36 (266.6 examples/sec; 0.030 sec/batch; 0h:53m:15s remains)
INFO - root - 2022-02-24 20:19:20.687490: step 92990, total loss = 0.48, batch loss = 0.22 (281.2 examples/sec; 0.028 sec/batch; 0h:50m:30s remains)
INFO - root - 2022-02-24 20:19:21.013874: step 93000, total loss = 0.55, batch loss = 0.28 (130.1 examples/sec; 0.061 sec/batch; 1h:49m:08s remains)
INFO - root - 2022-02-24 20:19:21.374234: step 93010, total loss = 0.58, batch loss = 0.31 (307.0 examples/sec; 0.026 sec/batch; 0h:46m:15s remains)
INFO - root - 2022-02-24 20:19:21.637814: step 93020, total loss = 0.66, batch loss = 0.39 (307.4 examples/sec; 0.026 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:19:22.001875: step 93030, total loss = 0.60, batch loss = 0.33 (356.7 examples/sec; 0.022 sec/batch; 0h:39m:48s remains)
INFO - root - 2022-02-24 20:19:22.428525: step 93040, total loss = 0.53, batch loss = 0.27 (208.4 examples/sec; 0.038 sec/batch; 1h:08m:05s remains)
INFO - root - 2022-02-24 20:19:22.705106: step 93050, total loss = 0.67, batch loss = 0.41 (307.6 examples/sec; 0.026 sec/batch; 0h:46m:08s remains)
INFO - root - 2022-02-24 20:19:23.030230: step 93060, total loss = 0.57, batch loss = 0.30 (113.0 examples/sec; 0.071 sec/batch; 2h:05m:37s remains)
INFO - root - 2022-02-24 20:19:23.446354: step 93070, total loss = 0.52, batch loss = 0.26 (354.5 examples/sec; 0.023 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:19:23.771016: step 93080, total loss = 0.61, batch loss = 0.35 (190.7 examples/sec; 0.042 sec/batch; 1h:14m:25s remains)
INFO - root - 2022-02-24 20:19:24.229026: step 93090, total loss = 0.60, batch loss = 0.33 (376.1 examples/sec; 0.021 sec/batch; 0h:37m:43s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-93099 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-93099 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:19:24.895278: step 93100, total loss = 0.59, batch loss = 0.33 (326.0 examples/sec; 0.025 sec/batch; 0h:43m:30s remains)
INFO - root - 2022-02-24 20:19:25.251384: step 93110, total loss = 0.52, batch loss = 0.26 (340.5 examples/sec; 0.023 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:19:25.727821: step 93120, total loss = 0.55, batch loss = 0.29 (189.0 examples/sec; 0.042 sec/batch; 1h:15m:02s remains)
INFO - root - 2022-02-24 20:19:26.132884: step 93130, total loss = 0.56, batch loss = 0.29 (160.2 examples/sec; 0.050 sec/batch; 1h:28m:30s remains)
INFO - root - 2022-02-24 20:19:26.502057: step 93140, total loss = 0.49, batch loss = 0.23 (333.3 examples/sec; 0.024 sec/batch; 0h:42m:32s remains)
INFO - root - 2022-02-24 20:19:26.787251: step 93150, total loss = 0.51, batch loss = 0.24 (218.1 examples/sec; 0.037 sec/batch; 1h:05m:01s remains)
INFO - root - 2022-02-24 20:19:27.114435: step 93160, total loss = 0.66, batch loss = 0.39 (226.3 examples/sec; 0.035 sec/batch; 1h:02m:39s remains)
INFO - root - 2022-02-24 20:19:27.432336: step 93170, total loss = 0.60, batch loss = 0.33 (312.8 examples/sec; 0.026 sec/batch; 0h:45m:19s remains)
INFO - root - 2022-02-24 20:19:27.887721: step 93180, total loss = 0.58, batch loss = 0.31 (137.0 examples/sec; 0.058 sec/batch; 1h:43m:27s remains)
INFO - root - 2022-02-24 20:19:28.275804: step 93190, total loss = 0.55, batch loss = 0.29 (159.3 examples/sec; 0.050 sec/batch; 1h:28m:58s remains)
INFO - root - 2022-02-24 20:19:28.621338: step 93200, total loss = 0.65, batch loss = 0.39 (330.9 examples/sec; 0.024 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:19:29.043993: step 93210, total loss = 0.63, batch loss = 0.37 (332.2 examples/sec; 0.024 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:19:29.369451: step 93220, total loss = 0.55, batch loss = 0.28 (253.0 examples/sec; 0.032 sec/batch; 0h:56m:01s remains)
INFO - root - 2022-02-24 20:19:29.752518: step 93230, total loss = 0.52, batch loss = 0.26 (133.3 examples/sec; 0.060 sec/batch; 1h:46m:16s remains)
INFO - root - 2022-02-24 20:19:30.097297: step 93240, total loss = 0.54, batch loss = 0.28 (204.3 examples/sec; 0.039 sec/batch; 1h:09m:21s remains)
INFO - root - 2022-02-24 20:19:30.529449: step 93250, total loss = 0.68, batch loss = 0.42 (275.8 examples/sec; 0.029 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:19:30.899217: step 93260, total loss = 0.61, batch loss = 0.35 (172.0 examples/sec; 0.047 sec/batch; 1h:22m:20s remains)
INFO - root - 2022-02-24 20:19:31.185076: step 93270, total loss = 0.60, batch loss = 0.33 (303.6 examples/sec; 0.026 sec/batch; 0h:46m:39s remains)
INFO - root - 2022-02-24 20:19:31.455874: step 93280, total loss = 0.57, batch loss = 0.30 (369.9 examples/sec; 0.022 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 20:19:31.741334: step 93290, total loss = 0.55, batch loss = 0.28 (191.6 examples/sec; 0.042 sec/batch; 1h:13m:54s remains)
INFO - root - 2022-02-24 20:19:32.083657: step 93300, total loss = 0.59, batch loss = 0.33 (190.7 examples/sec; 0.042 sec/batch; 1h:14m:15s remains)
INFO - root - 2022-02-24 20:19:32.550252: step 93310, total loss = 0.63, batch loss = 0.37 (325.2 examples/sec; 0.025 sec/batch; 0h:43m:32s remains)
INFO - root - 2022-02-24 20:19:32.943896: step 93320, total loss = 0.52, batch loss = 0.26 (362.9 examples/sec; 0.022 sec/batch; 0h:39m:00s remains)
INFO - root - 2022-02-24 20:19:33.261249: step 93330, total loss = 0.54, batch loss = 0.27 (315.9 examples/sec; 0.025 sec/batch; 0h:44m:48s remains)
INFO - root - 2022-02-24 20:19:33.566840: step 93340, total loss = 0.55, batch loss = 0.29 (212.2 examples/sec; 0.038 sec/batch; 1h:06m:42s remains)
INFO - root - 2022-02-24 20:19:33.895898: step 93350, total loss = 0.53, batch loss = 0.26 (283.7 examples/sec; 0.028 sec/batch; 0h:49m:53s remains)
INFO - root - 2022-02-24 20:19:34.325269: step 93360, total loss = 0.55, batch loss = 0.28 (194.5 examples/sec; 0.041 sec/batch; 1h:12m:46s remains)
INFO - root - 2022-02-24 20:19:34.866478: step 93370, total loss = 0.56, batch loss = 0.29 (245.4 examples/sec; 0.033 sec/batch; 0h:57m:40s remains)
INFO - root - 2022-02-24 20:19:35.932026: step 93380, total loss = 0.58, batch loss = 0.31 (151.1 examples/sec; 0.053 sec/batch; 1h:33m:38s remains)
INFO - root - 2022-02-24 20:19:36.419365: step 93390, total loss = 0.58, batch loss = 0.32 (110.4 examples/sec; 0.072 sec/batch; 2h:08m:08s remains)
INFO - root - 2022-02-24 20:19:36.764592: step 93400, total loss = 0.51, batch loss = 0.25 (181.7 examples/sec; 0.044 sec/batch; 1h:17m:50s remains)
INFO - root - 2022-02-24 20:19:37.167256: step 93410, total loss = 0.54, batch loss = 0.27 (348.1 examples/sec; 0.023 sec/batch; 0h:40m:37s remains)
INFO - root - 2022-02-24 20:19:37.478738: step 93420, total loss = 0.58, batch loss = 0.31 (355.7 examples/sec; 0.022 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:19:37.855929: step 93430, total loss = 0.58, batch loss = 0.32 (123.8 examples/sec; 0.065 sec/batch; 1h:54m:12s remains)
INFO - root - 2022-02-24 20:19:38.292476: step 93440, total loss = 0.51, batch loss = 0.24 (301.9 examples/sec; 0.026 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:19:38.633331: step 93450, total loss = 0.54, batch loss = 0.28 (210.0 examples/sec; 0.038 sec/batch; 1h:07m:19s remains)
INFO - root - 2022-02-24 20:19:38.952294: step 93460, total loss = 0.51, batch loss = 0.25 (128.7 examples/sec; 0.062 sec/batch; 1h:49m:50s remains)
INFO - root - 2022-02-24 20:19:39.237642: step 93470, total loss = 0.49, batch loss = 0.23 (360.3 examples/sec; 0.022 sec/batch; 0h:39m:14s remains)
INFO - root - 2022-02-24 20:19:39.548645: step 93480, total loss = 0.63, batch loss = 0.36 (145.5 examples/sec; 0.055 sec/batch; 1h:37m:08s remains)
INFO - root - 2022-02-24 20:19:39.907525: step 93490, total loss = 0.55, batch loss = 0.28 (227.8 examples/sec; 0.035 sec/batch; 1h:02m:02s remains)
INFO - root - 2022-02-24 20:19:40.357275: step 93500, total loss = 0.54, batch loss = 0.28 (59.5 examples/sec; 0.134 sec/batch; 3h:57m:29s remains)
INFO - root - 2022-02-24 20:19:40.796178: step 93510, total loss = 0.57, batch loss = 0.30 (154.3 examples/sec; 0.052 sec/batch; 1h:31m:36s remains)
INFO - root - 2022-02-24 20:19:41.102958: step 93520, total loss = 0.48, batch loss = 0.21 (143.6 examples/sec; 0.056 sec/batch; 1h:38m:26s remains)
INFO - root - 2022-02-24 20:19:41.412825: step 93530, total loss = 0.55, batch loss = 0.28 (353.1 examples/sec; 0.023 sec/batch; 0h:40m:00s remains)
INFO - root - 2022-02-24 20:19:41.775215: step 93540, total loss = 0.61, batch loss = 0.35 (152.5 examples/sec; 0.052 sec/batch; 1h:32m:38s remains)
INFO - root - 2022-02-24 20:19:42.054932: step 93550, total loss = 0.56, batch loss = 0.30 (332.6 examples/sec; 0.024 sec/batch; 0h:42m:28s remains)
INFO - root - 2022-02-24 20:19:42.451644: step 93560, total loss = 0.49, batch loss = 0.23 (166.2 examples/sec; 0.048 sec/batch; 1h:25m:00s remains)
INFO - root - 2022-02-24 20:19:42.801239: step 93570, total loss = 0.55, batch loss = 0.28 (245.9 examples/sec; 0.033 sec/batch; 0h:57m:26s remains)
INFO - root - 2022-02-24 20:19:43.075359: step 93580, total loss = 0.51, batch loss = 0.25 (321.6 examples/sec; 0.025 sec/batch; 0h:43m:55s remains)
INFO - root - 2022-02-24 20:19:43.419164: step 93590, total loss = 0.54, batch loss = 0.28 (278.8 examples/sec; 0.029 sec/batch; 0h:50m:38s remains)
INFO - root - 2022-02-24 20:19:43.682704: step 93600, total loss = 0.63, batch loss = 0.37 (358.2 examples/sec; 0.022 sec/batch; 0h:39m:25s remains)
INFO - root - 2022-02-24 20:19:44.067101: step 93610, total loss = 0.55, batch loss = 0.28 (243.2 examples/sec; 0.033 sec/batch; 0h:58m:03s remains)
INFO - root - 2022-02-24 20:19:44.482191: step 93620, total loss = 0.62, batch loss = 0.36 (141.5 examples/sec; 0.057 sec/batch; 1h:39m:46s remains)
INFO - root - 2022-02-24 20:19:44.871778: step 93630, total loss = 0.52, batch loss = 0.26 (274.0 examples/sec; 0.029 sec/batch; 0h:51m:31s remains)
INFO - root - 2022-02-24 20:19:45.192185: step 93640, total loss = 0.50, batch loss = 0.23 (175.8 examples/sec; 0.045 sec/batch; 1h:20m:16s remains)
INFO - root - 2022-02-24 20:19:45.591942: step 93650, total loss = 0.62, batch loss = 0.36 (132.1 examples/sec; 0.061 sec/batch; 1h:46m:48s remains)
INFO - root - 2022-02-24 20:19:46.015359: step 93660, total loss = 0.52, batch loss = 0.26 (151.5 examples/sec; 0.053 sec/batch; 1h:33m:07s remains)
INFO - root - 2022-02-24 20:19:46.406958: step 93670, total loss = 0.51, batch loss = 0.25 (204.7 examples/sec; 0.039 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 20:19:46.700962: step 93680, total loss = 0.61, batch loss = 0.34 (305.2 examples/sec; 0.026 sec/batch; 0h:46m:13s remains)
INFO - root - 2022-02-24 20:19:46.991441: step 93690, total loss = 0.55, batch loss = 0.28 (337.5 examples/sec; 0.024 sec/batch; 0h:41m:48s remains)
INFO - root - 2022-02-24 20:19:47.306620: step 93700, total loss = 0.53, batch loss = 0.26 (368.7 examples/sec; 0.022 sec/batch; 0h:38m:15s remains)
INFO - root - 2022-02-24 20:19:47.717830: step 93710, total loss = 0.46, batch loss = 0.19 (226.0 examples/sec; 0.035 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 20:19:48.158537: step 93720, total loss = 0.57, batch loss = 0.30 (142.4 examples/sec; 0.056 sec/batch; 1h:39m:01s remains)
INFO - root - 2022-02-24 20:19:48.534567: step 93730, total loss = 0.53, batch loss = 0.26 (134.7 examples/sec; 0.059 sec/batch; 1h:44m:40s remains)
INFO - root - 2022-02-24 20:19:48.878157: step 93740, total loss = 0.63, batch loss = 0.36 (349.8 examples/sec; 0.023 sec/batch; 0h:40m:18s remains)
INFO - root - 2022-02-24 20:19:49.134689: step 93750, total loss = 0.58, batch loss = 0.31 (337.4 examples/sec; 0.024 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:19:49.497510: step 93760, total loss = 0.65, batch loss = 0.39 (337.4 examples/sec; 0.024 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:19:49.798996: step 93770, total loss = 0.51, batch loss = 0.24 (337.0 examples/sec; 0.024 sec/batch; 0h:41m:49s remains)
INFO - root - 2022-02-24 20:19:50.234581: step 93780, total loss = 0.68, batch loss = 0.42 (98.6 examples/sec; 0.081 sec/batch; 2h:22m:53s remains)
INFO - root - 2022-02-24 20:19:50.718696: step 93790, total loss = 0.55, batch loss = 0.28 (183.2 examples/sec; 0.044 sec/batch; 1h:16m:56s remains)
INFO - root - 2022-02-24 20:19:51.042696: step 93800, total loss = 0.53, batch loss = 0.26 (195.5 examples/sec; 0.041 sec/batch; 1h:12m:06s remains)
INFO - root - 2022-02-24 20:19:51.403982: step 93810, total loss = 0.63, batch loss = 0.37 (379.3 examples/sec; 0.021 sec/batch; 0h:37m:09s remains)
INFO - root - 2022-02-24 20:19:51.692085: step 93820, total loss = 0.55, batch loss = 0.29 (161.0 examples/sec; 0.050 sec/batch; 1h:27m:32s remains)
INFO - root - 2022-02-24 20:19:51.991780: step 93830, total loss = 0.52, batch loss = 0.26 (344.6 examples/sec; 0.023 sec/batch; 0h:40m:53s remains)
INFO - root - 2022-02-24 20:19:52.385343: step 93840, total loss = 0.65, batch loss = 0.38 (145.3 examples/sec; 0.055 sec/batch; 1h:36m:57s remains)
INFO - root - 2022-02-24 20:19:52.858122: step 93850, total loss = 0.53, batch loss = 0.27 (342.0 examples/sec; 0.023 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:19:53.226689: step 93860, total loss = 0.55, batch loss = 0.29 (320.9 examples/sec; 0.025 sec/batch; 0h:43m:53s remains)
INFO - root - 2022-02-24 20:19:53.519603: step 93870, total loss = 0.46, batch loss = 0.19 (360.6 examples/sec; 0.022 sec/batch; 0h:39m:03s remains)
INFO - root - 2022-02-24 20:19:53.802101: step 93880, total loss = 0.60, batch loss = 0.34 (312.5 examples/sec; 0.026 sec/batch; 0h:45m:03s remains)
INFO - root - 2022-02-24 20:19:54.045954: step 93890, total loss = 0.46, batch loss = 0.19 (336.2 examples/sec; 0.024 sec/batch; 0h:41m:53s remains)
INFO - root - 2022-02-24 20:19:54.358278: step 93900, total loss = 0.53, batch loss = 0.26 (324.5 examples/sec; 0.025 sec/batch; 0h:43m:23s remains)
INFO - root - 2022-02-24 20:19:54.839745: step 93910, total loss = 0.57, batch loss = 0.31 (157.4 examples/sec; 0.051 sec/batch; 1h:29m:25s remains)
INFO - root - 2022-02-24 20:19:55.176841: step 93920, total loss = 0.54, batch loss = 0.27 (316.1 examples/sec; 0.025 sec/batch; 0h:44m:31s remains)
INFO - root - 2022-02-24 20:19:55.523534: step 93930, total loss = 0.56, batch loss = 0.29 (198.6 examples/sec; 0.040 sec/batch; 1h:10m:52s remains)
INFO - root - 2022-02-24 20:19:56.503730: step 93940, total loss = 0.62, batch loss = 0.36 (286.1 examples/sec; 0.028 sec/batch; 0h:49m:11s remains)
INFO - root - 2022-02-24 20:19:56.922193: step 93950, total loss = 0.51, batch loss = 0.25 (220.1 examples/sec; 0.036 sec/batch; 1h:03m:56s remains)
INFO - root - 2022-02-24 20:19:57.253501: step 93960, total loss = 0.51, batch loss = 0.24 (136.9 examples/sec; 0.058 sec/batch; 1h:42m:46s remains)
INFO - root - 2022-02-24 20:19:57.708268: step 93970, total loss = 0.61, batch loss = 0.34 (345.0 examples/sec; 0.023 sec/batch; 0h:40m:46s remains)
INFO - root - 2022-02-24 20:19:58.046723: step 93980, total loss = 0.61, batch loss = 0.34 (123.2 examples/sec; 0.065 sec/batch; 1h:54m:12s remains)
INFO - root - 2022-02-24 20:19:58.600006: step 93990, total loss = 0.54, batch loss = 0.28 (222.5 examples/sec; 0.036 sec/batch; 1h:03m:13s remains)
INFO - root - 2022-02-24 20:19:58.998216: step 94000, total loss = 0.53, batch loss = 0.26 (212.0 examples/sec; 0.038 sec/batch; 1h:06m:20s remains)
INFO - root - 2022-02-24 20:19:59.506656: step 94010, total loss = 0.50, batch loss = 0.24 (328.9 examples/sec; 0.024 sec/batch; 0h:42m:45s remains)
INFO - root - 2022-02-24 20:19:59.897937: step 94020, total loss = 0.51, batch loss = 0.24 (158.0 examples/sec; 0.051 sec/batch; 1h:28m:59s remains)
INFO - root - 2022-02-24 20:20:00.262114: step 94030, total loss = 0.49, batch loss = 0.22 (286.5 examples/sec; 0.028 sec/batch; 0h:49m:04s remains)
INFO - root - 2022-02-24 20:20:00.565504: step 94040, total loss = 0.56, batch loss = 0.29 (239.9 examples/sec; 0.033 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 20:20:01.357195: step 94050, total loss = 0.51, batch loss = 0.24 (285.1 examples/sec; 0.028 sec/batch; 0h:49m:19s remains)
INFO - root - 2022-02-24 20:20:01.828669: step 94060, total loss = 0.53, batch loss = 0.27 (324.0 examples/sec; 0.025 sec/batch; 0h:43m:23s remains)
INFO - root - 2022-02-24 20:20:02.181172: step 94070, total loss = 0.52, batch loss = 0.26 (169.7 examples/sec; 0.047 sec/batch; 1h:22m:49s remains)
INFO - root - 2022-02-24 20:20:02.509592: step 94080, total loss = 0.50, batch loss = 0.24 (345.3 examples/sec; 0.023 sec/batch; 0h:40m:42s remains)
INFO - root - 2022-02-24 20:20:02.833092: step 94090, total loss = 0.48, batch loss = 0.21 (347.4 examples/sec; 0.023 sec/batch; 0h:40m:27s remains)
INFO - root - 2022-02-24 20:20:03.225067: step 94100, total loss = 0.67, batch loss = 0.40 (126.0 examples/sec; 0.063 sec/batch; 1h:51m:31s remains)
INFO - root - 2022-02-24 20:20:03.701289: step 94110, total loss = 0.51, batch loss = 0.24 (247.3 examples/sec; 0.032 sec/batch; 0h:56m:49s remains)
INFO - root - 2022-02-24 20:20:04.064351: step 94120, total loss = 0.67, batch loss = 0.40 (202.0 examples/sec; 0.040 sec/batch; 1h:09m:33s remains)
INFO - root - 2022-02-24 20:20:04.375179: step 94130, total loss = 0.56, batch loss = 0.30 (225.4 examples/sec; 0.035 sec/batch; 1h:02m:20s remains)
INFO - root - 2022-02-24 20:20:04.681444: step 94140, total loss = 0.56, batch loss = 0.29 (295.1 examples/sec; 0.027 sec/batch; 0h:47m:36s remains)
INFO - root - 2022-02-24 20:20:05.002734: step 94150, total loss = 0.54, batch loss = 0.27 (315.7 examples/sec; 0.025 sec/batch; 0h:44m:29s remains)
INFO - root - 2022-02-24 20:20:05.378680: step 94160, total loss = 0.59, batch loss = 0.33 (341.0 examples/sec; 0.023 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:20:05.836419: step 94170, total loss = 0.63, batch loss = 0.37 (260.1 examples/sec; 0.031 sec/batch; 0h:53m:59s remains)
INFO - root - 2022-02-24 20:20:06.113577: step 94180, total loss = 0.56, batch loss = 0.30 (277.0 examples/sec; 0.029 sec/batch; 0h:50m:41s remains)
INFO - root - 2022-02-24 20:20:06.426939: step 94190, total loss = 0.50, batch loss = 0.24 (178.4 examples/sec; 0.045 sec/batch; 1h:18m:43s remains)
INFO - root - 2022-02-24 20:20:06.704060: step 94200, total loss = 0.62, batch loss = 0.36 (328.4 examples/sec; 0.024 sec/batch; 0h:42m:45s remains)
INFO - root - 2022-02-24 20:20:07.062516: step 94210, total loss = 0.52, batch loss = 0.26 (198.9 examples/sec; 0.040 sec/batch; 1h:10m:34s remains)
INFO - root - 2022-02-24 20:20:07.449821: step 94220, total loss = 0.55, batch loss = 0.28 (313.4 examples/sec; 0.026 sec/batch; 0h:44m:47s remains)
INFO - root - 2022-02-24 20:20:07.917487: step 94230, total loss = 0.58, batch loss = 0.31 (125.8 examples/sec; 0.064 sec/batch; 1h:51m:35s remains)
INFO - root - 2022-02-24 20:20:08.271652: step 94240, total loss = 0.50, batch loss = 0.24 (255.2 examples/sec; 0.031 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:20:08.558096: step 94250, total loss = 0.49, batch loss = 0.23 (364.0 examples/sec; 0.022 sec/batch; 0h:38m:33s remains)
INFO - root - 2022-02-24 20:20:08.844097: step 94260, total loss = 0.48, batch loss = 0.21 (267.0 examples/sec; 0.030 sec/batch; 0h:52m:32s remains)
INFO - root - 2022-02-24 20:20:09.117731: step 94270, total loss = 0.48, batch loss = 0.22 (227.0 examples/sec; 0.035 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 20:20:09.425737: step 94280, total loss = 0.57, batch loss = 0.30 (338.0 examples/sec; 0.024 sec/batch; 0h:41m:30s remains)
INFO - root - 2022-02-24 20:20:09.804087: step 94290, total loss = 0.61, batch loss = 0.34 (351.2 examples/sec; 0.023 sec/batch; 0h:39m:56s remains)
INFO - root - 2022-02-24 20:20:10.116180: step 94300, total loss = 0.51, batch loss = 0.25 (274.7 examples/sec; 0.029 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:20:10.474857: step 94310, total loss = 0.59, batch loss = 0.33 (381.6 examples/sec; 0.021 sec/batch; 0h:36m:45s remains)
INFO - root - 2022-02-24 20:20:10.824310: step 94320, total loss = 0.50, batch loss = 0.24 (163.6 examples/sec; 0.049 sec/batch; 1h:25m:43s remains)
INFO - root - 2022-02-24 20:20:11.098835: step 94330, total loss = 0.49, batch loss = 0.23 (292.8 examples/sec; 0.027 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:20:11.507309: step 94340, total loss = 0.59, batch loss = 0.32 (256.4 examples/sec; 0.031 sec/batch; 0h:54m:41s remains)
INFO - root - 2022-02-24 20:20:11.903091: step 94350, total loss = 0.67, batch loss = 0.41 (323.4 examples/sec; 0.025 sec/batch; 0h:43m:21s remains)
INFO - root - 2022-02-24 20:20:12.249357: step 94360, total loss = 0.55, batch loss = 0.28 (380.8 examples/sec; 0.021 sec/batch; 0h:36m:48s remains)
INFO - root - 2022-02-24 20:20:12.515478: step 94370, total loss = 0.54, batch loss = 0.27 (337.5 examples/sec; 0.024 sec/batch; 0h:41m:31s remains)
INFO - root - 2022-02-24 20:20:12.835441: step 94380, total loss = 0.47, batch loss = 0.20 (263.2 examples/sec; 0.030 sec/batch; 0h:53m:14s remains)
INFO - root - 2022-02-24 20:20:13.159057: step 94390, total loss = 0.56, batch loss = 0.29 (256.2 examples/sec; 0.031 sec/batch; 0h:54m:41s remains)
INFO - root - 2022-02-24 20:20:13.635905: step 94400, total loss = 0.64, batch loss = 0.38 (78.4 examples/sec; 0.102 sec/batch; 2h:58m:40s remains)
INFO - root - 2022-02-24 20:20:14.153218: step 94410, total loss = 0.53, batch loss = 0.26 (345.3 examples/sec; 0.023 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:20:14.648942: step 94420, total loss = 0.50, batch loss = 0.24 (320.8 examples/sec; 0.025 sec/batch; 0h:43m:40s remains)
INFO - root - 2022-02-24 20:20:15.239960: step 94430, total loss = 0.58, batch loss = 0.32 (229.8 examples/sec; 0.035 sec/batch; 1h:00m:58s remains)
INFO - root - 2022-02-24 20:20:15.727688: step 94440, total loss = 0.60, batch loss = 0.34 (337.1 examples/sec; 0.024 sec/batch; 0h:41m:33s remains)
INFO - root - 2022-02-24 20:20:16.635645: step 94450, total loss = 0.67, batch loss = 0.41 (328.4 examples/sec; 0.024 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:20:16.940126: step 94460, total loss = 0.55, batch loss = 0.28 (351.0 examples/sec; 0.023 sec/batch; 0h:39m:53s remains)
INFO - root - 2022-02-24 20:20:17.262207: step 94470, total loss = 0.56, batch loss = 0.30 (276.9 examples/sec; 0.029 sec/batch; 0h:50m:34s remains)
INFO - root - 2022-02-24 20:20:17.568405: step 94480, total loss = 0.66, batch loss = 0.39 (349.0 examples/sec; 0.023 sec/batch; 0h:40m:07s remains)
INFO - root - 2022-02-24 20:20:17.930160: step 94490, total loss = 0.65, batch loss = 0.39 (166.2 examples/sec; 0.048 sec/batch; 1h:24m:15s remains)
INFO - root - 2022-02-24 20:20:18.380679: step 94500, total loss = 0.59, batch loss = 0.33 (363.2 examples/sec; 0.022 sec/batch; 0h:38m:32s remains)
INFO - root - 2022-02-24 20:20:18.750521: step 94510, total loss = 0.50, batch loss = 0.24 (350.0 examples/sec; 0.023 sec/batch; 0h:39m:59s remains)
INFO - root - 2022-02-24 20:20:19.076708: step 94520, total loss = 0.58, batch loss = 0.31 (291.6 examples/sec; 0.027 sec/batch; 0h:48m:00s remains)
INFO - root - 2022-02-24 20:20:19.429138: step 94530, total loss = 0.49, batch loss = 0.23 (303.1 examples/sec; 0.026 sec/batch; 0h:46m:10s remains)
INFO - root - 2022-02-24 20:20:19.672877: step 94540, total loss = 0.63, batch loss = 0.37 (302.6 examples/sec; 0.026 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 20:20:19.981228: step 94550, total loss = 0.52, batch loss = 0.26 (163.2 examples/sec; 0.049 sec/batch; 1h:25m:46s remains)
INFO - root - 2022-02-24 20:20:20.311299: step 94560, total loss = 0.61, batch loss = 0.34 (146.0 examples/sec; 0.055 sec/batch; 1h:35m:48s remains)
INFO - root - 2022-02-24 20:20:20.716745: step 94570, total loss = 0.54, batch loss = 0.28 (313.3 examples/sec; 0.026 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 20:20:21.075190: step 94580, total loss = 0.65, batch loss = 0.38 (347.3 examples/sec; 0.023 sec/batch; 0h:40m:16s remains)
INFO - root - 2022-02-24 20:20:21.362767: step 94590, total loss = 0.66, batch loss = 0.40 (227.9 examples/sec; 0.035 sec/batch; 1h:01m:22s remains)
INFO - root - 2022-02-24 20:20:21.709046: step 94600, total loss = 0.53, batch loss = 0.27 (327.3 examples/sec; 0.024 sec/batch; 0h:42m:43s remains)
INFO - root - 2022-02-24 20:20:22.078153: step 94610, total loss = 0.57, batch loss = 0.30 (349.7 examples/sec; 0.023 sec/batch; 0h:39m:59s remains)
INFO - root - 2022-02-24 20:20:22.499629: step 94620, total loss = 0.59, batch loss = 0.33 (281.5 examples/sec; 0.028 sec/batch; 0h:49m:40s remains)
INFO - root - 2022-02-24 20:20:22.815108: step 94630, total loss = 0.51, batch loss = 0.24 (323.2 examples/sec; 0.025 sec/batch; 0h:43m:15s remains)
INFO - root - 2022-02-24 20:20:23.155588: step 94640, total loss = 0.51, batch loss = 0.25 (228.9 examples/sec; 0.035 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 20:20:23.481389: step 94650, total loss = 0.54, batch loss = 0.28 (278.0 examples/sec; 0.029 sec/batch; 0h:50m:17s remains)
INFO - root - 2022-02-24 20:20:23.774685: step 94660, total loss = 0.50, batch loss = 0.24 (337.7 examples/sec; 0.024 sec/batch; 0h:41m:23s remains)
INFO - root - 2022-02-24 20:20:24.079198: step 94670, total loss = 0.55, batch loss = 0.28 (377.4 examples/sec; 0.021 sec/batch; 0h:37m:02s remains)
INFO - root - 2022-02-24 20:20:24.496051: step 94680, total loss = 0.57, batch loss = 0.30 (252.4 examples/sec; 0.032 sec/batch; 0h:55m:21s remains)
INFO - root - 2022-02-24 20:20:24.942478: step 94690, total loss = 0.58, batch loss = 0.32 (323.1 examples/sec; 0.025 sec/batch; 0h:43m:14s remains)
INFO - root - 2022-02-24 20:20:25.284221: step 94700, total loss = 0.46, batch loss = 0.19 (329.2 examples/sec; 0.024 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:20:25.716506: step 94710, total loss = 0.59, batch loss = 0.33 (363.8 examples/sec; 0.022 sec/batch; 0h:38m:24s remains)
INFO - root - 2022-02-24 20:20:26.018389: step 94720, total loss = 0.43, batch loss = 0.17 (248.5 examples/sec; 0.032 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 20:20:26.323042: step 94730, total loss = 0.65, batch loss = 0.38 (191.4 examples/sec; 0.042 sec/batch; 1h:12m:59s remains)
INFO - root - 2022-02-24 20:20:26.735297: step 94740, total loss = 0.67, batch loss = 0.41 (265.7 examples/sec; 0.030 sec/batch; 0h:52m:34s remains)
INFO - root - 2022-02-24 20:20:27.123454: step 94750, total loss = 0.51, batch loss = 0.24 (176.9 examples/sec; 0.045 sec/batch; 1h:18m:58s remains)
INFO - root - 2022-02-24 20:20:27.412724: step 94760, total loss = 0.53, batch loss = 0.26 (276.1 examples/sec; 0.029 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:20:27.753318: step 94770, total loss = 0.52, batch loss = 0.26 (234.2 examples/sec; 0.034 sec/batch; 0h:59m:38s remains)
INFO - root - 2022-02-24 20:20:28.015141: step 94780, total loss = 0.49, batch loss = 0.22 (339.6 examples/sec; 0.024 sec/batch; 0h:41m:06s remains)
INFO - root - 2022-02-24 20:20:28.279165: step 94790, total loss = 0.57, batch loss = 0.31 (257.3 examples/sec; 0.031 sec/batch; 0h:54m:15s remains)
INFO - root - 2022-02-24 20:20:28.529436: step 94800, total loss = 0.57, batch loss = 0.30 (259.4 examples/sec; 0.031 sec/batch; 0h:53m:48s remains)
INFO - root - 2022-02-24 20:20:28.956020: step 94810, total loss = 0.46, batch loss = 0.20 (312.9 examples/sec; 0.026 sec/batch; 0h:44m:37s remains)
INFO - root - 2022-02-24 20:20:29.299999: step 94820, total loss = 0.53, batch loss = 0.27 (315.2 examples/sec; 0.025 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:20:29.640702: step 94830, total loss = 0.48, batch loss = 0.22 (345.6 examples/sec; 0.023 sec/batch; 0h:40m:22s remains)
INFO - root - 2022-02-24 20:20:29.945078: step 94840, total loss = 0.51, batch loss = 0.24 (198.4 examples/sec; 0.040 sec/batch; 1h:10m:19s remains)
INFO - root - 2022-02-24 20:20:30.226582: step 94850, total loss = 0.54, batch loss = 0.28 (338.6 examples/sec; 0.024 sec/batch; 0h:41m:12s remains)
INFO - root - 2022-02-24 20:20:30.561439: step 94860, total loss = 0.76, batch loss = 0.49 (260.4 examples/sec; 0.031 sec/batch; 0h:53m:35s remains)
INFO - root - 2022-02-24 20:20:31.027729: step 94870, total loss = 0.52, batch loss = 0.26 (130.6 examples/sec; 0.061 sec/batch; 1h:46m:46s remains)
INFO - root - 2022-02-24 20:20:31.446427: step 94880, total loss = 0.51, batch loss = 0.25 (97.0 examples/sec; 0.082 sec/batch; 2h:23m:48s remains)
INFO - root - 2022-02-24 20:20:32.241461: step 94890, total loss = 0.56, batch loss = 0.30 (271.1 examples/sec; 0.030 sec/batch; 0h:51m:26s remains)
INFO - root - 2022-02-24 20:20:32.531978: step 94900, total loss = 0.52, batch loss = 0.25 (206.4 examples/sec; 0.039 sec/batch; 1h:07m:34s remains)
INFO - root - 2022-02-24 20:20:33.115640: step 94910, total loss = 0.70, batch loss = 0.44 (91.5 examples/sec; 0.087 sec/batch; 2h:32m:19s remains)
INFO - root - 2022-02-24 20:20:33.423615: step 94920, total loss = 0.56, batch loss = 0.29 (295.5 examples/sec; 0.027 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:20:33.743608: step 94930, total loss = 0.58, batch loss = 0.32 (230.1 examples/sec; 0.035 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 20:20:34.117868: step 94940, total loss = 0.65, batch loss = 0.38 (117.5 examples/sec; 0.068 sec/batch; 1h:58m:37s remains)
INFO - root - 2022-02-24 20:20:34.470118: step 94950, total loss = 0.61, batch loss = 0.34 (270.2 examples/sec; 0.030 sec/batch; 0h:51m:35s remains)
INFO - root - 2022-02-24 20:20:34.802642: step 94960, total loss = 0.64, batch loss = 0.38 (103.3 examples/sec; 0.077 sec/batch; 2h:14m:53s remains)
INFO - root - 2022-02-24 20:20:35.246733: step 94970, total loss = 0.52, batch loss = 0.26 (104.0 examples/sec; 0.077 sec/batch; 2h:14m:02s remains)
INFO - root - 2022-02-24 20:20:35.583902: step 94980, total loss = 0.56, batch loss = 0.30 (236.5 examples/sec; 0.034 sec/batch; 0h:58m:56s remains)
INFO - root - 2022-02-24 20:20:35.910519: step 94990, total loss = 0.51, batch loss = 0.24 (283.9 examples/sec; 0.028 sec/batch; 0h:49m:05s remains)
INFO - root - 2022-02-24 20:20:36.239638: step 95000, total loss = 0.59, batch loss = 0.32 (292.8 examples/sec; 0.027 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:20:36.982435: step 95010, total loss = 0.66, batch loss = 0.39 (179.1 examples/sec; 0.045 sec/batch; 1h:17m:48s remains)
INFO - root - 2022-02-24 20:20:37.457635: step 95020, total loss = 0.65, batch loss = 0.38 (265.3 examples/sec; 0.030 sec/batch; 0h:52m:30s remains)
INFO - root - 2022-02-24 20:20:37.837812: step 95030, total loss = 0.60, batch loss = 0.34 (269.6 examples/sec; 0.030 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:20:38.164058: step 95040, total loss = 0.71, batch loss = 0.45 (244.6 examples/sec; 0.033 sec/batch; 0h:56m:55s remains)
INFO - root - 2022-02-24 20:20:38.530649: step 95050, total loss = 0.44, batch loss = 0.17 (195.6 examples/sec; 0.041 sec/batch; 1h:11m:11s remains)
INFO - root - 2022-02-24 20:20:38.891936: step 95060, total loss = 0.43, batch loss = 0.17 (138.3 examples/sec; 0.058 sec/batch; 1h:40m:43s remains)
INFO - root - 2022-02-24 20:20:39.226570: step 95070, total loss = 0.50, batch loss = 0.23 (298.3 examples/sec; 0.027 sec/batch; 0h:46m:40s remains)
INFO - root - 2022-02-24 20:20:39.631814: step 95080, total loss = 0.57, batch loss = 0.30 (148.9 examples/sec; 0.054 sec/batch; 1h:33m:29s remains)
INFO - root - 2022-02-24 20:20:39.982305: step 95090, total loss = 0.46, batch loss = 0.19 (299.8 examples/sec; 0.027 sec/batch; 0h:46m:26s remains)
INFO - root - 2022-02-24 20:20:40.275777: step 95100, total loss = 0.55, batch loss = 0.29 (199.3 examples/sec; 0.040 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 20:20:40.624436: step 95110, total loss = 0.50, batch loss = 0.24 (347.9 examples/sec; 0.023 sec/batch; 0h:40m:00s remains)
INFO - root - 2022-02-24 20:20:40.890895: step 95120, total loss = 0.47, batch loss = 0.21 (316.7 examples/sec; 0.025 sec/batch; 0h:43m:56s remains)
INFO - root - 2022-02-24 20:20:41.130216: step 95130, total loss = 0.53, batch loss = 0.27 (355.3 examples/sec; 0.023 sec/batch; 0h:39m:09s remains)
INFO - root - 2022-02-24 20:20:41.498404: step 95140, total loss = 0.57, batch loss = 0.30 (258.6 examples/sec; 0.031 sec/batch; 0h:53m:47s remains)
INFO - root - 2022-02-24 20:20:41.939339: step 95150, total loss = 0.62, batch loss = 0.36 (157.2 examples/sec; 0.051 sec/batch; 1h:28m:29s remains)
INFO - root - 2022-02-24 20:20:42.192142: step 95160, total loss = 0.55, batch loss = 0.28 (363.4 examples/sec; 0.022 sec/batch; 0h:38m:16s remains)
INFO - root - 2022-02-24 20:20:42.483336: step 95170, total loss = 0.52, batch loss = 0.25 (176.9 examples/sec; 0.045 sec/batch; 1h:18m:37s remains)
INFO - root - 2022-02-24 20:20:42.794206: step 95180, total loss = 0.53, batch loss = 0.26 (304.3 examples/sec; 0.026 sec/batch; 0h:45m:42s remains)
INFO - root - 2022-02-24 20:20:43.170958: step 95190, total loss = 0.49, batch loss = 0.23 (236.3 examples/sec; 0.034 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 20:20:43.663849: step 95200, total loss = 0.69, batch loss = 0.43 (120.4 examples/sec; 0.066 sec/batch; 1h:55m:30s remains)
INFO - root - 2022-02-24 20:20:44.041532: step 95210, total loss = 0.57, batch loss = 0.30 (325.4 examples/sec; 0.025 sec/batch; 0h:42m:44s remains)
INFO - root - 2022-02-24 20:20:44.345333: step 95220, total loss = 0.54, batch loss = 0.28 (219.5 examples/sec; 0.036 sec/batch; 1h:03m:21s remains)
INFO - root - 2022-02-24 20:20:44.613718: step 95230, total loss = 0.58, batch loss = 0.32 (349.7 examples/sec; 0.023 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:20:44.964000: step 95240, total loss = 0.49, batch loss = 0.23 (159.8 examples/sec; 0.050 sec/batch; 1h:27m:00s remains)
INFO - root - 2022-02-24 20:20:45.393967: step 95250, total loss = 0.46, batch loss = 0.20 (103.7 examples/sec; 0.077 sec/batch; 2h:14m:01s remains)
INFO - root - 2022-02-24 20:20:45.694625: step 95260, total loss = 0.53, batch loss = 0.26 (338.2 examples/sec; 0.024 sec/batch; 0h:41m:05s remains)
INFO - root - 2022-02-24 20:20:45.970907: step 95270, total loss = 0.56, batch loss = 0.29 (378.5 examples/sec; 0.021 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:20:46.243751: step 95280, total loss = 0.59, batch loss = 0.32 (318.7 examples/sec; 0.025 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 20:20:46.528276: step 95290, total loss = 0.58, batch loss = 0.32 (191.3 examples/sec; 0.042 sec/batch; 1h:12m:37s remains)
INFO - root - 2022-02-24 20:20:46.888275: step 95300, total loss = 0.58, batch loss = 0.31 (349.5 examples/sec; 0.023 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:20:47.485234: step 95310, total loss = 0.64, batch loss = 0.38 (203.6 examples/sec; 0.039 sec/batch; 1h:08m:14s remains)
INFO - root - 2022-02-24 20:20:47.830341: step 95320, total loss = 0.54, batch loss = 0.27 (352.1 examples/sec; 0.023 sec/batch; 0h:39m:27s remains)
INFO - root - 2022-02-24 20:20:48.121948: step 95330, total loss = 0.56, batch loss = 0.29 (246.6 examples/sec; 0.032 sec/batch; 0h:56m:19s remains)
INFO - root - 2022-02-24 20:20:48.418887: step 95340, total loss = 0.51, batch loss = 0.25 (334.4 examples/sec; 0.024 sec/batch; 0h:41m:32s remains)
INFO - root - 2022-02-24 20:20:48.777992: step 95350, total loss = 0.52, batch loss = 0.26 (173.1 examples/sec; 0.046 sec/batch; 1h:20m:12s remains)
INFO - root - 2022-02-24 20:20:49.160126: step 95360, total loss = 0.55, batch loss = 0.29 (143.6 examples/sec; 0.056 sec/batch; 1h:36m:43s remains)
INFO - root - 2022-02-24 20:20:49.555527: step 95370, total loss = 0.52, batch loss = 0.25 (114.5 examples/sec; 0.070 sec/batch; 2h:01m:13s remains)
INFO - root - 2022-02-24 20:20:49.895955: step 95380, total loss = 0.50, batch loss = 0.23 (351.3 examples/sec; 0.023 sec/batch; 0h:39m:31s remains)
INFO - root - 2022-02-24 20:20:50.351646: step 95390, total loss = 0.52, batch loss = 0.26 (225.0 examples/sec; 0.036 sec/batch; 1h:01m:41s remains)
INFO - root - 2022-02-24 20:20:50.722862: step 95400, total loss = 0.51, batch loss = 0.24 (241.0 examples/sec; 0.033 sec/batch; 0h:57m:35s remains)
INFO - root - 2022-02-24 20:20:51.093418: step 95410, total loss = 0.46, batch loss = 0.19 (172.8 examples/sec; 0.046 sec/batch; 1h:20m:17s remains)
INFO - root - 2022-02-24 20:20:51.504029: step 95420, total loss = 0.54, batch loss = 0.27 (187.9 examples/sec; 0.043 sec/batch; 1h:13m:52s remains)
INFO - root - 2022-02-24 20:20:51.888258: step 95430, total loss = 0.54, batch loss = 0.27 (283.4 examples/sec; 0.028 sec/batch; 0h:48m:57s remains)
INFO - root - 2022-02-24 20:20:52.841123: step 95440, total loss = 0.59, batch loss = 0.33 (193.7 examples/sec; 0.041 sec/batch; 1h:11m:37s remains)
INFO - root - 2022-02-24 20:20:53.237866: step 95450, total loss = 0.67, batch loss = 0.40 (100.5 examples/sec; 0.080 sec/batch; 2h:18m:03s remains)
INFO - root - 2022-02-24 20:20:53.574562: step 95460, total loss = 0.75, batch loss = 0.49 (289.2 examples/sec; 0.028 sec/batch; 0h:47m:58s remains)
INFO - root - 2022-02-24 20:20:53.902435: step 95470, total loss = 0.54, batch loss = 0.27 (156.2 examples/sec; 0.051 sec/batch; 1h:28m:46s remains)
INFO - root - 2022-02-24 20:20:54.264396: step 95480, total loss = 0.54, batch loss = 0.28 (297.3 examples/sec; 0.027 sec/batch; 0h:46m:38s remains)
INFO - root - 2022-02-24 20:20:54.697076: step 95490, total loss = 0.57, batch loss = 0.31 (170.0 examples/sec; 0.047 sec/batch; 1h:21m:33s remains)
INFO - root - 2022-02-24 20:20:55.005357: step 95500, total loss = 0.61, batch loss = 0.34 (338.7 examples/sec; 0.024 sec/batch; 0h:40m:56s remains)
INFO - root - 2022-02-24 20:20:55.417791: step 95510, total loss = 0.48, batch loss = 0.22 (298.8 examples/sec; 0.027 sec/batch; 0h:46m:24s remains)
INFO - root - 2022-02-24 20:20:55.739712: step 95520, total loss = 0.56, batch loss = 0.29 (247.9 examples/sec; 0.032 sec/batch; 0h:55m:55s remains)
INFO - root - 2022-02-24 20:20:56.196015: step 95530, total loss = 0.47, batch loss = 0.20 (120.1 examples/sec; 0.067 sec/batch; 1h:55m:25s remains)
INFO - root - 2022-02-24 20:20:56.580620: step 95540, total loss = 0.55, batch loss = 0.29 (235.7 examples/sec; 0.034 sec/batch; 0h:58m:48s remains)
INFO - root - 2022-02-24 20:20:56.859740: step 95550, total loss = 0.63, batch loss = 0.37 (294.1 examples/sec; 0.027 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:20:57.477943: step 95560, total loss = 0.55, batch loss = 0.29 (113.8 examples/sec; 0.070 sec/batch; 2h:01m:46s remains)
INFO - root - 2022-02-24 20:20:57.879557: step 95570, total loss = 0.55, batch loss = 0.28 (276.4 examples/sec; 0.029 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:20:58.436993: step 95580, total loss = 0.54, batch loss = 0.28 (140.1 examples/sec; 0.057 sec/batch; 1h:38m:55s remains)
INFO - root - 2022-02-24 20:20:58.809870: step 95590, total loss = 0.60, batch loss = 0.33 (206.6 examples/sec; 0.039 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:20:59.167245: step 95600, total loss = 0.64, batch loss = 0.37 (357.3 examples/sec; 0.022 sec/batch; 0h:38m:46s remains)
INFO - root - 2022-02-24 20:20:59.544174: step 95610, total loss = 0.57, batch loss = 0.31 (314.2 examples/sec; 0.025 sec/batch; 0h:44m:05s remains)
INFO - root - 2022-02-24 20:20:59.879033: step 95620, total loss = 0.59, batch loss = 0.32 (216.9 examples/sec; 0.037 sec/batch; 1h:03m:51s remains)
INFO - root - 2022-02-24 20:21:00.247353: step 95630, total loss = 0.47, batch loss = 0.20 (196.7 examples/sec; 0.041 sec/batch; 1h:10m:24s remains)
INFO - root - 2022-02-24 20:21:00.590490: step 95640, total loss = 0.54, batch loss = 0.28 (199.4 examples/sec; 0.040 sec/batch; 1h:09m:26s remains)
INFO - root - 2022-02-24 20:21:00.859815: step 95650, total loss = 0.47, batch loss = 0.21 (317.0 examples/sec; 0.025 sec/batch; 0h:43m:41s remains)
INFO - root - 2022-02-24 20:21:01.123645: step 95660, total loss = 0.65, batch loss = 0.38 (343.2 examples/sec; 0.023 sec/batch; 0h:40m:20s remains)
INFO - root - 2022-02-24 20:21:01.428925: step 95670, total loss = 0.55, batch loss = 0.29 (249.1 examples/sec; 0.032 sec/batch; 0h:55m:33s remains)
INFO - root - 2022-02-24 20:21:01.736249: step 95680, total loss = 0.59, batch loss = 0.32 (147.1 examples/sec; 0.054 sec/batch; 1h:34m:07s remains)
INFO - root - 2022-02-24 20:21:02.056197: step 95690, total loss = 0.60, batch loss = 0.34 (329.1 examples/sec; 0.024 sec/batch; 0h:42m:03s remains)
INFO - root - 2022-02-24 20:21:02.446113: step 95700, total loss = 0.51, batch loss = 0.24 (209.0 examples/sec; 0.038 sec/batch; 1h:06m:12s remains)
INFO - root - 2022-02-24 20:21:02.812541: step 95710, total loss = 0.53, batch loss = 0.27 (323.3 examples/sec; 0.025 sec/batch; 0h:42m:48s remains)
INFO - root - 2022-02-24 20:21:03.045447: step 95720, total loss = 0.44, batch loss = 0.17 (326.1 examples/sec; 0.025 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:21:03.303275: step 95730, total loss = 0.48, batch loss = 0.22 (335.2 examples/sec; 0.024 sec/batch; 0h:41m:16s remains)
INFO - root - 2022-02-24 20:21:03.591597: step 95740, total loss = 0.50, batch loss = 0.23 (179.0 examples/sec; 0.045 sec/batch; 1h:17m:16s remains)
INFO - root - 2022-02-24 20:21:04.016222: step 95750, total loss = 0.62, batch loss = 0.35 (222.9 examples/sec; 0.036 sec/batch; 1h:02m:04s remains)
INFO - root - 2022-02-24 20:21:04.355686: step 95760, total loss = 0.55, batch loss = 0.28 (337.1 examples/sec; 0.024 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:21:04.722719: step 95770, total loss = 0.52, batch loss = 0.25 (356.4 examples/sec; 0.022 sec/batch; 0h:38m:48s remains)
INFO - root - 2022-02-24 20:21:05.026488: step 95780, total loss = 0.61, batch loss = 0.35 (341.5 examples/sec; 0.023 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:21:05.350229: step 95790, total loss = 0.53, batch loss = 0.26 (188.5 examples/sec; 0.042 sec/batch; 1h:13m:21s remains)
INFO - root - 2022-02-24 20:21:05.684908: step 95800, total loss = 0.53, batch loss = 0.27 (199.0 examples/sec; 0.040 sec/batch; 1h:09m:28s remains)
INFO - root - 2022-02-24 20:21:06.133384: step 95810, total loss = 0.67, batch loss = 0.41 (260.5 examples/sec; 0.031 sec/batch; 0h:53m:04s remains)
INFO - root - 2022-02-24 20:21:06.576498: step 95820, total loss = 0.54, batch loss = 0.28 (127.7 examples/sec; 0.063 sec/batch; 1h:48m:13s remains)
INFO - root - 2022-02-24 20:21:06.887892: step 95830, total loss = 0.61, batch loss = 0.35 (327.6 examples/sec; 0.024 sec/batch; 0h:42m:11s remains)
INFO - root - 2022-02-24 20:21:07.208586: step 95840, total loss = 0.67, batch loss = 0.41 (316.0 examples/sec; 0.025 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:21:07.524689: step 95850, total loss = 0.55, batch loss = 0.29 (342.1 examples/sec; 0.023 sec/batch; 0h:40m:23s remains)
INFO - root - 2022-02-24 20:21:07.855489: step 95860, total loss = 0.53, batch loss = 0.26 (180.3 examples/sec; 0.044 sec/batch; 1h:16m:39s remains)
INFO - root - 2022-02-24 20:21:08.251144: step 95870, total loss = 0.51, batch loss = 0.25 (335.5 examples/sec; 0.024 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:21:08.658962: step 95880, total loss = 0.66, batch loss = 0.39 (373.4 examples/sec; 0.021 sec/batch; 0h:37m:00s remains)
INFO - root - 2022-02-24 20:21:09.148115: step 95890, total loss = 0.51, batch loss = 0.24 (168.0 examples/sec; 0.048 sec/batch; 1h:22m:14s remains)
INFO - root - 2022-02-24 20:21:09.894037: step 95900, total loss = 0.64, batch loss = 0.37 (141.4 examples/sec; 0.057 sec/batch; 1h:37m:42s remains)
INFO - root - 2022-02-24 20:21:11.026604: step 95910, total loss = 0.59, batch loss = 0.33 (334.9 examples/sec; 0.024 sec/batch; 0h:41m:14s remains)
INFO - root - 2022-02-24 20:21:11.267940: step 95920, total loss = 0.55, batch loss = 0.29 (328.3 examples/sec; 0.024 sec/batch; 0h:42m:04s remains)
INFO - root - 2022-02-24 20:21:11.507709: step 95930, total loss = 0.50, batch loss = 0.24 (373.5 examples/sec; 0.021 sec/batch; 0h:36m:58s remains)
INFO - root - 2022-02-24 20:21:11.743612: step 95940, total loss = 0.59, batch loss = 0.33 (330.6 examples/sec; 0.024 sec/batch; 0h:41m:45s remains)
INFO - root - 2022-02-24 20:21:11.980903: step 95950, total loss = 0.50, batch loss = 0.23 (324.7 examples/sec; 0.025 sec/batch; 0h:42m:31s remains)
INFO - root - 2022-02-24 20:21:12.769925: step 95960, total loss = 0.61, batch loss = 0.35 (334.4 examples/sec; 0.024 sec/batch; 0h:41m:16s remains)
INFO - root - 2022-02-24 20:21:13.258262: step 95970, total loss = 0.58, batch loss = 0.31 (169.4 examples/sec; 0.047 sec/batch; 1h:21m:30s remains)
INFO - root - 2022-02-24 20:21:13.588007: step 95980, total loss = 0.57, batch loss = 0.30 (323.6 examples/sec; 0.025 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:21:13.927725: step 95990, total loss = 0.57, batch loss = 0.31 (176.0 examples/sec; 0.045 sec/batch; 1h:18m:26s remains)
INFO - root - 2022-02-24 20:21:14.240450: step 96000, total loss = 0.49, batch loss = 0.23 (292.7 examples/sec; 0.027 sec/batch; 0h:47m:08s remains)
INFO - root - 2022-02-24 20:21:14.651869: step 96010, total loss = 0.59, batch loss = 0.33 (348.8 examples/sec; 0.023 sec/batch; 0h:39m:33s remains)
INFO - root - 2022-02-24 20:21:15.094285: step 96020, total loss = 0.51, batch loss = 0.24 (151.1 examples/sec; 0.053 sec/batch; 1h:31m:17s remains)
INFO - root - 2022-02-24 20:21:15.467831: step 96030, total loss = 0.51, batch loss = 0.25 (275.3 examples/sec; 0.029 sec/batch; 0h:50m:06s remains)
INFO - root - 2022-02-24 20:21:15.751689: step 96040, total loss = 0.59, batch loss = 0.32 (275.9 examples/sec; 0.029 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:21:16.072059: step 96050, total loss = 0.48, batch loss = 0.22 (195.9 examples/sec; 0.041 sec/batch; 1h:10m:23s remains)
INFO - root - 2022-02-24 20:21:16.340323: step 96060, total loss = 0.60, batch loss = 0.33 (335.6 examples/sec; 0.024 sec/batch; 0h:41m:05s remains)
INFO - root - 2022-02-24 20:21:16.673415: step 96070, total loss = 0.53, batch loss = 0.27 (134.2 examples/sec; 0.060 sec/batch; 1h:42m:46s remains)
INFO - root - 2022-02-24 20:21:17.025990: step 96080, total loss = 0.44, batch loss = 0.18 (321.8 examples/sec; 0.025 sec/batch; 0h:42m:51s remains)
INFO - root - 2022-02-24 20:21:17.412425: step 96090, total loss = 0.50, batch loss = 0.24 (219.2 examples/sec; 0.036 sec/batch; 1h:02m:54s remains)
INFO - root - 2022-02-24 20:21:17.738034: step 96100, total loss = 0.47, batch loss = 0.21 (176.7 examples/sec; 0.045 sec/batch; 1h:18m:02s remains)
INFO - root - 2022-02-24 20:21:18.133070: step 96110, total loss = 0.53, batch loss = 0.27 (190.1 examples/sec; 0.042 sec/batch; 1h:12m:30s remains)
INFO - root - 2022-02-24 20:21:18.423827: step 96120, total loss = 0.61, batch loss = 0.34 (345.4 examples/sec; 0.023 sec/batch; 0h:39m:54s remains)
INFO - root - 2022-02-24 20:21:18.748092: step 96130, total loss = 0.56, batch loss = 0.30 (350.6 examples/sec; 0.023 sec/batch; 0h:39m:18s remains)
INFO - root - 2022-02-24 20:21:19.090877: step 96140, total loss = 0.60, batch loss = 0.33 (303.3 examples/sec; 0.026 sec/batch; 0h:45m:26s remains)
INFO - root - 2022-02-24 20:21:19.489354: step 96150, total loss = 0.50, batch loss = 0.23 (362.6 examples/sec; 0.022 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 20:21:19.812662: step 96160, total loss = 0.48, batch loss = 0.22 (178.8 examples/sec; 0.045 sec/batch; 1h:17m:04s remains)
INFO - root - 2022-02-24 20:21:20.134789: step 96170, total loss = 0.72, batch loss = 0.46 (308.7 examples/sec; 0.026 sec/batch; 0h:44m:37s remains)
INFO - root - 2022-02-24 20:21:20.511712: step 96180, total loss = 0.58, batch loss = 0.32 (371.0 examples/sec; 0.022 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:21:20.795325: step 96190, total loss = 0.56, batch loss = 0.30 (210.4 examples/sec; 0.038 sec/batch; 1h:05m:27s remains)
INFO - root - 2022-02-24 20:21:21.179844: step 96200, total loss = 0.52, batch loss = 0.26 (196.5 examples/sec; 0.041 sec/batch; 1h:10m:05s remains)
INFO - root - 2022-02-24 20:21:21.553029: step 96210, total loss = 0.52, batch loss = 0.26 (361.7 examples/sec; 0.022 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:21:21.817973: step 96220, total loss = 0.50, batch loss = 0.24 (305.8 examples/sec; 0.026 sec/batch; 0h:45m:02s remains)
INFO - root - 2022-02-24 20:21:22.177200: step 96230, total loss = 0.54, batch loss = 0.27 (349.9 examples/sec; 0.023 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:21:22.478871: step 96240, total loss = 0.57, batch loss = 0.30 (297.3 examples/sec; 0.027 sec/batch; 0h:46m:18s remains)
INFO - root - 2022-02-24 20:21:22.808582: step 96250, total loss = 0.58, batch loss = 0.32 (169.2 examples/sec; 0.047 sec/batch; 1h:21m:20s remains)
INFO - root - 2022-02-24 20:21:23.215233: step 96260, total loss = 0.54, batch loss = 0.28 (214.5 examples/sec; 0.037 sec/batch; 1h:04m:10s remains)
INFO - root - 2022-02-24 20:21:23.621721: step 96270, total loss = 0.59, batch loss = 0.33 (331.7 examples/sec; 0.024 sec/batch; 0h:41m:29s remains)
INFO - root - 2022-02-24 20:21:23.986827: step 96280, total loss = 0.52, batch loss = 0.25 (264.4 examples/sec; 0.030 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:21:24.283258: step 96290, total loss = 0.54, batch loss = 0.27 (351.6 examples/sec; 0.023 sec/batch; 0h:39m:08s remains)
INFO - root - 2022-02-24 20:21:24.573326: step 96300, total loss = 0.60, batch loss = 0.33 (293.0 examples/sec; 0.027 sec/batch; 0h:46m:57s remains)
INFO - root - 2022-02-24 20:21:24.945740: step 96310, total loss = 0.48, batch loss = 0.21 (303.0 examples/sec; 0.026 sec/batch; 0h:45m:24s remains)
INFO - root - 2022-02-24 20:21:25.270425: step 96320, total loss = 0.48, batch loss = 0.21 (367.0 examples/sec; 0.022 sec/batch; 0h:37m:29s remains)
INFO - root - 2022-02-24 20:21:25.679487: step 96330, total loss = 0.50, batch loss = 0.23 (164.6 examples/sec; 0.049 sec/batch; 1h:23m:33s remains)
INFO - root - 2022-02-24 20:21:26.005222: step 96340, total loss = 0.66, batch loss = 0.39 (240.8 examples/sec; 0.033 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 20:21:26.431518: step 96350, total loss = 0.57, batch loss = 0.31 (144.0 examples/sec; 0.056 sec/batch; 1h:35m:30s remains)
INFO - root - 2022-02-24 20:21:27.063130: step 96360, total loss = 0.61, batch loss = 0.35 (310.9 examples/sec; 0.026 sec/batch; 0h:44m:14s remains)
INFO - root - 2022-02-24 20:21:28.023259: step 96370, total loss = 0.53, batch loss = 0.26 (129.8 examples/sec; 0.062 sec/batch; 1h:45m:57s remains)
INFO - root - 2022-02-24 20:21:28.352978: step 96380, total loss = 0.55, batch loss = 0.29 (327.2 examples/sec; 0.024 sec/batch; 0h:42m:01s remains)
INFO - root - 2022-02-24 20:21:28.645086: step 96390, total loss = 0.60, batch loss = 0.33 (343.5 examples/sec; 0.023 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:21:28.938923: step 96400, total loss = 0.52, batch loss = 0.25 (141.4 examples/sec; 0.057 sec/batch; 1h:37m:12s remains)
INFO - root - 2022-02-24 20:21:29.376422: step 96410, total loss = 0.56, batch loss = 0.30 (142.1 examples/sec; 0.056 sec/batch; 1h:36m:42s remains)
INFO - root - 2022-02-24 20:21:29.784655: step 96420, total loss = 0.67, batch loss = 0.41 (103.2 examples/sec; 0.078 sec/batch; 2h:13m:08s remains)
INFO - root - 2022-02-24 20:21:30.119410: step 96430, total loss = 0.53, batch loss = 0.27 (334.8 examples/sec; 0.024 sec/batch; 0h:41m:02s remains)
INFO - root - 2022-02-24 20:21:30.420645: step 96440, total loss = 0.53, batch loss = 0.26 (218.9 examples/sec; 0.037 sec/batch; 1h:02m:47s remains)
INFO - root - 2022-02-24 20:21:30.738108: step 96450, total loss = 0.59, batch loss = 0.33 (238.7 examples/sec; 0.034 sec/batch; 0h:57m:34s remains)
INFO - root - 2022-02-24 20:21:31.043977: step 96460, total loss = 0.63, batch loss = 0.36 (221.5 examples/sec; 0.036 sec/batch; 1h:02m:01s remains)
INFO - root - 2022-02-24 20:21:31.359993: step 96470, total loss = 0.57, batch loss = 0.31 (354.9 examples/sec; 0.023 sec/batch; 0h:38m:42s remains)
INFO - root - 2022-02-24 20:21:31.661682: step 96480, total loss = 0.50, batch loss = 0.23 (184.1 examples/sec; 0.043 sec/batch; 1h:14m:37s remains)
INFO - root - 2022-02-24 20:21:32.170231: step 96490, total loss = 0.52, batch loss = 0.25 (354.1 examples/sec; 0.023 sec/batch; 0h:38m:47s remains)
INFO - root - 2022-02-24 20:21:32.571262: step 96500, total loss = 0.50, batch loss = 0.23 (359.3 examples/sec; 0.022 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:21:32.973868: step 96510, total loss = 0.61, batch loss = 0.35 (121.5 examples/sec; 0.066 sec/batch; 1h:53m:01s remains)
INFO - root - 2022-02-24 20:21:33.317102: step 96520, total loss = 0.58, batch loss = 0.31 (214.2 examples/sec; 0.037 sec/batch; 1h:04m:06s remains)
INFO - root - 2022-02-24 20:21:33.808159: step 96530, total loss = 0.57, batch loss = 0.31 (69.5 examples/sec; 0.115 sec/batch; 3h:17m:25s remains)
INFO - root - 2022-02-24 20:21:34.236183: step 96540, total loss = 0.53, batch loss = 0.27 (274.2 examples/sec; 0.029 sec/batch; 0h:50m:03s remains)
INFO - root - 2022-02-24 20:21:34.561120: step 96550, total loss = 0.47, batch loss = 0.21 (320.5 examples/sec; 0.025 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:21:34.873669: step 96560, total loss = 0.46, batch loss = 0.20 (212.7 examples/sec; 0.038 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 20:21:35.265031: step 96570, total loss = 0.57, batch loss = 0.30 (228.2 examples/sec; 0.035 sec/batch; 1h:00m:08s remains)
INFO - root - 2022-02-24 20:21:35.642654: step 96580, total loss = 0.53, batch loss = 0.27 (124.0 examples/sec; 0.065 sec/batch; 1h:50m:39s remains)
INFO - root - 2022-02-24 20:21:36.011310: step 96590, total loss = 0.67, batch loss = 0.41 (343.8 examples/sec; 0.023 sec/batch; 0h:39m:54s remains)
INFO - root - 2022-02-24 20:21:36.261469: step 96600, total loss = 0.52, batch loss = 0.26 (311.4 examples/sec; 0.026 sec/batch; 0h:44m:03s remains)
INFO - root - 2022-02-24 20:21:36.641507: step 96610, total loss = 0.51, batch loss = 0.24 (171.3 examples/sec; 0.047 sec/batch; 1h:20m:06s remains)
INFO - root - 2022-02-24 20:21:36.889349: step 96620, total loss = 0.59, batch loss = 0.32 (359.1 examples/sec; 0.022 sec/batch; 0h:38m:12s remains)
INFO - root - 2022-02-24 20:21:37.205962: step 96630, total loss = 0.49, batch loss = 0.23 (359.7 examples/sec; 0.022 sec/batch; 0h:38m:07s remains)
INFO - root - 2022-02-24 20:21:37.609296: step 96640, total loss = 0.53, batch loss = 0.26 (131.7 examples/sec; 0.061 sec/batch; 1h:44m:08s remains)
INFO - root - 2022-02-24 20:21:38.024047: step 96650, total loss = 0.70, batch loss = 0.43 (315.1 examples/sec; 0.025 sec/batch; 0h:43m:31s remains)
INFO - root - 2022-02-24 20:21:38.324016: step 96660, total loss = 0.55, batch loss = 0.29 (249.0 examples/sec; 0.032 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:21:38.657061: step 96670, total loss = 0.49, batch loss = 0.23 (358.0 examples/sec; 0.022 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 20:21:38.949301: step 96680, total loss = 0.52, batch loss = 0.25 (247.0 examples/sec; 0.032 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 20:21:39.235368: step 96690, total loss = 0.63, batch loss = 0.36 (351.8 examples/sec; 0.023 sec/batch; 0h:38m:57s remains)
INFO - root - 2022-02-24 20:21:39.571829: step 96700, total loss = 0.52, batch loss = 0.25 (257.1 examples/sec; 0.031 sec/batch; 0h:53m:18s remains)
INFO - root - 2022-02-24 20:21:39.974637: step 96710, total loss = 0.59, batch loss = 0.33 (363.0 examples/sec; 0.022 sec/batch; 0h:37m:45s remains)
INFO - root - 2022-02-24 20:21:40.239941: step 96720, total loss = 0.55, batch loss = 0.28 (362.6 examples/sec; 0.022 sec/batch; 0h:37m:47s remains)
INFO - root - 2022-02-24 20:21:40.514131: step 96730, total loss = 0.66, batch loss = 0.39 (214.6 examples/sec; 0.037 sec/batch; 1h:03m:51s remains)
INFO - root - 2022-02-24 20:21:40.915540: step 96740, total loss = 0.58, batch loss = 0.32 (131.3 examples/sec; 0.061 sec/batch; 1h:44m:19s remains)
INFO - root - 2022-02-24 20:21:41.196053: step 96750, total loss = 0.48, batch loss = 0.21 (315.5 examples/sec; 0.025 sec/batch; 0h:43m:25s remains)
INFO - root - 2022-02-24 20:21:41.649490: step 96760, total loss = 0.59, batch loss = 0.32 (246.0 examples/sec; 0.033 sec/batch; 0h:55m:41s remains)
INFO - root - 2022-02-24 20:21:42.106813: step 96770, total loss = 0.54, batch loss = 0.28 (154.5 examples/sec; 0.052 sec/batch; 1h:28m:40s remains)
INFO - root - 2022-02-24 20:21:42.562850: step 96780, total loss = 0.59, batch loss = 0.32 (70.2 examples/sec; 0.114 sec/batch; 3h:15m:11s remains)
INFO - root - 2022-02-24 20:21:43.481755: step 96790, total loss = 0.55, batch loss = 0.28 (212.3 examples/sec; 0.038 sec/batch; 1h:04m:30s remains)
INFO - root - 2022-02-24 20:21:43.916127: step 96800, total loss = 0.63, batch loss = 0.36 (156.8 examples/sec; 0.051 sec/batch; 1h:27m:20s remains)
INFO - root - 2022-02-24 20:21:44.283915: step 96810, total loss = 0.57, batch loss = 0.31 (366.4 examples/sec; 0.022 sec/batch; 0h:37m:22s remains)
INFO - root - 2022-02-24 20:21:44.594891: step 96820, total loss = 0.50, batch loss = 0.23 (361.8 examples/sec; 0.022 sec/batch; 0h:37m:50s remains)
INFO - root - 2022-02-24 20:21:45.009625: step 96830, total loss = 0.54, batch loss = 0.27 (186.5 examples/sec; 0.043 sec/batch; 1h:13m:23s remains)
INFO - root - 2022-02-24 20:21:45.308852: step 96840, total loss = 0.51, batch loss = 0.25 (296.7 examples/sec; 0.027 sec/batch; 0h:46m:07s remains)
INFO - root - 2022-02-24 20:21:45.763788: step 96850, total loss = 0.68, batch loss = 0.41 (112.2 examples/sec; 0.071 sec/batch; 2h:01m:59s remains)
INFO - root - 2022-02-24 20:21:46.137695: step 96860, total loss = 0.56, batch loss = 0.29 (203.9 examples/sec; 0.039 sec/batch; 1h:07m:07s remains)
INFO - root - 2022-02-24 20:21:46.467843: step 96870, total loss = 0.63, batch loss = 0.37 (309.0 examples/sec; 0.026 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:21:46.802089: step 96880, total loss = 0.53, batch loss = 0.26 (297.0 examples/sec; 0.027 sec/batch; 0h:46m:04s remains)
INFO - root - 2022-02-24 20:21:47.165442: step 96890, total loss = 0.60, batch loss = 0.34 (348.2 examples/sec; 0.023 sec/batch; 0h:39m:17s remains)
INFO - root - 2022-02-24 20:21:47.457966: step 96900, total loss = 0.52, batch loss = 0.26 (186.5 examples/sec; 0.043 sec/batch; 1h:13m:20s remains)
INFO - root - 2022-02-24 20:21:48.216088: step 96910, total loss = 0.56, batch loss = 0.30 (182.4 examples/sec; 0.044 sec/batch; 1h:14m:59s remains)
INFO - root - 2022-02-24 20:21:48.709032: step 96920, total loss = 0.53, batch loss = 0.27 (295.0 examples/sec; 0.027 sec/batch; 0h:46m:22s remains)
INFO - root - 2022-02-24 20:21:49.039222: step 96930, total loss = 0.48, batch loss = 0.21 (329.0 examples/sec; 0.024 sec/batch; 0h:41m:34s remains)
INFO - root - 2022-02-24 20:21:49.284985: step 96940, total loss = 0.62, batch loss = 0.36 (350.4 examples/sec; 0.023 sec/batch; 0h:39m:01s remains)
INFO - root - 2022-02-24 20:21:49.631635: step 96950, total loss = 0.45, batch loss = 0.18 (264.6 examples/sec; 0.030 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:21:49.952362: step 96960, total loss = 0.51, batch loss = 0.24 (299.2 examples/sec; 0.027 sec/batch; 0h:45m:41s remains)
INFO - root - 2022-02-24 20:21:50.325595: step 96970, total loss = 0.50, batch loss = 0.23 (139.8 examples/sec; 0.057 sec/batch; 1h:37m:47s remains)
INFO - root - 2022-02-24 20:21:50.729672: step 96980, total loss = 0.53, batch loss = 0.27 (317.5 examples/sec; 0.025 sec/batch; 0h:43m:03s remains)
INFO - root - 2022-02-24 20:21:51.106746: step 96990, total loss = 0.63, batch loss = 0.37 (334.1 examples/sec; 0.024 sec/batch; 0h:40m:54s remains)
INFO - root - 2022-02-24 20:21:51.426798: step 97000, total loss = 0.58, batch loss = 0.32 (362.3 examples/sec; 0.022 sec/batch; 0h:37m:43s remains)
INFO - root - 2022-02-24 20:21:51.812681: step 97010, total loss = 0.54, batch loss = 0.28 (228.6 examples/sec; 0.035 sec/batch; 0h:59m:46s remains)
INFO - root - 2022-02-24 20:21:52.125954: step 97020, total loss = 0.58, batch loss = 0.32 (308.4 examples/sec; 0.026 sec/batch; 0h:44m:18s remains)
INFO - root - 2022-02-24 20:21:52.513522: step 97030, total loss = 0.53, batch loss = 0.27 (145.5 examples/sec; 0.055 sec/batch; 1h:33m:55s remains)
INFO - root - 2022-02-24 20:21:52.880143: step 97040, total loss = 0.51, batch loss = 0.25 (166.4 examples/sec; 0.048 sec/batch; 1h:22m:04s remains)
INFO - root - 2022-02-24 20:21:53.229122: step 97050, total loss = 0.44, batch loss = 0.17 (334.2 examples/sec; 0.024 sec/batch; 0h:40m:52s remains)
INFO - root - 2022-02-24 20:21:53.531378: step 97060, total loss = 0.49, batch loss = 0.23 (160.3 examples/sec; 0.050 sec/batch; 1h:25m:11s remains)
INFO - root - 2022-02-24 20:21:53.804160: step 97070, total loss = 0.60, batch loss = 0.34 (321.2 examples/sec; 0.025 sec/batch; 0h:42m:31s remains)
INFO - root - 2022-02-24 20:21:54.124331: step 97080, total loss = 0.62, batch loss = 0.36 (206.1 examples/sec; 0.039 sec/batch; 1h:06m:15s remains)
INFO - root - 2022-02-24 20:21:54.491754: step 97090, total loss = 0.54, batch loss = 0.28 (136.0 examples/sec; 0.059 sec/batch; 1h:40m:26s remains)
INFO - root - 2022-02-24 20:21:54.888896: step 97100, total loss = 0.50, batch loss = 0.23 (217.5 examples/sec; 0.037 sec/batch; 1h:02m:47s remains)
INFO - root - 2022-02-24 20:21:55.282391: step 97110, total loss = 0.51, batch loss = 0.25 (311.0 examples/sec; 0.026 sec/batch; 0h:43m:53s remains)
INFO - root - 2022-02-24 20:21:55.620984: step 97120, total loss = 0.51, batch loss = 0.24 (201.8 examples/sec; 0.040 sec/batch; 1h:07m:37s remains)
INFO - root - 2022-02-24 20:21:55.952314: step 97130, total loss = 0.64, batch loss = 0.38 (164.5 examples/sec; 0.049 sec/batch; 1h:22m:58s remains)
INFO - root - 2022-02-24 20:21:56.222000: step 97140, total loss = 0.60, batch loss = 0.34 (283.6 examples/sec; 0.028 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:21:56.514561: step 97150, total loss = 0.61, batch loss = 0.34 (256.0 examples/sec; 0.031 sec/batch; 0h:53m:18s remains)
INFO - root - 2022-02-24 20:21:56.947193: step 97160, total loss = 0.62, batch loss = 0.36 (344.4 examples/sec; 0.023 sec/batch; 0h:39m:37s remains)
INFO - root - 2022-02-24 20:21:57.304514: step 97170, total loss = 0.48, batch loss = 0.21 (158.3 examples/sec; 0.051 sec/batch; 1h:26m:12s remains)
INFO - root - 2022-02-24 20:21:57.577548: step 97180, total loss = 0.61, batch loss = 0.35 (315.9 examples/sec; 0.025 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:21:57.897224: step 97190, total loss = 0.52, batch loss = 0.26 (128.8 examples/sec; 0.062 sec/batch; 1h:45m:55s remains)
INFO - root - 2022-02-24 20:21:58.202603: step 97200, total loss = 0.53, batch loss = 0.27 (330.9 examples/sec; 0.024 sec/batch; 0h:41m:13s remains)
INFO - root - 2022-02-24 20:21:58.616313: step 97210, total loss = 0.50, batch loss = 0.23 (185.0 examples/sec; 0.043 sec/batch; 1h:13m:42s remains)
INFO - root - 2022-02-24 20:21:59.034590: step 97220, total loss = 0.56, batch loss = 0.30 (196.6 examples/sec; 0.041 sec/batch; 1h:09m:21s remains)
INFO - root - 2022-02-24 20:21:59.348368: step 97230, total loss = 0.59, batch loss = 0.33 (356.7 examples/sec; 0.022 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:21:59.623279: step 97240, total loss = 0.61, batch loss = 0.34 (310.2 examples/sec; 0.026 sec/batch; 0h:43m:57s remains)
INFO - root - 2022-02-24 20:22:00.018888: step 97250, total loss = 0.57, batch loss = 0.31 (343.9 examples/sec; 0.023 sec/batch; 0h:39m:38s remains)
INFO - root - 2022-02-24 20:22:00.339007: step 97260, total loss = 0.57, batch loss = 0.31 (319.0 examples/sec; 0.025 sec/batch; 0h:42m:43s remains)
INFO - root - 2022-02-24 20:22:00.705607: step 97270, total loss = 0.64, batch loss = 0.38 (285.6 examples/sec; 0.028 sec/batch; 0h:47m:43s remains)
INFO - root - 2022-02-24 20:22:01.178657: step 97280, total loss = 0.60, batch loss = 0.34 (185.2 examples/sec; 0.043 sec/batch; 1h:13m:35s remains)
INFO - root - 2022-02-24 20:22:01.470735: step 97290, total loss = 0.51, batch loss = 0.25 (298.9 examples/sec; 0.027 sec/batch; 0h:45m:35s remains)
INFO - root - 2022-02-24 20:22:01.789606: step 97300, total loss = 0.59, batch loss = 0.32 (319.2 examples/sec; 0.025 sec/batch; 0h:42m:41s remains)
INFO - root - 2022-02-24 20:22:02.214177: step 97310, total loss = 0.53, batch loss = 0.27 (290.7 examples/sec; 0.028 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 20:22:02.586074: step 97320, total loss = 0.59, batch loss = 0.32 (188.0 examples/sec; 0.043 sec/batch; 1h:12m:28s remains)
INFO - root - 2022-02-24 20:22:03.012879: step 97330, total loss = 0.55, batch loss = 0.29 (187.2 examples/sec; 0.043 sec/batch; 1h:12m:45s remains)
INFO - root - 2022-02-24 20:22:03.409590: step 97340, total loss = 0.58, batch loss = 0.32 (234.8 examples/sec; 0.034 sec/batch; 0h:58m:00s remains)
INFO - root - 2022-02-24 20:22:03.696147: step 97350, total loss = 0.54, batch loss = 0.28 (171.1 examples/sec; 0.047 sec/batch; 1h:19m:35s remains)
INFO - root - 2022-02-24 20:22:03.928533: step 97360, total loss = 0.58, batch loss = 0.31 (341.6 examples/sec; 0.023 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 20:22:04.214267: step 97370, total loss = 0.53, batch loss = 0.27 (250.6 examples/sec; 0.032 sec/batch; 0h:54m:20s remains)
INFO - root - 2022-02-24 20:22:04.520174: step 97380, total loss = 0.58, batch loss = 0.31 (366.7 examples/sec; 0.022 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:22:04.965944: step 97390, total loss = 0.62, batch loss = 0.36 (193.9 examples/sec; 0.041 sec/batch; 1h:10m:13s remains)
INFO - root - 2022-02-24 20:22:05.425461: step 97400, total loss = 0.61, batch loss = 0.34 (190.5 examples/sec; 0.042 sec/batch; 1h:11m:28s remains)
INFO - root - 2022-02-24 20:22:05.785757: step 97410, total loss = 0.64, batch loss = 0.37 (346.1 examples/sec; 0.023 sec/batch; 0h:39m:19s remains)
INFO - root - 2022-02-24 20:22:06.199453: step 97420, total loss = 0.65, batch loss = 0.39 (123.8 examples/sec; 0.065 sec/batch; 1h:49m:54s remains)
INFO - root - 2022-02-24 20:22:06.735467: step 97430, total loss = 0.52, batch loss = 0.26 (149.8 examples/sec; 0.053 sec/batch; 1h:30m:51s remains)
INFO - root - 2022-02-24 20:22:07.238736: step 97440, total loss = 0.60, batch loss = 0.34 (352.2 examples/sec; 0.023 sec/batch; 0h:38m:37s remains)
INFO - root - 2022-02-24 20:22:07.715610: step 97450, total loss = 0.57, batch loss = 0.31 (151.1 examples/sec; 0.053 sec/batch; 1h:30m:01s remains)
INFO - root - 2022-02-24 20:22:08.649954: step 97460, total loss = 0.58, batch loss = 0.31 (306.2 examples/sec; 0.026 sec/batch; 0h:44m:25s remains)
INFO - root - 2022-02-24 20:22:09.026618: step 97470, total loss = 0.46, batch loss = 0.20 (142.6 examples/sec; 0.056 sec/batch; 1h:35m:22s remains)
INFO - root - 2022-02-24 20:22:09.376932: step 97480, total loss = 0.47, batch loss = 0.21 (147.3 examples/sec; 0.054 sec/batch; 1h:32m:20s remains)
INFO - root - 2022-02-24 20:22:09.838563: step 97490, total loss = 0.44, batch loss = 0.18 (327.7 examples/sec; 0.024 sec/batch; 0h:41m:30s remains)
INFO - root - 2022-02-24 20:22:10.215017: step 97500, total loss = 0.57, batch loss = 0.30 (357.0 examples/sec; 0.022 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:22:10.843199: step 97510, total loss = 0.65, batch loss = 0.38 (324.1 examples/sec; 0.025 sec/batch; 0h:41m:57s remains)
INFO - root - 2022-02-24 20:22:11.079305: step 97520, total loss = 0.61, batch loss = 0.35 (333.4 examples/sec; 0.024 sec/batch; 0h:40m:46s remains)
INFO - root - 2022-02-24 20:22:11.323429: step 97530, total loss = 0.62, batch loss = 0.35 (345.7 examples/sec; 0.023 sec/batch; 0h:39m:20s remains)
INFO - root - 2022-02-24 20:22:11.714165: step 97540, total loss = 0.61, batch loss = 0.34 (184.1 examples/sec; 0.043 sec/batch; 1h:13m:50s remains)
INFO - root - 2022-02-24 20:22:12.178518: step 97550, total loss = 0.59, batch loss = 0.33 (221.9 examples/sec; 0.036 sec/batch; 1h:01m:16s remains)
INFO - root - 2022-02-24 20:22:12.477788: step 97560, total loss = 0.55, batch loss = 0.29 (338.3 examples/sec; 0.024 sec/batch; 0h:40m:10s remains)
INFO - root - 2022-02-24 20:22:12.857913: step 97570, total loss = 0.51, batch loss = 0.24 (178.4 examples/sec; 0.045 sec/batch; 1h:16m:10s remains)
INFO - root - 2022-02-24 20:22:13.415768: step 97580, total loss = 0.62, batch loss = 0.35 (349.2 examples/sec; 0.023 sec/batch; 0h:38m:54s remains)
INFO - root - 2022-02-24 20:22:13.808952: step 97590, total loss = 0.58, batch loss = 0.31 (169.3 examples/sec; 0.047 sec/batch; 1h:20m:16s remains)
INFO - root - 2022-02-24 20:22:14.235632: step 97600, total loss = 0.62, batch loss = 0.36 (196.6 examples/sec; 0.041 sec/batch; 1h:09m:06s remains)
INFO - root - 2022-02-24 20:22:14.660387: step 97610, total loss = 0.60, batch loss = 0.33 (365.3 examples/sec; 0.022 sec/batch; 0h:37m:11s remains)
INFO - root - 2022-02-24 20:22:14.974490: step 97620, total loss = 0.53, batch loss = 0.27 (304.9 examples/sec; 0.026 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:22:15.266777: step 97630, total loss = 0.50, batch loss = 0.24 (332.0 examples/sec; 0.024 sec/batch; 0h:40m:54s remains)
INFO - root - 2022-02-24 20:22:15.627024: step 97640, total loss = 0.52, batch loss = 0.25 (138.6 examples/sec; 0.058 sec/batch; 1h:37m:58s remains)
INFO - root - 2022-02-24 20:22:16.125804: step 97650, total loss = 0.50, batch loss = 0.23 (121.3 examples/sec; 0.066 sec/batch; 1h:51m:59s remains)
INFO - root - 2022-02-24 20:22:16.434473: step 97660, total loss = 0.67, batch loss = 0.40 (252.2 examples/sec; 0.032 sec/batch; 0h:53m:49s remains)
INFO - root - 2022-02-24 20:22:16.729196: step 97670, total loss = 0.58, batch loss = 0.32 (304.2 examples/sec; 0.026 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:22:17.059943: step 97680, total loss = 0.55, batch loss = 0.29 (364.4 examples/sec; 0.022 sec/batch; 0h:37m:15s remains)
INFO - root - 2022-02-24 20:22:17.352246: step 97690, total loss = 0.53, batch loss = 0.27 (335.0 examples/sec; 0.024 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:22:17.710281: step 97700, total loss = 0.50, batch loss = 0.24 (173.7 examples/sec; 0.046 sec/batch; 1h:18m:07s remains)
INFO - root - 2022-02-24 20:22:18.121965: step 97710, total loss = 0.68, batch loss = 0.41 (200.9 examples/sec; 0.040 sec/batch; 1h:07m:34s remains)
INFO - root - 2022-02-24 20:22:18.516793: step 97720, total loss = 0.52, batch loss = 0.26 (269.2 examples/sec; 0.030 sec/batch; 0h:50m:25s remains)
INFO - root - 2022-02-24 20:22:18.855112: step 97730, total loss = 0.67, batch loss = 0.40 (251.2 examples/sec; 0.032 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 20:22:19.168440: step 97740, total loss = 0.56, batch loss = 0.29 (354.0 examples/sec; 0.023 sec/batch; 0h:38m:19s remains)
INFO - root - 2022-02-24 20:22:19.471220: step 97750, total loss = 0.51, batch loss = 0.25 (362.3 examples/sec; 0.022 sec/batch; 0h:37m:26s remains)
INFO - root - 2022-02-24 20:22:19.772097: step 97760, total loss = 0.61, batch loss = 0.34 (252.4 examples/sec; 0.032 sec/batch; 0h:53m:44s remains)
INFO - root - 2022-02-24 20:22:20.155567: step 97770, total loss = 0.57, batch loss = 0.31 (357.5 examples/sec; 0.022 sec/batch; 0h:37m:56s remains)
INFO - root - 2022-02-24 20:22:20.582988: step 97780, total loss = 0.62, batch loss = 0.36 (265.1 examples/sec; 0.030 sec/batch; 0h:51m:09s remains)
INFO - root - 2022-02-24 20:22:20.879139: step 97790, total loss = 0.54, batch loss = 0.28 (323.7 examples/sec; 0.025 sec/batch; 0h:41m:53s remains)
INFO - root - 2022-02-24 20:22:21.157251: step 97800, total loss = 0.50, batch loss = 0.24 (336.1 examples/sec; 0.024 sec/batch; 0h:40m:20s remains)
INFO - root - 2022-02-24 20:22:21.507540: step 97810, total loss = 0.55, batch loss = 0.29 (312.6 examples/sec; 0.026 sec/batch; 0h:43m:22s remains)
INFO - root - 2022-02-24 20:22:21.833550: step 97820, total loss = 0.52, batch loss = 0.26 (280.3 examples/sec; 0.029 sec/batch; 0h:48m:22s remains)
INFO - root - 2022-02-24 20:22:22.171054: step 97830, total loss = 0.53, batch loss = 0.26 (338.4 examples/sec; 0.024 sec/batch; 0h:40m:03s remains)
INFO - root - 2022-02-24 20:22:22.687097: step 97840, total loss = 0.63, batch loss = 0.37 (160.3 examples/sec; 0.050 sec/batch; 1h:24m:33s remains)
INFO - root - 2022-02-24 20:22:23.077026: step 97850, total loss = 0.61, batch loss = 0.35 (241.2 examples/sec; 0.033 sec/batch; 0h:56m:10s remains)
INFO - root - 2022-02-24 20:22:23.340510: step 97860, total loss = 0.52, batch loss = 0.25 (327.9 examples/sec; 0.024 sec/batch; 0h:41m:19s remains)
INFO - root - 2022-02-24 20:22:23.633716: step 97870, total loss = 0.52, batch loss = 0.26 (362.0 examples/sec; 0.022 sec/batch; 0h:37m:26s remains)
INFO - root - 2022-02-24 20:22:23.962502: step 97880, total loss = 0.58, batch loss = 0.32 (337.7 examples/sec; 0.024 sec/batch; 0h:40m:07s remains)
INFO - root - 2022-02-24 20:22:24.372069: step 97890, total loss = 0.56, batch loss = 0.29 (263.5 examples/sec; 0.030 sec/batch; 0h:51m:24s remains)
INFO - root - 2022-02-24 20:22:24.776251: step 97900, total loss = 0.52, batch loss = 0.25 (175.9 examples/sec; 0.045 sec/batch; 1h:16m:59s remains)
INFO - root - 2022-02-24 20:22:25.172436: step 97910, total loss = 0.64, batch loss = 0.37 (320.1 examples/sec; 0.025 sec/batch; 0h:42m:19s remains)
INFO - root - 2022-02-24 20:22:25.525400: step 97920, total loss = 0.48, batch loss = 0.22 (211.6 examples/sec; 0.038 sec/batch; 1h:04m:01s remains)
INFO - root - 2022-02-24 20:22:25.852368: step 97930, total loss = 0.61, batch loss = 0.35 (326.5 examples/sec; 0.025 sec/batch; 0h:41m:29s remains)
INFO - root - 2022-02-24 20:22:26.304234: step 97940, total loss = 0.62, batch loss = 0.35 (216.4 examples/sec; 0.037 sec/batch; 1h:02m:35s remains)
INFO - root - 2022-02-24 20:22:26.751439: step 97950, total loss = 0.48, batch loss = 0.22 (204.1 examples/sec; 0.039 sec/batch; 1h:06m:20s remains)
INFO - root - 2022-02-24 20:22:27.072263: step 97960, total loss = 0.56, batch loss = 0.29 (218.8 examples/sec; 0.037 sec/batch; 1h:01m:52s remains)
INFO - root - 2022-02-24 20:22:27.403202: step 97970, total loss = 0.59, batch loss = 0.33 (357.8 examples/sec; 0.022 sec/batch; 0h:37m:50s remains)
INFO - root - 2022-02-24 20:22:27.734807: step 97980, total loss = 0.64, batch loss = 0.37 (269.1 examples/sec; 0.030 sec/batch; 0h:50m:18s remains)
INFO - root - 2022-02-24 20:22:28.061124: step 97990, total loss = 0.53, batch loss = 0.27 (197.2 examples/sec; 0.041 sec/batch; 1h:08m:37s remains)
INFO - root - 2022-02-24 20:22:28.423192: step 98000, total loss = 0.49, batch loss = 0.23 (287.4 examples/sec; 0.028 sec/batch; 0h:47m:05s remains)
INFO - root - 2022-02-24 20:22:28.951748: step 98010, total loss = 0.51, batch loss = 0.24 (327.4 examples/sec; 0.024 sec/batch; 0h:41m:20s remains)
INFO - root - 2022-02-24 20:22:29.312926: step 98020, total loss = 0.56, batch loss = 0.29 (246.6 examples/sec; 0.032 sec/batch; 0h:54m:51s remains)
INFO - root - 2022-02-24 20:22:29.669410: step 98030, total loss = 0.50, batch loss = 0.24 (313.7 examples/sec; 0.026 sec/batch; 0h:43m:07s remains)
INFO - root - 2022-02-24 20:22:29.978369: step 98040, total loss = 0.56, batch loss = 0.30 (234.4 examples/sec; 0.034 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:22:30.302889: step 98050, total loss = 0.48, batch loss = 0.22 (225.8 examples/sec; 0.035 sec/batch; 0h:59m:53s remains)
INFO - root - 2022-02-24 20:22:30.693481: step 98060, total loss = 0.59, batch loss = 0.33 (296.7 examples/sec; 0.027 sec/batch; 0h:45m:34s remains)
INFO - root - 2022-02-24 20:22:31.059754: step 98070, total loss = 0.56, batch loss = 0.29 (312.2 examples/sec; 0.026 sec/batch; 0h:43m:19s remains)
INFO - root - 2022-02-24 20:22:31.516124: step 98080, total loss = 0.61, batch loss = 0.35 (289.9 examples/sec; 0.028 sec/batch; 0h:46m:38s remains)
INFO - root - 2022-02-24 20:22:31.946763: step 98090, total loss = 0.49, batch loss = 0.22 (232.0 examples/sec; 0.034 sec/batch; 0h:58m:16s remains)
INFO - root - 2022-02-24 20:22:32.353669: step 98100, total loss = 0.56, batch loss = 0.30 (167.8 examples/sec; 0.048 sec/batch; 1h:20m:35s remains)
INFO - root - 2022-02-24 20:22:32.945375: step 98110, total loss = 0.61, batch loss = 0.34 (214.4 examples/sec; 0.037 sec/batch; 1h:03m:02s remains)
INFO - root - 2022-02-24 20:22:33.479298: step 98120, total loss = 0.50, batch loss = 0.23 (122.4 examples/sec; 0.065 sec/batch; 1h:50m:25s remains)
INFO - root - 2022-02-24 20:22:34.362752: step 98130, total loss = 0.54, batch loss = 0.28 (135.1 examples/sec; 0.059 sec/batch; 1h:40m:03s remains)
INFO - root - 2022-02-24 20:22:34.781293: step 98140, total loss = 0.56, batch loss = 0.30 (196.0 examples/sec; 0.041 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 20:22:35.195333: step 98150, total loss = 0.48, batch loss = 0.21 (241.5 examples/sec; 0.033 sec/batch; 0h:55m:57s remains)
INFO - root - 2022-02-24 20:22:35.510964: step 98160, total loss = 0.57, batch loss = 0.31 (175.6 examples/sec; 0.046 sec/batch; 1h:16m:57s remains)
INFO - root - 2022-02-24 20:22:35.828500: step 98170, total loss = 0.62, batch loss = 0.36 (159.1 examples/sec; 0.050 sec/batch; 1h:24m:56s remains)
INFO - root - 2022-02-24 20:22:36.104025: step 98180, total loss = 0.57, batch loss = 0.31 (322.5 examples/sec; 0.025 sec/batch; 0h:41m:53s remains)
INFO - root - 2022-02-24 20:22:36.442782: step 98190, total loss = 0.58, batch loss = 0.32 (349.3 examples/sec; 0.023 sec/batch; 0h:38m:40s remains)
INFO - root - 2022-02-24 20:22:36.905758: step 98200, total loss = 0.50, batch loss = 0.23 (123.8 examples/sec; 0.065 sec/batch; 1h:49m:06s remains)
INFO - root - 2022-02-24 20:22:37.360548: step 98210, total loss = 0.53, batch loss = 0.26 (231.7 examples/sec; 0.035 sec/batch; 0h:58m:17s remains)
INFO - root - 2022-02-24 20:22:37.675522: step 98220, total loss = 0.54, batch loss = 0.28 (271.9 examples/sec; 0.029 sec/batch; 0h:49m:39s remains)
INFO - root - 2022-02-24 20:22:38.068002: step 98230, total loss = 0.55, batch loss = 0.29 (212.8 examples/sec; 0.038 sec/batch; 1h:03m:27s remains)
INFO - root - 2022-02-24 20:22:38.390406: step 98240, total loss = 0.67, batch loss = 0.41 (188.5 examples/sec; 0.042 sec/batch; 1h:11m:37s remains)
INFO - root - 2022-02-24 20:22:38.884688: step 98250, total loss = 0.56, batch loss = 0.30 (155.3 examples/sec; 0.052 sec/batch; 1h:26m:56s remains)
INFO - root - 2022-02-24 20:22:39.239635: step 98260, total loss = 0.60, batch loss = 0.34 (334.8 examples/sec; 0.024 sec/batch; 0h:40m:19s remains)
INFO - root - 2022-02-24 20:22:39.547804: step 98270, total loss = 0.58, batch loss = 0.31 (304.5 examples/sec; 0.026 sec/batch; 0h:44m:19s remains)
INFO - root - 2022-02-24 20:22:39.882630: step 98280, total loss = 0.49, batch loss = 0.22 (312.1 examples/sec; 0.026 sec/batch; 0h:43m:14s remains)
INFO - root - 2022-02-24 20:22:40.203095: step 98290, total loss = 0.51, batch loss = 0.24 (261.9 examples/sec; 0.031 sec/batch; 0h:51m:31s remains)
INFO - root - 2022-02-24 20:22:40.525431: step 98300, total loss = 0.55, batch loss = 0.29 (106.3 examples/sec; 0.075 sec/batch; 2h:06m:56s remains)
INFO - root - 2022-02-24 20:22:40.982402: step 98310, total loss = 0.53, batch loss = 0.27 (123.9 examples/sec; 0.065 sec/batch; 1h:48m:53s remains)
INFO - root - 2022-02-24 20:22:41.269261: step 98320, total loss = 0.61, batch loss = 0.35 (288.8 examples/sec; 0.028 sec/batch; 0h:46m:42s remains)
INFO - root - 2022-02-24 20:22:41.571059: step 98330, total loss = 0.58, batch loss = 0.31 (322.8 examples/sec; 0.025 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:22:41.901861: step 98340, total loss = 0.69, batch loss = 0.42 (195.5 examples/sec; 0.041 sec/batch; 1h:09m:00s remains)
INFO - root - 2022-02-24 20:22:42.211912: step 98350, total loss = 0.55, batch loss = 0.28 (276.4 examples/sec; 0.029 sec/batch; 0h:48m:47s remains)
INFO - root - 2022-02-24 20:22:42.560428: step 98360, total loss = 0.56, batch loss = 0.29 (352.1 examples/sec; 0.023 sec/batch; 0h:38m:18s remains)
INFO - root - 2022-02-24 20:22:42.857786: step 98370, total loss = 0.44, batch loss = 0.17 (329.5 examples/sec; 0.024 sec/batch; 0h:40m:55s remains)
INFO - root - 2022-02-24 20:22:43.141384: step 98380, total loss = 0.47, batch loss = 0.21 (217.5 examples/sec; 0.037 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:22:43.448734: step 98390, total loss = 0.64, batch loss = 0.38 (344.4 examples/sec; 0.023 sec/batch; 0h:39m:08s remains)
INFO - root - 2022-02-24 20:22:43.813884: step 98400, total loss = 0.52, batch loss = 0.25 (282.0 examples/sec; 0.028 sec/batch; 0h:47m:48s remains)
INFO - root - 2022-02-24 20:22:44.270713: step 98410, total loss = 0.50, batch loss = 0.24 (320.2 examples/sec; 0.025 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 20:22:44.971798: step 98420, total loss = 0.59, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 4h:25m:59s remains)
INFO - root - 2022-02-24 20:22:45.529608: step 98430, total loss = 0.54, batch loss = 0.28 (154.2 examples/sec; 0.052 sec/batch; 1h:27m:22s remains)
INFO - root - 2022-02-24 20:22:46.004381: step 98440, total loss = 0.51, batch loss = 0.25 (236.8 examples/sec; 0.034 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 20:22:46.615170: step 98450, total loss = 0.56, batch loss = 0.30 (213.5 examples/sec; 0.037 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 20:22:47.319238: step 98460, total loss = 0.46, batch loss = 0.20 (147.8 examples/sec; 0.054 sec/batch; 1h:31m:08s remains)
INFO - root - 2022-02-24 20:22:47.688291: step 98470, total loss = 0.55, batch loss = 0.29 (86.2 examples/sec; 0.093 sec/batch; 2h:36m:18s remains)
INFO - root - 2022-02-24 20:22:48.263378: step 98480, total loss = 0.61, batch loss = 0.34 (137.4 examples/sec; 0.058 sec/batch; 1h:38m:00s remains)
INFO - root - 2022-02-24 20:22:48.752017: step 98490, total loss = 0.59, batch loss = 0.33 (360.3 examples/sec; 0.022 sec/batch; 0h:37m:22s remains)
INFO - root - 2022-02-24 20:22:49.399846: step 98500, total loss = 0.62, batch loss = 0.36 (255.1 examples/sec; 0.031 sec/batch; 0h:52m:47s remains)
INFO - root - 2022-02-24 20:22:49.991668: step 98510, total loss = 0.60, batch loss = 0.34 (338.8 examples/sec; 0.024 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:22:50.452696: step 98520, total loss = 0.56, batch loss = 0.30 (328.7 examples/sec; 0.024 sec/batch; 0h:40m:57s remains)
INFO - root - 2022-02-24 20:22:51.092538: step 98530, total loss = 0.51, batch loss = 0.24 (330.3 examples/sec; 0.024 sec/batch; 0h:40m:45s remains)
INFO - root - 2022-02-24 20:22:51.519724: step 98540, total loss = 0.56, batch loss = 0.29 (123.7 examples/sec; 0.065 sec/batch; 1h:48m:48s remains)
INFO - root - 2022-02-24 20:22:52.055172: step 98550, total loss = 0.56, batch loss = 0.30 (60.0 examples/sec; 0.133 sec/batch; 3h:44m:10s remains)
INFO - root - 2022-02-24 20:22:52.637543: step 98560, total loss = 0.52, batch loss = 0.26 (54.2 examples/sec; 0.148 sec/batch; 4h:08m:11s remains)
INFO - root - 2022-02-24 20:22:53.113125: step 98570, total loss = 0.62, batch loss = 0.36 (170.5 examples/sec; 0.047 sec/batch; 1h:18m:55s remains)
INFO - root - 2022-02-24 20:22:53.790217: step 98580, total loss = 0.55, batch loss = 0.29 (178.9 examples/sec; 0.045 sec/batch; 1h:15m:12s remains)
INFO - root - 2022-02-24 20:22:54.340024: step 98590, total loss = 0.50, batch loss = 0.24 (107.7 examples/sec; 0.074 sec/batch; 2h:04m:52s remains)
INFO - root - 2022-02-24 20:22:54.799102: step 98600, total loss = 0.58, batch loss = 0.31 (100.6 examples/sec; 0.080 sec/batch; 2h:13m:46s remains)
INFO - root - 2022-02-24 20:22:55.223041: step 98610, total loss = 0.53, batch loss = 0.26 (204.5 examples/sec; 0.039 sec/batch; 1h:05m:45s remains)
INFO - root - 2022-02-24 20:22:55.618462: step 98620, total loss = 0.60, batch loss = 0.33 (136.5 examples/sec; 0.059 sec/batch; 1h:38m:32s remains)
INFO - root - 2022-02-24 20:22:55.943682: step 98630, total loss = 0.50, batch loss = 0.23 (366.1 examples/sec; 0.022 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:22:56.282349: step 98640, total loss = 0.63, batch loss = 0.36 (354.9 examples/sec; 0.023 sec/batch; 0h:37m:53s remains)
INFO - root - 2022-02-24 20:22:56.615943: step 98650, total loss = 0.57, batch loss = 0.31 (184.7 examples/sec; 0.043 sec/batch; 1h:12m:48s remains)
INFO - root - 2022-02-24 20:22:57.010718: step 98660, total loss = 0.56, batch loss = 0.30 (154.9 examples/sec; 0.052 sec/batch; 1h:26m:48s remains)
INFO - root - 2022-02-24 20:22:57.356021: step 98670, total loss = 0.62, batch loss = 0.36 (337.1 examples/sec; 0.024 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 20:22:57.687175: step 98680, total loss = 0.52, batch loss = 0.25 (158.5 examples/sec; 0.050 sec/batch; 1h:24m:47s remains)
INFO - root - 2022-02-24 20:22:58.006368: step 98690, total loss = 0.57, batch loss = 0.31 (240.7 examples/sec; 0.033 sec/batch; 0h:55m:50s remains)
INFO - root - 2022-02-24 20:22:58.322675: step 98700, total loss = 0.63, batch loss = 0.36 (223.6 examples/sec; 0.036 sec/batch; 1h:00m:05s remains)
INFO - root - 2022-02-24 20:22:58.680892: step 98710, total loss = 0.49, batch loss = 0.22 (339.4 examples/sec; 0.024 sec/batch; 0h:39m:35s remains)
INFO - root - 2022-02-24 20:22:59.142576: step 98720, total loss = 0.61, batch loss = 0.35 (195.5 examples/sec; 0.041 sec/batch; 1h:08m:44s remains)
INFO - root - 2022-02-24 20:22:59.648050: step 98730, total loss = 0.59, batch loss = 0.33 (142.0 examples/sec; 0.056 sec/batch; 1h:34m:38s remains)
INFO - root - 2022-02-24 20:22:59.906034: step 98740, total loss = 0.50, batch loss = 0.24 (311.2 examples/sec; 0.026 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:23:00.180748: step 98750, total loss = 0.55, batch loss = 0.28 (327.8 examples/sec; 0.024 sec/batch; 0h:40m:58s remains)
INFO - root - 2022-02-24 20:23:00.531684: step 98760, total loss = 0.48, batch loss = 0.21 (334.9 examples/sec; 0.024 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:23:00.854982: step 98770, total loss = 0.52, batch loss = 0.26 (277.2 examples/sec; 0.029 sec/batch; 0h:48m:27s remains)
INFO - root - 2022-02-24 20:23:01.246580: step 98780, total loss = 0.61, batch loss = 0.35 (336.3 examples/sec; 0.024 sec/batch; 0h:39m:55s remains)
INFO - root - 2022-02-24 20:23:01.671075: step 98790, total loss = 0.49, batch loss = 0.23 (180.4 examples/sec; 0.044 sec/batch; 1h:14m:27s remains)
INFO - root - 2022-02-24 20:23:01.964702: step 98800, total loss = 0.51, batch loss = 0.24 (334.0 examples/sec; 0.024 sec/batch; 0h:40m:11s remains)
INFO - root - 2022-02-24 20:23:02.338762: step 98810, total loss = 0.53, batch loss = 0.26 (236.0 examples/sec; 0.034 sec/batch; 0h:56m:52s remains)
INFO - root - 2022-02-24 20:23:02.649446: step 98820, total loss = 0.64, batch loss = 0.38 (125.2 examples/sec; 0.064 sec/batch; 1h:47m:12s remains)
INFO - root - 2022-02-24 20:23:02.987168: step 98830, total loss = 0.53, batch loss = 0.26 (111.8 examples/sec; 0.072 sec/batch; 2h:00m:00s remains)
INFO - root - 2022-02-24 20:23:03.312496: step 98840, total loss = 0.54, batch loss = 0.28 (303.8 examples/sec; 0.026 sec/batch; 0h:44m:11s remains)
INFO - root - 2022-02-24 20:23:03.731584: step 98850, total loss = 0.57, batch loss = 0.30 (211.2 examples/sec; 0.038 sec/batch; 1h:03m:32s remains)
INFO - root - 2022-02-24 20:23:03.997959: step 98860, total loss = 0.58, batch loss = 0.32 (337.5 examples/sec; 0.024 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:23:04.441584: step 98870, total loss = 0.63, batch loss = 0.37 (323.3 examples/sec; 0.025 sec/batch; 0h:41m:30s remains)
INFO - root - 2022-02-24 20:23:04.791818: step 98880, total loss = 0.53, batch loss = 0.27 (327.0 examples/sec; 0.024 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:23:05.087626: step 98890, total loss = 0.65, batch loss = 0.39 (272.1 examples/sec; 0.029 sec/batch; 0h:49m:18s remains)
INFO - root - 2022-02-24 20:23:05.494163: step 98900, total loss = 0.50, batch loss = 0.24 (119.8 examples/sec; 0.067 sec/batch; 1h:51m:56s remains)
INFO - root - 2022-02-24 20:23:06.059074: step 98910, total loss = 0.58, batch loss = 0.31 (286.2 examples/sec; 0.028 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 20:23:06.475918: step 98920, total loss = 0.65, batch loss = 0.39 (340.6 examples/sec; 0.023 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:23:07.137065: step 98930, total loss = 0.60, batch loss = 0.34 (88.2 examples/sec; 0.091 sec/batch; 2h:32m:00s remains)
INFO - root - 2022-02-24 20:23:07.524897: step 98940, total loss = 0.58, batch loss = 0.32 (271.7 examples/sec; 0.029 sec/batch; 0h:49m:20s remains)
INFO - root - 2022-02-24 20:23:08.060766: step 98950, total loss = 0.59, batch loss = 0.33 (129.2 examples/sec; 0.062 sec/batch; 1h:43m:44s remains)
INFO - root - 2022-02-24 20:23:08.481206: step 98960, total loss = 0.49, batch loss = 0.22 (196.2 examples/sec; 0.041 sec/batch; 1h:08m:19s remains)
INFO - root - 2022-02-24 20:23:08.846548: step 98970, total loss = 0.60, batch loss = 0.34 (90.0 examples/sec; 0.089 sec/batch; 2h:28m:51s remains)
INFO - root - 2022-02-24 20:23:09.269750: step 98980, total loss = 0.51, batch loss = 0.25 (345.6 examples/sec; 0.023 sec/batch; 0h:38m:46s remains)
INFO - root - 2022-02-24 20:23:10.234477: step 98990, total loss = 0.46, batch loss = 0.20 (150.6 examples/sec; 0.053 sec/batch; 1h:29m:00s remains)
INFO - root - 2022-02-24 20:23:10.657649: step 99000, total loss = 0.53, batch loss = 0.27 (168.6 examples/sec; 0.047 sec/batch; 1h:19m:28s remains)
INFO - root - 2022-02-24 20:23:11.059484: step 99010, total loss = 0.59, batch loss = 0.32 (330.9 examples/sec; 0.024 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:23:11.425288: step 99020, total loss = 0.59, batch loss = 0.32 (219.9 examples/sec; 0.036 sec/batch; 1h:00m:55s remains)
INFO - root - 2022-02-24 20:23:11.766111: step 99030, total loss = 0.58, batch loss = 0.31 (360.7 examples/sec; 0.022 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:23:12.102182: step 99040, total loss = 0.55, batch loss = 0.29 (325.3 examples/sec; 0.025 sec/batch; 0h:41m:10s remains)
INFO - root - 2022-02-24 20:23:12.518540: step 99050, total loss = 0.60, batch loss = 0.34 (196.5 examples/sec; 0.041 sec/batch; 1h:08m:10s remains)
INFO - root - 2022-02-24 20:23:12.846548: step 99060, total loss = 0.55, batch loss = 0.29 (352.7 examples/sec; 0.023 sec/batch; 0h:37m:57s remains)
INFO - root - 2022-02-24 20:23:13.187783: step 99070, total loss = 0.48, batch loss = 0.21 (254.2 examples/sec; 0.031 sec/batch; 0h:52m:40s remains)
INFO - root - 2022-02-24 20:23:13.638114: step 99080, total loss = 0.51, batch loss = 0.25 (147.1 examples/sec; 0.054 sec/batch; 1h:31m:03s remains)
INFO - root - 2022-02-24 20:23:13.957186: step 99090, total loss = 0.63, batch loss = 0.37 (219.8 examples/sec; 0.036 sec/batch; 1h:00m:54s remains)
INFO - root - 2022-02-24 20:23:14.280957: step 99100, total loss = 0.54, batch loss = 0.28 (352.2 examples/sec; 0.023 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 20:23:14.845646: step 99110, total loss = 0.58, batch loss = 0.32 (214.5 examples/sec; 0.037 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 20:23:15.370790: step 99120, total loss = 0.48, batch loss = 0.22 (340.0 examples/sec; 0.024 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:23:15.693030: step 99130, total loss = 0.49, batch loss = 0.23 (261.4 examples/sec; 0.031 sec/batch; 0h:51m:12s remains)
INFO - root - 2022-02-24 20:23:16.005152: step 99140, total loss = 0.49, batch loss = 0.23 (401.2 examples/sec; 0.020 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:23:16.409786: step 99150, total loss = 0.61, batch loss = 0.34 (194.9 examples/sec; 0.041 sec/batch; 1h:08m:39s remains)
INFO - root - 2022-02-24 20:23:16.826198: step 99160, total loss = 0.57, batch loss = 0.30 (368.4 examples/sec; 0.022 sec/batch; 0h:36m:18s remains)
INFO - root - 2022-02-24 20:23:17.178626: step 99170, total loss = 0.58, batch loss = 0.31 (228.4 examples/sec; 0.035 sec/batch; 0h:58m:34s remains)
INFO - root - 2022-02-24 20:23:17.501960: step 99180, total loss = 0.63, batch loss = 0.37 (289.9 examples/sec; 0.028 sec/batch; 0h:46m:08s remains)
INFO - root - 2022-02-24 20:23:17.786728: step 99190, total loss = 0.57, batch loss = 0.31 (277.4 examples/sec; 0.029 sec/batch; 0h:48m:12s remains)
INFO - root - 2022-02-24 20:23:18.111859: step 99200, total loss = 0.47, batch loss = 0.21 (182.0 examples/sec; 0.044 sec/batch; 1h:13m:28s remains)
INFO - root - 2022-02-24 20:23:18.573557: step 99210, total loss = 0.57, batch loss = 0.30 (333.9 examples/sec; 0.024 sec/batch; 0h:40m:03s remains)
INFO - root - 2022-02-24 20:23:18.933959: step 99220, total loss = 0.56, batch loss = 0.29 (217.6 examples/sec; 0.037 sec/batch; 1h:01m:26s remains)
INFO - root - 2022-02-24 20:23:19.293239: step 99230, total loss = 0.52, batch loss = 0.25 (316.0 examples/sec; 0.025 sec/batch; 0h:42m:18s remains)
INFO - root - 2022-02-24 20:23:19.573765: step 99240, total loss = 0.45, batch loss = 0.19 (326.5 examples/sec; 0.024 sec/batch; 0h:40m:56s remains)
INFO - root - 2022-02-24 20:23:19.920623: step 99250, total loss = 0.80, batch loss = 0.53 (226.0 examples/sec; 0.035 sec/batch; 0h:59m:09s remains)
INFO - root - 2022-02-24 20:23:20.307491: step 99260, total loss = 0.64, batch loss = 0.38 (84.6 examples/sec; 0.095 sec/batch; 2h:38m:00s remains)
INFO - root - 2022-02-24 20:23:20.697943: step 99270, total loss = 0.58, batch loss = 0.31 (230.5 examples/sec; 0.035 sec/batch; 0h:57m:58s remains)
INFO - root - 2022-02-24 20:23:21.023319: step 99280, total loss = 0.48, batch loss = 0.22 (121.8 examples/sec; 0.066 sec/batch; 1h:49m:41s remains)
INFO - root - 2022-02-24 20:23:21.370078: step 99290, total loss = 0.61, batch loss = 0.35 (183.2 examples/sec; 0.044 sec/batch; 1h:12m:54s remains)
INFO - root - 2022-02-24 20:23:21.687872: step 99300, total loss = 0.52, batch loss = 0.25 (305.5 examples/sec; 0.026 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:23:22.100931: step 99310, total loss = 0.66, batch loss = 0.39 (228.0 examples/sec; 0.035 sec/batch; 0h:58m:34s remains)
INFO - root - 2022-02-24 20:23:22.358860: step 99320, total loss = 0.57, batch loss = 0.30 (347.4 examples/sec; 0.023 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:23:22.690702: step 99330, total loss = 0.58, batch loss = 0.32 (233.1 examples/sec; 0.034 sec/batch; 0h:57m:18s remains)
INFO - root - 2022-02-24 20:23:23.066122: step 99340, total loss = 0.63, batch loss = 0.36 (245.0 examples/sec; 0.033 sec/batch; 0h:54m:30s remains)
INFO - root - 2022-02-24 20:23:23.404611: step 99350, total loss = 0.62, batch loss = 0.35 (335.1 examples/sec; 0.024 sec/batch; 0h:39m:51s remains)
INFO - root - 2022-02-24 20:23:23.690428: step 99360, total loss = 0.57, batch loss = 0.31 (309.2 examples/sec; 0.026 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:23:23.940831: step 99370, total loss = 0.52, batch loss = 0.26 (332.9 examples/sec; 0.024 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:23:24.226107: step 99380, total loss = 0.66, batch loss = 0.39 (273.4 examples/sec; 0.029 sec/batch; 0h:48m:49s remains)
INFO - root - 2022-02-24 20:23:24.580898: step 99390, total loss = 0.45, batch loss = 0.19 (235.8 examples/sec; 0.034 sec/batch; 0h:56m:36s remains)
INFO - root - 2022-02-24 20:23:24.952356: step 99400, total loss = 0.59, batch loss = 0.33 (210.1 examples/sec; 0.038 sec/batch; 1h:03m:32s remains)
INFO - root - 2022-02-24 20:23:25.467739: step 99410, total loss = 0.58, batch loss = 0.32 (344.2 examples/sec; 0.023 sec/batch; 0h:38m:46s remains)
INFO - root - 2022-02-24 20:23:25.768349: step 99420, total loss = 0.59, batch loss = 0.33 (336.9 examples/sec; 0.024 sec/batch; 0h:39m:36s remains)
INFO - root - 2022-02-24 20:23:26.057475: step 99430, total loss = 0.55, batch loss = 0.29 (343.4 examples/sec; 0.023 sec/batch; 0h:38m:51s remains)
INFO - root - 2022-02-24 20:23:26.377539: step 99440, total loss = 0.67, batch loss = 0.41 (325.4 examples/sec; 0.025 sec/batch; 0h:40m:59s remains)
INFO - root - 2022-02-24 20:23:26.706552: step 99450, total loss = 0.66, batch loss = 0.40 (178.1 examples/sec; 0.045 sec/batch; 1h:14m:53s remains)
INFO - root - 2022-02-24 20:23:27.102264: step 99460, total loss = 0.58, batch loss = 0.31 (140.9 examples/sec; 0.057 sec/batch; 1h:34m:41s remains)
INFO - root - 2022-02-24 20:23:27.435010: step 99470, total loss = 0.64, batch loss = 0.37 (351.2 examples/sec; 0.023 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 20:23:27.743212: step 99480, total loss = 0.60, batch loss = 0.33 (352.2 examples/sec; 0.023 sec/batch; 0h:37m:52s remains)
INFO - root - 2022-02-24 20:23:28.035885: step 99490, total loss = 0.54, batch loss = 0.28 (311.3 examples/sec; 0.026 sec/batch; 0h:42m:50s remains)
INFO - root - 2022-02-24 20:23:28.361693: step 99500, total loss = 0.49, batch loss = 0.23 (127.9 examples/sec; 0.063 sec/batch; 1h:44m:15s remains)
INFO - root - 2022-02-24 20:23:28.786733: step 99510, total loss = 0.49, batch loss = 0.22 (234.4 examples/sec; 0.034 sec/batch; 0h:56m:53s remains)
INFO - root - 2022-02-24 20:23:29.197744: step 99520, total loss = 0.72, batch loss = 0.46 (186.8 examples/sec; 0.043 sec/batch; 1h:11m:22s remains)
INFO - root - 2022-02-24 20:23:29.542366: step 99530, total loss = 0.58, batch loss = 0.32 (214.9 examples/sec; 0.037 sec/batch; 1h:02m:01s remains)
INFO - root - 2022-02-24 20:23:29.864092: step 99540, total loss = 0.78, batch loss = 0.52 (312.8 examples/sec; 0.026 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 20:23:30.149242: step 99550, total loss = 0.61, batch loss = 0.34 (329.7 examples/sec; 0.024 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:23:30.480655: step 99560, total loss = 0.55, batch loss = 0.28 (289.2 examples/sec; 0.028 sec/batch; 0h:46m:04s remains)
INFO - root - 2022-02-24 20:23:30.827659: step 99570, total loss = 0.59, batch loss = 0.33 (197.8 examples/sec; 0.040 sec/batch; 1h:07m:21s remains)
INFO - root - 2022-02-24 20:23:31.192161: step 99580, total loss = 0.66, batch loss = 0.40 (385.2 examples/sec; 0.021 sec/batch; 0h:34m:35s remains)
INFO - root - 2022-02-24 20:23:31.506827: step 99590, total loss = 0.55, batch loss = 0.29 (317.5 examples/sec; 0.025 sec/batch; 0h:41m:57s remains)
INFO - root - 2022-02-24 20:23:31.769884: step 99600, total loss = 0.56, batch loss = 0.29 (208.5 examples/sec; 0.038 sec/batch; 1h:03m:54s remains)
INFO - root - 2022-02-24 20:23:32.126242: step 99610, total loss = 0.58, batch loss = 0.32 (318.0 examples/sec; 0.025 sec/batch; 0h:41m:53s remains)
INFO - root - 2022-02-24 20:23:32.398826: step 99620, total loss = 0.60, batch loss = 0.34 (263.3 examples/sec; 0.030 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:23:32.974627: step 99630, total loss = 0.62, batch loss = 0.35 (150.9 examples/sec; 0.053 sec/batch; 1h:28m:13s remains)
INFO - root - 2022-02-24 20:23:33.422541: step 99640, total loss = 0.53, batch loss = 0.26 (73.1 examples/sec; 0.109 sec/batch; 3h:02m:03s remains)
INFO - root - 2022-02-24 20:23:33.969518: step 99650, total loss = 0.50, batch loss = 0.24 (97.5 examples/sec; 0.082 sec/batch; 2h:16m:33s remains)
INFO - root - 2022-02-24 20:23:34.605125: step 99660, total loss = 0.66, batch loss = 0.40 (125.7 examples/sec; 0.064 sec/batch; 1h:45m:54s remains)
INFO - root - 2022-02-24 20:23:35.134464: step 99670, total loss = 0.58, batch loss = 0.31 (311.9 examples/sec; 0.026 sec/batch; 0h:42m:40s remains)
INFO - root - 2022-02-24 20:23:36.275558: step 99680, total loss = 0.50, batch loss = 0.24 (180.6 examples/sec; 0.044 sec/batch; 1h:13m:41s remains)
INFO - root - 2022-02-24 20:23:36.618981: step 99690, total loss = 0.53, batch loss = 0.27 (217.3 examples/sec; 0.037 sec/batch; 1h:01m:14s remains)
INFO - root - 2022-02-24 20:23:36.958986: step 99700, total loss = 0.54, batch loss = 0.28 (224.4 examples/sec; 0.036 sec/batch; 0h:59m:17s remains)
INFO - root - 2022-02-24 20:23:37.380985: step 99710, total loss = 0.53, batch loss = 0.27 (120.6 examples/sec; 0.066 sec/batch; 1h:50m:17s remains)
INFO - root - 2022-02-24 20:23:37.771561: step 99720, total loss = 0.57, batch loss = 0.31 (305.6 examples/sec; 0.026 sec/batch; 0h:43m:32s remains)
INFO - root - 2022-02-24 20:23:38.257293: step 99730, total loss = 0.58, batch loss = 0.32 (108.7 examples/sec; 0.074 sec/batch; 2h:02m:25s remains)
INFO - root - 2022-02-24 20:23:38.628999: step 99740, total loss = 0.50, batch loss = 0.24 (269.6 examples/sec; 0.030 sec/batch; 0h:49m:19s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-99749 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-99749 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:23:39.416033: step 99750, total loss = 0.73, batch loss = 0.46 (279.4 examples/sec; 0.029 sec/batch; 0h:47m:36s remains)
INFO - root - 2022-02-24 20:23:39.665355: step 99760, total loss = 0.52, batch loss = 0.25 (339.0 examples/sec; 0.024 sec/batch; 0h:39m:13s remains)
INFO - root - 2022-02-24 20:23:40.022411: step 99770, total loss = 0.50, batch loss = 0.24 (186.2 examples/sec; 0.043 sec/batch; 1h:11m:25s remains)
INFO - root - 2022-02-24 20:23:40.517605: step 99780, total loss = 0.46, batch loss = 0.20 (208.4 examples/sec; 0.038 sec/batch; 1h:03m:47s remains)
INFO - root - 2022-02-24 20:23:40.833648: step 99790, total loss = 0.56, batch loss = 0.30 (305.4 examples/sec; 0.026 sec/batch; 0h:43m:31s remains)
INFO - root - 2022-02-24 20:23:41.233207: step 99800, total loss = 0.54, batch loss = 0.28 (184.0 examples/sec; 0.043 sec/batch; 1h:12m:15s remains)
INFO - root - 2022-02-24 20:23:41.679622: step 99810, total loss = 0.67, batch loss = 0.41 (222.3 examples/sec; 0.036 sec/batch; 0h:59m:47s remains)
INFO - root - 2022-02-24 20:23:42.006382: step 99820, total loss = 0.56, batch loss = 0.30 (207.1 examples/sec; 0.039 sec/batch; 1h:04m:11s remains)
INFO - root - 2022-02-24 20:23:42.365354: step 99830, total loss = 0.62, batch loss = 0.36 (161.3 examples/sec; 0.050 sec/batch; 1h:22m:22s remains)
INFO - root - 2022-02-24 20:23:42.674652: step 99840, total loss = 0.59, batch loss = 0.32 (194.8 examples/sec; 0.041 sec/batch; 1h:08m:12s remains)
INFO - root - 2022-02-24 20:23:42.938047: step 99850, total loss = 0.62, batch loss = 0.36 (364.1 examples/sec; 0.022 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:23:43.260910: step 99860, total loss = 0.52, batch loss = 0.26 (242.6 examples/sec; 0.033 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:23:43.625957: step 99870, total loss = 0.59, batch loss = 0.33 (165.4 examples/sec; 0.048 sec/batch; 1h:20m:18s remains)
INFO - root - 2022-02-24 20:23:44.037060: step 99880, total loss = 0.62, batch loss = 0.35 (380.2 examples/sec; 0.021 sec/batch; 0h:34m:56s remains)
INFO - root - 2022-02-24 20:23:44.371819: step 99890, total loss = 0.63, batch loss = 0.36 (321.1 examples/sec; 0.025 sec/batch; 0h:41m:21s remains)
INFO - root - 2022-02-24 20:23:44.655556: step 99900, total loss = 0.53, batch loss = 0.27 (194.3 examples/sec; 0.041 sec/batch; 1h:08m:20s remains)
INFO - root - 2022-02-24 20:23:44.995558: step 99910, total loss = 0.47, batch loss = 0.20 (330.9 examples/sec; 0.024 sec/batch; 0h:40m:07s remains)
INFO - root - 2022-02-24 20:23:45.239401: step 99920, total loss = 0.53, batch loss = 0.26 (309.4 examples/sec; 0.026 sec/batch; 0h:42m:54s remains)
INFO - root - 2022-02-24 20:23:45.580438: step 99930, total loss = 0.49, batch loss = 0.23 (192.3 examples/sec; 0.042 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 20:23:45.923583: step 99940, total loss = 0.51, batch loss = 0.24 (264.6 examples/sec; 0.030 sec/batch; 0h:50m:10s remains)
INFO - root - 2022-02-24 20:23:46.303319: step 99950, total loss = 0.51, batch loss = 0.24 (294.3 examples/sec; 0.027 sec/batch; 0h:45m:05s remains)
INFO - root - 2022-02-24 20:23:46.620857: step 99960, total loss = 0.57, batch loss = 0.31 (183.2 examples/sec; 0.044 sec/batch; 1h:12m:25s remains)
INFO - root - 2022-02-24 20:23:46.921141: step 99970, total loss = 0.57, batch loss = 0.30 (312.6 examples/sec; 0.026 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:23:47.232307: step 99980, total loss = 0.47, batch loss = 0.20 (281.5 examples/sec; 0.028 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:23:47.655277: step 99990, total loss = 0.54, batch loss = 0.28 (335.0 examples/sec; 0.024 sec/batch; 0h:39m:36s remains)
INFO - root - 2022-02-24 20:23:47.991969: step 100000, total loss = 0.48, batch loss = 0.21 (314.6 examples/sec; 0.025 sec/batch; 0h:42m:10s remains)
INFO - root - 2022-02-24 20:23:48.346593: step 100010, total loss = 0.44, batch loss = 0.18 (308.4 examples/sec; 0.026 sec/batch; 0h:43m:01s remains)
INFO - root - 2022-02-24 20:23:48.604165: step 100020, total loss = 0.56, batch loss = 0.30 (329.4 examples/sec; 0.024 sec/batch; 0h:40m:15s remains)
INFO - root - 2022-02-24 20:23:48.893413: step 100030, total loss = 0.58, batch loss = 0.31 (197.7 examples/sec; 0.040 sec/batch; 1h:07m:04s remains)
INFO - root - 2022-02-24 20:23:49.185902: step 100040, total loss = 0.57, batch loss = 0.31 (208.2 examples/sec; 0.038 sec/batch; 1h:03m:42s remains)
INFO - root - 2022-02-24 20:23:49.564491: step 100050, total loss = 0.51, batch loss = 0.25 (205.2 examples/sec; 0.039 sec/batch; 1h:04m:38s remains)
INFO - root - 2022-02-24 20:23:49.993790: step 100060, total loss = 0.52, batch loss = 0.26 (143.8 examples/sec; 0.056 sec/batch; 1h:32m:11s remains)
INFO - root - 2022-02-24 20:23:50.291019: step 100070, total loss = 0.56, batch loss = 0.29 (186.7 examples/sec; 0.043 sec/batch; 1h:11m:00s remains)
INFO - root - 2022-02-24 20:23:50.665051: step 100080, total loss = 0.65, batch loss = 0.39 (130.3 examples/sec; 0.061 sec/batch; 1h:41m:44s remains)
INFO - root - 2022-02-24 20:23:50.964002: step 100090, total loss = 0.52, batch loss = 0.25 (236.6 examples/sec; 0.034 sec/batch; 0h:56m:01s remains)
INFO - root - 2022-02-24 20:23:51.363952: step 100100, total loss = 0.56, batch loss = 0.30 (136.9 examples/sec; 0.058 sec/batch; 1h:36m:47s remains)
INFO - root - 2022-02-24 20:23:51.769215: step 100110, total loss = 0.43, batch loss = 0.16 (216.6 examples/sec; 0.037 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 20:23:52.053003: step 100120, total loss = 0.62, batch loss = 0.35 (275.9 examples/sec; 0.029 sec/batch; 0h:48m:01s remains)
INFO - root - 2022-02-24 20:23:52.417543: step 100130, total loss = 0.52, batch loss = 0.25 (198.2 examples/sec; 0.040 sec/batch; 1h:06m:51s remains)
INFO - root - 2022-02-24 20:23:52.763320: step 100140, total loss = 0.70, batch loss = 0.43 (345.8 examples/sec; 0.023 sec/batch; 0h:38m:18s remains)
INFO - root - 2022-02-24 20:23:53.053257: step 100150, total loss = 0.57, batch loss = 0.31 (255.5 examples/sec; 0.031 sec/batch; 0h:51m:50s remains)
INFO - root - 2022-02-24 20:23:53.491802: step 100160, total loss = 0.54, batch loss = 0.27 (240.7 examples/sec; 0.033 sec/batch; 0h:55m:01s remains)
INFO - root - 2022-02-24 20:23:53.812863: step 100170, total loss = 0.48, batch loss = 0.22 (315.7 examples/sec; 0.025 sec/batch; 0h:41m:56s remains)
INFO - root - 2022-02-24 20:23:54.169387: step 100180, total loss = 0.53, batch loss = 0.27 (278.1 examples/sec; 0.029 sec/batch; 0h:47m:36s remains)
INFO - root - 2022-02-24 20:23:54.508720: step 100190, total loss = 0.62, batch loss = 0.36 (199.9 examples/sec; 0.040 sec/batch; 1h:06m:14s remains)
INFO - root - 2022-02-24 20:23:54.792127: step 100200, total loss = 0.52, batch loss = 0.26 (276.4 examples/sec; 0.029 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:23:55.159019: step 100210, total loss = 0.60, batch loss = 0.34 (318.8 examples/sec; 0.025 sec/batch; 0h:41m:31s remains)
INFO - root - 2022-02-24 20:23:55.511151: step 100220, total loss = 0.62, batch loss = 0.36 (190.9 examples/sec; 0.042 sec/batch; 1h:09m:20s remains)
INFO - root - 2022-02-24 20:23:55.902749: step 100230, total loss = 0.60, batch loss = 0.34 (180.4 examples/sec; 0.044 sec/batch; 1h:13m:21s remains)
INFO - root - 2022-02-24 20:23:56.681727: step 100240, total loss = 0.65, batch loss = 0.39 (317.9 examples/sec; 0.025 sec/batch; 0h:41m:37s remains)
INFO - root - 2022-02-24 20:23:57.109098: step 100250, total loss = 0.50, batch loss = 0.23 (224.0 examples/sec; 0.036 sec/batch; 0h:59m:04s remains)
INFO - root - 2022-02-24 20:23:57.477114: step 100260, total loss = 0.57, batch loss = 0.31 (280.3 examples/sec; 0.029 sec/batch; 0h:47m:12s remains)
INFO - root - 2022-02-24 20:23:57.941988: step 100270, total loss = 0.57, batch loss = 0.31 (170.1 examples/sec; 0.047 sec/batch; 1h:17m:46s remains)
INFO - root - 2022-02-24 20:23:58.445622: step 100280, total loss = 0.48, batch loss = 0.22 (335.2 examples/sec; 0.024 sec/batch; 0h:39m:28s remains)
INFO - root - 2022-02-24 20:23:58.898229: step 100290, total loss = 0.62, batch loss = 0.35 (156.3 examples/sec; 0.051 sec/batch; 1h:24m:38s remains)
INFO - root - 2022-02-24 20:23:59.279771: step 100300, total loss = 0.62, batch loss = 0.36 (178.2 examples/sec; 0.045 sec/batch; 1h:14m:12s remains)
INFO - root - 2022-02-24 20:23:59.737987: step 100310, total loss = 0.50, batch loss = 0.24 (263.1 examples/sec; 0.030 sec/batch; 0h:50m:15s remains)
INFO - root - 2022-02-24 20:24:00.106366: step 100320, total loss = 0.52, batch loss = 0.25 (147.7 examples/sec; 0.054 sec/batch; 1h:29m:32s remains)
INFO - root - 2022-02-24 20:24:00.465598: step 100330, total loss = 0.62, batch loss = 0.36 (187.3 examples/sec; 0.043 sec/batch; 1h:10m:36s remains)
INFO - root - 2022-02-24 20:24:00.829836: step 100340, total loss = 0.80, batch loss = 0.54 (312.2 examples/sec; 0.026 sec/batch; 0h:42m:21s remains)
INFO - root - 2022-02-24 20:24:01.610237: step 100350, total loss = 0.57, batch loss = 0.30 (95.6 examples/sec; 0.084 sec/batch; 2h:18m:17s remains)
INFO - root - 2022-02-24 20:24:02.037922: step 100360, total loss = 0.70, batch loss = 0.44 (252.7 examples/sec; 0.032 sec/batch; 0h:52m:18s remains)
INFO - root - 2022-02-24 20:24:02.363857: step 100370, total loss = 0.61, batch loss = 0.35 (192.8 examples/sec; 0.041 sec/batch; 1h:08m:33s remains)
INFO - root - 2022-02-24 20:24:02.712180: step 100380, total loss = 0.55, batch loss = 0.28 (236.2 examples/sec; 0.034 sec/batch; 0h:55m:56s remains)
INFO - root - 2022-02-24 20:24:02.982463: step 100390, total loss = 0.53, batch loss = 0.26 (313.1 examples/sec; 0.026 sec/batch; 0h:42m:11s remains)
INFO - root - 2022-02-24 20:24:03.219798: step 100400, total loss = 0.49, batch loss = 0.23 (258.8 examples/sec; 0.031 sec/batch; 0h:51m:02s remains)
INFO - root - 2022-02-24 20:24:03.725409: step 100410, total loss = 0.50, batch loss = 0.24 (149.9 examples/sec; 0.053 sec/batch; 1h:28m:07s remains)
INFO - root - 2022-02-24 20:24:04.087536: step 100420, total loss = 0.55, batch loss = 0.28 (275.7 examples/sec; 0.029 sec/batch; 0h:47m:54s remains)
INFO - root - 2022-02-24 20:24:04.614753: step 100430, total loss = 0.60, batch loss = 0.34 (350.2 examples/sec; 0.023 sec/batch; 0h:37m:43s remains)
INFO - root - 2022-02-24 20:24:04.991454: step 100440, total loss = 0.55, batch loss = 0.29 (301.6 examples/sec; 0.027 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:24:05.259742: step 100450, total loss = 0.59, batch loss = 0.32 (322.6 examples/sec; 0.025 sec/batch; 0h:40m:56s remains)
INFO - root - 2022-02-24 20:24:05.580124: step 100460, total loss = 0.68, batch loss = 0.42 (396.7 examples/sec; 0.020 sec/batch; 0h:33m:17s remains)
INFO - root - 2022-02-24 20:24:06.006705: step 100470, total loss = 0.64, batch loss = 0.38 (114.2 examples/sec; 0.070 sec/batch; 1h:55m:34s remains)
INFO - root - 2022-02-24 20:24:06.392803: step 100480, total loss = 0.60, batch loss = 0.34 (182.6 examples/sec; 0.044 sec/batch; 1h:12m:17s remains)
INFO - root - 2022-02-24 20:24:06.766207: step 100490, total loss = 0.52, batch loss = 0.25 (100.8 examples/sec; 0.079 sec/batch; 2h:10m:57s remains)
INFO - root - 2022-02-24 20:24:07.102390: step 100500, total loss = 0.91, batch loss = 0.65 (332.5 examples/sec; 0.024 sec/batch; 0h:39m:42s remains)
INFO - root - 2022-02-24 20:24:07.464805: step 100510, total loss = 0.54, batch loss = 0.27 (162.7 examples/sec; 0.049 sec/batch; 1h:21m:07s remains)
INFO - root - 2022-02-24 20:24:07.778772: step 100520, total loss = 0.54, batch loss = 0.28 (213.7 examples/sec; 0.037 sec/batch; 1h:01m:45s remains)
INFO - root - 2022-02-24 20:24:08.160919: step 100530, total loss = 0.51, batch loss = 0.25 (316.5 examples/sec; 0.025 sec/batch; 0h:41m:41s remains)
INFO - root - 2022-02-24 20:24:08.556859: step 100540, total loss = 0.53, batch loss = 0.27 (303.2 examples/sec; 0.026 sec/batch; 0h:43m:31s remains)
INFO - root - 2022-02-24 20:24:08.863688: step 100550, total loss = 0.51, batch loss = 0.25 (328.0 examples/sec; 0.024 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:24:09.128754: step 100560, total loss = 0.52, batch loss = 0.25 (336.6 examples/sec; 0.024 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 20:24:09.472644: step 100570, total loss = 0.44, batch loss = 0.18 (294.7 examples/sec; 0.027 sec/batch; 0h:44m:45s remains)
INFO - root - 2022-02-24 20:24:09.737972: step 100580, total loss = 0.51, batch loss = 0.24 (326.9 examples/sec; 0.024 sec/batch; 0h:40m:21s remains)
INFO - root - 2022-02-24 20:24:10.121865: step 100590, total loss = 0.52, batch loss = 0.26 (138.4 examples/sec; 0.058 sec/batch; 1h:35m:18s remains)
INFO - root - 2022-02-24 20:24:10.501362: step 100600, total loss = 0.63, batch loss = 0.37 (213.8 examples/sec; 0.037 sec/batch; 1h:01m:41s remains)
INFO - root - 2022-02-24 20:24:10.888900: step 100610, total loss = 0.54, batch loss = 0.28 (191.0 examples/sec; 0.042 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 20:24:11.176574: step 100620, total loss = 0.62, batch loss = 0.35 (340.6 examples/sec; 0.023 sec/batch; 0h:38m:42s remains)
INFO - root - 2022-02-24 20:24:11.526276: step 100630, total loss = 0.54, batch loss = 0.28 (330.3 examples/sec; 0.024 sec/batch; 0h:39m:54s remains)
INFO - root - 2022-02-24 20:24:11.860063: step 100640, total loss = 0.60, batch loss = 0.34 (350.8 examples/sec; 0.023 sec/batch; 0h:37m:34s remains)
INFO - root - 2022-02-24 20:24:12.194029: step 100650, total loss = 0.50, batch loss = 0.24 (200.6 examples/sec; 0.040 sec/batch; 1h:05m:41s remains)
INFO - root - 2022-02-24 20:24:12.562728: step 100660, total loss = 0.70, batch loss = 0.43 (125.8 examples/sec; 0.064 sec/batch; 1h:44m:43s remains)
INFO - root - 2022-02-24 20:24:12.859826: step 100670, total loss = 0.48, batch loss = 0.21 (236.1 examples/sec; 0.034 sec/batch; 0h:55m:48s remains)
INFO - root - 2022-02-24 20:24:13.140488: step 100680, total loss = 0.55, batch loss = 0.29 (283.5 examples/sec; 0.028 sec/batch; 0h:46m:28s remains)
INFO - root - 2022-02-24 20:24:13.512252: step 100690, total loss = 0.52, batch loss = 0.26 (184.6 examples/sec; 0.043 sec/batch; 1h:11m:23s remains)
INFO - root - 2022-02-24 20:24:13.936884: step 100700, total loss = 0.53, batch loss = 0.27 (77.0 examples/sec; 0.104 sec/batch; 2h:51m:10s remains)
INFO - root - 2022-02-24 20:24:14.358927: step 100710, total loss = 0.58, batch loss = 0.32 (213.1 examples/sec; 0.038 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 20:24:14.708343: step 100720, total loss = 0.54, batch loss = 0.28 (347.1 examples/sec; 0.023 sec/batch; 0h:37m:56s remains)
INFO - root - 2022-02-24 20:24:14.982743: step 100730, total loss = 0.51, batch loss = 0.25 (344.3 examples/sec; 0.023 sec/batch; 0h:38m:14s remains)
INFO - root - 2022-02-24 20:24:15.264413: step 100740, total loss = 0.73, batch loss = 0.46 (261.7 examples/sec; 0.031 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 20:24:15.520302: step 100750, total loss = 0.55, batch loss = 0.29 (324.5 examples/sec; 0.025 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:24:15.870256: step 100760, total loss = 0.50, batch loss = 0.23 (149.2 examples/sec; 0.054 sec/batch; 1h:28m:15s remains)
INFO - root - 2022-02-24 20:24:16.271198: step 100770, total loss = 0.49, batch loss = 0.22 (190.9 examples/sec; 0.042 sec/batch; 1h:08m:57s remains)
INFO - root - 2022-02-24 20:24:16.693034: step 100780, total loss = 0.54, batch loss = 0.28 (334.2 examples/sec; 0.024 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:24:17.038564: step 100790, total loss = 0.53, batch loss = 0.26 (270.0 examples/sec; 0.030 sec/batch; 0h:48m:44s remains)
INFO - root - 2022-02-24 20:24:17.342802: step 100800, total loss = 0.52, batch loss = 0.26 (341.0 examples/sec; 0.023 sec/batch; 0h:38m:35s remains)
INFO - root - 2022-02-24 20:24:17.699430: step 100810, total loss = 0.53, batch loss = 0.27 (330.9 examples/sec; 0.024 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:24:17.982111: step 100820, total loss = 0.62, batch loss = 0.36 (360.1 examples/sec; 0.022 sec/batch; 0h:36m:32s remains)
INFO - root - 2022-02-24 20:24:18.418961: step 100830, total loss = 0.63, batch loss = 0.37 (245.2 examples/sec; 0.033 sec/batch; 0h:53m:39s remains)
INFO - root - 2022-02-24 20:24:18.866187: step 100840, total loss = 0.54, batch loss = 0.28 (250.6 examples/sec; 0.032 sec/batch; 0h:52m:30s remains)
INFO - root - 2022-02-24 20:24:19.147390: step 100850, total loss = 0.58, batch loss = 0.31 (343.0 examples/sec; 0.023 sec/batch; 0h:38m:20s remains)
INFO - root - 2022-02-24 20:24:19.439477: step 100860, total loss = 0.73, batch loss = 0.46 (311.2 examples/sec; 0.026 sec/batch; 0h:42m:15s remains)
INFO - root - 2022-02-24 20:24:19.793568: step 100870, total loss = 0.56, batch loss = 0.29 (263.8 examples/sec; 0.030 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:24:20.101860: step 100880, total loss = 0.52, batch loss = 0.26 (326.1 examples/sec; 0.025 sec/batch; 0h:40m:19s remains)
INFO - root - 2022-02-24 20:24:20.508093: step 100890, total loss = 0.65, batch loss = 0.38 (208.5 examples/sec; 0.038 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 20:24:20.958172: step 100900, total loss = 0.49, batch loss = 0.22 (330.2 examples/sec; 0.024 sec/batch; 0h:39m:49s remains)
INFO - root - 2022-02-24 20:24:21.295994: step 100910, total loss = 0.59, batch loss = 0.33 (340.8 examples/sec; 0.023 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 20:24:21.603960: step 100920, total loss = 0.48, batch loss = 0.22 (236.3 examples/sec; 0.034 sec/batch; 0h:55m:36s remains)
INFO - root - 2022-02-24 20:24:21.888790: step 100930, total loss = 0.64, batch loss = 0.38 (325.1 examples/sec; 0.025 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:24:22.122927: step 100940, total loss = 0.58, batch loss = 0.32 (289.3 examples/sec; 0.028 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:24:22.390441: step 100950, total loss = 0.50, batch loss = 0.23 (340.7 examples/sec; 0.023 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 20:24:22.791585: step 100960, total loss = 0.50, batch loss = 0.23 (236.5 examples/sec; 0.034 sec/batch; 0h:55m:32s remains)
INFO - root - 2022-02-24 20:24:23.184252: step 100970, total loss = 0.49, batch loss = 0.23 (298.4 examples/sec; 0.027 sec/batch; 0h:44m:01s remains)
INFO - root - 2022-02-24 20:24:23.496193: step 100980, total loss = 0.60, batch loss = 0.34 (320.3 examples/sec; 0.025 sec/batch; 0h:41m:00s remains)
INFO - root - 2022-02-24 20:24:23.816856: step 100990, total loss = 0.47, batch loss = 0.20 (152.8 examples/sec; 0.052 sec/batch; 1h:25m:56s remains)
INFO - root - 2022-02-24 20:24:24.166392: step 101000, total loss = 0.54, batch loss = 0.28 (113.3 examples/sec; 0.071 sec/batch; 1h:55m:54s remains)
INFO - root - 2022-02-24 20:24:24.744513: step 101010, total loss = 0.60, batch loss = 0.33 (257.0 examples/sec; 0.031 sec/batch; 0h:51m:05s remains)
INFO - root - 2022-02-24 20:24:25.177068: step 101020, total loss = 0.55, batch loss = 0.29 (217.8 examples/sec; 0.037 sec/batch; 1h:00m:17s remains)
INFO - root - 2022-02-24 20:24:25.577310: step 101030, total loss = 0.61, batch loss = 0.35 (169.7 examples/sec; 0.047 sec/batch; 1h:17m:21s remains)
INFO - root - 2022-02-24 20:24:25.909903: step 101040, total loss = 0.52, batch loss = 0.26 (369.7 examples/sec; 0.022 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:24:26.315607: step 101050, total loss = 0.54, batch loss = 0.28 (370.9 examples/sec; 0.022 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 20:24:27.116330: step 101060, total loss = 0.53, batch loss = 0.27 (115.5 examples/sec; 0.069 sec/batch; 1h:53m:39s remains)
INFO - root - 2022-02-24 20:24:27.577912: step 101070, total loss = 0.53, batch loss = 0.27 (176.1 examples/sec; 0.045 sec/batch; 1h:14m:30s remains)
INFO - root - 2022-02-24 20:24:27.959299: step 101080, total loss = 0.48, batch loss = 0.22 (182.4 examples/sec; 0.044 sec/batch; 1h:11m:56s remains)
INFO - root - 2022-02-24 20:24:28.296362: step 101090, total loss = 0.53, batch loss = 0.27 (234.0 examples/sec; 0.034 sec/batch; 0h:56m:04s remains)
INFO - root - 2022-02-24 20:24:28.604212: step 101100, total loss = 0.49, batch loss = 0.23 (233.3 examples/sec; 0.034 sec/batch; 0h:56m:14s remains)
INFO - root - 2022-02-24 20:24:29.101457: step 101110, total loss = 0.51, batch loss = 0.25 (265.6 examples/sec; 0.030 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:24:29.574115: step 101120, total loss = 0.72, batch loss = 0.46 (188.3 examples/sec; 0.042 sec/batch; 1h:09m:39s remains)
INFO - root - 2022-02-24 20:24:30.066453: step 101130, total loss = 0.58, batch loss = 0.32 (371.5 examples/sec; 0.022 sec/batch; 0h:35m:18s remains)
INFO - root - 2022-02-24 20:24:30.537982: step 101140, total loss = 0.63, batch loss = 0.36 (197.0 examples/sec; 0.041 sec/batch; 1h:06m:34s remains)
INFO - root - 2022-02-24 20:24:30.916404: step 101150, total loss = 0.54, batch loss = 0.28 (322.7 examples/sec; 0.025 sec/batch; 0h:40m:37s remains)
INFO - root - 2022-02-24 20:24:31.282769: step 101160, total loss = 0.59, batch loss = 0.32 (207.6 examples/sec; 0.039 sec/batch; 1h:03m:08s remains)
INFO - root - 2022-02-24 20:24:32.050655: step 101170, total loss = 0.77, batch loss = 0.50 (291.1 examples/sec; 0.027 sec/batch; 0h:45m:02s remains)
INFO - root - 2022-02-24 20:24:32.415023: step 101180, total loss = 0.63, batch loss = 0.36 (251.5 examples/sec; 0.032 sec/batch; 0h:52m:07s remains)
INFO - root - 2022-02-24 20:24:32.685446: step 101190, total loss = 0.51, batch loss = 0.24 (255.5 examples/sec; 0.031 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:24:32.935285: step 101200, total loss = 0.52, batch loss = 0.25 (337.6 examples/sec; 0.024 sec/batch; 0h:38m:49s remains)
INFO - root - 2022-02-24 20:24:33.310323: step 101210, total loss = 0.55, batch loss = 0.28 (235.3 examples/sec; 0.034 sec/batch; 0h:55m:41s remains)
INFO - root - 2022-02-24 20:24:33.599633: step 101220, total loss = 0.70, batch loss = 0.44 (355.3 examples/sec; 0.023 sec/batch; 0h:36m:53s remains)
INFO - root - 2022-02-24 20:24:34.078136: step 101230, total loss = 0.70, batch loss = 0.44 (341.2 examples/sec; 0.023 sec/batch; 0h:38m:23s remains)
INFO - root - 2022-02-24 20:24:34.501682: step 101240, total loss = 0.52, batch loss = 0.25 (122.0 examples/sec; 0.066 sec/batch; 1h:47m:23s remains)
INFO - root - 2022-02-24 20:24:34.785359: step 101250, total loss = 0.54, batch loss = 0.28 (260.7 examples/sec; 0.031 sec/batch; 0h:50m:15s remains)
INFO - root - 2022-02-24 20:24:35.157535: step 101260, total loss = 0.56, batch loss = 0.30 (333.3 examples/sec; 0.024 sec/batch; 0h:39m:18s remains)
INFO - root - 2022-02-24 20:24:35.493945: step 101270, total loss = 0.66, batch loss = 0.39 (211.8 examples/sec; 0.038 sec/batch; 1h:01m:50s remains)
INFO - root - 2022-02-24 20:24:35.864266: step 101280, total loss = 0.58, batch loss = 0.32 (349.5 examples/sec; 0.023 sec/batch; 0h:37m:28s remains)
INFO - root - 2022-02-24 20:24:36.348590: step 101290, total loss = 0.68, batch loss = 0.42 (293.9 examples/sec; 0.027 sec/batch; 0h:44m:33s remains)
INFO - root - 2022-02-24 20:24:36.671058: step 101300, total loss = 0.59, batch loss = 0.33 (307.8 examples/sec; 0.026 sec/batch; 0h:42m:32s remains)
INFO - root - 2022-02-24 20:24:37.237301: step 101310, total loss = 0.54, batch loss = 0.27 (296.1 examples/sec; 0.027 sec/batch; 0h:44m:12s remains)
INFO - root - 2022-02-24 20:24:37.595108: step 101320, total loss = 0.54, batch loss = 0.28 (141.6 examples/sec; 0.057 sec/batch; 1h:32m:28s remains)
INFO - root - 2022-02-24 20:24:38.045886: step 101330, total loss = 0.51, batch loss = 0.24 (181.4 examples/sec; 0.044 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 20:24:38.455163: step 101340, total loss = 0.57, batch loss = 0.31 (292.4 examples/sec; 0.027 sec/batch; 0h:44m:45s remains)
INFO - root - 2022-02-24 20:24:38.810570: step 101350, total loss = 0.55, batch loss = 0.29 (367.7 examples/sec; 0.022 sec/batch; 0h:35m:35s remains)
INFO - root - 2022-02-24 20:24:39.154482: step 101360, total loss = 0.51, batch loss = 0.25 (212.7 examples/sec; 0.038 sec/batch; 1h:01m:30s remains)
INFO - root - 2022-02-24 20:24:39.497328: step 101370, total loss = 0.55, batch loss = 0.29 (366.8 examples/sec; 0.022 sec/batch; 0h:35m:40s remains)
INFO - root - 2022-02-24 20:24:39.880767: step 101380, total loss = 0.51, batch loss = 0.24 (314.4 examples/sec; 0.025 sec/batch; 0h:41m:36s remains)
INFO - root - 2022-02-24 20:24:40.326752: step 101390, total loss = 0.61, batch loss = 0.34 (211.7 examples/sec; 0.038 sec/batch; 1h:01m:48s remains)
INFO - root - 2022-02-24 20:24:40.743056: step 101400, total loss = 0.52, batch loss = 0.26 (177.3 examples/sec; 0.045 sec/batch; 1h:13m:46s remains)
INFO - root - 2022-02-24 20:24:41.101441: step 101410, total loss = 0.55, batch loss = 0.29 (236.0 examples/sec; 0.034 sec/batch; 0h:55m:25s remains)
INFO - root - 2022-02-24 20:24:41.357568: step 101420, total loss = 0.56, batch loss = 0.29 (358.2 examples/sec; 0.022 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:24:41.706623: step 101430, total loss = 0.54, batch loss = 0.28 (378.2 examples/sec; 0.021 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:24:42.200707: step 101440, total loss = 0.58, batch loss = 0.31 (154.7 examples/sec; 0.052 sec/batch; 1h:24m:30s remains)
INFO - root - 2022-02-24 20:24:42.620679: step 101450, total loss = 0.55, batch loss = 0.29 (149.1 examples/sec; 0.054 sec/batch; 1h:27m:41s remains)
INFO - root - 2022-02-24 20:24:42.899901: step 101460, total loss = 0.53, batch loss = 0.27 (334.1 examples/sec; 0.024 sec/batch; 0h:39m:07s remains)
INFO - root - 2022-02-24 20:24:43.198858: step 101470, total loss = 0.49, batch loss = 0.22 (279.4 examples/sec; 0.029 sec/batch; 0h:46m:47s remains)
INFO - root - 2022-02-24 20:24:43.574566: step 101480, total loss = 0.59, batch loss = 0.33 (94.8 examples/sec; 0.084 sec/batch; 2h:17m:50s remains)
INFO - root - 2022-02-24 20:24:43.946031: step 101490, total loss = 0.58, batch loss = 0.32 (104.2 examples/sec; 0.077 sec/batch; 2h:05m:27s remains)
INFO - root - 2022-02-24 20:24:44.337000: step 101500, total loss = 0.56, batch loss = 0.30 (363.1 examples/sec; 0.022 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:24:44.838420: step 101510, total loss = 0.50, batch loss = 0.23 (333.4 examples/sec; 0.024 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 20:24:45.112525: step 101520, total loss = 0.54, batch loss = 0.28 (337.1 examples/sec; 0.024 sec/batch; 0h:38m:45s remains)
INFO - root - 2022-02-24 20:24:45.376277: step 101530, total loss = 0.65, batch loss = 0.38 (240.8 examples/sec; 0.033 sec/batch; 0h:54m:14s remains)
INFO - root - 2022-02-24 20:24:45.647368: step 101540, total loss = 0.48, batch loss = 0.22 (343.7 examples/sec; 0.023 sec/batch; 0h:37m:59s remains)
INFO - root - 2022-02-24 20:24:45.971520: step 101550, total loss = 0.54, batch loss = 0.28 (382.9 examples/sec; 0.021 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:24:46.365109: step 101560, total loss = 0.60, batch loss = 0.34 (161.2 examples/sec; 0.050 sec/batch; 1h:21m:01s remains)
INFO - root - 2022-02-24 20:24:46.733808: step 101570, total loss = 0.62, batch loss = 0.36 (161.6 examples/sec; 0.049 sec/batch; 1h:20m:46s remains)
INFO - root - 2022-02-24 20:24:47.576707: step 101580, total loss = 0.51, batch loss = 0.24 (300.9 examples/sec; 0.027 sec/batch; 0h:43m:23s remains)
INFO - root - 2022-02-24 20:24:48.128084: step 101590, total loss = 0.50, batch loss = 0.24 (110.5 examples/sec; 0.072 sec/batch; 1h:58m:11s remains)
INFO - root - 2022-02-24 20:24:48.653597: step 101600, total loss = 0.51, batch loss = 0.25 (337.6 examples/sec; 0.024 sec/batch; 0h:38m:40s remains)
INFO - root - 2022-02-24 20:24:49.193692: step 101610, total loss = 0.50, batch loss = 0.24 (295.3 examples/sec; 0.027 sec/batch; 0h:44m:11s remains)
INFO - root - 2022-02-24 20:24:49.515507: step 101620, total loss = 0.51, batch loss = 0.25 (253.8 examples/sec; 0.032 sec/batch; 0h:51m:25s remains)
INFO - root - 2022-02-24 20:24:49.865249: step 101630, total loss = 0.53, batch loss = 0.27 (248.7 examples/sec; 0.032 sec/batch; 0h:52m:28s remains)
INFO - root - 2022-02-24 20:24:50.217902: step 101640, total loss = 0.60, batch loss = 0.34 (221.6 examples/sec; 0.036 sec/batch; 0h:58m:53s remains)
INFO - root - 2022-02-24 20:24:50.551583: step 101650, total loss = 0.50, batch loss = 0.24 (332.7 examples/sec; 0.024 sec/batch; 0h:39m:12s remains)
INFO - root - 2022-02-24 20:24:50.870274: step 101660, total loss = 0.52, batch loss = 0.26 (355.5 examples/sec; 0.023 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:24:51.231448: step 101670, total loss = 0.57, batch loss = 0.31 (127.9 examples/sec; 0.063 sec/batch; 1h:41m:57s remains)
INFO - root - 2022-02-24 20:24:51.560690: step 101680, total loss = 0.60, batch loss = 0.34 (185.4 examples/sec; 0.043 sec/batch; 1h:10m:20s remains)
INFO - root - 2022-02-24 20:24:52.018409: step 101690, total loss = 0.53, batch loss = 0.27 (358.9 examples/sec; 0.022 sec/batch; 0h:36m:20s remains)
INFO - root - 2022-02-24 20:24:52.639712: step 101700, total loss = 0.54, batch loss = 0.27 (29.0 examples/sec; 0.276 sec/batch; 7h:29m:08s remains)
INFO - root - 2022-02-24 20:24:53.099372: step 101710, total loss = 0.55, batch loss = 0.28 (320.3 examples/sec; 0.025 sec/batch; 0h:40m:42s remains)
INFO - root - 2022-02-24 20:24:53.480290: step 101720, total loss = 0.47, batch loss = 0.21 (285.4 examples/sec; 0.028 sec/batch; 0h:45m:41s remains)
INFO - root - 2022-02-24 20:24:53.784089: step 101730, total loss = 0.55, batch loss = 0.28 (322.6 examples/sec; 0.025 sec/batch; 0h:40m:24s remains)
INFO - root - 2022-02-24 20:24:54.127491: step 101740, total loss = 0.60, batch loss = 0.34 (369.9 examples/sec; 0.022 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 20:24:54.471679: step 101750, total loss = 0.59, batch loss = 0.33 (349.1 examples/sec; 0.023 sec/batch; 0h:37m:19s remains)
INFO - root - 2022-02-24 20:24:54.830312: step 101760, total loss = 0.60, batch loss = 0.33 (119.2 examples/sec; 0.067 sec/batch; 1h:49m:20s remains)
INFO - root - 2022-02-24 20:24:55.211378: step 101770, total loss = 0.67, batch loss = 0.41 (376.5 examples/sec; 0.021 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:24:55.523390: step 101780, total loss = 0.57, batch loss = 0.31 (259.7 examples/sec; 0.031 sec/batch; 0h:50m:10s remains)
INFO - root - 2022-02-24 20:24:55.831308: step 101790, total loss = 0.57, batch loss = 0.31 (305.8 examples/sec; 0.026 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 20:24:56.112823: step 101800, total loss = 0.60, batch loss = 0.34 (235.3 examples/sec; 0.034 sec/batch; 0h:55m:22s remains)
INFO - root - 2022-02-24 20:24:56.546093: step 101810, total loss = 0.56, batch loss = 0.30 (365.6 examples/sec; 0.022 sec/batch; 0h:35m:37s remains)
INFO - root - 2022-02-24 20:24:56.956105: step 101820, total loss = 0.49, batch loss = 0.22 (176.3 examples/sec; 0.045 sec/batch; 1h:13m:52s remains)
INFO - root - 2022-02-24 20:24:57.353631: step 101830, total loss = 0.56, batch loss = 0.29 (224.9 examples/sec; 0.036 sec/batch; 0h:57m:54s remains)
INFO - root - 2022-02-24 20:24:57.775949: step 101840, total loss = 0.51, batch loss = 0.25 (168.1 examples/sec; 0.048 sec/batch; 1h:17m:27s remains)
INFO - root - 2022-02-24 20:24:58.046498: step 101850, total loss = 0.62, batch loss = 0.36 (286.6 examples/sec; 0.028 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:24:58.332056: step 101860, total loss = 0.57, batch loss = 0.30 (238.4 examples/sec; 0.034 sec/batch; 0h:54m:36s remains)
INFO - root - 2022-02-24 20:24:58.696425: step 101870, total loss = 0.62, batch loss = 0.35 (366.6 examples/sec; 0.022 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:24:59.025177: step 101880, total loss = 0.48, batch loss = 0.21 (206.5 examples/sec; 0.039 sec/batch; 1h:03m:02s remains)
INFO - root - 2022-02-24 20:24:59.466259: step 101890, total loss = 0.61, batch loss = 0.35 (363.2 examples/sec; 0.022 sec/batch; 0h:35m:50s remains)
INFO - root - 2022-02-24 20:24:59.768327: step 101900, total loss = 0.54, batch loss = 0.28 (251.7 examples/sec; 0.032 sec/batch; 0h:51m:42s remains)
INFO - root - 2022-02-24 20:25:00.142410: step 101910, total loss = 0.62, batch loss = 0.36 (298.8 examples/sec; 0.027 sec/batch; 0h:43m:33s remains)
INFO - root - 2022-02-24 20:25:00.383543: step 101920, total loss = 0.64, batch loss = 0.38 (346.6 examples/sec; 0.023 sec/batch; 0h:37m:32s remains)
INFO - root - 2022-02-24 20:25:00.745206: step 101930, total loss = 0.65, batch loss = 0.39 (196.8 examples/sec; 0.041 sec/batch; 1h:06m:05s remains)
INFO - root - 2022-02-24 20:25:01.220052: step 101940, total loss = 0.53, batch loss = 0.27 (122.1 examples/sec; 0.065 sec/batch; 1h:46m:29s remains)
INFO - root - 2022-02-24 20:25:01.582595: step 101950, total loss = 0.49, batch loss = 0.23 (156.5 examples/sec; 0.051 sec/batch; 1h:23m:07s remains)
INFO - root - 2022-02-24 20:25:01.910702: step 101960, total loss = 0.50, batch loss = 0.24 (181.9 examples/sec; 0.044 sec/batch; 1h:11m:30s remains)
INFO - root - 2022-02-24 20:25:02.198791: step 101970, total loss = 0.59, batch loss = 0.32 (344.8 examples/sec; 0.023 sec/batch; 0h:37m:42s remains)
INFO - root - 2022-02-24 20:25:02.525289: step 101980, total loss = 0.51, batch loss = 0.25 (317.0 examples/sec; 0.025 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:25:03.078846: step 101990, total loss = 0.63, batch loss = 0.37 (103.2 examples/sec; 0.078 sec/batch; 2h:06m:02s remains)
INFO - root - 2022-02-24 20:25:03.438003: step 102000, total loss = 0.55, batch loss = 0.29 (268.1 examples/sec; 0.030 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:25:03.841232: step 102010, total loss = 0.49, batch loss = 0.23 (153.8 examples/sec; 0.052 sec/batch; 1h:24m:31s remains)
INFO - root - 2022-02-24 20:25:04.132501: step 102020, total loss = 0.49, batch loss = 0.23 (316.1 examples/sec; 0.025 sec/batch; 0h:41m:06s remains)
INFO - root - 2022-02-24 20:25:04.411734: step 102030, total loss = 0.56, batch loss = 0.30 (355.9 examples/sec; 0.022 sec/batch; 0h:36m:31s remains)
INFO - root - 2022-02-24 20:25:04.874371: step 102040, total loss = 0.53, batch loss = 0.26 (328.3 examples/sec; 0.024 sec/batch; 0h:39m:34s remains)
INFO - root - 2022-02-24 20:25:05.219296: step 102050, total loss = 0.56, batch loss = 0.30 (160.2 examples/sec; 0.050 sec/batch; 1h:21m:05s remains)
INFO - root - 2022-02-24 20:25:05.510388: step 102060, total loss = 0.50, batch loss = 0.24 (369.5 examples/sec; 0.022 sec/batch; 0h:35m:09s remains)
INFO - root - 2022-02-24 20:25:05.840656: step 102070, total loss = 0.55, batch loss = 0.29 (341.5 examples/sec; 0.023 sec/batch; 0h:38m:02s remains)
INFO - root - 2022-02-24 20:25:06.182148: step 102080, total loss = 0.45, batch loss = 0.19 (159.2 examples/sec; 0.050 sec/batch; 1h:21m:34s remains)
INFO - root - 2022-02-24 20:25:06.455376: step 102090, total loss = 0.54, batch loss = 0.27 (338.7 examples/sec; 0.024 sec/batch; 0h:38m:20s remains)
INFO - root - 2022-02-24 20:25:06.784079: step 102100, total loss = 0.60, batch loss = 0.34 (148.3 examples/sec; 0.054 sec/batch; 1h:27m:34s remains)
INFO - root - 2022-02-24 20:25:07.212487: step 102110, total loss = 0.61, batch loss = 0.35 (158.4 examples/sec; 0.051 sec/batch; 1h:21m:59s remains)
INFO - root - 2022-02-24 20:25:07.552453: step 102120, total loss = 0.58, batch loss = 0.32 (219.8 examples/sec; 0.036 sec/batch; 0h:59m:04s remains)
INFO - root - 2022-02-24 20:25:07.935386: step 102130, total loss = 0.55, batch loss = 0.28 (312.8 examples/sec; 0.026 sec/batch; 0h:41m:29s remains)
INFO - root - 2022-02-24 20:25:08.233701: step 102140, total loss = 0.53, batch loss = 0.27 (391.5 examples/sec; 0.020 sec/batch; 0h:33m:09s remains)
INFO - root - 2022-02-24 20:25:08.569361: step 102150, total loss = 0.62, batch loss = 0.35 (318.1 examples/sec; 0.025 sec/batch; 0h:40m:48s remains)
INFO - root - 2022-02-24 20:25:08.911097: step 102160, total loss = 0.67, batch loss = 0.41 (108.6 examples/sec; 0.074 sec/batch; 1h:59m:33s remains)
INFO - root - 2022-02-24 20:25:09.304120: step 102170, total loss = 0.53, batch loss = 0.26 (379.8 examples/sec; 0.021 sec/batch; 0h:34m:10s remains)
INFO - root - 2022-02-24 20:25:09.759851: step 102180, total loss = 0.47, batch loss = 0.20 (351.3 examples/sec; 0.023 sec/batch; 0h:36m:56s remains)
INFO - root - 2022-02-24 20:25:10.105808: step 102190, total loss = 0.66, batch loss = 0.40 (366.8 examples/sec; 0.022 sec/batch; 0h:35m:22s remains)
INFO - root - 2022-02-24 20:25:10.487286: step 102200, total loss = 0.45, batch loss = 0.19 (358.3 examples/sec; 0.022 sec/batch; 0h:36m:12s remains)
INFO - root - 2022-02-24 20:25:10.857240: step 102210, total loss = 0.50, batch loss = 0.24 (359.3 examples/sec; 0.022 sec/batch; 0h:36m:06s remains)
INFO - root - 2022-02-24 20:25:11.277157: step 102220, total loss = 0.52, batch loss = 0.26 (102.5 examples/sec; 0.078 sec/batch; 2h:06m:29s remains)
INFO - root - 2022-02-24 20:25:11.649852: step 102230, total loss = 0.58, batch loss = 0.32 (386.6 examples/sec; 0.021 sec/batch; 0h:33m:32s remains)
INFO - root - 2022-02-24 20:25:12.203990: step 102240, total loss = 0.53, batch loss = 0.27 (290.4 examples/sec; 0.028 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 20:25:12.636128: step 102250, total loss = 0.63, batch loss = 0.37 (353.4 examples/sec; 0.023 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:25:13.488040: step 102260, total loss = 0.57, batch loss = 0.31 (315.0 examples/sec; 0.025 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:25:13.936199: step 102270, total loss = 0.71, batch loss = 0.45 (178.4 examples/sec; 0.045 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 20:25:14.424961: step 102280, total loss = 0.57, batch loss = 0.31 (311.1 examples/sec; 0.026 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:25:14.814698: step 102290, total loss = 0.56, batch loss = 0.30 (310.4 examples/sec; 0.026 sec/batch; 0h:41m:45s remains)
INFO - root - 2022-02-24 20:25:15.254539: step 102300, total loss = 0.60, batch loss = 0.33 (162.0 examples/sec; 0.049 sec/batch; 1h:19m:59s remains)
INFO - root - 2022-02-24 20:25:15.749116: step 102310, total loss = 0.57, batch loss = 0.31 (259.1 examples/sec; 0.031 sec/batch; 0h:50m:01s remains)
INFO - root - 2022-02-24 20:25:16.193851: step 102320, total loss = 0.55, batch loss = 0.29 (191.2 examples/sec; 0.042 sec/batch; 1h:07m:45s remains)
INFO - root - 2022-02-24 20:25:16.523372: step 102330, total loss = 0.52, batch loss = 0.25 (159.5 examples/sec; 0.050 sec/batch; 1h:21m:15s remains)
INFO - root - 2022-02-24 20:25:16.916514: step 102340, total loss = 0.57, batch loss = 0.31 (105.2 examples/sec; 0.076 sec/batch; 2h:03m:05s remains)
INFO - root - 2022-02-24 20:25:17.253215: step 102350, total loss = 0.55, batch loss = 0.28 (329.5 examples/sec; 0.024 sec/batch; 0h:39m:18s remains)
INFO - root - 2022-02-24 20:25:17.639634: step 102360, total loss = 0.48, batch loss = 0.22 (316.2 examples/sec; 0.025 sec/batch; 0h:40m:58s remains)
INFO - root - 2022-02-24 20:25:18.146967: step 102370, total loss = 0.61, batch loss = 0.35 (136.6 examples/sec; 0.059 sec/batch; 1h:34m:48s remains)
INFO - root - 2022-02-24 20:25:18.498755: step 102380, total loss = 0.58, batch loss = 0.32 (115.9 examples/sec; 0.069 sec/batch; 1h:51m:43s remains)
INFO - root - 2022-02-24 20:25:18.790979: step 102390, total loss = 0.54, batch loss = 0.28 (270.5 examples/sec; 0.030 sec/batch; 0h:47m:51s remains)
INFO - root - 2022-02-24 20:25:19.143316: step 102400, total loss = 0.55, batch loss = 0.28 (154.8 examples/sec; 0.052 sec/batch; 1h:23m:39s remains)
INFO - root - 2022-02-24 20:25:19.598188: step 102410, total loss = 0.54, batch loss = 0.28 (314.8 examples/sec; 0.025 sec/batch; 0h:41m:07s remains)
INFO - root - 2022-02-24 20:25:20.027394: step 102420, total loss = 0.53, batch loss = 0.27 (298.6 examples/sec; 0.027 sec/batch; 0h:43m:20s remains)
INFO - root - 2022-02-24 20:25:20.343465: step 102430, total loss = 0.67, batch loss = 0.41 (270.5 examples/sec; 0.030 sec/batch; 0h:47m:51s remains)
INFO - root - 2022-02-24 20:25:20.635814: step 102440, total loss = 0.72, batch loss = 0.46 (333.4 examples/sec; 0.024 sec/batch; 0h:38m:49s remains)
INFO - root - 2022-02-24 20:25:20.916433: step 102450, total loss = 0.49, batch loss = 0.22 (231.6 examples/sec; 0.035 sec/batch; 0h:55m:52s remains)
INFO - root - 2022-02-24 20:25:21.231528: step 102460, total loss = 0.47, batch loss = 0.21 (181.3 examples/sec; 0.044 sec/batch; 1h:11m:22s remains)
INFO - root - 2022-02-24 20:25:21.567235: step 102470, total loss = 0.49, batch loss = 0.23 (132.5 examples/sec; 0.060 sec/batch; 1h:37m:36s remains)
INFO - root - 2022-02-24 20:25:21.859993: step 102480, total loss = 0.61, batch loss = 0.35 (344.1 examples/sec; 0.023 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:25:22.283734: step 102490, total loss = 0.49, batch loss = 0.22 (369.5 examples/sec; 0.022 sec/batch; 0h:35m:00s remains)
INFO - root - 2022-02-24 20:25:22.611001: step 102500, total loss = 0.46, batch loss = 0.20 (319.9 examples/sec; 0.025 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:25:23.071293: step 102510, total loss = 0.58, batch loss = 0.31 (212.9 examples/sec; 0.038 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:25:23.427982: step 102520, total loss = 0.63, batch loss = 0.36 (279.7 examples/sec; 0.029 sec/batch; 0h:46m:13s remains)
INFO - root - 2022-02-24 20:25:23.766799: step 102530, total loss = 0.52, batch loss = 0.26 (160.8 examples/sec; 0.050 sec/batch; 1h:20m:23s remains)
INFO - root - 2022-02-24 20:25:24.058516: step 102540, total loss = 0.57, batch loss = 0.30 (298.7 examples/sec; 0.027 sec/batch; 0h:43m:16s remains)
INFO - root - 2022-02-24 20:25:24.380116: step 102550, total loss = 0.66, batch loss = 0.39 (348.8 examples/sec; 0.023 sec/batch; 0h:37m:03s remains)
INFO - root - 2022-02-24 20:25:24.714393: step 102560, total loss = 0.63, batch loss = 0.36 (352.3 examples/sec; 0.023 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:25:25.086367: step 102570, total loss = 0.57, batch loss = 0.31 (352.1 examples/sec; 0.023 sec/batch; 0h:36m:42s remains)
INFO - root - 2022-02-24 20:25:25.542485: step 102580, total loss = 0.64, batch loss = 0.38 (292.4 examples/sec; 0.027 sec/batch; 0h:44m:11s remains)
INFO - root - 2022-02-24 20:25:25.867578: step 102590, total loss = 0.54, batch loss = 0.28 (163.9 examples/sec; 0.049 sec/batch; 1h:18m:51s remains)
INFO - root - 2022-02-24 20:25:26.156901: step 102600, total loss = 0.67, batch loss = 0.40 (320.0 examples/sec; 0.025 sec/batch; 0h:40m:22s remains)
INFO - root - 2022-02-24 20:25:26.527984: step 102610, total loss = 0.53, batch loss = 0.27 (300.3 examples/sec; 0.027 sec/batch; 0h:43m:00s remains)
INFO - root - 2022-02-24 20:25:26.784173: step 102620, total loss = 0.45, batch loss = 0.19 (315.9 examples/sec; 0.025 sec/batch; 0h:40m:53s remains)
INFO - root - 2022-02-24 20:25:27.113114: step 102630, total loss = 0.68, batch loss = 0.42 (231.7 examples/sec; 0.035 sec/batch; 0h:55m:45s remains)
INFO - root - 2022-02-24 20:25:27.421245: step 102640, total loss = 0.48, batch loss = 0.22 (343.8 examples/sec; 0.023 sec/batch; 0h:37m:34s remains)
INFO - root - 2022-02-24 20:25:27.778632: step 102650, total loss = 0.57, batch loss = 0.31 (210.3 examples/sec; 0.038 sec/batch; 1h:01m:24s remains)
INFO - root - 2022-02-24 20:25:28.150017: step 102660, total loss = 0.53, batch loss = 0.27 (329.3 examples/sec; 0.024 sec/batch; 0h:39m:12s remains)
INFO - root - 2022-02-24 20:25:28.501688: step 102670, total loss = 0.59, batch loss = 0.33 (327.6 examples/sec; 0.024 sec/batch; 0h:39m:24s remains)
INFO - root - 2022-02-24 20:25:28.769632: step 102680, total loss = 0.60, batch loss = 0.34 (338.8 examples/sec; 0.024 sec/batch; 0h:38m:06s remains)
INFO - root - 2022-02-24 20:25:29.121267: step 102690, total loss = 0.56, batch loss = 0.30 (170.1 examples/sec; 0.047 sec/batch; 1h:15m:54s remains)
INFO - root - 2022-02-24 20:25:29.509242: step 102700, total loss = 0.55, batch loss = 0.28 (195.7 examples/sec; 0.041 sec/batch; 1h:05m:57s remains)
INFO - root - 2022-02-24 20:25:30.109474: step 102710, total loss = 0.53, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 4h:15m:49s remains)
INFO - root - 2022-02-24 20:25:30.520796: step 102720, total loss = 0.51, batch loss = 0.24 (89.4 examples/sec; 0.089 sec/batch; 2h:24m:19s remains)
INFO - root - 2022-02-24 20:25:31.205666: step 102730, total loss = 0.60, batch loss = 0.33 (301.6 examples/sec; 0.027 sec/batch; 0h:42m:46s remains)
INFO - root - 2022-02-24 20:25:31.773446: step 102740, total loss = 0.57, batch loss = 0.30 (138.8 examples/sec; 0.058 sec/batch; 1h:32m:58s remains)
INFO - root - 2022-02-24 20:25:32.261841: step 102750, total loss = 0.52, batch loss = 0.26 (196.5 examples/sec; 0.041 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 20:25:32.629569: step 102760, total loss = 0.64, batch loss = 0.38 (329.3 examples/sec; 0.024 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 20:25:33.361960: step 102770, total loss = 0.60, batch loss = 0.33 (18.5 examples/sec; 0.433 sec/batch; 11h:37m:22s remains)
INFO - root - 2022-02-24 20:25:33.807940: step 102780, total loss = 0.68, batch loss = 0.41 (102.9 examples/sec; 0.078 sec/batch; 2h:05m:17s remains)
INFO - root - 2022-02-24 20:25:34.227910: step 102790, total loss = 0.50, batch loss = 0.24 (232.0 examples/sec; 0.034 sec/batch; 0h:55m:34s remains)
INFO - root - 2022-02-24 20:25:34.501581: step 102800, total loss = 0.52, batch loss = 0.25 (346.5 examples/sec; 0.023 sec/batch; 0h:37m:12s remains)
INFO - root - 2022-02-24 20:25:34.861368: step 102810, total loss = 0.50, batch loss = 0.24 (333.1 examples/sec; 0.024 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:25:35.137197: step 102820, total loss = 0.52, batch loss = 0.26 (367.9 examples/sec; 0.022 sec/batch; 0h:35m:02s remains)
INFO - root - 2022-02-24 20:25:35.426909: step 102830, total loss = 0.53, batch loss = 0.27 (236.8 examples/sec; 0.034 sec/batch; 0h:54m:25s remains)
INFO - root - 2022-02-24 20:25:35.778503: step 102840, total loss = 0.49, batch loss = 0.23 (329.1 examples/sec; 0.024 sec/batch; 0h:39m:09s remains)
INFO - root - 2022-02-24 20:25:36.191319: step 102850, total loss = 0.59, batch loss = 0.33 (244.9 examples/sec; 0.033 sec/batch; 0h:52m:37s remains)
INFO - root - 2022-02-24 20:25:36.585408: step 102860, total loss = 0.49, batch loss = 0.22 (293.1 examples/sec; 0.027 sec/batch; 0h:43m:58s remains)
INFO - root - 2022-02-24 20:25:36.900028: step 102870, total loss = 0.50, batch loss = 0.24 (235.6 examples/sec; 0.034 sec/batch; 0h:54m:40s remains)
INFO - root - 2022-02-24 20:25:37.252113: step 102880, total loss = 0.48, batch loss = 0.22 (163.0 examples/sec; 0.049 sec/batch; 1h:19m:02s remains)
INFO - root - 2022-02-24 20:25:37.716454: step 102890, total loss = 0.55, batch loss = 0.29 (126.2 examples/sec; 0.063 sec/batch; 1h:42m:03s remains)
INFO - root - 2022-02-24 20:25:38.112014: step 102900, total loss = 0.52, batch loss = 0.25 (187.3 examples/sec; 0.043 sec/batch; 1h:08m:46s remains)
INFO - root - 2022-02-24 20:25:38.536793: step 102910, total loss = 0.62, batch loss = 0.36 (346.5 examples/sec; 0.023 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:25:38.937056: step 102920, total loss = 0.51, batch loss = 0.25 (335.5 examples/sec; 0.024 sec/batch; 0h:38m:23s remains)
INFO - root - 2022-02-24 20:25:39.217919: step 102930, total loss = 0.62, batch loss = 0.36 (340.7 examples/sec; 0.023 sec/batch; 0h:37m:47s remains)
INFO - root - 2022-02-24 20:25:39.567304: step 102940, total loss = 0.52, batch loss = 0.25 (372.6 examples/sec; 0.021 sec/batch; 0h:34m:33s remains)
INFO - root - 2022-02-24 20:25:39.962785: step 102950, total loss = 0.50, batch loss = 0.23 (208.0 examples/sec; 0.038 sec/batch; 1h:01m:54s remains)
INFO - root - 2022-02-24 20:25:40.374272: step 102960, total loss = 0.58, batch loss = 0.31 (197.8 examples/sec; 0.040 sec/batch; 1h:05m:04s remains)
INFO - root - 2022-02-24 20:25:40.652544: step 102970, total loss = 0.58, batch loss = 0.32 (370.9 examples/sec; 0.022 sec/batch; 0h:34m:42s remains)
INFO - root - 2022-02-24 20:25:40.970319: step 102980, total loss = 0.68, batch loss = 0.41 (339.8 examples/sec; 0.024 sec/batch; 0h:37m:52s remains)
INFO - root - 2022-02-24 20:25:41.295904: step 102990, total loss = 0.49, batch loss = 0.23 (182.3 examples/sec; 0.044 sec/batch; 1h:10m:36s remains)
INFO - root - 2022-02-24 20:25:41.564600: step 103000, total loss = 0.49, batch loss = 0.23 (195.7 examples/sec; 0.041 sec/batch; 1h:05m:45s remains)
INFO - root - 2022-02-24 20:25:42.039496: step 103010, total loss = 0.54, batch loss = 0.27 (323.1 examples/sec; 0.025 sec/batch; 0h:39m:49s remains)
INFO - root - 2022-02-24 20:25:42.482418: step 103020, total loss = 0.59, batch loss = 0.33 (156.2 examples/sec; 0.051 sec/batch; 1h:22m:22s remains)
INFO - root - 2022-02-24 20:25:42.746715: step 103030, total loss = 0.66, batch loss = 0.40 (175.9 examples/sec; 0.045 sec/batch; 1h:13m:06s remains)
INFO - root - 2022-02-24 20:25:43.033779: step 103040, total loss = 0.60, batch loss = 0.34 (339.7 examples/sec; 0.024 sec/batch; 0h:37m:51s remains)
INFO - root - 2022-02-24 20:25:43.319030: step 103050, total loss = 0.60, batch loss = 0.33 (238.0 examples/sec; 0.034 sec/batch; 0h:54m:02s remains)
INFO - root - 2022-02-24 20:25:43.710034: step 103060, total loss = 0.54, batch loss = 0.28 (150.4 examples/sec; 0.053 sec/batch; 1h:25m:28s remains)
INFO - root - 2022-02-24 20:25:44.141724: step 103070, total loss = 0.59, batch loss = 0.32 (128.8 examples/sec; 0.062 sec/batch; 1h:39m:49s remains)
INFO - root - 2022-02-24 20:25:44.554563: step 103080, total loss = 0.71, batch loss = 0.44 (325.9 examples/sec; 0.025 sec/batch; 0h:39m:27s remains)
INFO - root - 2022-02-24 20:25:44.856931: step 103090, total loss = 0.64, batch loss = 0.37 (171.1 examples/sec; 0.047 sec/batch; 1h:15m:07s remains)
INFO - root - 2022-02-24 20:25:45.138934: step 103100, total loss = 0.65, batch loss = 0.39 (304.4 examples/sec; 0.026 sec/batch; 0h:42m:13s remains)
INFO - root - 2022-02-24 20:25:45.524085: step 103110, total loss = 0.55, batch loss = 0.28 (251.7 examples/sec; 0.032 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:25:45.837393: step 103120, total loss = 0.59, batch loss = 0.33 (266.4 examples/sec; 0.030 sec/batch; 0h:48m:13s remains)
INFO - root - 2022-02-24 20:25:46.196270: step 103130, total loss = 0.59, batch loss = 0.33 (220.7 examples/sec; 0.036 sec/batch; 0h:58m:13s remains)
INFO - root - 2022-02-24 20:25:46.614911: step 103140, total loss = 0.52, batch loss = 0.25 (326.1 examples/sec; 0.025 sec/batch; 0h:39m:24s remains)
INFO - root - 2022-02-24 20:25:47.082407: step 103150, total loss = 0.49, batch loss = 0.23 (352.1 examples/sec; 0.023 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:25:47.572317: step 103160, total loss = 0.59, batch loss = 0.33 (108.1 examples/sec; 0.074 sec/batch; 1h:58m:52s remains)
INFO - root - 2022-02-24 20:25:48.126729: step 103170, total loss = 0.72, batch loss = 0.46 (150.8 examples/sec; 0.053 sec/batch; 1h:25m:11s remains)
INFO - root - 2022-02-24 20:25:49.050098: step 103180, total loss = 0.60, batch loss = 0.34 (264.5 examples/sec; 0.030 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:25:49.353715: step 103190, total loss = 0.52, batch loss = 0.25 (353.4 examples/sec; 0.023 sec/batch; 0h:36m:20s remains)
INFO - root - 2022-02-24 20:25:49.676503: step 103200, total loss = 0.52, batch loss = 0.26 (157.6 examples/sec; 0.051 sec/batch; 1h:21m:28s remains)
INFO - root - 2022-02-24 20:25:50.132005: step 103210, total loss = 0.55, batch loss = 0.28 (142.4 examples/sec; 0.056 sec/batch; 1h:30m:09s remains)
INFO - root - 2022-02-24 20:25:50.445686: step 103220, total loss = 0.63, batch loss = 0.37 (345.2 examples/sec; 0.023 sec/batch; 0h:37m:11s remains)
INFO - root - 2022-02-24 20:25:50.716999: step 103230, total loss = 0.57, batch loss = 0.31 (261.3 examples/sec; 0.031 sec/batch; 0h:49m:07s remains)
INFO - root - 2022-02-24 20:25:51.028173: step 103240, total loss = 0.48, batch loss = 0.22 (266.4 examples/sec; 0.030 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:25:51.373536: step 103250, total loss = 0.62, batch loss = 0.36 (176.3 examples/sec; 0.045 sec/batch; 1h:12m:48s remains)
INFO - root - 2022-02-24 20:25:51.788126: step 103260, total loss = 0.60, batch loss = 0.34 (124.2 examples/sec; 0.064 sec/batch; 1h:43m:19s remains)
INFO - root - 2022-02-24 20:25:52.163981: step 103270, total loss = 0.58, batch loss = 0.32 (242.0 examples/sec; 0.033 sec/batch; 0h:53m:01s remains)
INFO - root - 2022-02-24 20:25:52.531632: step 103280, total loss = 0.59, batch loss = 0.32 (304.7 examples/sec; 0.026 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:25:52.835714: step 103290, total loss = 0.53, batch loss = 0.27 (373.5 examples/sec; 0.021 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:25:53.212836: step 103300, total loss = 0.53, batch loss = 0.26 (179.4 examples/sec; 0.045 sec/batch; 1h:11m:28s remains)
INFO - root - 2022-02-24 20:25:53.580150: step 103310, total loss = 0.46, batch loss = 0.20 (326.7 examples/sec; 0.024 sec/batch; 0h:39m:15s remains)
INFO - root - 2022-02-24 20:25:53.961234: step 103320, total loss = 0.57, batch loss = 0.30 (250.1 examples/sec; 0.032 sec/batch; 0h:51m:16s remains)
INFO - root - 2022-02-24 20:25:54.361667: step 103330, total loss = 0.50, batch loss = 0.24 (314.4 examples/sec; 0.025 sec/batch; 0h:40m:47s remains)
INFO - root - 2022-02-24 20:25:54.654581: step 103340, total loss = 0.70, batch loss = 0.44 (254.9 examples/sec; 0.031 sec/batch; 0h:50m:18s remains)
INFO - root - 2022-02-24 20:25:54.977603: step 103350, total loss = 0.57, batch loss = 0.31 (175.8 examples/sec; 0.046 sec/batch; 1h:12m:56s remains)
INFO - root - 2022-02-24 20:25:55.247615: step 103360, total loss = 0.56, batch loss = 0.30 (328.0 examples/sec; 0.024 sec/batch; 0h:39m:04s remains)
INFO - root - 2022-02-24 20:25:55.596893: step 103370, total loss = 0.54, batch loss = 0.28 (159.2 examples/sec; 0.050 sec/batch; 1h:20m:31s remains)
INFO - root - 2022-02-24 20:25:55.997287: step 103380, total loss = 0.59, batch loss = 0.33 (178.3 examples/sec; 0.045 sec/batch; 1h:11m:53s remains)
INFO - root - 2022-02-24 20:25:56.455109: step 103390, total loss = 0.50, batch loss = 0.23 (210.4 examples/sec; 0.038 sec/batch; 1h:00m:54s remains)
INFO - root - 2022-02-24 20:25:56.753916: step 103400, total loss = 0.55, batch loss = 0.29 (333.7 examples/sec; 0.024 sec/batch; 0h:38m:24s remains)
INFO - root - 2022-02-24 20:25:57.091633: step 103410, total loss = 0.61, batch loss = 0.34 (328.9 examples/sec; 0.024 sec/batch; 0h:38m:57s remains)
INFO - root - 2022-02-24 20:25:57.335686: step 103420, total loss = 0.49, batch loss = 0.23 (352.0 examples/sec; 0.023 sec/batch; 0h:36m:23s remains)
INFO - root - 2022-02-24 20:25:57.686787: step 103430, total loss = 0.52, batch loss = 0.25 (141.2 examples/sec; 0.057 sec/batch; 1h:30m:44s remains)
INFO - root - 2022-02-24 20:25:58.079260: step 103440, total loss = 0.63, batch loss = 0.37 (186.4 examples/sec; 0.043 sec/batch; 1h:08m:42s remains)
INFO - root - 2022-02-24 20:25:58.439349: step 103450, total loss = 0.53, batch loss = 0.27 (135.3 examples/sec; 0.059 sec/batch; 1h:34m:37s remains)
INFO - root - 2022-02-24 20:25:58.788348: step 103460, total loss = 0.54, batch loss = 0.27 (171.5 examples/sec; 0.047 sec/batch; 1h:14m:40s remains)
INFO - root - 2022-02-24 20:25:59.148995: step 103470, total loss = 0.52, batch loss = 0.25 (218.4 examples/sec; 0.037 sec/batch; 0h:58m:37s remains)
INFO - root - 2022-02-24 20:25:59.539675: step 103480, total loss = 0.58, batch loss = 0.32 (203.5 examples/sec; 0.039 sec/batch; 1h:02m:54s remains)
INFO - root - 2022-02-24 20:25:59.872726: step 103490, total loss = 0.51, batch loss = 0.25 (260.0 examples/sec; 0.031 sec/batch; 0h:49m:14s remains)
INFO - root - 2022-02-24 20:26:00.369637: step 103500, total loss = 0.80, batch loss = 0.54 (172.0 examples/sec; 0.047 sec/batch; 1h:14m:25s remains)
INFO - root - 2022-02-24 20:26:00.751069: step 103510, total loss = 0.55, batch loss = 0.28 (308.8 examples/sec; 0.026 sec/batch; 0h:41m:27s remains)
INFO - root - 2022-02-24 20:26:01.089580: step 103520, total loss = 0.53, batch loss = 0.27 (276.2 examples/sec; 0.029 sec/batch; 0h:46m:19s remains)
INFO - root - 2022-02-24 20:26:01.371049: step 103530, total loss = 0.51, batch loss = 0.24 (343.3 examples/sec; 0.023 sec/batch; 0h:37m:16s remains)
INFO - root - 2022-02-24 20:26:01.686889: step 103540, total loss = 0.56, batch loss = 0.30 (206.7 examples/sec; 0.039 sec/batch; 1h:01m:54s remains)
INFO - root - 2022-02-24 20:26:02.054640: step 103550, total loss = 0.68, batch loss = 0.42 (286.6 examples/sec; 0.028 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:26:02.383639: step 103560, total loss = 0.62, batch loss = 0.36 (356.8 examples/sec; 0.022 sec/batch; 0h:35m:51s remains)
INFO - root - 2022-02-24 20:26:02.665359: step 103570, total loss = 0.70, batch loss = 0.43 (336.6 examples/sec; 0.024 sec/batch; 0h:37m:59s remains)
INFO - root - 2022-02-24 20:26:03.051808: step 103580, total loss = 0.54, batch loss = 0.28 (247.9 examples/sec; 0.032 sec/batch; 0h:51m:35s remains)
INFO - root - 2022-02-24 20:26:03.490198: step 103590, total loss = 0.56, batch loss = 0.30 (140.6 examples/sec; 0.057 sec/batch; 1h:30m:57s remains)
INFO - root - 2022-02-24 20:26:04.061484: step 103600, total loss = 0.52, batch loss = 0.26 (275.9 examples/sec; 0.029 sec/batch; 0h:46m:20s remains)
INFO - root - 2022-02-24 20:26:05.007700: step 103610, total loss = 0.64, batch loss = 0.37 (310.1 examples/sec; 0.026 sec/batch; 0h:41m:13s remains)
INFO - root - 2022-02-24 20:26:05.391515: step 103620, total loss = 0.58, batch loss = 0.32 (329.8 examples/sec; 0.024 sec/batch; 0h:38m:45s remains)
INFO - root - 2022-02-24 20:26:05.778285: step 103630, total loss = 0.56, batch loss = 0.30 (301.8 examples/sec; 0.027 sec/batch; 0h:42m:21s remains)
INFO - root - 2022-02-24 20:26:06.245108: step 103640, total loss = 0.59, batch loss = 0.32 (166.4 examples/sec; 0.048 sec/batch; 1h:16m:49s remains)
INFO - root - 2022-02-24 20:26:06.658286: step 103650, total loss = 0.55, batch loss = 0.28 (120.4 examples/sec; 0.066 sec/batch; 1h:46m:08s remains)
INFO - root - 2022-02-24 20:26:07.088525: step 103660, total loss = 0.46, batch loss = 0.20 (289.4 examples/sec; 0.028 sec/batch; 0h:44m:09s remains)
INFO - root - 2022-02-24 20:26:07.444327: step 103670, total loss = 0.63, batch loss = 0.37 (283.0 examples/sec; 0.028 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:26:07.783484: step 103680, total loss = 0.50, batch loss = 0.24 (316.4 examples/sec; 0.025 sec/batch; 0h:40m:23s remains)
INFO - root - 2022-02-24 20:26:08.122589: step 103690, total loss = 0.52, batch loss = 0.26 (244.4 examples/sec; 0.033 sec/batch; 0h:52m:16s remains)
INFO - root - 2022-02-24 20:26:08.524750: step 103700, total loss = 0.60, batch loss = 0.34 (307.4 examples/sec; 0.026 sec/batch; 0h:41m:33s remains)
INFO - root - 2022-02-24 20:26:08.958871: step 103710, total loss = 0.55, batch loss = 0.28 (252.6 examples/sec; 0.032 sec/batch; 0h:50m:33s remains)
INFO - root - 2022-02-24 20:26:09.404716: step 103720, total loss = 0.53, batch loss = 0.26 (211.4 examples/sec; 0.038 sec/batch; 1h:00m:25s remains)
INFO - root - 2022-02-24 20:26:09.802383: step 103730, total loss = 0.52, batch loss = 0.26 (328.1 examples/sec; 0.024 sec/batch; 0h:38m:55s remains)
INFO - root - 2022-02-24 20:26:10.096918: step 103740, total loss = 0.46, batch loss = 0.20 (347.4 examples/sec; 0.023 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:26:10.377519: step 103750, total loss = 0.56, batch loss = 0.29 (335.2 examples/sec; 0.024 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:26:10.769531: step 103760, total loss = 0.48, batch loss = 0.22 (284.1 examples/sec; 0.028 sec/batch; 0h:44m:56s remains)
INFO - root - 2022-02-24 20:26:11.106726: step 103770, total loss = 0.50, batch loss = 0.24 (306.9 examples/sec; 0.026 sec/batch; 0h:41m:35s remains)
INFO - root - 2022-02-24 20:26:11.423574: step 103780, total loss = 0.63, batch loss = 0.37 (356.9 examples/sec; 0.022 sec/batch; 0h:35m:45s remains)
INFO - root - 2022-02-24 20:26:11.737131: step 103790, total loss = 0.57, batch loss = 0.31 (349.6 examples/sec; 0.023 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:26:12.038788: step 103800, total loss = 0.56, batch loss = 0.29 (178.5 examples/sec; 0.045 sec/batch; 1h:11m:29s remains)
INFO - root - 2022-02-24 20:26:12.497542: step 103810, total loss = 0.55, batch loss = 0.29 (148.4 examples/sec; 0.054 sec/batch; 1h:25m:57s remains)
INFO - root - 2022-02-24 20:26:12.844826: step 103820, total loss = 0.50, batch loss = 0.24 (229.4 examples/sec; 0.035 sec/batch; 0h:55m:37s remains)
INFO - root - 2022-02-24 20:26:13.249138: step 103830, total loss = 0.48, batch loss = 0.21 (186.4 examples/sec; 0.043 sec/batch; 1h:08m:25s remains)
INFO - root - 2022-02-24 20:26:13.540808: step 103840, total loss = 0.58, batch loss = 0.32 (358.7 examples/sec; 0.022 sec/batch; 0h:35m:33s remains)
INFO - root - 2022-02-24 20:26:13.825822: step 103850, total loss = 0.57, batch loss = 0.31 (314.7 examples/sec; 0.025 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:26:14.193431: step 103860, total loss = 0.62, batch loss = 0.36 (318.0 examples/sec; 0.025 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:26:14.576840: step 103870, total loss = 0.46, batch loss = 0.20 (328.6 examples/sec; 0.024 sec/batch; 0h:38m:48s remains)
INFO - root - 2022-02-24 20:26:14.955107: step 103880, total loss = 0.55, batch loss = 0.29 (146.1 examples/sec; 0.055 sec/batch; 1h:27m:17s remains)
INFO - root - 2022-02-24 20:26:15.349257: step 103890, total loss = 0.66, batch loss = 0.39 (197.6 examples/sec; 0.040 sec/batch; 1h:04m:30s remains)
INFO - root - 2022-02-24 20:26:15.649323: step 103900, total loss = 0.55, batch loss = 0.28 (349.4 examples/sec; 0.023 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:26:16.059906: step 103910, total loss = 0.47, batch loss = 0.20 (319.5 examples/sec; 0.025 sec/batch; 0h:39m:53s remains)
INFO - root - 2022-02-24 20:26:16.342508: step 103920, total loss = 0.50, batch loss = 0.24 (350.4 examples/sec; 0.023 sec/batch; 0h:36m:22s remains)
INFO - root - 2022-02-24 20:26:16.633236: step 103930, total loss = 0.50, batch loss = 0.24 (366.1 examples/sec; 0.022 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:26:17.001596: step 103940, total loss = 0.57, batch loss = 0.31 (212.0 examples/sec; 0.038 sec/batch; 1h:00m:06s remains)
INFO - root - 2022-02-24 20:26:17.443129: step 103950, total loss = 0.54, batch loss = 0.27 (291.0 examples/sec; 0.027 sec/batch; 0h:43m:46s remains)
INFO - root - 2022-02-24 20:26:17.819690: step 103960, total loss = 0.66, batch loss = 0.39 (151.5 examples/sec; 0.053 sec/batch; 1h:24m:04s remains)
INFO - root - 2022-02-24 20:26:18.108415: step 103970, total loss = 0.54, batch loss = 0.27 (293.3 examples/sec; 0.027 sec/batch; 0h:43m:25s remains)
INFO - root - 2022-02-24 20:26:18.422939: step 103980, total loss = 0.55, batch loss = 0.29 (311.8 examples/sec; 0.026 sec/batch; 0h:40m:50s remains)
INFO - root - 2022-02-24 20:26:18.734233: step 103990, total loss = 0.73, batch loss = 0.47 (163.5 examples/sec; 0.049 sec/batch; 1h:17m:52s remains)
INFO - root - 2022-02-24 20:26:19.000573: step 104000, total loss = 0.47, batch loss = 0.20 (252.7 examples/sec; 0.032 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 20:26:19.381785: step 104010, total loss = 0.48, batch loss = 0.21 (258.2 examples/sec; 0.031 sec/batch; 0h:49m:19s remains)
INFO - root - 2022-02-24 20:26:19.867221: step 104020, total loss = 0.64, batch loss = 0.38 (249.7 examples/sec; 0.032 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:26:20.387239: step 104030, total loss = 0.65, batch loss = 0.38 (299.4 examples/sec; 0.027 sec/batch; 0h:42m:31s remains)
INFO - root - 2022-02-24 20:26:20.702566: step 104040, total loss = 0.47, batch loss = 0.21 (269.8 examples/sec; 0.030 sec/batch; 0h:47m:10s remains)
INFO - root - 2022-02-24 20:26:21.193242: step 104050, total loss = 0.64, batch loss = 0.38 (290.6 examples/sec; 0.028 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:26:21.624157: step 104060, total loss = 0.56, batch loss = 0.30 (295.9 examples/sec; 0.027 sec/batch; 0h:43m:00s remains)
INFO - root - 2022-02-24 20:26:22.163328: step 104070, total loss = 0.61, batch loss = 0.34 (341.4 examples/sec; 0.023 sec/batch; 0h:37m:16s remains)
INFO - root - 2022-02-24 20:26:22.629608: step 104080, total loss = 0.55, batch loss = 0.29 (179.0 examples/sec; 0.045 sec/batch; 1h:11m:03s remains)
INFO - root - 2022-02-24 20:26:22.908192: step 104090, total loss = 0.53, batch loss = 0.26 (361.0 examples/sec; 0.022 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 20:26:23.352043: step 104100, total loss = 0.55, batch loss = 0.29 (130.0 examples/sec; 0.062 sec/batch; 1h:37m:49s remains)
INFO - root - 2022-02-24 20:26:23.845717: step 104110, total loss = 0.50, batch loss = 0.23 (234.1 examples/sec; 0.034 sec/batch; 0h:54m:20s remains)
INFO - root - 2022-02-24 20:26:24.302465: step 104120, total loss = 0.47, batch loss = 0.20 (245.3 examples/sec; 0.033 sec/batch; 0h:51m:51s remains)
INFO - root - 2022-02-24 20:26:25.058921: step 104130, total loss = 0.61, batch loss = 0.35 (304.2 examples/sec; 0.026 sec/batch; 0h:41m:48s remains)
INFO - root - 2022-02-24 20:26:25.412790: step 104140, total loss = 0.55, batch loss = 0.29 (216.2 examples/sec; 0.037 sec/batch; 0h:58m:47s remains)
INFO - root - 2022-02-24 20:26:25.755212: step 104150, total loss = 0.51, batch loss = 0.25 (231.2 examples/sec; 0.035 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:26:26.135979: step 104160, total loss = 0.58, batch loss = 0.32 (245.8 examples/sec; 0.033 sec/batch; 0h:51m:43s remains)
INFO - root - 2022-02-24 20:26:26.556556: step 104170, total loss = 0.46, batch loss = 0.20 (207.6 examples/sec; 0.039 sec/batch; 1h:01m:13s remains)
INFO - root - 2022-02-24 20:26:26.943879: step 104180, total loss = 0.62, batch loss = 0.36 (149.2 examples/sec; 0.054 sec/batch; 1h:25m:10s remains)
INFO - root - 2022-02-24 20:26:27.285897: step 104190, total loss = 0.65, batch loss = 0.38 (189.8 examples/sec; 0.042 sec/batch; 1h:06m:56s remains)
INFO - root - 2022-02-24 20:26:27.597945: step 104200, total loss = 0.51, batch loss = 0.24 (326.6 examples/sec; 0.024 sec/batch; 0h:38m:54s remains)
INFO - root - 2022-02-24 20:26:27.965857: step 104210, total loss = 0.54, batch loss = 0.28 (311.6 examples/sec; 0.026 sec/batch; 0h:40m:46s remains)
INFO - root - 2022-02-24 20:26:28.433068: step 104220, total loss = 0.55, batch loss = 0.28 (82.5 examples/sec; 0.097 sec/batch; 2h:33m:57s remains)
INFO - root - 2022-02-24 20:26:28.788508: step 104230, total loss = 0.58, batch loss = 0.31 (226.9 examples/sec; 0.035 sec/batch; 0h:55m:59s remains)
INFO - root - 2022-02-24 20:26:29.065546: step 104240, total loss = 0.53, batch loss = 0.27 (333.1 examples/sec; 0.024 sec/batch; 0h:38m:07s remains)
INFO - root - 2022-02-24 20:26:29.311619: step 104250, total loss = 0.52, batch loss = 0.25 (305.3 examples/sec; 0.026 sec/batch; 0h:41m:36s remains)
INFO - root - 2022-02-24 20:26:29.552935: step 104260, total loss = 0.52, batch loss = 0.25 (356.2 examples/sec; 0.022 sec/batch; 0h:35m:39s remains)
INFO - root - 2022-02-24 20:26:29.948435: step 104270, total loss = 0.61, batch loss = 0.34 (93.3 examples/sec; 0.086 sec/batch; 2h:16m:09s remains)
INFO - root - 2022-02-24 20:26:30.356028: step 104280, total loss = 0.51, batch loss = 0.25 (138.8 examples/sec; 0.058 sec/batch; 1h:31m:28s remains)
INFO - root - 2022-02-24 20:26:30.699335: step 104290, total loss = 0.49, batch loss = 0.22 (335.9 examples/sec; 0.024 sec/batch; 0h:37m:47s remains)
INFO - root - 2022-02-24 20:26:31.004448: step 104300, total loss = 0.50, batch loss = 0.24 (275.1 examples/sec; 0.029 sec/batch; 0h:46m:08s remains)
INFO - root - 2022-02-24 20:26:31.429203: step 104310, total loss = 0.52, batch loss = 0.25 (294.0 examples/sec; 0.027 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:26:31.765344: step 104320, total loss = 0.54, batch loss = 0.28 (175.0 examples/sec; 0.046 sec/batch; 1h:12m:30s remains)
INFO - root - 2022-02-24 20:26:32.151483: step 104330, total loss = 0.60, batch loss = 0.34 (337.3 examples/sec; 0.024 sec/batch; 0h:37m:37s remains)
INFO - root - 2022-02-24 20:26:32.549985: step 104340, total loss = 0.56, batch loss = 0.30 (189.5 examples/sec; 0.042 sec/batch; 1h:06m:57s remains)
INFO - root - 2022-02-24 20:26:32.901500: step 104350, total loss = 0.71, batch loss = 0.45 (358.8 examples/sec; 0.022 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:26:33.197285: step 104360, total loss = 0.54, batch loss = 0.27 (346.5 examples/sec; 0.023 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:26:33.532488: step 104370, total loss = 0.60, batch loss = 0.33 (294.8 examples/sec; 0.027 sec/batch; 0h:43m:01s remains)
INFO - root - 2022-02-24 20:26:33.855609: step 104380, total loss = 0.64, batch loss = 0.37 (182.6 examples/sec; 0.044 sec/batch; 1h:09m:27s remains)
INFO - root - 2022-02-24 20:26:34.164599: step 104390, total loss = 0.59, batch loss = 0.33 (350.8 examples/sec; 0.023 sec/batch; 0h:36m:08s remains)
INFO - root - 2022-02-24 20:26:34.631289: step 104400, total loss = 0.44, batch loss = 0.18 (253.1 examples/sec; 0.032 sec/batch; 0h:50m:05s remains)
INFO - root - 2022-02-24 20:26:35.113086: step 104410, total loss = 0.59, batch loss = 0.32 (144.7 examples/sec; 0.055 sec/batch; 1h:27m:36s remains)
INFO - root - 2022-02-24 20:26:35.432571: step 104420, total loss = 0.54, batch loss = 0.27 (313.4 examples/sec; 0.026 sec/batch; 0h:40m:27s remains)
INFO - root - 2022-02-24 20:26:35.682260: step 104430, total loss = 0.58, batch loss = 0.31 (319.5 examples/sec; 0.025 sec/batch; 0h:39m:40s remains)
INFO - root - 2022-02-24 20:26:35.945798: step 104440, total loss = 0.50, batch loss = 0.23 (314.5 examples/sec; 0.025 sec/batch; 0h:40m:17s remains)
INFO - root - 2022-02-24 20:26:36.301298: step 104450, total loss = 0.59, batch loss = 0.33 (84.8 examples/sec; 0.094 sec/batch; 2h:29m:25s remains)
INFO - root - 2022-02-24 20:26:36.642470: step 104460, total loss = 0.62, batch loss = 0.36 (346.8 examples/sec; 0.023 sec/batch; 0h:36m:32s remains)
INFO - root - 2022-02-24 20:26:36.996793: step 104470, total loss = 0.53, batch loss = 0.27 (110.2 examples/sec; 0.073 sec/batch; 1h:54m:59s remains)
INFO - root - 2022-02-24 20:26:37.301169: step 104480, total loss = 0.52, batch loss = 0.26 (330.8 examples/sec; 0.024 sec/batch; 0h:38m:18s remains)
INFO - root - 2022-02-24 20:26:37.627028: step 104490, total loss = 0.50, batch loss = 0.23 (218.2 examples/sec; 0.037 sec/batch; 0h:58m:03s remains)
INFO - root - 2022-02-24 20:26:38.294832: step 104500, total loss = 0.57, batch loss = 0.31 (378.8 examples/sec; 0.021 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:26:39.422869: step 104510, total loss = 0.54, batch loss = 0.28 (330.1 examples/sec; 0.024 sec/batch; 0h:38m:21s remains)
INFO - root - 2022-02-24 20:26:39.662764: step 104520, total loss = 0.48, batch loss = 0.21 (360.4 examples/sec; 0.022 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:26:39.900341: step 104530, total loss = 0.64, batch loss = 0.38 (332.4 examples/sec; 0.024 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:26:40.133917: step 104540, total loss = 0.48, batch loss = 0.22 (354.3 examples/sec; 0.023 sec/batch; 0h:35m:44s remains)
INFO - root - 2022-02-24 20:26:40.895250: step 104550, total loss = 0.60, batch loss = 0.33 (336.2 examples/sec; 0.024 sec/batch; 0h:37m:39s remains)
INFO - root - 2022-02-24 20:26:41.284048: step 104560, total loss = 0.47, batch loss = 0.21 (235.7 examples/sec; 0.034 sec/batch; 0h:53m:42s remains)
INFO - root - 2022-02-24 20:26:41.591950: step 104570, total loss = 0.55, batch loss = 0.29 (306.8 examples/sec; 0.026 sec/batch; 0h:41m:15s remains)
INFO - root - 2022-02-24 20:26:41.876016: step 104580, total loss = 0.47, batch loss = 0.21 (334.7 examples/sec; 0.024 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 20:26:42.211446: step 104590, total loss = 0.52, batch loss = 0.26 (231.6 examples/sec; 0.035 sec/batch; 0h:54m:39s remains)
INFO - root - 2022-02-24 20:26:42.542651: step 104600, total loss = 0.71, batch loss = 0.45 (188.7 examples/sec; 0.042 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:26:43.011130: step 104610, total loss = 0.57, batch loss = 0.30 (128.2 examples/sec; 0.062 sec/batch; 1h:38m:39s remains)
INFO - root - 2022-02-24 20:26:43.453471: step 104620, total loss = 0.54, batch loss = 0.28 (225.9 examples/sec; 0.035 sec/batch; 0h:55m:59s remains)
INFO - root - 2022-02-24 20:26:43.849989: step 104630, total loss = 0.52, batch loss = 0.26 (324.4 examples/sec; 0.025 sec/batch; 0h:38m:59s remains)
INFO - root - 2022-02-24 20:26:44.176546: step 104640, total loss = 0.58, batch loss = 0.32 (329.2 examples/sec; 0.024 sec/batch; 0h:38m:25s remains)
INFO - root - 2022-02-24 20:26:44.425777: step 104650, total loss = 0.50, batch loss = 0.23 (256.3 examples/sec; 0.031 sec/batch; 0h:49m:20s remains)
INFO - root - 2022-02-24 20:26:44.794029: step 104660, total loss = 0.56, batch loss = 0.30 (269.0 examples/sec; 0.030 sec/batch; 0h:47m:00s remains)
INFO - root - 2022-02-24 20:26:45.232842: step 104670, total loss = 0.49, batch loss = 0.23 (147.6 examples/sec; 0.054 sec/batch; 1h:25m:41s remains)
INFO - root - 2022-02-24 20:26:45.498911: step 104680, total loss = 0.61, batch loss = 0.35 (299.6 examples/sec; 0.027 sec/batch; 0h:42m:11s remains)
INFO - root - 2022-02-24 20:26:45.760068: step 104690, total loss = 0.70, batch loss = 0.43 (359.5 examples/sec; 0.022 sec/batch; 0h:35m:09s remains)
INFO - root - 2022-02-24 20:26:46.019636: step 104700, total loss = 0.68, batch loss = 0.41 (282.9 examples/sec; 0.028 sec/batch; 0h:44m:40s remains)
INFO - root - 2022-02-24 20:26:46.441831: step 104710, total loss = 0.52, batch loss = 0.26 (189.0 examples/sec; 0.042 sec/batch; 1h:06m:52s remains)
INFO - root - 2022-02-24 20:26:46.784275: step 104720, total loss = 0.58, batch loss = 0.32 (339.6 examples/sec; 0.024 sec/batch; 0h:37m:12s remains)
INFO - root - 2022-02-24 20:26:47.150552: step 104730, total loss = 0.59, batch loss = 0.33 (344.6 examples/sec; 0.023 sec/batch; 0h:36m:40s remains)
INFO - root - 2022-02-24 20:26:47.512041: step 104740, total loss = 0.84, batch loss = 0.57 (306.4 examples/sec; 0.026 sec/batch; 0h:41m:13s remains)
INFO - root - 2022-02-24 20:26:47.811219: step 104750, total loss = 0.64, batch loss = 0.38 (132.2 examples/sec; 0.061 sec/batch; 1h:35m:32s remains)
INFO - root - 2022-02-24 20:26:48.083946: step 104760, total loss = 0.50, batch loss = 0.23 (284.5 examples/sec; 0.028 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:26:48.389027: step 104770, total loss = 0.53, batch loss = 0.26 (222.3 examples/sec; 0.036 sec/batch; 0h:56m:48s remains)
INFO - root - 2022-02-24 20:26:48.739315: step 104780, total loss = 0.57, batch loss = 0.31 (356.8 examples/sec; 0.022 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 20:26:49.191084: step 104790, total loss = 0.55, batch loss = 0.29 (121.7 examples/sec; 0.066 sec/batch; 1h:43m:43s remains)
INFO - root - 2022-02-24 20:26:49.525388: step 104800, total loss = 0.51, batch loss = 0.24 (338.7 examples/sec; 0.024 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 20:26:49.883576: step 104810, total loss = 0.52, batch loss = 0.25 (345.8 examples/sec; 0.023 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:26:50.186441: step 104820, total loss = 0.50, batch loss = 0.24 (162.4 examples/sec; 0.049 sec/batch; 1h:17m:43s remains)
INFO - root - 2022-02-24 20:26:50.519266: step 104830, total loss = 0.61, batch loss = 0.35 (107.1 examples/sec; 0.075 sec/batch; 1h:57m:48s remains)
INFO - root - 2022-02-24 20:26:50.965966: step 104840, total loss = 0.55, batch loss = 0.28 (173.3 examples/sec; 0.046 sec/batch; 1h:12m:50s remains)
INFO - root - 2022-02-24 20:26:51.331090: step 104850, total loss = 0.50, batch loss = 0.24 (305.9 examples/sec; 0.026 sec/batch; 0h:41m:15s remains)
INFO - root - 2022-02-24 20:26:51.658476: step 104860, total loss = 0.56, batch loss = 0.30 (238.1 examples/sec; 0.034 sec/batch; 0h:53m:00s remains)
INFO - root - 2022-02-24 20:26:51.991903: step 104870, total loss = 0.53, batch loss = 0.27 (283.9 examples/sec; 0.028 sec/batch; 0h:44m:26s remains)
INFO - root - 2022-02-24 20:26:52.268718: step 104880, total loss = 0.52, batch loss = 0.25 (296.2 examples/sec; 0.027 sec/batch; 0h:42m:35s remains)
INFO - root - 2022-02-24 20:26:52.646234: step 104890, total loss = 0.52, batch loss = 0.25 (270.8 examples/sec; 0.030 sec/batch; 0h:46m:34s remains)
INFO - root - 2022-02-24 20:26:52.997467: step 104900, total loss = 0.62, batch loss = 0.35 (135.3 examples/sec; 0.059 sec/batch; 1h:33m:12s remains)
INFO - root - 2022-02-24 20:26:53.354926: step 104910, total loss = 0.60, batch loss = 0.34 (235.9 examples/sec; 0.034 sec/batch; 0h:53m:27s remains)
INFO - root - 2022-02-24 20:26:53.718203: step 104920, total loss = 0.59, batch loss = 0.33 (324.3 examples/sec; 0.025 sec/batch; 0h:38m:53s remains)
INFO - root - 2022-02-24 20:26:54.000971: step 104930, total loss = 0.55, batch loss = 0.29 (240.6 examples/sec; 0.033 sec/batch; 0h:52m:24s remains)
INFO - root - 2022-02-24 20:26:54.313371: step 104940, total loss = 0.49, batch loss = 0.23 (190.1 examples/sec; 0.042 sec/batch; 1h:06m:18s remains)
INFO - root - 2022-02-24 20:26:54.632485: step 104950, total loss = 0.53, batch loss = 0.27 (240.9 examples/sec; 0.033 sec/batch; 0h:52m:19s remains)
INFO - root - 2022-02-24 20:26:55.016889: step 104960, total loss = 0.57, batch loss = 0.31 (354.8 examples/sec; 0.023 sec/batch; 0h:35m:31s remains)
INFO - root - 2022-02-24 20:26:55.525398: step 104970, total loss = 0.53, batch loss = 0.27 (178.7 examples/sec; 0.045 sec/batch; 1h:10m:30s remains)
INFO - root - 2022-02-24 20:26:55.850699: step 104980, total loss = 0.60, batch loss = 0.33 (334.8 examples/sec; 0.024 sec/batch; 0h:37m:38s remains)
INFO - root - 2022-02-24 20:26:56.171684: step 104990, total loss = 0.61, batch loss = 0.35 (311.5 examples/sec; 0.026 sec/batch; 0h:40m:26s remains)
INFO - root - 2022-02-24 20:26:56.433907: step 105000, total loss = 0.48, batch loss = 0.22 (219.3 examples/sec; 0.036 sec/batch; 0h:57m:27s remains)
INFO - root - 2022-02-24 20:26:56.865950: step 105010, total loss = 0.49, batch loss = 0.23 (202.9 examples/sec; 0.039 sec/batch; 1h:02m:04s remains)
INFO - root - 2022-02-24 20:26:57.224191: step 105020, total loss = 0.83, batch loss = 0.57 (322.9 examples/sec; 0.025 sec/batch; 0h:39m:00s remains)
INFO - root - 2022-02-24 20:26:57.676839: step 105030, total loss = 0.57, batch loss = 0.31 (126.5 examples/sec; 0.063 sec/batch; 1h:39m:34s remains)
INFO - root - 2022-02-24 20:26:58.015431: step 105040, total loss = 0.51, batch loss = 0.24 (338.3 examples/sec; 0.024 sec/batch; 0h:37m:13s remains)
INFO - root - 2022-02-24 20:26:58.319143: step 105050, total loss = 0.52, batch loss = 0.25 (311.1 examples/sec; 0.026 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:26:58.564975: step 105060, total loss = 0.58, batch loss = 0.32 (322.6 examples/sec; 0.025 sec/batch; 0h:39m:02s remains)
INFO - root - 2022-02-24 20:26:58.938392: step 105070, total loss = 0.59, batch loss = 0.33 (146.0 examples/sec; 0.055 sec/batch; 1h:26m:14s remains)
INFO - root - 2022-02-24 20:26:59.337243: step 105080, total loss = 0.59, batch loss = 0.33 (299.3 examples/sec; 0.027 sec/batch; 0h:42m:04s remains)
INFO - root - 2022-02-24 20:26:59.728505: step 105090, total loss = 0.64, batch loss = 0.38 (167.8 examples/sec; 0.048 sec/batch; 1h:15m:02s remains)
INFO - root - 2022-02-24 20:27:00.074725: step 105100, total loss = 0.63, batch loss = 0.36 (328.4 examples/sec; 0.024 sec/batch; 0h:38m:19s remains)
INFO - root - 2022-02-24 20:27:00.470463: step 105110, total loss = 0.47, batch loss = 0.21 (295.0 examples/sec; 0.027 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:27:00.740329: step 105120, total loss = 0.58, batch loss = 0.31 (354.8 examples/sec; 0.023 sec/batch; 0h:35m:28s remains)
INFO - root - 2022-02-24 20:27:01.603311: step 105130, total loss = 0.55, batch loss = 0.28 (165.8 examples/sec; 0.048 sec/batch; 1h:15m:54s remains)
INFO - root - 2022-02-24 20:27:02.026166: step 105140, total loss = 0.58, batch loss = 0.32 (193.7 examples/sec; 0.041 sec/batch; 1h:04m:57s remains)
INFO - root - 2022-02-24 20:27:02.391039: step 105150, total loss = 0.66, batch loss = 0.40 (326.0 examples/sec; 0.025 sec/batch; 0h:38m:35s remains)
INFO - root - 2022-02-24 20:27:02.658261: step 105160, total loss = 0.59, batch loss = 0.33 (386.8 examples/sec; 0.021 sec/batch; 0h:32m:31s remains)
INFO - root - 2022-02-24 20:27:03.042200: step 105170, total loss = 0.49, batch loss = 0.23 (177.7 examples/sec; 0.045 sec/batch; 1h:10m:47s remains)
INFO - root - 2022-02-24 20:27:03.502510: step 105180, total loss = 0.67, batch loss = 0.40 (248.2 examples/sec; 0.032 sec/batch; 0h:50m:40s remains)
INFO - root - 2022-02-24 20:27:03.955452: step 105190, total loss = 0.50, batch loss = 0.23 (133.6 examples/sec; 0.060 sec/batch; 1h:34m:07s remains)
INFO - root - 2022-02-24 20:27:04.423499: step 105200, total loss = 0.69, batch loss = 0.42 (190.4 examples/sec; 0.042 sec/batch; 1h:06m:01s remains)
INFO - root - 2022-02-24 20:27:04.977677: step 105210, total loss = 0.51, batch loss = 0.24 (178.6 examples/sec; 0.045 sec/batch; 1h:10m:24s remains)
INFO - root - 2022-02-24 20:27:05.741204: step 105220, total loss = 0.61, batch loss = 0.35 (146.2 examples/sec; 0.055 sec/batch; 1h:25m:58s remains)
INFO - root - 2022-02-24 20:27:06.084844: step 105230, total loss = 0.59, batch loss = 0.33 (155.5 examples/sec; 0.051 sec/batch; 1h:20m:48s remains)
INFO - root - 2022-02-24 20:27:06.457675: step 105240, total loss = 0.46, batch loss = 0.19 (356.5 examples/sec; 0.022 sec/batch; 0h:35m:15s remains)
INFO - root - 2022-02-24 20:27:06.865399: step 105250, total loss = 0.52, batch loss = 0.26 (329.4 examples/sec; 0.024 sec/batch; 0h:38m:09s remains)
INFO - root - 2022-02-24 20:27:07.157520: step 105260, total loss = 0.79, batch loss = 0.53 (348.3 examples/sec; 0.023 sec/batch; 0h:36m:04s remains)
INFO - root - 2022-02-24 20:27:07.497219: step 105270, total loss = 0.50, batch loss = 0.24 (202.8 examples/sec; 0.039 sec/batch; 1h:01m:57s remains)
INFO - root - 2022-02-24 20:27:07.744458: step 105280, total loss = 0.55, batch loss = 0.28 (316.5 examples/sec; 0.025 sec/batch; 0h:39m:41s remains)
INFO - root - 2022-02-24 20:27:08.009820: step 105290, total loss = 0.57, batch loss = 0.31 (341.1 examples/sec; 0.023 sec/batch; 0h:36m:49s remains)
INFO - root - 2022-02-24 20:27:08.290546: step 105300, total loss = 0.57, batch loss = 0.31 (211.2 examples/sec; 0.038 sec/batch; 0h:59m:27s remains)
INFO - root - 2022-02-24 20:27:08.737184: step 105310, total loss = 0.50, batch loss = 0.23 (158.3 examples/sec; 0.051 sec/batch; 1h:19m:18s remains)
INFO - root - 2022-02-24 20:27:09.188356: step 105320, total loss = 0.60, batch loss = 0.33 (152.8 examples/sec; 0.052 sec/batch; 1h:22m:11s remains)
INFO - root - 2022-02-24 20:27:09.571355: step 105330, total loss = 0.54, batch loss = 0.27 (294.7 examples/sec; 0.027 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 20:27:09.821107: step 105340, total loss = 0.51, batch loss = 0.25 (320.2 examples/sec; 0.025 sec/batch; 0h:39m:12s remains)
INFO - root - 2022-02-24 20:27:10.124912: step 105350, total loss = 0.51, batch loss = 0.25 (338.1 examples/sec; 0.024 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:27:10.439547: step 105360, total loss = 0.52, batch loss = 0.26 (306.1 examples/sec; 0.026 sec/batch; 0h:40m:59s remains)
INFO - root - 2022-02-24 20:27:10.810713: step 105370, total loss = 0.56, batch loss = 0.30 (165.5 examples/sec; 0.048 sec/batch; 1h:15m:49s remains)
INFO - root - 2022-02-24 20:27:11.154788: step 105380, total loss = 0.53, batch loss = 0.27 (337.4 examples/sec; 0.024 sec/batch; 0h:37m:11s remains)
INFO - root - 2022-02-24 20:27:11.472235: step 105390, total loss = 0.62, batch loss = 0.35 (347.3 examples/sec; 0.023 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:27:11.792279: step 105400, total loss = 0.57, batch loss = 0.30 (262.6 examples/sec; 0.030 sec/batch; 0h:47m:46s remains)
INFO - root - 2022-02-24 20:27:12.158592: step 105410, total loss = 0.52, batch loss = 0.26 (319.7 examples/sec; 0.025 sec/batch; 0h:39m:14s remains)
INFO - root - 2022-02-24 20:27:12.453770: step 105420, total loss = 0.52, batch loss = 0.26 (171.3 examples/sec; 0.047 sec/batch; 1h:13m:14s remains)
INFO - root - 2022-02-24 20:27:12.835669: step 105430, total loss = 0.55, batch loss = 0.29 (381.6 examples/sec; 0.021 sec/batch; 0h:32m:52s remains)
INFO - root - 2022-02-24 20:27:13.200588: step 105440, total loss = 0.65, batch loss = 0.38 (339.4 examples/sec; 0.024 sec/batch; 0h:36m:56s remains)
INFO - root - 2022-02-24 20:27:13.592799: step 105450, total loss = 0.58, batch loss = 0.32 (315.0 examples/sec; 0.025 sec/batch; 0h:39m:48s remains)
INFO - root - 2022-02-24 20:27:13.866766: step 105460, total loss = 0.62, batch loss = 0.35 (329.0 examples/sec; 0.024 sec/batch; 0h:38m:06s remains)
INFO - root - 2022-02-24 20:27:14.179209: step 105470, total loss = 0.49, batch loss = 0.23 (287.5 examples/sec; 0.028 sec/batch; 0h:43m:36s remains)
INFO - root - 2022-02-24 20:27:14.443294: step 105480, total loss = 0.46, batch loss = 0.19 (310.2 examples/sec; 0.026 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:27:14.849794: step 105490, total loss = 0.52, batch loss = 0.25 (173.4 examples/sec; 0.046 sec/batch; 1h:12m:16s remains)
INFO - root - 2022-02-24 20:27:15.227707: step 105500, total loss = 0.55, batch loss = 0.28 (202.2 examples/sec; 0.040 sec/batch; 1h:01m:58s remains)
INFO - root - 2022-02-24 20:27:15.664282: step 105510, total loss = 0.47, batch loss = 0.21 (352.9 examples/sec; 0.023 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:27:15.982848: step 105520, total loss = 0.51, batch loss = 0.25 (325.5 examples/sec; 0.025 sec/batch; 0h:38m:29s remains)
INFO - root - 2022-02-24 20:27:16.275685: step 105530, total loss = 0.51, batch loss = 0.25 (183.2 examples/sec; 0.044 sec/batch; 1h:08m:24s remains)
INFO - root - 2022-02-24 20:27:16.635778: step 105540, total loss = 0.57, batch loss = 0.30 (102.8 examples/sec; 0.078 sec/batch; 2h:01m:49s remains)
INFO - root - 2022-02-24 20:27:17.071804: step 105550, total loss = 0.54, batch loss = 0.28 (350.7 examples/sec; 0.023 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 20:27:17.378346: step 105560, total loss = 0.58, batch loss = 0.31 (356.9 examples/sec; 0.022 sec/batch; 0h:35m:05s remains)
INFO - root - 2022-02-24 20:27:17.660575: step 105570, total loss = 0.60, batch loss = 0.34 (321.1 examples/sec; 0.025 sec/batch; 0h:39m:00s remains)
INFO - root - 2022-02-24 20:27:17.934193: step 105580, total loss = 0.52, batch loss = 0.25 (337.1 examples/sec; 0.024 sec/batch; 0h:37m:09s remains)
INFO - root - 2022-02-24 20:27:18.251532: step 105590, total loss = 0.52, batch loss = 0.25 (310.1 examples/sec; 0.026 sec/batch; 0h:40m:22s remains)
INFO - root - 2022-02-24 20:27:18.662611: step 105600, total loss = 0.76, batch loss = 0.50 (137.6 examples/sec; 0.058 sec/batch; 1h:30m:59s remains)
INFO - root - 2022-02-24 20:27:19.178980: step 105610, total loss = 0.47, batch loss = 0.20 (102.6 examples/sec; 0.078 sec/batch; 2h:02m:01s remains)
INFO - root - 2022-02-24 20:27:19.522811: step 105620, total loss = 0.58, batch loss = 0.32 (246.7 examples/sec; 0.032 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 20:27:19.841113: step 105630, total loss = 0.50, batch loss = 0.23 (195.0 examples/sec; 0.041 sec/batch; 1h:04m:10s remains)
INFO - root - 2022-02-24 20:27:20.183412: step 105640, total loss = 0.54, batch loss = 0.28 (253.0 examples/sec; 0.032 sec/batch; 0h:49m:27s remains)
INFO - root - 2022-02-24 20:27:20.601510: step 105650, total loss = 0.52, batch loss = 0.26 (165.1 examples/sec; 0.048 sec/batch; 1h:15m:47s remains)
INFO - root - 2022-02-24 20:27:20.985826: step 105660, total loss = 0.56, batch loss = 0.30 (223.9 examples/sec; 0.036 sec/batch; 0h:55m:52s remains)
INFO - root - 2022-02-24 20:27:21.427405: step 105670, total loss = 0.61, batch loss = 0.35 (132.5 examples/sec; 0.060 sec/batch; 1h:34m:25s remains)
INFO - root - 2022-02-24 20:27:22.258700: step 105680, total loss = 0.61, batch loss = 0.35 (340.6 examples/sec; 0.023 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:27:22.579977: step 105690, total loss = 0.63, batch loss = 0.37 (335.6 examples/sec; 0.024 sec/batch; 0h:37m:15s remains)
INFO - root - 2022-02-24 20:27:23.017943: step 105700, total loss = 0.56, batch loss = 0.29 (136.2 examples/sec; 0.059 sec/batch; 1h:31m:48s remains)
INFO - root - 2022-02-24 20:27:24.091612: step 105710, total loss = 0.70, batch loss = 0.43 (288.0 examples/sec; 0.028 sec/batch; 0h:43m:24s remains)
INFO - root - 2022-02-24 20:27:24.327589: step 105720, total loss = 0.58, batch loss = 0.32 (343.5 examples/sec; 0.023 sec/batch; 0h:36m:24s remains)
INFO - root - 2022-02-24 20:27:24.572544: step 105730, total loss = 0.52, batch loss = 0.25 (275.3 examples/sec; 0.029 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:27:24.819281: step 105740, total loss = 0.55, batch loss = 0.29 (332.6 examples/sec; 0.024 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:27:25.103662: step 105750, total loss = 0.51, batch loss = 0.24 (149.4 examples/sec; 0.054 sec/batch; 1h:23m:40s remains)
INFO - root - 2022-02-24 20:27:25.443026: step 105760, total loss = 0.56, batch loss = 0.30 (131.9 examples/sec; 0.061 sec/batch; 1h:34m:45s remains)
INFO - root - 2022-02-24 20:27:26.168902: step 105770, total loss = 0.61, batch loss = 0.35 (120.3 examples/sec; 0.067 sec/batch; 1h:43m:54s remains)
INFO - root - 2022-02-24 20:27:26.486369: step 105780, total loss = 0.61, batch loss = 0.35 (359.4 examples/sec; 0.022 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 20:27:26.805560: step 105790, total loss = 0.57, batch loss = 0.31 (362.2 examples/sec; 0.022 sec/batch; 0h:34m:29s remains)
INFO - root - 2022-02-24 20:27:27.082308: step 105800, total loss = 0.62, batch loss = 0.36 (344.2 examples/sec; 0.023 sec/batch; 0h:36m:17s remains)
INFO - root - 2022-02-24 20:27:27.503842: step 105810, total loss = 0.61, batch loss = 0.35 (404.7 examples/sec; 0.020 sec/batch; 0h:30m:52s remains)
INFO - root - 2022-02-24 20:27:27.796142: step 105820, total loss = 0.53, batch loss = 0.27 (337.3 examples/sec; 0.024 sec/batch; 0h:37m:02s remains)
INFO - root - 2022-02-24 20:27:28.129576: step 105830, total loss = 0.45, batch loss = 0.19 (168.3 examples/sec; 0.048 sec/batch; 1h:14m:12s remains)
INFO - root - 2022-02-24 20:27:28.515034: step 105840, total loss = 0.54, batch loss = 0.28 (89.8 examples/sec; 0.089 sec/batch; 2h:19m:03s remains)
INFO - root - 2022-02-24 20:27:28.794864: step 105850, total loss = 0.50, batch loss = 0.23 (277.3 examples/sec; 0.029 sec/batch; 0h:45m:02s remains)
INFO - root - 2022-02-24 20:27:29.111021: step 105860, total loss = 0.52, batch loss = 0.25 (155.5 examples/sec; 0.051 sec/batch; 1h:20m:16s remains)
INFO - root - 2022-02-24 20:27:29.497097: step 105870, total loss = 0.56, batch loss = 0.30 (109.6 examples/sec; 0.073 sec/batch; 1h:53m:54s remains)
INFO - root - 2022-02-24 20:27:29.879391: step 105880, total loss = 0.62, batch loss = 0.36 (320.9 examples/sec; 0.025 sec/batch; 0h:38m:53s remains)
INFO - root - 2022-02-24 20:27:30.209329: step 105890, total loss = 0.53, batch loss = 0.27 (255.5 examples/sec; 0.031 sec/batch; 0h:48m:50s remains)
INFO - root - 2022-02-24 20:27:30.563923: step 105900, total loss = 0.56, batch loss = 0.30 (148.0 examples/sec; 0.054 sec/batch; 1h:24m:21s remains)
INFO - root - 2022-02-24 20:27:30.942028: step 105910, total loss = 0.52, batch loss = 0.25 (305.1 examples/sec; 0.026 sec/batch; 0h:40m:54s remains)
INFO - root - 2022-02-24 20:27:31.267461: step 105920, total loss = 0.73, batch loss = 0.47 (324.1 examples/sec; 0.025 sec/batch; 0h:38m:29s remains)
INFO - root - 2022-02-24 20:27:31.620164: step 105930, total loss = 0.58, batch loss = 0.32 (313.7 examples/sec; 0.026 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:27:31.998381: step 105940, total loss = 0.59, batch loss = 0.32 (114.9 examples/sec; 0.070 sec/batch; 1h:48m:36s remains)
INFO - root - 2022-02-24 20:27:32.305256: step 105950, total loss = 0.52, batch loss = 0.25 (351.6 examples/sec; 0.023 sec/batch; 0h:35m:28s remains)
INFO - root - 2022-02-24 20:27:32.659315: step 105960, total loss = 0.58, batch loss = 0.32 (170.9 examples/sec; 0.047 sec/batch; 1h:12m:58s remains)
INFO - root - 2022-02-24 20:27:32.997045: step 105970, total loss = 0.62, batch loss = 0.36 (369.7 examples/sec; 0.022 sec/batch; 0h:33m:43s remains)
INFO - root - 2022-02-24 20:27:33.252313: step 105980, total loss = 0.51, batch loss = 0.25 (307.0 examples/sec; 0.026 sec/batch; 0h:40m:37s remains)
INFO - root - 2022-02-24 20:27:33.662054: step 105990, total loss = 0.53, batch loss = 0.26 (137.2 examples/sec; 0.058 sec/batch; 1h:30m:51s remains)
INFO - root - 2022-02-24 20:27:34.048170: step 106000, total loss = 0.65, batch loss = 0.39 (153.7 examples/sec; 0.052 sec/batch; 1h:21m:06s remains)
INFO - root - 2022-02-24 20:27:34.416435: step 106010, total loss = 0.67, batch loss = 0.41 (334.6 examples/sec; 0.024 sec/batch; 0h:37m:15s remains)
INFO - root - 2022-02-24 20:27:34.788037: step 106020, total loss = 0.47, batch loss = 0.21 (342.5 examples/sec; 0.023 sec/batch; 0h:36m:23s remains)
INFO - root - 2022-02-24 20:27:35.050998: step 106030, total loss = 0.53, batch loss = 0.27 (330.2 examples/sec; 0.024 sec/batch; 0h:37m:44s remains)
INFO - root - 2022-02-24 20:27:35.512501: step 106040, total loss = 0.64, batch loss = 0.38 (344.8 examples/sec; 0.023 sec/batch; 0h:36m:08s remains)
INFO - root - 2022-02-24 20:27:35.927196: step 106050, total loss = 0.70, batch loss = 0.44 (272.0 examples/sec; 0.029 sec/batch; 0h:45m:48s remains)
INFO - root - 2022-02-24 20:27:36.251933: step 106060, total loss = 0.67, batch loss = 0.40 (316.9 examples/sec; 0.025 sec/batch; 0h:39m:18s remains)
INFO - root - 2022-02-24 20:27:36.534741: step 106070, total loss = 0.58, batch loss = 0.32 (378.5 examples/sec; 0.021 sec/batch; 0h:32m:54s remains)
INFO - root - 2022-02-24 20:27:36.835225: step 106080, total loss = 0.58, batch loss = 0.32 (313.3 examples/sec; 0.026 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:27:37.104517: step 106090, total loss = 0.47, batch loss = 0.21 (315.0 examples/sec; 0.025 sec/batch; 0h:39m:31s remains)
INFO - root - 2022-02-24 20:27:37.442078: step 106100, total loss = 0.67, batch loss = 0.41 (375.4 examples/sec; 0.021 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:27:37.893213: step 106110, total loss = 0.46, batch loss = 0.20 (271.7 examples/sec; 0.029 sec/batch; 0h:45m:49s remains)
INFO - root - 2022-02-24 20:27:38.285700: step 106120, total loss = 0.54, batch loss = 0.27 (148.8 examples/sec; 0.054 sec/batch; 1h:23m:39s remains)
INFO - root - 2022-02-24 20:27:38.680831: step 106130, total loss = 0.50, batch loss = 0.24 (100.5 examples/sec; 0.080 sec/batch; 2h:03m:54s remains)
INFO - root - 2022-02-24 20:27:39.196978: step 106140, total loss = 0.46, batch loss = 0.20 (120.6 examples/sec; 0.066 sec/batch; 1h:43m:14s remains)
INFO - root - 2022-02-24 20:27:39.652649: step 106150, total loss = 0.56, batch loss = 0.30 (227.0 examples/sec; 0.035 sec/batch; 0h:54m:49s remains)
INFO - root - 2022-02-24 20:27:40.118890: step 106160, total loss = 0.55, batch loss = 0.29 (115.9 examples/sec; 0.069 sec/batch; 1h:47m:21s remains)
INFO - root - 2022-02-24 20:27:40.635149: step 106170, total loss = 0.52, batch loss = 0.26 (108.5 examples/sec; 0.074 sec/batch; 1h:54m:40s remains)
INFO - root - 2022-02-24 20:27:41.421594: step 106180, total loss = 0.56, batch loss = 0.30 (233.5 examples/sec; 0.034 sec/batch; 0h:53m:16s remains)
INFO - root - 2022-02-24 20:27:41.850181: step 106190, total loss = 0.56, batch loss = 0.30 (247.9 examples/sec; 0.032 sec/batch; 0h:50m:11s remains)
INFO - root - 2022-02-24 20:27:42.202597: step 106200, total loss = 0.54, batch loss = 0.28 (264.7 examples/sec; 0.030 sec/batch; 0h:46m:59s remains)
INFO - root - 2022-02-24 20:27:42.646816: step 106210, total loss = 0.61, batch loss = 0.35 (147.6 examples/sec; 0.054 sec/batch; 1h:24m:14s remains)
INFO - root - 2022-02-24 20:27:42.937517: step 106220, total loss = 0.47, batch loss = 0.21 (317.5 examples/sec; 0.025 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 20:27:43.239202: step 106230, total loss = 0.57, batch loss = 0.31 (146.8 examples/sec; 0.055 sec/batch; 1h:24m:44s remains)
INFO - root - 2022-02-24 20:27:43.602130: step 106240, total loss = 0.52, batch loss = 0.26 (112.1 examples/sec; 0.071 sec/batch; 1h:50m:54s remains)
INFO - root - 2022-02-24 20:27:44.027386: step 106250, total loss = 0.53, batch loss = 0.27 (216.6 examples/sec; 0.037 sec/batch; 0h:57m:24s remains)
INFO - root - 2022-02-24 20:27:44.416318: step 106260, total loss = 0.59, batch loss = 0.33 (228.1 examples/sec; 0.035 sec/batch; 0h:54m:30s remains)
INFO - root - 2022-02-24 20:27:44.741962: step 106270, total loss = 0.64, batch loss = 0.38 (333.1 examples/sec; 0.024 sec/batch; 0h:37m:18s remains)
INFO - root - 2022-02-24 20:27:45.096280: step 106280, total loss = 0.54, batch loss = 0.27 (222.3 examples/sec; 0.036 sec/batch; 0h:55m:54s remains)
INFO - root - 2022-02-24 20:27:45.482466: step 106290, total loss = 0.57, batch loss = 0.30 (178.3 examples/sec; 0.045 sec/batch; 1h:09m:41s remains)
INFO - root - 2022-02-24 20:27:45.953370: step 106300, total loss = 0.54, batch loss = 0.28 (282.2 examples/sec; 0.028 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:27:46.450263: step 106310, total loss = 0.59, batch loss = 0.33 (238.1 examples/sec; 0.034 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:27:46.837627: step 106320, total loss = 0.55, batch loss = 0.28 (225.6 examples/sec; 0.035 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:27:47.103864: step 106330, total loss = 0.63, batch loss = 0.36 (286.1 examples/sec; 0.028 sec/batch; 0h:43m:24s remains)
INFO - root - 2022-02-24 20:27:47.388338: step 106340, total loss = 0.51, batch loss = 0.25 (260.5 examples/sec; 0.031 sec/batch; 0h:47m:41s remains)
INFO - root - 2022-02-24 20:27:47.691514: step 106350, total loss = 0.53, batch loss = 0.27 (315.1 examples/sec; 0.025 sec/batch; 0h:39m:24s remains)
INFO - root - 2022-02-24 20:27:48.107705: step 106360, total loss = 0.46, batch loss = 0.20 (300.9 examples/sec; 0.027 sec/batch; 0h:41m:16s remains)
INFO - root - 2022-02-24 20:27:48.556097: step 106370, total loss = 0.55, batch loss = 0.29 (258.8 examples/sec; 0.031 sec/batch; 0h:47m:59s remains)
INFO - root - 2022-02-24 20:27:48.834519: step 106380, total loss = 0.72, batch loss = 0.46 (323.9 examples/sec; 0.025 sec/batch; 0h:38m:19s remains)
INFO - root - 2022-02-24 20:27:49.129094: step 106390, total loss = 0.48, batch loss = 0.22 (353.9 examples/sec; 0.023 sec/batch; 0h:35m:04s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-106399 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-106399 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:27:49.839097: step 106400, total loss = 0.65, batch loss = 0.38 (350.8 examples/sec; 0.023 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 20:27:50.135132: step 106410, total loss = 0.56, batch loss = 0.30 (345.7 examples/sec; 0.023 sec/batch; 0h:35m:54s remains)
INFO - root - 2022-02-24 20:27:50.398231: step 106420, total loss = 0.50, batch loss = 0.23 (234.3 examples/sec; 0.034 sec/batch; 0h:52m:58s remains)
INFO - root - 2022-02-24 20:27:50.755767: step 106430, total loss = 0.43, batch loss = 0.16 (315.3 examples/sec; 0.025 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:27:51.159712: step 106440, total loss = 0.54, batch loss = 0.28 (181.6 examples/sec; 0.044 sec/batch; 1h:08m:18s remains)
INFO - root - 2022-02-24 20:27:51.462486: step 106450, total loss = 0.52, batch loss = 0.26 (190.4 examples/sec; 0.042 sec/batch; 1h:05m:08s remains)
INFO - root - 2022-02-24 20:27:51.735464: step 106460, total loss = 0.53, batch loss = 0.27 (326.7 examples/sec; 0.024 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 20:27:52.100254: step 106470, total loss = 0.54, batch loss = 0.28 (334.4 examples/sec; 0.024 sec/batch; 0h:37m:05s remains)
INFO - root - 2022-02-24 20:27:52.491286: step 106480, total loss = 0.50, batch loss = 0.23 (243.2 examples/sec; 0.033 sec/batch; 0h:51m:00s remains)
INFO - root - 2022-02-24 20:27:52.781910: step 106490, total loss = 0.58, batch loss = 0.32 (288.7 examples/sec; 0.028 sec/batch; 0h:42m:56s remains)
INFO - root - 2022-02-24 20:27:53.143462: step 106500, total loss = 0.56, batch loss = 0.30 (336.9 examples/sec; 0.024 sec/batch; 0h:36m:48s remains)
INFO - root - 2022-02-24 20:27:53.556579: step 106510, total loss = 0.59, batch loss = 0.33 (292.5 examples/sec; 0.027 sec/batch; 0h:42m:23s remains)
INFO - root - 2022-02-24 20:27:53.873410: step 106520, total loss = 0.58, batch loss = 0.32 (342.8 examples/sec; 0.023 sec/batch; 0h:36m:09s remains)
INFO - root - 2022-02-24 20:27:54.276423: step 106530, total loss = 0.54, batch loss = 0.27 (285.0 examples/sec; 0.028 sec/batch; 0h:43m:29s remains)
INFO - root - 2022-02-24 20:27:54.616111: step 106540, total loss = 0.59, batch loss = 0.32 (332.4 examples/sec; 0.024 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 20:27:55.000872: step 106550, total loss = 0.59, batch loss = 0.32 (335.7 examples/sec; 0.024 sec/batch; 0h:36m:55s remains)
INFO - root - 2022-02-24 20:27:55.286288: step 106560, total loss = 0.44, batch loss = 0.17 (306.5 examples/sec; 0.026 sec/batch; 0h:40m:26s remains)
INFO - root - 2022-02-24 20:27:55.555940: step 106570, total loss = 0.65, batch loss = 0.38 (345.3 examples/sec; 0.023 sec/batch; 0h:35m:53s remains)
INFO - root - 2022-02-24 20:27:56.189240: step 106580, total loss = 0.54, batch loss = 0.28 (209.2 examples/sec; 0.038 sec/batch; 0h:59m:13s remains)
INFO - root - 2022-02-24 20:27:56.624347: step 106590, total loss = 0.58, batch loss = 0.32 (177.6 examples/sec; 0.045 sec/batch; 1h:09m:44s remains)
INFO - root - 2022-02-24 20:27:56.991417: step 106600, total loss = 0.55, batch loss = 0.29 (165.0 examples/sec; 0.048 sec/batch; 1h:15m:04s remains)
INFO - root - 2022-02-24 20:27:57.351482: step 106610, total loss = 0.58, batch loss = 0.32 (338.2 examples/sec; 0.024 sec/batch; 0h:36m:37s remains)
INFO - root - 2022-02-24 20:27:57.642354: step 106620, total loss = 0.68, batch loss = 0.42 (324.7 examples/sec; 0.025 sec/batch; 0h:38m:08s remains)
INFO - root - 2022-02-24 20:27:58.109246: step 106630, total loss = 0.63, batch loss = 0.37 (164.3 examples/sec; 0.049 sec/batch; 1h:15m:21s remains)
INFO - root - 2022-02-24 20:27:58.526861: step 106640, total loss = 0.65, batch loss = 0.38 (99.1 examples/sec; 0.081 sec/batch; 2h:04m:53s remains)
INFO - root - 2022-02-24 20:27:58.941227: step 106650, total loss = 0.53, batch loss = 0.27 (135.5 examples/sec; 0.059 sec/batch; 1h:31m:22s remains)
INFO - root - 2022-02-24 20:27:59.378115: step 106660, total loss = 0.53, batch loss = 0.27 (316.8 examples/sec; 0.025 sec/batch; 0h:39m:04s remains)
INFO - root - 2022-02-24 20:27:59.852492: step 106670, total loss = 0.56, batch loss = 0.30 (305.5 examples/sec; 0.026 sec/batch; 0h:40m:30s remains)
INFO - root - 2022-02-24 20:28:00.233736: step 106680, total loss = 0.48, batch loss = 0.22 (134.5 examples/sec; 0.060 sec/batch; 1h:32m:02s remains)
INFO - root - 2022-02-24 20:28:00.650694: step 106690, total loss = 0.56, batch loss = 0.30 (174.7 examples/sec; 0.046 sec/batch; 1h:10m:50s remains)
INFO - root - 2022-02-24 20:28:00.961754: step 106700, total loss = 0.50, batch loss = 0.24 (303.9 examples/sec; 0.026 sec/batch; 0h:40m:42s remains)
INFO - root - 2022-02-24 20:28:01.314356: step 106710, total loss = 0.43, batch loss = 0.16 (325.4 examples/sec; 0.025 sec/batch; 0h:38m:01s remains)
INFO - root - 2022-02-24 20:28:02.102058: step 106720, total loss = 0.51, batch loss = 0.25 (327.1 examples/sec; 0.024 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 20:28:02.502802: step 106730, total loss = 0.55, batch loss = 0.28 (178.7 examples/sec; 0.045 sec/batch; 1h:09m:12s remains)
INFO - root - 2022-02-24 20:28:02.821540: step 106740, total loss = 0.52, batch loss = 0.26 (344.8 examples/sec; 0.023 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 20:28:03.103371: step 106750, total loss = 0.50, batch loss = 0.23 (305.2 examples/sec; 0.026 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:28:03.453374: step 106760, total loss = 0.63, batch loss = 0.36 (283.5 examples/sec; 0.028 sec/batch; 0h:43m:37s remains)
INFO - root - 2022-02-24 20:28:03.759993: step 106770, total loss = 0.52, batch loss = 0.25 (191.8 examples/sec; 0.042 sec/batch; 1h:04m:28s remains)
INFO - root - 2022-02-24 20:28:04.209125: step 106780, total loss = 0.55, batch loss = 0.29 (111.2 examples/sec; 0.072 sec/batch; 1h:51m:10s remains)
INFO - root - 2022-02-24 20:28:04.760059: step 106790, total loss = 0.53, batch loss = 0.26 (334.5 examples/sec; 0.024 sec/batch; 0h:36m:57s remains)
INFO - root - 2022-02-24 20:28:05.161829: step 106800, total loss = 0.53, batch loss = 0.27 (209.1 examples/sec; 0.038 sec/batch; 0h:59m:07s remains)
INFO - root - 2022-02-24 20:28:05.518167: step 106810, total loss = 0.67, batch loss = 0.40 (333.7 examples/sec; 0.024 sec/batch; 0h:37m:02s remains)
INFO - root - 2022-02-24 20:28:05.852675: step 106820, total loss = 0.53, batch loss = 0.27 (309.3 examples/sec; 0.026 sec/batch; 0h:39m:57s remains)
INFO - root - 2022-02-24 20:28:06.182632: step 106830, total loss = 0.53, batch loss = 0.27 (258.1 examples/sec; 0.031 sec/batch; 0h:47m:52s remains)
INFO - root - 2022-02-24 20:28:06.668793: step 106840, total loss = 0.57, batch loss = 0.31 (273.6 examples/sec; 0.029 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:28:07.023923: step 106850, total loss = 0.44, batch loss = 0.18 (344.0 examples/sec; 0.023 sec/batch; 0h:35m:54s remains)
INFO - root - 2022-02-24 20:28:07.323305: step 106860, total loss = 0.70, batch loss = 0.43 (165.5 examples/sec; 0.048 sec/batch; 1h:14m:37s remains)
INFO - root - 2022-02-24 20:28:07.626059: step 106870, total loss = 0.53, batch loss = 0.26 (224.2 examples/sec; 0.036 sec/batch; 0h:55m:05s remains)
INFO - root - 2022-02-24 20:28:07.953189: step 106880, total loss = 0.56, batch loss = 0.30 (201.4 examples/sec; 0.040 sec/batch; 1h:01m:19s remains)
INFO - root - 2022-02-24 20:28:08.313126: step 106890, total loss = 0.55, batch loss = 0.29 (232.7 examples/sec; 0.034 sec/batch; 0h:53m:03s remains)
INFO - root - 2022-02-24 20:28:08.735620: step 106900, total loss = 0.50, batch loss = 0.23 (316.7 examples/sec; 0.025 sec/batch; 0h:38m:59s remains)
INFO - root - 2022-02-24 20:28:09.107141: step 106910, total loss = 0.55, batch loss = 0.28 (330.1 examples/sec; 0.024 sec/batch; 0h:37m:24s remains)
INFO - root - 2022-02-24 20:28:09.474293: step 106920, total loss = 0.57, batch loss = 0.31 (333.3 examples/sec; 0.024 sec/batch; 0h:37m:02s remains)
INFO - root - 2022-02-24 20:28:09.784194: step 106930, total loss = 0.58, batch loss = 0.32 (184.1 examples/sec; 0.043 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 20:28:10.112757: step 106940, total loss = 0.54, batch loss = 0.27 (219.6 examples/sec; 0.036 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 20:28:10.519262: step 106950, total loss = 0.45, batch loss = 0.19 (176.2 examples/sec; 0.045 sec/batch; 1h:10m:03s remains)
INFO - root - 2022-02-24 20:28:10.915754: step 106960, total loss = 0.56, batch loss = 0.29 (166.3 examples/sec; 0.048 sec/batch; 1h:14m:10s remains)
INFO - root - 2022-02-24 20:28:11.266599: step 106970, total loss = 0.49, batch loss = 0.23 (267.3 examples/sec; 0.030 sec/batch; 0h:46m:09s remains)
INFO - root - 2022-02-24 20:28:11.612764: step 106980, total loss = 0.48, batch loss = 0.22 (348.7 examples/sec; 0.023 sec/batch; 0h:35m:22s remains)
INFO - root - 2022-02-24 20:28:11.906448: step 106990, total loss = 0.58, batch loss = 0.32 (321.4 examples/sec; 0.025 sec/batch; 0h:38m:23s remains)
INFO - root - 2022-02-24 20:28:12.255964: step 107000, total loss = 0.57, batch loss = 0.31 (142.3 examples/sec; 0.056 sec/batch; 1h:26m:38s remains)
INFO - root - 2022-02-24 20:28:12.706353: step 107010, total loss = 0.55, batch loss = 0.29 (359.3 examples/sec; 0.022 sec/batch; 0h:34m:19s remains)
INFO - root - 2022-02-24 20:28:13.114390: step 107020, total loss = 0.58, batch loss = 0.32 (166.5 examples/sec; 0.048 sec/batch; 1h:14m:03s remains)
INFO - root - 2022-02-24 20:28:13.481711: step 107030, total loss = 0.54, batch loss = 0.28 (189.3 examples/sec; 0.042 sec/batch; 1h:05m:08s remains)
INFO - root - 2022-02-24 20:28:13.802903: step 107040, total loss = 0.62, batch loss = 0.36 (320.2 examples/sec; 0.025 sec/batch; 0h:38m:29s remains)
INFO - root - 2022-02-24 20:28:14.101037: step 107050, total loss = 0.60, batch loss = 0.33 (197.3 examples/sec; 0.041 sec/batch; 1h:02m:29s remains)
INFO - root - 2022-02-24 20:28:14.375999: step 107060, total loss = 0.62, batch loss = 0.36 (348.1 examples/sec; 0.023 sec/batch; 0h:35m:24s remains)
INFO - root - 2022-02-24 20:28:14.736892: step 107070, total loss = 0.59, batch loss = 0.32 (160.6 examples/sec; 0.050 sec/batch; 1h:16m:45s remains)
INFO - root - 2022-02-24 20:28:15.108289: step 107080, total loss = 0.62, batch loss = 0.36 (324.0 examples/sec; 0.025 sec/batch; 0h:38m:01s remains)
INFO - root - 2022-02-24 20:28:15.375015: step 107090, total loss = 0.57, batch loss = 0.31 (340.2 examples/sec; 0.024 sec/batch; 0h:36m:13s remains)
INFO - root - 2022-02-24 20:28:15.660790: step 107100, total loss = 0.54, batch loss = 0.27 (256.7 examples/sec; 0.031 sec/batch; 0h:48m:00s remains)
INFO - root - 2022-02-24 20:28:16.039117: step 107110, total loss = 0.54, batch loss = 0.28 (372.9 examples/sec; 0.021 sec/batch; 0h:33m:02s remains)
INFO - root - 2022-02-24 20:28:16.396544: step 107120, total loss = 0.56, batch loss = 0.29 (117.3 examples/sec; 0.068 sec/batch; 1h:45m:00s remains)
INFO - root - 2022-02-24 20:28:16.868364: step 107130, total loss = 0.53, batch loss = 0.27 (168.9 examples/sec; 0.047 sec/batch; 1h:12m:56s remains)
INFO - root - 2022-02-24 20:28:17.244625: step 107140, total loss = 0.56, batch loss = 0.30 (318.2 examples/sec; 0.025 sec/batch; 0h:38m:42s remains)
INFO - root - 2022-02-24 20:28:17.558413: step 107150, total loss = 0.57, batch loss = 0.31 (359.7 examples/sec; 0.022 sec/batch; 0h:34m:14s remains)
INFO - root - 2022-02-24 20:28:17.808303: step 107160, total loss = 0.50, batch loss = 0.24 (317.8 examples/sec; 0.025 sec/batch; 0h:38m:44s remains)
INFO - root - 2022-02-24 20:28:18.099962: step 107170, total loss = 0.47, batch loss = 0.21 (245.0 examples/sec; 0.033 sec/batch; 0h:50m:15s remains)
INFO - root - 2022-02-24 20:28:18.450232: step 107180, total loss = 0.60, batch loss = 0.34 (325.6 examples/sec; 0.025 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 20:28:18.802863: step 107190, total loss = 0.58, batch loss = 0.31 (165.9 examples/sec; 0.048 sec/batch; 1h:14m:11s remains)
INFO - root - 2022-02-24 20:28:19.130024: step 107200, total loss = 0.60, batch loss = 0.34 (328.8 examples/sec; 0.024 sec/batch; 0h:37m:25s remains)
INFO - root - 2022-02-24 20:28:19.467607: step 107210, total loss = 0.57, batch loss = 0.30 (322.9 examples/sec; 0.025 sec/batch; 0h:38m:06s remains)
INFO - root - 2022-02-24 20:28:19.729760: step 107220, total loss = 0.48, batch loss = 0.22 (349.3 examples/sec; 0.023 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:28:20.003618: step 107230, total loss = 0.46, batch loss = 0.20 (193.4 examples/sec; 0.041 sec/batch; 1h:03m:36s remains)
INFO - root - 2022-02-24 20:28:20.315425: step 107240, total loss = 0.52, batch loss = 0.26 (195.3 examples/sec; 0.041 sec/batch; 1h:02m:58s remains)
INFO - root - 2022-02-24 20:28:20.695652: step 107250, total loss = 0.55, batch loss = 0.29 (204.3 examples/sec; 0.039 sec/batch; 1h:00m:12s remains)
INFO - root - 2022-02-24 20:28:21.103378: step 107260, total loss = 0.60, batch loss = 0.34 (303.0 examples/sec; 0.026 sec/batch; 0h:40m:35s remains)
INFO - root - 2022-02-24 20:28:21.482210: step 107270, total loss = 0.54, batch loss = 0.28 (155.6 examples/sec; 0.051 sec/batch; 1h:19m:03s remains)
INFO - root - 2022-02-24 20:28:21.872593: step 107280, total loss = 0.52, batch loss = 0.26 (349.8 examples/sec; 0.023 sec/batch; 0h:35m:09s remains)
INFO - root - 2022-02-24 20:28:22.187185: step 107290, total loss = 0.58, batch loss = 0.32 (292.5 examples/sec; 0.027 sec/batch; 0h:42m:02s remains)
INFO - root - 2022-02-24 20:28:22.562089: step 107300, total loss = 0.63, batch loss = 0.36 (329.2 examples/sec; 0.024 sec/batch; 0h:37m:20s remains)
INFO - root - 2022-02-24 20:28:22.984779: step 107310, total loss = 0.58, batch loss = 0.32 (229.4 examples/sec; 0.035 sec/batch; 0h:53m:34s remains)
INFO - root - 2022-02-24 20:28:23.391600: step 107320, total loss = 0.55, batch loss = 0.28 (117.4 examples/sec; 0.068 sec/batch; 1h:44m:41s remains)
INFO - root - 2022-02-24 20:28:23.671477: step 107330, total loss = 0.52, batch loss = 0.26 (325.9 examples/sec; 0.025 sec/batch; 0h:37m:42s remains)
INFO - root - 2022-02-24 20:28:23.980829: step 107340, total loss = 0.64, batch loss = 0.38 (369.5 examples/sec; 0.022 sec/batch; 0h:33m:15s remains)
INFO - root - 2022-02-24 20:28:24.307471: step 107350, total loss = 0.52, batch loss = 0.26 (331.0 examples/sec; 0.024 sec/batch; 0h:37m:07s remains)
INFO - root - 2022-02-24 20:28:24.750520: step 107360, total loss = 0.55, batch loss = 0.29 (223.6 examples/sec; 0.036 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 20:28:25.118132: step 107370, total loss = 0.65, batch loss = 0.39 (144.9 examples/sec; 0.055 sec/batch; 1h:24m:47s remains)
INFO - root - 2022-02-24 20:28:25.664423: step 107380, total loss = 0.57, batch loss = 0.31 (227.9 examples/sec; 0.035 sec/batch; 0h:53m:54s remains)
INFO - root - 2022-02-24 20:28:26.058573: step 107390, total loss = 0.47, batch loss = 0.21 (183.2 examples/sec; 0.044 sec/batch; 1h:07m:01s remains)
INFO - root - 2022-02-24 20:28:26.413118: step 107400, total loss = 0.50, batch loss = 0.24 (307.0 examples/sec; 0.026 sec/batch; 0h:39m:59s remains)
INFO - root - 2022-02-24 20:28:27.288289: step 107410, total loss = 0.53, batch loss = 0.27 (155.0 examples/sec; 0.052 sec/batch; 1h:19m:12s remains)
INFO - root - 2022-02-24 20:28:27.662237: step 107420, total loss = 0.56, batch loss = 0.30 (205.1 examples/sec; 0.039 sec/batch; 0h:59m:52s remains)
INFO - root - 2022-02-24 20:28:28.103673: step 107430, total loss = 0.57, batch loss = 0.31 (307.0 examples/sec; 0.026 sec/batch; 0h:39m:59s remains)
INFO - root - 2022-02-24 20:28:28.447786: step 107440, total loss = 0.60, batch loss = 0.34 (257.2 examples/sec; 0.031 sec/batch; 0h:47m:43s remains)
INFO - root - 2022-02-24 20:28:28.889207: step 107450, total loss = 0.58, batch loss = 0.32 (189.6 examples/sec; 0.042 sec/batch; 1h:04m:43s remains)
INFO - root - 2022-02-24 20:28:29.352703: step 107460, total loss = 0.59, batch loss = 0.33 (232.9 examples/sec; 0.034 sec/batch; 0h:52m:42s remains)
INFO - root - 2022-02-24 20:28:29.942554: step 107470, total loss = 0.54, batch loss = 0.28 (137.4 examples/sec; 0.058 sec/batch; 1h:29m:18s remains)
INFO - root - 2022-02-24 20:28:30.286439: step 107480, total loss = 0.47, batch loss = 0.20 (329.2 examples/sec; 0.024 sec/batch; 0h:37m:16s remains)
INFO - root - 2022-02-24 20:28:30.702660: step 107490, total loss = 0.56, batch loss = 0.30 (297.9 examples/sec; 0.027 sec/batch; 0h:41m:10s remains)
INFO - root - 2022-02-24 20:28:31.111829: step 107500, total loss = 0.57, batch loss = 0.30 (262.8 examples/sec; 0.030 sec/batch; 0h:46m:40s remains)
INFO - root - 2022-02-24 20:28:31.602030: step 107510, total loss = 0.47, batch loss = 0.21 (357.5 examples/sec; 0.022 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:28:32.014082: step 107520, total loss = 0.56, batch loss = 0.29 (283.3 examples/sec; 0.028 sec/batch; 0h:43m:17s remains)
INFO - root - 2022-02-24 20:28:32.654634: step 107530, total loss = 0.76, batch loss = 0.50 (203.0 examples/sec; 0.039 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 20:28:33.005563: step 107540, total loss = 0.66, batch loss = 0.40 (317.9 examples/sec; 0.025 sec/batch; 0h:38m:33s remains)
INFO - root - 2022-02-24 20:28:33.337672: step 107550, total loss = 0.57, batch loss = 0.31 (327.4 examples/sec; 0.024 sec/batch; 0h:37m:26s remains)
INFO - root - 2022-02-24 20:28:33.701049: step 107560, total loss = 0.54, batch loss = 0.28 (178.5 examples/sec; 0.045 sec/batch; 1h:08m:40s remains)
INFO - root - 2022-02-24 20:28:34.090727: step 107570, total loss = 0.59, batch loss = 0.33 (279.3 examples/sec; 0.029 sec/batch; 0h:43m:52s remains)
INFO - root - 2022-02-24 20:28:34.382350: step 107580, total loss = 0.50, batch loss = 0.23 (373.0 examples/sec; 0.021 sec/batch; 0h:32m:51s remains)
INFO - root - 2022-02-24 20:28:34.702252: step 107590, total loss = 0.54, batch loss = 0.28 (343.7 examples/sec; 0.023 sec/batch; 0h:35m:39s remains)
INFO - root - 2022-02-24 20:28:35.139076: step 107600, total loss = 0.51, batch loss = 0.25 (82.1 examples/sec; 0.097 sec/batch; 2h:29m:10s remains)
INFO - root - 2022-02-24 20:28:35.635595: step 107610, total loss = 0.53, batch loss = 0.27 (329.8 examples/sec; 0.024 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:28:35.931836: step 107620, total loss = 0.63, batch loss = 0.37 (325.0 examples/sec; 0.025 sec/batch; 0h:37m:41s remains)
INFO - root - 2022-02-24 20:28:36.344094: step 107630, total loss = 0.60, batch loss = 0.33 (287.3 examples/sec; 0.028 sec/batch; 0h:42m:37s remains)
INFO - root - 2022-02-24 20:28:36.682587: step 107640, total loss = 0.54, batch loss = 0.28 (158.3 examples/sec; 0.051 sec/batch; 1h:17m:23s remains)
INFO - root - 2022-02-24 20:28:37.000137: step 107650, total loss = 0.51, batch loss = 0.25 (330.7 examples/sec; 0.024 sec/batch; 0h:37m:02s remains)
INFO - root - 2022-02-24 20:28:37.398776: step 107660, total loss = 0.54, batch loss = 0.27 (282.8 examples/sec; 0.028 sec/batch; 0h:43m:18s remains)
INFO - root - 2022-02-24 20:28:37.760716: step 107670, total loss = 0.53, batch loss = 0.26 (160.6 examples/sec; 0.050 sec/batch; 1h:16m:14s remains)
INFO - root - 2022-02-24 20:28:38.089715: step 107680, total loss = 0.59, batch loss = 0.33 (212.0 examples/sec; 0.038 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 20:28:38.458017: step 107690, total loss = 0.60, batch loss = 0.33 (230.7 examples/sec; 0.035 sec/batch; 0h:53m:03s remains)
INFO - root - 2022-02-24 20:28:38.737241: step 107700, total loss = 0.72, batch loss = 0.46 (293.4 examples/sec; 0.027 sec/batch; 0h:41m:42s remains)
INFO - root - 2022-02-24 20:28:39.158076: step 107710, total loss = 0.49, batch loss = 0.23 (248.3 examples/sec; 0.032 sec/batch; 0h:49m:17s remains)
INFO - root - 2022-02-24 20:28:39.525611: step 107720, total loss = 0.51, batch loss = 0.24 (364.7 examples/sec; 0.022 sec/batch; 0h:33m:33s remains)
INFO - root - 2022-02-24 20:28:39.854140: step 107730, total loss = 0.54, batch loss = 0.27 (193.2 examples/sec; 0.041 sec/batch; 1h:03m:19s remains)
INFO - root - 2022-02-24 20:28:40.139209: step 107740, total loss = 0.55, batch loss = 0.29 (352.3 examples/sec; 0.023 sec/batch; 0h:34m:43s remains)
INFO - root - 2022-02-24 20:28:40.390266: step 107750, total loss = 0.61, batch loss = 0.35 (359.1 examples/sec; 0.022 sec/batch; 0h:34m:03s remains)
INFO - root - 2022-02-24 20:28:40.773420: step 107760, total loss = 0.60, batch loss = 0.34 (194.5 examples/sec; 0.041 sec/batch; 1h:02m:52s remains)
INFO - root - 2022-02-24 20:28:41.095116: step 107770, total loss = 0.51, batch loss = 0.24 (250.7 examples/sec; 0.032 sec/batch; 0h:48m:46s remains)
INFO - root - 2022-02-24 20:28:41.426275: step 107780, total loss = 0.49, batch loss = 0.23 (182.1 examples/sec; 0.044 sec/batch; 1h:07m:10s remains)
INFO - root - 2022-02-24 20:28:41.834398: step 107790, total loss = 0.64, batch loss = 0.38 (314.9 examples/sec; 0.025 sec/batch; 0h:38m:49s remains)
INFO - root - 2022-02-24 20:28:42.102284: step 107800, total loss = 0.60, batch loss = 0.34 (348.0 examples/sec; 0.023 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:28:42.525123: step 107810, total loss = 0.56, batch loss = 0.29 (173.9 examples/sec; 0.046 sec/batch; 1h:10m:18s remains)
INFO - root - 2022-02-24 20:28:42.842856: step 107820, total loss = 0.57, batch loss = 0.31 (360.7 examples/sec; 0.022 sec/batch; 0h:33m:53s remains)
INFO - root - 2022-02-24 20:28:43.309762: step 107830, total loss = 0.52, batch loss = 0.26 (301.2 examples/sec; 0.027 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:28:43.669351: step 107840, total loss = 0.52, batch loss = 0.26 (300.9 examples/sec; 0.027 sec/batch; 0h:40m:37s remains)
INFO - root - 2022-02-24 20:28:43.926702: step 107850, total loss = 0.53, batch loss = 0.27 (364.8 examples/sec; 0.022 sec/batch; 0h:33m:30s remains)
INFO - root - 2022-02-24 20:28:44.266523: step 107860, total loss = 0.67, batch loss = 0.41 (297.7 examples/sec; 0.027 sec/batch; 0h:41m:02s remains)
INFO - root - 2022-02-24 20:28:44.550355: step 107870, total loss = 0.52, batch loss = 0.26 (241.9 examples/sec; 0.033 sec/batch; 0h:50m:30s remains)
INFO - root - 2022-02-24 20:28:44.936174: step 107880, total loss = 0.54, batch loss = 0.28 (204.6 examples/sec; 0.039 sec/batch; 0h:59m:43s remains)
INFO - root - 2022-02-24 20:28:45.355168: step 107890, total loss = 0.58, batch loss = 0.32 (338.4 examples/sec; 0.024 sec/batch; 0h:36m:05s remains)
INFO - root - 2022-02-24 20:28:45.779765: step 107900, total loss = 0.70, batch loss = 0.44 (125.5 examples/sec; 0.064 sec/batch; 1h:37m:17s remains)
INFO - root - 2022-02-24 20:28:46.124033: step 107910, total loss = 0.57, batch loss = 0.31 (343.3 examples/sec; 0.023 sec/batch; 0h:35m:34s remains)
INFO - root - 2022-02-24 20:28:46.401532: step 107920, total loss = 0.50, batch loss = 0.24 (273.6 examples/sec; 0.029 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:28:46.668899: step 107930, total loss = 0.54, batch loss = 0.28 (273.0 examples/sec; 0.029 sec/batch; 0h:44m:43s remains)
INFO - root - 2022-02-24 20:28:47.132878: step 107940, total loss = 0.56, batch loss = 0.29 (284.3 examples/sec; 0.028 sec/batch; 0h:42m:56s remains)
INFO - root - 2022-02-24 20:28:47.514730: step 107950, total loss = 0.49, batch loss = 0.23 (278.7 examples/sec; 0.029 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:28:47.819731: step 107960, total loss = 0.55, batch loss = 0.29 (411.5 examples/sec; 0.019 sec/batch; 0h:29m:39s remains)
INFO - root - 2022-02-24 20:28:48.120414: step 107970, total loss = 0.50, batch loss = 0.24 (343.8 examples/sec; 0.023 sec/batch; 0h:35m:29s remains)
INFO - root - 2022-02-24 20:28:48.405644: step 107980, total loss = 0.55, batch loss = 0.29 (328.8 examples/sec; 0.024 sec/batch; 0h:37m:06s remains)
INFO - root - 2022-02-24 20:28:48.673049: step 107990, total loss = 0.53, batch loss = 0.27 (351.2 examples/sec; 0.023 sec/batch; 0h:34m:44s remains)
INFO - root - 2022-02-24 20:28:49.006383: step 108000, total loss = 0.53, batch loss = 0.27 (289.8 examples/sec; 0.028 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 20:28:49.515308: step 108010, total loss = 0.73, batch loss = 0.46 (219.3 examples/sec; 0.036 sec/batch; 0h:55m:36s remains)
INFO - root - 2022-02-24 20:28:49.960630: step 108020, total loss = 0.53, batch loss = 0.27 (103.9 examples/sec; 0.077 sec/batch; 1h:57m:24s remains)
INFO - root - 2022-02-24 20:28:50.298193: step 108030, total loss = 0.63, batch loss = 0.36 (233.5 examples/sec; 0.034 sec/batch; 0h:52m:13s remains)
INFO - root - 2022-02-24 20:28:50.769176: step 108040, total loss = 0.49, batch loss = 0.23 (112.9 examples/sec; 0.071 sec/batch; 1h:47m:58s remains)
INFO - root - 2022-02-24 20:28:51.155657: step 108050, total loss = 0.55, batch loss = 0.29 (166.6 examples/sec; 0.048 sec/batch; 1h:13m:11s remains)
INFO - root - 2022-02-24 20:28:51.695017: step 108060, total loss = 0.55, batch loss = 0.28 (79.6 examples/sec; 0.101 sec/batch; 2h:33m:10s remains)
INFO - root - 2022-02-24 20:28:52.673227: step 108070, total loss = 0.57, batch loss = 0.30 (15.2 examples/sec; 0.525 sec/batch; 13h:19m:58s remains)
INFO - root - 2022-02-24 20:28:53.068313: step 108080, total loss = 0.55, batch loss = 0.29 (104.7 examples/sec; 0.076 sec/batch; 1h:56m:26s remains)
INFO - root - 2022-02-24 20:28:53.442137: step 108090, total loss = 0.56, batch loss = 0.29 (194.2 examples/sec; 0.041 sec/batch; 1h:02m:45s remains)
INFO - root - 2022-02-24 20:28:53.822198: step 108100, total loss = 0.56, batch loss = 0.30 (236.9 examples/sec; 0.034 sec/batch; 0h:51m:26s remains)
INFO - root - 2022-02-24 20:28:54.321625: step 108110, total loss = 0.56, batch loss = 0.30 (292.3 examples/sec; 0.027 sec/batch; 0h:41m:41s remains)
INFO - root - 2022-02-24 20:28:54.695463: step 108120, total loss = 0.52, batch loss = 0.26 (159.4 examples/sec; 0.050 sec/batch; 1h:16m:27s remains)
INFO - root - 2022-02-24 20:28:55.098338: step 108130, total loss = 0.55, batch loss = 0.29 (342.7 examples/sec; 0.023 sec/batch; 0h:35m:32s remains)
INFO - root - 2022-02-24 20:28:55.563105: step 108140, total loss = 0.75, batch loss = 0.48 (216.1 examples/sec; 0.037 sec/batch; 0h:56m:22s remains)
INFO - root - 2022-02-24 20:28:56.005186: step 108150, total loss = 0.59, batch loss = 0.33 (269.5 examples/sec; 0.030 sec/batch; 0h:45m:11s remains)
INFO - root - 2022-02-24 20:28:56.447623: step 108160, total loss = 0.53, batch loss = 0.27 (277.5 examples/sec; 0.029 sec/batch; 0h:43m:53s remains)
INFO - root - 2022-02-24 20:28:56.754299: step 108170, total loss = 0.57, batch loss = 0.31 (313.4 examples/sec; 0.026 sec/batch; 0h:38m:51s remains)
INFO - root - 2022-02-24 20:28:57.066699: step 108180, total loss = 0.48, batch loss = 0.22 (282.9 examples/sec; 0.028 sec/batch; 0h:43m:02s remains)
INFO - root - 2022-02-24 20:28:57.442564: step 108190, total loss = 0.55, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 3h:51m:36s remains)
INFO - root - 2022-02-24 20:28:57.948807: step 108200, total loss = 0.55, batch loss = 0.29 (203.7 examples/sec; 0.039 sec/batch; 0h:59m:46s remains)
INFO - root - 2022-02-24 20:28:58.401906: step 108210, total loss = 0.58, batch loss = 0.32 (337.0 examples/sec; 0.024 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:28:58.675912: step 108220, total loss = 0.59, batch loss = 0.32 (323.8 examples/sec; 0.025 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:28:59.037245: step 108230, total loss = 0.61, batch loss = 0.35 (352.3 examples/sec; 0.023 sec/batch; 0h:34m:32s remains)
INFO - root - 2022-02-24 20:28:59.414172: step 108240, total loss = 0.53, batch loss = 0.26 (334.3 examples/sec; 0.024 sec/batch; 0h:36m:23s remains)
INFO - root - 2022-02-24 20:28:59.838625: step 108250, total loss = 0.53, batch loss = 0.27 (148.4 examples/sec; 0.054 sec/batch; 1h:22m:00s remains)
INFO - root - 2022-02-24 20:29:00.293106: step 108260, total loss = 0.57, batch loss = 0.31 (233.0 examples/sec; 0.034 sec/batch; 0h:52m:12s remains)
INFO - root - 2022-02-24 20:29:00.608774: step 108270, total loss = 0.68, batch loss = 0.42 (339.3 examples/sec; 0.024 sec/batch; 0h:35m:51s remains)
INFO - root - 2022-02-24 20:29:00.930744: step 108280, total loss = 0.53, batch loss = 0.27 (351.8 examples/sec; 0.023 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:29:01.261121: step 108290, total loss = 0.54, batch loss = 0.28 (186.1 examples/sec; 0.043 sec/batch; 1h:05m:21s remains)
INFO - root - 2022-02-24 20:29:01.681195: step 108300, total loss = 0.55, batch loss = 0.28 (272.7 examples/sec; 0.029 sec/batch; 0h:44m:35s remains)
INFO - root - 2022-02-24 20:29:02.142240: step 108310, total loss = 0.47, batch loss = 0.21 (106.0 examples/sec; 0.075 sec/batch; 1h:54m:41s remains)
INFO - root - 2022-02-24 20:29:02.513350: step 108320, total loss = 0.51, batch loss = 0.25 (226.4 examples/sec; 0.035 sec/batch; 0h:53m:42s remains)
INFO - root - 2022-02-24 20:29:02.823022: step 108330, total loss = 0.50, batch loss = 0.24 (200.3 examples/sec; 0.040 sec/batch; 1h:00m:40s remains)
INFO - root - 2022-02-24 20:29:03.163043: step 108340, total loss = 0.50, batch loss = 0.24 (241.9 examples/sec; 0.033 sec/batch; 0h:50m:14s remains)
INFO - root - 2022-02-24 20:29:03.496553: step 108350, total loss = 0.56, batch loss = 0.30 (246.1 examples/sec; 0.033 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:29:03.796175: step 108360, total loss = 0.55, batch loss = 0.29 (353.9 examples/sec; 0.023 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:29:04.192485: step 108370, total loss = 0.52, batch loss = 0.26 (164.7 examples/sec; 0.049 sec/batch; 1h:13m:45s remains)
INFO - root - 2022-02-24 20:29:04.545556: step 108380, total loss = 0.54, batch loss = 0.27 (152.3 examples/sec; 0.053 sec/batch; 1h:19m:47s remains)
INFO - root - 2022-02-24 20:29:04.860250: step 108390, total loss = 0.48, batch loss = 0.22 (191.1 examples/sec; 0.042 sec/batch; 1h:03m:34s remains)
INFO - root - 2022-02-24 20:29:05.163059: step 108400, total loss = 0.54, batch loss = 0.28 (329.7 examples/sec; 0.024 sec/batch; 0h:36m:50s remains)
INFO - root - 2022-02-24 20:29:05.522497: step 108410, total loss = 0.54, batch loss = 0.28 (325.4 examples/sec; 0.025 sec/batch; 0h:37m:19s remains)
INFO - root - 2022-02-24 20:29:05.774953: step 108420, total loss = 0.60, batch loss = 0.34 (288.0 examples/sec; 0.028 sec/batch; 0h:42m:09s remains)
INFO - root - 2022-02-24 20:29:06.280369: step 108430, total loss = 0.59, batch loss = 0.32 (243.9 examples/sec; 0.033 sec/batch; 0h:49m:47s remains)
INFO - root - 2022-02-24 20:29:06.616853: step 108440, total loss = 0.52, batch loss = 0.26 (340.6 examples/sec; 0.023 sec/batch; 0h:35m:38s remains)
INFO - root - 2022-02-24 20:29:06.905907: step 108450, total loss = 0.68, batch loss = 0.42 (302.8 examples/sec; 0.026 sec/batch; 0h:40m:05s remains)
INFO - root - 2022-02-24 20:29:07.252891: step 108460, total loss = 0.55, batch loss = 0.29 (270.3 examples/sec; 0.030 sec/batch; 0h:44m:54s remains)
INFO - root - 2022-02-24 20:29:07.617142: step 108470, total loss = 0.56, batch loss = 0.30 (159.3 examples/sec; 0.050 sec/batch; 1h:16m:11s remains)
INFO - root - 2022-02-24 20:29:08.344752: step 108480, total loss = 0.51, batch loss = 0.25 (23.1 examples/sec; 0.347 sec/batch; 8h:46m:02s remains)
INFO - root - 2022-02-24 20:29:08.870564: step 108490, total loss = 0.50, batch loss = 0.23 (329.9 examples/sec; 0.024 sec/batch; 0h:36m:46s remains)
INFO - root - 2022-02-24 20:29:09.307494: step 108500, total loss = 0.60, batch loss = 0.34 (332.9 examples/sec; 0.024 sec/batch; 0h:36m:26s remains)
INFO - root - 2022-02-24 20:29:09.780771: step 108510, total loss = 0.67, batch loss = 0.41 (314.0 examples/sec; 0.025 sec/batch; 0h:38m:37s remains)
INFO - root - 2022-02-24 20:29:10.099012: step 108520, total loss = 0.50, batch loss = 0.24 (172.4 examples/sec; 0.046 sec/batch; 1h:10m:22s remains)
INFO - root - 2022-02-24 20:29:10.522612: step 108530, total loss = 0.53, batch loss = 0.27 (182.4 examples/sec; 0.044 sec/batch; 1h:06m:30s remains)
INFO - root - 2022-02-24 20:29:10.882586: step 108540, total loss = 0.50, batch loss = 0.24 (261.1 examples/sec; 0.031 sec/batch; 0h:46m:26s remains)
INFO - root - 2022-02-24 20:29:11.221844: step 108550, total loss = 0.47, batch loss = 0.21 (229.9 examples/sec; 0.035 sec/batch; 0h:52m:44s remains)
INFO - root - 2022-02-24 20:29:11.555258: step 108560, total loss = 0.50, batch loss = 0.24 (322.6 examples/sec; 0.025 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:29:11.878234: step 108570, total loss = 0.55, batch loss = 0.28 (362.6 examples/sec; 0.022 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:29:12.348576: step 108580, total loss = 0.46, batch loss = 0.20 (302.9 examples/sec; 0.026 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:29:12.691637: step 108590, total loss = 0.59, batch loss = 0.33 (221.3 examples/sec; 0.036 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:29:13.412729: step 108600, total loss = 0.51, batch loss = 0.25 (19.9 examples/sec; 0.403 sec/batch; 10h:10m:13s remains)
INFO - root - 2022-02-24 20:29:13.892737: step 108610, total loss = 0.55, batch loss = 0.29 (152.4 examples/sec; 0.052 sec/batch; 1h:19m:31s remains)
INFO - root - 2022-02-24 20:29:14.451329: step 108620, total loss = 0.50, batch loss = 0.24 (220.9 examples/sec; 0.036 sec/batch; 0h:54m:50s remains)
INFO - root - 2022-02-24 20:29:14.818280: step 108630, total loss = 0.58, batch loss = 0.31 (309.1 examples/sec; 0.026 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 20:29:15.118446: step 108640, total loss = 0.60, batch loss = 0.33 (238.0 examples/sec; 0.034 sec/batch; 0h:50m:54s remains)
INFO - root - 2022-02-24 20:29:15.430895: step 108650, total loss = 0.59, batch loss = 0.33 (205.8 examples/sec; 0.039 sec/batch; 0h:58m:50s remains)
INFO - root - 2022-02-24 20:29:15.743652: step 108660, total loss = 0.56, batch loss = 0.30 (325.7 examples/sec; 0.025 sec/batch; 0h:37m:11s remains)
INFO - root - 2022-02-24 20:29:16.075666: step 108670, total loss = 0.54, batch loss = 0.28 (304.4 examples/sec; 0.026 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:29:16.477292: step 108680, total loss = 0.57, batch loss = 0.30 (341.2 examples/sec; 0.023 sec/batch; 0h:35m:29s remains)
INFO - root - 2022-02-24 20:29:16.954426: step 108690, total loss = 0.59, batch loss = 0.33 (339.7 examples/sec; 0.024 sec/batch; 0h:35m:38s remains)
INFO - root - 2022-02-24 20:29:17.253062: step 108700, total loss = 0.51, batch loss = 0.24 (319.5 examples/sec; 0.025 sec/batch; 0h:37m:53s remains)
INFO - root - 2022-02-24 20:29:17.615469: step 108710, total loss = 0.48, batch loss = 0.22 (283.5 examples/sec; 0.028 sec/batch; 0h:42m:41s remains)
INFO - root - 2022-02-24 20:29:17.939249: step 108720, total loss = 0.57, batch loss = 0.31 (185.0 examples/sec; 0.043 sec/batch; 1h:05m:25s remains)
INFO - root - 2022-02-24 20:29:18.264006: step 108730, total loss = 0.57, batch loss = 0.31 (215.0 examples/sec; 0.037 sec/batch; 0h:56m:17s remains)
INFO - root - 2022-02-24 20:29:18.738163: step 108740, total loss = 0.51, batch loss = 0.25 (253.2 examples/sec; 0.032 sec/batch; 0h:47m:47s remains)
INFO - root - 2022-02-24 20:29:19.130427: step 108750, total loss = 0.75, batch loss = 0.48 (231.0 examples/sec; 0.035 sec/batch; 0h:52m:22s remains)
INFO - root - 2022-02-24 20:29:19.457919: step 108760, total loss = 0.49, batch loss = 0.22 (212.1 examples/sec; 0.038 sec/batch; 0h:57m:02s remains)
INFO - root - 2022-02-24 20:29:19.762331: step 108770, total loss = 0.53, batch loss = 0.27 (225.2 examples/sec; 0.036 sec/batch; 0h:53m:42s remains)
INFO - root - 2022-02-24 20:29:20.066879: step 108780, total loss = 0.44, batch loss = 0.18 (226.9 examples/sec; 0.035 sec/batch; 0h:53m:19s remains)
INFO - root - 2022-02-24 20:29:20.464808: step 108790, total loss = 0.54, batch loss = 0.27 (90.5 examples/sec; 0.088 sec/batch; 2h:13m:40s remains)
INFO - root - 2022-02-24 20:29:20.904175: step 108800, total loss = 0.49, batch loss = 0.23 (81.5 examples/sec; 0.098 sec/batch; 2h:28m:25s remains)
INFO - root - 2022-02-24 20:29:21.344140: step 108810, total loss = 0.54, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 0h:36m:38s remains)
INFO - root - 2022-02-24 20:29:21.599741: step 108820, total loss = 0.59, batch loss = 0.33 (356.9 examples/sec; 0.022 sec/batch; 0h:33m:52s remains)
INFO - root - 2022-02-24 20:29:21.946944: step 108830, total loss = 0.52, batch loss = 0.25 (232.9 examples/sec; 0.034 sec/batch; 0h:51m:54s remains)
INFO - root - 2022-02-24 20:29:22.300289: step 108840, total loss = 0.57, batch loss = 0.30 (129.9 examples/sec; 0.062 sec/batch; 1h:33m:05s remains)
INFO - root - 2022-02-24 20:29:22.635436: step 108850, total loss = 0.56, batch loss = 0.30 (237.3 examples/sec; 0.034 sec/batch; 0h:50m:56s remains)
INFO - root - 2022-02-24 20:29:23.077596: step 108860, total loss = 0.48, batch loss = 0.22 (302.9 examples/sec; 0.026 sec/batch; 0h:39m:53s remains)
INFO - root - 2022-02-24 20:29:23.329399: step 108870, total loss = 0.51, batch loss = 0.25 (230.1 examples/sec; 0.035 sec/batch; 0h:52m:31s remains)
INFO - root - 2022-02-24 20:29:23.702282: step 108880, total loss = 0.56, batch loss = 0.30 (281.2 examples/sec; 0.028 sec/batch; 0h:42m:58s remains)
INFO - root - 2022-02-24 20:29:24.032234: step 108890, total loss = 0.66, batch loss = 0.40 (377.9 examples/sec; 0.021 sec/batch; 0h:31m:58s remains)
INFO - root - 2022-02-24 20:29:24.391508: step 108900, total loss = 0.54, batch loss = 0.28 (361.1 examples/sec; 0.022 sec/batch; 0h:33m:27s remains)
INFO - root - 2022-02-24 20:29:24.806736: step 108910, total loss = 0.53, batch loss = 0.26 (355.2 examples/sec; 0.023 sec/batch; 0h:34m:00s remains)
INFO - root - 2022-02-24 20:29:25.209488: step 108920, total loss = 0.48, batch loss = 0.21 (228.8 examples/sec; 0.035 sec/batch; 0h:52m:47s remains)
INFO - root - 2022-02-24 20:29:25.715378: step 108930, total loss = 0.61, batch loss = 0.34 (132.5 examples/sec; 0.060 sec/batch; 1h:31m:08s remains)
INFO - root - 2022-02-24 20:29:26.209632: step 108940, total loss = 0.58, batch loss = 0.32 (117.4 examples/sec; 0.068 sec/batch; 1h:42m:48s remains)
INFO - root - 2022-02-24 20:29:26.679638: step 108950, total loss = 0.49, batch loss = 0.23 (158.5 examples/sec; 0.050 sec/batch; 1h:16m:09s remains)
INFO - root - 2022-02-24 20:29:27.128183: step 108960, total loss = 0.53, batch loss = 0.27 (198.5 examples/sec; 0.040 sec/batch; 1h:00m:48s remains)
INFO - root - 2022-02-24 20:29:27.540673: step 108970, total loss = 0.43, batch loss = 0.17 (304.1 examples/sec; 0.026 sec/batch; 0h:39m:41s remains)
INFO - root - 2022-02-24 20:29:27.866060: step 108980, total loss = 0.49, batch loss = 0.23 (289.0 examples/sec; 0.028 sec/batch; 0h:41m:45s remains)
INFO - root - 2022-02-24 20:29:28.187103: step 108990, total loss = 0.62, batch loss = 0.36 (333.0 examples/sec; 0.024 sec/batch; 0h:36m:14s remains)
INFO - root - 2022-02-24 20:29:28.472637: step 109000, total loss = 0.51, batch loss = 0.25 (353.8 examples/sec; 0.023 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:29:29.450947: step 109010, total loss = 0.52, batch loss = 0.25 (132.8 examples/sec; 0.060 sec/batch; 1h:30m:52s remains)
INFO - root - 2022-02-24 20:29:29.911928: step 109020, total loss = 0.59, batch loss = 0.33 (160.1 examples/sec; 0.050 sec/batch; 1h:15m:20s remains)
INFO - root - 2022-02-24 20:29:30.204940: step 109030, total loss = 0.51, batch loss = 0.25 (334.4 examples/sec; 0.024 sec/batch; 0h:36m:04s remains)
INFO - root - 2022-02-24 20:29:30.565423: step 109040, total loss = 0.62, batch loss = 0.36 (151.3 examples/sec; 0.053 sec/batch; 1h:19m:43s remains)
INFO - root - 2022-02-24 20:29:30.932096: step 109050, total loss = 0.62, batch loss = 0.36 (188.8 examples/sec; 0.042 sec/batch; 1h:03m:52s remains)
INFO - root - 2022-02-24 20:29:31.374513: step 109060, total loss = 0.54, batch loss = 0.28 (114.4 examples/sec; 0.070 sec/batch; 1h:45m:23s remains)
INFO - root - 2022-02-24 20:29:31.778719: step 109070, total loss = 0.69, batch loss = 0.43 (277.2 examples/sec; 0.029 sec/batch; 0h:43m:29s remains)
INFO - root - 2022-02-24 20:29:32.117710: step 109080, total loss = 0.61, batch loss = 0.35 (261.1 examples/sec; 0.031 sec/batch; 0h:46m:10s remains)
INFO - root - 2022-02-24 20:29:32.387686: step 109090, total loss = 0.61, batch loss = 0.35 (322.3 examples/sec; 0.025 sec/batch; 0h:37m:24s remains)
INFO - root - 2022-02-24 20:29:32.679001: step 109100, total loss = 0.52, batch loss = 0.26 (337.4 examples/sec; 0.024 sec/batch; 0h:35m:43s remains)
INFO - root - 2022-02-24 20:29:33.040687: step 109110, total loss = 0.56, batch loss = 0.30 (235.8 examples/sec; 0.034 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:29:33.472491: step 109120, total loss = 0.54, batch loss = 0.28 (123.7 examples/sec; 0.065 sec/batch; 1h:37m:27s remains)
INFO - root - 2022-02-24 20:29:33.833829: step 109130, total loss = 0.67, batch loss = 0.41 (301.6 examples/sec; 0.027 sec/batch; 0h:39m:57s remains)
INFO - root - 2022-02-24 20:29:34.147408: step 109140, total loss = 0.58, batch loss = 0.31 (332.8 examples/sec; 0.024 sec/batch; 0h:36m:11s remains)
INFO - root - 2022-02-24 20:29:34.452747: step 109150, total loss = 0.72, batch loss = 0.46 (351.0 examples/sec; 0.023 sec/batch; 0h:34m:19s remains)
INFO - root - 2022-02-24 20:29:34.753177: step 109160, total loss = 0.61, batch loss = 0.35 (311.4 examples/sec; 0.026 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:29:35.252544: step 109170, total loss = 0.54, batch loss = 0.28 (115.3 examples/sec; 0.069 sec/batch; 1h:44m:27s remains)
INFO - root - 2022-02-24 20:29:35.610385: step 109180, total loss = 0.50, batch loss = 0.24 (346.0 examples/sec; 0.023 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:29:35.913769: step 109190, total loss = 0.50, batch loss = 0.24 (171.1 examples/sec; 0.047 sec/batch; 1h:10m:23s remains)
INFO - root - 2022-02-24 20:29:36.251201: step 109200, total loss = 0.55, batch loss = 0.29 (194.0 examples/sec; 0.041 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 20:29:36.623795: step 109210, total loss = 0.55, batch loss = 0.28 (341.3 examples/sec; 0.023 sec/batch; 0h:35m:16s remains)
INFO - root - 2022-02-24 20:29:36.954630: step 109220, total loss = 0.58, batch loss = 0.32 (318.6 examples/sec; 0.025 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:29:37.299162: step 109230, total loss = 0.50, batch loss = 0.24 (175.2 examples/sec; 0.046 sec/batch; 1h:08m:41s remains)
INFO - root - 2022-02-24 20:29:37.727096: step 109240, total loss = 0.52, batch loss = 0.26 (127.2 examples/sec; 0.063 sec/batch; 1h:34m:38s remains)
INFO - root - 2022-02-24 20:29:38.021712: step 109250, total loss = 0.66, batch loss = 0.40 (334.4 examples/sec; 0.024 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:29:38.313305: step 109260, total loss = 0.54, batch loss = 0.27 (154.6 examples/sec; 0.052 sec/batch; 1h:17m:49s remains)
INFO - root - 2022-02-24 20:29:38.643348: step 109270, total loss = 0.46, batch loss = 0.20 (225.9 examples/sec; 0.035 sec/batch; 0h:53m:15s remains)
INFO - root - 2022-02-24 20:29:38.943010: step 109280, total loss = 0.58, batch loss = 0.32 (270.0 examples/sec; 0.030 sec/batch; 0h:44m:33s remains)
INFO - root - 2022-02-24 20:29:39.386920: step 109290, total loss = 0.49, batch loss = 0.23 (216.7 examples/sec; 0.037 sec/batch; 0h:55m:30s remains)
INFO - root - 2022-02-24 20:29:39.762327: step 109300, total loss = 0.57, batch loss = 0.30 (198.1 examples/sec; 0.040 sec/batch; 1h:00m:42s remains)
INFO - root - 2022-02-24 20:29:40.195970: step 109310, total loss = 0.57, batch loss = 0.31 (223.8 examples/sec; 0.036 sec/batch; 0h:53m:43s remains)
INFO - root - 2022-02-24 20:29:40.469124: step 109320, total loss = 0.55, batch loss = 0.29 (298.4 examples/sec; 0.027 sec/batch; 0h:40m:17s remains)
INFO - root - 2022-02-24 20:29:40.794815: step 109330, total loss = 0.52, batch loss = 0.26 (285.5 examples/sec; 0.028 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:29:41.188266: step 109340, total loss = 0.53, batch loss = 0.27 (189.8 examples/sec; 0.042 sec/batch; 1h:03m:20s remains)
INFO - root - 2022-02-24 20:29:41.613312: step 109350, total loss = 0.60, batch loss = 0.34 (156.8 examples/sec; 0.051 sec/batch; 1h:16m:38s remains)
INFO - root - 2022-02-24 20:29:42.012177: step 109360, total loss = 0.72, batch loss = 0.45 (150.9 examples/sec; 0.053 sec/batch; 1h:19m:38s remains)
INFO - root - 2022-02-24 20:29:42.385427: step 109370, total loss = 0.53, batch loss = 0.26 (185.0 examples/sec; 0.043 sec/batch; 1h:04m:56s remains)
INFO - root - 2022-02-24 20:29:42.843926: step 109380, total loss = 0.62, batch loss = 0.36 (85.4 examples/sec; 0.094 sec/batch; 2h:20m:41s remains)
INFO - root - 2022-02-24 20:29:43.394039: step 109390, total loss = 0.51, batch loss = 0.25 (165.8 examples/sec; 0.048 sec/batch; 1h:12m:26s remains)
INFO - root - 2022-02-24 20:29:43.834705: step 109400, total loss = 0.58, batch loss = 0.31 (236.8 examples/sec; 0.034 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 20:29:44.703842: step 109410, total loss = 0.48, batch loss = 0.22 (307.2 examples/sec; 0.026 sec/batch; 0h:39m:05s remains)
INFO - root - 2022-02-24 20:29:44.999858: step 109420, total loss = 0.56, batch loss = 0.30 (347.5 examples/sec; 0.023 sec/batch; 0h:34m:33s remains)
INFO - root - 2022-02-24 20:29:45.283945: step 109430, total loss = 0.59, batch loss = 0.32 (309.9 examples/sec; 0.026 sec/batch; 0h:38m:45s remains)
INFO - root - 2022-02-24 20:29:45.611935: step 109440, total loss = 0.57, batch loss = 0.30 (291.5 examples/sec; 0.027 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:29:45.951660: step 109450, total loss = 0.56, batch loss = 0.30 (97.2 examples/sec; 0.082 sec/batch; 2h:03m:27s remains)
INFO - root - 2022-02-24 20:29:46.412124: step 109460, total loss = 0.53, batch loss = 0.26 (153.7 examples/sec; 0.052 sec/batch; 1h:18m:05s remains)
INFO - root - 2022-02-24 20:29:46.730048: step 109470, total loss = 0.53, batch loss = 0.26 (232.2 examples/sec; 0.034 sec/batch; 0h:51m:41s remains)
INFO - root - 2022-02-24 20:29:47.026654: step 109480, total loss = 0.64, batch loss = 0.37 (332.1 examples/sec; 0.024 sec/batch; 0h:36m:08s remains)
INFO - root - 2022-02-24 20:29:47.325178: step 109490, total loss = 0.54, batch loss = 0.28 (298.6 examples/sec; 0.027 sec/batch; 0h:40m:11s remains)
INFO - root - 2022-02-24 20:29:47.683845: step 109500, total loss = 0.56, batch loss = 0.30 (205.2 examples/sec; 0.039 sec/batch; 0h:58m:27s remains)
INFO - root - 2022-02-24 20:29:48.284647: step 109510, total loss = 0.58, batch loss = 0.32 (134.8 examples/sec; 0.059 sec/batch; 1h:29m:00s remains)
INFO - root - 2022-02-24 20:29:48.620426: step 109520, total loss = 0.60, batch loss = 0.34 (309.4 examples/sec; 0.026 sec/batch; 0h:38m:46s remains)
INFO - root - 2022-02-24 20:29:48.930319: step 109530, total loss = 0.45, batch loss = 0.19 (296.2 examples/sec; 0.027 sec/batch; 0h:40m:30s remains)
INFO - root - 2022-02-24 20:29:49.258045: step 109540, total loss = 0.51, batch loss = 0.25 (332.5 examples/sec; 0.024 sec/batch; 0h:36m:04s remains)
INFO - root - 2022-02-24 20:29:49.614474: step 109550, total loss = 0.53, batch loss = 0.27 (204.0 examples/sec; 0.039 sec/batch; 0h:58m:46s remains)
INFO - root - 2022-02-24 20:29:50.002392: step 109560, total loss = 0.63, batch loss = 0.37 (199.3 examples/sec; 0.040 sec/batch; 1h:00m:10s remains)
INFO - root - 2022-02-24 20:29:50.443717: step 109570, total loss = 0.59, batch loss = 0.33 (92.0 examples/sec; 0.087 sec/batch; 2h:10m:17s remains)
INFO - root - 2022-02-24 20:29:50.799650: step 109580, total loss = 0.48, batch loss = 0.22 (231.7 examples/sec; 0.035 sec/batch; 0h:51m:45s remains)
INFO - root - 2022-02-24 20:29:51.157069: step 109590, total loss = 0.61, batch loss = 0.35 (275.8 examples/sec; 0.029 sec/batch; 0h:43m:28s remains)
INFO - root - 2022-02-24 20:29:51.498888: step 109600, total loss = 0.60, batch loss = 0.34 (246.8 examples/sec; 0.032 sec/batch; 0h:48m:34s remains)
INFO - root - 2022-02-24 20:29:51.894831: step 109610, total loss = 0.54, batch loss = 0.28 (332.5 examples/sec; 0.024 sec/batch; 0h:36m:02s remains)
INFO - root - 2022-02-24 20:29:52.347715: step 109620, total loss = 0.51, batch loss = 0.25 (155.6 examples/sec; 0.051 sec/batch; 1h:17m:00s remains)
INFO - root - 2022-02-24 20:29:52.766777: step 109630, total loss = 0.68, batch loss = 0.42 (156.9 examples/sec; 0.051 sec/batch; 1h:16m:21s remains)
INFO - root - 2022-02-24 20:29:53.069239: step 109640, total loss = 0.57, batch loss = 0.31 (236.7 examples/sec; 0.034 sec/batch; 0h:50m:36s remains)
INFO - root - 2022-02-24 20:29:53.339203: step 109650, total loss = 0.64, batch loss = 0.37 (329.7 examples/sec; 0.024 sec/batch; 0h:36m:20s remains)
INFO - root - 2022-02-24 20:29:53.574539: step 109660, total loss = 0.58, batch loss = 0.32 (345.0 examples/sec; 0.023 sec/batch; 0h:34m:43s remains)
INFO - root - 2022-02-24 20:29:53.953472: step 109670, total loss = 0.54, batch loss = 0.27 (343.7 examples/sec; 0.023 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:29:54.402893: step 109680, total loss = 0.50, batch loss = 0.23 (108.5 examples/sec; 0.074 sec/batch; 1h:50m:25s remains)
INFO - root - 2022-02-24 20:29:54.709258: step 109690, total loss = 0.59, batch loss = 0.32 (324.9 examples/sec; 0.025 sec/batch; 0h:36m:51s remains)
INFO - root - 2022-02-24 20:29:54.992341: step 109700, total loss = 0.59, batch loss = 0.33 (268.2 examples/sec; 0.030 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 20:29:55.369578: step 109710, total loss = 0.46, batch loss = 0.20 (360.0 examples/sec; 0.022 sec/batch; 0h:33m:15s remains)
INFO - root - 2022-02-24 20:29:55.696093: step 109720, total loss = 0.57, batch loss = 0.31 (229.1 examples/sec; 0.035 sec/batch; 0h:52m:14s remains)
INFO - root - 2022-02-24 20:29:56.102800: step 109730, total loss = 0.64, batch loss = 0.38 (200.5 examples/sec; 0.040 sec/batch; 0h:59m:41s remains)
INFO - root - 2022-02-24 20:29:56.492757: step 109740, total loss = 0.50, batch loss = 0.23 (345.3 examples/sec; 0.023 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:29:56.790716: step 109750, total loss = 0.53, batch loss = 0.27 (350.1 examples/sec; 0.023 sec/batch; 0h:34m:11s remains)
INFO - root - 2022-02-24 20:29:57.112174: step 109760, total loss = 0.65, batch loss = 0.38 (256.5 examples/sec; 0.031 sec/batch; 0h:46m:38s remains)
INFO - root - 2022-02-24 20:29:57.430592: step 109770, total loss = 0.58, batch loss = 0.32 (206.6 examples/sec; 0.039 sec/batch; 0h:57m:54s remains)
INFO - root - 2022-02-24 20:29:57.755171: step 109780, total loss = 0.55, batch loss = 0.29 (106.3 examples/sec; 0.075 sec/batch; 1h:52m:33s remains)
INFO - root - 2022-02-24 20:29:58.178441: step 109790, total loss = 0.60, batch loss = 0.34 (136.8 examples/sec; 0.058 sec/batch; 1h:27m:25s remains)
INFO - root - 2022-02-24 20:29:58.597118: step 109800, total loss = 0.47, batch loss = 0.21 (218.5 examples/sec; 0.037 sec/batch; 0h:54m:44s remains)
INFO - root - 2022-02-24 20:29:58.983019: step 109810, total loss = 0.55, batch loss = 0.29 (176.8 examples/sec; 0.045 sec/batch; 1h:07m:37s remains)
INFO - root - 2022-02-24 20:29:59.780514: step 109820, total loss = 0.57, batch loss = 0.31 (211.1 examples/sec; 0.038 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 20:30:00.249981: step 109830, total loss = 0.54, batch loss = 0.28 (289.2 examples/sec; 0.028 sec/batch; 0h:41m:20s remains)
INFO - root - 2022-02-24 20:30:00.667245: step 109840, total loss = 0.49, batch loss = 0.23 (313.8 examples/sec; 0.025 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:30:01.098117: step 109850, total loss = 0.48, batch loss = 0.22 (124.4 examples/sec; 0.064 sec/batch; 1h:36m:05s remains)
INFO - root - 2022-02-24 20:30:01.452247: step 109860, total loss = 0.51, batch loss = 0.25 (214.5 examples/sec; 0.037 sec/batch; 0h:55m:42s remains)
INFO - root - 2022-02-24 20:30:01.854763: step 109870, total loss = 0.65, batch loss = 0.39 (170.5 examples/sec; 0.047 sec/batch; 1h:10m:04s remains)
INFO - root - 2022-02-24 20:30:02.250106: step 109880, total loss = 0.53, batch loss = 0.27 (157.7 examples/sec; 0.051 sec/batch; 1h:15m:47s remains)
INFO - root - 2022-02-24 20:30:02.597416: step 109890, total loss = 0.55, batch loss = 0.29 (251.0 examples/sec; 0.032 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:30:02.964880: step 109900, total loss = 0.50, batch loss = 0.24 (160.9 examples/sec; 0.050 sec/batch; 1h:14m:15s remains)
INFO - root - 2022-02-24 20:30:03.325423: step 109910, total loss = 0.49, batch loss = 0.23 (324.9 examples/sec; 0.025 sec/batch; 0h:36m:46s remains)
INFO - root - 2022-02-24 20:30:03.670100: step 109920, total loss = 0.50, batch loss = 0.24 (339.3 examples/sec; 0.024 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 20:30:04.020880: step 109930, total loss = 0.54, batch loss = 0.28 (348.2 examples/sec; 0.023 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:30:04.769078: step 109940, total loss = 0.52, batch loss = 0.26 (247.3 examples/sec; 0.032 sec/batch; 0h:48m:17s remains)
INFO - root - 2022-02-24 20:30:05.123635: step 109950, total loss = 0.63, batch loss = 0.37 (220.2 examples/sec; 0.036 sec/batch; 0h:54m:13s remains)
INFO - root - 2022-02-24 20:30:05.447859: step 109960, total loss = 0.56, batch loss = 0.30 (308.2 examples/sec; 0.026 sec/batch; 0h:38m:44s remains)
INFO - root - 2022-02-24 20:30:05.780544: step 109970, total loss = 0.51, batch loss = 0.25 (149.7 examples/sec; 0.053 sec/batch; 1h:19m:43s remains)
INFO - root - 2022-02-24 20:30:06.134849: step 109980, total loss = 0.56, batch loss = 0.30 (182.9 examples/sec; 0.044 sec/batch; 1h:05m:16s remains)
INFO - root - 2022-02-24 20:30:06.530076: step 109990, total loss = 0.56, batch loss = 0.30 (366.1 examples/sec; 0.022 sec/batch; 0h:32m:35s remains)
INFO - root - 2022-02-24 20:30:06.939695: step 110000, total loss = 0.60, batch loss = 0.33 (316.8 examples/sec; 0.025 sec/batch; 0h:37m:39s remains)
INFO - root - 2022-02-24 20:30:07.320673: step 110010, total loss = 0.52, batch loss = 0.25 (231.8 examples/sec; 0.035 sec/batch; 0h:51m:28s remains)
INFO - root - 2022-02-24 20:30:07.622408: step 110020, total loss = 0.54, batch loss = 0.28 (150.4 examples/sec; 0.053 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 20:30:07.952890: step 110030, total loss = 0.54, batch loss = 0.28 (228.4 examples/sec; 0.035 sec/batch; 0h:52m:14s remains)
INFO - root - 2022-02-24 20:30:08.370782: step 110040, total loss = 0.60, batch loss = 0.34 (107.8 examples/sec; 0.074 sec/batch; 1h:50m:38s remains)
INFO - root - 2022-02-24 20:30:08.688800: step 110050, total loss = 0.54, batch loss = 0.27 (343.6 examples/sec; 0.023 sec/batch; 0h:34m:42s remains)
INFO - root - 2022-02-24 20:30:09.138838: step 110060, total loss = 0.47, batch loss = 0.21 (208.3 examples/sec; 0.038 sec/batch; 0h:57m:14s remains)
INFO - root - 2022-02-24 20:30:09.492803: step 110070, total loss = 0.57, batch loss = 0.31 (332.6 examples/sec; 0.024 sec/batch; 0h:35m:51s remains)
INFO - root - 2022-02-24 20:30:09.774544: step 110080, total loss = 0.53, batch loss = 0.27 (285.3 examples/sec; 0.028 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:30:10.139691: step 110090, total loss = 0.56, batch loss = 0.29 (271.4 examples/sec; 0.029 sec/batch; 0h:43m:55s remains)
INFO - root - 2022-02-24 20:30:10.492933: step 110100, total loss = 0.59, batch loss = 0.33 (241.8 examples/sec; 0.033 sec/batch; 0h:49m:17s remains)
INFO - root - 2022-02-24 20:30:10.972068: step 110110, total loss = 0.61, batch loss = 0.35 (263.5 examples/sec; 0.030 sec/batch; 0h:45m:14s remains)
INFO - root - 2022-02-24 20:30:11.443978: step 110120, total loss = 0.58, batch loss = 0.32 (270.5 examples/sec; 0.030 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:30:11.705560: step 110130, total loss = 0.58, batch loss = 0.32 (325.7 examples/sec; 0.025 sec/batch; 0h:36m:34s remains)
INFO - root - 2022-02-24 20:30:11.970074: step 110140, total loss = 0.55, batch loss = 0.28 (328.0 examples/sec; 0.024 sec/batch; 0h:36m:19s remains)
INFO - root - 2022-02-24 20:30:12.247794: step 110150, total loss = 0.56, batch loss = 0.30 (196.1 examples/sec; 0.041 sec/batch; 1h:00m:45s remains)
INFO - root - 2022-02-24 20:30:12.631580: step 110160, total loss = 0.57, batch loss = 0.31 (144.4 examples/sec; 0.055 sec/batch; 1h:22m:28s remains)
INFO - root - 2022-02-24 20:30:12.971346: step 110170, total loss = 0.55, batch loss = 0.29 (302.7 examples/sec; 0.026 sec/batch; 0h:39m:20s remains)
INFO - root - 2022-02-24 20:30:13.366471: step 110180, total loss = 0.51, batch loss = 0.25 (202.3 examples/sec; 0.040 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 20:30:13.647217: step 110190, total loss = 0.47, batch loss = 0.20 (326.8 examples/sec; 0.024 sec/batch; 0h:36m:26s remains)
INFO - root - 2022-02-24 20:30:13.948276: step 110200, total loss = 0.59, batch loss = 0.32 (355.5 examples/sec; 0.023 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:30:14.413766: step 110210, total loss = 0.50, batch loss = 0.24 (211.3 examples/sec; 0.038 sec/batch; 0h:56m:20s remains)
INFO - root - 2022-02-24 20:30:14.807535: step 110220, total loss = 0.58, batch loss = 0.32 (339.1 examples/sec; 0.024 sec/batch; 0h:35m:06s remains)
INFO - root - 2022-02-24 20:30:15.156389: step 110230, total loss = 0.55, batch loss = 0.29 (339.5 examples/sec; 0.024 sec/batch; 0h:35m:03s remains)
INFO - root - 2022-02-24 20:30:15.484902: step 110240, total loss = 0.53, batch loss = 0.27 (268.1 examples/sec; 0.030 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:30:15.800135: step 110250, total loss = 0.63, batch loss = 0.36 (165.0 examples/sec; 0.048 sec/batch; 1h:12m:06s remains)
INFO - root - 2022-02-24 20:30:16.159223: step 110260, total loss = 0.68, batch loss = 0.42 (184.3 examples/sec; 0.043 sec/batch; 1h:04m:33s remains)
INFO - root - 2022-02-24 20:30:16.632575: step 110270, total loss = 0.57, batch loss = 0.31 (125.7 examples/sec; 0.064 sec/batch; 1h:34m:39s remains)
INFO - root - 2022-02-24 20:30:17.099382: step 110280, total loss = 0.50, batch loss = 0.24 (196.3 examples/sec; 0.041 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 20:30:17.549508: step 110290, total loss = 0.53, batch loss = 0.27 (133.9 examples/sec; 0.060 sec/batch; 1h:28m:49s remains)
INFO - root - 2022-02-24 20:30:17.995201: step 110300, total loss = 0.52, batch loss = 0.26 (167.4 examples/sec; 0.048 sec/batch; 1h:11m:03s remains)
INFO - root - 2022-02-24 20:30:18.407637: step 110310, total loss = 0.47, batch loss = 0.21 (312.6 examples/sec; 0.026 sec/batch; 0h:38m:02s remains)
INFO - root - 2022-02-24 20:30:18.775246: step 110320, total loss = 0.70, batch loss = 0.44 (299.1 examples/sec; 0.027 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:30:19.769934: step 110330, total loss = 0.48, batch loss = 0.22 (348.0 examples/sec; 0.023 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:30:20.129891: step 110340, total loss = 0.52, batch loss = 0.26 (306.8 examples/sec; 0.026 sec/batch; 0h:38m:44s remains)
INFO - root - 2022-02-24 20:30:20.457360: step 110350, total loss = 0.54, batch loss = 0.28 (199.3 examples/sec; 0.040 sec/batch; 0h:59m:39s remains)
INFO - root - 2022-02-24 20:30:20.803269: step 110360, total loss = 0.53, batch loss = 0.27 (272.6 examples/sec; 0.029 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 20:30:21.190426: step 110370, total loss = 0.59, batch loss = 0.33 (259.2 examples/sec; 0.031 sec/batch; 0h:45m:50s remains)
INFO - root - 2022-02-24 20:30:21.691372: step 110380, total loss = 0.50, batch loss = 0.24 (210.7 examples/sec; 0.038 sec/batch; 0h:56m:24s remains)
INFO - root - 2022-02-24 20:30:22.124580: step 110390, total loss = 0.74, batch loss = 0.48 (162.8 examples/sec; 0.049 sec/batch; 1h:12m:57s remains)
INFO - root - 2022-02-24 20:30:22.469163: step 110400, total loss = 0.57, batch loss = 0.30 (270.4 examples/sec; 0.030 sec/batch; 0h:43m:55s remains)
INFO - root - 2022-02-24 20:30:22.870224: step 110410, total loss = 0.53, batch loss = 0.27 (198.3 examples/sec; 0.040 sec/batch; 0h:59m:53s remains)
INFO - root - 2022-02-24 20:30:23.208722: step 110420, total loss = 0.63, batch loss = 0.37 (139.2 examples/sec; 0.057 sec/batch; 1h:25m:19s remains)
INFO - root - 2022-02-24 20:30:23.612047: step 110430, total loss = 0.68, batch loss = 0.42 (228.9 examples/sec; 0.035 sec/batch; 0h:51m:53s remains)
INFO - root - 2022-02-24 20:30:23.997803: step 110440, total loss = 0.52, batch loss = 0.26 (331.1 examples/sec; 0.024 sec/batch; 0h:35m:51s remains)
INFO - root - 2022-02-24 20:30:24.362807: step 110450, total loss = 0.51, batch loss = 0.25 (286.8 examples/sec; 0.028 sec/batch; 0h:41m:23s remains)
INFO - root - 2022-02-24 20:30:24.852412: step 110460, total loss = 0.67, batch loss = 0.41 (316.5 examples/sec; 0.025 sec/batch; 0h:37m:30s remains)
INFO - root - 2022-02-24 20:30:25.133488: step 110470, total loss = 0.54, batch loss = 0.28 (324.2 examples/sec; 0.025 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:30:25.524781: step 110480, total loss = 0.54, batch loss = 0.28 (357.9 examples/sec; 0.022 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:30:25.907323: step 110490, total loss = 0.56, batch loss = 0.30 (156.9 examples/sec; 0.051 sec/batch; 1h:15m:39s remains)
INFO - root - 2022-02-24 20:30:26.231931: step 110500, total loss = 0.67, batch loss = 0.41 (150.5 examples/sec; 0.053 sec/batch; 1h:18m:52s remains)
INFO - root - 2022-02-24 20:30:26.662142: step 110510, total loss = 0.58, batch loss = 0.32 (281.4 examples/sec; 0.028 sec/batch; 0h:42m:09s remains)
INFO - root - 2022-02-24 20:30:26.934661: step 110520, total loss = 0.59, batch loss = 0.33 (360.0 examples/sec; 0.022 sec/batch; 0h:32m:57s remains)
INFO - root - 2022-02-24 20:30:27.226258: step 110530, total loss = 0.67, batch loss = 0.41 (188.2 examples/sec; 0.043 sec/batch; 1h:03m:02s remains)
INFO - root - 2022-02-24 20:30:27.495357: step 110540, total loss = 0.51, batch loss = 0.25 (317.1 examples/sec; 0.025 sec/batch; 0h:37m:24s remains)
INFO - root - 2022-02-24 20:30:27.805026: step 110550, total loss = 0.65, batch loss = 0.39 (130.0 examples/sec; 0.062 sec/batch; 1h:31m:15s remains)
INFO - root - 2022-02-24 20:30:28.216119: step 110560, total loss = 0.53, batch loss = 0.27 (128.4 examples/sec; 0.062 sec/batch; 1h:32m:20s remains)
INFO - root - 2022-02-24 20:30:28.622304: step 110570, total loss = 0.67, batch loss = 0.40 (163.6 examples/sec; 0.049 sec/batch; 1h:12m:27s remains)
INFO - root - 2022-02-24 20:30:28.919119: step 110580, total loss = 0.49, batch loss = 0.23 (319.1 examples/sec; 0.025 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:30:29.208421: step 110590, total loss = 0.50, batch loss = 0.24 (209.5 examples/sec; 0.038 sec/batch; 0h:56m:35s remains)
INFO - root - 2022-02-24 20:30:29.522734: step 110600, total loss = 0.51, batch loss = 0.24 (145.3 examples/sec; 0.055 sec/batch; 1h:21m:36s remains)
INFO - root - 2022-02-24 20:30:29.923320: step 110610, total loss = 0.53, batch loss = 0.26 (227.3 examples/sec; 0.035 sec/batch; 0h:52m:08s remains)
INFO - root - 2022-02-24 20:30:30.427663: step 110620, total loss = 0.61, batch loss = 0.34 (115.7 examples/sec; 0.069 sec/batch; 1h:42m:23s remains)
INFO - root - 2022-02-24 20:30:30.795216: step 110630, total loss = 0.60, batch loss = 0.34 (166.6 examples/sec; 0.048 sec/batch; 1h:11m:07s remains)
INFO - root - 2022-02-24 20:30:31.143096: step 110640, total loss = 0.59, batch loss = 0.33 (340.4 examples/sec; 0.024 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:30:31.460966: step 110650, total loss = 0.60, batch loss = 0.34 (303.8 examples/sec; 0.026 sec/batch; 0h:38m:59s remains)
INFO - root - 2022-02-24 20:30:31.953338: step 110660, total loss = 0.55, batch loss = 0.28 (153.4 examples/sec; 0.052 sec/batch; 1h:17m:12s remains)
INFO - root - 2022-02-24 20:30:32.353232: step 110670, total loss = 0.59, batch loss = 0.33 (124.0 examples/sec; 0.065 sec/batch; 1h:35m:33s remains)
INFO - root - 2022-02-24 20:30:32.702139: step 110680, total loss = 0.69, batch loss = 0.43 (270.5 examples/sec; 0.030 sec/batch; 0h:43m:46s remains)
INFO - root - 2022-02-24 20:30:33.002054: step 110690, total loss = 0.55, batch loss = 0.29 (321.4 examples/sec; 0.025 sec/batch; 0h:36m:50s remains)
INFO - root - 2022-02-24 20:30:33.283972: step 110700, total loss = 0.51, batch loss = 0.25 (362.8 examples/sec; 0.022 sec/batch; 0h:32m:37s remains)
INFO - root - 2022-02-24 20:30:33.706107: step 110710, total loss = 0.47, batch loss = 0.20 (349.6 examples/sec; 0.023 sec/batch; 0h:33m:51s remains)
INFO - root - 2022-02-24 20:30:34.115965: step 110720, total loss = 0.55, batch loss = 0.28 (224.4 examples/sec; 0.036 sec/batch; 0h:52m:45s remains)
INFO - root - 2022-02-24 20:30:34.514000: step 110730, total loss = 0.59, batch loss = 0.33 (125.3 examples/sec; 0.064 sec/batch; 1h:34m:28s remains)
INFO - root - 2022-02-24 20:30:34.843198: step 110740, total loss = 0.56, batch loss = 0.30 (323.8 examples/sec; 0.025 sec/batch; 0h:36m:32s remains)
INFO - root - 2022-02-24 20:30:35.173274: step 110750, total loss = 0.56, batch loss = 0.30 (366.3 examples/sec; 0.022 sec/batch; 0h:32m:18s remains)
INFO - root - 2022-02-24 20:30:35.537471: step 110760, total loss = 0.62, batch loss = 0.36 (339.6 examples/sec; 0.024 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:30:35.905442: step 110770, total loss = 0.49, batch loss = 0.23 (303.6 examples/sec; 0.026 sec/batch; 0h:38m:57s remains)
INFO - root - 2022-02-24 20:30:36.429034: step 110780, total loss = 0.54, batch loss = 0.28 (281.2 examples/sec; 0.028 sec/batch; 0h:42m:04s remains)
INFO - root - 2022-02-24 20:30:36.838853: step 110790, total loss = 0.62, batch loss = 0.36 (327.3 examples/sec; 0.024 sec/batch; 0h:36m:08s remains)
INFO - root - 2022-02-24 20:30:37.088521: step 110800, total loss = 0.54, batch loss = 0.28 (328.5 examples/sec; 0.024 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 20:30:37.515440: step 110810, total loss = 0.52, batch loss = 0.26 (290.4 examples/sec; 0.028 sec/batch; 0h:40m:43s remains)
INFO - root - 2022-02-24 20:30:37.880459: step 110820, total loss = 0.68, batch loss = 0.42 (111.6 examples/sec; 0.072 sec/batch; 1h:45m:56s remains)
INFO - root - 2022-02-24 20:30:38.174072: step 110830, total loss = 0.51, batch loss = 0.25 (269.2 examples/sec; 0.030 sec/batch; 0h:43m:55s remains)
INFO - root - 2022-02-24 20:30:38.558577: step 110840, total loss = 0.55, batch loss = 0.29 (172.1 examples/sec; 0.046 sec/batch; 1h:08m:40s remains)
INFO - root - 2022-02-24 20:30:38.858582: step 110850, total loss = 0.75, batch loss = 0.48 (192.9 examples/sec; 0.041 sec/batch; 1h:01m:16s remains)
INFO - root - 2022-02-24 20:30:39.162164: step 110860, total loss = 0.59, batch loss = 0.33 (207.5 examples/sec; 0.039 sec/batch; 0h:56m:56s remains)
INFO - root - 2022-02-24 20:30:39.454076: step 110870, total loss = 0.59, batch loss = 0.33 (292.3 examples/sec; 0.027 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 20:30:39.863741: step 110880, total loss = 0.60, batch loss = 0.34 (339.2 examples/sec; 0.024 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:30:40.234261: step 110890, total loss = 0.50, batch loss = 0.24 (269.9 examples/sec; 0.030 sec/batch; 0h:43m:46s remains)
INFO - root - 2022-02-24 20:30:40.779411: step 110900, total loss = 0.53, batch loss = 0.27 (132.5 examples/sec; 0.060 sec/batch; 1h:29m:09s remains)
INFO - root - 2022-02-24 20:30:41.365212: step 110910, total loss = 0.49, batch loss = 0.23 (149.0 examples/sec; 0.054 sec/batch; 1h:19m:18s remains)
INFO - root - 2022-02-24 20:30:41.823441: step 110920, total loss = 0.42, batch loss = 0.16 (107.0 examples/sec; 0.075 sec/batch; 1h:50m:22s remains)
INFO - root - 2022-02-24 20:30:42.379228: step 110930, total loss = 0.57, batch loss = 0.31 (89.7 examples/sec; 0.089 sec/batch; 2h:11m:40s remains)
INFO - root - 2022-02-24 20:30:42.860039: step 110940, total loss = 0.56, batch loss = 0.30 (200.5 examples/sec; 0.040 sec/batch; 0h:58m:53s remains)
INFO - root - 2022-02-24 20:30:43.259215: step 110950, total loss = 0.58, batch loss = 0.32 (265.4 examples/sec; 0.030 sec/batch; 0h:44m:29s remains)
INFO - root - 2022-02-24 20:30:43.730687: step 110960, total loss = 0.59, batch loss = 0.33 (79.1 examples/sec; 0.101 sec/batch; 2h:29m:09s remains)
INFO - root - 2022-02-24 20:30:44.080126: step 110970, total loss = 0.53, batch loss = 0.27 (277.2 examples/sec; 0.029 sec/batch; 0h:42m:34s remains)
INFO - root - 2022-02-24 20:30:44.509327: step 110980, total loss = 0.64, batch loss = 0.38 (271.9 examples/sec; 0.029 sec/batch; 0h:43m:24s remains)
INFO - root - 2022-02-24 20:30:45.347187: step 110990, total loss = 0.54, batch loss = 0.28 (273.2 examples/sec; 0.029 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:30:45.656586: step 111000, total loss = 0.60, batch loss = 0.34 (272.6 examples/sec; 0.029 sec/batch; 0h:43m:17s remains)
INFO - root - 2022-02-24 20:30:46.025948: step 111010, total loss = 0.62, batch loss = 0.36 (338.6 examples/sec; 0.024 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:30:46.425069: step 111020, total loss = 0.52, batch loss = 0.26 (361.1 examples/sec; 0.022 sec/batch; 0h:32m:40s remains)
INFO - root - 2022-02-24 20:30:46.831098: step 111030, total loss = 0.53, batch loss = 0.27 (346.3 examples/sec; 0.023 sec/batch; 0h:34m:03s remains)
INFO - root - 2022-02-24 20:30:47.146888: step 111040, total loss = 0.50, batch loss = 0.24 (117.2 examples/sec; 0.068 sec/batch; 1h:40m:38s remains)
INFO - root - 2022-02-24 20:30:47.465949: step 111050, total loss = 0.48, batch loss = 0.22 (147.2 examples/sec; 0.054 sec/batch; 1h:20m:08s remains)
INFO - root - 2022-02-24 20:30:47.789390: step 111060, total loss = 0.55, batch loss = 0.29 (226.6 examples/sec; 0.035 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:30:48.194402: step 111070, total loss = 0.60, batch loss = 0.33 (88.8 examples/sec; 0.090 sec/batch; 2h:12m:47s remains)
INFO - root - 2022-02-24 20:30:48.596398: step 111080, total loss = 0.47, batch loss = 0.21 (164.7 examples/sec; 0.049 sec/batch; 1h:11m:35s remains)
INFO - root - 2022-02-24 20:30:48.958703: step 111090, total loss = 0.56, batch loss = 0.30 (320.9 examples/sec; 0.025 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:30:49.242904: step 111100, total loss = 0.67, batch loss = 0.40 (317.9 examples/sec; 0.025 sec/batch; 0h:37m:04s remains)
INFO - root - 2022-02-24 20:30:49.590946: step 111110, total loss = 0.55, batch loss = 0.29 (369.9 examples/sec; 0.022 sec/batch; 0h:31m:51s remains)
INFO - root - 2022-02-24 20:30:49.980281: step 111120, total loss = 0.51, batch loss = 0.25 (103.3 examples/sec; 0.077 sec/batch; 1h:54m:05s remains)
INFO - root - 2022-02-24 20:30:50.484365: step 111130, total loss = 0.51, batch loss = 0.25 (205.8 examples/sec; 0.039 sec/batch; 0h:57m:14s remains)
INFO - root - 2022-02-24 20:30:50.848367: step 111140, total loss = 0.53, batch loss = 0.27 (263.7 examples/sec; 0.030 sec/batch; 0h:44m:40s remains)
INFO - root - 2022-02-24 20:30:51.109643: step 111150, total loss = 0.51, batch loss = 0.25 (325.9 examples/sec; 0.025 sec/batch; 0h:36m:08s remains)
INFO - root - 2022-02-24 20:30:51.435575: step 111160, total loss = 0.50, batch loss = 0.23 (323.2 examples/sec; 0.025 sec/batch; 0h:36m:26s remains)
INFO - root - 2022-02-24 20:30:51.758782: step 111170, total loss = 0.47, batch loss = 0.20 (212.0 examples/sec; 0.038 sec/batch; 0h:55m:32s remains)
INFO - root - 2022-02-24 20:30:52.142680: step 111180, total loss = 0.72, batch loss = 0.45 (290.8 examples/sec; 0.028 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:30:52.485442: step 111190, total loss = 0.68, batch loss = 0.42 (341.5 examples/sec; 0.023 sec/batch; 0h:34m:28s remains)
INFO - root - 2022-02-24 20:30:52.834430: step 111200, total loss = 0.65, batch loss = 0.38 (151.0 examples/sec; 0.053 sec/batch; 1h:17m:57s remains)
INFO - root - 2022-02-24 20:30:53.187577: step 111210, total loss = 0.56, batch loss = 0.30 (326.1 examples/sec; 0.025 sec/batch; 0h:36m:06s remains)
INFO - root - 2022-02-24 20:30:53.466330: step 111220, total loss = 0.60, batch loss = 0.34 (357.0 examples/sec; 0.022 sec/batch; 0h:32m:58s remains)
INFO - root - 2022-02-24 20:30:53.701403: step 111230, total loss = 0.53, batch loss = 0.27 (335.1 examples/sec; 0.024 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:30:53.950633: step 111240, total loss = 0.55, batch loss = 0.29 (351.5 examples/sec; 0.023 sec/batch; 0h:33m:28s remains)
INFO - root - 2022-02-24 20:30:54.338680: step 111250, total loss = 0.55, batch loss = 0.29 (289.5 examples/sec; 0.028 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:30:54.733679: step 111260, total loss = 0.54, batch loss = 0.28 (321.5 examples/sec; 0.025 sec/batch; 0h:36m:35s remains)
INFO - root - 2022-02-24 20:30:55.168639: step 111270, total loss = 0.54, batch loss = 0.27 (239.3 examples/sec; 0.033 sec/batch; 0h:49m:09s remains)
INFO - root - 2022-02-24 20:30:55.537074: step 111280, total loss = 0.52, batch loss = 0.26 (125.0 examples/sec; 0.064 sec/batch; 1h:34m:07s remains)
INFO - root - 2022-02-24 20:30:55.847672: step 111290, total loss = 0.56, batch loss = 0.30 (162.8 examples/sec; 0.049 sec/batch; 1h:12m:14s remains)
INFO - root - 2022-02-24 20:30:56.148210: step 111300, total loss = 0.51, batch loss = 0.25 (151.1 examples/sec; 0.053 sec/batch; 1h:17m:50s remains)
INFO - root - 2022-02-24 20:30:56.591661: step 111310, total loss = 0.59, batch loss = 0.33 (121.7 examples/sec; 0.066 sec/batch; 1h:36m:38s remains)
INFO - root - 2022-02-24 20:30:57.062047: step 111320, total loss = 0.68, batch loss = 0.42 (240.1 examples/sec; 0.033 sec/batch; 0h:48m:58s remains)
INFO - root - 2022-02-24 20:30:57.425245: step 111330, total loss = 0.49, batch loss = 0.23 (344.9 examples/sec; 0.023 sec/batch; 0h:34m:05s remains)
INFO - root - 2022-02-24 20:30:57.707615: step 111340, total loss = 0.56, batch loss = 0.30 (360.0 examples/sec; 0.022 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 20:30:58.023291: step 111350, total loss = 0.60, batch loss = 0.34 (237.2 examples/sec; 0.034 sec/batch; 0h:49m:32s remains)
INFO - root - 2022-02-24 20:30:58.465369: step 111360, total loss = 0.59, batch loss = 0.33 (90.8 examples/sec; 0.088 sec/batch; 2h:09m:29s remains)
INFO - root - 2022-02-24 20:30:58.989365: step 111370, total loss = 0.55, batch loss = 0.29 (292.1 examples/sec; 0.027 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:30:59.551886: step 111380, total loss = 0.52, batch loss = 0.26 (150.3 examples/sec; 0.053 sec/batch; 1h:18m:10s remains)
INFO - root - 2022-02-24 20:30:59.962735: step 111390, total loss = 0.53, batch loss = 0.27 (195.8 examples/sec; 0.041 sec/batch; 1h:00m:00s remains)
INFO - root - 2022-02-24 20:31:00.968048: step 111400, total loss = 0.48, batch loss = 0.22 (104.8 examples/sec; 0.076 sec/batch; 1h:52m:02s remains)
INFO - root - 2022-02-24 20:31:01.482847: step 111410, total loss = 0.50, batch loss = 0.24 (181.7 examples/sec; 0.044 sec/batch; 1h:04m:37s remains)
INFO - root - 2022-02-24 20:31:01.760829: step 111420, total loss = 0.53, batch loss = 0.27 (346.3 examples/sec; 0.023 sec/batch; 0h:33m:54s remains)
INFO - root - 2022-02-24 20:31:02.116140: step 111430, total loss = 0.57, batch loss = 0.31 (316.5 examples/sec; 0.025 sec/batch; 0h:37m:05s remains)
INFO - root - 2022-02-24 20:31:02.457705: step 111440, total loss = 0.53, batch loss = 0.27 (186.7 examples/sec; 0.043 sec/batch; 1h:02m:53s remains)
INFO - root - 2022-02-24 20:31:02.816525: step 111450, total loss = 0.52, batch loss = 0.26 (212.8 examples/sec; 0.038 sec/batch; 0h:55m:10s remains)
INFO - root - 2022-02-24 20:31:03.180623: step 111460, total loss = 0.58, batch loss = 0.32 (347.6 examples/sec; 0.023 sec/batch; 0h:33m:46s remains)
INFO - root - 2022-02-24 20:31:03.596317: step 111470, total loss = 0.56, batch loss = 0.29 (132.6 examples/sec; 0.060 sec/batch; 1h:28m:31s remains)
INFO - root - 2022-02-24 20:31:03.944969: step 111480, total loss = 0.53, batch loss = 0.27 (203.0 examples/sec; 0.039 sec/batch; 0h:57m:49s remains)
INFO - root - 2022-02-24 20:31:04.352028: step 111490, total loss = 0.58, batch loss = 0.31 (314.6 examples/sec; 0.025 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 20:31:04.645352: step 111500, total loss = 0.49, batch loss = 0.22 (350.0 examples/sec; 0.023 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:31:05.124622: step 111510, total loss = 0.50, batch loss = 0.24 (141.5 examples/sec; 0.057 sec/batch; 1h:22m:56s remains)
INFO - root - 2022-02-24 20:31:05.466553: step 111520, total loss = 0.57, batch loss = 0.31 (202.6 examples/sec; 0.039 sec/batch; 0h:57m:53s remains)
INFO - root - 2022-02-24 20:31:05.845740: step 111530, total loss = 0.68, batch loss = 0.42 (336.0 examples/sec; 0.024 sec/batch; 0h:34m:54s remains)
INFO - root - 2022-02-24 20:31:06.174711: step 111540, total loss = 0.42, batch loss = 0.16 (262.7 examples/sec; 0.030 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 20:31:06.438435: step 111550, total loss = 0.58, batch loss = 0.31 (348.9 examples/sec; 0.023 sec/batch; 0h:33m:36s remains)
INFO - root - 2022-02-24 20:31:06.727631: step 111560, total loss = 0.55, batch loss = 0.29 (336.9 examples/sec; 0.024 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:31:07.043749: step 111570, total loss = 0.60, batch loss = 0.33 (132.2 examples/sec; 0.060 sec/batch; 1h:28m:39s remains)
INFO - root - 2022-02-24 20:31:07.409295: step 111580, total loss = 0.59, batch loss = 0.33 (171.1 examples/sec; 0.047 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 20:31:07.772202: step 111590, total loss = 0.56, batch loss = 0.30 (342.7 examples/sec; 0.023 sec/batch; 0h:34m:12s remains)
INFO - root - 2022-02-24 20:31:08.104080: step 111600, total loss = 0.68, batch loss = 0.42 (274.5 examples/sec; 0.029 sec/batch; 0h:42m:41s remains)
INFO - root - 2022-02-24 20:31:08.539345: step 111610, total loss = 0.55, batch loss = 0.29 (192.5 examples/sec; 0.042 sec/batch; 1h:00m:51s remains)
INFO - root - 2022-02-24 20:31:08.954475: step 111620, total loss = 0.56, batch loss = 0.29 (136.7 examples/sec; 0.059 sec/batch; 1h:25m:41s remains)
INFO - root - 2022-02-24 20:31:09.307780: step 111630, total loss = 0.55, batch loss = 0.29 (170.3 examples/sec; 0.047 sec/batch; 1h:08m:47s remains)
INFO - root - 2022-02-24 20:31:09.704697: step 111640, total loss = 0.58, batch loss = 0.32 (200.6 examples/sec; 0.040 sec/batch; 0h:58m:23s remains)
INFO - root - 2022-02-24 20:31:10.048966: step 111650, total loss = 0.49, batch loss = 0.23 (152.7 examples/sec; 0.052 sec/batch; 1h:16m:41s remains)
INFO - root - 2022-02-24 20:31:10.373551: step 111660, total loss = 0.56, batch loss = 0.30 (325.4 examples/sec; 0.025 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:31:10.683649: step 111670, total loss = 0.55, batch loss = 0.28 (235.7 examples/sec; 0.034 sec/batch; 0h:49m:41s remains)
INFO - root - 2022-02-24 20:31:11.057680: step 111680, total loss = 0.53, batch loss = 0.27 (155.6 examples/sec; 0.051 sec/batch; 1h:15m:14s remains)
INFO - root - 2022-02-24 20:31:11.501936: step 111690, total loss = 0.60, batch loss = 0.33 (234.5 examples/sec; 0.034 sec/batch; 0h:49m:55s remains)
INFO - root - 2022-02-24 20:31:11.840101: step 111700, total loss = 0.57, batch loss = 0.31 (182.6 examples/sec; 0.044 sec/batch; 1h:04m:05s remains)
INFO - root - 2022-02-24 20:31:12.245215: step 111710, total loss = 0.55, batch loss = 0.28 (315.9 examples/sec; 0.025 sec/batch; 0h:37m:03s remains)
INFO - root - 2022-02-24 20:31:12.525212: step 111720, total loss = 0.45, batch loss = 0.19 (200.8 examples/sec; 0.040 sec/batch; 0h:58m:17s remains)
INFO - root - 2022-02-24 20:31:12.855418: step 111730, total loss = 0.51, batch loss = 0.24 (176.0 examples/sec; 0.045 sec/batch; 1h:06m:28s remains)
INFO - root - 2022-02-24 20:31:13.246285: step 111740, total loss = 0.68, batch loss = 0.42 (190.0 examples/sec; 0.042 sec/batch; 1h:01m:35s remains)
INFO - root - 2022-02-24 20:31:13.672823: step 111750, total loss = 0.64, batch loss = 0.38 (251.8 examples/sec; 0.032 sec/batch; 0h:46m:28s remains)
INFO - root - 2022-02-24 20:31:14.084352: step 111760, total loss = 0.49, batch loss = 0.23 (322.8 examples/sec; 0.025 sec/batch; 0h:36m:14s remains)
INFO - root - 2022-02-24 20:31:14.483157: step 111770, total loss = 0.56, batch loss = 0.30 (195.8 examples/sec; 0.041 sec/batch; 0h:59m:44s remains)
INFO - root - 2022-02-24 20:31:15.123543: step 111780, total loss = 0.53, batch loss = 0.26 (315.6 examples/sec; 0.025 sec/batch; 0h:37m:03s remains)
INFO - root - 2022-02-24 20:31:15.963260: step 111790, total loss = 0.53, batch loss = 0.27 (144.4 examples/sec; 0.055 sec/batch; 1h:20m:57s remains)
INFO - root - 2022-02-24 20:31:16.306615: step 111800, total loss = 0.59, batch loss = 0.33 (253.5 examples/sec; 0.032 sec/batch; 0h:46m:07s remains)
INFO - root - 2022-02-24 20:31:16.734469: step 111810, total loss = 0.58, batch loss = 0.32 (259.9 examples/sec; 0.031 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 20:31:17.058150: step 111820, total loss = 0.50, batch loss = 0.24 (352.8 examples/sec; 0.023 sec/batch; 0h:33m:08s remains)
INFO - root - 2022-02-24 20:31:17.356105: step 111830, total loss = 0.63, batch loss = 0.37 (208.0 examples/sec; 0.038 sec/batch; 0h:56m:11s remains)
INFO - root - 2022-02-24 20:31:17.770471: step 111840, total loss = 0.55, batch loss = 0.29 (224.0 examples/sec; 0.036 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:31:18.224047: step 111850, total loss = 0.67, batch loss = 0.41 (179.8 examples/sec; 0.044 sec/batch; 1h:04m:58s remains)
INFO - root - 2022-02-24 20:31:18.583456: step 111860, total loss = 0.63, batch loss = 0.37 (293.8 examples/sec; 0.027 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:31:18.931288: step 111870, total loss = 0.48, batch loss = 0.22 (309.7 examples/sec; 0.026 sec/batch; 0h:37m:43s remains)
INFO - root - 2022-02-24 20:31:19.186773: step 111880, total loss = 0.63, batch loss = 0.37 (350.7 examples/sec; 0.023 sec/batch; 0h:33m:18s remains)
INFO - root - 2022-02-24 20:31:19.440978: step 111890, total loss = 0.76, batch loss = 0.50 (339.4 examples/sec; 0.024 sec/batch; 0h:34m:24s remains)
INFO - root - 2022-02-24 20:31:19.768145: step 111900, total loss = 0.53, batch loss = 0.27 (352.0 examples/sec; 0.023 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:31:20.395738: step 111910, total loss = 0.52, batch loss = 0.25 (56.7 examples/sec; 0.141 sec/batch; 3h:25m:50s remains)
INFO - root - 2022-02-24 20:31:20.848052: step 111920, total loss = 0.51, batch loss = 0.25 (121.6 examples/sec; 0.066 sec/batch; 1h:36m:03s remains)
INFO - root - 2022-02-24 20:31:21.209023: step 111930, total loss = 0.46, batch loss = 0.20 (199.4 examples/sec; 0.040 sec/batch; 0h:58m:33s remains)
INFO - root - 2022-02-24 20:31:21.538466: step 111940, total loss = 0.54, batch loss = 0.27 (210.1 examples/sec; 0.038 sec/batch; 0h:55m:34s remains)
INFO - root - 2022-02-24 20:31:21.882729: step 111950, total loss = 0.45, batch loss = 0.19 (343.9 examples/sec; 0.023 sec/batch; 0h:33m:56s remains)
INFO - root - 2022-02-24 20:31:22.228441: step 111960, total loss = 0.48, batch loss = 0.22 (307.0 examples/sec; 0.026 sec/batch; 0h:38m:01s remains)
INFO - root - 2022-02-24 20:31:22.545259: step 111970, total loss = 0.56, batch loss = 0.29 (244.3 examples/sec; 0.033 sec/batch; 0h:47m:46s remains)
INFO - root - 2022-02-24 20:31:22.970798: step 111980, total loss = 0.59, batch loss = 0.33 (269.6 examples/sec; 0.030 sec/batch; 0h:43m:16s remains)
INFO - root - 2022-02-24 20:31:23.411554: step 111990, total loss = 0.61, batch loss = 0.35 (122.3 examples/sec; 0.065 sec/batch; 1h:35m:22s remains)
INFO - root - 2022-02-24 20:31:23.698145: step 112000, total loss = 0.70, batch loss = 0.44 (342.1 examples/sec; 0.023 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:31:24.114872: step 112010, total loss = 0.46, batch loss = 0.20 (299.7 examples/sec; 0.027 sec/batch; 0h:38m:55s remains)
INFO - root - 2022-02-24 20:31:24.448271: step 112020, total loss = 0.51, batch loss = 0.25 (167.3 examples/sec; 0.048 sec/batch; 1h:09m:43s remains)
INFO - root - 2022-02-24 20:31:24.891318: step 112030, total loss = 0.56, batch loss = 0.30 (173.2 examples/sec; 0.046 sec/batch; 1h:07m:20s remains)
INFO - root - 2022-02-24 20:31:25.263112: step 112040, total loss = 0.52, batch loss = 0.25 (315.4 examples/sec; 0.025 sec/batch; 0h:36m:58s remains)
INFO - root - 2022-02-24 20:31:25.626708: step 112050, total loss = 0.57, batch loss = 0.30 (312.4 examples/sec; 0.026 sec/batch; 0h:37m:19s remains)
INFO - root - 2022-02-24 20:31:25.899169: step 112060, total loss = 0.70, batch loss = 0.44 (364.1 examples/sec; 0.022 sec/batch; 0h:32m:01s remains)
INFO - root - 2022-02-24 20:31:26.174885: step 112070, total loss = 0.55, batch loss = 0.29 (281.0 examples/sec; 0.028 sec/batch; 0h:41m:29s remains)
INFO - root - 2022-02-24 20:31:26.560452: step 112080, total loss = 0.52, batch loss = 0.26 (102.7 examples/sec; 0.078 sec/batch; 1h:53m:26s remains)
INFO - root - 2022-02-24 20:31:26.965282: step 112090, total loss = 0.69, batch loss = 0.43 (135.2 examples/sec; 0.059 sec/batch; 1h:26m:14s remains)
INFO - root - 2022-02-24 20:31:27.272888: step 112100, total loss = 0.64, batch loss = 0.37 (317.4 examples/sec; 0.025 sec/batch; 0h:36m:42s remains)
INFO - root - 2022-02-24 20:31:27.618980: step 112110, total loss = 0.53, batch loss = 0.27 (320.7 examples/sec; 0.025 sec/batch; 0h:36m:19s remains)
INFO - root - 2022-02-24 20:31:27.950613: step 112120, total loss = 0.60, batch loss = 0.34 (342.7 examples/sec; 0.023 sec/batch; 0h:33m:59s remains)
INFO - root - 2022-02-24 20:31:28.282582: step 112130, total loss = 0.53, batch loss = 0.27 (180.4 examples/sec; 0.044 sec/batch; 1h:04m:34s remains)
INFO - root - 2022-02-24 20:31:28.702011: step 112140, total loss = 0.68, batch loss = 0.42 (365.5 examples/sec; 0.022 sec/batch; 0h:31m:52s remains)
INFO - root - 2022-02-24 20:31:29.076486: step 112150, total loss = 0.54, batch loss = 0.28 (318.3 examples/sec; 0.025 sec/batch; 0h:36m:35s remains)
INFO - root - 2022-02-24 20:31:29.467058: step 112160, total loss = 0.54, batch loss = 0.27 (189.5 examples/sec; 0.042 sec/batch; 1h:01m:27s remains)
INFO - root - 2022-02-24 20:31:29.848986: step 112170, total loss = 0.57, batch loss = 0.31 (151.3 examples/sec; 0.053 sec/batch; 1h:16m:58s remains)
INFO - root - 2022-02-24 20:31:30.133415: step 112180, total loss = 0.46, batch loss = 0.20 (318.0 examples/sec; 0.025 sec/batch; 0h:36m:37s remains)
INFO - root - 2022-02-24 20:31:30.552705: step 112190, total loss = 0.57, batch loss = 0.31 (110.8 examples/sec; 0.072 sec/batch; 1h:45m:06s remains)
INFO - root - 2022-02-24 20:31:31.194767: step 112200, total loss = 0.49, batch loss = 0.23 (285.4 examples/sec; 0.028 sec/batch; 0h:40m:46s remains)
INFO - root - 2022-02-24 20:31:31.681716: step 112210, total loss = 0.49, batch loss = 0.23 (140.2 examples/sec; 0.057 sec/batch; 1h:22m:59s remains)
INFO - root - 2022-02-24 20:31:31.979048: step 112220, total loss = 0.48, batch loss = 0.21 (239.8 examples/sec; 0.033 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:31:32.293546: step 112230, total loss = 0.51, batch loss = 0.25 (347.2 examples/sec; 0.023 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:31:32.773227: step 112240, total loss = 0.52, batch loss = 0.25 (158.0 examples/sec; 0.051 sec/batch; 1h:13m:37s remains)
INFO - root - 2022-02-24 20:31:33.181485: step 112250, total loss = 0.50, batch loss = 0.24 (236.7 examples/sec; 0.034 sec/batch; 0h:49m:09s remains)
INFO - root - 2022-02-24 20:31:33.835087: step 112260, total loss = 0.49, batch loss = 0.23 (160.1 examples/sec; 0.050 sec/batch; 1h:12m:39s remains)
INFO - root - 2022-02-24 20:31:34.192855: step 112270, total loss = 0.53, batch loss = 0.27 (343.5 examples/sec; 0.023 sec/batch; 0h:33m:51s remains)
INFO - root - 2022-02-24 20:31:34.565371: step 112280, total loss = 0.53, batch loss = 0.26 (179.4 examples/sec; 0.045 sec/batch; 1h:04m:49s remains)
INFO - root - 2022-02-24 20:31:34.931785: step 112290, total loss = 0.63, batch loss = 0.37 (298.8 examples/sec; 0.027 sec/batch; 0h:38m:55s remains)
INFO - root - 2022-02-24 20:31:35.322063: step 112300, total loss = 0.48, batch loss = 0.22 (184.8 examples/sec; 0.043 sec/batch; 1h:02m:55s remains)
INFO - root - 2022-02-24 20:31:36.066366: step 112310, total loss = 0.52, batch loss = 0.26 (109.0 examples/sec; 0.073 sec/batch; 1h:46m:40s remains)
INFO - root - 2022-02-24 20:31:36.509052: step 112320, total loss = 0.52, batch loss = 0.25 (134.4 examples/sec; 0.060 sec/batch; 1h:26m:28s remains)
INFO - root - 2022-02-24 20:31:37.013864: step 112330, total loss = 0.55, batch loss = 0.29 (195.3 examples/sec; 0.041 sec/batch; 0h:59m:30s remains)
INFO - root - 2022-02-24 20:31:37.581777: step 112340, total loss = 0.62, batch loss = 0.36 (344.2 examples/sec; 0.023 sec/batch; 0h:33m:46s remains)
INFO - root - 2022-02-24 20:31:38.133851: step 112350, total loss = 0.51, batch loss = 0.25 (142.6 examples/sec; 0.056 sec/batch; 1h:21m:28s remains)
INFO - root - 2022-02-24 20:31:38.615835: step 112360, total loss = 0.59, batch loss = 0.33 (213.4 examples/sec; 0.037 sec/batch; 0h:54m:27s remains)
INFO - root - 2022-02-24 20:31:39.251124: step 112370, total loss = 0.49, batch loss = 0.22 (341.2 examples/sec; 0.023 sec/batch; 0h:34m:02s remains)
INFO - root - 2022-02-24 20:31:39.631673: step 112380, total loss = 0.54, batch loss = 0.28 (287.8 examples/sec; 0.028 sec/batch; 0h:40m:21s remains)
INFO - root - 2022-02-24 20:31:39.994442: step 112390, total loss = 0.50, batch loss = 0.24 (367.0 examples/sec; 0.022 sec/batch; 0h:31m:39s remains)
INFO - root - 2022-02-24 20:31:40.762715: step 112400, total loss = 0.50, batch loss = 0.24 (78.3 examples/sec; 0.102 sec/batch; 2h:28m:19s remains)
INFO - root - 2022-02-24 20:31:41.221482: step 112410, total loss = 0.53, batch loss = 0.27 (244.3 examples/sec; 0.033 sec/batch; 0h:47m:31s remains)
INFO - root - 2022-02-24 20:31:41.803532: step 112420, total loss = 0.58, batch loss = 0.32 (66.7 examples/sec; 0.120 sec/batch; 2h:54m:01s remains)
INFO - root - 2022-02-24 20:31:42.480692: step 112430, total loss = 0.54, batch loss = 0.28 (68.9 examples/sec; 0.116 sec/batch; 2h:48m:36s remains)
INFO - root - 2022-02-24 20:31:42.806721: step 112440, total loss = 0.50, batch loss = 0.24 (347.1 examples/sec; 0.023 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:31:43.463137: step 112450, total loss = 0.52, batch loss = 0.26 (158.5 examples/sec; 0.050 sec/batch; 1h:13m:13s remains)
INFO - root - 2022-02-24 20:31:43.806646: step 112460, total loss = 0.58, batch loss = 0.32 (159.3 examples/sec; 0.050 sec/batch; 1h:12m:50s remains)
INFO - root - 2022-02-24 20:31:44.457187: step 112470, total loss = 0.47, batch loss = 0.20 (226.9 examples/sec; 0.035 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:31:44.832545: step 112480, total loss = 0.57, batch loss = 0.31 (358.0 examples/sec; 0.022 sec/batch; 0h:32m:24s remains)
INFO - root - 2022-02-24 20:31:45.358593: step 112490, total loss = 0.58, batch loss = 0.32 (161.0 examples/sec; 0.050 sec/batch; 1h:12m:04s remains)
INFO - root - 2022-02-24 20:31:45.975824: step 112500, total loss = 0.59, batch loss = 0.33 (81.8 examples/sec; 0.098 sec/batch; 2h:21m:53s remains)
INFO - root - 2022-02-24 20:31:46.567763: step 112510, total loss = 0.53, batch loss = 0.27 (161.1 examples/sec; 0.050 sec/batch; 1h:12m:00s remains)
INFO - root - 2022-02-24 20:31:47.076858: step 112520, total loss = 0.55, batch loss = 0.29 (316.8 examples/sec; 0.025 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:31:47.885740: step 112530, total loss = 0.56, batch loss = 0.30 (175.0 examples/sec; 0.046 sec/batch; 1h:06m:16s remains)
INFO - root - 2022-02-24 20:31:48.362146: step 112540, total loss = 0.55, batch loss = 0.29 (141.4 examples/sec; 0.057 sec/batch; 1h:21m:58s remains)
INFO - root - 2022-02-24 20:31:48.716264: step 112550, total loss = 0.62, batch loss = 0.35 (182.4 examples/sec; 0.044 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 20:31:49.106493: step 112560, total loss = 0.58, batch loss = 0.31 (210.4 examples/sec; 0.038 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:31:49.537417: step 112570, total loss = 0.52, batch loss = 0.26 (225.9 examples/sec; 0.035 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:31:49.884855: step 112580, total loss = 0.48, batch loss = 0.22 (232.9 examples/sec; 0.034 sec/batch; 0h:49m:45s remains)
INFO - root - 2022-02-24 20:31:50.225244: step 112590, total loss = 0.52, batch loss = 0.26 (145.9 examples/sec; 0.055 sec/batch; 1h:19m:26s remains)
INFO - root - 2022-02-24 20:31:50.514993: step 112600, total loss = 0.49, batch loss = 0.23 (179.0 examples/sec; 0.045 sec/batch; 1h:04m:44s remains)
INFO - root - 2022-02-24 20:31:50.987600: step 112610, total loss = 0.67, batch loss = 0.40 (342.2 examples/sec; 0.023 sec/batch; 0h:33m:51s remains)
INFO - root - 2022-02-24 20:31:51.433505: step 112620, total loss = 0.56, batch loss = 0.29 (224.8 examples/sec; 0.036 sec/batch; 0h:51m:32s remains)
INFO - root - 2022-02-24 20:31:51.824070: step 112630, total loss = 0.50, batch loss = 0.24 (124.2 examples/sec; 0.064 sec/batch; 1h:33m:16s remains)
INFO - root - 2022-02-24 20:31:52.250991: step 112640, total loss = 0.55, batch loss = 0.29 (273.6 examples/sec; 0.029 sec/batch; 0h:42m:19s remains)
INFO - root - 2022-02-24 20:31:52.595864: step 112650, total loss = 0.52, batch loss = 0.26 (281.5 examples/sec; 0.028 sec/batch; 0h:41m:07s remains)
INFO - root - 2022-02-24 20:31:52.975846: step 112660, total loss = 0.57, batch loss = 0.31 (287.1 examples/sec; 0.028 sec/batch; 0h:40m:20s remains)
INFO - root - 2022-02-24 20:31:53.345436: step 112670, total loss = 0.52, batch loss = 0.26 (170.1 examples/sec; 0.047 sec/batch; 1h:08m:03s remains)
INFO - root - 2022-02-24 20:31:53.718886: step 112680, total loss = 0.56, batch loss = 0.29 (233.9 examples/sec; 0.034 sec/batch; 0h:49m:29s remains)
INFO - root - 2022-02-24 20:31:54.023689: step 112690, total loss = 0.59, batch loss = 0.32 (353.3 examples/sec; 0.023 sec/batch; 0h:32m:45s remains)
INFO - root - 2022-02-24 20:31:54.320054: step 112700, total loss = 0.57, batch loss = 0.31 (322.6 examples/sec; 0.025 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 20:31:54.720625: step 112710, total loss = 0.49, batch loss = 0.23 (340.9 examples/sec; 0.023 sec/batch; 0h:33m:56s remains)
INFO - root - 2022-02-24 20:31:55.162766: step 112720, total loss = 0.61, batch loss = 0.35 (361.7 examples/sec; 0.022 sec/batch; 0h:31m:59s remains)
INFO - root - 2022-02-24 20:31:55.599672: step 112730, total loss = 0.47, batch loss = 0.21 (228.0 examples/sec; 0.035 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 20:31:55.954738: step 112740, total loss = 0.54, batch loss = 0.27 (323.2 examples/sec; 0.025 sec/batch; 0h:35m:47s remains)
INFO - root - 2022-02-24 20:31:56.301078: step 112750, total loss = 0.49, batch loss = 0.23 (342.7 examples/sec; 0.023 sec/batch; 0h:33m:45s remains)
INFO - root - 2022-02-24 20:31:56.619545: step 112760, total loss = 0.63, batch loss = 0.37 (291.8 examples/sec; 0.027 sec/batch; 0h:39m:38s remains)
INFO - root - 2022-02-24 20:31:56.913404: step 112770, total loss = 0.71, batch loss = 0.45 (337.5 examples/sec; 0.024 sec/batch; 0h:34m:15s remains)
INFO - root - 2022-02-24 20:31:57.375771: step 112780, total loss = 0.73, batch loss = 0.47 (216.1 examples/sec; 0.037 sec/batch; 0h:53m:30s remains)
INFO - root - 2022-02-24 20:31:57.780675: step 112790, total loss = 0.60, batch loss = 0.34 (295.9 examples/sec; 0.027 sec/batch; 0h:39m:04s remains)
INFO - root - 2022-02-24 20:31:58.137668: step 112800, total loss = 0.52, batch loss = 0.25 (305.1 examples/sec; 0.026 sec/batch; 0h:37m:53s remains)
INFO - root - 2022-02-24 20:31:58.467583: step 112810, total loss = 0.46, batch loss = 0.20 (341.8 examples/sec; 0.023 sec/batch; 0h:33m:48s remains)
INFO - root - 2022-02-24 20:31:58.796521: step 112820, total loss = 0.43, batch loss = 0.17 (304.4 examples/sec; 0.026 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 20:31:59.092515: step 112830, total loss = 0.47, batch loss = 0.21 (356.8 examples/sec; 0.022 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 20:31:59.527886: step 112840, total loss = 0.69, batch loss = 0.43 (301.9 examples/sec; 0.027 sec/batch; 0h:38m:16s remains)
INFO - root - 2022-02-24 20:31:59.918950: step 112850, total loss = 0.52, batch loss = 0.26 (351.2 examples/sec; 0.023 sec/batch; 0h:32m:53s remains)
INFO - root - 2022-02-24 20:32:00.220510: step 112860, total loss = 0.49, batch loss = 0.22 (184.9 examples/sec; 0.043 sec/batch; 1h:02m:29s remains)
INFO - root - 2022-02-24 20:32:00.475615: step 112870, total loss = 0.53, batch loss = 0.27 (348.7 examples/sec; 0.023 sec/batch; 0h:33m:07s remains)
INFO - root - 2022-02-24 20:32:00.786840: step 112880, total loss = 0.58, batch loss = 0.32 (165.3 examples/sec; 0.048 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 20:32:01.185922: step 112890, total loss = 0.63, batch loss = 0.37 (149.9 examples/sec; 0.053 sec/batch; 1h:17m:03s remains)
INFO - root - 2022-02-24 20:32:01.578672: step 112900, total loss = 0.55, batch loss = 0.29 (199.6 examples/sec; 0.040 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 20:32:01.960680: step 112910, total loss = 0.60, batch loss = 0.34 (202.4 examples/sec; 0.040 sec/batch; 0h:57m:03s remains)
INFO - root - 2022-02-24 20:32:02.309057: step 112920, total loss = 0.49, batch loss = 0.23 (269.0 examples/sec; 0.030 sec/batch; 0h:42m:55s remains)
INFO - root - 2022-02-24 20:32:02.583181: step 112930, total loss = 0.59, batch loss = 0.33 (340.2 examples/sec; 0.024 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:32:02.892597: step 112940, total loss = 0.55, batch loss = 0.29 (360.0 examples/sec; 0.022 sec/batch; 0h:32m:03s remains)
INFO - root - 2022-02-24 20:32:03.241077: step 112950, total loss = 0.55, batch loss = 0.29 (279.4 examples/sec; 0.029 sec/batch; 0h:41m:18s remains)
INFO - root - 2022-02-24 20:32:03.709229: step 112960, total loss = 0.51, batch loss = 0.25 (259.1 examples/sec; 0.031 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:32:04.093269: step 112970, total loss = 0.51, batch loss = 0.25 (322.9 examples/sec; 0.025 sec/batch; 0h:35m:43s remains)
INFO - root - 2022-02-24 20:32:04.396202: step 112980, total loss = 0.55, batch loss = 0.28 (152.7 examples/sec; 0.052 sec/batch; 1h:15m:33s remains)
INFO - root - 2022-02-24 20:32:04.682376: step 112990, total loss = 0.53, batch loss = 0.27 (338.1 examples/sec; 0.024 sec/batch; 0h:34m:07s remains)
INFO - root - 2022-02-24 20:32:05.005495: step 113000, total loss = 0.53, batch loss = 0.27 (339.0 examples/sec; 0.024 sec/batch; 0h:34m:01s remains)
INFO - root - 2022-02-24 20:32:05.429091: step 113010, total loss = 0.55, batch loss = 0.29 (141.2 examples/sec; 0.057 sec/batch; 1h:21m:40s remains)
INFO - root - 2022-02-24 20:32:05.856335: step 113020, total loss = 0.60, batch loss = 0.34 (179.1 examples/sec; 0.045 sec/batch; 1h:04m:22s remains)
INFO - root - 2022-02-24 20:32:06.651356: step 113030, total loss = 0.59, batch loss = 0.33 (319.3 examples/sec; 0.025 sec/batch; 0h:36m:06s remains)
INFO - root - 2022-02-24 20:32:06.999744: step 113040, total loss = 0.68, batch loss = 0.42 (248.2 examples/sec; 0.032 sec/batch; 0h:46m:26s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-113049 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-113049 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:32:08.207647: step 113050, total loss = 0.55, batch loss = 0.29 (342.9 examples/sec; 0.023 sec/batch; 0h:33m:36s remains)
INFO - root - 2022-02-24 20:32:08.431138: step 113060, total loss = 0.55, batch loss = 0.29 (324.9 examples/sec; 0.025 sec/batch; 0h:35m:28s remains)
INFO - root - 2022-02-24 20:32:08.672292: step 113070, total loss = 0.65, batch loss = 0.39 (371.8 examples/sec; 0.022 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 20:32:08.933413: step 113080, total loss = 0.55, batch loss = 0.29 (346.7 examples/sec; 0.023 sec/batch; 0h:33m:14s remains)
INFO - root - 2022-02-24 20:32:09.350168: step 113090, total loss = 0.61, batch loss = 0.35 (361.6 examples/sec; 0.022 sec/batch; 0h:31m:51s remains)
INFO - root - 2022-02-24 20:32:09.774310: step 113100, total loss = 0.54, batch loss = 0.28 (367.4 examples/sec; 0.022 sec/batch; 0h:31m:21s remains)
INFO - root - 2022-02-24 20:32:10.377466: step 113110, total loss = 0.54, batch loss = 0.28 (101.3 examples/sec; 0.079 sec/batch; 1h:53m:45s remains)
INFO - root - 2022-02-24 20:32:10.781768: step 113120, total loss = 0.50, batch loss = 0.24 (330.4 examples/sec; 0.024 sec/batch; 0h:34m:51s remains)
INFO - root - 2022-02-24 20:32:11.114732: step 113130, total loss = 0.58, batch loss = 0.32 (310.2 examples/sec; 0.026 sec/batch; 0h:37m:07s remains)
INFO - root - 2022-02-24 20:32:11.495387: step 113140, total loss = 0.54, batch loss = 0.28 (174.5 examples/sec; 0.046 sec/batch; 1h:05m:59s remains)
INFO - root - 2022-02-24 20:32:12.309394: step 113150, total loss = 0.50, batch loss = 0.24 (138.9 examples/sec; 0.058 sec/batch; 1h:22m:51s remains)
INFO - root - 2022-02-24 20:32:12.641486: step 113160, total loss = 0.56, batch loss = 0.30 (283.2 examples/sec; 0.028 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:32:12.984367: step 113170, total loss = 0.59, batch loss = 0.33 (162.7 examples/sec; 0.049 sec/batch; 1h:10m:45s remains)
INFO - root - 2022-02-24 20:32:13.313806: step 113180, total loss = 0.48, batch loss = 0.21 (332.0 examples/sec; 0.024 sec/batch; 0h:34m:40s remains)
INFO - root - 2022-02-24 20:32:13.625891: step 113190, total loss = 0.46, batch loss = 0.20 (308.2 examples/sec; 0.026 sec/batch; 0h:37m:20s remains)
INFO - root - 2022-02-24 20:32:14.003751: step 113200, total loss = 0.52, batch loss = 0.26 (196.4 examples/sec; 0.041 sec/batch; 0h:58m:34s remains)
INFO - root - 2022-02-24 20:32:14.424955: step 113210, total loss = 0.56, batch loss = 0.30 (352.8 examples/sec; 0.023 sec/batch; 0h:32m:36s remains)
INFO - root - 2022-02-24 20:32:14.784361: step 113220, total loss = 0.53, batch loss = 0.27 (189.4 examples/sec; 0.042 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:32:15.089611: step 113230, total loss = 0.49, batch loss = 0.23 (332.3 examples/sec; 0.024 sec/batch; 0h:34m:37s remains)
INFO - root - 2022-02-24 20:32:15.450173: step 113240, total loss = 0.58, batch loss = 0.32 (175.7 examples/sec; 0.046 sec/batch; 1h:05m:27s remains)
INFO - root - 2022-02-24 20:32:15.839575: step 113250, total loss = 0.55, batch loss = 0.29 (241.7 examples/sec; 0.033 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:32:16.284457: step 113260, total loss = 0.57, batch loss = 0.31 (174.3 examples/sec; 0.046 sec/batch; 1h:05m:58s remains)
INFO - root - 2022-02-24 20:32:16.592371: step 113270, total loss = 0.54, batch loss = 0.28 (249.8 examples/sec; 0.032 sec/batch; 0h:46m:01s remains)
INFO - root - 2022-02-24 20:32:16.951593: step 113280, total loss = 0.54, batch loss = 0.28 (226.1 examples/sec; 0.035 sec/batch; 0h:50m:50s remains)
INFO - root - 2022-02-24 20:32:17.314286: step 113290, total loss = 0.50, batch loss = 0.24 (279.4 examples/sec; 0.029 sec/batch; 0h:41m:08s remains)
INFO - root - 2022-02-24 20:32:17.662891: step 113300, total loss = 0.52, batch loss = 0.26 (349.5 examples/sec; 0.023 sec/batch; 0h:32m:52s remains)
INFO - root - 2022-02-24 20:32:18.116233: step 113310, total loss = 0.58, batch loss = 0.32 (275.0 examples/sec; 0.029 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:32:18.503883: step 113320, total loss = 0.50, batch loss = 0.24 (198.0 examples/sec; 0.040 sec/batch; 0h:58m:01s remains)
INFO - root - 2022-02-24 20:32:18.825946: step 113330, total loss = 0.59, batch loss = 0.33 (336.3 examples/sec; 0.024 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:32:19.076945: step 113340, total loss = 0.53, batch loss = 0.27 (338.7 examples/sec; 0.024 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:32:19.439820: step 113350, total loss = 0.54, batch loss = 0.28 (285.2 examples/sec; 0.028 sec/batch; 0h:40m:16s remains)
INFO - root - 2022-02-24 20:32:19.851228: step 113360, total loss = 0.44, batch loss = 0.18 (138.6 examples/sec; 0.058 sec/batch; 1h:22m:53s remains)
INFO - root - 2022-02-24 20:32:20.200104: step 113370, total loss = 0.61, batch loss = 0.34 (353.0 examples/sec; 0.023 sec/batch; 0h:32m:32s remains)
INFO - root - 2022-02-24 20:32:20.457595: step 113380, total loss = 0.49, batch loss = 0.23 (329.5 examples/sec; 0.024 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:32:20.780576: step 113390, total loss = 0.50, batch loss = 0.24 (188.4 examples/sec; 0.042 sec/batch; 1h:00m:57s remains)
INFO - root - 2022-02-24 20:32:21.067946: step 113400, total loss = 0.47, batch loss = 0.21 (327.3 examples/sec; 0.024 sec/batch; 0h:35m:04s remains)
INFO - root - 2022-02-24 20:32:21.428157: step 113410, total loss = 0.58, batch loss = 0.31 (311.4 examples/sec; 0.026 sec/batch; 0h:36m:51s remains)
INFO - root - 2022-02-24 20:32:21.804352: step 113420, total loss = 0.56, batch loss = 0.30 (190.4 examples/sec; 0.042 sec/batch; 1h:00m:16s remains)
INFO - root - 2022-02-24 20:32:22.176795: step 113430, total loss = 0.66, batch loss = 0.40 (241.8 examples/sec; 0.033 sec/batch; 0h:47m:27s remains)
INFO - root - 2022-02-24 20:32:22.462546: step 113440, total loss = 0.64, batch loss = 0.38 (314.8 examples/sec; 0.025 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:32:22.803769: step 113450, total loss = 0.55, batch loss = 0.29 (214.8 examples/sec; 0.037 sec/batch; 0h:53m:24s remains)
INFO - root - 2022-02-24 20:32:23.051135: step 113460, total loss = 0.54, batch loss = 0.28 (326.6 examples/sec; 0.024 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:32:23.384099: step 113470, total loss = 0.49, batch loss = 0.23 (108.8 examples/sec; 0.074 sec/batch; 1h:45m:25s remains)
INFO - root - 2022-02-24 20:32:23.839539: step 113480, total loss = 0.55, batch loss = 0.29 (376.8 examples/sec; 0.021 sec/batch; 0h:30m:26s remains)
INFO - root - 2022-02-24 20:32:24.250345: step 113490, total loss = 0.58, batch loss = 0.32 (259.0 examples/sec; 0.031 sec/batch; 0h:44m:17s remains)
INFO - root - 2022-02-24 20:32:24.519448: step 113500, total loss = 0.55, batch loss = 0.29 (328.8 examples/sec; 0.024 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:32:24.880667: step 113510, total loss = 0.67, batch loss = 0.41 (344.7 examples/sec; 0.023 sec/batch; 0h:33m:15s remains)
INFO - root - 2022-02-24 20:32:25.128165: step 113520, total loss = 0.59, batch loss = 0.33 (331.3 examples/sec; 0.024 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:32:25.542419: step 113530, total loss = 0.52, batch loss = 0.26 (154.6 examples/sec; 0.052 sec/batch; 1h:14m:07s remains)
INFO - root - 2022-02-24 20:32:26.015253: step 113540, total loss = 0.65, batch loss = 0.39 (252.7 examples/sec; 0.032 sec/batch; 0h:45m:20s remains)
INFO - root - 2022-02-24 20:32:26.403186: step 113550, total loss = 0.55, batch loss = 0.29 (123.0 examples/sec; 0.065 sec/batch; 1h:33m:09s remains)
INFO - root - 2022-02-24 20:32:27.848532: step 113560, total loss = 0.54, batch loss = 0.28 (340.8 examples/sec; 0.023 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:32:28.288768: step 113570, total loss = 0.53, batch loss = 0.27 (178.5 examples/sec; 0.045 sec/batch; 1h:04m:12s remains)
INFO - root - 2022-02-24 20:32:28.766747: step 113580, total loss = 0.50, batch loss = 0.24 (124.2 examples/sec; 0.064 sec/batch; 1h:32m:15s remains)
INFO - root - 2022-02-24 20:32:29.136021: step 113590, total loss = 0.51, batch loss = 0.25 (318.2 examples/sec; 0.025 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 20:32:29.466397: step 113600, total loss = 0.63, batch loss = 0.37 (199.7 examples/sec; 0.040 sec/batch; 0h:57m:20s remains)
INFO - root - 2022-02-24 20:32:29.948193: step 113610, total loss = 0.56, batch loss = 0.30 (367.9 examples/sec; 0.022 sec/batch; 0h:31m:07s remains)
INFO - root - 2022-02-24 20:32:30.435505: step 113620, total loss = 0.55, batch loss = 0.29 (102.3 examples/sec; 0.078 sec/batch; 1h:51m:56s remains)
INFO - root - 2022-02-24 20:32:30.799880: step 113630, total loss = 0.56, batch loss = 0.30 (205.7 examples/sec; 0.039 sec/batch; 0h:55m:40s remains)
INFO - root - 2022-02-24 20:32:31.239112: step 113640, total loss = 0.57, batch loss = 0.31 (116.5 examples/sec; 0.069 sec/batch; 1h:38m:17s remains)
INFO - root - 2022-02-24 20:32:31.799946: step 113650, total loss = 0.71, batch loss = 0.45 (169.9 examples/sec; 0.047 sec/batch; 1h:07m:22s remains)
INFO - root - 2022-02-24 20:32:32.329188: step 113660, total loss = 0.60, batch loss = 0.34 (126.7 examples/sec; 0.063 sec/batch; 1h:30m:18s remains)
INFO - root - 2022-02-24 20:32:32.826454: step 113670, total loss = 0.59, batch loss = 0.32 (318.0 examples/sec; 0.025 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:32:33.353216: step 113680, total loss = 0.65, batch loss = 0.39 (146.8 examples/sec; 0.054 sec/batch; 1h:17m:56s remains)
INFO - root - 2022-02-24 20:32:33.721489: step 113690, total loss = 0.56, batch loss = 0.30 (137.6 examples/sec; 0.058 sec/batch; 1h:23m:07s remains)
INFO - root - 2022-02-24 20:32:34.085587: step 113700, total loss = 0.52, batch loss = 0.26 (360.0 examples/sec; 0.022 sec/batch; 0h:31m:46s remains)
INFO - root - 2022-02-24 20:32:34.459584: step 113710, total loss = 0.60, batch loss = 0.34 (318.4 examples/sec; 0.025 sec/batch; 0h:35m:55s remains)
INFO - root - 2022-02-24 20:32:34.723851: step 113720, total loss = 0.51, batch loss = 0.25 (330.5 examples/sec; 0.024 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:32:35.039183: step 113730, total loss = 0.60, batch loss = 0.34 (329.9 examples/sec; 0.024 sec/batch; 0h:34m:40s remains)
INFO - root - 2022-02-24 20:32:35.489885: step 113740, total loss = 0.51, batch loss = 0.25 (112.4 examples/sec; 0.071 sec/batch; 1h:41m:45s remains)
INFO - root - 2022-02-24 20:32:35.878111: step 113750, total loss = 0.60, batch loss = 0.34 (190.0 examples/sec; 0.042 sec/batch; 1h:00m:10s remains)
INFO - root - 2022-02-24 20:32:36.298641: step 113760, total loss = 0.61, batch loss = 0.34 (327.3 examples/sec; 0.024 sec/batch; 0h:34m:55s remains)
INFO - root - 2022-02-24 20:32:36.569235: step 113770, total loss = 0.51, batch loss = 0.25 (293.3 examples/sec; 0.027 sec/batch; 0h:38m:58s remains)
INFO - root - 2022-02-24 20:32:36.881908: step 113780, total loss = 0.53, batch loss = 0.27 (178.2 examples/sec; 0.045 sec/batch; 1h:04m:07s remains)
INFO - root - 2022-02-24 20:32:37.277044: step 113790, total loss = 0.56, batch loss = 0.30 (76.7 examples/sec; 0.104 sec/batch; 2h:28m:57s remains)
INFO - root - 2022-02-24 20:32:37.705253: step 113800, total loss = 0.59, batch loss = 0.33 (141.9 examples/sec; 0.056 sec/batch; 1h:20m:32s remains)
INFO - root - 2022-02-24 20:32:38.248961: step 113810, total loss = 0.51, batch loss = 0.24 (250.9 examples/sec; 0.032 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:32:38.625800: step 113820, total loss = 0.60, batch loss = 0.34 (364.0 examples/sec; 0.022 sec/batch; 0h:31m:22s remains)
INFO - root - 2022-02-24 20:32:38.923534: step 113830, total loss = 0.49, batch loss = 0.23 (314.3 examples/sec; 0.025 sec/batch; 0h:36m:20s remains)
INFO - root - 2022-02-24 20:32:39.264182: step 113840, total loss = 0.56, batch loss = 0.30 (307.3 examples/sec; 0.026 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:32:39.594665: step 113850, total loss = 0.68, batch loss = 0.42 (284.7 examples/sec; 0.028 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:32:40.024586: step 113860, total loss = 0.51, batch loss = 0.24 (183.5 examples/sec; 0.044 sec/batch; 1h:02m:14s remains)
INFO - root - 2022-02-24 20:32:40.367152: step 113870, total loss = 0.51, batch loss = 0.25 (345.7 examples/sec; 0.023 sec/batch; 0h:33m:01s remains)
INFO - root - 2022-02-24 20:32:40.692994: step 113880, total loss = 0.67, batch loss = 0.41 (232.7 examples/sec; 0.034 sec/batch; 0h:49m:03s remains)
INFO - root - 2022-02-24 20:32:40.974824: step 113890, total loss = 0.67, batch loss = 0.40 (332.0 examples/sec; 0.024 sec/batch; 0h:34m:23s remains)
INFO - root - 2022-02-24 20:32:41.284529: step 113900, total loss = 0.49, batch loss = 0.23 (223.2 examples/sec; 0.036 sec/batch; 0h:51m:08s remains)
INFO - root - 2022-02-24 20:32:41.701048: step 113910, total loss = 0.52, batch loss = 0.26 (195.2 examples/sec; 0.041 sec/batch; 0h:58m:27s remains)
INFO - root - 2022-02-24 20:32:42.136096: step 113920, total loss = 0.55, batch loss = 0.29 (150.0 examples/sec; 0.053 sec/batch; 1h:16m:03s remains)
INFO - root - 2022-02-24 20:32:42.569254: step 113930, total loss = 0.49, batch loss = 0.23 (164.9 examples/sec; 0.049 sec/batch; 1h:09m:12s remains)
INFO - root - 2022-02-24 20:32:42.928010: step 113940, total loss = 0.51, batch loss = 0.25 (184.9 examples/sec; 0.043 sec/batch; 1h:01m:42s remains)
INFO - root - 2022-02-24 20:32:43.195473: step 113950, total loss = 0.48, batch loss = 0.22 (364.7 examples/sec; 0.022 sec/batch; 0h:31m:16s remains)
INFO - root - 2022-02-24 20:32:43.533224: step 113960, total loss = 0.65, batch loss = 0.39 (142.0 examples/sec; 0.056 sec/batch; 1h:20m:20s remains)
INFO - root - 2022-02-24 20:32:43.858393: step 113970, total loss = 0.60, batch loss = 0.34 (215.0 examples/sec; 0.037 sec/batch; 0h:53m:03s remains)
INFO - root - 2022-02-24 20:32:44.294540: step 113980, total loss = 0.66, batch loss = 0.40 (187.7 examples/sec; 0.043 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:32:44.620459: step 113990, total loss = 0.52, batch loss = 0.26 (204.4 examples/sec; 0.039 sec/batch; 0h:55m:46s remains)
INFO - root - 2022-02-24 20:32:44.877712: step 114000, total loss = 0.73, batch loss = 0.47 (337.5 examples/sec; 0.024 sec/batch; 0h:33m:46s remains)
INFO - root - 2022-02-24 20:32:45.210576: step 114010, total loss = 0.51, batch loss = 0.25 (334.7 examples/sec; 0.024 sec/batch; 0h:34m:03s remains)
INFO - root - 2022-02-24 20:32:45.551481: step 114020, total loss = 0.56, batch loss = 0.30 (326.8 examples/sec; 0.024 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:32:46.005864: step 114030, total loss = 0.55, batch loss = 0.28 (113.0 examples/sec; 0.071 sec/batch; 1h:40m:50s remains)
INFO - root - 2022-02-24 20:32:46.363743: step 114040, total loss = 0.62, batch loss = 0.36 (173.3 examples/sec; 0.046 sec/batch; 1h:05m:45s remains)
INFO - root - 2022-02-24 20:32:46.647350: step 114050, total loss = 0.50, batch loss = 0.24 (314.5 examples/sec; 0.025 sec/batch; 0h:36m:13s remains)
INFO - root - 2022-02-24 20:32:46.949115: step 114060, total loss = 0.54, batch loss = 0.27 (356.8 examples/sec; 0.022 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:32:47.224097: step 114070, total loss = 0.49, batch loss = 0.23 (287.7 examples/sec; 0.028 sec/batch; 0h:39m:35s remains)
INFO - root - 2022-02-24 20:32:47.509050: step 114080, total loss = 0.53, batch loss = 0.27 (285.6 examples/sec; 0.028 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 20:32:47.910854: step 114090, total loss = 0.52, batch loss = 0.26 (366.0 examples/sec; 0.022 sec/batch; 0h:31m:06s remains)
INFO - root - 2022-02-24 20:32:48.283478: step 114100, total loss = 0.59, batch loss = 0.33 (342.6 examples/sec; 0.023 sec/batch; 0h:33m:14s remains)
INFO - root - 2022-02-24 20:32:48.647835: step 114110, total loss = 0.55, batch loss = 0.29 (317.8 examples/sec; 0.025 sec/batch; 0h:35m:49s remains)
INFO - root - 2022-02-24 20:32:48.996801: step 114120, total loss = 0.60, batch loss = 0.34 (149.0 examples/sec; 0.054 sec/batch; 1h:16m:24s remains)
INFO - root - 2022-02-24 20:32:49.327930: step 114130, total loss = 0.53, batch loss = 0.27 (348.4 examples/sec; 0.023 sec/batch; 0h:32m:40s remains)
INFO - root - 2022-02-24 20:32:49.726108: step 114140, total loss = 0.49, batch loss = 0.23 (204.8 examples/sec; 0.039 sec/batch; 0h:55m:33s remains)
INFO - root - 2022-02-24 20:32:50.030748: step 114150, total loss = 0.55, batch loss = 0.29 (349.5 examples/sec; 0.023 sec/batch; 0h:32m:33s remains)
INFO - root - 2022-02-24 20:32:50.336685: step 114160, total loss = 0.49, batch loss = 0.23 (225.7 examples/sec; 0.035 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:32:50.631750: step 114170, total loss = 0.52, batch loss = 0.26 (326.3 examples/sec; 0.025 sec/batch; 0h:34m:51s remains)
INFO - root - 2022-02-24 20:32:50.991004: step 114180, total loss = 0.49, batch loss = 0.23 (172.8 examples/sec; 0.046 sec/batch; 1h:05m:49s remains)
INFO - root - 2022-02-24 20:32:51.377937: step 114190, total loss = 0.64, batch loss = 0.38 (130.5 examples/sec; 0.061 sec/batch; 1h:27m:11s remains)
INFO - root - 2022-02-24 20:32:51.794823: step 114200, total loss = 0.70, batch loss = 0.44 (255.3 examples/sec; 0.031 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:32:52.390963: step 114210, total loss = 0.47, batch loss = 0.21 (95.8 examples/sec; 0.084 sec/batch; 1h:58m:44s remains)
INFO - root - 2022-02-24 20:32:52.800523: step 114220, total loss = 0.49, batch loss = 0.23 (194.8 examples/sec; 0.041 sec/batch; 0h:58m:21s remains)
INFO - root - 2022-02-24 20:32:53.104513: step 114230, total loss = 0.57, batch loss = 0.31 (282.6 examples/sec; 0.028 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:32:53.518680: step 114240, total loss = 0.51, batch loss = 0.25 (210.1 examples/sec; 0.038 sec/batch; 0h:54m:05s remains)
INFO - root - 2022-02-24 20:32:53.986496: step 114250, total loss = 0.51, batch loss = 0.25 (122.5 examples/sec; 0.065 sec/batch; 1h:32m:45s remains)
INFO - root - 2022-02-24 20:32:54.378086: step 114260, total loss = 0.47, batch loss = 0.21 (286.7 examples/sec; 0.028 sec/batch; 0h:39m:38s remains)
INFO - root - 2022-02-24 20:32:54.738476: step 114270, total loss = 0.57, batch loss = 0.31 (247.6 examples/sec; 0.032 sec/batch; 0h:45m:53s remains)
INFO - root - 2022-02-24 20:32:55.233363: step 114280, total loss = 0.61, batch loss = 0.35 (110.6 examples/sec; 0.072 sec/batch; 1h:42m:42s remains)
INFO - root - 2022-02-24 20:32:55.779365: step 114290, total loss = 0.63, batch loss = 0.36 (208.1 examples/sec; 0.038 sec/batch; 0h:54m:35s remains)
INFO - root - 2022-02-24 20:32:56.395938: step 114300, total loss = 0.64, batch loss = 0.38 (103.2 examples/sec; 0.078 sec/batch; 1h:50m:04s remains)
INFO - root - 2022-02-24 20:32:56.881406: step 114310, total loss = 0.59, batch loss = 0.33 (326.6 examples/sec; 0.024 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 20:32:57.223629: step 114320, total loss = 0.46, batch loss = 0.20 (322.9 examples/sec; 0.025 sec/batch; 0h:35m:10s remains)
INFO - root - 2022-02-24 20:32:57.781151: step 114330, total loss = 0.56, batch loss = 0.30 (99.8 examples/sec; 0.080 sec/batch; 1h:53m:46s remains)
INFO - root - 2022-02-24 20:32:58.702087: step 114340, total loss = 0.58, batch loss = 0.32 (356.8 examples/sec; 0.022 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 20:32:59.101970: step 114350, total loss = 0.49, batch loss = 0.23 (272.6 examples/sec; 0.029 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:32:59.449611: step 114360, total loss = 0.48, batch loss = 0.22 (145.7 examples/sec; 0.055 sec/batch; 1h:17m:55s remains)
INFO - root - 2022-02-24 20:32:59.740700: step 114370, total loss = 0.56, batch loss = 0.30 (205.4 examples/sec; 0.039 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:33:00.103730: step 114380, total loss = 0.56, batch loss = 0.30 (149.6 examples/sec; 0.053 sec/batch; 1h:15m:52s remains)
INFO - root - 2022-02-24 20:33:00.501976: step 114390, total loss = 0.53, batch loss = 0.27 (266.3 examples/sec; 0.030 sec/batch; 0h:42m:37s remains)
INFO - root - 2022-02-24 20:33:00.820407: step 114400, total loss = 0.60, batch loss = 0.34 (156.3 examples/sec; 0.051 sec/batch; 1h:12m:34s remains)
INFO - root - 2022-02-24 20:33:01.191063: step 114410, total loss = 0.56, batch loss = 0.30 (185.0 examples/sec; 0.043 sec/batch; 1h:01m:18s remains)
INFO - root - 2022-02-24 20:33:01.502886: step 114420, total loss = 0.49, batch loss = 0.23 (301.7 examples/sec; 0.027 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 20:33:01.876037: step 114430, total loss = 0.50, batch loss = 0.24 (176.1 examples/sec; 0.045 sec/batch; 1h:04m:25s remains)
INFO - root - 2022-02-24 20:33:02.340395: step 114440, total loss = 0.55, batch loss = 0.29 (184.9 examples/sec; 0.043 sec/batch; 1h:01m:20s remains)
INFO - root - 2022-02-24 20:33:02.758019: step 114450, total loss = 0.50, batch loss = 0.24 (199.3 examples/sec; 0.040 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 20:33:03.166919: step 114460, total loss = 0.56, batch loss = 0.30 (225.8 examples/sec; 0.035 sec/batch; 0h:50m:13s remains)
INFO - root - 2022-02-24 20:33:03.769845: step 114470, total loss = 0.54, batch loss = 0.28 (362.5 examples/sec; 0.022 sec/batch; 0h:31m:16s remains)
INFO - root - 2022-02-24 20:33:04.180394: step 114480, total loss = 0.54, batch loss = 0.28 (154.7 examples/sec; 0.052 sec/batch; 1h:13m:17s remains)
INFO - root - 2022-02-24 20:33:04.586253: step 114490, total loss = 0.56, batch loss = 0.29 (277.4 examples/sec; 0.029 sec/batch; 0h:40m:51s remains)
INFO - root - 2022-02-24 20:33:04.885977: step 114500, total loss = 0.63, batch loss = 0.37 (329.7 examples/sec; 0.024 sec/batch; 0h:34m:22s remains)
INFO - root - 2022-02-24 20:33:05.269862: step 114510, total loss = 0.54, batch loss = 0.28 (312.5 examples/sec; 0.026 sec/batch; 0h:36m:15s remains)
INFO - root - 2022-02-24 20:33:05.551367: step 114520, total loss = 0.59, batch loss = 0.33 (326.8 examples/sec; 0.024 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:33:05.891476: step 114530, total loss = 0.56, batch loss = 0.29 (325.9 examples/sec; 0.025 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 20:33:06.302777: step 114540, total loss = 0.47, batch loss = 0.21 (335.8 examples/sec; 0.024 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 20:33:06.620088: step 114550, total loss = 0.52, batch loss = 0.25 (231.7 examples/sec; 0.035 sec/batch; 0h:48m:53s remains)
INFO - root - 2022-02-24 20:33:06.949111: step 114560, total loss = 0.64, batch loss = 0.38 (317.7 examples/sec; 0.025 sec/batch; 0h:35m:38s remains)
INFO - root - 2022-02-24 20:33:07.295047: step 114570, total loss = 0.48, batch loss = 0.22 (178.8 examples/sec; 0.045 sec/batch; 1h:03m:19s remains)
INFO - root - 2022-02-24 20:33:07.642833: step 114580, total loss = 0.61, batch loss = 0.34 (213.0 examples/sec; 0.038 sec/batch; 0h:53m:10s remains)
INFO - root - 2022-02-24 20:33:07.994244: step 114590, total loss = 0.74, batch loss = 0.48 (317.1 examples/sec; 0.025 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 20:33:08.338357: step 114600, total loss = 0.55, batch loss = 0.29 (351.4 examples/sec; 0.023 sec/batch; 0h:32m:12s remains)
INFO - root - 2022-02-24 20:33:08.757049: step 114610, total loss = 0.54, batch loss = 0.27 (262.6 examples/sec; 0.030 sec/batch; 0h:43m:06s remains)
INFO - root - 2022-02-24 20:33:09.059805: step 114620, total loss = 0.56, batch loss = 0.29 (255.6 examples/sec; 0.031 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:33:09.378279: step 114630, total loss = 0.51, batch loss = 0.25 (252.5 examples/sec; 0.032 sec/batch; 0h:44m:48s remains)
INFO - root - 2022-02-24 20:33:09.776754: step 114640, total loss = 0.54, batch loss = 0.28 (111.9 examples/sec; 0.072 sec/batch; 1h:41m:08s remains)
INFO - root - 2022-02-24 20:33:10.172228: step 114650, total loss = 0.57, batch loss = 0.31 (156.5 examples/sec; 0.051 sec/batch; 1h:12m:18s remains)
INFO - root - 2022-02-24 20:33:10.537134: step 114660, total loss = 0.53, batch loss = 0.27 (347.1 examples/sec; 0.023 sec/batch; 0h:32m:35s remains)
INFO - root - 2022-02-24 20:33:10.839474: step 114670, total loss = 0.50, batch loss = 0.24 (331.8 examples/sec; 0.024 sec/batch; 0h:34m:05s remains)
INFO - root - 2022-02-24 20:33:11.128321: step 114680, total loss = 0.52, batch loss = 0.26 (265.9 examples/sec; 0.030 sec/batch; 0h:42m:31s remains)
INFO - root - 2022-02-24 20:33:11.418105: step 114690, total loss = 0.73, batch loss = 0.47 (163.5 examples/sec; 0.049 sec/batch; 1h:09m:08s remains)
INFO - root - 2022-02-24 20:33:11.727325: step 114700, total loss = 0.62, batch loss = 0.36 (179.3 examples/sec; 0.045 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 20:33:12.275112: step 114710, total loss = 0.52, batch loss = 0.26 (329.9 examples/sec; 0.024 sec/batch; 0h:34m:16s remains)
INFO - root - 2022-02-24 20:33:12.604633: step 114720, total loss = 0.60, batch loss = 0.34 (187.1 examples/sec; 0.043 sec/batch; 1h:00m:24s remains)
INFO - root - 2022-02-24 20:33:12.945460: step 114730, total loss = 0.50, batch loss = 0.24 (134.2 examples/sec; 0.060 sec/batch; 1h:24m:13s remains)
INFO - root - 2022-02-24 20:33:13.305976: step 114740, total loss = 0.48, batch loss = 0.22 (173.2 examples/sec; 0.046 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 20:33:13.690876: step 114750, total loss = 0.66, batch loss = 0.40 (205.9 examples/sec; 0.039 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 20:33:14.643236: step 114760, total loss = 0.53, batch loss = 0.27 (270.4 examples/sec; 0.030 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:33:14.974304: step 114770, total loss = 0.60, batch loss = 0.34 (223.1 examples/sec; 0.036 sec/batch; 0h:50m:37s remains)
INFO - root - 2022-02-24 20:33:15.267374: step 114780, total loss = 0.58, batch loss = 0.32 (281.6 examples/sec; 0.028 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:33:15.589233: step 114790, total loss = 0.58, batch loss = 0.31 (340.2 examples/sec; 0.024 sec/batch; 0h:33m:11s remains)
INFO - root - 2022-02-24 20:33:15.952176: step 114800, total loss = 0.48, batch loss = 0.22 (291.9 examples/sec; 0.027 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:33:16.424507: step 114810, total loss = 0.58, batch loss = 0.32 (184.7 examples/sec; 0.043 sec/batch; 1h:01m:07s remains)
INFO - root - 2022-02-24 20:33:16.925994: step 114820, total loss = 0.47, batch loss = 0.20 (163.9 examples/sec; 0.049 sec/batch; 1h:08m:52s remains)
INFO - root - 2022-02-24 20:33:17.252932: step 114830, total loss = 0.62, batch loss = 0.36 (319.3 examples/sec; 0.025 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:33:17.607714: step 114840, total loss = 0.58, batch loss = 0.32 (318.1 examples/sec; 0.025 sec/batch; 0h:35m:29s remains)
INFO - root - 2022-02-24 20:33:17.895439: step 114850, total loss = 0.58, batch loss = 0.32 (340.4 examples/sec; 0.024 sec/batch; 0h:33m:09s remains)
INFO - root - 2022-02-24 20:33:18.237761: step 114860, total loss = 0.54, batch loss = 0.28 (266.6 examples/sec; 0.030 sec/batch; 0h:42m:20s remains)
INFO - root - 2022-02-24 20:33:18.952423: step 114870, total loss = 0.52, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 5h:27m:31s remains)
INFO - root - 2022-02-24 20:33:19.294634: step 114880, total loss = 0.52, batch loss = 0.26 (187.2 examples/sec; 0.043 sec/batch; 1h:00m:15s remains)
INFO - root - 2022-02-24 20:33:19.666836: step 114890, total loss = 0.58, batch loss = 0.32 (132.3 examples/sec; 0.060 sec/batch; 1h:25m:14s remains)
INFO - root - 2022-02-24 20:33:20.043505: step 114900, total loss = 0.61, batch loss = 0.35 (150.7 examples/sec; 0.053 sec/batch; 1h:14m:50s remains)
INFO - root - 2022-02-24 20:33:20.437535: step 114910, total loss = 0.60, batch loss = 0.34 (109.4 examples/sec; 0.073 sec/batch; 1h:43m:07s remains)
INFO - root - 2022-02-24 20:33:20.823843: step 114920, total loss = 0.56, batch loss = 0.30 (200.0 examples/sec; 0.040 sec/batch; 0h:56m:22s remains)
INFO - root - 2022-02-24 20:33:21.213706: step 114930, total loss = 0.55, batch loss = 0.29 (362.3 examples/sec; 0.022 sec/batch; 0h:31m:07s remains)
INFO - root - 2022-02-24 20:33:21.480111: step 114940, total loss = 0.46, batch loss = 0.20 (380.3 examples/sec; 0.021 sec/batch; 0h:29m:38s remains)
INFO - root - 2022-02-24 20:33:21.836099: step 114950, total loss = 0.55, batch loss = 0.29 (183.0 examples/sec; 0.044 sec/batch; 1h:01m:37s remains)
INFO - root - 2022-02-24 20:33:22.070296: step 114960, total loss = 0.53, batch loss = 0.27 (332.2 examples/sec; 0.024 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:33:22.378724: step 114970, total loss = 0.61, batch loss = 0.35 (319.5 examples/sec; 0.025 sec/batch; 0h:35m:16s remains)
INFO - root - 2022-02-24 20:33:22.763465: step 114980, total loss = 0.55, batch loss = 0.29 (154.8 examples/sec; 0.052 sec/batch; 1h:12m:48s remains)
INFO - root - 2022-02-24 20:33:23.074867: step 114990, total loss = 0.52, batch loss = 0.26 (219.4 examples/sec; 0.036 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:33:23.334274: step 115000, total loss = 0.48, batch loss = 0.22 (310.6 examples/sec; 0.026 sec/batch; 0h:36m:16s remains)
INFO - root - 2022-02-24 20:33:23.731511: step 115010, total loss = 0.59, batch loss = 0.33 (221.5 examples/sec; 0.036 sec/batch; 0h:50m:51s remains)
INFO - root - 2022-02-24 20:33:24.070320: step 115020, total loss = 0.57, batch loss = 0.31 (115.1 examples/sec; 0.070 sec/batch; 1h:37m:51s remains)
INFO - root - 2022-02-24 20:33:24.399983: step 115030, total loss = 0.54, batch loss = 0.28 (341.5 examples/sec; 0.023 sec/batch; 0h:32m:58s remains)
INFO - root - 2022-02-24 20:33:24.874650: step 115040, total loss = 0.53, batch loss = 0.27 (149.6 examples/sec; 0.053 sec/batch; 1h:15m:17s remains)
INFO - root - 2022-02-24 20:33:25.191092: step 115050, total loss = 0.57, batch loss = 0.31 (333.0 examples/sec; 0.024 sec/batch; 0h:33m:48s remains)
INFO - root - 2022-02-24 20:33:25.465893: step 115060, total loss = 0.49, batch loss = 0.23 (324.9 examples/sec; 0.025 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:33:25.795685: step 115070, total loss = 0.51, batch loss = 0.25 (340.0 examples/sec; 0.024 sec/batch; 0h:33m:06s remains)
INFO - root - 2022-02-24 20:33:26.183154: step 115080, total loss = 0.56, batch loss = 0.30 (338.0 examples/sec; 0.024 sec/batch; 0h:33m:17s remains)
INFO - root - 2022-02-24 20:33:26.586481: step 115090, total loss = 0.62, batch loss = 0.36 (187.3 examples/sec; 0.043 sec/batch; 1h:00m:06s remains)
INFO - root - 2022-02-24 20:33:26.972589: step 115100, total loss = 0.57, batch loss = 0.31 (178.4 examples/sec; 0.045 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 20:33:27.449490: step 115110, total loss = 0.54, batch loss = 0.28 (242.4 examples/sec; 0.033 sec/batch; 0h:46m:25s remains)
INFO - root - 2022-02-24 20:33:27.738392: step 115120, total loss = 0.50, batch loss = 0.24 (348.1 examples/sec; 0.023 sec/batch; 0h:32m:19s remains)
INFO - root - 2022-02-24 20:33:28.068919: step 115130, total loss = 0.66, batch loss = 0.40 (256.0 examples/sec; 0.031 sec/batch; 0h:43m:56s remains)
INFO - root - 2022-02-24 20:33:28.356695: step 115140, total loss = 0.52, batch loss = 0.26 (206.7 examples/sec; 0.039 sec/batch; 0h:54m:25s remains)
INFO - root - 2022-02-24 20:33:28.722524: step 115150, total loss = 0.53, batch loss = 0.27 (105.8 examples/sec; 0.076 sec/batch; 1h:46m:15s remains)
INFO - root - 2022-02-24 20:33:29.106629: step 115160, total loss = 0.55, batch loss = 0.29 (368.4 examples/sec; 0.022 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 20:33:29.529558: step 115170, total loss = 0.57, batch loss = 0.31 (147.9 examples/sec; 0.054 sec/batch; 1h:16m:02s remains)
INFO - root - 2022-02-24 20:33:29.854234: step 115180, total loss = 0.57, batch loss = 0.31 (192.9 examples/sec; 0.041 sec/batch; 0h:58m:16s remains)
INFO - root - 2022-02-24 20:33:30.167369: step 115190, total loss = 0.53, batch loss = 0.27 (207.8 examples/sec; 0.039 sec/batch; 0h:54m:06s remains)
INFO - root - 2022-02-24 20:33:30.468409: step 115200, total loss = 0.57, batch loss = 0.30 (287.4 examples/sec; 0.028 sec/batch; 0h:39m:06s remains)
INFO - root - 2022-02-24 20:33:30.838059: step 115210, total loss = 0.67, batch loss = 0.41 (325.7 examples/sec; 0.025 sec/batch; 0h:34m:30s remains)
INFO - root - 2022-02-24 20:33:31.339564: step 115220, total loss = 0.63, batch loss = 0.37 (115.3 examples/sec; 0.069 sec/batch; 1h:37m:28s remains)
INFO - root - 2022-02-24 20:33:31.726409: step 115230, total loss = 0.55, batch loss = 0.29 (151.1 examples/sec; 0.053 sec/batch; 1h:14m:23s remains)
INFO - root - 2022-02-24 20:33:32.121579: step 115240, total loss = 0.52, batch loss = 0.26 (337.6 examples/sec; 0.024 sec/batch; 0h:33m:16s remains)
INFO - root - 2022-02-24 20:33:32.604479: step 115250, total loss = 0.62, batch loss = 0.36 (158.6 examples/sec; 0.050 sec/batch; 1h:10m:50s remains)
INFO - root - 2022-02-24 20:33:33.173139: step 115260, total loss = 0.49, batch loss = 0.23 (233.2 examples/sec; 0.034 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:33:33.675664: step 115270, total loss = 0.49, batch loss = 0.23 (365.5 examples/sec; 0.022 sec/batch; 0h:30m:43s remains)
INFO - root - 2022-02-24 20:33:33.983876: step 115280, total loss = 0.51, batch loss = 0.25 (299.5 examples/sec; 0.027 sec/batch; 0h:37m:29s remains)
INFO - root - 2022-02-24 20:33:34.746554: step 115290, total loss = 0.66, batch loss = 0.39 (319.2 examples/sec; 0.025 sec/batch; 0h:35m:10s remains)
INFO - root - 2022-02-24 20:33:35.206772: step 115300, total loss = 0.50, batch loss = 0.24 (103.0 examples/sec; 0.078 sec/batch; 1h:49m:02s remains)
INFO - root - 2022-02-24 20:33:35.676927: step 115310, total loss = 0.62, batch loss = 0.36 (295.4 examples/sec; 0.027 sec/batch; 0h:37m:59s remains)
INFO - root - 2022-02-24 20:33:35.995914: step 115320, total loss = 0.64, batch loss = 0.38 (319.3 examples/sec; 0.025 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:33:36.282369: step 115330, total loss = 0.60, batch loss = 0.34 (267.2 examples/sec; 0.030 sec/batch; 0h:42m:00s remains)
INFO - root - 2022-02-24 20:33:36.555898: step 115340, total loss = 0.50, batch loss = 0.24 (235.3 examples/sec; 0.034 sec/batch; 0h:47m:41s remains)
INFO - root - 2022-02-24 20:33:36.951749: step 115350, total loss = 0.52, batch loss = 0.26 (317.1 examples/sec; 0.025 sec/batch; 0h:35m:22s remains)
INFO - root - 2022-02-24 20:33:37.296961: step 115360, total loss = 0.55, batch loss = 0.29 (162.4 examples/sec; 0.049 sec/batch; 1h:09m:05s remains)
INFO - root - 2022-02-24 20:33:37.575612: step 115370, total loss = 0.52, batch loss = 0.26 (322.6 examples/sec; 0.025 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 20:33:37.917764: step 115380, total loss = 0.51, batch loss = 0.25 (346.5 examples/sec; 0.023 sec/batch; 0h:32m:22s remains)
INFO - root - 2022-02-24 20:33:38.212311: step 115390, total loss = 0.57, batch loss = 0.30 (189.2 examples/sec; 0.042 sec/batch; 0h:59m:16s remains)
INFO - root - 2022-02-24 20:33:38.617351: step 115400, total loss = 0.65, batch loss = 0.39 (214.4 examples/sec; 0.037 sec/batch; 0h:52m:18s remains)
INFO - root - 2022-02-24 20:33:39.163095: step 115410, total loss = 0.57, batch loss = 0.30 (133.2 examples/sec; 0.060 sec/batch; 1h:24m:11s remains)
INFO - root - 2022-02-24 20:33:39.578835: step 115420, total loss = 0.67, batch loss = 0.41 (209.0 examples/sec; 0.038 sec/batch; 0h:53m:38s remains)
INFO - root - 2022-02-24 20:33:39.874988: step 115430, total loss = 0.50, batch loss = 0.24 (288.2 examples/sec; 0.028 sec/batch; 0h:38m:53s remains)
INFO - root - 2022-02-24 20:33:40.217951: step 115440, total loss = 0.53, batch loss = 0.27 (213.6 examples/sec; 0.037 sec/batch; 0h:52m:28s remains)
INFO - root - 2022-02-24 20:33:40.561752: step 115450, total loss = 0.58, batch loss = 0.31 (359.6 examples/sec; 0.022 sec/batch; 0h:31m:09s remains)
INFO - root - 2022-02-24 20:33:40.988040: step 115460, total loss = 0.53, batch loss = 0.27 (97.1 examples/sec; 0.082 sec/batch; 1h:55m:26s remains)
INFO - root - 2022-02-24 20:33:41.392880: step 115470, total loss = 0.49, batch loss = 0.23 (331.7 examples/sec; 0.024 sec/batch; 0h:33m:46s remains)
INFO - root - 2022-02-24 20:33:41.769255: step 115480, total loss = 0.71, batch loss = 0.44 (316.1 examples/sec; 0.025 sec/batch; 0h:35m:26s remains)
INFO - root - 2022-02-24 20:33:42.052220: step 115490, total loss = 0.54, batch loss = 0.28 (316.3 examples/sec; 0.025 sec/batch; 0h:35m:24s remains)
INFO - root - 2022-02-24 20:33:42.385119: step 115500, total loss = 0.58, batch loss = 0.32 (199.2 examples/sec; 0.040 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 20:33:42.776001: step 115510, total loss = 0.54, batch loss = 0.28 (341.5 examples/sec; 0.023 sec/batch; 0h:32m:47s remains)
INFO - root - 2022-02-24 20:33:43.220033: step 115520, total loss = 0.66, batch loss = 0.40 (96.7 examples/sec; 0.083 sec/batch; 1h:55m:48s remains)
INFO - root - 2022-02-24 20:33:43.644499: step 115530, total loss = 0.61, batch loss = 0.35 (198.2 examples/sec; 0.040 sec/batch; 0h:56m:29s remains)
INFO - root - 2022-02-24 20:33:43.951514: step 115540, total loss = 0.63, batch loss = 0.37 (265.9 examples/sec; 0.030 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:33:44.319205: step 115550, total loss = 0.48, batch loss = 0.22 (325.1 examples/sec; 0.025 sec/batch; 0h:34m:25s remains)
INFO - root - 2022-02-24 20:33:44.608954: step 115560, total loss = 0.51, batch loss = 0.25 (340.0 examples/sec; 0.024 sec/batch; 0h:32m:55s remains)
INFO - root - 2022-02-24 20:33:44.917318: step 115570, total loss = 0.47, batch loss = 0.21 (275.5 examples/sec; 0.029 sec/batch; 0h:40m:36s remains)
INFO - root - 2022-02-24 20:33:45.177595: step 115580, total loss = 0.52, batch loss = 0.26 (285.1 examples/sec; 0.028 sec/batch; 0h:39m:14s remains)
INFO - root - 2022-02-24 20:33:45.588668: step 115590, total loss = 0.56, batch loss = 0.30 (228.3 examples/sec; 0.035 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 20:33:45.990209: step 115600, total loss = 0.51, batch loss = 0.25 (381.0 examples/sec; 0.021 sec/batch; 0h:29m:21s remains)
INFO - root - 2022-02-24 20:33:46.467309: step 115610, total loss = 0.54, batch loss = 0.28 (293.2 examples/sec; 0.027 sec/batch; 0h:38m:08s remains)
INFO - root - 2022-02-24 20:33:46.826815: step 115620, total loss = 0.51, batch loss = 0.25 (193.3 examples/sec; 0.041 sec/batch; 0h:57m:51s remains)
INFO - root - 2022-02-24 20:33:47.160137: step 115630, total loss = 0.56, batch loss = 0.30 (162.0 examples/sec; 0.049 sec/batch; 1h:09m:01s remains)
INFO - root - 2022-02-24 20:33:47.571021: step 115640, total loss = 0.56, batch loss = 0.30 (206.1 examples/sec; 0.039 sec/batch; 0h:54m:14s remains)
INFO - root - 2022-02-24 20:33:48.030159: step 115650, total loss = 0.51, batch loss = 0.25 (211.3 examples/sec; 0.038 sec/batch; 0h:52m:54s remains)
INFO - root - 2022-02-24 20:33:48.380280: step 115660, total loss = 0.58, batch loss = 0.32 (229.7 examples/sec; 0.035 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 20:33:48.685604: step 115670, total loss = 0.62, batch loss = 0.36 (243.5 examples/sec; 0.033 sec/batch; 0h:45m:54s remains)
INFO - root - 2022-02-24 20:33:49.188368: step 115680, total loss = 0.62, batch loss = 0.36 (304.2 examples/sec; 0.026 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:33:50.056773: step 115690, total loss = 0.58, batch loss = 0.32 (166.6 examples/sec; 0.048 sec/batch; 1h:07m:04s remains)
INFO - root - 2022-02-24 20:33:50.407765: step 115700, total loss = 0.55, batch loss = 0.29 (313.9 examples/sec; 0.025 sec/batch; 0h:35m:36s remains)
INFO - root - 2022-02-24 20:33:50.793102: step 115710, total loss = 0.57, batch loss = 0.31 (319.1 examples/sec; 0.025 sec/batch; 0h:35m:00s remains)
INFO - root - 2022-02-24 20:33:51.139645: step 115720, total loss = 0.55, batch loss = 0.29 (253.9 examples/sec; 0.032 sec/batch; 0h:43m:59s remains)
INFO - root - 2022-02-24 20:33:51.492111: step 115730, total loss = 0.45, batch loss = 0.19 (226.1 examples/sec; 0.035 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:33:51.899306: step 115740, total loss = 0.56, batch loss = 0.29 (130.8 examples/sec; 0.061 sec/batch; 1h:25m:24s remains)
INFO - root - 2022-02-24 20:33:52.255334: step 115750, total loss = 0.53, batch loss = 0.27 (387.3 examples/sec; 0.021 sec/batch; 0h:28m:49s remains)
INFO - root - 2022-02-24 20:33:52.700317: step 115760, total loss = 0.56, batch loss = 0.30 (365.1 examples/sec; 0.022 sec/batch; 0h:30m:34s remains)
INFO - root - 2022-02-24 20:33:53.063166: step 115770, total loss = 0.49, batch loss = 0.23 (276.9 examples/sec; 0.029 sec/batch; 0h:40m:18s remains)
INFO - root - 2022-02-24 20:33:53.383588: step 115780, total loss = 0.60, batch loss = 0.34 (210.0 examples/sec; 0.038 sec/batch; 0h:53m:09s remains)
INFO - root - 2022-02-24 20:33:53.774816: step 115790, total loss = 0.59, batch loss = 0.33 (208.1 examples/sec; 0.038 sec/batch; 0h:53m:37s remains)
INFO - root - 2022-02-24 20:33:54.246119: step 115800, total loss = 0.46, batch loss = 0.20 (156.6 examples/sec; 0.051 sec/batch; 1h:11m:15s remains)
INFO - root - 2022-02-24 20:33:54.652518: step 115810, total loss = 0.52, batch loss = 0.26 (335.6 examples/sec; 0.024 sec/batch; 0h:33m:14s remains)
INFO - root - 2022-02-24 20:33:55.057142: step 115820, total loss = 0.67, batch loss = 0.41 (287.4 examples/sec; 0.028 sec/batch; 0h:38m:48s remains)
INFO - root - 2022-02-24 20:33:55.488549: step 115830, total loss = 0.57, batch loss = 0.31 (165.9 examples/sec; 0.048 sec/batch; 1h:07m:15s remains)
INFO - root - 2022-02-24 20:33:55.890945: step 115840, total loss = 0.54, batch loss = 0.28 (376.2 examples/sec; 0.021 sec/batch; 0h:29m:39s remains)
INFO - root - 2022-02-24 20:33:56.282358: step 115850, total loss = 0.49, batch loss = 0.23 (155.1 examples/sec; 0.052 sec/batch; 1h:11m:54s remains)
INFO - root - 2022-02-24 20:33:56.664243: step 115860, total loss = 0.57, batch loss = 0.31 (358.7 examples/sec; 0.022 sec/batch; 0h:31m:05s remains)
INFO - root - 2022-02-24 20:33:57.013204: step 115870, total loss = 0.60, batch loss = 0.34 (320.6 examples/sec; 0.025 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:33:57.316502: step 115880, total loss = 0.55, batch loss = 0.29 (290.3 examples/sec; 0.028 sec/batch; 0h:38m:24s remains)
INFO - root - 2022-02-24 20:33:57.588196: step 115890, total loss = 0.58, batch loss = 0.32 (335.3 examples/sec; 0.024 sec/batch; 0h:33m:14s remains)
INFO - root - 2022-02-24 20:33:57.958043: step 115900, total loss = 0.52, batch loss = 0.26 (334.3 examples/sec; 0.024 sec/batch; 0h:33m:20s remains)
INFO - root - 2022-02-24 20:33:58.316517: step 115910, total loss = 0.58, batch loss = 0.32 (195.1 examples/sec; 0.041 sec/batch; 0h:57m:07s remains)
INFO - root - 2022-02-24 20:33:58.646629: step 115920, total loss = 0.54, batch loss = 0.27 (346.3 examples/sec; 0.023 sec/batch; 0h:32m:10s remains)
INFO - root - 2022-02-24 20:33:58.964582: step 115930, total loss = 0.66, batch loss = 0.40 (274.6 examples/sec; 0.029 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:33:59.275945: step 115940, total loss = 0.54, batch loss = 0.28 (220.0 examples/sec; 0.036 sec/batch; 0h:50m:38s remains)
INFO - root - 2022-02-24 20:33:59.667336: step 115950, total loss = 0.52, batch loss = 0.25 (171.1 examples/sec; 0.047 sec/batch; 1h:05m:07s remains)
INFO - root - 2022-02-24 20:34:00.068999: step 115960, total loss = 0.51, batch loss = 0.25 (257.7 examples/sec; 0.031 sec/batch; 0h:43m:13s remains)
INFO - root - 2022-02-24 20:34:00.504310: step 115970, total loss = 0.53, batch loss = 0.27 (341.9 examples/sec; 0.023 sec/batch; 0h:32m:34s remains)
INFO - root - 2022-02-24 20:34:00.822458: step 115980, total loss = 0.54, batch loss = 0.28 (254.4 examples/sec; 0.031 sec/batch; 0h:43m:46s remains)
INFO - root - 2022-02-24 20:34:01.222597: step 115990, total loss = 0.47, batch loss = 0.21 (269.6 examples/sec; 0.030 sec/batch; 0h:41m:17s remains)
INFO - root - 2022-02-24 20:34:01.538310: step 116000, total loss = 0.52, batch loss = 0.26 (179.1 examples/sec; 0.045 sec/batch; 1h:02m:09s remains)
INFO - root - 2022-02-24 20:34:02.019379: step 116010, total loss = 0.56, batch loss = 0.30 (178.8 examples/sec; 0.045 sec/batch; 1h:02m:14s remains)
INFO - root - 2022-02-24 20:34:02.380583: step 116020, total loss = 0.54, batch loss = 0.28 (243.3 examples/sec; 0.033 sec/batch; 0h:45m:44s remains)
INFO - root - 2022-02-24 20:34:02.751562: step 116030, total loss = 0.55, batch loss = 0.29 (340.1 examples/sec; 0.024 sec/batch; 0h:32m:43s remains)
INFO - root - 2022-02-24 20:34:03.088611: step 116040, total loss = 0.52, batch loss = 0.26 (241.6 examples/sec; 0.033 sec/batch; 0h:46m:03s remains)
INFO - root - 2022-02-24 20:34:03.418228: step 116050, total loss = 0.51, batch loss = 0.25 (231.1 examples/sec; 0.035 sec/batch; 0h:48m:08s remains)
INFO - root - 2022-02-24 20:34:03.684637: step 116060, total loss = 0.75, batch loss = 0.49 (333.6 examples/sec; 0.024 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:34:04.031135: step 116070, total loss = 0.48, batch loss = 0.22 (368.9 examples/sec; 0.022 sec/batch; 0h:30m:09s remains)
INFO - root - 2022-02-24 20:34:04.466833: step 116080, total loss = 0.54, batch loss = 0.27 (369.7 examples/sec; 0.022 sec/batch; 0h:30m:04s remains)
INFO - root - 2022-02-24 20:34:04.840789: step 116090, total loss = 0.49, batch loss = 0.22 (328.3 examples/sec; 0.024 sec/batch; 0h:33m:52s remains)
INFO - root - 2022-02-24 20:34:05.166768: step 116100, total loss = 0.46, batch loss = 0.20 (332.5 examples/sec; 0.024 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:34:05.538566: step 116110, total loss = 0.50, batch loss = 0.24 (233.3 examples/sec; 0.034 sec/batch; 0h:47m:40s remains)
INFO - root - 2022-02-24 20:34:05.869978: step 116120, total loss = 0.51, batch loss = 0.25 (346.4 examples/sec; 0.023 sec/batch; 0h:32m:05s remains)
INFO - root - 2022-02-24 20:34:06.287115: step 116130, total loss = 0.61, batch loss = 0.35 (257.7 examples/sec; 0.031 sec/batch; 0h:43m:08s remains)
INFO - root - 2022-02-24 20:34:06.701605: step 116140, total loss = 0.51, batch loss = 0.25 (315.5 examples/sec; 0.025 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:34:07.237145: step 116150, total loss = 0.57, batch loss = 0.31 (159.8 examples/sec; 0.050 sec/batch; 1h:09m:32s remains)
INFO - root - 2022-02-24 20:34:07.569303: step 116160, total loss = 0.56, batch loss = 0.30 (318.3 examples/sec; 0.025 sec/batch; 0h:34m:54s remains)
INFO - root - 2022-02-24 20:34:07.938027: step 116170, total loss = 0.58, batch loss = 0.32 (149.8 examples/sec; 0.053 sec/batch; 1h:14m:08s remains)
INFO - root - 2022-02-24 20:34:08.383028: step 116180, total loss = 0.56, batch loss = 0.30 (175.3 examples/sec; 0.046 sec/batch; 1h:03m:21s remains)
INFO - root - 2022-02-24 20:34:08.807747: step 116190, total loss = 0.54, batch loss = 0.28 (299.8 examples/sec; 0.027 sec/batch; 0h:37m:03s remains)
INFO - root - 2022-02-24 20:34:09.348301: step 116200, total loss = 0.58, batch loss = 0.32 (104.0 examples/sec; 0.077 sec/batch; 1h:46m:48s remains)
INFO - root - 2022-02-24 20:34:09.783236: step 116210, total loss = 0.57, batch loss = 0.31 (177.2 examples/sec; 0.045 sec/batch; 1h:02m:40s remains)
INFO - root - 2022-02-24 20:34:10.896396: step 116220, total loss = 0.55, batch loss = 0.29 (265.2 examples/sec; 0.030 sec/batch; 0h:41m:51s remains)
INFO - root - 2022-02-24 20:34:11.218536: step 116230, total loss = 0.48, batch loss = 0.22 (337.7 examples/sec; 0.024 sec/batch; 0h:32m:52s remains)
INFO - root - 2022-02-24 20:34:11.583873: step 116240, total loss = 0.58, batch loss = 0.31 (348.3 examples/sec; 0.023 sec/batch; 0h:31m:52s remains)
INFO - root - 2022-02-24 20:34:11.931877: step 116250, total loss = 0.50, batch loss = 0.24 (137.4 examples/sec; 0.058 sec/batch; 1h:20m:47s remains)
INFO - root - 2022-02-24 20:34:12.263026: step 116260, total loss = 0.69, batch loss = 0.43 (308.3 examples/sec; 0.026 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:34:12.663919: step 116270, total loss = 0.57, batch loss = 0.31 (184.7 examples/sec; 0.043 sec/batch; 1h:00m:05s remains)
INFO - root - 2022-02-24 20:34:13.123785: step 116280, total loss = 0.57, batch loss = 0.31 (151.2 examples/sec; 0.053 sec/batch; 1h:13m:22s remains)
INFO - root - 2022-02-24 20:34:13.544654: step 116290, total loss = 0.55, batch loss = 0.29 (363.8 examples/sec; 0.022 sec/batch; 0h:30m:29s remains)
INFO - root - 2022-02-24 20:34:13.871463: step 116300, total loss = 0.62, batch loss = 0.36 (196.8 examples/sec; 0.041 sec/batch; 0h:56m:21s remains)
INFO - root - 2022-02-24 20:34:14.307229: step 116310, total loss = 0.48, batch loss = 0.22 (201.2 examples/sec; 0.040 sec/batch; 0h:55m:07s remains)
INFO - root - 2022-02-24 20:34:14.710829: step 116320, total loss = 0.56, batch loss = 0.30 (191.9 examples/sec; 0.042 sec/batch; 0h:57m:46s remains)
INFO - root - 2022-02-24 20:34:15.239387: step 116330, total loss = 0.48, batch loss = 0.22 (56.4 examples/sec; 0.142 sec/batch; 3h:16m:30s remains)
INFO - root - 2022-02-24 20:34:15.645810: step 116340, total loss = 0.54, batch loss = 0.28 (138.0 examples/sec; 0.058 sec/batch; 1h:20m:19s remains)
INFO - root - 2022-02-24 20:34:16.086903: step 116350, total loss = 0.49, batch loss = 0.23 (162.8 examples/sec; 0.049 sec/batch; 1h:08m:07s remains)
INFO - root - 2022-02-24 20:34:16.392322: step 116360, total loss = 0.61, batch loss = 0.35 (355.6 examples/sec; 0.022 sec/batch; 0h:31m:10s remains)
INFO - root - 2022-02-24 20:34:16.687835: step 116370, total loss = 0.60, batch loss = 0.34 (260.4 examples/sec; 0.031 sec/batch; 0h:42m:33s remains)
INFO - root - 2022-02-24 20:34:17.171323: step 116380, total loss = 0.53, batch loss = 0.27 (125.2 examples/sec; 0.064 sec/batch; 1h:28m:29s remains)
INFO - root - 2022-02-24 20:34:17.606751: step 116390, total loss = 0.51, batch loss = 0.25 (108.0 examples/sec; 0.074 sec/batch; 1h:42m:34s remains)
INFO - root - 2022-02-24 20:34:17.908984: step 116400, total loss = 0.56, batch loss = 0.30 (234.8 examples/sec; 0.034 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:34:18.254275: step 116410, total loss = 0.60, batch loss = 0.34 (329.1 examples/sec; 0.024 sec/batch; 0h:33m:39s remains)
INFO - root - 2022-02-24 20:34:18.553737: step 116420, total loss = 0.56, batch loss = 0.30 (344.6 examples/sec; 0.023 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 20:34:18.818316: step 116430, total loss = 0.51, batch loss = 0.25 (320.8 examples/sec; 0.025 sec/batch; 0h:34m:31s remains)
INFO - root - 2022-02-24 20:34:19.217917: step 116440, total loss = 0.52, batch loss = 0.25 (365.9 examples/sec; 0.022 sec/batch; 0h:30m:15s remains)
INFO - root - 2022-02-24 20:34:19.645741: step 116450, total loss = 0.53, batch loss = 0.27 (393.2 examples/sec; 0.020 sec/batch; 0h:28m:09s remains)
INFO - root - 2022-02-24 20:34:19.968431: step 116460, total loss = 0.50, batch loss = 0.24 (290.3 examples/sec; 0.028 sec/batch; 0h:38m:08s remains)
INFO - root - 2022-02-24 20:34:20.334665: step 116470, total loss = 0.55, batch loss = 0.29 (332.7 examples/sec; 0.024 sec/batch; 0h:33m:16s remains)
INFO - root - 2022-02-24 20:34:20.587582: step 116480, total loss = 0.51, batch loss = 0.25 (273.2 examples/sec; 0.029 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:34:20.918338: step 116490, total loss = 0.51, batch loss = 0.25 (284.0 examples/sec; 0.028 sec/batch; 0h:38m:58s remains)
INFO - root - 2022-02-24 20:34:21.347046: step 116500, total loss = 0.51, batch loss = 0.25 (231.4 examples/sec; 0.035 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:34:21.858456: step 116510, total loss = 0.50, batch loss = 0.24 (245.5 examples/sec; 0.033 sec/batch; 0h:45m:04s remains)
INFO - root - 2022-02-24 20:34:22.178705: step 116520, total loss = 0.52, batch loss = 0.26 (116.7 examples/sec; 0.069 sec/batch; 1h:34m:48s remains)
INFO - root - 2022-02-24 20:34:22.476104: step 116530, total loss = 0.45, batch loss = 0.19 (319.9 examples/sec; 0.025 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:34:22.778101: step 116540, total loss = 0.53, batch loss = 0.26 (220.3 examples/sec; 0.036 sec/batch; 0h:50m:13s remains)
INFO - root - 2022-02-24 20:34:23.075290: step 116550, total loss = 0.51, batch loss = 0.24 (275.3 examples/sec; 0.029 sec/batch; 0h:40m:10s remains)
INFO - root - 2022-02-24 20:34:23.627493: step 116560, total loss = 0.62, batch loss = 0.35 (77.6 examples/sec; 0.103 sec/batch; 2h:22m:27s remains)
INFO - root - 2022-02-24 20:34:23.987792: step 116570, total loss = 0.53, batch loss = 0.27 (279.6 examples/sec; 0.029 sec/batch; 0h:39m:32s remains)
INFO - root - 2022-02-24 20:34:24.260790: step 116580, total loss = 0.57, batch loss = 0.31 (332.3 examples/sec; 0.024 sec/batch; 0h:33m:16s remains)
INFO - root - 2022-02-24 20:34:24.533034: step 116590, total loss = 0.58, batch loss = 0.32 (345.3 examples/sec; 0.023 sec/batch; 0h:32m:00s remains)
INFO - root - 2022-02-24 20:34:24.899120: step 116600, total loss = 0.45, batch loss = 0.19 (289.5 examples/sec; 0.028 sec/batch; 0h:38m:10s remains)
INFO - root - 2022-02-24 20:34:25.743428: step 116610, total loss = 0.52, batch loss = 0.26 (173.8 examples/sec; 0.046 sec/batch; 1h:03m:35s remains)
INFO - root - 2022-02-24 20:34:26.194987: step 116620, total loss = 0.52, batch loss = 0.26 (336.3 examples/sec; 0.024 sec/batch; 0h:32m:51s remains)
INFO - root - 2022-02-24 20:34:26.539036: step 116630, total loss = 0.55, batch loss = 0.29 (252.8 examples/sec; 0.032 sec/batch; 0h:43m:42s remains)
INFO - root - 2022-02-24 20:34:26.931783: step 116640, total loss = 0.51, batch loss = 0.25 (312.4 examples/sec; 0.026 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:34:27.237227: step 116650, total loss = 0.49, batch loss = 0.23 (336.2 examples/sec; 0.024 sec/batch; 0h:32m:51s remains)
INFO - root - 2022-02-24 20:34:27.660847: step 116660, total loss = 0.54, batch loss = 0.28 (131.1 examples/sec; 0.061 sec/batch; 1h:24m:15s remains)
INFO - root - 2022-02-24 20:34:28.052681: step 116670, total loss = 0.55, batch loss = 0.29 (352.6 examples/sec; 0.023 sec/batch; 0h:31m:19s remains)
INFO - root - 2022-02-24 20:34:28.371763: step 116680, total loss = 0.68, batch loss = 0.42 (191.1 examples/sec; 0.042 sec/batch; 0h:57m:46s remains)
INFO - root - 2022-02-24 20:34:28.791315: step 116690, total loss = 0.58, batch loss = 0.32 (93.3 examples/sec; 0.086 sec/batch; 1h:58m:22s remains)
INFO - root - 2022-02-24 20:34:29.130801: step 116700, total loss = 0.49, batch loss = 0.23 (156.3 examples/sec; 0.051 sec/batch; 1h:10m:36s remains)
INFO - root - 2022-02-24 20:34:29.665856: step 116710, total loss = 0.61, batch loss = 0.35 (169.0 examples/sec; 0.047 sec/batch; 1h:05m:18s remains)
INFO - root - 2022-02-24 20:34:30.129241: step 116720, total loss = 0.44, batch loss = 0.18 (268.6 examples/sec; 0.030 sec/batch; 0h:41m:05s remains)
INFO - root - 2022-02-24 20:34:30.519689: step 116730, total loss = 0.66, batch loss = 0.39 (228.7 examples/sec; 0.035 sec/batch; 0h:48m:14s remains)
INFO - root - 2022-02-24 20:34:31.208693: step 116740, total loss = 0.49, batch loss = 0.23 (176.6 examples/sec; 0.045 sec/batch; 1h:02m:29s remains)
INFO - root - 2022-02-24 20:34:31.690072: step 116750, total loss = 0.52, batch loss = 0.26 (94.6 examples/sec; 0.085 sec/batch; 1h:56m:38s remains)
INFO - root - 2022-02-24 20:34:32.056663: step 116760, total loss = 0.62, batch loss = 0.36 (245.8 examples/sec; 0.033 sec/batch; 0h:44m:53s remains)
INFO - root - 2022-02-24 20:34:32.358712: step 116770, total loss = 0.51, batch loss = 0.25 (381.2 examples/sec; 0.021 sec/batch; 0h:28m:56s remains)
INFO - root - 2022-02-24 20:34:32.764448: step 116780, total loss = 0.50, batch loss = 0.24 (222.3 examples/sec; 0.036 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 20:34:33.110151: step 116790, total loss = 0.47, batch loss = 0.21 (210.2 examples/sec; 0.038 sec/batch; 0h:52m:27s remains)
INFO - root - 2022-02-24 20:34:33.420317: step 116800, total loss = 0.61, batch loss = 0.35 (282.0 examples/sec; 0.028 sec/batch; 0h:39m:06s remains)
INFO - root - 2022-02-24 20:34:33.783982: step 116810, total loss = 0.70, batch loss = 0.44 (237.7 examples/sec; 0.034 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:34:34.186146: step 116820, total loss = 0.49, batch loss = 0.23 (244.3 examples/sec; 0.033 sec/batch; 0h:45m:07s remains)
INFO - root - 2022-02-24 20:34:34.563828: step 116830, total loss = 0.60, batch loss = 0.34 (180.1 examples/sec; 0.044 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 20:34:34.895565: step 116840, total loss = 0.56, batch loss = 0.29 (272.2 examples/sec; 0.029 sec/batch; 0h:40m:29s remains)
INFO - root - 2022-02-24 20:34:35.230506: step 116850, total loss = 0.56, batch loss = 0.30 (137.2 examples/sec; 0.058 sec/batch; 1h:20m:18s remains)
INFO - root - 2022-02-24 20:34:35.680985: step 116860, total loss = 0.59, batch loss = 0.33 (223.0 examples/sec; 0.036 sec/batch; 0h:49m:25s remains)
INFO - root - 2022-02-24 20:34:36.086950: step 116870, total loss = 0.51, batch loss = 0.25 (113.4 examples/sec; 0.071 sec/batch; 1h:37m:08s remains)
INFO - root - 2022-02-24 20:34:36.487177: step 116880, total loss = 0.50, batch loss = 0.24 (304.9 examples/sec; 0.026 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:34:36.762493: step 116890, total loss = 0.52, batch loss = 0.26 (339.5 examples/sec; 0.024 sec/batch; 0h:32m:26s remains)
INFO - root - 2022-02-24 20:34:37.043510: step 116900, total loss = 0.60, batch loss = 0.34 (192.1 examples/sec; 0.042 sec/batch; 0h:57m:20s remains)
INFO - root - 2022-02-24 20:34:37.421118: step 116910, total loss = 0.66, batch loss = 0.40 (254.4 examples/sec; 0.031 sec/batch; 0h:43m:16s remains)
INFO - root - 2022-02-24 20:34:37.792418: step 116920, total loss = 0.47, batch loss = 0.21 (174.0 examples/sec; 0.046 sec/batch; 1h:03m:16s remains)
INFO - root - 2022-02-24 20:34:38.158699: step 116930, total loss = 0.60, batch loss = 0.34 (193.5 examples/sec; 0.041 sec/batch; 0h:56m:54s remains)
INFO - root - 2022-02-24 20:34:38.525926: step 116940, total loss = 0.56, batch loss = 0.30 (293.3 examples/sec; 0.027 sec/batch; 0h:37m:31s remains)
INFO - root - 2022-02-24 20:34:38.864251: step 116950, total loss = 0.50, batch loss = 0.24 (325.6 examples/sec; 0.025 sec/batch; 0h:33m:48s remains)
INFO - root - 2022-02-24 20:34:39.158245: step 116960, total loss = 0.49, batch loss = 0.22 (315.0 examples/sec; 0.025 sec/batch; 0h:34m:55s remains)
INFO - root - 2022-02-24 20:34:39.469374: step 116970, total loss = 0.55, batch loss = 0.28 (319.1 examples/sec; 0.025 sec/batch; 0h:34m:28s remains)
INFO - root - 2022-02-24 20:34:39.837287: step 116980, total loss = 0.53, batch loss = 0.27 (129.9 examples/sec; 0.062 sec/batch; 1h:24m:42s remains)
INFO - root - 2022-02-24 20:34:40.227553: step 116990, total loss = 0.52, batch loss = 0.26 (133.4 examples/sec; 0.060 sec/batch; 1h:22m:26s remains)
INFO - root - 2022-02-24 20:34:40.590069: step 117000, total loss = 0.58, batch loss = 0.31 (347.3 examples/sec; 0.023 sec/batch; 0h:31m:40s remains)
INFO - root - 2022-02-24 20:34:41.021508: step 117010, total loss = 0.55, batch loss = 0.28 (304.8 examples/sec; 0.026 sec/batch; 0h:36m:04s remains)
INFO - root - 2022-02-24 20:34:41.332773: step 117020, total loss = 0.57, batch loss = 0.31 (297.0 examples/sec; 0.027 sec/batch; 0h:37m:01s remains)
INFO - root - 2022-02-24 20:34:41.720255: step 117030, total loss = 0.51, batch loss = 0.25 (229.4 examples/sec; 0.035 sec/batch; 0h:47m:56s remains)
INFO - root - 2022-02-24 20:34:42.108506: step 117040, total loss = 0.60, batch loss = 0.34 (302.3 examples/sec; 0.026 sec/batch; 0h:36m:21s remains)
INFO - root - 2022-02-24 20:34:42.582465: step 117050, total loss = 0.55, batch loss = 0.29 (165.4 examples/sec; 0.048 sec/batch; 1h:06m:26s remains)
INFO - root - 2022-02-24 20:34:43.370865: step 117060, total loss = 0.57, batch loss = 0.31 (326.1 examples/sec; 0.025 sec/batch; 0h:33m:42s remains)
INFO - root - 2022-02-24 20:34:43.917349: step 117070, total loss = 0.57, batch loss = 0.31 (197.6 examples/sec; 0.040 sec/batch; 0h:55m:37s remains)
INFO - root - 2022-02-24 20:34:44.301423: step 117080, total loss = 0.62, batch loss = 0.36 (285.6 examples/sec; 0.028 sec/batch; 0h:38m:28s remains)
INFO - root - 2022-02-24 20:34:44.692201: step 117090, total loss = 0.49, batch loss = 0.22 (304.4 examples/sec; 0.026 sec/batch; 0h:36m:05s remains)
INFO - root - 2022-02-24 20:34:45.049951: step 117100, total loss = 0.49, batch loss = 0.23 (331.4 examples/sec; 0.024 sec/batch; 0h:33m:08s remains)
INFO - root - 2022-02-24 20:34:45.445913: step 117110, total loss = 0.49, batch loss = 0.23 (196.5 examples/sec; 0.041 sec/batch; 0h:55m:54s remains)
INFO - root - 2022-02-24 20:34:45.830812: step 117120, total loss = 0.58, batch loss = 0.32 (117.0 examples/sec; 0.068 sec/batch; 1h:33m:51s remains)
INFO - root - 2022-02-24 20:34:46.715980: step 117130, total loss = 0.56, batch loss = 0.30 (318.6 examples/sec; 0.025 sec/batch; 0h:34m:28s remains)
INFO - root - 2022-02-24 20:34:47.046684: step 117140, total loss = 0.57, batch loss = 0.31 (211.0 examples/sec; 0.038 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:34:47.448304: step 117150, total loss = 0.60, batch loss = 0.33 (127.2 examples/sec; 0.063 sec/batch; 1h:26m:21s remains)
INFO - root - 2022-02-24 20:34:47.811176: step 117160, total loss = 0.47, batch loss = 0.21 (341.6 examples/sec; 0.023 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 20:34:48.223703: step 117170, total loss = 0.63, batch loss = 0.37 (176.9 examples/sec; 0.045 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 20:34:48.526201: step 117180, total loss = 0.56, batch loss = 0.30 (342.0 examples/sec; 0.023 sec/batch; 0h:32m:05s remains)
INFO - root - 2022-02-24 20:34:48.854294: step 117190, total loss = 0.50, batch loss = 0.24 (290.6 examples/sec; 0.028 sec/batch; 0h:37m:45s remains)
INFO - root - 2022-02-24 20:34:49.170849: step 117200, total loss = 0.54, batch loss = 0.28 (187.2 examples/sec; 0.043 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 20:34:49.626348: step 117210, total loss = 0.51, batch loss = 0.25 (161.5 examples/sec; 0.050 sec/batch; 1h:07m:56s remains)
INFO - root - 2022-02-24 20:34:50.010982: step 117220, total loss = 0.52, batch loss = 0.26 (185.8 examples/sec; 0.043 sec/batch; 0h:59m:02s remains)
INFO - root - 2022-02-24 20:34:50.411245: step 117230, total loss = 0.54, batch loss = 0.28 (224.4 examples/sec; 0.036 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:34:50.760256: step 117240, total loss = 0.66, batch loss = 0.40 (201.7 examples/sec; 0.040 sec/batch; 0h:54m:23s remains)
INFO - root - 2022-02-24 20:34:51.084853: step 117250, total loss = 0.55, batch loss = 0.29 (357.6 examples/sec; 0.022 sec/batch; 0h:30m:39s remains)
INFO - root - 2022-02-24 20:34:51.385306: step 117260, total loss = 0.70, batch loss = 0.44 (344.6 examples/sec; 0.023 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 20:34:51.798224: step 117270, total loss = 0.62, batch loss = 0.36 (120.6 examples/sec; 0.066 sec/batch; 1h:30m:56s remains)
INFO - root - 2022-02-24 20:34:52.213508: step 117280, total loss = 0.52, batch loss = 0.26 (109.2 examples/sec; 0.073 sec/batch; 1h:40m:23s remains)
INFO - root - 2022-02-24 20:34:52.579815: step 117290, total loss = 0.47, batch loss = 0.21 (333.4 examples/sec; 0.024 sec/batch; 0h:32m:52s remains)
INFO - root - 2022-02-24 20:34:52.911468: step 117300, total loss = 0.47, batch loss = 0.21 (216.6 examples/sec; 0.037 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:34:53.321375: step 117310, total loss = 0.74, batch loss = 0.48 (159.0 examples/sec; 0.050 sec/batch; 1h:08m:56s remains)
INFO - root - 2022-02-24 20:34:53.591973: step 117320, total loss = 0.60, batch loss = 0.34 (364.5 examples/sec; 0.022 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 20:34:54.034666: step 117330, total loss = 0.69, batch loss = 0.43 (323.5 examples/sec; 0.025 sec/batch; 0h:33m:52s remains)
INFO - root - 2022-02-24 20:34:54.401482: step 117340, total loss = 0.49, batch loss = 0.22 (231.1 examples/sec; 0.035 sec/batch; 0h:47m:24s remains)
INFO - root - 2022-02-24 20:34:54.690318: step 117350, total loss = 0.54, batch loss = 0.28 (352.7 examples/sec; 0.023 sec/batch; 0h:31m:03s remains)
INFO - root - 2022-02-24 20:34:55.002492: step 117360, total loss = 0.58, batch loss = 0.32 (187.5 examples/sec; 0.043 sec/batch; 0h:58m:23s remains)
INFO - root - 2022-02-24 20:34:55.291644: step 117370, total loss = 0.59, batch loss = 0.33 (322.6 examples/sec; 0.025 sec/batch; 0h:33m:56s remains)
INFO - root - 2022-02-24 20:34:55.557531: step 117380, total loss = 0.55, batch loss = 0.28 (349.4 examples/sec; 0.023 sec/batch; 0h:31m:20s remains)
INFO - root - 2022-02-24 20:34:55.971566: step 117390, total loss = 0.51, batch loss = 0.25 (156.3 examples/sec; 0.051 sec/batch; 1h:10m:02s remains)
INFO - root - 2022-02-24 20:34:56.416869: step 117400, total loss = 0.52, batch loss = 0.26 (263.5 examples/sec; 0.030 sec/batch; 0h:41m:32s remains)
INFO - root - 2022-02-24 20:34:56.855878: step 117410, total loss = 0.54, batch loss = 0.28 (338.8 examples/sec; 0.024 sec/batch; 0h:32m:18s remains)
INFO - root - 2022-02-24 20:34:57.180908: step 117420, total loss = 0.61, batch loss = 0.35 (340.5 examples/sec; 0.023 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 20:34:57.541109: step 117430, total loss = 0.57, batch loss = 0.30 (100.5 examples/sec; 0.080 sec/batch; 1h:48m:53s remains)
INFO - root - 2022-02-24 20:34:57.821093: step 117440, total loss = 0.57, batch loss = 0.31 (226.1 examples/sec; 0.035 sec/batch; 0h:48m:23s remains)
INFO - root - 2022-02-24 20:34:58.168987: step 117450, total loss = 0.56, batch loss = 0.29 (231.9 examples/sec; 0.035 sec/batch; 0h:47m:10s remains)
INFO - root - 2022-02-24 20:34:58.542537: step 117460, total loss = 0.61, batch loss = 0.35 (290.1 examples/sec; 0.028 sec/batch; 0h:37m:42s remains)
INFO - root - 2022-02-24 20:34:58.937247: step 117470, total loss = 0.60, batch loss = 0.34 (188.3 examples/sec; 0.042 sec/batch; 0h:58m:05s remains)
INFO - root - 2022-02-24 20:34:59.419876: step 117480, total loss = 0.59, batch loss = 0.33 (207.0 examples/sec; 0.039 sec/batch; 0h:52m:50s remains)
INFO - root - 2022-02-24 20:34:59.990237: step 117490, total loss = 0.56, batch loss = 0.30 (137.7 examples/sec; 0.058 sec/batch; 1h:19m:24s remains)
INFO - root - 2022-02-24 20:35:00.414789: step 117500, total loss = 0.48, batch loss = 0.22 (179.0 examples/sec; 0.045 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 20:35:01.049307: step 117510, total loss = 0.53, batch loss = 0.27 (312.6 examples/sec; 0.026 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 20:35:01.317069: step 117520, total loss = 0.56, batch loss = 0.30 (162.1 examples/sec; 0.049 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 20:35:01.618121: step 117530, total loss = 0.59, batch loss = 0.33 (331.4 examples/sec; 0.024 sec/batch; 0h:32m:58s remains)
INFO - root - 2022-02-24 20:35:02.493827: step 117540, total loss = 0.51, batch loss = 0.25 (345.7 examples/sec; 0.023 sec/batch; 0h:31m:36s remains)
INFO - root - 2022-02-24 20:35:02.958822: step 117550, total loss = 0.49, batch loss = 0.23 (261.3 examples/sec; 0.031 sec/batch; 0h:41m:49s remains)
INFO - root - 2022-02-24 20:35:03.356617: step 117560, total loss = 0.54, batch loss = 0.28 (203.9 examples/sec; 0.039 sec/batch; 0h:53m:34s remains)
INFO - root - 2022-02-24 20:35:03.669961: step 117570, total loss = 0.56, batch loss = 0.30 (338.8 examples/sec; 0.024 sec/batch; 0h:32m:14s remains)
INFO - root - 2022-02-24 20:35:03.953083: step 117580, total loss = 0.58, batch loss = 0.31 (283.2 examples/sec; 0.028 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 20:35:04.207319: step 117590, total loss = 0.55, batch loss = 0.28 (326.1 examples/sec; 0.025 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:35:04.547788: step 117600, total loss = 0.46, batch loss = 0.20 (329.1 examples/sec; 0.024 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:35:05.028364: step 117610, total loss = 0.54, batch loss = 0.28 (145.4 examples/sec; 0.055 sec/batch; 1h:15m:05s remains)
INFO - root - 2022-02-24 20:35:05.497570: step 117620, total loss = 0.51, batch loss = 0.25 (136.5 examples/sec; 0.059 sec/batch; 1h:19m:59s remains)
INFO - root - 2022-02-24 20:35:05.851921: step 117630, total loss = 0.60, batch loss = 0.34 (356.9 examples/sec; 0.022 sec/batch; 0h:30m:35s remains)
INFO - root - 2022-02-24 20:35:06.182362: step 117640, total loss = 0.47, batch loss = 0.21 (179.8 examples/sec; 0.045 sec/batch; 1h:00m:43s remains)
INFO - root - 2022-02-24 20:35:06.477175: step 117650, total loss = 0.63, batch loss = 0.37 (347.6 examples/sec; 0.023 sec/batch; 0h:31m:23s remains)
INFO - root - 2022-02-24 20:35:06.762948: step 117660, total loss = 0.45, batch loss = 0.19 (241.9 examples/sec; 0.033 sec/batch; 0h:45m:06s remains)
INFO - root - 2022-02-24 20:35:07.243484: step 117670, total loss = 0.58, batch loss = 0.32 (253.3 examples/sec; 0.032 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:35:07.618263: step 117680, total loss = 0.57, batch loss = 0.31 (178.7 examples/sec; 0.045 sec/batch; 1h:01m:03s remains)
INFO - root - 2022-02-24 20:35:07.909147: step 117690, total loss = 0.49, batch loss = 0.23 (236.8 examples/sec; 0.034 sec/batch; 0h:46m:04s remains)
INFO - root - 2022-02-24 20:35:08.283975: step 117700, total loss = 0.47, batch loss = 0.21 (286.9 examples/sec; 0.028 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 20:35:08.674573: step 117710, total loss = 0.51, batch loss = 0.25 (148.0 examples/sec; 0.054 sec/batch; 1h:13m:41s remains)
INFO - root - 2022-02-24 20:35:09.056898: step 117720, total loss = 0.74, batch loss = 0.48 (268.3 examples/sec; 0.030 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:35:09.472430: step 117730, total loss = 0.53, batch loss = 0.27 (152.3 examples/sec; 0.053 sec/batch; 1h:11m:36s remains)
INFO - root - 2022-02-24 20:35:09.798645: step 117740, total loss = 0.58, batch loss = 0.32 (325.2 examples/sec; 0.025 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:35:10.079471: step 117750, total loss = 0.58, batch loss = 0.32 (261.6 examples/sec; 0.031 sec/batch; 0h:41m:40s remains)
INFO - root - 2022-02-24 20:35:10.365739: step 117760, total loss = 0.57, batch loss = 0.31 (317.7 examples/sec; 0.025 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:35:10.711070: step 117770, total loss = 0.54, batch loss = 0.28 (351.7 examples/sec; 0.023 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 20:35:11.097983: step 117780, total loss = 0.63, batch loss = 0.37 (161.6 examples/sec; 0.050 sec/batch; 1h:07m:25s remains)
INFO - root - 2022-02-24 20:35:11.515768: step 117790, total loss = 0.61, batch loss = 0.35 (372.4 examples/sec; 0.021 sec/batch; 0h:29m:15s remains)
INFO - root - 2022-02-24 20:35:11.891653: step 117800, total loss = 0.54, batch loss = 0.27 (351.7 examples/sec; 0.023 sec/batch; 0h:30m:58s remains)
INFO - root - 2022-02-24 20:35:12.247030: step 117810, total loss = 0.51, batch loss = 0.25 (338.5 examples/sec; 0.024 sec/batch; 0h:32m:10s remains)
INFO - root - 2022-02-24 20:35:12.635518: step 117820, total loss = 0.50, batch loss = 0.24 (298.5 examples/sec; 0.027 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:35:12.935752: step 117830, total loss = 0.50, batch loss = 0.23 (340.8 examples/sec; 0.023 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:35:13.250227: step 117840, total loss = 0.59, batch loss = 0.33 (227.6 examples/sec; 0.035 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:35:13.671366: step 117850, total loss = 0.68, batch loss = 0.42 (368.1 examples/sec; 0.022 sec/batch; 0h:29m:34s remains)
INFO - root - 2022-02-24 20:35:14.039591: step 117860, total loss = 0.51, batch loss = 0.25 (337.6 examples/sec; 0.024 sec/batch; 0h:32m:14s remains)
INFO - root - 2022-02-24 20:35:14.432052: step 117870, total loss = 0.69, batch loss = 0.43 (258.3 examples/sec; 0.031 sec/batch; 0h:42m:08s remains)
INFO - root - 2022-02-24 20:35:14.815192: step 117880, total loss = 0.52, batch loss = 0.26 (312.9 examples/sec; 0.026 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 20:35:15.221310: step 117890, total loss = 0.56, batch loss = 0.29 (198.9 examples/sec; 0.040 sec/batch; 0h:54m:42s remains)
INFO - root - 2022-02-24 20:35:15.693647: step 117900, total loss = 0.56, batch loss = 0.30 (304.8 examples/sec; 0.026 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 20:35:16.236053: step 117910, total loss = 0.49, batch loss = 0.23 (69.4 examples/sec; 0.115 sec/batch; 2h:36m:45s remains)
INFO - root - 2022-02-24 20:35:16.770575: step 117920, total loss = 0.53, batch loss = 0.27 (326.3 examples/sec; 0.025 sec/batch; 0h:33m:20s remains)
INFO - root - 2022-02-24 20:35:17.134312: step 117930, total loss = 0.51, batch loss = 0.25 (322.4 examples/sec; 0.025 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 20:35:17.514693: step 117940, total loss = 0.47, batch loss = 0.21 (185.1 examples/sec; 0.043 sec/batch; 0h:58m:45s remains)
INFO - root - 2022-02-24 20:35:18.433547: step 117950, total loss = 0.62, batch loss = 0.35 (128.6 examples/sec; 0.062 sec/batch; 1h:24m:34s remains)
INFO - root - 2022-02-24 20:35:18.775793: step 117960, total loss = 0.55, batch loss = 0.29 (353.7 examples/sec; 0.023 sec/batch; 0h:30m:44s remains)
INFO - root - 2022-02-24 20:35:19.041741: step 117970, total loss = 0.53, batch loss = 0.27 (325.7 examples/sec; 0.025 sec/batch; 0h:33m:22s remains)
INFO - root - 2022-02-24 20:35:19.353319: step 117980, total loss = 0.52, batch loss = 0.26 (313.6 examples/sec; 0.026 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:35:19.617605: step 117990, total loss = 0.54, batch loss = 0.27 (310.4 examples/sec; 0.026 sec/batch; 0h:35m:00s remains)
INFO - root - 2022-02-24 20:35:20.072664: step 118000, total loss = 0.61, batch loss = 0.34 (176.9 examples/sec; 0.045 sec/batch; 1h:01m:26s remains)
INFO - root - 2022-02-24 20:35:20.508490: step 118010, total loss = 0.61, batch loss = 0.34 (140.8 examples/sec; 0.057 sec/batch; 1h:17m:11s remains)
INFO - root - 2022-02-24 20:35:20.833719: step 118020, total loss = 0.52, batch loss = 0.26 (163.5 examples/sec; 0.049 sec/batch; 1h:06m:26s remains)
INFO - root - 2022-02-24 20:35:21.161780: step 118030, total loss = 0.52, batch loss = 0.26 (199.6 examples/sec; 0.040 sec/batch; 0h:54m:25s remains)
INFO - root - 2022-02-24 20:35:21.526774: step 118040, total loss = 0.46, batch loss = 0.20 (145.5 examples/sec; 0.055 sec/batch; 1h:14m:38s remains)
INFO - root - 2022-02-24 20:35:21.803417: step 118050, total loss = 0.48, batch loss = 0.22 (329.1 examples/sec; 0.024 sec/batch; 0h:32m:59s remains)
INFO - root - 2022-02-24 20:35:22.229825: step 118060, total loss = 0.45, batch loss = 0.19 (189.9 examples/sec; 0.042 sec/batch; 0h:57m:10s remains)
INFO - root - 2022-02-24 20:35:22.603530: step 118070, total loss = 0.58, batch loss = 0.32 (252.0 examples/sec; 0.032 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:35:22.957770: step 118080, total loss = 0.53, batch loss = 0.27 (277.7 examples/sec; 0.029 sec/batch; 0h:39m:05s remains)
INFO - root - 2022-02-24 20:35:23.273816: step 118090, total loss = 0.49, batch loss = 0.23 (209.6 examples/sec; 0.038 sec/batch; 0h:51m:47s remains)
INFO - root - 2022-02-24 20:35:23.554534: step 118100, total loss = 0.51, batch loss = 0.25 (333.8 examples/sec; 0.024 sec/batch; 0h:32m:30s remains)
INFO - root - 2022-02-24 20:35:23.890468: step 118110, total loss = 0.45, batch loss = 0.19 (296.5 examples/sec; 0.027 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:35:24.354307: step 118120, total loss = 0.45, batch loss = 0.19 (90.5 examples/sec; 0.088 sec/batch; 1h:59m:56s remains)
INFO - root - 2022-02-24 20:35:24.651485: step 118130, total loss = 0.52, batch loss = 0.26 (289.6 examples/sec; 0.028 sec/batch; 0h:37m:28s remains)
INFO - root - 2022-02-24 20:35:24.942708: step 118140, total loss = 0.57, batch loss = 0.31 (280.5 examples/sec; 0.029 sec/batch; 0h:38m:40s remains)
INFO - root - 2022-02-24 20:35:25.241829: step 118150, total loss = 0.52, batch loss = 0.26 (351.4 examples/sec; 0.023 sec/batch; 0h:30m:52s remains)
INFO - root - 2022-02-24 20:35:25.514238: step 118160, total loss = 0.62, batch loss = 0.36 (307.8 examples/sec; 0.026 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:35:26.008449: step 118170, total loss = 0.53, batch loss = 0.27 (137.5 examples/sec; 0.058 sec/batch; 1h:18m:51s remains)
INFO - root - 2022-02-24 20:35:26.325961: step 118180, total loss = 0.56, batch loss = 0.30 (212.3 examples/sec; 0.038 sec/batch; 0h:51m:04s remains)
INFO - root - 2022-02-24 20:35:26.727896: step 118190, total loss = 0.54, batch loss = 0.27 (339.8 examples/sec; 0.024 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 20:35:26.978240: step 118200, total loss = 0.63, batch loss = 0.36 (353.1 examples/sec; 0.023 sec/batch; 0h:30m:41s remains)
INFO - root - 2022-02-24 20:35:27.389552: step 118210, total loss = 0.49, batch loss = 0.23 (128.0 examples/sec; 0.062 sec/batch; 1h:24m:40s remains)
INFO - root - 2022-02-24 20:35:27.835457: step 118220, total loss = 0.58, batch loss = 0.32 (152.5 examples/sec; 0.052 sec/batch; 1h:11m:04s remains)
INFO - root - 2022-02-24 20:35:28.180344: step 118230, total loss = 0.54, batch loss = 0.27 (362.7 examples/sec; 0.022 sec/batch; 0h:29m:52s remains)
INFO - root - 2022-02-24 20:35:28.590534: step 118240, total loss = 0.69, batch loss = 0.43 (208.2 examples/sec; 0.038 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:35:28.913506: step 118250, total loss = 0.57, batch loss = 0.31 (326.5 examples/sec; 0.025 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:35:29.239759: step 118260, total loss = 0.56, batch loss = 0.30 (304.8 examples/sec; 0.026 sec/batch; 0h:35m:32s remains)
INFO - root - 2022-02-24 20:35:29.519008: step 118270, total loss = 0.53, batch loss = 0.27 (319.6 examples/sec; 0.025 sec/batch; 0h:33m:53s remains)
INFO - root - 2022-02-24 20:35:29.961593: step 118280, total loss = 0.48, batch loss = 0.22 (239.4 examples/sec; 0.033 sec/batch; 0h:45m:14s remains)
INFO - root - 2022-02-24 20:35:30.358988: step 118290, total loss = 0.58, batch loss = 0.31 (345.9 examples/sec; 0.023 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 20:35:30.682539: step 118300, total loss = 0.58, batch loss = 0.31 (294.3 examples/sec; 0.027 sec/batch; 0h:36m:47s remains)
INFO - root - 2022-02-24 20:35:31.079607: step 118310, total loss = 0.61, batch loss = 0.35 (308.0 examples/sec; 0.026 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:35:31.403160: step 118320, total loss = 0.57, batch loss = 0.31 (219.2 examples/sec; 0.037 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:35:31.794911: step 118330, total loss = 0.63, batch loss = 0.37 (180.4 examples/sec; 0.044 sec/batch; 0h:59m:59s remains)
INFO - root - 2022-02-24 20:35:32.316533: step 118340, total loss = 0.57, batch loss = 0.31 (256.8 examples/sec; 0.031 sec/batch; 0h:42m:08s remains)
INFO - root - 2022-02-24 20:35:32.786863: step 118350, total loss = 0.69, batch loss = 0.43 (271.5 examples/sec; 0.029 sec/batch; 0h:39m:51s remains)
INFO - root - 2022-02-24 20:35:33.857906: step 118360, total loss = 0.61, batch loss = 0.35 (156.8 examples/sec; 0.051 sec/batch; 1h:08m:59s remains)
INFO - root - 2022-02-24 20:35:34.314985: step 118370, total loss = 0.53, batch loss = 0.27 (202.7 examples/sec; 0.039 sec/batch; 0h:53m:21s remains)
INFO - root - 2022-02-24 20:35:34.738366: step 118380, total loss = 0.50, batch loss = 0.24 (108.4 examples/sec; 0.074 sec/batch; 1h:39m:45s remains)
INFO - root - 2022-02-24 20:35:35.060488: step 118390, total loss = 0.54, batch loss = 0.28 (215.5 examples/sec; 0.037 sec/batch; 0h:50m:10s remains)
INFO - root - 2022-02-24 20:35:35.438387: step 118400, total loss = 0.53, batch loss = 0.27 (310.4 examples/sec; 0.026 sec/batch; 0h:34m:50s remains)
INFO - root - 2022-02-24 20:35:35.894506: step 118410, total loss = 0.47, batch loss = 0.21 (136.7 examples/sec; 0.059 sec/batch; 1h:19m:05s remains)
INFO - root - 2022-02-24 20:35:36.248400: step 118420, total loss = 0.52, batch loss = 0.26 (210.7 examples/sec; 0.038 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:35:36.649513: step 118430, total loss = 0.54, batch loss = 0.28 (294.7 examples/sec; 0.027 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:35:36.945071: step 118440, total loss = 0.49, batch loss = 0.23 (351.4 examples/sec; 0.023 sec/batch; 0h:30m:45s remains)
INFO - root - 2022-02-24 20:35:37.194625: step 118450, total loss = 0.60, batch loss = 0.34 (339.4 examples/sec; 0.024 sec/batch; 0h:31m:50s remains)
INFO - root - 2022-02-24 20:35:37.504612: step 118460, total loss = 0.55, batch loss = 0.29 (213.3 examples/sec; 0.038 sec/batch; 0h:50m:39s remains)
INFO - root - 2022-02-24 20:35:37.915252: step 118470, total loss = 0.56, batch loss = 0.30 (106.2 examples/sec; 0.075 sec/batch; 1h:41m:45s remains)
INFO - root - 2022-02-24 20:35:38.322366: step 118480, total loss = 0.54, batch loss = 0.27 (143.6 examples/sec; 0.056 sec/batch; 1h:15m:12s remains)
INFO - root - 2022-02-24 20:35:38.854816: step 118490, total loss = 0.49, batch loss = 0.23 (215.1 examples/sec; 0.037 sec/batch; 0h:50m:13s remains)
INFO - root - 2022-02-24 20:35:39.188389: step 118500, total loss = 0.51, batch loss = 0.25 (337.9 examples/sec; 0.024 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:35:39.554474: step 118510, total loss = 0.51, batch loss = 0.25 (271.5 examples/sec; 0.029 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:35:39.851513: step 118520, total loss = 0.56, batch loss = 0.30 (350.2 examples/sec; 0.023 sec/batch; 0h:30m:50s remains)
INFO - root - 2022-02-24 20:35:40.271941: step 118530, total loss = 0.56, batch loss = 0.30 (137.4 examples/sec; 0.058 sec/batch; 1h:18m:35s remains)
INFO - root - 2022-02-24 20:35:40.656419: step 118540, total loss = 0.59, batch loss = 0.33 (217.5 examples/sec; 0.037 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 20:35:41.014426: step 118550, total loss = 0.54, batch loss = 0.28 (356.0 examples/sec; 0.022 sec/batch; 0h:30m:18s remains)
INFO - root - 2022-02-24 20:35:41.346897: step 118560, total loss = 0.56, batch loss = 0.30 (171.3 examples/sec; 0.047 sec/batch; 1h:03m:00s remains)
INFO - root - 2022-02-24 20:35:41.632125: step 118570, total loss = 0.58, batch loss = 0.32 (242.8 examples/sec; 0.033 sec/batch; 0h:44m:26s remains)
INFO - root - 2022-02-24 20:35:41.990225: step 118580, total loss = 0.49, batch loss = 0.22 (163.9 examples/sec; 0.049 sec/batch; 1h:05m:49s remains)
INFO - root - 2022-02-24 20:35:42.391336: step 118590, total loss = 0.52, batch loss = 0.26 (297.0 examples/sec; 0.027 sec/batch; 0h:36m:19s remains)
INFO - root - 2022-02-24 20:35:42.812466: step 118600, total loss = 0.55, batch loss = 0.29 (179.0 examples/sec; 0.045 sec/batch; 1h:00m:14s remains)
INFO - root - 2022-02-24 20:35:43.286323: step 118610, total loss = 0.67, batch loss = 0.41 (354.0 examples/sec; 0.023 sec/batch; 0h:30m:28s remains)
INFO - root - 2022-02-24 20:35:43.645084: step 118620, total loss = 0.59, batch loss = 0.33 (344.6 examples/sec; 0.023 sec/batch; 0h:31m:17s remains)
INFO - root - 2022-02-24 20:35:44.117814: step 118630, total loss = 0.63, batch loss = 0.37 (122.4 examples/sec; 0.065 sec/batch; 1h:28m:07s remains)
INFO - root - 2022-02-24 20:35:44.438714: step 118640, total loss = 0.57, batch loss = 0.31 (368.5 examples/sec; 0.022 sec/batch; 0h:29m:15s remains)
INFO - root - 2022-02-24 20:35:44.820607: step 118650, total loss = 0.48, batch loss = 0.22 (206.8 examples/sec; 0.039 sec/batch; 0h:52m:07s remains)
INFO - root - 2022-02-24 20:35:45.148060: step 118660, total loss = 0.55, batch loss = 0.29 (207.1 examples/sec; 0.039 sec/batch; 0h:52m:02s remains)
INFO - root - 2022-02-24 20:35:45.430963: step 118670, total loss = 0.49, batch loss = 0.23 (317.8 examples/sec; 0.025 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:35:45.740710: step 118680, total loss = 0.52, batch loss = 0.26 (301.8 examples/sec; 0.027 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 20:35:46.155760: step 118690, total loss = 0.62, batch loss = 0.36 (121.1 examples/sec; 0.066 sec/batch; 1h:28m:56s remains)
INFO - root - 2022-02-24 20:35:46.505368: step 118700, total loss = 0.60, batch loss = 0.34 (265.4 examples/sec; 0.030 sec/batch; 0h:40m:35s remains)
INFO - root - 2022-02-24 20:35:46.962001: step 118710, total loss = 0.47, batch loss = 0.21 (225.4 examples/sec; 0.035 sec/batch; 0h:47m:47s remains)
INFO - root - 2022-02-24 20:35:47.292930: step 118720, total loss = 0.52, batch loss = 0.26 (233.5 examples/sec; 0.034 sec/batch; 0h:46m:07s remains)
INFO - root - 2022-02-24 20:35:47.624171: step 118730, total loss = 0.58, batch loss = 0.31 (224.3 examples/sec; 0.036 sec/batch; 0h:48m:01s remains)
INFO - root - 2022-02-24 20:35:47.928003: step 118740, total loss = 0.57, batch loss = 0.31 (134.5 examples/sec; 0.059 sec/batch; 1h:20m:04s remains)
INFO - root - 2022-02-24 20:35:48.396937: step 118750, total loss = 0.48, batch loss = 0.22 (213.7 examples/sec; 0.037 sec/batch; 0h:50m:22s remains)
INFO - root - 2022-02-24 20:35:48.748020: step 118760, total loss = 0.57, batch loss = 0.30 (220.6 examples/sec; 0.036 sec/batch; 0h:48m:47s remains)
INFO - root - 2022-02-24 20:35:49.224371: step 118770, total loss = 0.52, batch loss = 0.26 (91.5 examples/sec; 0.087 sec/batch; 1h:57m:39s remains)
INFO - root - 2022-02-24 20:35:49.858979: step 118780, total loss = 0.48, batch loss = 0.22 (281.6 examples/sec; 0.028 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:35:50.219395: step 118790, total loss = 0.60, batch loss = 0.33 (267.0 examples/sec; 0.030 sec/batch; 0h:40m:18s remains)
INFO - root - 2022-02-24 20:35:50.706329: step 118800, total loss = 0.51, batch loss = 0.25 (215.4 examples/sec; 0.037 sec/batch; 0h:49m:57s remains)
INFO - root - 2022-02-24 20:35:51.153807: step 118810, total loss = 0.45, batch loss = 0.19 (149.6 examples/sec; 0.053 sec/batch; 1h:11m:53s remains)
INFO - root - 2022-02-24 20:35:51.497273: step 118820, total loss = 0.57, batch loss = 0.31 (160.3 examples/sec; 0.050 sec/batch; 1h:07m:06s remains)
INFO - root - 2022-02-24 20:35:51.967499: step 118830, total loss = 0.51, batch loss = 0.25 (114.8 examples/sec; 0.070 sec/batch; 1h:33m:40s remains)
INFO - root - 2022-02-24 20:35:52.345259: step 118840, total loss = 0.50, batch loss = 0.24 (220.7 examples/sec; 0.036 sec/batch; 0h:48m:43s remains)
INFO - root - 2022-02-24 20:35:52.712193: step 118850, total loss = 0.61, batch loss = 0.35 (266.4 examples/sec; 0.030 sec/batch; 0h:40m:21s remains)
INFO - root - 2022-02-24 20:35:53.485995: step 118860, total loss = 0.56, batch loss = 0.30 (231.1 examples/sec; 0.035 sec/batch; 0h:46m:31s remains)
INFO - root - 2022-02-24 20:35:53.821903: step 118870, total loss = 0.55, batch loss = 0.28 (322.7 examples/sec; 0.025 sec/batch; 0h:33m:18s remains)
INFO - root - 2022-02-24 20:35:54.161179: step 118880, total loss = 0.52, batch loss = 0.26 (344.5 examples/sec; 0.023 sec/batch; 0h:31m:12s remains)
INFO - root - 2022-02-24 20:35:54.533121: step 118890, total loss = 0.63, batch loss = 0.37 (152.9 examples/sec; 0.052 sec/batch; 1h:10m:16s remains)
INFO - root - 2022-02-24 20:35:54.902671: step 118900, total loss = 0.52, batch loss = 0.26 (316.7 examples/sec; 0.025 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:35:55.339954: step 118910, total loss = 0.55, batch loss = 0.29 (195.7 examples/sec; 0.041 sec/batch; 0h:54m:55s remains)
INFO - root - 2022-02-24 20:35:55.759939: step 118920, total loss = 0.55, batch loss = 0.29 (208.2 examples/sec; 0.038 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:35:56.171187: step 118930, total loss = 0.54, batch loss = 0.27 (343.9 examples/sec; 0.023 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:35:56.535522: step 118940, total loss = 0.54, batch loss = 0.28 (225.9 examples/sec; 0.035 sec/batch; 0h:47m:33s remains)
INFO - root - 2022-02-24 20:35:56.877773: step 118950, total loss = 0.52, batch loss = 0.26 (348.2 examples/sec; 0.023 sec/batch; 0h:30m:50s remains)
INFO - root - 2022-02-24 20:35:57.269486: step 118960, total loss = 0.58, batch loss = 0.32 (163.6 examples/sec; 0.049 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:35:57.531563: step 118970, total loss = 0.50, batch loss = 0.24 (285.0 examples/sec; 0.028 sec/batch; 0h:37m:40s remains)
INFO - root - 2022-02-24 20:35:57.855336: step 118980, total loss = 0.56, batch loss = 0.30 (335.3 examples/sec; 0.024 sec/batch; 0h:32m:01s remains)
INFO - root - 2022-02-24 20:35:58.195601: step 118990, total loss = 0.64, batch loss = 0.38 (214.5 examples/sec; 0.037 sec/batch; 0h:50m:02s remains)
INFO - root - 2022-02-24 20:35:58.601747: step 119000, total loss = 0.53, batch loss = 0.27 (354.0 examples/sec; 0.023 sec/batch; 0h:30m:19s remains)
INFO - root - 2022-02-24 20:35:59.043891: step 119010, total loss = 0.63, batch loss = 0.37 (185.1 examples/sec; 0.043 sec/batch; 0h:57m:58s remains)
INFO - root - 2022-02-24 20:35:59.436118: step 119020, total loss = 0.61, batch loss = 0.35 (342.3 examples/sec; 0.023 sec/batch; 0h:31m:20s remains)
INFO - root - 2022-02-24 20:35:59.678493: step 119030, total loss = 0.67, batch loss = 0.41 (333.3 examples/sec; 0.024 sec/batch; 0h:32m:11s remains)
INFO - root - 2022-02-24 20:36:00.071879: step 119040, total loss = 0.51, batch loss = 0.25 (139.1 examples/sec; 0.058 sec/batch; 1h:17m:07s remains)
INFO - root - 2022-02-24 20:36:00.439960: step 119050, total loss = 0.57, batch loss = 0.31 (314.0 examples/sec; 0.025 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:36:00.821774: step 119060, total loss = 0.55, batch loss = 0.29 (180.7 examples/sec; 0.044 sec/batch; 0h:59m:20s remains)
INFO - root - 2022-02-24 20:36:01.283346: step 119070, total loss = 0.62, batch loss = 0.36 (81.7 examples/sec; 0.098 sec/batch; 2h:11m:12s remains)
INFO - root - 2022-02-24 20:36:01.601301: step 119080, total loss = 0.67, batch loss = 0.41 (254.5 examples/sec; 0.031 sec/batch; 0h:42m:07s remains)
INFO - root - 2022-02-24 20:36:01.906076: step 119090, total loss = 0.52, batch loss = 0.26 (331.3 examples/sec; 0.024 sec/batch; 0h:32m:21s remains)
INFO - root - 2022-02-24 20:36:02.208839: step 119100, total loss = 0.57, batch loss = 0.31 (300.8 examples/sec; 0.027 sec/batch; 0h:35m:38s remains)
INFO - root - 2022-02-24 20:36:02.577154: step 119110, total loss = 0.49, batch loss = 0.23 (331.1 examples/sec; 0.024 sec/batch; 0h:32m:22s remains)
INFO - root - 2022-02-24 20:36:02.928041: step 119120, total loss = 0.56, batch loss = 0.29 (151.0 examples/sec; 0.053 sec/batch; 1h:10m:58s remains)
INFO - root - 2022-02-24 20:36:03.416811: step 119130, total loss = 0.51, batch loss = 0.25 (271.2 examples/sec; 0.029 sec/batch; 0h:39m:30s remains)
INFO - root - 2022-02-24 20:36:03.763944: step 119140, total loss = 0.54, batch loss = 0.28 (311.0 examples/sec; 0.026 sec/batch; 0h:34m:26s remains)
INFO - root - 2022-02-24 20:36:04.054158: step 119150, total loss = 0.54, batch loss = 0.28 (211.6 examples/sec; 0.038 sec/batch; 0h:50m:37s remains)
INFO - root - 2022-02-24 20:36:04.382566: step 119160, total loss = 0.54, batch loss = 0.28 (370.4 examples/sec; 0.022 sec/batch; 0h:28m:55s remains)
INFO - root - 2022-02-24 20:36:04.736151: step 119170, total loss = 0.72, batch loss = 0.46 (190.5 examples/sec; 0.042 sec/batch; 0h:56m:13s remains)
INFO - root - 2022-02-24 20:36:05.186775: step 119180, total loss = 0.53, batch loss = 0.27 (228.9 examples/sec; 0.035 sec/batch; 0h:46m:47s remains)
INFO - root - 2022-02-24 20:36:05.566123: step 119190, total loss = 0.47, batch loss = 0.20 (334.0 examples/sec; 0.024 sec/batch; 0h:32m:03s remains)
INFO - root - 2022-02-24 20:36:05.927845: step 119200, total loss = 0.60, batch loss = 0.34 (218.4 examples/sec; 0.037 sec/batch; 0h:49m:01s remains)
INFO - root - 2022-02-24 20:36:06.554926: step 119210, total loss = 0.49, batch loss = 0.23 (297.4 examples/sec; 0.027 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 20:36:07.005219: step 119220, total loss = 0.76, batch loss = 0.50 (154.8 examples/sec; 0.052 sec/batch; 1h:09m:09s remains)
INFO - root - 2022-02-24 20:36:07.563222: step 119230, total loss = 0.65, batch loss = 0.39 (341.1 examples/sec; 0.023 sec/batch; 0h:31m:22s remains)
INFO - root - 2022-02-24 20:36:07.939638: step 119240, total loss = 0.56, batch loss = 0.30 (329.0 examples/sec; 0.024 sec/batch; 0h:32m:31s remains)
INFO - root - 2022-02-24 20:36:08.832497: step 119250, total loss = 0.50, batch loss = 0.24 (210.3 examples/sec; 0.038 sec/batch; 0h:50m:53s remains)
INFO - root - 2022-02-24 20:36:09.218187: step 119260, total loss = 0.54, batch loss = 0.28 (193.3 examples/sec; 0.041 sec/batch; 0h:55m:20s remains)
INFO - root - 2022-02-24 20:36:09.628255: step 119270, total loss = 0.62, batch loss = 0.36 (231.6 examples/sec; 0.035 sec/batch; 0h:46m:11s remains)
INFO - root - 2022-02-24 20:36:10.002786: step 119280, total loss = 0.60, batch loss = 0.34 (360.7 examples/sec; 0.022 sec/batch; 0h:29m:39s remains)
INFO - root - 2022-02-24 20:36:10.351220: step 119290, total loss = 0.44, batch loss = 0.17 (120.4 examples/sec; 0.066 sec/batch; 1h:28m:49s remains)
INFO - root - 2022-02-24 20:36:10.598521: step 119300, total loss = 0.55, batch loss = 0.29 (324.5 examples/sec; 0.025 sec/batch; 0h:32m:57s remains)
INFO - root - 2022-02-24 20:36:10.910905: step 119310, total loss = 0.57, batch loss = 0.31 (351.5 examples/sec; 0.023 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 20:36:11.164777: step 119320, total loss = 0.54, batch loss = 0.28 (356.5 examples/sec; 0.022 sec/batch; 0h:29m:59s remains)
INFO - root - 2022-02-24 20:36:11.554005: step 119330, total loss = 0.51, batch loss = 0.25 (285.8 examples/sec; 0.028 sec/batch; 0h:37m:24s remains)
INFO - root - 2022-02-24 20:36:11.994167: step 119340, total loss = 0.68, batch loss = 0.42 (212.9 examples/sec; 0.038 sec/batch; 0h:50m:12s remains)
INFO - root - 2022-02-24 20:36:12.439866: step 119350, total loss = 0.50, batch loss = 0.24 (287.7 examples/sec; 0.028 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:36:12.728988: step 119360, total loss = 0.56, batch loss = 0.30 (302.6 examples/sec; 0.026 sec/batch; 0h:35m:18s remains)
INFO - root - 2022-02-24 20:36:13.091990: step 119370, total loss = 0.52, batch loss = 0.26 (178.1 examples/sec; 0.045 sec/batch; 0h:59m:59s remains)
INFO - root - 2022-02-24 20:36:13.533570: step 119380, total loss = 0.51, batch loss = 0.25 (194.4 examples/sec; 0.041 sec/batch; 0h:54m:57s remains)
INFO - root - 2022-02-24 20:36:13.961430: step 119390, total loss = 0.57, batch loss = 0.31 (147.9 examples/sec; 0.054 sec/batch; 1h:12m:12s remains)
INFO - root - 2022-02-24 20:36:14.272832: step 119400, total loss = 0.49, batch loss = 0.23 (304.0 examples/sec; 0.026 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:36:14.631937: step 119410, total loss = 0.47, batch loss = 0.21 (347.3 examples/sec; 0.023 sec/batch; 0h:30m:45s remains)
INFO - root - 2022-02-24 20:36:14.879680: step 119420, total loss = 0.53, batch loss = 0.27 (327.8 examples/sec; 0.024 sec/batch; 0h:32m:34s remains)
INFO - root - 2022-02-24 20:36:15.310617: step 119430, total loss = 0.56, batch loss = 0.29 (241.8 examples/sec; 0.033 sec/batch; 0h:44m:09s remains)
INFO - root - 2022-02-24 20:36:15.722095: step 119440, total loss = 0.51, batch loss = 0.25 (191.0 examples/sec; 0.042 sec/batch; 0h:55m:53s remains)
INFO - root - 2022-02-24 20:36:16.107039: step 119450, total loss = 0.58, batch loss = 0.32 (256.8 examples/sec; 0.031 sec/batch; 0h:41m:33s remains)
INFO - root - 2022-02-24 20:36:16.368631: step 119460, total loss = 0.66, batch loss = 0.40 (363.3 examples/sec; 0.022 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 20:36:16.689749: step 119470, total loss = 0.54, batch loss = 0.28 (316.3 examples/sec; 0.025 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 20:36:16.959874: step 119480, total loss = 0.62, batch loss = 0.36 (272.5 examples/sec; 0.029 sec/batch; 0h:39m:09s remains)
INFO - root - 2022-02-24 20:36:17.254485: step 119490, total loss = 0.54, batch loss = 0.28 (182.9 examples/sec; 0.044 sec/batch; 0h:58m:19s remains)
INFO - root - 2022-02-24 20:36:17.588485: step 119500, total loss = 0.53, batch loss = 0.27 (334.0 examples/sec; 0.024 sec/batch; 0h:31m:56s remains)
INFO - root - 2022-02-24 20:36:18.003871: step 119510, total loss = 0.51, batch loss = 0.25 (233.5 examples/sec; 0.034 sec/batch; 0h:45m:40s remains)
INFO - root - 2022-02-24 20:36:18.357958: step 119520, total loss = 0.61, batch loss = 0.35 (185.9 examples/sec; 0.043 sec/batch; 0h:57m:21s remains)
INFO - root - 2022-02-24 20:36:18.692009: step 119530, total loss = 0.52, batch loss = 0.26 (276.1 examples/sec; 0.029 sec/batch; 0h:38m:36s remains)
INFO - root - 2022-02-24 20:36:19.146067: step 119540, total loss = 0.50, batch loss = 0.24 (198.4 examples/sec; 0.040 sec/batch; 0h:53m:44s remains)
INFO - root - 2022-02-24 20:36:19.588632: step 119550, total loss = 0.48, batch loss = 0.22 (233.8 examples/sec; 0.034 sec/batch; 0h:45m:35s remains)
INFO - root - 2022-02-24 20:36:19.979211: step 119560, total loss = 0.59, batch loss = 0.33 (154.5 examples/sec; 0.052 sec/batch; 1h:08m:59s remains)
INFO - root - 2022-02-24 20:36:20.327660: step 119570, total loss = 0.53, batch loss = 0.26 (317.6 examples/sec; 0.025 sec/batch; 0h:33m:33s remains)
INFO - root - 2022-02-24 20:36:20.653663: step 119580, total loss = 0.55, batch loss = 0.29 (311.8 examples/sec; 0.026 sec/batch; 0h:34m:10s remains)
INFO - root - 2022-02-24 20:36:20.969917: step 119590, total loss = 0.66, batch loss = 0.39 (203.7 examples/sec; 0.039 sec/batch; 0h:52m:18s remains)
INFO - root - 2022-02-24 20:36:21.394518: step 119600, total loss = 0.67, batch loss = 0.41 (153.7 examples/sec; 0.052 sec/batch; 1h:09m:19s remains)
INFO - root - 2022-02-24 20:36:21.831855: step 119610, total loss = 0.57, batch loss = 0.31 (148.2 examples/sec; 0.054 sec/batch; 1h:11m:51s remains)
INFO - root - 2022-02-24 20:36:22.202899: step 119620, total loss = 0.42, batch loss = 0.16 (356.0 examples/sec; 0.022 sec/batch; 0h:29m:55s remains)
INFO - root - 2022-02-24 20:36:22.621186: step 119630, total loss = 0.58, batch loss = 0.32 (212.5 examples/sec; 0.038 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:36:22.923796: step 119640, total loss = 0.48, batch loss = 0.22 (344.9 examples/sec; 0.023 sec/batch; 0h:30m:52s remains)
INFO - root - 2022-02-24 20:36:23.259599: step 119650, total loss = 0.60, batch loss = 0.34 (134.2 examples/sec; 0.060 sec/batch; 1h:19m:21s remains)
INFO - root - 2022-02-24 20:36:23.708896: step 119660, total loss = 0.54, batch loss = 0.28 (199.5 examples/sec; 0.040 sec/batch; 0h:53m:21s remains)
INFO - root - 2022-02-24 20:36:24.217896: step 119670, total loss = 0.59, batch loss = 0.33 (194.4 examples/sec; 0.041 sec/batch; 0h:54m:45s remains)
INFO - root - 2022-02-24 20:36:25.138622: step 119680, total loss = 0.57, batch loss = 0.31 (317.2 examples/sec; 0.025 sec/batch; 0h:33m:33s remains)
INFO - root - 2022-02-24 20:36:25.429763: step 119690, total loss = 0.52, batch loss = 0.26 (201.5 examples/sec; 0.040 sec/batch; 0h:52m:48s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-119699 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-119699 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:36:26.578634: step 119700, total loss = 0.56, batch loss = 0.30 (322.7 examples/sec; 0.025 sec/batch; 0h:32m:58s remains)
INFO - root - 2022-02-24 20:36:26.910126: step 119710, total loss = 0.52, batch loss = 0.26 (300.2 examples/sec; 0.027 sec/batch; 0h:35m:25s remains)
INFO - root - 2022-02-24 20:36:27.140298: step 119720, total loss = 0.58, batch loss = 0.32 (360.0 examples/sec; 0.022 sec/batch; 0h:29m:32s remains)
INFO - root - 2022-02-24 20:36:27.373667: step 119730, total loss = 0.61, batch loss = 0.35 (348.5 examples/sec; 0.023 sec/batch; 0h:30m:30s remains)
INFO - root - 2022-02-24 20:36:27.663004: step 119740, total loss = 0.50, batch loss = 0.24 (204.3 examples/sec; 0.039 sec/batch; 0h:52m:03s remains)
INFO - root - 2022-02-24 20:36:28.038754: step 119750, total loss = 0.73, batch loss = 0.47 (368.1 examples/sec; 0.022 sec/batch; 0h:28m:53s remains)
INFO - root - 2022-02-24 20:36:28.454764: step 119760, total loss = 0.51, batch loss = 0.25 (277.9 examples/sec; 0.029 sec/batch; 0h:38m:15s remains)
INFO - root - 2022-02-24 20:36:28.743831: step 119770, total loss = 0.52, batch loss = 0.26 (251.6 examples/sec; 0.032 sec/batch; 0h:42m:14s remains)
INFO - root - 2022-02-24 20:36:29.171673: step 119780, total loss = 0.51, batch loss = 0.25 (317.8 examples/sec; 0.025 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:36:29.463209: step 119790, total loss = 0.56, batch loss = 0.30 (251.8 examples/sec; 0.032 sec/batch; 0h:42m:12s remains)
INFO - root - 2022-02-24 20:36:29.884129: step 119800, total loss = 0.74, batch loss = 0.48 (100.3 examples/sec; 0.080 sec/batch; 1h:45m:57s remains)
INFO - root - 2022-02-24 20:36:30.400193: step 119810, total loss = 0.49, batch loss = 0.23 (107.8 examples/sec; 0.074 sec/batch; 1h:38m:32s remains)
INFO - root - 2022-02-24 20:36:30.751144: step 119820, total loss = 0.61, batch loss = 0.35 (158.8 examples/sec; 0.050 sec/batch; 1h:06m:55s remains)
INFO - root - 2022-02-24 20:36:31.133406: step 119830, total loss = 0.50, batch loss = 0.24 (263.6 examples/sec; 0.030 sec/batch; 0h:40m:18s remains)
INFO - root - 2022-02-24 20:36:31.516139: step 119840, total loss = 0.51, batch loss = 0.25 (292.0 examples/sec; 0.027 sec/batch; 0h:36m:22s remains)
INFO - root - 2022-02-24 20:36:31.819448: step 119850, total loss = 0.58, batch loss = 0.31 (270.3 examples/sec; 0.030 sec/batch; 0h:39m:17s remains)
INFO - root - 2022-02-24 20:36:32.240027: step 119860, total loss = 0.67, batch loss = 0.41 (227.2 examples/sec; 0.035 sec/batch; 0h:46m:44s remains)
INFO - root - 2022-02-24 20:36:32.554776: step 119870, total loss = 0.52, batch loss = 0.26 (213.9 examples/sec; 0.037 sec/batch; 0h:49m:38s remains)
INFO - root - 2022-02-24 20:36:32.859382: step 119880, total loss = 0.55, batch loss = 0.29 (339.9 examples/sec; 0.024 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:36:33.174697: step 119890, total loss = 0.57, batch loss = 0.31 (340.7 examples/sec; 0.023 sec/batch; 0h:31m:09s remains)
INFO - root - 2022-02-24 20:36:33.514205: step 119900, total loss = 0.50, batch loss = 0.24 (341.9 examples/sec; 0.023 sec/batch; 0h:31m:02s remains)
INFO - root - 2022-02-24 20:36:34.063674: step 119910, total loss = 0.47, batch loss = 0.21 (351.8 examples/sec; 0.023 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 20:36:34.476687: step 119920, total loss = 0.52, batch loss = 0.26 (128.5 examples/sec; 0.062 sec/batch; 1h:22m:32s remains)
INFO - root - 2022-02-24 20:36:34.865186: step 119930, total loss = 0.62, batch loss = 0.35 (158.2 examples/sec; 0.051 sec/batch; 1h:07m:04s remains)
INFO - root - 2022-02-24 20:36:35.200244: step 119940, total loss = 0.49, batch loss = 0.23 (161.5 examples/sec; 0.050 sec/batch; 1h:05m:40s remains)
INFO - root - 2022-02-24 20:36:35.475897: step 119950, total loss = 0.48, batch loss = 0.22 (316.6 examples/sec; 0.025 sec/batch; 0h:33m:30s remains)
INFO - root - 2022-02-24 20:36:35.777216: step 119960, total loss = 0.55, batch loss = 0.29 (295.7 examples/sec; 0.027 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 20:36:36.205091: step 119970, total loss = 0.54, batch loss = 0.28 (140.1 examples/sec; 0.057 sec/batch; 1h:15m:41s remains)
INFO - root - 2022-02-24 20:36:36.599190: step 119980, total loss = 0.73, batch loss = 0.47 (157.0 examples/sec; 0.051 sec/batch; 1h:07m:33s remains)
INFO - root - 2022-02-24 20:36:36.935367: step 119990, total loss = 0.55, batch loss = 0.29 (291.0 examples/sec; 0.027 sec/batch; 0h:36m:25s remains)
INFO - root - 2022-02-24 20:36:37.314161: step 120000, total loss = 0.61, batch loss = 0.35 (338.6 examples/sec; 0.024 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 20:36:37.659946: step 120010, total loss = 0.59, batch loss = 0.33 (282.3 examples/sec; 0.028 sec/batch; 0h:37m:32s remains)
INFO - root - 2022-02-24 20:36:38.014861: step 120020, total loss = 0.53, batch loss = 0.26 (302.4 examples/sec; 0.026 sec/batch; 0h:35m:02s remains)
INFO - root - 2022-02-24 20:36:38.423236: step 120030, total loss = 0.50, batch loss = 0.24 (214.7 examples/sec; 0.037 sec/batch; 0h:49m:21s remains)
INFO - root - 2022-02-24 20:36:38.788959: step 120040, total loss = 0.55, batch loss = 0.29 (386.6 examples/sec; 0.021 sec/batch; 0h:27m:24s remains)
INFO - root - 2022-02-24 20:36:39.037083: step 120050, total loss = 0.61, batch loss = 0.35 (297.4 examples/sec; 0.027 sec/batch; 0h:35m:36s remains)
INFO - root - 2022-02-24 20:36:39.428711: step 120060, total loss = 0.56, batch loss = 0.30 (302.7 examples/sec; 0.026 sec/batch; 0h:34m:59s remains)
INFO - root - 2022-02-24 20:36:39.794457: step 120070, total loss = 0.56, batch loss = 0.30 (319.5 examples/sec; 0.025 sec/batch; 0h:33m:09s remains)
INFO - root - 2022-02-24 20:36:40.185300: step 120080, total loss = 0.52, batch loss = 0.26 (300.7 examples/sec; 0.027 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:36:40.639572: step 120090, total loss = 0.52, batch loss = 0.26 (159.9 examples/sec; 0.050 sec/batch; 1h:06m:12s remains)
INFO - root - 2022-02-24 20:36:41.375238: step 120100, total loss = 0.51, batch loss = 0.25 (126.7 examples/sec; 0.063 sec/batch; 1h:23m:34s remains)
INFO - root - 2022-02-24 20:36:42.115030: step 120110, total loss = 0.50, batch loss = 0.24 (327.7 examples/sec; 0.024 sec/batch; 0h:32m:17s remains)
INFO - root - 2022-02-24 20:36:42.543762: step 120120, total loss = 0.50, batch loss = 0.24 (115.1 examples/sec; 0.069 sec/batch; 1h:31m:55s remains)
INFO - root - 2022-02-24 20:36:42.901605: step 120130, total loss = 0.65, batch loss = 0.39 (237.3 examples/sec; 0.034 sec/batch; 0h:44m:36s remains)
INFO - root - 2022-02-24 20:36:43.260383: step 120140, total loss = 0.54, batch loss = 0.28 (192.5 examples/sec; 0.042 sec/batch; 0h:54m:58s remains)
INFO - root - 2022-02-24 20:36:43.703711: step 120150, total loss = 0.54, batch loss = 0.28 (202.7 examples/sec; 0.039 sec/batch; 0h:52m:11s remains)
INFO - root - 2022-02-24 20:36:44.040149: step 120160, total loss = 0.52, batch loss = 0.26 (216.3 examples/sec; 0.037 sec/batch; 0h:48m:54s remains)
INFO - root - 2022-02-24 20:36:44.875416: step 120170, total loss = 0.46, batch loss = 0.20 (207.7 examples/sec; 0.039 sec/batch; 0h:50m:56s remains)
INFO - root - 2022-02-24 20:36:45.174433: step 120180, total loss = 0.60, batch loss = 0.34 (324.2 examples/sec; 0.025 sec/batch; 0h:32m:37s remains)
INFO - root - 2022-02-24 20:36:45.480757: step 120190, total loss = 0.60, batch loss = 0.33 (281.3 examples/sec; 0.028 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:36:45.821398: step 120200, total loss = 0.46, batch loss = 0.19 (308.2 examples/sec; 0.026 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:36:46.182735: step 120210, total loss = 0.48, batch loss = 0.22 (347.6 examples/sec; 0.023 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 20:36:46.570583: step 120220, total loss = 0.53, batch loss = 0.27 (349.1 examples/sec; 0.023 sec/batch; 0h:30m:16s remains)
INFO - root - 2022-02-24 20:36:47.139457: step 120230, total loss = 0.58, batch loss = 0.32 (109.3 examples/sec; 0.073 sec/batch; 1h:36m:43s remains)
INFO - root - 2022-02-24 20:36:47.622081: step 120240, total loss = 0.50, batch loss = 0.24 (138.1 examples/sec; 0.058 sec/batch; 1h:16m:32s remains)
INFO - root - 2022-02-24 20:36:47.988752: step 120250, total loss = 0.52, batch loss = 0.26 (347.3 examples/sec; 0.023 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 20:36:48.326385: step 120260, total loss = 0.49, batch loss = 0.23 (279.9 examples/sec; 0.029 sec/batch; 0h:37m:44s remains)
INFO - root - 2022-02-24 20:36:48.715389: step 120270, total loss = 0.62, batch loss = 0.36 (168.2 examples/sec; 0.048 sec/batch; 1h:02m:49s remains)
INFO - root - 2022-02-24 20:36:49.139496: step 120280, total loss = 0.62, batch loss = 0.36 (179.1 examples/sec; 0.045 sec/batch; 0h:58m:57s remains)
INFO - root - 2022-02-24 20:36:49.461427: step 120290, total loss = 0.73, batch loss = 0.47 (345.0 examples/sec; 0.023 sec/batch; 0h:30m:36s remains)
INFO - root - 2022-02-24 20:36:49.898813: step 120300, total loss = 0.54, batch loss = 0.28 (226.8 examples/sec; 0.035 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:36:50.261434: step 120310, total loss = 0.61, batch loss = 0.35 (305.2 examples/sec; 0.026 sec/batch; 0h:34m:35s remains)
INFO - root - 2022-02-24 20:36:50.558742: step 120320, total loss = 0.57, batch loss = 0.31 (305.8 examples/sec; 0.026 sec/batch; 0h:34m:31s remains)
INFO - root - 2022-02-24 20:36:50.971693: step 120330, total loss = 0.56, batch loss = 0.30 (252.0 examples/sec; 0.032 sec/batch; 0h:41m:52s remains)
INFO - root - 2022-02-24 20:36:51.281133: step 120340, total loss = 0.54, batch loss = 0.27 (261.5 examples/sec; 0.031 sec/batch; 0h:40m:21s remains)
INFO - root - 2022-02-24 20:36:51.635631: step 120350, total loss = 0.55, batch loss = 0.29 (337.8 examples/sec; 0.024 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:36:51.943652: step 120360, total loss = 0.46, batch loss = 0.20 (194.9 examples/sec; 0.041 sec/batch; 0h:54m:08s remains)
INFO - root - 2022-02-24 20:36:52.311357: step 120370, total loss = 0.52, batch loss = 0.26 (160.8 examples/sec; 0.050 sec/batch; 1h:05m:37s remains)
INFO - root - 2022-02-24 20:36:52.622210: step 120380, total loss = 0.67, batch loss = 0.41 (247.8 examples/sec; 0.032 sec/batch; 0h:42m:33s remains)
INFO - root - 2022-02-24 20:36:52.980603: step 120390, total loss = 0.58, batch loss = 0.32 (192.4 examples/sec; 0.042 sec/batch; 0h:54m:48s remains)
INFO - root - 2022-02-24 20:36:53.368051: step 120400, total loss = 0.47, batch loss = 0.21 (127.3 examples/sec; 0.063 sec/batch; 1h:22m:49s remains)
INFO - root - 2022-02-24 20:36:53.746472: step 120410, total loss = 0.68, batch loss = 0.42 (375.4 examples/sec; 0.021 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:36:53.990196: step 120420, total loss = 0.63, batch loss = 0.37 (335.2 examples/sec; 0.024 sec/batch; 0h:31m:27s remains)
INFO - root - 2022-02-24 20:36:54.285842: step 120430, total loss = 0.62, batch loss = 0.36 (210.9 examples/sec; 0.038 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:36:54.637819: step 120440, total loss = 0.50, batch loss = 0.24 (115.9 examples/sec; 0.069 sec/batch; 1h:30m:56s remains)
INFO - root - 2022-02-24 20:36:55.159373: step 120450, total loss = 0.54, batch loss = 0.28 (138.9 examples/sec; 0.058 sec/batch; 1h:15m:53s remains)
INFO - root - 2022-02-24 20:36:55.562772: step 120460, total loss = 0.55, batch loss = 0.29 (278.7 examples/sec; 0.029 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 20:36:55.866948: step 120470, total loss = 0.69, batch loss = 0.43 (263.0 examples/sec; 0.030 sec/batch; 0h:40m:03s remains)
INFO - root - 2022-02-24 20:36:56.175914: step 120480, total loss = 0.58, batch loss = 0.32 (320.8 examples/sec; 0.025 sec/batch; 0h:32m:50s remains)
INFO - root - 2022-02-24 20:36:56.465415: step 120490, total loss = 0.61, batch loss = 0.35 (343.2 examples/sec; 0.023 sec/batch; 0h:30m:41s remains)
INFO - root - 2022-02-24 20:36:56.795266: step 120500, total loss = 0.62, batch loss = 0.36 (228.5 examples/sec; 0.035 sec/batch; 0h:46m:06s remains)
INFO - root - 2022-02-24 20:36:57.344424: step 120510, total loss = 0.53, batch loss = 0.27 (227.3 examples/sec; 0.035 sec/batch; 0h:46m:19s remains)
INFO - root - 2022-02-24 20:36:57.690579: step 120520, total loss = 0.49, batch loss = 0.23 (345.7 examples/sec; 0.023 sec/batch; 0h:30m:27s remains)
INFO - root - 2022-02-24 20:36:58.064958: step 120530, total loss = 0.56, batch loss = 0.29 (343.5 examples/sec; 0.023 sec/batch; 0h:30m:39s remains)
INFO - root - 2022-02-24 20:36:58.402617: step 120540, total loss = 0.51, batch loss = 0.25 (320.4 examples/sec; 0.025 sec/batch; 0h:32m:51s remains)
INFO - root - 2022-02-24 20:36:58.733717: step 120550, total loss = 0.69, batch loss = 0.42 (233.1 examples/sec; 0.034 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:36:59.119853: step 120560, total loss = 0.51, batch loss = 0.25 (151.5 examples/sec; 0.053 sec/batch; 1h:09m:27s remains)
INFO - root - 2022-02-24 20:36:59.623470: step 120570, total loss = 0.47, batch loss = 0.21 (309.2 examples/sec; 0.026 sec/batch; 0h:34m:02s remains)
INFO - root - 2022-02-24 20:36:59.982378: step 120580, total loss = 0.64, batch loss = 0.38 (218.6 examples/sec; 0.037 sec/batch; 0h:48m:08s remains)
INFO - root - 2022-02-24 20:37:00.325716: step 120590, total loss = 0.46, batch loss = 0.19 (156.9 examples/sec; 0.051 sec/batch; 1h:07m:02s remains)
INFO - root - 2022-02-24 20:37:00.712658: step 120600, total loss = 0.51, batch loss = 0.25 (321.3 examples/sec; 0.025 sec/batch; 0h:32m:44s remains)
INFO - root - 2022-02-24 20:37:01.103142: step 120610, total loss = 0.57, batch loss = 0.31 (335.6 examples/sec; 0.024 sec/batch; 0h:31m:20s remains)
INFO - root - 2022-02-24 20:37:01.537901: step 120620, total loss = 0.53, batch loss = 0.27 (171.0 examples/sec; 0.047 sec/batch; 1h:01m:30s remains)
INFO - root - 2022-02-24 20:37:01.837683: step 120630, total loss = 0.56, batch loss = 0.30 (321.9 examples/sec; 0.025 sec/batch; 0h:32m:39s remains)
INFO - root - 2022-02-24 20:37:02.126030: step 120640, total loss = 0.46, batch loss = 0.20 (149.8 examples/sec; 0.053 sec/batch; 1h:10m:11s remains)
INFO - root - 2022-02-24 20:37:02.425907: step 120650, total loss = 0.47, batch loss = 0.21 (318.1 examples/sec; 0.025 sec/batch; 0h:33m:02s remains)
INFO - root - 2022-02-24 20:37:02.691456: step 120660, total loss = 0.47, batch loss = 0.21 (179.3 examples/sec; 0.045 sec/batch; 0h:58m:38s remains)
INFO - root - 2022-02-24 20:37:03.013812: step 120670, total loss = 0.51, batch loss = 0.25 (252.4 examples/sec; 0.032 sec/batch; 0h:41m:38s remains)
INFO - root - 2022-02-24 20:37:03.438794: step 120680, total loss = 0.54, batch loss = 0.28 (332.1 examples/sec; 0.024 sec/batch; 0h:31m:38s remains)
INFO - root - 2022-02-24 20:37:03.901229: step 120690, total loss = 0.51, batch loss = 0.25 (332.4 examples/sec; 0.024 sec/batch; 0h:31m:36s remains)
INFO - root - 2022-02-24 20:37:04.192526: step 120700, total loss = 0.57, batch loss = 0.31 (324.6 examples/sec; 0.025 sec/batch; 0h:32m:22s remains)
INFO - root - 2022-02-24 20:37:04.590396: step 120710, total loss = 0.60, batch loss = 0.34 (327.0 examples/sec; 0.024 sec/batch; 0h:32m:07s remains)
INFO - root - 2022-02-24 20:37:04.847120: step 120720, total loss = 0.54, batch loss = 0.28 (192.6 examples/sec; 0.042 sec/batch; 0h:54m:31s remains)
INFO - root - 2022-02-24 20:37:05.273576: step 120730, total loss = 0.55, batch loss = 0.29 (231.5 examples/sec; 0.035 sec/batch; 0h:45m:22s remains)
INFO - root - 2022-02-24 20:37:05.699093: step 120740, total loss = 0.53, batch loss = 0.27 (105.5 examples/sec; 0.076 sec/batch; 1h:39m:33s remains)
INFO - root - 2022-02-24 20:37:06.023194: step 120750, total loss = 0.72, batch loss = 0.46 (363.4 examples/sec; 0.022 sec/batch; 0h:28m:53s remains)
INFO - root - 2022-02-24 20:37:06.363883: step 120760, total loss = 0.58, batch loss = 0.32 (352.0 examples/sec; 0.023 sec/batch; 0h:29m:49s remains)
INFO - root - 2022-02-24 20:37:06.642512: step 120770, total loss = 0.52, batch loss = 0.26 (391.8 examples/sec; 0.020 sec/batch; 0h:26m:47s remains)
INFO - root - 2022-02-24 20:37:06.928382: step 120780, total loss = 0.50, batch loss = 0.24 (347.1 examples/sec; 0.023 sec/batch; 0h:30m:14s remains)
INFO - root - 2022-02-24 20:37:07.337423: step 120790, total loss = 0.50, batch loss = 0.24 (183.1 examples/sec; 0.044 sec/batch; 0h:57m:18s remains)
INFO - root - 2022-02-24 20:37:07.774417: step 120800, total loss = 0.56, batch loss = 0.30 (202.4 examples/sec; 0.040 sec/batch; 0h:51m:50s remains)
INFO - root - 2022-02-24 20:37:08.291914: step 120810, total loss = 0.57, batch loss = 0.31 (94.4 examples/sec; 0.085 sec/batch; 1h:51m:10s remains)
INFO - root - 2022-02-24 20:37:08.825577: step 120820, total loss = 0.57, batch loss = 0.31 (133.5 examples/sec; 0.060 sec/batch; 1h:18m:33s remains)
INFO - root - 2022-02-24 20:37:09.339934: step 120830, total loss = 0.52, batch loss = 0.26 (134.1 examples/sec; 0.060 sec/batch; 1h:18m:12s remains)
INFO - root - 2022-02-24 20:37:10.405281: step 120840, total loss = 0.57, batch loss = 0.31 (115.4 examples/sec; 0.069 sec/batch; 1h:30m:51s remains)
INFO - root - 2022-02-24 20:37:10.781963: step 120850, total loss = 0.53, batch loss = 0.27 (255.1 examples/sec; 0.031 sec/batch; 0h:41m:06s remains)
INFO - root - 2022-02-24 20:37:11.243546: step 120860, total loss = 0.54, batch loss = 0.28 (101.9 examples/sec; 0.078 sec/batch; 1h:42m:51s remains)
INFO - root - 2022-02-24 20:37:11.645080: step 120870, total loss = 0.51, batch loss = 0.25 (218.3 examples/sec; 0.037 sec/batch; 0h:48m:01s remains)
INFO - root - 2022-02-24 20:37:11.934214: step 120880, total loss = 0.75, batch loss = 0.49 (335.9 examples/sec; 0.024 sec/batch; 0h:31m:12s remains)
INFO - root - 2022-02-24 20:37:12.271213: step 120890, total loss = 0.59, batch loss = 0.33 (293.2 examples/sec; 0.027 sec/batch; 0h:35m:44s remains)
INFO - root - 2022-02-24 20:37:12.674677: step 120900, total loss = 0.63, batch loss = 0.37 (266.7 examples/sec; 0.030 sec/batch; 0h:39m:17s remains)
INFO - root - 2022-02-24 20:37:13.166675: step 120910, total loss = 0.53, batch loss = 0.27 (84.2 examples/sec; 0.095 sec/batch; 2h:04m:26s remains)
INFO - root - 2022-02-24 20:37:13.611385: step 120920, total loss = 0.53, batch loss = 0.27 (232.2 examples/sec; 0.034 sec/batch; 0h:45m:06s remains)
INFO - root - 2022-02-24 20:37:13.923710: step 120930, total loss = 0.51, batch loss = 0.25 (331.0 examples/sec; 0.024 sec/batch; 0h:31m:39s remains)
INFO - root - 2022-02-24 20:37:14.277242: step 120940, total loss = 0.59, batch loss = 0.33 (267.8 examples/sec; 0.030 sec/batch; 0h:39m:07s remains)
INFO - root - 2022-02-24 20:37:14.625390: step 120950, total loss = 0.62, batch loss = 0.36 (263.4 examples/sec; 0.030 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:37:14.994653: step 120960, total loss = 0.61, batch loss = 0.35 (261.7 examples/sec; 0.031 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:37:15.586102: step 120970, total loss = 0.55, batch loss = 0.29 (137.1 examples/sec; 0.058 sec/batch; 1h:16m:21s remains)
INFO - root - 2022-02-24 20:37:16.045500: step 120980, total loss = 0.44, batch loss = 0.18 (144.9 examples/sec; 0.055 sec/batch; 1h:12m:15s remains)
INFO - root - 2022-02-24 20:37:16.370949: step 120990, total loss = 0.65, batch loss = 0.39 (332.4 examples/sec; 0.024 sec/batch; 0h:31m:29s remains)
INFO - root - 2022-02-24 20:37:16.707479: step 121000, total loss = 0.57, batch loss = 0.30 (348.1 examples/sec; 0.023 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 20:37:17.207140: step 121010, total loss = 0.49, batch loss = 0.23 (340.7 examples/sec; 0.023 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 20:37:17.642878: step 121020, total loss = 0.68, batch loss = 0.42 (332.2 examples/sec; 0.024 sec/batch; 0h:31m:29s remains)
INFO - root - 2022-02-24 20:37:17.976474: step 121030, total loss = 0.56, batch loss = 0.30 (204.1 examples/sec; 0.039 sec/batch; 0h:51m:15s remains)
INFO - root - 2022-02-24 20:37:18.294585: step 121040, total loss = 0.60, batch loss = 0.34 (231.6 examples/sec; 0.035 sec/batch; 0h:45m:10s remains)
INFO - root - 2022-02-24 20:37:18.637333: step 121050, total loss = 0.51, batch loss = 0.25 (308.4 examples/sec; 0.026 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:37:18.936430: step 121060, total loss = 0.55, batch loss = 0.29 (327.5 examples/sec; 0.024 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:37:19.302570: step 121070, total loss = 0.46, batch loss = 0.20 (207.4 examples/sec; 0.039 sec/batch; 0h:50m:25s remains)
INFO - root - 2022-02-24 20:37:19.620812: step 121080, total loss = 0.57, batch loss = 0.31 (308.7 examples/sec; 0.026 sec/batch; 0h:33m:52s remains)
INFO - root - 2022-02-24 20:37:19.962297: step 121090, total loss = 0.61, batch loss = 0.35 (315.1 examples/sec; 0.025 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:37:20.277951: step 121100, total loss = 0.67, batch loss = 0.41 (365.4 examples/sec; 0.022 sec/batch; 0h:28m:36s remains)
INFO - root - 2022-02-24 20:37:20.754033: step 121110, total loss = 0.48, batch loss = 0.22 (113.6 examples/sec; 0.070 sec/batch; 1h:31m:58s remains)
INFO - root - 2022-02-24 20:37:21.147354: step 121120, total loss = 0.62, batch loss = 0.36 (138.8 examples/sec; 0.058 sec/batch; 1h:15m:17s remains)
INFO - root - 2022-02-24 20:37:21.602885: step 121130, total loss = 0.54, batch loss = 0.28 (234.9 examples/sec; 0.034 sec/batch; 0h:44m:29s remains)
INFO - root - 2022-02-24 20:37:21.923205: step 121140, total loss = 0.59, batch loss = 0.33 (245.3 examples/sec; 0.033 sec/batch; 0h:42m:35s remains)
INFO - root - 2022-02-24 20:37:22.223014: step 121150, total loss = 0.55, batch loss = 0.29 (208.9 examples/sec; 0.038 sec/batch; 0h:50m:00s remains)
INFO - root - 2022-02-24 20:37:22.473440: step 121160, total loss = 0.51, batch loss = 0.25 (313.2 examples/sec; 0.026 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:37:22.821406: step 121170, total loss = 0.52, batch loss = 0.26 (171.2 examples/sec; 0.047 sec/batch; 1h:00m:59s remains)
INFO - root - 2022-02-24 20:37:23.139283: step 121180, total loss = 0.46, batch loss = 0.20 (203.6 examples/sec; 0.039 sec/batch; 0h:51m:17s remains)
INFO - root - 2022-02-24 20:37:23.555265: step 121190, total loss = 0.52, batch loss = 0.26 (165.6 examples/sec; 0.048 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 20:37:23.987706: step 121200, total loss = 0.49, batch loss = 0.23 (94.8 examples/sec; 0.084 sec/batch; 1h:50m:06s remains)
INFO - root - 2022-02-24 20:37:24.422039: step 121210, total loss = 0.55, batch loss = 0.29 (153.1 examples/sec; 0.052 sec/batch; 1h:08m:10s remains)
INFO - root - 2022-02-24 20:37:24.830589: step 121220, total loss = 0.43, batch loss = 0.17 (214.1 examples/sec; 0.037 sec/batch; 0h:48m:45s remains)
INFO - root - 2022-02-24 20:37:25.123424: step 121230, total loss = 0.63, batch loss = 0.37 (292.1 examples/sec; 0.027 sec/batch; 0h:35m:43s remains)
INFO - root - 2022-02-24 20:37:25.549360: step 121240, total loss = 0.56, batch loss = 0.29 (248.3 examples/sec; 0.032 sec/batch; 0h:42m:01s remains)
INFO - root - 2022-02-24 20:37:26.036158: step 121250, total loss = 0.51, batch loss = 0.24 (145.6 examples/sec; 0.055 sec/batch; 1h:11m:38s remains)
INFO - root - 2022-02-24 20:37:26.406485: step 121260, total loss = 0.47, batch loss = 0.21 (208.5 examples/sec; 0.038 sec/batch; 0h:50m:02s remains)
INFO - root - 2022-02-24 20:37:26.731584: step 121270, total loss = 0.54, batch loss = 0.28 (204.6 examples/sec; 0.039 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 20:37:27.093940: step 121280, total loss = 0.47, batch loss = 0.21 (323.3 examples/sec; 0.025 sec/batch; 0h:32m:15s remains)
INFO - root - 2022-02-24 20:37:27.394280: step 121290, total loss = 0.60, batch loss = 0.34 (280.7 examples/sec; 0.029 sec/batch; 0h:37m:08s remains)
INFO - root - 2022-02-24 20:37:27.744013: step 121300, total loss = 0.61, batch loss = 0.35 (267.4 examples/sec; 0.030 sec/batch; 0h:38m:59s remains)
INFO - root - 2022-02-24 20:37:28.195012: step 121310, total loss = 0.53, batch loss = 0.27 (171.4 examples/sec; 0.047 sec/batch; 1h:00m:49s remains)
INFO - root - 2022-02-24 20:37:28.574783: step 121320, total loss = 0.54, batch loss = 0.28 (312.9 examples/sec; 0.026 sec/batch; 0h:33m:18s remains)
INFO - root - 2022-02-24 20:37:28.907047: step 121330, total loss = 0.60, batch loss = 0.34 (253.0 examples/sec; 0.032 sec/batch; 0h:41m:12s remains)
INFO - root - 2022-02-24 20:37:29.222714: step 121340, total loss = 0.58, batch loss = 0.32 (330.8 examples/sec; 0.024 sec/batch; 0h:31m:30s remains)
INFO - root - 2022-02-24 20:37:29.584135: step 121350, total loss = 0.80, batch loss = 0.54 (241.2 examples/sec; 0.033 sec/batch; 0h:43m:12s remains)
INFO - root - 2022-02-24 20:37:29.954409: step 121360, total loss = 0.61, batch loss = 0.35 (167.6 examples/sec; 0.048 sec/batch; 1h:02m:10s remains)
INFO - root - 2022-02-24 20:37:30.319473: step 121370, total loss = 0.58, batch loss = 0.32 (321.6 examples/sec; 0.025 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 20:37:30.696181: step 121380, total loss = 0.58, batch loss = 0.32 (337.1 examples/sec; 0.024 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 20:37:31.049397: step 121390, total loss = 0.55, batch loss = 0.29 (330.8 examples/sec; 0.024 sec/batch; 0h:31m:28s remains)
INFO - root - 2022-02-24 20:37:31.407079: step 121400, total loss = 0.48, batch loss = 0.22 (207.1 examples/sec; 0.039 sec/batch; 0h:50m:16s remains)
INFO - root - 2022-02-24 20:37:31.868355: step 121410, total loss = 0.53, batch loss = 0.27 (222.9 examples/sec; 0.036 sec/batch; 0h:46m:42s remains)
INFO - root - 2022-02-24 20:37:32.289504: step 121420, total loss = 0.58, batch loss = 0.32 (272.6 examples/sec; 0.029 sec/batch; 0h:38m:11s remains)
INFO - root - 2022-02-24 20:37:32.863634: step 121430, total loss = 0.63, batch loss = 0.37 (79.6 examples/sec; 0.100 sec/batch; 2h:10m:42s remains)
INFO - root - 2022-02-24 20:37:33.493706: step 121440, total loss = 0.49, batch loss = 0.23 (87.2 examples/sec; 0.092 sec/batch; 1h:59m:21s remains)
INFO - root - 2022-02-24 20:37:34.264176: step 121450, total loss = 0.50, batch loss = 0.24 (45.2 examples/sec; 0.177 sec/batch; 3h:50m:11s remains)
INFO - root - 2022-02-24 20:37:34.706832: step 121460, total loss = 0.61, batch loss = 0.34 (193.5 examples/sec; 0.041 sec/batch; 0h:53m:46s remains)
INFO - root - 2022-02-24 20:37:35.060132: step 121470, total loss = 0.57, batch loss = 0.31 (228.0 examples/sec; 0.035 sec/batch; 0h:45m:37s remains)
INFO - root - 2022-02-24 20:37:35.397317: step 121480, total loss = 0.57, batch loss = 0.31 (229.1 examples/sec; 0.035 sec/batch; 0h:45m:24s remains)
INFO - root - 2022-02-24 20:37:35.685393: step 121490, total loss = 0.55, batch loss = 0.29 (330.3 examples/sec; 0.024 sec/batch; 0h:31m:29s remains)
INFO - root - 2022-02-24 20:37:36.467595: step 121500, total loss = 0.49, batch loss = 0.23 (172.9 examples/sec; 0.046 sec/batch; 1h:00m:08s remains)
INFO - root - 2022-02-24 20:37:36.887948: step 121510, total loss = 0.53, batch loss = 0.27 (354.2 examples/sec; 0.023 sec/batch; 0h:29m:21s remains)
INFO - root - 2022-02-24 20:37:37.310963: step 121520, total loss = 0.57, batch loss = 0.31 (300.7 examples/sec; 0.027 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:37:37.651218: step 121530, total loss = 0.46, batch loss = 0.20 (151.3 examples/sec; 0.053 sec/batch; 1h:08m:42s remains)
INFO - root - 2022-02-24 20:37:37.978204: step 121540, total loss = 0.49, batch loss = 0.23 (171.1 examples/sec; 0.047 sec/batch; 1h:00m:45s remains)
INFO - root - 2022-02-24 20:37:38.304919: step 121550, total loss = 0.51, batch loss = 0.25 (305.6 examples/sec; 0.026 sec/batch; 0h:34m:00s remains)
INFO - root - 2022-02-24 20:37:38.728749: step 121560, total loss = 0.54, batch loss = 0.28 (169.5 examples/sec; 0.047 sec/batch; 1h:01m:17s remains)
INFO - root - 2022-02-24 20:37:39.145494: step 121570, total loss = 0.57, batch loss = 0.31 (348.7 examples/sec; 0.023 sec/batch; 0h:29m:47s remains)
INFO - root - 2022-02-24 20:37:39.603201: step 121580, total loss = 0.60, batch loss = 0.34 (165.7 examples/sec; 0.048 sec/batch; 1h:02m:42s remains)
INFO - root - 2022-02-24 20:37:39.992764: step 121590, total loss = 0.64, batch loss = 0.38 (111.7 examples/sec; 0.072 sec/batch; 1h:32m:59s remains)
INFO - root - 2022-02-24 20:37:40.299519: step 121600, total loss = 0.51, batch loss = 0.25 (336.7 examples/sec; 0.024 sec/batch; 0h:30m:50s remains)
INFO - root - 2022-02-24 20:37:40.770798: step 121610, total loss = 0.65, batch loss = 0.39 (263.5 examples/sec; 0.030 sec/batch; 0h:39m:25s remains)
INFO - root - 2022-02-24 20:37:41.209970: step 121620, total loss = 0.54, batch loss = 0.28 (199.6 examples/sec; 0.040 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:37:41.605150: step 121630, total loss = 0.47, batch loss = 0.21 (275.3 examples/sec; 0.029 sec/batch; 0h:37m:42s remains)
INFO - root - 2022-02-24 20:37:41.940377: step 121640, total loss = 0.54, batch loss = 0.28 (351.5 examples/sec; 0.023 sec/batch; 0h:29m:31s remains)
INFO - root - 2022-02-24 20:37:42.387523: step 121650, total loss = 0.57, batch loss = 0.31 (155.8 examples/sec; 0.051 sec/batch; 1h:06m:37s remains)
INFO - root - 2022-02-24 20:37:42.656051: step 121660, total loss = 0.51, batch loss = 0.25 (333.6 examples/sec; 0.024 sec/batch; 0h:31m:06s remains)
INFO - root - 2022-02-24 20:37:42.981196: step 121670, total loss = 0.59, batch loss = 0.33 (266.2 examples/sec; 0.030 sec/batch; 0h:38m:58s remains)
INFO - root - 2022-02-24 20:37:43.373366: step 121680, total loss = 0.55, batch loss = 0.29 (219.3 examples/sec; 0.036 sec/batch; 0h:47m:18s remains)
INFO - root - 2022-02-24 20:37:43.722014: step 121690, total loss = 0.52, batch loss = 0.26 (367.0 examples/sec; 0.022 sec/batch; 0h:28m:16s remains)
INFO - root - 2022-02-24 20:37:44.066421: step 121700, total loss = 0.69, batch loss = 0.43 (127.3 examples/sec; 0.063 sec/batch; 1h:21m:29s remains)
INFO - root - 2022-02-24 20:37:44.423147: step 121710, total loss = 0.56, batch loss = 0.30 (320.2 examples/sec; 0.025 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 20:37:44.734092: step 121720, total loss = 0.53, batch loss = 0.27 (274.6 examples/sec; 0.029 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:37:45.075828: step 121730, total loss = 0.63, batch loss = 0.37 (309.6 examples/sec; 0.026 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:37:45.441747: step 121740, total loss = 0.57, batch loss = 0.31 (156.4 examples/sec; 0.051 sec/batch; 1h:06m:16s remains)
INFO - root - 2022-02-24 20:37:45.824755: step 121750, total loss = 0.56, batch loss = 0.30 (157.8 examples/sec; 0.051 sec/batch; 1h:05m:42s remains)
INFO - root - 2022-02-24 20:37:46.371383: step 121760, total loss = 0.62, batch loss = 0.36 (267.9 examples/sec; 0.030 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:37:46.664231: step 121770, total loss = 0.52, batch loss = 0.26 (335.5 examples/sec; 0.024 sec/batch; 0h:30m:53s remains)
INFO - root - 2022-02-24 20:37:47.071211: step 121780, total loss = 0.63, batch loss = 0.37 (105.0 examples/sec; 0.076 sec/batch; 1h:38m:42s remains)
INFO - root - 2022-02-24 20:37:47.535561: step 121790, total loss = 0.55, batch loss = 0.29 (107.2 examples/sec; 0.075 sec/batch; 1h:36m:39s remains)
INFO - root - 2022-02-24 20:37:47.868757: step 121800, total loss = 0.48, batch loss = 0.22 (356.8 examples/sec; 0.022 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 20:37:48.275639: step 121810, total loss = 0.52, batch loss = 0.26 (320.8 examples/sec; 0.025 sec/batch; 0h:32m:17s remains)
INFO - root - 2022-02-24 20:37:48.615423: step 121820, total loss = 0.65, batch loss = 0.39 (252.5 examples/sec; 0.032 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:37:49.105209: step 121830, total loss = 0.60, batch loss = 0.34 (134.2 examples/sec; 0.060 sec/batch; 1h:17m:10s remains)
INFO - root - 2022-02-24 20:37:49.614126: step 121840, total loss = 0.51, batch loss = 0.25 (182.7 examples/sec; 0.044 sec/batch; 0h:56m:40s remains)
INFO - root - 2022-02-24 20:37:49.962605: step 121850, total loss = 0.66, batch loss = 0.40 (329.0 examples/sec; 0.024 sec/batch; 0h:31m:28s remains)
INFO - root - 2022-02-24 20:37:50.657163: step 121860, total loss = 0.52, batch loss = 0.26 (294.0 examples/sec; 0.027 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 20:37:51.029459: step 121870, total loss = 0.52, batch loss = 0.26 (322.9 examples/sec; 0.025 sec/batch; 0h:32m:03s remains)
INFO - root - 2022-02-24 20:37:51.936104: step 121880, total loss = 0.49, batch loss = 0.23 (290.7 examples/sec; 0.028 sec/batch; 0h:35m:36s remains)
INFO - root - 2022-02-24 20:37:52.347535: step 121890, total loss = 0.53, batch loss = 0.27 (357.0 examples/sec; 0.022 sec/batch; 0h:28m:59s remains)
INFO - root - 2022-02-24 20:37:52.622662: step 121900, total loss = 0.59, batch loss = 0.33 (313.6 examples/sec; 0.026 sec/batch; 0h:32m:59s remains)
INFO - root - 2022-02-24 20:37:52.992475: step 121910, total loss = 0.58, batch loss = 0.31 (325.7 examples/sec; 0.025 sec/batch; 0h:31m:45s remains)
INFO - root - 2022-02-24 20:37:53.305940: step 121920, total loss = 0.43, batch loss = 0.17 (311.1 examples/sec; 0.026 sec/batch; 0h:33m:14s remains)
INFO - root - 2022-02-24 20:37:53.775255: step 121930, total loss = 0.51, batch loss = 0.25 (121.6 examples/sec; 0.066 sec/batch; 1h:25m:03s remains)
INFO - root - 2022-02-24 20:37:54.165393: step 121940, total loss = 0.68, batch loss = 0.42 (180.9 examples/sec; 0.044 sec/batch; 0h:57m:10s remains)
INFO - root - 2022-02-24 20:37:54.585590: step 121950, total loss = 0.50, batch loss = 0.24 (142.3 examples/sec; 0.056 sec/batch; 1h:12m:41s remains)
INFO - root - 2022-02-24 20:37:54.898080: step 121960, total loss = 0.53, batch loss = 0.27 (266.2 examples/sec; 0.030 sec/batch; 0h:38m:50s remains)
INFO - root - 2022-02-24 20:37:55.190467: step 121970, total loss = 0.62, batch loss = 0.36 (209.3 examples/sec; 0.038 sec/batch; 0h:49m:23s remains)
INFO - root - 2022-02-24 20:37:55.545558: step 121980, total loss = 0.59, batch loss = 0.33 (245.0 examples/sec; 0.033 sec/batch; 0h:42m:11s remains)
INFO - root - 2022-02-24 20:37:56.008172: step 121990, total loss = 0.58, batch loss = 0.32 (205.3 examples/sec; 0.039 sec/batch; 0h:50m:20s remains)
INFO - root - 2022-02-24 20:37:56.449408: step 122000, total loss = 0.55, batch loss = 0.29 (228.2 examples/sec; 0.035 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 20:37:56.852762: step 122010, total loss = 0.54, batch loss = 0.28 (324.3 examples/sec; 0.025 sec/batch; 0h:31m:51s remains)
INFO - root - 2022-02-24 20:37:57.239732: step 122020, total loss = 0.54, batch loss = 0.28 (176.6 examples/sec; 0.045 sec/batch; 0h:58m:29s remains)
INFO - root - 2022-02-24 20:37:57.537440: step 122030, total loss = 0.51, batch loss = 0.25 (276.8 examples/sec; 0.029 sec/batch; 0h:37m:18s remains)
INFO - root - 2022-02-24 20:37:57.872910: step 122040, total loss = 0.59, batch loss = 0.33 (306.8 examples/sec; 0.026 sec/batch; 0h:33m:40s remains)
INFO - root - 2022-02-24 20:37:58.263526: step 122050, total loss = 0.65, batch loss = 0.39 (367.0 examples/sec; 0.022 sec/batch; 0h:28m:08s remains)
INFO - root - 2022-02-24 20:37:58.659577: step 122060, total loss = 0.56, batch loss = 0.30 (208.4 examples/sec; 0.038 sec/batch; 0h:49m:32s remains)
INFO - root - 2022-02-24 20:37:59.060161: step 122070, total loss = 0.63, batch loss = 0.37 (349.1 examples/sec; 0.023 sec/batch; 0h:29m:34s remains)
INFO - root - 2022-02-24 20:37:59.497551: step 122080, total loss = 0.54, batch loss = 0.28 (323.4 examples/sec; 0.025 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:37:59.804392: step 122090, total loss = 0.57, batch loss = 0.31 (186.0 examples/sec; 0.043 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 20:38:00.140102: step 122100, total loss = 0.53, batch loss = 0.27 (230.1 examples/sec; 0.035 sec/batch; 0h:44m:50s remains)
INFO - root - 2022-02-24 20:38:00.541560: step 122110, total loss = 0.61, batch loss = 0.35 (344.1 examples/sec; 0.023 sec/batch; 0h:29m:59s remains)
INFO - root - 2022-02-24 20:38:00.907573: step 122120, total loss = 0.63, batch loss = 0.37 (139.0 examples/sec; 0.058 sec/batch; 1h:14m:14s remains)
INFO - root - 2022-02-24 20:38:01.299107: step 122130, total loss = 0.65, batch loss = 0.39 (96.2 examples/sec; 0.083 sec/batch; 1h:47m:16s remains)
INFO - root - 2022-02-24 20:38:01.628840: step 122140, total loss = 0.60, batch loss = 0.34 (257.7 examples/sec; 0.031 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:38:01.969370: step 122150, total loss = 0.57, batch loss = 0.30 (311.3 examples/sec; 0.026 sec/batch; 0h:33m:07s remains)
INFO - root - 2022-02-24 20:38:02.299022: step 122160, total loss = 0.54, batch loss = 0.28 (302.0 examples/sec; 0.026 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 20:38:02.674288: step 122170, total loss = 0.53, batch loss = 0.27 (299.6 examples/sec; 0.027 sec/batch; 0h:34m:24s remains)
INFO - root - 2022-02-24 20:38:03.102464: step 122180, total loss = 0.52, batch loss = 0.26 (355.1 examples/sec; 0.023 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 20:38:03.497503: step 122190, total loss = 0.54, batch loss = 0.28 (325.9 examples/sec; 0.025 sec/batch; 0h:31m:37s remains)
INFO - root - 2022-02-24 20:38:03.810026: step 122200, total loss = 0.55, batch loss = 0.29 (325.9 examples/sec; 0.025 sec/batch; 0h:31m:37s remains)
INFO - root - 2022-02-24 20:38:04.186061: step 122210, total loss = 0.72, batch loss = 0.46 (316.1 examples/sec; 0.025 sec/batch; 0h:32m:36s remains)
INFO - root - 2022-02-24 20:38:04.652399: step 122220, total loss = 0.58, batch loss = 0.32 (118.9 examples/sec; 0.067 sec/batch; 1h:26m:40s remains)
INFO - root - 2022-02-24 20:38:05.125782: step 122230, total loss = 0.55, batch loss = 0.28 (147.3 examples/sec; 0.054 sec/batch; 1h:09m:56s remains)
INFO - root - 2022-02-24 20:38:05.485764: step 122240, total loss = 0.56, batch loss = 0.30 (170.4 examples/sec; 0.047 sec/batch; 1h:00m:26s remains)
INFO - root - 2022-02-24 20:38:05.782893: step 122250, total loss = 0.55, batch loss = 0.29 (259.6 examples/sec; 0.031 sec/batch; 0h:39m:40s remains)
INFO - root - 2022-02-24 20:38:06.141208: step 122260, total loss = 0.49, batch loss = 0.23 (304.5 examples/sec; 0.026 sec/batch; 0h:33m:49s remains)
INFO - root - 2022-02-24 20:38:06.670223: step 122270, total loss = 0.58, batch loss = 0.32 (133.4 examples/sec; 0.060 sec/batch; 1h:17m:12s remains)
INFO - root - 2022-02-24 20:38:06.969924: step 122280, total loss = 0.51, batch loss = 0.25 (328.9 examples/sec; 0.024 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 20:38:07.354511: step 122290, total loss = 0.55, batch loss = 0.29 (175.6 examples/sec; 0.046 sec/batch; 0h:58m:37s remains)
INFO - root - 2022-02-24 20:38:07.705184: step 122300, total loss = 0.54, batch loss = 0.28 (262.2 examples/sec; 0.031 sec/batch; 0h:39m:15s remains)
INFO - root - 2022-02-24 20:38:08.087534: step 122310, total loss = 0.52, batch loss = 0.26 (338.0 examples/sec; 0.024 sec/batch; 0h:30m:26s remains)
INFO - root - 2022-02-24 20:38:08.500840: step 122320, total loss = 0.54, batch loss = 0.28 (346.0 examples/sec; 0.023 sec/batch; 0h:29m:44s remains)
INFO - root - 2022-02-24 20:38:08.912688: step 122330, total loss = 0.62, batch loss = 0.36 (289.8 examples/sec; 0.028 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:38:09.265092: step 122340, total loss = 0.52, batch loss = 0.26 (346.6 examples/sec; 0.023 sec/batch; 0h:29m:40s remains)
INFO - root - 2022-02-24 20:38:09.559844: step 122350, total loss = 0.53, batch loss = 0.27 (315.1 examples/sec; 0.025 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 20:38:09.888384: step 122360, total loss = 0.51, batch loss = 0.25 (270.6 examples/sec; 0.030 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 20:38:10.207007: step 122370, total loss = 0.48, batch loss = 0.22 (300.5 examples/sec; 0.027 sec/batch; 0h:34m:13s remains)
INFO - root - 2022-02-24 20:38:10.588310: step 122380, total loss = 0.48, batch loss = 0.22 (210.4 examples/sec; 0.038 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 20:38:11.130604: step 122390, total loss = 0.54, batch loss = 0.28 (99.0 examples/sec; 0.081 sec/batch; 1h:43m:52s remains)
INFO - root - 2022-02-24 20:38:12.062235: step 122400, total loss = 0.57, batch loss = 0.31 (286.1 examples/sec; 0.028 sec/batch; 0h:35m:56s remains)
INFO - root - 2022-02-24 20:38:12.531848: step 122410, total loss = 0.61, batch loss = 0.35 (346.2 examples/sec; 0.023 sec/batch; 0h:29m:41s remains)
INFO - root - 2022-02-24 20:38:12.918478: step 122420, total loss = 0.47, batch loss = 0.21 (237.9 examples/sec; 0.034 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:38:13.324184: step 122430, total loss = 0.51, batch loss = 0.25 (320.4 examples/sec; 0.025 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:38:13.792939: step 122440, total loss = 0.46, batch loss = 0.20 (211.8 examples/sec; 0.038 sec/batch; 0h:48m:30s remains)
INFO - root - 2022-02-24 20:38:14.138644: step 122450, total loss = 0.52, batch loss = 0.26 (194.5 examples/sec; 0.041 sec/batch; 0h:52m:49s remains)
INFO - root - 2022-02-24 20:38:14.457308: step 122460, total loss = 0.56, batch loss = 0.30 (343.8 examples/sec; 0.023 sec/batch; 0h:29m:52s remains)
INFO - root - 2022-02-24 20:38:14.852040: step 122470, total loss = 0.49, batch loss = 0.23 (168.1 examples/sec; 0.048 sec/batch; 1h:01m:05s remains)
INFO - root - 2022-02-24 20:38:15.216394: step 122480, total loss = 0.71, batch loss = 0.45 (211.2 examples/sec; 0.038 sec/batch; 0h:48m:36s remains)
INFO - root - 2022-02-24 20:38:15.591129: step 122490, total loss = 0.59, batch loss = 0.33 (172.2 examples/sec; 0.046 sec/batch; 0h:59m:37s remains)
INFO - root - 2022-02-24 20:38:16.057652: step 122500, total loss = 0.52, batch loss = 0.26 (229.4 examples/sec; 0.035 sec/batch; 0h:44m:44s remains)
INFO - root - 2022-02-24 20:38:16.470263: step 122510, total loss = 0.54, batch loss = 0.28 (225.8 examples/sec; 0.035 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:38:17.261274: step 122520, total loss = 0.53, batch loss = 0.27 (22.3 examples/sec; 0.359 sec/batch; 7h:40m:30s remains)
INFO - root - 2022-02-24 20:38:17.690650: step 122530, total loss = 0.52, batch loss = 0.26 (292.3 examples/sec; 0.027 sec/batch; 0h:35m:06s remains)
INFO - root - 2022-02-24 20:38:18.005075: step 122540, total loss = 0.52, batch loss = 0.26 (198.8 examples/sec; 0.040 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:38:18.322578: step 122550, total loss = 0.50, batch loss = 0.24 (132.4 examples/sec; 0.060 sec/batch; 1h:17m:29s remains)
INFO - root - 2022-02-24 20:38:18.720176: step 122560, total loss = 0.64, batch loss = 0.38 (279.9 examples/sec; 0.029 sec/batch; 0h:36m:39s remains)
INFO - root - 2022-02-24 20:38:19.139570: step 122570, total loss = 0.46, batch loss = 0.20 (358.5 examples/sec; 0.022 sec/batch; 0h:28m:36s remains)
INFO - root - 2022-02-24 20:38:19.616018: step 122580, total loss = 0.58, batch loss = 0.32 (144.3 examples/sec; 0.055 sec/batch; 1h:11m:04s remains)
INFO - root - 2022-02-24 20:38:19.892649: step 122590, total loss = 0.55, batch loss = 0.29 (231.4 examples/sec; 0.035 sec/batch; 0h:44m:19s remains)
INFO - root - 2022-02-24 20:38:20.225041: step 122600, total loss = 0.45, batch loss = 0.19 (251.6 examples/sec; 0.032 sec/batch; 0h:40m:44s remains)
INFO - root - 2022-02-24 20:38:20.657947: step 122610, total loss = 0.65, batch loss = 0.39 (212.9 examples/sec; 0.038 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:38:21.002210: step 122620, total loss = 0.62, batch loss = 0.36 (339.5 examples/sec; 0.024 sec/batch; 0h:30m:11s remains)
INFO - root - 2022-02-24 20:38:21.468318: step 122630, total loss = 0.63, batch loss = 0.37 (127.0 examples/sec; 0.063 sec/batch; 1h:20m:41s remains)
INFO - root - 2022-02-24 20:38:21.863551: step 122640, total loss = 0.58, batch loss = 0.32 (126.2 examples/sec; 0.063 sec/batch; 1h:21m:12s remains)
INFO - root - 2022-02-24 20:38:22.186504: step 122650, total loss = 0.55, batch loss = 0.29 (304.3 examples/sec; 0.026 sec/batch; 0h:33m:40s remains)
INFO - root - 2022-02-24 20:38:22.592450: step 122660, total loss = 0.60, batch loss = 0.34 (177.2 examples/sec; 0.045 sec/batch; 0h:57m:48s remains)
INFO - root - 2022-02-24 20:38:22.930225: step 122670, total loss = 0.57, batch loss = 0.31 (157.5 examples/sec; 0.051 sec/batch; 1h:05m:03s remains)
INFO - root - 2022-02-24 20:38:23.331719: step 122680, total loss = 0.56, batch loss = 0.30 (90.5 examples/sec; 0.088 sec/batch; 1h:53m:13s remains)
INFO - root - 2022-02-24 20:38:23.787340: step 122690, total loss = 0.46, batch loss = 0.20 (143.3 examples/sec; 0.056 sec/batch; 1h:11m:28s remains)
INFO - root - 2022-02-24 20:38:24.161627: step 122700, total loss = 0.56, batch loss = 0.30 (333.1 examples/sec; 0.024 sec/batch; 0h:30m:44s remains)
INFO - root - 2022-02-24 20:38:24.529807: step 122710, total loss = 0.48, batch loss = 0.21 (289.0 examples/sec; 0.028 sec/batch; 0h:35m:25s remains)
INFO - root - 2022-02-24 20:38:24.830215: step 122720, total loss = 0.55, batch loss = 0.29 (287.2 examples/sec; 0.028 sec/batch; 0h:35m:39s remains)
INFO - root - 2022-02-24 20:38:25.141082: step 122730, total loss = 0.50, batch loss = 0.23 (318.6 examples/sec; 0.025 sec/batch; 0h:32m:07s remains)
INFO - root - 2022-02-24 20:38:25.540548: step 122740, total loss = 0.46, batch loss = 0.20 (396.1 examples/sec; 0.020 sec/batch; 0h:25m:50s remains)
INFO - root - 2022-02-24 20:38:25.918386: step 122750, total loss = 0.50, batch loss = 0.24 (174.9 examples/sec; 0.046 sec/batch; 0h:58m:30s remains)
INFO - root - 2022-02-24 20:38:26.345698: step 122760, total loss = 0.63, batch loss = 0.37 (205.3 examples/sec; 0.039 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:38:26.679684: step 122770, total loss = 0.56, batch loss = 0.30 (248.7 examples/sec; 0.032 sec/batch; 0h:41m:07s remains)
INFO - root - 2022-02-24 20:38:26.957334: step 122780, total loss = 0.60, batch loss = 0.33 (297.8 examples/sec; 0.027 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:38:27.226877: step 122790, total loss = 0.58, batch loss = 0.32 (326.6 examples/sec; 0.024 sec/batch; 0h:31m:19s remains)
INFO - root - 2022-02-24 20:38:27.726244: step 122800, total loss = 0.54, batch loss = 0.28 (203.1 examples/sec; 0.039 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:38:28.143298: step 122810, total loss = 0.54, batch loss = 0.28 (329.9 examples/sec; 0.024 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 20:38:28.652933: step 122820, total loss = 0.61, batch loss = 0.35 (306.5 examples/sec; 0.026 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:38:28.979588: step 122830, total loss = 0.58, batch loss = 0.32 (323.9 examples/sec; 0.025 sec/batch; 0h:31m:33s remains)
INFO - root - 2022-02-24 20:38:29.426053: step 122840, total loss = 0.61, batch loss = 0.35 (368.1 examples/sec; 0.022 sec/batch; 0h:27m:45s remains)
INFO - root - 2022-02-24 20:38:29.958203: step 122850, total loss = 0.52, batch loss = 0.26 (248.3 examples/sec; 0.032 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:38:30.544291: step 122860, total loss = 0.57, batch loss = 0.31 (219.9 examples/sec; 0.036 sec/batch; 0h:46m:28s remains)
INFO - root - 2022-02-24 20:38:30.978632: step 122870, total loss = 0.62, batch loss = 0.36 (294.8 examples/sec; 0.027 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:38:31.529529: step 122880, total loss = 0.54, batch loss = 0.28 (300.9 examples/sec; 0.027 sec/batch; 0h:33m:56s remains)
INFO - root - 2022-02-24 20:38:31.931892: step 122890, total loss = 0.52, batch loss = 0.26 (235.7 examples/sec; 0.034 sec/batch; 0h:43m:19s remains)
INFO - root - 2022-02-24 20:38:32.916874: step 122900, total loss = 0.52, batch loss = 0.26 (13.6 examples/sec; 0.588 sec/batch; 12h:30m:54s remains)
INFO - root - 2022-02-24 20:38:33.461962: step 122910, total loss = 0.51, batch loss = 0.25 (181.7 examples/sec; 0.044 sec/batch; 0h:56m:12s remains)
INFO - root - 2022-02-24 20:38:33.812087: step 122920, total loss = 0.58, batch loss = 0.32 (134.0 examples/sec; 0.060 sec/batch; 1h:16m:11s remains)
INFO - root - 2022-02-24 20:38:34.231190: step 122930, total loss = 0.54, batch loss = 0.28 (212.0 examples/sec; 0.038 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:38:34.527262: step 122940, total loss = 0.60, batch loss = 0.34 (242.3 examples/sec; 0.033 sec/batch; 0h:42m:07s remains)
INFO - root - 2022-02-24 20:38:34.902329: step 122950, total loss = 0.52, batch loss = 0.25 (207.6 examples/sec; 0.039 sec/batch; 0h:49m:09s remains)
INFO - root - 2022-02-24 20:38:35.243892: step 122960, total loss = 0.51, batch loss = 0.25 (327.2 examples/sec; 0.024 sec/batch; 0h:31m:11s remains)
INFO - root - 2022-02-24 20:38:35.576348: step 122970, total loss = 0.58, batch loss = 0.32 (232.4 examples/sec; 0.034 sec/batch; 0h:43m:54s remains)
INFO - root - 2022-02-24 20:38:35.873465: step 122980, total loss = 0.52, batch loss = 0.26 (168.0 examples/sec; 0.048 sec/batch; 1h:00m:44s remains)
INFO - root - 2022-02-24 20:38:36.324024: step 122990, total loss = 0.55, batch loss = 0.29 (304.3 examples/sec; 0.026 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:38:36.663484: step 123000, total loss = 0.51, batch loss = 0.25 (350.3 examples/sec; 0.023 sec/batch; 0h:29m:07s remains)
INFO - root - 2022-02-24 20:38:37.211088: step 123010, total loss = 0.55, batch loss = 0.29 (166.8 examples/sec; 0.048 sec/batch; 1h:01m:09s remains)
INFO - root - 2022-02-24 20:38:37.606047: step 123020, total loss = 0.53, batch loss = 0.27 (305.4 examples/sec; 0.026 sec/batch; 0h:33m:23s remains)
INFO - root - 2022-02-24 20:38:37.925957: step 123030, total loss = 0.54, batch loss = 0.28 (317.8 examples/sec; 0.025 sec/batch; 0h:32m:05s remains)
INFO - root - 2022-02-24 20:38:38.290501: step 123040, total loss = 0.65, batch loss = 0.39 (198.7 examples/sec; 0.040 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:38:38.594714: step 123050, total loss = 0.59, batch loss = 0.33 (283.3 examples/sec; 0.028 sec/batch; 0h:35m:58s remains)
INFO - root - 2022-02-24 20:38:39.068319: step 123060, total loss = 0.47, batch loss = 0.21 (335.9 examples/sec; 0.024 sec/batch; 0h:30m:20s remains)
INFO - root - 2022-02-24 20:38:39.429614: step 123070, total loss = 0.53, batch loss = 0.27 (216.2 examples/sec; 0.037 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:38:39.734359: step 123080, total loss = 0.68, batch loss = 0.42 (344.4 examples/sec; 0.023 sec/batch; 0h:29m:35s remains)
INFO - root - 2022-02-24 20:38:40.095693: step 123090, total loss = 0.59, batch loss = 0.33 (344.0 examples/sec; 0.023 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 20:38:40.441421: step 123100, total loss = 0.45, batch loss = 0.19 (203.8 examples/sec; 0.039 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:38:40.915388: step 123110, total loss = 0.58, batch loss = 0.32 (241.9 examples/sec; 0.033 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:38:41.464728: step 123120, total loss = 0.53, batch loss = 0.27 (149.7 examples/sec; 0.053 sec/batch; 1h:08m:02s remains)
INFO - root - 2022-02-24 20:38:41.834254: step 123130, total loss = 0.66, batch loss = 0.40 (372.8 examples/sec; 0.021 sec/batch; 0h:27m:18s remains)
INFO - root - 2022-02-24 20:38:42.127358: step 123140, total loss = 0.58, batch loss = 0.32 (297.5 examples/sec; 0.027 sec/batch; 0h:34m:13s remains)
INFO - root - 2022-02-24 20:38:42.458765: step 123150, total loss = 0.54, batch loss = 0.28 (223.0 examples/sec; 0.036 sec/batch; 0h:45m:38s remains)
INFO - root - 2022-02-24 20:38:42.843899: step 123160, total loss = 0.66, batch loss = 0.40 (131.4 examples/sec; 0.061 sec/batch; 1h:17m:26s remains)
INFO - root - 2022-02-24 20:38:43.335553: step 123170, total loss = 0.82, batch loss = 0.56 (201.2 examples/sec; 0.040 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:38:43.770730: step 123180, total loss = 0.55, batch loss = 0.29 (141.7 examples/sec; 0.056 sec/batch; 1h:11m:48s remains)
INFO - root - 2022-02-24 20:38:44.102893: step 123190, total loss = 0.57, batch loss = 0.31 (319.2 examples/sec; 0.025 sec/batch; 0h:31m:52s remains)
INFO - root - 2022-02-24 20:38:44.437975: step 123200, total loss = 0.48, batch loss = 0.22 (264.5 examples/sec; 0.030 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:38:44.808550: step 123210, total loss = 0.70, batch loss = 0.44 (302.8 examples/sec; 0.026 sec/batch; 0h:33m:35s remains)
INFO - root - 2022-02-24 20:38:45.182548: step 123220, total loss = 0.63, batch loss = 0.37 (374.5 examples/sec; 0.021 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 20:38:45.640349: step 123230, total loss = 0.57, batch loss = 0.30 (293.3 examples/sec; 0.027 sec/batch; 0h:34m:40s remains)
INFO - root - 2022-02-24 20:38:46.043114: step 123240, total loss = 0.54, batch loss = 0.28 (318.2 examples/sec; 0.025 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:38:46.355456: step 123250, total loss = 0.61, batch loss = 0.35 (334.8 examples/sec; 0.024 sec/batch; 0h:30m:22s remains)
INFO - root - 2022-02-24 20:38:46.694956: step 123260, total loss = 0.51, batch loss = 0.25 (307.7 examples/sec; 0.026 sec/batch; 0h:33m:01s remains)
INFO - root - 2022-02-24 20:38:47.238650: step 123270, total loss = 0.72, batch loss = 0.46 (190.2 examples/sec; 0.042 sec/batch; 0h:53m:25s remains)
INFO - root - 2022-02-24 20:38:47.688538: step 123280, total loss = 0.53, batch loss = 0.27 (152.7 examples/sec; 0.052 sec/batch; 1h:06m:33s remains)
INFO - root - 2022-02-24 20:38:48.597967: step 123290, total loss = 0.53, batch loss = 0.27 (18.1 examples/sec; 0.443 sec/batch; 9h:22m:34s remains)
INFO - root - 2022-02-24 20:38:48.998328: step 123300, total loss = 0.50, batch loss = 0.24 (184.7 examples/sec; 0.043 sec/batch; 0h:55m:01s remains)
INFO - root - 2022-02-24 20:38:49.558458: step 123310, total loss = 0.52, batch loss = 0.26 (104.3 examples/sec; 0.077 sec/batch; 1h:37m:22s remains)
INFO - root - 2022-02-24 20:38:50.026339: step 123320, total loss = 0.57, batch loss = 0.31 (255.5 examples/sec; 0.031 sec/batch; 0h:39m:45s remains)
INFO - root - 2022-02-24 20:38:50.397587: step 123330, total loss = 0.60, batch loss = 0.34 (315.4 examples/sec; 0.025 sec/batch; 0h:32m:11s remains)
INFO - root - 2022-02-24 20:38:50.759773: step 123340, total loss = 0.59, batch loss = 0.33 (162.7 examples/sec; 0.049 sec/batch; 1h:02m:24s remains)
INFO - root - 2022-02-24 20:38:51.111300: step 123350, total loss = 0.56, batch loss = 0.30 (348.3 examples/sec; 0.023 sec/batch; 0h:29m:08s remains)
INFO - root - 2022-02-24 20:38:51.529241: step 123360, total loss = 0.53, batch loss = 0.27 (129.4 examples/sec; 0.062 sec/batch; 1h:18m:27s remains)
INFO - root - 2022-02-24 20:38:51.993637: step 123370, total loss = 0.49, batch loss = 0.23 (78.2 examples/sec; 0.102 sec/batch; 2h:09m:43s remains)
INFO - root - 2022-02-24 20:38:52.337154: step 123380, total loss = 0.54, batch loss = 0.28 (274.9 examples/sec; 0.029 sec/batch; 0h:36m:55s remains)
INFO - root - 2022-02-24 20:38:52.756308: step 123390, total loss = 0.55, batch loss = 0.29 (110.4 examples/sec; 0.072 sec/batch; 1h:31m:52s remains)
INFO - root - 2022-02-24 20:38:53.336452: step 123400, total loss = 0.55, batch loss = 0.29 (152.0 examples/sec; 0.053 sec/batch; 1h:06m:45s remains)
INFO - root - 2022-02-24 20:38:53.728083: step 123410, total loss = 0.53, batch loss = 0.27 (237.4 examples/sec; 0.034 sec/batch; 0h:42m:44s remains)
INFO - root - 2022-02-24 20:38:54.251764: step 123420, total loss = 0.50, batch loss = 0.24 (162.9 examples/sec; 0.049 sec/batch; 1h:02m:15s remains)
INFO - root - 2022-02-24 20:38:54.555031: step 123430, total loss = 0.61, batch loss = 0.35 (259.5 examples/sec; 0.031 sec/batch; 0h:39m:05s remains)
INFO - root - 2022-02-24 20:38:54.896465: step 123440, total loss = 0.57, batch loss = 0.31 (193.0 examples/sec; 0.041 sec/batch; 0h:52m:32s remains)
INFO - root - 2022-02-24 20:38:55.267408: step 123450, total loss = 0.55, batch loss = 0.29 (224.8 examples/sec; 0.036 sec/batch; 0h:45m:06s remains)
INFO - root - 2022-02-24 20:38:55.676099: step 123460, total loss = 0.60, batch loss = 0.34 (287.7 examples/sec; 0.028 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 20:38:56.011918: step 123470, total loss = 0.49, batch loss = 0.23 (269.6 examples/sec; 0.030 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 20:38:56.335905: step 123480, total loss = 0.53, batch loss = 0.26 (306.6 examples/sec; 0.026 sec/batch; 0h:33m:03s remains)
INFO - root - 2022-02-24 20:38:56.622930: step 123490, total loss = 0.51, batch loss = 0.25 (238.8 examples/sec; 0.034 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:38:56.955124: step 123500, total loss = 0.61, batch loss = 0.35 (166.3 examples/sec; 0.048 sec/batch; 1h:00m:57s remains)
INFO - root - 2022-02-24 20:38:57.347236: step 123510, total loss = 0.49, batch loss = 0.23 (294.4 examples/sec; 0.027 sec/batch; 0h:34m:24s remains)
INFO - root - 2022-02-24 20:38:57.780231: step 123520, total loss = 0.50, batch loss = 0.24 (291.1 examples/sec; 0.027 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:38:58.177511: step 123530, total loss = 0.51, batch loss = 0.25 (382.8 examples/sec; 0.021 sec/batch; 0h:26m:27s remains)
INFO - root - 2022-02-24 20:38:58.546500: step 123540, total loss = 0.46, batch loss = 0.20 (242.9 examples/sec; 0.033 sec/batch; 0h:41m:42s remains)
INFO - root - 2022-02-24 20:38:58.858668: step 123550, total loss = 0.51, batch loss = 0.25 (355.8 examples/sec; 0.022 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 20:38:59.188558: step 123560, total loss = 0.55, batch loss = 0.29 (337.0 examples/sec; 0.024 sec/batch; 0h:30m:02s remains)
INFO - root - 2022-02-24 20:38:59.615113: step 123570, total loss = 0.53, batch loss = 0.27 (121.9 examples/sec; 0.066 sec/batch; 1h:23m:04s remains)
INFO - root - 2022-02-24 20:39:00.140471: step 123580, total loss = 0.60, batch loss = 0.34 (183.9 examples/sec; 0.044 sec/batch; 0h:55m:03s remains)
INFO - root - 2022-02-24 20:39:00.554792: step 123590, total loss = 0.57, batch loss = 0.31 (154.5 examples/sec; 0.052 sec/batch; 1h:05m:31s remains)
INFO - root - 2022-02-24 20:39:00.870207: step 123600, total loss = 0.56, batch loss = 0.29 (333.4 examples/sec; 0.024 sec/batch; 0h:30m:21s remains)
INFO - root - 2022-02-24 20:39:01.324004: step 123610, total loss = 0.52, batch loss = 0.26 (316.2 examples/sec; 0.025 sec/batch; 0h:31m:59s remains)
INFO - root - 2022-02-24 20:39:01.730380: step 123620, total loss = 0.61, batch loss = 0.35 (336.2 examples/sec; 0.024 sec/batch; 0h:30m:05s remains)
INFO - root - 2022-02-24 20:39:02.085730: step 123630, total loss = 0.53, batch loss = 0.27 (287.4 examples/sec; 0.028 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 20:39:02.518829: step 123640, total loss = 0.48, batch loss = 0.22 (363.7 examples/sec; 0.022 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 20:39:02.863504: step 123650, total loss = 0.65, batch loss = 0.38 (201.1 examples/sec; 0.040 sec/batch; 0h:50m:17s remains)
INFO - root - 2022-02-24 20:39:03.245133: step 123660, total loss = 0.52, batch loss = 0.26 (312.3 examples/sec; 0.026 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 20:39:04.157064: step 123670, total loss = 0.55, batch loss = 0.29 (174.4 examples/sec; 0.046 sec/batch; 0h:57m:57s remains)
INFO - root - 2022-02-24 20:39:04.597272: step 123680, total loss = 0.59, batch loss = 0.33 (117.3 examples/sec; 0.068 sec/batch; 1h:26m:11s remains)
INFO - root - 2022-02-24 20:39:05.087055: step 123690, total loss = 0.52, batch loss = 0.26 (292.1 examples/sec; 0.027 sec/batch; 0h:34m:35s remains)
INFO - root - 2022-02-24 20:39:05.482147: step 123700, total loss = 0.53, batch loss = 0.27 (257.5 examples/sec; 0.031 sec/batch; 0h:39m:15s remains)
INFO - root - 2022-02-24 20:39:05.853139: step 123710, total loss = 0.54, batch loss = 0.28 (316.4 examples/sec; 0.025 sec/batch; 0h:31m:56s remains)
INFO - root - 2022-02-24 20:39:06.304065: step 123720, total loss = 0.50, batch loss = 0.24 (156.9 examples/sec; 0.051 sec/batch; 1h:04m:24s remains)
INFO - root - 2022-02-24 20:39:06.699750: step 123730, total loss = 0.49, batch loss = 0.23 (280.1 examples/sec; 0.029 sec/batch; 0h:36m:03s remains)
INFO - root - 2022-02-24 20:39:06.985141: step 123740, total loss = 0.48, batch loss = 0.22 (294.4 examples/sec; 0.027 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:39:07.392785: step 123750, total loss = 0.60, batch loss = 0.34 (170.5 examples/sec; 0.047 sec/batch; 0h:59m:13s remains)
INFO - root - 2022-02-24 20:39:07.726715: step 123760, total loss = 0.53, batch loss = 0.27 (319.1 examples/sec; 0.025 sec/batch; 0h:31m:38s remains)
INFO - root - 2022-02-24 20:39:08.063685: step 123770, total loss = 0.47, batch loss = 0.21 (172.6 examples/sec; 0.046 sec/batch; 0h:58m:30s remains)
INFO - root - 2022-02-24 20:39:08.809857: step 123780, total loss = 0.51, batch loss = 0.25 (165.4 examples/sec; 0.048 sec/batch; 1h:01m:02s remains)
INFO - root - 2022-02-24 20:39:09.194077: step 123790, total loss = 0.51, batch loss = 0.25 (233.7 examples/sec; 0.034 sec/batch; 0h:43m:11s remains)
INFO - root - 2022-02-24 20:39:09.560519: step 123800, total loss = 0.62, batch loss = 0.36 (209.9 examples/sec; 0.038 sec/batch; 0h:48m:05s remains)
INFO - root - 2022-02-24 20:39:09.926527: step 123810, total loss = 0.61, batch loss = 0.35 (336.0 examples/sec; 0.024 sec/batch; 0h:30m:01s remains)
INFO - root - 2022-02-24 20:39:10.308175: step 123820, total loss = 0.52, batch loss = 0.26 (87.9 examples/sec; 0.091 sec/batch; 1h:54m:49s remains)
INFO - root - 2022-02-24 20:39:10.755950: step 123830, total loss = 0.49, batch loss = 0.23 (91.3 examples/sec; 0.088 sec/batch; 1h:50m:34s remains)
INFO - root - 2022-02-24 20:39:11.133714: step 123840, total loss = 0.49, batch loss = 0.23 (375.4 examples/sec; 0.021 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 20:39:11.459341: step 123850, total loss = 0.52, batch loss = 0.26 (341.6 examples/sec; 0.023 sec/batch; 0h:29m:31s remains)
INFO - root - 2022-02-24 20:39:11.850403: step 123860, total loss = 0.52, batch loss = 0.26 (332.0 examples/sec; 0.024 sec/batch; 0h:30m:22s remains)
INFO - root - 2022-02-24 20:39:12.181412: step 123870, total loss = 0.67, batch loss = 0.41 (319.5 examples/sec; 0.025 sec/batch; 0h:31m:33s remains)
INFO - root - 2022-02-24 20:39:12.581312: step 123880, total loss = 0.50, batch loss = 0.24 (198.0 examples/sec; 0.040 sec/batch; 0h:50m:55s remains)
INFO - root - 2022-02-24 20:39:13.016881: step 123890, total loss = 0.46, batch loss = 0.20 (200.6 examples/sec; 0.040 sec/batch; 0h:50m:15s remains)
INFO - root - 2022-02-24 20:39:13.428943: step 123900, total loss = 0.51, batch loss = 0.25 (365.4 examples/sec; 0.022 sec/batch; 0h:27m:35s remains)
INFO - root - 2022-02-24 20:39:13.811390: step 123910, total loss = 0.67, batch loss = 0.41 (328.1 examples/sec; 0.024 sec/batch; 0h:30m:43s remains)
INFO - root - 2022-02-24 20:39:14.115101: step 123920, total loss = 0.62, batch loss = 0.36 (273.7 examples/sec; 0.029 sec/batch; 0h:36m:49s remains)
INFO - root - 2022-02-24 20:39:14.440414: step 123930, total loss = 0.52, batch loss = 0.26 (308.1 examples/sec; 0.026 sec/batch; 0h:32m:41s remains)
INFO - root - 2022-02-24 20:39:14.897238: step 123940, total loss = 0.52, batch loss = 0.26 (274.8 examples/sec; 0.029 sec/batch; 0h:36m:39s remains)
INFO - root - 2022-02-24 20:39:15.251082: step 123950, total loss = 0.63, batch loss = 0.37 (86.0 examples/sec; 0.093 sec/batch; 1h:57m:08s remains)
INFO - root - 2022-02-24 20:39:15.630857: step 123960, total loss = 0.49, batch loss = 0.23 (222.9 examples/sec; 0.036 sec/batch; 0h:45m:11s remains)
INFO - root - 2022-02-24 20:39:15.954721: step 123970, total loss = 0.56, batch loss = 0.30 (298.2 examples/sec; 0.027 sec/batch; 0h:33m:46s remains)
INFO - root - 2022-02-24 20:39:16.301586: step 123980, total loss = 0.61, batch loss = 0.35 (379.5 examples/sec; 0.021 sec/batch; 0h:26m:32s remains)
INFO - root - 2022-02-24 20:39:16.621605: step 123990, total loss = 0.54, batch loss = 0.28 (359.8 examples/sec; 0.022 sec/batch; 0h:27m:59s remains)
INFO - root - 2022-02-24 20:39:17.012932: step 124000, total loss = 0.61, batch loss = 0.35 (315.3 examples/sec; 0.025 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:39:17.586156: step 124010, total loss = 0.63, batch loss = 0.37 (229.8 examples/sec; 0.035 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:39:17.948885: step 124020, total loss = 0.61, batch loss = 0.35 (280.0 examples/sec; 0.029 sec/batch; 0h:35m:56s remains)
INFO - root - 2022-02-24 20:39:18.226563: step 124030, total loss = 0.60, batch loss = 0.34 (322.5 examples/sec; 0.025 sec/batch; 0h:31m:11s remains)
INFO - root - 2022-02-24 20:39:18.619453: step 124040, total loss = 0.47, batch loss = 0.21 (328.0 examples/sec; 0.024 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:39:18.892166: step 124050, total loss = 0.59, batch loss = 0.32 (184.4 examples/sec; 0.043 sec/batch; 0h:54m:33s remains)
INFO - root - 2022-02-24 20:39:19.295335: step 124060, total loss = 0.56, batch loss = 0.30 (338.3 examples/sec; 0.024 sec/batch; 0h:29m:44s remains)
INFO - root - 2022-02-24 20:39:19.678324: step 124070, total loss = 0.51, batch loss = 0.25 (195.5 examples/sec; 0.041 sec/batch; 0h:51m:26s remains)
INFO - root - 2022-02-24 20:39:20.092711: step 124080, total loss = 0.58, batch loss = 0.32 (272.6 examples/sec; 0.029 sec/batch; 0h:36m:53s remains)
INFO - root - 2022-02-24 20:39:20.614860: step 124090, total loss = 0.48, batch loss = 0.22 (312.8 examples/sec; 0.026 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 20:39:21.308515: step 124100, total loss = 0.61, batch loss = 0.35 (178.1 examples/sec; 0.045 sec/batch; 0h:56m:27s remains)
INFO - root - 2022-02-24 20:39:21.743337: step 124110, total loss = 0.57, batch loss = 0.31 (200.4 examples/sec; 0.040 sec/batch; 0h:50m:09s remains)
INFO - root - 2022-02-24 20:39:22.152692: step 124120, total loss = 0.76, batch loss = 0.50 (226.4 examples/sec; 0.035 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:39:22.453200: step 124130, total loss = 0.51, batch loss = 0.25 (305.7 examples/sec; 0.026 sec/batch; 0h:32m:52s remains)
INFO - root - 2022-02-24 20:39:22.922083: step 124140, total loss = 0.60, batch loss = 0.34 (234.7 examples/sec; 0.034 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:39:23.310183: step 124150, total loss = 0.50, batch loss = 0.24 (165.2 examples/sec; 0.048 sec/batch; 1h:00m:48s remains)
INFO - root - 2022-02-24 20:39:24.189145: step 124160, total loss = 0.59, batch loss = 0.33 (291.4 examples/sec; 0.027 sec/batch; 0h:34m:28s remains)
INFO - root - 2022-02-24 20:39:24.589284: step 124170, total loss = 0.58, batch loss = 0.32 (330.9 examples/sec; 0.024 sec/batch; 0h:30m:21s remains)
INFO - root - 2022-02-24 20:39:24.910309: step 124180, total loss = 0.47, batch loss = 0.21 (350.1 examples/sec; 0.023 sec/batch; 0h:28m:40s remains)
INFO - root - 2022-02-24 20:39:25.269942: step 124190, total loss = 0.57, batch loss = 0.31 (341.2 examples/sec; 0.023 sec/batch; 0h:29m:25s remains)
INFO - root - 2022-02-24 20:39:25.659679: step 124200, total loss = 0.52, batch loss = 0.26 (302.8 examples/sec; 0.026 sec/batch; 0h:33m:09s remains)
INFO - root - 2022-02-24 20:39:26.123208: step 124210, total loss = 0.60, batch loss = 0.34 (129.8 examples/sec; 0.062 sec/batch; 1h:17m:21s remains)
INFO - root - 2022-02-24 20:39:26.520739: step 124220, total loss = 0.69, batch loss = 0.43 (203.0 examples/sec; 0.039 sec/batch; 0h:49m:26s remains)
INFO - root - 2022-02-24 20:39:26.989413: step 124230, total loss = 0.62, batch loss = 0.36 (278.6 examples/sec; 0.029 sec/batch; 0h:36m:01s remains)
INFO - root - 2022-02-24 20:39:27.420870: step 124240, total loss = 0.47, batch loss = 0.21 (307.4 examples/sec; 0.026 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 20:39:27.777966: step 124250, total loss = 0.57, batch loss = 0.31 (242.7 examples/sec; 0.033 sec/batch; 0h:41m:20s remains)
INFO - root - 2022-02-24 20:39:28.119209: step 124260, total loss = 0.52, batch loss = 0.26 (251.7 examples/sec; 0.032 sec/batch; 0h:39m:51s remains)
INFO - root - 2022-02-24 20:39:28.582760: step 124270, total loss = 0.66, batch loss = 0.40 (122.8 examples/sec; 0.065 sec/batch; 1h:21m:40s remains)
INFO - root - 2022-02-24 20:39:29.002759: step 124280, total loss = 0.52, batch loss = 0.26 (346.6 examples/sec; 0.023 sec/batch; 0h:28m:56s remains)
INFO - root - 2022-02-24 20:39:29.341182: step 124290, total loss = 0.56, batch loss = 0.30 (350.9 examples/sec; 0.023 sec/batch; 0h:28m:34s remains)
INFO - root - 2022-02-24 20:39:29.663648: step 124300, total loss = 0.49, batch loss = 0.23 (352.9 examples/sec; 0.023 sec/batch; 0h:28m:24s remains)
INFO - root - 2022-02-24 20:39:30.016644: step 124310, total loss = 0.53, batch loss = 0.26 (357.5 examples/sec; 0.022 sec/batch; 0h:28m:02s remains)
INFO - root - 2022-02-24 20:39:30.385353: step 124320, total loss = 0.55, batch loss = 0.29 (322.6 examples/sec; 0.025 sec/batch; 0h:31m:04s remains)
INFO - root - 2022-02-24 20:39:30.816476: step 124330, total loss = 0.58, batch loss = 0.32 (269.6 examples/sec; 0.030 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:39:31.152083: step 124340, total loss = 0.51, batch loss = 0.25 (261.8 examples/sec; 0.031 sec/batch; 0h:38m:16s remains)
INFO - root - 2022-02-24 20:39:31.487071: step 124350, total loss = 0.57, batch loss = 0.31 (233.6 examples/sec; 0.034 sec/batch; 0h:42m:53s remains)
INFO - root - 2022-02-24 20:39:31.894830: step 124360, total loss = 0.67, batch loss = 0.41 (338.6 examples/sec; 0.024 sec/batch; 0h:29m:35s remains)
INFO - root - 2022-02-24 20:39:32.281953: step 124370, total loss = 0.49, batch loss = 0.23 (150.6 examples/sec; 0.053 sec/batch; 1h:06m:31s remains)
INFO - root - 2022-02-24 20:39:32.643223: step 124380, total loss = 0.52, batch loss = 0.26 (323.6 examples/sec; 0.025 sec/batch; 0h:30m:57s remains)
INFO - root - 2022-02-24 20:39:33.026741: step 124390, total loss = 0.56, batch loss = 0.30 (366.7 examples/sec; 0.022 sec/batch; 0h:27m:18s remains)
INFO - root - 2022-02-24 20:39:33.422625: step 124400, total loss = 0.50, batch loss = 0.24 (189.8 examples/sec; 0.042 sec/batch; 0h:52m:44s remains)
INFO - root - 2022-02-24 20:39:33.895785: step 124410, total loss = 0.55, batch loss = 0.29 (153.2 examples/sec; 0.052 sec/batch; 1h:05m:21s remains)
INFO - root - 2022-02-24 20:39:34.157968: step 124420, total loss = 0.54, batch loss = 0.28 (319.3 examples/sec; 0.025 sec/batch; 0h:31m:21s remains)
INFO - root - 2022-02-24 20:39:34.590506: step 124430, total loss = 0.67, batch loss = 0.41 (214.3 examples/sec; 0.037 sec/batch; 0h:46m:43s remains)
INFO - root - 2022-02-24 20:39:35.058249: step 124440, total loss = 0.50, batch loss = 0.24 (138.9 examples/sec; 0.058 sec/batch; 1h:12m:04s remains)
INFO - root - 2022-02-24 20:39:35.565787: step 124450, total loss = 0.46, batch loss = 0.20 (257.0 examples/sec; 0.031 sec/batch; 0h:38m:55s remains)
INFO - root - 2022-02-24 20:39:35.875976: step 124460, total loss = 0.44, batch loss = 0.18 (288.9 examples/sec; 0.028 sec/batch; 0h:34m:38s remains)
INFO - root - 2022-02-24 20:39:36.203424: step 124470, total loss = 0.61, batch loss = 0.35 (318.1 examples/sec; 0.025 sec/batch; 0h:31m:27s remains)
INFO - root - 2022-02-24 20:39:36.550781: step 124480, total loss = 0.60, batch loss = 0.34 (224.6 examples/sec; 0.036 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:39:37.073576: step 124490, total loss = 0.53, batch loss = 0.27 (129.7 examples/sec; 0.062 sec/batch; 1h:17m:05s remains)
INFO - root - 2022-02-24 20:39:37.601293: step 124500, total loss = 0.52, batch loss = 0.26 (182.1 examples/sec; 0.044 sec/batch; 0h:54m:55s remains)
INFO - root - 2022-02-24 20:39:38.472440: step 124510, total loss = 0.48, batch loss = 0.22 (292.4 examples/sec; 0.027 sec/batch; 0h:34m:11s remains)
INFO - root - 2022-02-24 20:39:38.709974: step 124520, total loss = 0.67, batch loss = 0.41 (364.8 examples/sec; 0.022 sec/batch; 0h:27m:24s remains)
INFO - root - 2022-02-24 20:39:39.610867: step 124530, total loss = 0.58, batch loss = 0.32 (287.4 examples/sec; 0.028 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:39:39.930117: step 124540, total loss = 0.53, batch loss = 0.26 (262.5 examples/sec; 0.030 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:39:40.337752: step 124550, total loss = 0.56, batch loss = 0.30 (320.6 examples/sec; 0.025 sec/batch; 0h:31m:10s remains)
INFO - root - 2022-02-24 20:39:40.604992: step 124560, total loss = 0.54, batch loss = 0.28 (322.8 examples/sec; 0.025 sec/batch; 0h:30m:57s remains)
INFO - root - 2022-02-24 20:39:40.994088: step 124570, total loss = 0.70, batch loss = 0.44 (139.4 examples/sec; 0.057 sec/batch; 1h:11m:38s remains)
INFO - root - 2022-02-24 20:39:41.378452: step 124580, total loss = 0.56, batch loss = 0.30 (362.7 examples/sec; 0.022 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:39:41.818511: step 124590, total loss = 0.51, batch loss = 0.25 (345.5 examples/sec; 0.023 sec/batch; 0h:28m:54s remains)
INFO - root - 2022-02-24 20:39:42.181622: step 124600, total loss = 0.53, batch loss = 0.27 (323.1 examples/sec; 0.025 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 20:39:42.715143: step 124610, total loss = 0.57, batch loss = 0.31 (292.5 examples/sec; 0.027 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 20:39:43.022021: step 124620, total loss = 0.49, batch loss = 0.23 (262.7 examples/sec; 0.030 sec/batch; 0h:37m:59s remains)
INFO - root - 2022-02-24 20:39:43.340150: step 124630, total loss = 0.62, batch loss = 0.36 (222.6 examples/sec; 0.036 sec/batch; 0h:44m:50s remains)
INFO - root - 2022-02-24 20:39:43.740866: step 124640, total loss = 0.55, batch loss = 0.29 (225.4 examples/sec; 0.035 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:39:44.334106: step 124650, total loss = 0.58, batch loss = 0.32 (250.6 examples/sec; 0.032 sec/batch; 0h:39m:49s remains)
INFO - root - 2022-02-24 20:39:44.699121: step 124660, total loss = 0.55, batch loss = 0.29 (331.5 examples/sec; 0.024 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:39:45.065415: step 124670, total loss = 0.52, batch loss = 0.26 (262.5 examples/sec; 0.030 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 20:39:45.385333: step 124680, total loss = 0.54, batch loss = 0.28 (320.9 examples/sec; 0.025 sec/batch; 0h:31m:05s remains)
INFO - root - 2022-02-24 20:39:45.712989: step 124690, total loss = 0.53, batch loss = 0.27 (232.9 examples/sec; 0.034 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:39:46.098401: step 124700, total loss = 0.52, batch loss = 0.26 (76.6 examples/sec; 0.104 sec/batch; 2h:10m:07s remains)
INFO - root - 2022-02-24 20:39:46.529871: step 124710, total loss = 0.60, batch loss = 0.34 (323.8 examples/sec; 0.025 sec/batch; 0h:30m:47s remains)
INFO - root - 2022-02-24 20:39:46.841621: step 124720, total loss = 0.58, batch loss = 0.32 (240.5 examples/sec; 0.033 sec/batch; 0h:41m:27s remains)
INFO - root - 2022-02-24 20:39:47.224244: step 124730, total loss = 0.48, batch loss = 0.22 (155.1 examples/sec; 0.052 sec/batch; 1h:04m:17s remains)
INFO - root - 2022-02-24 20:39:47.593512: step 124740, total loss = 0.57, batch loss = 0.31 (196.4 examples/sec; 0.041 sec/batch; 0h:50m:45s remains)
INFO - root - 2022-02-24 20:39:48.004701: step 124750, total loss = 0.53, batch loss = 0.27 (361.6 examples/sec; 0.022 sec/batch; 0h:27m:33s remains)
INFO - root - 2022-02-24 20:39:48.489307: step 124760, total loss = 0.51, batch loss = 0.25 (79.3 examples/sec; 0.101 sec/batch; 2h:05m:42s remains)
INFO - root - 2022-02-24 20:39:48.796305: step 124770, total loss = 0.54, batch loss = 0.28 (313.0 examples/sec; 0.026 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 20:39:49.125916: step 124780, total loss = 0.51, batch loss = 0.25 (238.7 examples/sec; 0.034 sec/batch; 0h:41m:43s remains)
INFO - root - 2022-02-24 20:39:49.489612: step 124790, total loss = 0.61, batch loss = 0.35 (152.7 examples/sec; 0.052 sec/batch; 1h:05m:13s remains)
INFO - root - 2022-02-24 20:39:49.952288: step 124800, total loss = 0.53, batch loss = 0.27 (144.3 examples/sec; 0.055 sec/batch; 1h:09m:02s remains)
INFO - root - 2022-02-24 20:39:50.337211: step 124810, total loss = 0.54, batch loss = 0.28 (175.8 examples/sec; 0.045 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 20:39:50.676520: step 124820, total loss = 0.55, batch loss = 0.29 (223.6 examples/sec; 0.036 sec/batch; 0h:44m:32s remains)
INFO - root - 2022-02-24 20:39:50.985628: step 124830, total loss = 0.52, batch loss = 0.26 (238.6 examples/sec; 0.034 sec/batch; 0h:41m:43s remains)
INFO - root - 2022-02-24 20:39:51.344710: step 124840, total loss = 0.48, batch loss = 0.22 (224.6 examples/sec; 0.036 sec/batch; 0h:44m:19s remains)
INFO - root - 2022-02-24 20:39:51.772108: step 124850, total loss = 0.56, batch loss = 0.30 (124.1 examples/sec; 0.064 sec/batch; 1h:20m:10s remains)
INFO - root - 2022-02-24 20:39:52.161811: step 124860, total loss = 0.53, batch loss = 0.27 (101.0 examples/sec; 0.079 sec/batch; 1h:38m:30s remains)
INFO - root - 2022-02-24 20:39:52.570315: step 124870, total loss = 0.52, batch loss = 0.26 (145.3 examples/sec; 0.055 sec/batch; 1h:08m:29s remains)
INFO - root - 2022-02-24 20:39:53.059853: step 124880, total loss = 0.65, batch loss = 0.39 (87.3 examples/sec; 0.092 sec/batch; 1h:53m:57s remains)
INFO - root - 2022-02-24 20:39:53.796556: step 124890, total loss = 0.52, batch loss = 0.26 (324.3 examples/sec; 0.025 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:39:54.797096: step 124900, total loss = 0.57, batch loss = 0.31 (322.4 examples/sec; 0.025 sec/batch; 0h:30m:51s remains)
INFO - root - 2022-02-24 20:39:55.175578: step 124910, total loss = 0.53, batch loss = 0.27 (359.8 examples/sec; 0.022 sec/batch; 0h:27m:38s remains)
INFO - root - 2022-02-24 20:39:55.523319: step 124920, total loss = 0.48, batch loss = 0.22 (169.5 examples/sec; 0.047 sec/batch; 0h:58m:39s remains)
INFO - root - 2022-02-24 20:39:55.849989: step 124930, total loss = 0.56, batch loss = 0.30 (163.3 examples/sec; 0.049 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 20:39:56.235234: step 124940, total loss = 0.54, batch loss = 0.28 (170.3 examples/sec; 0.047 sec/batch; 0h:58m:22s remains)
INFO - root - 2022-02-24 20:39:56.731174: step 124950, total loss = 0.56, batch loss = 0.30 (269.6 examples/sec; 0.030 sec/batch; 0h:36m:52s remains)
INFO - root - 2022-02-24 20:39:57.106103: step 124960, total loss = 0.56, batch loss = 0.30 (363.6 examples/sec; 0.022 sec/batch; 0h:27m:20s remains)
INFO - root - 2022-02-24 20:39:57.495551: step 124970, total loss = 0.58, batch loss = 0.32 (123.8 examples/sec; 0.065 sec/batch; 1h:20m:17s remains)
INFO - root - 2022-02-24 20:39:57.854644: step 124980, total loss = 0.64, batch loss = 0.38 (348.9 examples/sec; 0.023 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 20:39:58.170848: step 124990, total loss = 0.53, batch loss = 0.27 (163.3 examples/sec; 0.049 sec/batch; 1h:00m:50s remains)
INFO - root - 2022-02-24 20:39:58.548668: step 125000, total loss = 0.60, batch loss = 0.34 (303.0 examples/sec; 0.026 sec/batch; 0h:32m:46s remains)
INFO - root - 2022-02-24 20:39:59.068208: step 125010, total loss = 0.57, batch loss = 0.31 (112.4 examples/sec; 0.071 sec/batch; 1h:28m:22s remains)
INFO - root - 2022-02-24 20:39:59.366121: step 125020, total loss = 0.51, batch loss = 0.24 (318.7 examples/sec; 0.025 sec/batch; 0h:31m:09s remains)
INFO - root - 2022-02-24 20:39:59.745801: step 125030, total loss = 0.86, batch loss = 0.60 (226.7 examples/sec; 0.035 sec/batch; 0h:43m:47s remains)
INFO - root - 2022-02-24 20:40:00.124701: step 125040, total loss = 0.48, batch loss = 0.22 (317.8 examples/sec; 0.025 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:40:00.561115: step 125050, total loss = 0.53, batch loss = 0.27 (270.9 examples/sec; 0.030 sec/batch; 0h:36m:38s remains)
INFO - root - 2022-02-24 20:40:00.885453: step 125060, total loss = 0.45, batch loss = 0.19 (181.9 examples/sec; 0.044 sec/batch; 0h:54m:34s remains)
INFO - root - 2022-02-24 20:40:01.246652: step 125070, total loss = 0.53, batch loss = 0.27 (316.7 examples/sec; 0.025 sec/batch; 0h:31m:20s remains)
INFO - root - 2022-02-24 20:40:01.541894: step 125080, total loss = 0.58, batch loss = 0.32 (331.9 examples/sec; 0.024 sec/batch; 0h:29m:53s remains)
INFO - root - 2022-02-24 20:40:01.842399: step 125090, total loss = 0.59, batch loss = 0.33 (359.1 examples/sec; 0.022 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 20:40:02.150108: step 125100, total loss = 0.46, batch loss = 0.20 (184.7 examples/sec; 0.043 sec/batch; 0h:53m:42s remains)
INFO - root - 2022-02-24 20:40:02.619594: step 125110, total loss = 0.54, batch loss = 0.28 (341.7 examples/sec; 0.023 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 20:40:02.999332: step 125120, total loss = 0.64, batch loss = 0.38 (181.0 examples/sec; 0.044 sec/batch; 0h:54m:48s remains)
INFO - root - 2022-02-24 20:40:03.372184: step 125130, total loss = 0.46, batch loss = 0.20 (190.2 examples/sec; 0.042 sec/batch; 0h:52m:07s remains)
INFO - root - 2022-02-24 20:40:03.699965: step 125140, total loss = 0.58, batch loss = 0.32 (183.1 examples/sec; 0.044 sec/batch; 0h:54m:08s remains)
INFO - root - 2022-02-24 20:40:04.015192: step 125150, total loss = 0.58, batch loss = 0.32 (219.2 examples/sec; 0.037 sec/batch; 0h:45m:13s remains)
INFO - root - 2022-02-24 20:40:04.413054: step 125160, total loss = 0.60, batch loss = 0.34 (129.8 examples/sec; 0.062 sec/batch; 1h:16m:22s remains)
INFO - root - 2022-02-24 20:40:04.865279: step 125170, total loss = 0.57, batch loss = 0.31 (166.5 examples/sec; 0.048 sec/batch; 0h:59m:32s remains)
INFO - root - 2022-02-24 20:40:05.366454: step 125180, total loss = 0.54, batch loss = 0.28 (159.4 examples/sec; 0.050 sec/batch; 1h:02m:11s remains)
INFO - root - 2022-02-24 20:40:05.724087: step 125190, total loss = 0.49, batch loss = 0.23 (293.0 examples/sec; 0.027 sec/batch; 0h:33m:48s remains)
INFO - root - 2022-02-24 20:40:06.042148: step 125200, total loss = 0.51, batch loss = 0.25 (188.4 examples/sec; 0.042 sec/batch; 0h:52m:34s remains)
INFO - root - 2022-02-24 20:40:06.556061: step 125210, total loss = 0.51, batch loss = 0.25 (80.1 examples/sec; 0.100 sec/batch; 2h:03m:36s remains)
INFO - root - 2022-02-24 20:40:06.896213: step 125220, total loss = 0.51, batch loss = 0.25 (286.6 examples/sec; 0.028 sec/batch; 0h:34m:33s remains)
INFO - root - 2022-02-24 20:40:07.306386: step 125230, total loss = 0.45, batch loss = 0.19 (143.4 examples/sec; 0.056 sec/batch; 1h:09m:04s remains)
INFO - root - 2022-02-24 20:40:07.626694: step 125240, total loss = 0.53, batch loss = 0.27 (185.7 examples/sec; 0.043 sec/batch; 0h:53m:19s remains)
INFO - root - 2022-02-24 20:40:07.947995: step 125250, total loss = 0.55, batch loss = 0.29 (313.9 examples/sec; 0.025 sec/batch; 0h:31m:32s remains)
INFO - root - 2022-02-24 20:40:08.228594: step 125260, total loss = 0.63, batch loss = 0.37 (269.6 examples/sec; 0.030 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:40:08.570854: step 125270, total loss = 0.49, batch loss = 0.23 (254.5 examples/sec; 0.031 sec/batch; 0h:38m:52s remains)
INFO - root - 2022-02-24 20:40:08.992359: step 125280, total loss = 0.65, batch loss = 0.39 (174.6 examples/sec; 0.046 sec/batch; 0h:56m:39s remains)
INFO - root - 2022-02-24 20:40:09.389839: step 125290, total loss = 0.61, batch loss = 0.35 (337.1 examples/sec; 0.024 sec/batch; 0h:29m:21s remains)
INFO - root - 2022-02-24 20:40:09.677889: step 125300, total loss = 0.54, batch loss = 0.28 (276.4 examples/sec; 0.029 sec/batch; 0h:35m:47s remains)
INFO - root - 2022-02-24 20:40:10.432249: step 125310, total loss = 0.57, batch loss = 0.31 (343.3 examples/sec; 0.023 sec/batch; 0h:28m:48s remains)
INFO - root - 2022-02-24 20:40:10.865444: step 125320, total loss = 0.59, batch loss = 0.33 (142.6 examples/sec; 0.056 sec/batch; 1h:09m:21s remains)
INFO - root - 2022-02-24 20:40:11.332151: step 125330, total loss = 0.62, batch loss = 0.36 (216.1 examples/sec; 0.037 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:40:11.696092: step 125340, total loss = 0.55, batch loss = 0.29 (258.2 examples/sec; 0.031 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 20:40:12.210713: step 125350, total loss = 0.51, batch loss = 0.25 (223.5 examples/sec; 0.036 sec/batch; 0h:44m:13s remains)
INFO - root - 2022-02-24 20:40:12.560710: step 125360, total loss = 0.44, batch loss = 0.18 (287.9 examples/sec; 0.028 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:40:13.066125: step 125370, total loss = 0.54, batch loss = 0.28 (297.9 examples/sec; 0.027 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:40:13.563957: step 125380, total loss = 0.56, batch loss = 0.30 (186.3 examples/sec; 0.043 sec/batch; 0h:53m:02s remains)
INFO - root - 2022-02-24 20:40:13.898781: step 125390, total loss = 0.51, batch loss = 0.25 (267.3 examples/sec; 0.030 sec/batch; 0h:36m:57s remains)
INFO - root - 2022-02-24 20:40:14.228047: step 125400, total loss = 0.68, batch loss = 0.42 (199.5 examples/sec; 0.040 sec/batch; 0h:49m:31s remains)
INFO - root - 2022-02-24 20:40:14.650426: step 125410, total loss = 0.67, batch loss = 0.41 (323.2 examples/sec; 0.025 sec/batch; 0h:30m:34s remains)
INFO - root - 2022-02-24 20:40:15.546047: step 125420, total loss = 0.63, batch loss = 0.37 (110.9 examples/sec; 0.072 sec/batch; 1h:29m:02s remains)
INFO - root - 2022-02-24 20:40:16.042106: step 125430, total loss = 0.57, batch loss = 0.31 (72.7 examples/sec; 0.110 sec/batch; 2h:15m:53s remains)
INFO - root - 2022-02-24 20:40:16.401144: step 125440, total loss = 0.64, batch loss = 0.38 (327.6 examples/sec; 0.024 sec/batch; 0h:30m:08s remains)
INFO - root - 2022-02-24 20:40:16.784179: step 125450, total loss = 0.47, batch loss = 0.21 (218.4 examples/sec; 0.037 sec/batch; 0h:45m:12s remains)
INFO - root - 2022-02-24 20:40:17.141492: step 125460, total loss = 0.60, batch loss = 0.34 (306.6 examples/sec; 0.026 sec/batch; 0h:32m:12s remains)
INFO - root - 2022-02-24 20:40:17.534510: step 125470, total loss = 0.64, batch loss = 0.38 (135.2 examples/sec; 0.059 sec/batch; 1h:13m:00s remains)
INFO - root - 2022-02-24 20:40:17.924537: step 125480, total loss = 0.61, batch loss = 0.35 (309.1 examples/sec; 0.026 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:40:18.295876: step 125490, total loss = 0.72, batch loss = 0.46 (274.2 examples/sec; 0.029 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 20:40:18.630872: step 125500, total loss = 0.50, batch loss = 0.24 (330.0 examples/sec; 0.024 sec/batch; 0h:29m:53s remains)
INFO - root - 2022-02-24 20:40:19.018024: step 125510, total loss = 0.64, batch loss = 0.38 (270.2 examples/sec; 0.030 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:40:19.405802: step 125520, total loss = 0.50, batch loss = 0.24 (170.8 examples/sec; 0.047 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 20:40:19.867521: step 125530, total loss = 0.51, batch loss = 0.25 (284.6 examples/sec; 0.028 sec/batch; 0h:34m:39s remains)
INFO - root - 2022-02-24 20:40:20.235998: step 125540, total loss = 0.67, batch loss = 0.41 (303.3 examples/sec; 0.026 sec/batch; 0h:32m:30s remains)
INFO - root - 2022-02-24 20:40:20.567891: step 125550, total loss = 0.51, batch loss = 0.25 (342.1 examples/sec; 0.023 sec/batch; 0h:28m:49s remains)
INFO - root - 2022-02-24 20:40:20.916226: step 125560, total loss = 0.52, batch loss = 0.26 (338.6 examples/sec; 0.024 sec/batch; 0h:29m:06s remains)
INFO - root - 2022-02-24 20:40:21.251847: step 125570, total loss = 0.52, batch loss = 0.26 (193.5 examples/sec; 0.041 sec/batch; 0h:50m:56s remains)
INFO - root - 2022-02-24 20:40:21.606936: step 125580, total loss = 0.54, batch loss = 0.28 (148.0 examples/sec; 0.054 sec/batch; 1h:06m:36s remains)
INFO - root - 2022-02-24 20:40:22.144651: step 125590, total loss = 0.58, batch loss = 0.32 (109.4 examples/sec; 0.073 sec/batch; 1h:30m:05s remains)
INFO - root - 2022-02-24 20:40:22.538335: step 125600, total loss = 0.47, batch loss = 0.21 (319.0 examples/sec; 0.025 sec/batch; 0h:30m:53s remains)
INFO - root - 2022-02-24 20:40:22.904333: step 125610, total loss = 0.59, batch loss = 0.33 (250.5 examples/sec; 0.032 sec/batch; 0h:39m:19s remains)
INFO - root - 2022-02-24 20:40:23.258803: step 125620, total loss = 0.57, batch loss = 0.31 (285.1 examples/sec; 0.028 sec/batch; 0h:34m:33s remains)
INFO - root - 2022-02-24 20:40:23.666583: step 125630, total loss = 0.49, batch loss = 0.23 (124.1 examples/sec; 0.064 sec/batch; 1h:19m:23s remains)
INFO - root - 2022-02-24 20:40:24.082352: step 125640, total loss = 0.65, batch loss = 0.39 (230.8 examples/sec; 0.035 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:40:24.384774: step 125650, total loss = 0.52, batch loss = 0.26 (351.8 examples/sec; 0.023 sec/batch; 0h:27m:59s remains)
INFO - root - 2022-02-24 20:40:24.704666: step 125660, total loss = 0.52, batch loss = 0.26 (194.7 examples/sec; 0.041 sec/batch; 0h:50m:33s remains)
INFO - root - 2022-02-24 20:40:25.026689: step 125670, total loss = 0.52, batch loss = 0.26 (308.2 examples/sec; 0.026 sec/batch; 0h:31m:56s remains)
INFO - root - 2022-02-24 20:40:25.427370: step 125680, total loss = 0.58, batch loss = 0.32 (308.5 examples/sec; 0.026 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 20:40:25.839944: step 125690, total loss = 0.52, batch loss = 0.26 (348.3 examples/sec; 0.023 sec/batch; 0h:28m:15s remains)
INFO - root - 2022-02-24 20:40:26.286187: step 125700, total loss = 0.49, batch loss = 0.23 (149.9 examples/sec; 0.053 sec/batch; 1h:05m:38s remains)
INFO - root - 2022-02-24 20:40:26.741423: step 125710, total loss = 0.70, batch loss = 0.44 (300.3 examples/sec; 0.027 sec/batch; 0h:32m:46s remains)
INFO - root - 2022-02-24 20:40:27.070752: step 125720, total loss = 0.66, batch loss = 0.40 (314.0 examples/sec; 0.025 sec/batch; 0h:31m:19s remains)
INFO - root - 2022-02-24 20:40:27.554820: step 125730, total loss = 0.67, batch loss = 0.41 (310.9 examples/sec; 0.026 sec/batch; 0h:31m:38s remains)
INFO - root - 2022-02-24 20:40:28.257803: step 125740, total loss = 0.54, batch loss = 0.28 (272.3 examples/sec; 0.029 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:40:28.759562: step 125750, total loss = 0.57, batch loss = 0.31 (335.0 examples/sec; 0.024 sec/batch; 0h:29m:21s remains)
INFO - root - 2022-02-24 20:40:29.175785: step 125760, total loss = 0.54, batch loss = 0.28 (257.0 examples/sec; 0.031 sec/batch; 0h:38m:15s remains)
INFO - root - 2022-02-24 20:40:29.620565: step 125770, total loss = 0.57, batch loss = 0.31 (305.3 examples/sec; 0.026 sec/batch; 0h:32m:12s remains)
INFO - root - 2022-02-24 20:40:30.086473: step 125780, total loss = 0.58, batch loss = 0.32 (95.9 examples/sec; 0.083 sec/batch; 1h:42m:29s remains)
INFO - root - 2022-02-24 20:40:30.989659: step 125790, total loss = 0.56, batch loss = 0.30 (299.3 examples/sec; 0.027 sec/batch; 0h:32m:50s remains)
INFO - root - 2022-02-24 20:40:31.298355: step 125800, total loss = 0.59, batch loss = 0.33 (314.2 examples/sec; 0.025 sec/batch; 0h:31m:16s remains)
INFO - root - 2022-02-24 20:40:31.701966: step 125810, total loss = 0.61, batch loss = 0.35 (221.3 examples/sec; 0.036 sec/batch; 0h:44m:24s remains)
INFO - root - 2022-02-24 20:40:32.097817: step 125820, total loss = 0.49, batch loss = 0.23 (131.6 examples/sec; 0.061 sec/batch; 1h:14m:40s remains)
INFO - root - 2022-02-24 20:40:32.375650: step 125830, total loss = 0.54, batch loss = 0.28 (351.0 examples/sec; 0.023 sec/batch; 0h:27m:59s remains)
INFO - root - 2022-02-24 20:40:32.686019: step 125840, total loss = 0.51, batch loss = 0.25 (340.4 examples/sec; 0.024 sec/batch; 0h:28m:51s remains)
INFO - root - 2022-02-24 20:40:33.151521: step 125850, total loss = 0.49, batch loss = 0.23 (333.4 examples/sec; 0.024 sec/batch; 0h:29m:27s remains)
INFO - root - 2022-02-24 20:40:33.869448: step 125860, total loss = 0.49, batch loss = 0.23 (61.7 examples/sec; 0.130 sec/batch; 2h:39m:00s remains)
INFO - root - 2022-02-24 20:40:34.299026: step 125870, total loss = 0.54, batch loss = 0.28 (127.8 examples/sec; 0.063 sec/batch; 1h:16m:49s remains)
INFO - root - 2022-02-24 20:40:34.848361: step 125880, total loss = 0.62, batch loss = 0.36 (129.4 examples/sec; 0.062 sec/batch; 1h:15m:53s remains)
INFO - root - 2022-02-24 20:40:35.310039: step 125890, total loss = 0.57, batch loss = 0.31 (176.2 examples/sec; 0.045 sec/batch; 0h:55m:42s remains)
INFO - root - 2022-02-24 20:40:35.820109: step 125900, total loss = 0.58, batch loss = 0.32 (279.9 examples/sec; 0.029 sec/batch; 0h:35m:03s remains)
INFO - root - 2022-02-24 20:40:36.467673: step 125910, total loss = 0.55, batch loss = 0.29 (215.3 examples/sec; 0.037 sec/batch; 0h:45m:34s remains)
INFO - root - 2022-02-24 20:40:37.462439: step 125920, total loss = 0.67, batch loss = 0.41 (191.6 examples/sec; 0.042 sec/batch; 0h:51m:12s remains)
INFO - root - 2022-02-24 20:40:37.887232: step 125930, total loss = 0.62, batch loss = 0.36 (171.7 examples/sec; 0.047 sec/batch; 0h:57m:08s remains)
INFO - root - 2022-02-24 20:40:38.587741: step 125940, total loss = 0.49, batch loss = 0.23 (164.6 examples/sec; 0.049 sec/batch; 0h:59m:34s remains)
INFO - root - 2022-02-24 20:40:39.118014: step 125950, total loss = 0.65, batch loss = 0.39 (302.7 examples/sec; 0.026 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 20:40:39.604560: step 125960, total loss = 0.49, batch loss = 0.23 (347.5 examples/sec; 0.023 sec/batch; 0h:28m:12s remains)
INFO - root - 2022-02-24 20:40:40.174058: step 125970, total loss = 0.69, batch loss = 0.43 (335.4 examples/sec; 0.024 sec/batch; 0h:29m:13s remains)
INFO - root - 2022-02-24 20:40:40.794224: step 125980, total loss = 0.64, batch loss = 0.38 (165.7 examples/sec; 0.048 sec/batch; 0h:59m:09s remains)
INFO - root - 2022-02-24 20:40:41.388066: step 125990, total loss = 0.58, batch loss = 0.32 (111.4 examples/sec; 0.072 sec/batch; 1h:27m:57s remains)
INFO - root - 2022-02-24 20:40:42.222096: step 126000, total loss = 0.54, batch loss = 0.28 (172.2 examples/sec; 0.046 sec/batch; 0h:56m:55s remains)
INFO - root - 2022-02-24 20:40:42.763720: step 126010, total loss = 0.50, batch loss = 0.24 (167.4 examples/sec; 0.048 sec/batch; 0h:58m:31s remains)
INFO - root - 2022-02-24 20:40:43.157862: step 126020, total loss = 0.59, batch loss = 0.33 (124.2 examples/sec; 0.064 sec/batch; 1h:18m:51s remains)
INFO - root - 2022-02-24 20:40:43.494746: step 126030, total loss = 0.53, batch loss = 0.27 (255.8 examples/sec; 0.031 sec/batch; 0h:38m:18s remains)
INFO - root - 2022-02-24 20:40:43.860912: step 126040, total loss = 0.67, batch loss = 0.41 (326.8 examples/sec; 0.024 sec/batch; 0h:29m:58s remains)
INFO - root - 2022-02-24 20:40:44.208093: step 126050, total loss = 0.53, batch loss = 0.27 (312.5 examples/sec; 0.026 sec/batch; 0h:31m:20s remains)
INFO - root - 2022-02-24 20:40:44.500113: step 126060, total loss = 0.51, batch loss = 0.25 (300.1 examples/sec; 0.027 sec/batch; 0h:32m:37s remains)
INFO - root - 2022-02-24 20:40:44.845907: step 126070, total loss = 0.49, batch loss = 0.23 (186.3 examples/sec; 0.043 sec/batch; 0h:52m:33s remains)
INFO - root - 2022-02-24 20:40:45.269237: step 126080, total loss = 0.53, batch loss = 0.27 (143.5 examples/sec; 0.056 sec/batch; 1h:08m:14s remains)
INFO - root - 2022-02-24 20:40:45.624913: step 126090, total loss = 0.56, batch loss = 0.30 (321.0 examples/sec; 0.025 sec/batch; 0h:30m:29s remains)
INFO - root - 2022-02-24 20:40:45.951666: step 126100, total loss = 0.60, batch loss = 0.34 (326.4 examples/sec; 0.025 sec/batch; 0h:29m:59s remains)
INFO - root - 2022-02-24 20:40:46.329612: step 126110, total loss = 0.47, batch loss = 0.21 (324.2 examples/sec; 0.025 sec/batch; 0h:30m:11s remains)
INFO - root - 2022-02-24 20:40:46.693664: step 126120, total loss = 0.52, batch loss = 0.26 (203.2 examples/sec; 0.039 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:40:47.218669: step 126130, total loss = 0.54, batch loss = 0.28 (95.9 examples/sec; 0.083 sec/batch; 1h:41m:57s remains)
INFO - root - 2022-02-24 20:40:47.629884: step 126140, total loss = 0.50, batch loss = 0.24 (116.9 examples/sec; 0.068 sec/batch; 1h:23m:39s remains)
INFO - root - 2022-02-24 20:40:47.918491: step 126150, total loss = 0.53, batch loss = 0.27 (319.8 examples/sec; 0.025 sec/batch; 0h:30m:35s remains)
INFO - root - 2022-02-24 20:40:48.236237: step 126160, total loss = 0.53, batch loss = 0.27 (292.7 examples/sec; 0.027 sec/batch; 0h:33m:24s remains)
INFO - root - 2022-02-24 20:40:48.580214: step 126170, total loss = 0.52, batch loss = 0.26 (174.2 examples/sec; 0.046 sec/batch; 0h:56m:08s remains)
INFO - root - 2022-02-24 20:40:49.021239: step 126180, total loss = 0.58, batch loss = 0.32 (242.7 examples/sec; 0.033 sec/batch; 0h:40m:17s remains)
INFO - root - 2022-02-24 20:40:49.514726: step 126190, total loss = 0.54, batch loss = 0.28 (202.9 examples/sec; 0.039 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:40:49.905173: step 126200, total loss = 0.52, batch loss = 0.26 (202.4 examples/sec; 0.040 sec/batch; 0h:48m:17s remains)
INFO - root - 2022-02-24 20:40:50.369123: step 126210, total loss = 0.54, batch loss = 0.28 (199.5 examples/sec; 0.040 sec/batch; 0h:48m:58s remains)
INFO - root - 2022-02-24 20:40:50.888853: step 126220, total loss = 0.55, batch loss = 0.29 (160.5 examples/sec; 0.050 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 20:40:51.449337: step 126230, total loss = 0.60, batch loss = 0.34 (170.2 examples/sec; 0.047 sec/batch; 0h:57m:23s remains)
INFO - root - 2022-02-24 20:40:51.796899: step 126240, total loss = 0.49, batch loss = 0.23 (215.6 examples/sec; 0.037 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 20:40:52.311536: step 126250, total loss = 0.45, batch loss = 0.19 (156.3 examples/sec; 0.051 sec/batch; 1h:02m:30s remains)
INFO - root - 2022-02-24 20:40:52.894510: step 126260, total loss = 0.63, batch loss = 0.37 (60.7 examples/sec; 0.132 sec/batch; 2h:41m:00s remains)
INFO - root - 2022-02-24 20:40:53.278145: step 126270, total loss = 0.56, batch loss = 0.30 (147.4 examples/sec; 0.054 sec/batch; 1h:06m:14s remains)
INFO - root - 2022-02-24 20:40:53.615569: step 126280, total loss = 0.63, batch loss = 0.37 (303.5 examples/sec; 0.026 sec/batch; 0h:32m:10s remains)
INFO - root - 2022-02-24 20:40:53.939333: step 126290, total loss = 0.56, batch loss = 0.30 (218.2 examples/sec; 0.037 sec/batch; 0h:44m:44s remains)
INFO - root - 2022-02-24 20:40:54.225418: step 126300, total loss = 0.60, batch loss = 0.34 (212.8 examples/sec; 0.038 sec/batch; 0h:45m:51s remains)
INFO - root - 2022-02-24 20:40:54.644899: step 126310, total loss = 0.51, batch loss = 0.25 (360.2 examples/sec; 0.022 sec/batch; 0h:27m:05s remains)
INFO - root - 2022-02-24 20:40:55.082408: step 126320, total loss = 0.58, batch loss = 0.32 (313.4 examples/sec; 0.026 sec/batch; 0h:31m:07s remains)
INFO - root - 2022-02-24 20:40:55.407462: step 126330, total loss = 0.50, batch loss = 0.24 (274.2 examples/sec; 0.029 sec/batch; 0h:35m:34s remains)
INFO - root - 2022-02-24 20:40:55.751116: step 126340, total loss = 0.54, batch loss = 0.28 (124.7 examples/sec; 0.064 sec/batch; 1h:18m:12s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-126349 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-126349 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:40:56.475319: step 126350, total loss = 0.62, batch loss = 0.36 (336.9 examples/sec; 0.024 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 20:40:56.712073: step 126360, total loss = 0.56, batch loss = 0.30 (322.3 examples/sec; 0.025 sec/batch; 0h:30m:15s remains)
INFO - root - 2022-02-24 20:40:56.956680: step 126370, total loss = 0.54, batch loss = 0.28 (372.0 examples/sec; 0.022 sec/batch; 0h:26m:12s remains)
INFO - root - 2022-02-24 20:40:57.246063: step 126380, total loss = 0.51, batch loss = 0.25 (225.8 examples/sec; 0.035 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:40:57.514298: step 126390, total loss = 0.48, batch loss = 0.22 (345.7 examples/sec; 0.023 sec/batch; 0h:28m:11s remains)
INFO - root - 2022-02-24 20:40:57.899896: step 126400, total loss = 0.52, batch loss = 0.26 (193.5 examples/sec; 0.041 sec/batch; 0h:50m:22s remains)
INFO - root - 2022-02-24 20:40:58.366826: step 126410, total loss = 0.58, batch loss = 0.32 (255.9 examples/sec; 0.031 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:40:58.809641: step 126420, total loss = 0.49, batch loss = 0.23 (106.7 examples/sec; 0.075 sec/batch; 1h:31m:19s remains)
INFO - root - 2022-02-24 20:40:59.113477: step 126430, total loss = 0.50, batch loss = 0.24 (335.6 examples/sec; 0.024 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 20:40:59.447849: step 126440, total loss = 0.59, batch loss = 0.33 (180.2 examples/sec; 0.044 sec/batch; 0h:54m:03s remains)
INFO - root - 2022-02-24 20:40:59.814958: step 126450, total loss = 0.56, batch loss = 0.30 (306.1 examples/sec; 0.026 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 20:41:00.273029: step 126460, total loss = 0.57, batch loss = 0.31 (104.2 examples/sec; 0.077 sec/batch; 1h:33m:30s remains)
INFO - root - 2022-02-24 20:41:00.693241: step 126470, total loss = 0.52, batch loss = 0.26 (122.8 examples/sec; 0.065 sec/batch; 1h:19m:19s remains)
INFO - root - 2022-02-24 20:41:01.034351: step 126480, total loss = 0.65, batch loss = 0.39 (251.0 examples/sec; 0.032 sec/batch; 0h:38m:46s remains)
INFO - root - 2022-02-24 20:41:01.282924: step 126490, total loss = 0.58, batch loss = 0.32 (335.8 examples/sec; 0.024 sec/batch; 0h:28m:59s remains)
INFO - root - 2022-02-24 20:41:01.661333: step 126500, total loss = 0.54, batch loss = 0.28 (338.3 examples/sec; 0.024 sec/batch; 0h:28m:46s remains)
INFO - root - 2022-02-24 20:41:02.095018: step 126510, total loss = 0.66, batch loss = 0.40 (161.9 examples/sec; 0.049 sec/batch; 1h:00m:07s remains)
INFO - root - 2022-02-24 20:41:02.553979: step 126520, total loss = 0.54, batch loss = 0.28 (151.0 examples/sec; 0.053 sec/batch; 1h:04m:26s remains)
INFO - root - 2022-02-24 20:41:02.910782: step 126530, total loss = 0.57, batch loss = 0.31 (354.9 examples/sec; 0.023 sec/batch; 0h:27m:24s remains)
INFO - root - 2022-02-24 20:41:03.253935: step 126540, total loss = 0.59, batch loss = 0.33 (320.4 examples/sec; 0.025 sec/batch; 0h:30m:21s remains)
INFO - root - 2022-02-24 20:41:03.548246: step 126550, total loss = 0.47, batch loss = 0.21 (245.3 examples/sec; 0.033 sec/batch; 0h:39m:39s remains)
INFO - root - 2022-02-24 20:41:03.880083: step 126560, total loss = 0.63, batch loss = 0.37 (316.9 examples/sec; 0.025 sec/batch; 0h:30m:41s remains)
INFO - root - 2022-02-24 20:41:04.272808: step 126570, total loss = 0.51, batch loss = 0.25 (228.1 examples/sec; 0.035 sec/batch; 0h:42m:37s remains)
INFO - root - 2022-02-24 20:41:04.723345: step 126580, total loss = 0.58, batch loss = 0.32 (85.4 examples/sec; 0.094 sec/batch; 1h:53m:48s remains)
INFO - root - 2022-02-24 20:41:05.149622: step 126590, total loss = 0.59, batch loss = 0.33 (352.4 examples/sec; 0.023 sec/batch; 0h:27m:34s remains)
INFO - root - 2022-02-24 20:41:05.577821: step 126600, total loss = 0.57, batch loss = 0.31 (112.1 examples/sec; 0.071 sec/batch; 1h:26m:41s remains)
INFO - root - 2022-02-24 20:41:06.040250: step 126610, total loss = 0.57, batch loss = 0.31 (123.0 examples/sec; 0.065 sec/batch; 1h:19m:00s remains)
INFO - root - 2022-02-24 20:41:06.507324: step 126620, total loss = 0.58, batch loss = 0.32 (321.5 examples/sec; 0.025 sec/batch; 0h:30m:13s remains)
INFO - root - 2022-02-24 20:41:06.891090: step 126630, total loss = 0.54, batch loss = 0.28 (166.3 examples/sec; 0.048 sec/batch; 0h:58m:25s remains)
INFO - root - 2022-02-24 20:41:07.275220: step 126640, total loss = 0.53, batch loss = 0.27 (165.5 examples/sec; 0.048 sec/batch; 0h:58m:42s remains)
INFO - root - 2022-02-24 20:41:07.958252: step 126650, total loss = 0.54, batch loss = 0.28 (128.2 examples/sec; 0.062 sec/batch; 1h:15m:44s remains)
INFO - root - 2022-02-24 20:41:08.366719: step 126660, total loss = 0.55, batch loss = 0.29 (86.5 examples/sec; 0.093 sec/batch; 1h:52m:18s remains)
INFO - root - 2022-02-24 20:41:08.791028: step 126670, total loss = 0.67, batch loss = 0.41 (243.5 examples/sec; 0.033 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 20:41:09.228994: step 126680, total loss = 0.54, batch loss = 0.28 (130.1 examples/sec; 0.062 sec/batch; 1h:14m:38s remains)
INFO - root - 2022-02-24 20:41:09.686613: step 126690, total loss = 0.48, batch loss = 0.22 (178.9 examples/sec; 0.045 sec/batch; 0h:54m:15s remains)
INFO - root - 2022-02-24 20:41:10.206209: step 126700, total loss = 0.58, batch loss = 0.32 (243.9 examples/sec; 0.033 sec/batch; 0h:39m:47s remains)
INFO - root - 2022-02-24 20:41:10.645685: step 126710, total loss = 0.48, batch loss = 0.22 (201.8 examples/sec; 0.040 sec/batch; 0h:48m:05s remains)
INFO - root - 2022-02-24 20:41:11.034604: step 126720, total loss = 0.50, batch loss = 0.24 (230.3 examples/sec; 0.035 sec/batch; 0h:42m:07s remains)
INFO - root - 2022-02-24 20:41:11.563959: step 126730, total loss = 0.55, batch loss = 0.29 (336.5 examples/sec; 0.024 sec/batch; 0h:28m:50s remains)
INFO - root - 2022-02-24 20:41:11.978792: step 126740, total loss = 0.54, batch loss = 0.28 (268.5 examples/sec; 0.030 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:41:12.815015: step 126750, total loss = 0.64, batch loss = 0.38 (175.1 examples/sec; 0.046 sec/batch; 0h:55m:24s remains)
INFO - root - 2022-02-24 20:41:13.220287: step 126760, total loss = 0.70, batch loss = 0.44 (133.6 examples/sec; 0.060 sec/batch; 1h:12m:35s remains)
INFO - root - 2022-02-24 20:41:13.521092: step 126770, total loss = 0.65, batch loss = 0.39 (229.8 examples/sec; 0.035 sec/batch; 0h:42m:12s remains)
INFO - root - 2022-02-24 20:41:13.852006: step 126780, total loss = 0.52, batch loss = 0.26 (159.9 examples/sec; 0.050 sec/batch; 1h:00m:38s remains)
INFO - root - 2022-02-24 20:41:14.166793: step 126790, total loss = 0.60, batch loss = 0.34 (324.0 examples/sec; 0.025 sec/batch; 0h:29m:55s remains)
INFO - root - 2022-02-24 20:41:14.575543: step 126800, total loss = 0.57, batch loss = 0.31 (324.7 examples/sec; 0.025 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 20:41:15.128574: step 126810, total loss = 0.52, batch loss = 0.26 (175.2 examples/sec; 0.046 sec/batch; 0h:55m:19s remains)
INFO - root - 2022-02-24 20:41:15.536649: step 126820, total loss = 0.63, batch loss = 0.37 (256.3 examples/sec; 0.031 sec/batch; 0h:37m:49s remains)
INFO - root - 2022-02-24 20:41:15.935093: step 126830, total loss = 0.49, batch loss = 0.23 (316.5 examples/sec; 0.025 sec/batch; 0h:30m:36s remains)
INFO - root - 2022-02-24 20:41:16.555484: step 126840, total loss = 0.54, batch loss = 0.28 (333.3 examples/sec; 0.024 sec/batch; 0h:29m:04s remains)
INFO - root - 2022-02-24 20:41:16.882501: step 126850, total loss = 0.60, batch loss = 0.34 (344.5 examples/sec; 0.023 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 20:41:17.307173: step 126860, total loss = 0.60, batch loss = 0.34 (327.8 examples/sec; 0.024 sec/batch; 0h:29m:33s remains)
INFO - root - 2022-02-24 20:41:17.586912: step 126870, total loss = 0.52, batch loss = 0.26 (328.5 examples/sec; 0.024 sec/batch; 0h:29m:28s remains)
INFO - root - 2022-02-24 20:41:17.960532: step 126880, total loss = 0.60, batch loss = 0.34 (263.8 examples/sec; 0.030 sec/batch; 0h:36m:42s remains)
INFO - root - 2022-02-24 20:41:18.348847: step 126890, total loss = 0.57, batch loss = 0.31 (326.8 examples/sec; 0.024 sec/batch; 0h:29m:37s remains)
INFO - root - 2022-02-24 20:41:18.695120: step 126900, total loss = 0.53, batch loss = 0.27 (265.4 examples/sec; 0.030 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:41:19.264796: step 126910, total loss = 0.54, batch loss = 0.28 (257.0 examples/sec; 0.031 sec/batch; 0h:37m:39s remains)
INFO - root - 2022-02-24 20:41:19.653851: step 126920, total loss = 0.53, batch loss = 0.27 (333.7 examples/sec; 0.024 sec/batch; 0h:28m:59s remains)
INFO - root - 2022-02-24 20:41:19.943658: step 126930, total loss = 0.77, batch loss = 0.51 (306.2 examples/sec; 0.026 sec/batch; 0h:31m:35s remains)
INFO - root - 2022-02-24 20:41:20.307685: step 126940, total loss = 0.49, batch loss = 0.23 (160.2 examples/sec; 0.050 sec/batch; 1h:00m:23s remains)
INFO - root - 2022-02-24 20:41:20.660744: step 126950, total loss = 0.47, batch loss = 0.21 (265.0 examples/sec; 0.030 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:41:21.125507: step 126960, total loss = 0.56, batch loss = 0.30 (117.4 examples/sec; 0.068 sec/batch; 1h:22m:24s remains)
INFO - root - 2022-02-24 20:41:21.496485: step 126970, total loss = 0.48, batch loss = 0.22 (205.3 examples/sec; 0.039 sec/batch; 0h:47m:06s remains)
INFO - root - 2022-02-24 20:41:21.835910: step 126980, total loss = 0.61, batch loss = 0.35 (340.1 examples/sec; 0.024 sec/batch; 0h:28m:25s remains)
INFO - root - 2022-02-24 20:41:22.080655: step 126990, total loss = 0.51, batch loss = 0.25 (349.9 examples/sec; 0.023 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 20:41:22.422502: step 127000, total loss = 0.51, batch loss = 0.25 (175.3 examples/sec; 0.046 sec/batch; 0h:55m:08s remains)
INFO - root - 2022-02-24 20:41:22.932141: step 127010, total loss = 0.54, batch loss = 0.28 (211.0 examples/sec; 0.038 sec/batch; 0h:45m:48s remains)
INFO - root - 2022-02-24 20:41:23.312182: step 127020, total loss = 0.49, batch loss = 0.23 (198.6 examples/sec; 0.040 sec/batch; 0h:48m:40s remains)
INFO - root - 2022-02-24 20:41:23.657797: step 127030, total loss = 0.51, batch loss = 0.25 (333.2 examples/sec; 0.024 sec/batch; 0h:28m:59s remains)
INFO - root - 2022-02-24 20:41:23.971622: step 127040, total loss = 0.64, batch loss = 0.38 (169.4 examples/sec; 0.047 sec/batch; 0h:57m:01s remains)
INFO - root - 2022-02-24 20:41:24.342709: step 127050, total loss = 0.61, batch loss = 0.35 (95.9 examples/sec; 0.083 sec/batch; 1h:40m:40s remains)
INFO - root - 2022-02-24 20:41:24.766885: step 127060, total loss = 0.48, batch loss = 0.22 (92.1 examples/sec; 0.087 sec/batch; 1h:44m:54s remains)
INFO - root - 2022-02-24 20:41:25.353385: step 127070, total loss = 0.56, batch loss = 0.30 (85.3 examples/sec; 0.094 sec/batch; 1h:53m:15s remains)
INFO - root - 2022-02-24 20:41:25.793694: step 127080, total loss = 0.54, batch loss = 0.28 (151.6 examples/sec; 0.053 sec/batch; 1h:03m:41s remains)
INFO - root - 2022-02-24 20:41:26.239467: step 127090, total loss = 0.49, batch loss = 0.23 (164.1 examples/sec; 0.049 sec/batch; 0h:58m:49s remains)
INFO - root - 2022-02-24 20:41:27.265266: step 127100, total loss = 0.51, batch loss = 0.25 (153.0 examples/sec; 0.052 sec/batch; 1h:03m:05s remains)
INFO - root - 2022-02-24 20:41:27.698526: step 127110, total loss = 0.55, batch loss = 0.29 (171.1 examples/sec; 0.047 sec/batch; 0h:56m:24s remains)
INFO - root - 2022-02-24 20:41:28.091094: step 127120, total loss = 0.52, batch loss = 0.26 (268.6 examples/sec; 0.030 sec/batch; 0h:35m:55s remains)
INFO - root - 2022-02-24 20:41:28.410973: step 127130, total loss = 0.51, batch loss = 0.25 (349.3 examples/sec; 0.023 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 20:41:28.718812: step 127140, total loss = 0.56, batch loss = 0.30 (307.3 examples/sec; 0.026 sec/batch; 0h:31m:23s remains)
INFO - root - 2022-02-24 20:41:29.066562: step 127150, total loss = 0.46, batch loss = 0.20 (229.1 examples/sec; 0.035 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:41:29.410889: step 127160, total loss = 0.54, batch loss = 0.28 (358.2 examples/sec; 0.022 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 20:41:29.823659: step 127170, total loss = 0.57, batch loss = 0.31 (208.0 examples/sec; 0.038 sec/batch; 0h:46m:21s remains)
INFO - root - 2022-02-24 20:41:30.249188: step 127180, total loss = 0.54, batch loss = 0.28 (339.5 examples/sec; 0.024 sec/batch; 0h:28m:24s remains)
INFO - root - 2022-02-24 20:41:30.564527: step 127190, total loss = 0.47, batch loss = 0.21 (351.0 examples/sec; 0.023 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:41:31.006485: step 127200, total loss = 0.49, batch loss = 0.23 (343.1 examples/sec; 0.023 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:41:31.458693: step 127210, total loss = 0.54, batch loss = 0.28 (151.0 examples/sec; 0.053 sec/batch; 1h:03m:50s remains)
INFO - root - 2022-02-24 20:41:31.885871: step 127220, total loss = 0.57, batch loss = 0.31 (146.4 examples/sec; 0.055 sec/batch; 1h:05m:49s remains)
INFO - root - 2022-02-24 20:41:32.400127: step 127230, total loss = 0.57, batch loss = 0.31 (201.9 examples/sec; 0.040 sec/batch; 0h:47m:44s remains)
INFO - root - 2022-02-24 20:41:32.795629: step 127240, total loss = 0.51, batch loss = 0.25 (345.2 examples/sec; 0.023 sec/batch; 0h:27m:54s remains)
INFO - root - 2022-02-24 20:41:33.113676: step 127250, total loss = 0.54, batch loss = 0.28 (338.7 examples/sec; 0.024 sec/batch; 0h:28m:26s remains)
INFO - root - 2022-02-24 20:41:33.440435: step 127260, total loss = 0.60, batch loss = 0.34 (355.1 examples/sec; 0.023 sec/batch; 0h:27m:07s remains)
INFO - root - 2022-02-24 20:41:33.797184: step 127270, total loss = 0.53, batch loss = 0.27 (306.1 examples/sec; 0.026 sec/batch; 0h:31m:27s remains)
INFO - root - 2022-02-24 20:41:34.226115: step 127280, total loss = 0.75, batch loss = 0.49 (189.3 examples/sec; 0.042 sec/batch; 0h:50m:52s remains)
INFO - root - 2022-02-24 20:41:34.621210: step 127290, total loss = 0.53, batch loss = 0.27 (263.9 examples/sec; 0.030 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:41:34.910016: step 127300, total loss = 0.48, batch loss = 0.22 (351.8 examples/sec; 0.023 sec/batch; 0h:27m:21s remains)
INFO - root - 2022-02-24 20:41:35.320337: step 127310, total loss = 0.50, batch loss = 0.24 (266.2 examples/sec; 0.030 sec/batch; 0h:36m:09s remains)
INFO - root - 2022-02-24 20:41:35.718393: step 127320, total loss = 0.49, batch loss = 0.23 (369.6 examples/sec; 0.022 sec/batch; 0h:26m:02s remains)
INFO - root - 2022-02-24 20:41:36.193411: step 127330, total loss = 0.55, batch loss = 0.29 (188.3 examples/sec; 0.042 sec/batch; 0h:51m:05s remains)
INFO - root - 2022-02-24 20:41:36.577094: step 127340, total loss = 0.47, batch loss = 0.21 (243.9 examples/sec; 0.033 sec/batch; 0h:39m:26s remains)
INFO - root - 2022-02-24 20:41:36.924728: step 127350, total loss = 0.51, batch loss = 0.25 (273.7 examples/sec; 0.029 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:41:37.289502: step 127360, total loss = 0.53, batch loss = 0.27 (338.4 examples/sec; 0.024 sec/batch; 0h:28m:25s remains)
INFO - root - 2022-02-24 20:41:37.530805: step 127370, total loss = 0.59, batch loss = 0.33 (357.0 examples/sec; 0.022 sec/batch; 0h:26m:56s remains)
INFO - root - 2022-02-24 20:41:37.897634: step 127380, total loss = 0.52, batch loss = 0.26 (351.8 examples/sec; 0.023 sec/batch; 0h:27m:20s remains)
INFO - root - 2022-02-24 20:41:38.314412: step 127390, total loss = 0.57, batch loss = 0.31 (175.0 examples/sec; 0.046 sec/batch; 0h:54m:56s remains)
INFO - root - 2022-02-24 20:41:38.671475: step 127400, total loss = 0.53, batch loss = 0.27 (285.9 examples/sec; 0.028 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:41:39.062461: step 127410, total loss = 0.59, batch loss = 0.33 (353.3 examples/sec; 0.023 sec/batch; 0h:27m:12s remains)
INFO - root - 2022-02-24 20:41:39.356596: step 127420, total loss = 0.50, batch loss = 0.24 (216.8 examples/sec; 0.037 sec/batch; 0h:44m:19s remains)
INFO - root - 2022-02-24 20:41:39.827239: step 127430, total loss = 0.62, batch loss = 0.36 (211.6 examples/sec; 0.038 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:41:40.245563: step 127440, total loss = 0.55, batch loss = 0.29 (340.8 examples/sec; 0.023 sec/batch; 0h:28m:11s remains)
INFO - root - 2022-02-24 20:41:40.488486: step 127450, total loss = 0.49, batch loss = 0.23 (310.6 examples/sec; 0.026 sec/batch; 0h:30m:55s remains)
INFO - root - 2022-02-24 20:41:40.818631: step 127460, total loss = 0.54, batch loss = 0.28 (110.0 examples/sec; 0.073 sec/batch; 1h:27m:20s remains)
INFO - root - 2022-02-24 20:41:41.150939: step 127470, total loss = 0.63, batch loss = 0.37 (246.8 examples/sec; 0.032 sec/batch; 0h:38m:54s remains)
INFO - root - 2022-02-24 20:41:41.535695: step 127480, total loss = 0.52, batch loss = 0.26 (366.8 examples/sec; 0.022 sec/batch; 0h:26m:10s remains)
INFO - root - 2022-02-24 20:41:41.952595: step 127490, total loss = 0.57, batch loss = 0.31 (277.4 examples/sec; 0.029 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:41:42.435276: step 127500, total loss = 0.56, batch loss = 0.30 (199.0 examples/sec; 0.040 sec/batch; 0h:48m:14s remains)
INFO - root - 2022-02-24 20:41:42.905420: step 127510, total loss = 0.50, batch loss = 0.24 (341.5 examples/sec; 0.023 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 20:41:43.190402: step 127520, total loss = 0.58, batch loss = 0.32 (313.0 examples/sec; 0.026 sec/batch; 0h:30m:39s remains)
INFO - root - 2022-02-24 20:41:43.449743: step 127530, total loss = 0.65, batch loss = 0.39 (283.5 examples/sec; 0.028 sec/batch; 0h:33m:51s remains)
INFO - root - 2022-02-24 20:41:43.753214: step 127540, total loss = 0.52, batch loss = 0.26 (295.0 examples/sec; 0.027 sec/batch; 0h:32m:31s remains)
INFO - root - 2022-02-24 20:41:44.130518: step 127550, total loss = 0.55, batch loss = 0.29 (137.7 examples/sec; 0.058 sec/batch; 1h:09m:39s remains)
INFO - root - 2022-02-24 20:41:44.492563: step 127560, total loss = 0.50, batch loss = 0.24 (272.1 examples/sec; 0.029 sec/batch; 0h:35m:15s remains)
INFO - root - 2022-02-24 20:41:44.842105: step 127570, total loss = 0.56, batch loss = 0.30 (268.4 examples/sec; 0.030 sec/batch; 0h:35m:44s remains)
INFO - root - 2022-02-24 20:41:45.180199: step 127580, total loss = 0.50, batch loss = 0.24 (348.7 examples/sec; 0.023 sec/batch; 0h:27m:29s remains)
INFO - root - 2022-02-24 20:41:45.451114: step 127590, total loss = 0.58, batch loss = 0.32 (323.2 examples/sec; 0.025 sec/batch; 0h:29m:40s remains)
INFO - root - 2022-02-24 20:41:45.801190: step 127600, total loss = 0.61, batch loss = 0.35 (267.2 examples/sec; 0.030 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 20:41:46.366522: step 127610, total loss = 0.54, batch loss = 0.28 (109.1 examples/sec; 0.073 sec/batch; 1h:27m:49s remains)
INFO - root - 2022-02-24 20:41:46.794319: step 127620, total loss = 0.48, batch loss = 0.22 (206.1 examples/sec; 0.039 sec/batch; 0h:46m:29s remains)
INFO - root - 2022-02-24 20:41:47.082207: step 127630, total loss = 0.62, batch loss = 0.36 (226.2 examples/sec; 0.035 sec/batch; 0h:42m:21s remains)
INFO - root - 2022-02-24 20:41:47.337285: step 127640, total loss = 0.53, batch loss = 0.27 (354.8 examples/sec; 0.023 sec/batch; 0h:27m:00s remains)
INFO - root - 2022-02-24 20:41:47.624401: step 127650, total loss = 0.58, batch loss = 0.32 (340.7 examples/sec; 0.023 sec/batch; 0h:28m:07s remains)
INFO - root - 2022-02-24 20:41:47.878858: step 127660, total loss = 0.55, batch loss = 0.29 (312.8 examples/sec; 0.026 sec/batch; 0h:30m:37s remains)
INFO - root - 2022-02-24 20:41:48.346245: step 127670, total loss = 0.49, batch loss = 0.23 (155.7 examples/sec; 0.051 sec/batch; 1h:01m:30s remains)
INFO - root - 2022-02-24 20:41:48.773518: step 127680, total loss = 0.58, batch loss = 0.32 (172.6 examples/sec; 0.046 sec/batch; 0h:55m:29s remains)
INFO - root - 2022-02-24 20:41:49.167830: step 127690, total loss = 0.56, batch loss = 0.30 (195.1 examples/sec; 0.041 sec/batch; 0h:49m:04s remains)
INFO - root - 2022-02-24 20:41:49.502774: step 127700, total loss = 0.57, batch loss = 0.31 (345.5 examples/sec; 0.023 sec/batch; 0h:27m:42s remains)
INFO - root - 2022-02-24 20:41:49.908935: step 127710, total loss = 0.48, batch loss = 0.22 (270.2 examples/sec; 0.030 sec/batch; 0h:35m:25s remains)
INFO - root - 2022-02-24 20:41:50.218095: step 127720, total loss = 0.42, batch loss = 0.16 (337.2 examples/sec; 0.024 sec/batch; 0h:28m:22s remains)
INFO - root - 2022-02-24 20:41:50.616977: step 127730, total loss = 0.54, batch loss = 0.28 (177.1 examples/sec; 0.045 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 20:41:51.054292: step 127740, total loss = 0.46, batch loss = 0.20 (183.6 examples/sec; 0.044 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 20:41:51.475649: step 127750, total loss = 0.60, batch loss = 0.34 (167.9 examples/sec; 0.048 sec/batch; 0h:56m:59s remains)
INFO - root - 2022-02-24 20:41:52.060466: step 127760, total loss = 0.52, batch loss = 0.26 (190.7 examples/sec; 0.042 sec/batch; 0h:50m:09s remains)
INFO - root - 2022-02-24 20:41:52.940063: step 127770, total loss = 0.47, batch loss = 0.22 (307.8 examples/sec; 0.026 sec/batch; 0h:31m:04s remains)
INFO - root - 2022-02-24 20:41:53.374505: step 127780, total loss = 0.57, batch loss = 0.31 (208.9 examples/sec; 0.038 sec/batch; 0h:45m:46s remains)
INFO - root - 2022-02-24 20:41:53.818191: step 127790, total loss = 0.47, batch loss = 0.21 (118.4 examples/sec; 0.068 sec/batch; 1h:20m:45s remains)
INFO - root - 2022-02-24 20:41:54.224669: step 127800, total loss = 0.59, batch loss = 0.33 (271.9 examples/sec; 0.029 sec/batch; 0h:35m:09s remains)
INFO - root - 2022-02-24 20:41:54.678942: step 127810, total loss = 0.53, batch loss = 0.27 (286.8 examples/sec; 0.028 sec/batch; 0h:33m:19s remains)
INFO - root - 2022-02-24 20:41:55.165709: step 127820, total loss = 0.49, batch loss = 0.23 (190.5 examples/sec; 0.042 sec/batch; 0h:50m:09s remains)
INFO - root - 2022-02-24 20:41:55.572094: step 127830, total loss = 0.45, batch loss = 0.19 (197.1 examples/sec; 0.041 sec/batch; 0h:48m:28s remains)
INFO - root - 2022-02-24 20:41:55.962491: step 127840, total loss = 0.60, batch loss = 0.34 (235.1 examples/sec; 0.034 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:41:56.222539: step 127850, total loss = 0.52, batch loss = 0.26 (340.1 examples/sec; 0.024 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:41:56.578448: step 127860, total loss = 0.44, batch loss = 0.18 (272.5 examples/sec; 0.029 sec/batch; 0h:35m:03s remains)
INFO - root - 2022-02-24 20:41:56.959573: step 127870, total loss = 0.66, batch loss = 0.40 (388.0 examples/sec; 0.021 sec/batch; 0h:24m:36s remains)
INFO - root - 2022-02-24 20:41:57.726547: step 127880, total loss = 0.58, batch loss = 0.32 (243.1 examples/sec; 0.033 sec/batch; 0h:39m:16s remains)
INFO - root - 2022-02-24 20:41:58.099380: step 127890, total loss = 0.56, batch loss = 0.30 (179.3 examples/sec; 0.045 sec/batch; 0h:53m:15s remains)
INFO - root - 2022-02-24 20:41:58.438903: step 127900, total loss = 0.53, batch loss = 0.27 (178.9 examples/sec; 0.045 sec/batch; 0h:53m:22s remains)
INFO - root - 2022-02-24 20:41:59.030310: step 127910, total loss = 0.52, batch loss = 0.26 (115.7 examples/sec; 0.069 sec/batch; 1h:22m:30s remains)
INFO - root - 2022-02-24 20:41:59.432397: step 127920, total loss = 0.60, batch loss = 0.34 (126.3 examples/sec; 0.063 sec/batch; 1h:15m:32s remains)
INFO - root - 2022-02-24 20:41:59.965734: step 127930, total loss = 0.49, batch loss = 0.23 (173.9 examples/sec; 0.046 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 20:42:00.235441: step 127940, total loss = 0.52, batch loss = 0.26 (285.3 examples/sec; 0.028 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:42:00.518854: step 127950, total loss = 0.64, batch loss = 0.38 (352.2 examples/sec; 0.023 sec/batch; 0h:27m:05s remains)
INFO - root - 2022-02-24 20:42:00.872964: step 127960, total loss = 0.57, batch loss = 0.31 (184.8 examples/sec; 0.043 sec/batch; 0h:51m:37s remains)
INFO - root - 2022-02-24 20:42:01.130651: step 127970, total loss = 0.46, batch loss = 0.20 (338.6 examples/sec; 0.024 sec/batch; 0h:28m:10s remains)
INFO - root - 2022-02-24 20:42:01.416375: step 127980, total loss = 0.57, batch loss = 0.31 (178.6 examples/sec; 0.045 sec/batch; 0h:53m:23s remains)
INFO - root - 2022-02-24 20:42:01.835562: step 127990, total loss = 0.61, batch loss = 0.35 (261.6 examples/sec; 0.031 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:42:02.171654: step 128000, total loss = 0.54, batch loss = 0.28 (355.3 examples/sec; 0.023 sec/batch; 0h:26m:50s remains)
INFO - root - 2022-02-24 20:42:02.589230: step 128010, total loss = 0.54, batch loss = 0.28 (207.5 examples/sec; 0.039 sec/batch; 0h:45m:56s remains)
INFO - root - 2022-02-24 20:42:02.958744: step 128020, total loss = 0.52, batch loss = 0.26 (136.4 examples/sec; 0.059 sec/batch; 1h:09m:52s remains)
INFO - root - 2022-02-24 20:42:03.284162: step 128030, total loss = 0.62, batch loss = 0.36 (189.1 examples/sec; 0.042 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:42:03.670354: step 128040, total loss = 0.57, batch loss = 0.31 (232.2 examples/sec; 0.034 sec/batch; 0h:41m:02s remains)
INFO - root - 2022-02-24 20:42:04.132575: step 128050, total loss = 0.56, batch loss = 0.30 (173.1 examples/sec; 0.046 sec/batch; 0h:55m:01s remains)
INFO - root - 2022-02-24 20:42:04.478997: step 128060, total loss = 0.61, batch loss = 0.35 (262.3 examples/sec; 0.030 sec/batch; 0h:36m:18s remains)
INFO - root - 2022-02-24 20:42:04.765055: step 128070, total loss = 0.56, batch loss = 0.30 (274.3 examples/sec; 0.029 sec/batch; 0h:34m:43s remains)
INFO - root - 2022-02-24 20:42:05.093175: step 128080, total loss = 0.63, batch loss = 0.37 (230.8 examples/sec; 0.035 sec/batch; 0h:41m:15s remains)
INFO - root - 2022-02-24 20:42:05.421269: step 128090, total loss = 0.62, batch loss = 0.36 (335.3 examples/sec; 0.024 sec/batch; 0h:28m:23s remains)
INFO - root - 2022-02-24 20:42:05.862963: step 128100, total loss = 0.57, batch loss = 0.31 (105.9 examples/sec; 0.076 sec/batch; 1h:29m:51s remains)
INFO - root - 2022-02-24 20:42:06.320206: step 128110, total loss = 0.54, batch loss = 0.28 (260.3 examples/sec; 0.031 sec/batch; 0h:36m:34s remains)
INFO - root - 2022-02-24 20:42:06.704183: step 128120, total loss = 0.52, batch loss = 0.26 (106.5 examples/sec; 0.075 sec/batch; 1h:29m:22s remains)
INFO - root - 2022-02-24 20:42:07.034444: step 128130, total loss = 0.58, batch loss = 0.32 (204.3 examples/sec; 0.039 sec/batch; 0h:46m:34s remains)
INFO - root - 2022-02-24 20:42:07.382477: step 128140, total loss = 0.52, batch loss = 0.26 (201.4 examples/sec; 0.040 sec/batch; 0h:47m:14s remains)
INFO - root - 2022-02-24 20:42:07.806279: step 128150, total loss = 0.64, batch loss = 0.38 (350.9 examples/sec; 0.023 sec/batch; 0h:27m:06s remains)
INFO - root - 2022-02-24 20:42:08.233413: step 128160, total loss = 0.60, batch loss = 0.34 (256.2 examples/sec; 0.031 sec/batch; 0h:37m:07s remains)
INFO - root - 2022-02-24 20:42:08.579666: step 128170, total loss = 0.64, batch loss = 0.38 (223.5 examples/sec; 0.036 sec/batch; 0h:42m:33s remains)
INFO - root - 2022-02-24 20:42:08.955990: step 128180, total loss = 0.72, batch loss = 0.46 (305.6 examples/sec; 0.026 sec/batch; 0h:31m:07s remains)
INFO - root - 2022-02-24 20:42:09.242104: step 128190, total loss = 0.46, batch loss = 0.20 (329.0 examples/sec; 0.024 sec/batch; 0h:28m:54s remains)
INFO - root - 2022-02-24 20:42:09.635639: step 128200, total loss = 0.61, batch loss = 0.35 (257.9 examples/sec; 0.031 sec/batch; 0h:36m:51s remains)
INFO - root - 2022-02-24 20:42:10.107784: step 128210, total loss = 0.62, batch loss = 0.36 (114.9 examples/sec; 0.070 sec/batch; 1h:22m:43s remains)
INFO - root - 2022-02-24 20:42:10.547489: step 128220, total loss = 0.55, batch loss = 0.29 (291.2 examples/sec; 0.027 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 20:42:10.910149: step 128230, total loss = 0.67, batch loss = 0.41 (211.0 examples/sec; 0.038 sec/batch; 0h:45m:02s remains)
INFO - root - 2022-02-24 20:42:11.216582: step 128240, total loss = 0.63, batch loss = 0.37 (273.1 examples/sec; 0.029 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:42:11.555995: step 128250, total loss = 0.59, batch loss = 0.33 (291.9 examples/sec; 0.027 sec/batch; 0h:32m:32s remains)
INFO - root - 2022-02-24 20:42:11.864311: step 128260, total loss = 0.52, batch loss = 0.26 (306.7 examples/sec; 0.026 sec/batch; 0h:30m:58s remains)
INFO - root - 2022-02-24 20:42:12.243772: step 128270, total loss = 0.67, batch loss = 0.41 (197.4 examples/sec; 0.041 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:42:12.624094: step 128280, total loss = 0.55, batch loss = 0.29 (339.8 examples/sec; 0.024 sec/batch; 0h:27m:56s remains)
INFO - root - 2022-02-24 20:42:12.978860: step 128290, total loss = 0.52, batch loss = 0.26 (358.9 examples/sec; 0.022 sec/batch; 0h:26m:27s remains)
INFO - root - 2022-02-24 20:42:13.294857: step 128300, total loss = 0.63, batch loss = 0.37 (325.8 examples/sec; 0.025 sec/batch; 0h:29m:08s remains)
INFO - root - 2022-02-24 20:42:13.718046: step 128310, total loss = 0.52, batch loss = 0.26 (124.8 examples/sec; 0.064 sec/batch; 1h:16m:03s remains)
INFO - root - 2022-02-24 20:42:14.171029: step 128320, total loss = 0.52, batch loss = 0.26 (253.5 examples/sec; 0.032 sec/batch; 0h:37m:26s remains)
INFO - root - 2022-02-24 20:42:14.618519: step 128330, total loss = 0.60, batch loss = 0.34 (325.9 examples/sec; 0.025 sec/batch; 0h:29m:06s remains)
INFO - root - 2022-02-24 20:42:14.922420: step 128340, total loss = 0.59, batch loss = 0.33 (272.0 examples/sec; 0.029 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:42:15.519445: step 128350, total loss = 0.58, batch loss = 0.32 (209.6 examples/sec; 0.038 sec/batch; 0h:45m:15s remains)
INFO - root - 2022-02-24 20:42:16.135811: step 128360, total loss = 0.53, batch loss = 0.27 (248.9 examples/sec; 0.032 sec/batch; 0h:38m:06s remains)
INFO - root - 2022-02-24 20:42:16.567299: step 128370, total loss = 0.49, batch loss = 0.23 (182.5 examples/sec; 0.044 sec/batch; 0h:51m:57s remains)
INFO - root - 2022-02-24 20:42:16.992029: step 128380, total loss = 0.69, batch loss = 0.43 (265.5 examples/sec; 0.030 sec/batch; 0h:35m:43s remains)
INFO - root - 2022-02-24 20:42:17.395982: step 128390, total loss = 0.62, batch loss = 0.36 (241.8 examples/sec; 0.033 sec/batch; 0h:39m:12s remains)
INFO - root - 2022-02-24 20:42:17.855102: step 128400, total loss = 0.45, batch loss = 0.19 (179.6 examples/sec; 0.045 sec/batch; 0h:52m:46s remains)
INFO - root - 2022-02-24 20:42:18.936726: step 128410, total loss = 0.55, batch loss = 0.29 (94.3 examples/sec; 0.085 sec/batch; 1h:40m:33s remains)
INFO - root - 2022-02-24 20:42:19.318755: step 128420, total loss = 0.63, batch loss = 0.37 (149.5 examples/sec; 0.053 sec/batch; 1h:03m:22s remains)
INFO - root - 2022-02-24 20:42:19.605025: step 128430, total loss = 0.66, batch loss = 0.40 (292.3 examples/sec; 0.027 sec/batch; 0h:32m:25s remains)
INFO - root - 2022-02-24 20:42:19.870501: step 128440, total loss = 0.50, batch loss = 0.24 (353.0 examples/sec; 0.023 sec/batch; 0h:26m:50s remains)
INFO - root - 2022-02-24 20:42:20.201915: step 128450, total loss = 0.51, batch loss = 0.25 (309.9 examples/sec; 0.026 sec/batch; 0h:30m:34s remains)
INFO - root - 2022-02-24 20:42:20.615219: step 128460, total loss = 0.66, batch loss = 0.40 (230.9 examples/sec; 0.035 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 20:42:21.020785: step 128470, total loss = 0.53, batch loss = 0.27 (171.6 examples/sec; 0.047 sec/batch; 0h:55m:10s remains)
INFO - root - 2022-02-24 20:42:21.374802: step 128480, total loss = 0.59, batch loss = 0.33 (343.9 examples/sec; 0.023 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:42:21.672133: step 128490, total loss = 0.52, batch loss = 0.26 (328.7 examples/sec; 0.024 sec/batch; 0h:28m:48s remains)
INFO - root - 2022-02-24 20:42:21.963224: step 128500, total loss = 0.57, batch loss = 0.31 (164.4 examples/sec; 0.049 sec/batch; 0h:57m:35s remains)
INFO - root - 2022-02-24 20:42:22.366774: step 128510, total loss = 0.48, batch loss = 0.22 (245.2 examples/sec; 0.033 sec/batch; 0h:38m:36s remains)
INFO - root - 2022-02-24 20:42:22.802457: step 128520, total loss = 0.60, batch loss = 0.34 (198.9 examples/sec; 0.040 sec/batch; 0h:47m:35s remains)
INFO - root - 2022-02-24 20:42:23.283543: step 128530, total loss = 0.48, batch loss = 0.22 (172.7 examples/sec; 0.046 sec/batch; 0h:54m:47s remains)
INFO - root - 2022-02-24 20:42:23.692609: step 128540, total loss = 0.55, batch loss = 0.29 (270.6 examples/sec; 0.030 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 20:42:24.121925: step 128550, total loss = 0.48, batch loss = 0.22 (229.6 examples/sec; 0.035 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:42:24.533544: step 128560, total loss = 0.55, batch loss = 0.29 (147.8 examples/sec; 0.054 sec/batch; 1h:04m:00s remains)
INFO - root - 2022-02-24 20:42:25.043338: step 128570, total loss = 0.59, batch loss = 0.33 (108.7 examples/sec; 0.074 sec/batch; 1h:27m:02s remains)
INFO - root - 2022-02-24 20:42:25.462534: step 128580, total loss = 0.46, batch loss = 0.20 (182.9 examples/sec; 0.044 sec/batch; 0h:51m:41s remains)
INFO - root - 2022-02-24 20:42:25.753260: step 128590, total loss = 0.60, batch loss = 0.34 (189.0 examples/sec; 0.042 sec/batch; 0h:50m:01s remains)
INFO - root - 2022-02-24 20:42:26.085079: step 128600, total loss = 0.55, batch loss = 0.29 (179.6 examples/sec; 0.045 sec/batch; 0h:52m:38s remains)
INFO - root - 2022-02-24 20:42:26.468843: step 128610, total loss = 0.59, batch loss = 0.33 (299.3 examples/sec; 0.027 sec/batch; 0h:31m:35s remains)
INFO - root - 2022-02-24 20:42:26.821222: step 128620, total loss = 0.56, batch loss = 0.30 (164.4 examples/sec; 0.049 sec/batch; 0h:57m:29s remains)
INFO - root - 2022-02-24 20:42:27.156394: step 128630, total loss = 0.56, batch loss = 0.30 (235.0 examples/sec; 0.034 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:42:27.608165: step 128640, total loss = 0.58, batch loss = 0.32 (210.5 examples/sec; 0.038 sec/batch; 0h:44m:52s remains)
INFO - root - 2022-02-24 20:42:27.925285: step 128650, total loss = 0.61, batch loss = 0.35 (348.3 examples/sec; 0.023 sec/batch; 0h:27m:07s remains)
INFO - root - 2022-02-24 20:42:28.323403: step 128660, total loss = 0.55, batch loss = 0.29 (308.0 examples/sec; 0.026 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:42:28.651469: step 128670, total loss = 0.56, batch loss = 0.30 (300.3 examples/sec; 0.027 sec/batch; 0h:31m:26s remains)
INFO - root - 2022-02-24 20:42:29.059300: step 128680, total loss = 0.58, batch loss = 0.32 (281.5 examples/sec; 0.028 sec/batch; 0h:33m:32s remains)
INFO - root - 2022-02-24 20:42:29.498898: step 128690, total loss = 0.59, batch loss = 0.33 (189.9 examples/sec; 0.042 sec/batch; 0h:49m:42s remains)
INFO - root - 2022-02-24 20:42:29.796857: step 128700, total loss = 0.56, batch loss = 0.30 (323.9 examples/sec; 0.025 sec/batch; 0h:29m:08s remains)
INFO - root - 2022-02-24 20:42:30.187626: step 128710, total loss = 0.61, batch loss = 0.35 (183.5 examples/sec; 0.044 sec/batch; 0h:51m:25s remains)
INFO - root - 2022-02-24 20:42:30.479473: step 128720, total loss = 0.59, batch loss = 0.33 (154.7 examples/sec; 0.052 sec/batch; 1h:01m:00s remains)
INFO - root - 2022-02-24 20:42:30.828116: step 128730, total loss = 0.54, batch loss = 0.28 (294.2 examples/sec; 0.027 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:42:31.163684: step 128740, total loss = 0.63, batch loss = 0.37 (326.5 examples/sec; 0.024 sec/batch; 0h:28m:53s remains)
INFO - root - 2022-02-24 20:42:31.588448: step 128750, total loss = 0.59, batch loss = 0.33 (165.9 examples/sec; 0.048 sec/batch; 0h:56m:50s remains)
INFO - root - 2022-02-24 20:42:31.922909: step 128760, total loss = 0.63, batch loss = 0.37 (185.4 examples/sec; 0.043 sec/batch; 0h:50m:53s remains)
INFO - root - 2022-02-24 20:42:32.243694: step 128770, total loss = 0.62, batch loss = 0.36 (280.4 examples/sec; 0.029 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:42:32.586078: step 128780, total loss = 0.58, batch loss = 0.32 (238.3 examples/sec; 0.034 sec/batch; 0h:39m:34s remains)
INFO - root - 2022-02-24 20:42:33.075766: step 128790, total loss = 0.51, batch loss = 0.25 (138.6 examples/sec; 0.058 sec/batch; 1h:08m:00s remains)
INFO - root - 2022-02-24 20:42:33.644117: step 128800, total loss = 0.54, batch loss = 0.28 (101.0 examples/sec; 0.079 sec/batch; 1h:33m:20s remains)
INFO - root - 2022-02-24 20:42:34.585867: step 128810, total loss = 0.49, batch loss = 0.23 (157.7 examples/sec; 0.051 sec/batch; 0h:59m:45s remains)
INFO - root - 2022-02-24 20:42:34.996369: step 128820, total loss = 0.55, batch loss = 0.29 (116.8 examples/sec; 0.068 sec/batch; 1h:20m:41s remains)
INFO - root - 2022-02-24 20:42:35.435326: step 128830, total loss = 0.54, batch loss = 0.28 (321.9 examples/sec; 0.025 sec/batch; 0h:29m:16s remains)
INFO - root - 2022-02-24 20:42:35.838254: step 128840, total loss = 0.55, batch loss = 0.29 (214.7 examples/sec; 0.037 sec/batch; 0h:43m:52s remains)
INFO - root - 2022-02-24 20:42:36.270128: step 128850, total loss = 0.47, batch loss = 0.21 (274.3 examples/sec; 0.029 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:42:36.728726: step 128860, total loss = 0.56, batch loss = 0.30 (100.6 examples/sec; 0.080 sec/batch; 1h:33m:37s remains)
INFO - root - 2022-02-24 20:42:37.131541: step 128870, total loss = 0.53, batch loss = 0.27 (374.2 examples/sec; 0.021 sec/batch; 0h:25m:10s remains)
INFO - root - 2022-02-24 20:42:37.464620: step 128880, total loss = 0.48, batch loss = 0.22 (127.3 examples/sec; 0.063 sec/batch; 1h:13m:59s remains)
INFO - root - 2022-02-24 20:42:37.793531: step 128890, total loss = 0.59, batch loss = 0.33 (338.5 examples/sec; 0.024 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 20:42:38.227812: step 128900, total loss = 0.52, batch loss = 0.26 (275.4 examples/sec; 0.029 sec/batch; 0h:34m:11s remains)
INFO - root - 2022-02-24 20:42:38.660249: step 128910, total loss = 0.50, batch loss = 0.24 (211.1 examples/sec; 0.038 sec/batch; 0h:44m:34s remains)
INFO - root - 2022-02-24 20:42:39.171849: step 128920, total loss = 0.52, batch loss = 0.26 (126.7 examples/sec; 0.063 sec/batch; 1h:14m:16s remains)
INFO - root - 2022-02-24 20:42:39.506115: step 128930, total loss = 0.55, batch loss = 0.29 (180.9 examples/sec; 0.044 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:42:39.841511: step 128940, total loss = 0.64, batch loss = 0.38 (275.4 examples/sec; 0.029 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:42:40.154757: step 128950, total loss = 0.46, batch loss = 0.20 (359.6 examples/sec; 0.022 sec/batch; 0h:26m:09s remains)
INFO - root - 2022-02-24 20:42:40.565851: step 128960, total loss = 0.54, batch loss = 0.28 (250.0 examples/sec; 0.032 sec/batch; 0h:37m:37s remains)
INFO - root - 2022-02-24 20:42:41.042907: step 128970, total loss = 0.58, batch loss = 0.32 (133.8 examples/sec; 0.060 sec/batch; 1h:10m:15s remains)
INFO - root - 2022-02-24 20:42:41.386440: step 128980, total loss = 0.66, batch loss = 0.40 (293.0 examples/sec; 0.027 sec/batch; 0h:32m:05s remains)
INFO - root - 2022-02-24 20:42:41.721390: step 128990, total loss = 0.55, batch loss = 0.29 (182.2 examples/sec; 0.044 sec/batch; 0h:51m:36s remains)
INFO - root - 2022-02-24 20:42:42.053235: step 129000, total loss = 0.54, batch loss = 0.28 (338.7 examples/sec; 0.024 sec/batch; 0h:27m:45s remains)
INFO - root - 2022-02-24 20:42:42.401948: step 129010, total loss = 0.53, batch loss = 0.27 (355.5 examples/sec; 0.023 sec/batch; 0h:26m:26s remains)
INFO - root - 2022-02-24 20:42:42.834263: step 129020, total loss = 0.55, batch loss = 0.29 (197.0 examples/sec; 0.041 sec/batch; 0h:47m:42s remains)
INFO - root - 2022-02-24 20:42:43.212268: step 129030, total loss = 0.60, batch loss = 0.34 (319.2 examples/sec; 0.025 sec/batch; 0h:29m:26s remains)
INFO - root - 2022-02-24 20:42:43.523248: step 129040, total loss = 0.53, batch loss = 0.27 (324.6 examples/sec; 0.025 sec/batch; 0h:28m:56s remains)
INFO - root - 2022-02-24 20:42:43.960887: step 129050, total loss = 0.49, batch loss = 0.23 (226.8 examples/sec; 0.035 sec/batch; 0h:41m:24s remains)
INFO - root - 2022-02-24 20:42:44.219200: step 129060, total loss = 0.51, batch loss = 0.25 (349.5 examples/sec; 0.023 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 20:42:44.605934: step 129070, total loss = 0.51, batch loss = 0.25 (108.6 examples/sec; 0.074 sec/batch; 1h:26m:28s remains)
INFO - root - 2022-02-24 20:42:44.988912: step 129080, total loss = 0.50, batch loss = 0.24 (342.7 examples/sec; 0.023 sec/batch; 0h:27m:24s remains)
INFO - root - 2022-02-24 20:42:45.419228: step 129090, total loss = 0.56, batch loss = 0.30 (236.0 examples/sec; 0.034 sec/batch; 0h:39m:47s remains)
INFO - root - 2022-02-24 20:42:45.759256: step 129100, total loss = 0.51, batch loss = 0.25 (328.9 examples/sec; 0.024 sec/batch; 0h:28m:32s remains)
INFO - root - 2022-02-24 20:42:46.188528: step 129110, total loss = 0.54, batch loss = 0.28 (198.5 examples/sec; 0.040 sec/batch; 0h:47m:16s remains)
INFO - root - 2022-02-24 20:42:46.524408: step 129120, total loss = 0.61, batch loss = 0.35 (200.4 examples/sec; 0.040 sec/batch; 0h:46m:49s remains)
INFO - root - 2022-02-24 20:42:47.078477: step 129130, total loss = 0.59, batch loss = 0.33 (119.2 examples/sec; 0.067 sec/batch; 1h:18m:42s remains)
INFO - root - 2022-02-24 20:42:47.463149: step 129140, total loss = 0.52, batch loss = 0.26 (268.9 examples/sec; 0.030 sec/batch; 0h:34m:53s remains)
INFO - root - 2022-02-24 20:42:47.774722: step 129150, total loss = 0.58, batch loss = 0.32 (240.1 examples/sec; 0.033 sec/batch; 0h:39m:03s remains)
INFO - root - 2022-02-24 20:42:48.122323: step 129160, total loss = 0.61, batch loss = 0.35 (185.0 examples/sec; 0.043 sec/batch; 0h:50m:41s remains)
INFO - root - 2022-02-24 20:42:48.556744: step 129170, total loss = 0.58, batch loss = 0.32 (162.5 examples/sec; 0.049 sec/batch; 0h:57m:42s remains)
INFO - root - 2022-02-24 20:42:48.947125: step 129180, total loss = 0.55, batch loss = 0.29 (189.1 examples/sec; 0.042 sec/batch; 0h:49m:34s remains)
INFO - root - 2022-02-24 20:42:49.347787: step 129190, total loss = 0.48, batch loss = 0.22 (128.1 examples/sec; 0.062 sec/batch; 1h:13m:09s remains)
INFO - root - 2022-02-24 20:42:49.688689: step 129200, total loss = 0.49, batch loss = 0.23 (303.9 examples/sec; 0.026 sec/batch; 0h:30m:50s remains)
INFO - root - 2022-02-24 20:42:50.186033: step 129210, total loss = 0.52, batch loss = 0.26 (257.4 examples/sec; 0.031 sec/batch; 0h:36m:25s remains)
INFO - root - 2022-02-24 20:42:50.597020: step 129220, total loss = 0.47, batch loss = 0.21 (146.3 examples/sec; 0.055 sec/batch; 1h:04m:03s remains)
INFO - root - 2022-02-24 20:42:51.169397: step 129230, total loss = 0.54, batch loss = 0.28 (378.1 examples/sec; 0.021 sec/batch; 0h:24m:46s remains)
INFO - root - 2022-02-24 20:42:51.521436: step 129240, total loss = 0.57, batch loss = 0.31 (155.2 examples/sec; 0.052 sec/batch; 1h:00m:22s remains)
INFO - root - 2022-02-24 20:42:52.037535: step 129250, total loss = 0.64, batch loss = 0.38 (192.2 examples/sec; 0.042 sec/batch; 0h:48m:43s remains)
INFO - root - 2022-02-24 20:42:52.482368: step 129260, total loss = 0.55, batch loss = 0.29 (183.7 examples/sec; 0.044 sec/batch; 0h:50m:59s remains)
INFO - root - 2022-02-24 20:42:52.801378: step 129270, total loss = 0.57, batch loss = 0.31 (330.0 examples/sec; 0.024 sec/batch; 0h:28m:22s remains)
INFO - root - 2022-02-24 20:42:53.217069: step 129280, total loss = 0.67, batch loss = 0.41 (158.2 examples/sec; 0.051 sec/batch; 0h:59m:10s remains)
INFO - root - 2022-02-24 20:42:53.600224: step 129290, total loss = 0.57, batch loss = 0.31 (173.8 examples/sec; 0.046 sec/batch; 0h:53m:51s remains)
INFO - root - 2022-02-24 20:42:54.482555: step 129300, total loss = 0.55, batch loss = 0.29 (134.1 examples/sec; 0.060 sec/batch; 1h:09m:48s remains)
INFO - root - 2022-02-24 20:42:54.892098: step 129310, total loss = 0.58, batch loss = 0.33 (256.6 examples/sec; 0.031 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:42:55.288696: step 129320, total loss = 0.53, batch loss = 0.27 (317.7 examples/sec; 0.025 sec/batch; 0h:29m:27s remains)
INFO - root - 2022-02-24 20:42:55.638852: step 129330, total loss = 0.52, batch loss = 0.26 (226.8 examples/sec; 0.035 sec/batch; 0h:41m:14s remains)
INFO - root - 2022-02-24 20:42:56.127086: step 129340, total loss = 0.52, batch loss = 0.26 (212.3 examples/sec; 0.038 sec/batch; 0h:44m:03s remains)
INFO - root - 2022-02-24 20:42:56.546735: step 129350, total loss = 0.45, batch loss = 0.19 (294.2 examples/sec; 0.027 sec/batch; 0h:31m:47s remains)
INFO - root - 2022-02-24 20:42:56.869103: step 129360, total loss = 0.60, batch loss = 0.34 (248.6 examples/sec; 0.032 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 20:42:57.209456: step 129370, total loss = 0.57, batch loss = 0.31 (226.3 examples/sec; 0.035 sec/batch; 0h:41m:19s remains)
INFO - root - 2022-02-24 20:42:57.602582: step 129380, total loss = 0.61, batch loss = 0.35 (256.4 examples/sec; 0.031 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:42:57.965534: step 129390, total loss = 0.54, batch loss = 0.28 (317.5 examples/sec; 0.025 sec/batch; 0h:29m:26s remains)
INFO - root - 2022-02-24 20:42:58.461181: step 129400, total loss = 0.57, batch loss = 0.31 (194.0 examples/sec; 0.041 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:42:58.966315: step 129410, total loss = 0.57, batch loss = 0.32 (146.6 examples/sec; 0.055 sec/batch; 1h:03m:44s remains)
INFO - root - 2022-02-24 20:42:59.315285: step 129420, total loss = 0.55, batch loss = 0.29 (244.8 examples/sec; 0.033 sec/batch; 0h:38m:09s remains)
INFO - root - 2022-02-24 20:42:59.743384: step 129430, total loss = 0.47, batch loss = 0.22 (273.3 examples/sec; 0.029 sec/batch; 0h:34m:10s remains)
INFO - root - 2022-02-24 20:43:00.164656: step 129440, total loss = 0.45, batch loss = 0.19 (244.5 examples/sec; 0.033 sec/batch; 0h:38m:12s remains)
INFO - root - 2022-02-24 20:43:00.527851: step 129450, total loss = 0.55, batch loss = 0.29 (154.1 examples/sec; 0.052 sec/batch; 1h:00m:35s remains)
INFO - root - 2022-02-24 20:43:00.913657: step 129460, total loss = 0.64, batch loss = 0.38 (329.5 examples/sec; 0.024 sec/batch; 0h:28m:20s remains)
INFO - root - 2022-02-24 20:43:01.257628: step 129470, total loss = 0.48, batch loss = 0.22 (245.8 examples/sec; 0.033 sec/batch; 0h:37m:59s remains)
INFO - root - 2022-02-24 20:43:01.523339: step 129480, total loss = 0.49, batch loss = 0.23 (317.0 examples/sec; 0.025 sec/batch; 0h:29m:27s remains)
INFO - root - 2022-02-24 20:43:01.806061: step 129490, total loss = 0.53, batch loss = 0.27 (221.9 examples/sec; 0.036 sec/batch; 0h:42m:04s remains)
INFO - root - 2022-02-24 20:43:02.156623: step 129500, total loss = 0.54, batch loss = 0.28 (277.6 examples/sec; 0.029 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:43:02.730047: step 129510, total loss = 0.51, batch loss = 0.25 (96.3 examples/sec; 0.083 sec/batch; 1h:36m:52s remains)
INFO - root - 2022-02-24 20:43:03.210671: step 129520, total loss = 0.61, batch loss = 0.35 (169.4 examples/sec; 0.047 sec/batch; 0h:55m:04s remains)
INFO - root - 2022-02-24 20:43:03.597565: step 129530, total loss = 0.60, batch loss = 0.34 (117.1 examples/sec; 0.068 sec/batch; 1h:19m:39s remains)
INFO - root - 2022-02-24 20:43:03.950247: step 129540, total loss = 0.65, batch loss = 0.39 (150.9 examples/sec; 0.053 sec/batch; 1h:01m:49s remains)
INFO - root - 2022-02-24 20:43:04.351944: step 129550, total loss = 0.70, batch loss = 0.44 (323.6 examples/sec; 0.025 sec/batch; 0h:28m:49s remains)
INFO - root - 2022-02-24 20:43:04.816164: step 129560, total loss = 0.61, batch loss = 0.35 (279.5 examples/sec; 0.029 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:43:05.319411: step 129570, total loss = 0.55, batch loss = 0.29 (287.3 examples/sec; 0.028 sec/batch; 0h:32m:27s remains)
INFO - root - 2022-02-24 20:43:05.676790: step 129580, total loss = 0.51, batch loss = 0.25 (221.4 examples/sec; 0.036 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 20:43:05.958243: step 129590, total loss = 0.44, batch loss = 0.18 (232.4 examples/sec; 0.034 sec/batch; 0h:40m:06s remains)
INFO - root - 2022-02-24 20:43:06.318042: step 129600, total loss = 0.50, batch loss = 0.24 (216.4 examples/sec; 0.037 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:43:06.823704: step 129610, total loss = 0.60, batch loss = 0.34 (109.8 examples/sec; 0.073 sec/batch; 1h:24m:50s remains)
INFO - root - 2022-02-24 20:43:07.241165: step 129620, total loss = 0.64, batch loss = 0.39 (122.4 examples/sec; 0.065 sec/batch; 1h:16m:07s remains)
INFO - root - 2022-02-24 20:43:07.897677: step 129630, total loss = 0.58, batch loss = 0.32 (183.0 examples/sec; 0.044 sec/batch; 0h:50m:55s remains)
INFO - root - 2022-02-24 20:43:08.340135: step 129640, total loss = 0.52, batch loss = 0.26 (294.1 examples/sec; 0.027 sec/batch; 0h:31m:40s remains)
INFO - root - 2022-02-24 20:43:09.118141: step 129650, total loss = 0.49, batch loss = 0.23 (203.9 examples/sec; 0.039 sec/batch; 0h:45m:40s remains)
INFO - root - 2022-02-24 20:43:09.568058: step 129660, total loss = 0.51, batch loss = 0.25 (338.0 examples/sec; 0.024 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:43:10.376053: step 129670, total loss = 0.51, batch loss = 0.25 (123.8 examples/sec; 0.065 sec/batch; 1h:15m:11s remains)
INFO - root - 2022-02-24 20:43:10.791162: step 129680, total loss = 0.47, batch loss = 0.21 (196.9 examples/sec; 0.041 sec/batch; 0h:47m:16s remains)
INFO - root - 2022-02-24 20:43:11.196018: step 129690, total loss = 0.74, batch loss = 0.48 (167.8 examples/sec; 0.048 sec/batch; 0h:55m:28s remains)
INFO - root - 2022-02-24 20:43:11.558385: step 129700, total loss = 0.51, batch loss = 0.25 (174.0 examples/sec; 0.046 sec/batch; 0h:53m:28s remains)
INFO - root - 2022-02-24 20:43:11.970067: step 129710, total loss = 0.52, batch loss = 0.26 (272.7 examples/sec; 0.029 sec/batch; 0h:34m:07s remains)
INFO - root - 2022-02-24 20:43:12.312179: step 129720, total loss = 0.52, batch loss = 0.27 (317.1 examples/sec; 0.025 sec/batch; 0h:29m:20s remains)
INFO - root - 2022-02-24 20:43:12.605416: step 129730, total loss = 0.55, batch loss = 0.29 (337.5 examples/sec; 0.024 sec/batch; 0h:27m:34s remains)
INFO - root - 2022-02-24 20:43:12.932442: step 129740, total loss = 0.56, batch loss = 0.30 (184.3 examples/sec; 0.043 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 20:43:13.391532: step 129750, total loss = 0.65, batch loss = 0.39 (161.0 examples/sec; 0.050 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 20:43:13.819758: step 129760, total loss = 0.55, batch loss = 0.29 (169.1 examples/sec; 0.047 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:43:14.206438: step 129770, total loss = 0.55, batch loss = 0.29 (125.6 examples/sec; 0.064 sec/batch; 1h:14m:00s remains)
INFO - root - 2022-02-24 20:43:14.638073: step 129780, total loss = 0.64, batch loss = 0.38 (358.1 examples/sec; 0.022 sec/batch; 0h:25m:57s remains)
INFO - root - 2022-02-24 20:43:14.976663: step 129790, total loss = 0.51, batch loss = 0.25 (278.5 examples/sec; 0.029 sec/batch; 0h:33m:22s remains)
INFO - root - 2022-02-24 20:43:15.376462: step 129800, total loss = 0.60, batch loss = 0.34 (162.9 examples/sec; 0.049 sec/batch; 0h:57m:02s remains)
INFO - root - 2022-02-24 20:43:15.892665: step 129810, total loss = 0.57, batch loss = 0.31 (233.8 examples/sec; 0.034 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:43:16.238860: step 129820, total loss = 0.53, batch loss = 0.27 (309.9 examples/sec; 0.026 sec/batch; 0h:29m:58s remains)
INFO - root - 2022-02-24 20:43:16.597536: step 129830, total loss = 0.48, batch loss = 0.22 (365.7 examples/sec; 0.022 sec/batch; 0h:25m:24s remains)
INFO - root - 2022-02-24 20:43:16.925186: step 129840, total loss = 0.59, batch loss = 0.33 (232.6 examples/sec; 0.034 sec/batch; 0h:39m:55s remains)
INFO - root - 2022-02-24 20:43:17.413299: step 129850, total loss = 0.53, batch loss = 0.27 (156.5 examples/sec; 0.051 sec/batch; 0h:59m:21s remains)
INFO - root - 2022-02-24 20:43:17.906372: step 129860, total loss = 0.57, batch loss = 0.31 (91.6 examples/sec; 0.087 sec/batch; 1h:41m:20s remains)
INFO - root - 2022-02-24 20:43:18.330859: step 129870, total loss = 0.52, batch loss = 0.26 (349.8 examples/sec; 0.023 sec/batch; 0h:26m:32s remains)
INFO - root - 2022-02-24 20:43:18.618476: step 129880, total loss = 0.53, batch loss = 0.27 (359.6 examples/sec; 0.022 sec/batch; 0h:25m:48s remains)
INFO - root - 2022-02-24 20:43:19.050713: step 129890, total loss = 0.48, batch loss = 0.22 (346.5 examples/sec; 0.023 sec/batch; 0h:26m:47s remains)
INFO - root - 2022-02-24 20:43:19.400299: step 129900, total loss = 0.60, batch loss = 0.34 (256.3 examples/sec; 0.031 sec/batch; 0h:36m:12s remains)
INFO - root - 2022-02-24 20:43:19.847558: step 129910, total loss = 0.59, batch loss = 0.33 (313.4 examples/sec; 0.026 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 20:43:20.301391: step 129920, total loss = 0.60, batch loss = 0.34 (232.1 examples/sec; 0.034 sec/batch; 0h:39m:58s remains)
INFO - root - 2022-02-24 20:43:20.706678: step 129930, total loss = 0.54, batch loss = 0.28 (255.8 examples/sec; 0.031 sec/batch; 0h:36m:15s remains)
INFO - root - 2022-02-24 20:43:21.024369: step 129940, total loss = 0.58, batch loss = 0.32 (282.6 examples/sec; 0.028 sec/batch; 0h:32m:49s remains)
INFO - root - 2022-02-24 20:43:21.436750: step 129950, total loss = 0.58, batch loss = 0.32 (146.4 examples/sec; 0.055 sec/batch; 1h:03m:20s remains)
INFO - root - 2022-02-24 20:43:21.850872: step 129960, total loss = 0.49, batch loss = 0.23 (188.5 examples/sec; 0.042 sec/batch; 0h:49m:10s remains)
INFO - root - 2022-02-24 20:43:22.281994: step 129970, total loss = 0.56, batch loss = 0.30 (279.3 examples/sec; 0.029 sec/batch; 0h:33m:11s remains)
INFO - root - 2022-02-24 20:43:22.622770: step 129980, total loss = 0.54, batch loss = 0.28 (232.4 examples/sec; 0.034 sec/batch; 0h:39m:53s remains)
INFO - root - 2022-02-24 20:43:23.131788: step 129990, total loss = 0.61, batch loss = 0.35 (189.0 examples/sec; 0.042 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:43:23.473349: step 130000, total loss = 0.60, batch loss = 0.34 (337.2 examples/sec; 0.024 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:43:23.895603: step 130010, total loss = 0.49, batch loss = 0.23 (173.1 examples/sec; 0.046 sec/batch; 0h:53m:30s remains)
INFO - root - 2022-02-24 20:43:24.371726: step 130020, total loss = 0.53, batch loss = 0.27 (133.3 examples/sec; 0.060 sec/batch; 1h:09m:31s remains)
INFO - root - 2022-02-24 20:43:24.708965: step 130030, total loss = 0.67, batch loss = 0.41 (322.5 examples/sec; 0.025 sec/batch; 0h:28m:43s remains)
INFO - root - 2022-02-24 20:43:25.151407: step 130040, total loss = 0.54, batch loss = 0.29 (235.9 examples/sec; 0.034 sec/batch; 0h:39m:15s remains)
INFO - root - 2022-02-24 20:43:25.538943: step 130050, total loss = 0.54, batch loss = 0.28 (177.3 examples/sec; 0.045 sec/batch; 0h:52m:13s remains)
INFO - root - 2022-02-24 20:43:26.063400: step 130060, total loss = 0.51, batch loss = 0.25 (93.0 examples/sec; 0.086 sec/batch; 1h:39m:36s remains)
INFO - root - 2022-02-24 20:43:26.686812: step 130070, total loss = 0.58, batch loss = 0.32 (305.6 examples/sec; 0.026 sec/batch; 0h:30m:17s remains)
INFO - root - 2022-02-24 20:43:27.553208: step 130080, total loss = 0.48, batch loss = 0.22 (14.9 examples/sec; 0.538 sec/batch; 10h:22m:19s remains)
INFO - root - 2022-02-24 20:43:28.071398: step 130090, total loss = 0.52, batch loss = 0.26 (67.7 examples/sec; 0.118 sec/batch; 2h:16m:39s remains)
INFO - root - 2022-02-24 20:43:28.618562: step 130100, total loss = 0.44, batch loss = 0.18 (278.7 examples/sec; 0.029 sec/batch; 0h:33m:12s remains)
INFO - root - 2022-02-24 20:43:29.022866: step 130110, total loss = 0.77, batch loss = 0.51 (103.1 examples/sec; 0.078 sec/batch; 1h:29m:44s remains)
INFO - root - 2022-02-24 20:43:29.422312: step 130120, total loss = 0.63, batch loss = 0.37 (275.5 examples/sec; 0.029 sec/batch; 0h:33m:34s remains)
INFO - root - 2022-02-24 20:43:29.709714: step 130130, total loss = 0.59, batch loss = 0.33 (309.2 examples/sec; 0.026 sec/batch; 0h:29m:54s remains)
INFO - root - 2022-02-24 20:43:30.114273: step 130140, total loss = 0.61, batch loss = 0.35 (374.2 examples/sec; 0.021 sec/batch; 0h:24m:42s remains)
INFO - root - 2022-02-24 20:43:30.503484: step 130150, total loss = 0.53, batch loss = 0.27 (257.3 examples/sec; 0.031 sec/batch; 0h:35m:56s remains)
INFO - root - 2022-02-24 20:43:30.899578: step 130160, total loss = 0.51, batch loss = 0.25 (213.4 examples/sec; 0.037 sec/batch; 0h:43m:18s remains)
INFO - root - 2022-02-24 20:43:31.332290: step 130170, total loss = 0.66, batch loss = 0.40 (165.2 examples/sec; 0.048 sec/batch; 0h:55m:56s remains)
INFO - root - 2022-02-24 20:43:31.709141: step 130180, total loss = 0.67, batch loss = 0.41 (265.0 examples/sec; 0.030 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:43:32.141701: step 130190, total loss = 0.48, batch loss = 0.22 (192.3 examples/sec; 0.042 sec/batch; 0h:48m:03s remains)
INFO - root - 2022-02-24 20:43:32.514828: step 130200, total loss = 0.60, batch loss = 0.34 (359.3 examples/sec; 0.022 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 20:43:32.861190: step 130210, total loss = 0.49, batch loss = 0.23 (168.5 examples/sec; 0.047 sec/batch; 0h:54m:50s remains)
INFO - root - 2022-02-24 20:43:33.226532: step 130220, total loss = 0.66, batch loss = 0.40 (230.1 examples/sec; 0.035 sec/batch; 0h:40m:08s remains)
INFO - root - 2022-02-24 20:43:33.551118: step 130230, total loss = 0.52, batch loss = 0.26 (325.3 examples/sec; 0.025 sec/batch; 0h:28m:23s remains)
INFO - root - 2022-02-24 20:43:33.846359: step 130240, total loss = 0.51, batch loss = 0.25 (181.1 examples/sec; 0.044 sec/batch; 0h:50m:59s remains)
INFO - root - 2022-02-24 20:43:34.109430: step 130250, total loss = 0.55, batch loss = 0.29 (318.6 examples/sec; 0.025 sec/batch; 0h:28m:58s remains)
INFO - root - 2022-02-24 20:43:34.467218: step 130260, total loss = 0.53, batch loss = 0.27 (142.4 examples/sec; 0.056 sec/batch; 1h:04m:50s remains)
INFO - root - 2022-02-24 20:43:34.892479: step 130270, total loss = 0.55, batch loss = 0.29 (338.8 examples/sec; 0.024 sec/batch; 0h:27m:14s remains)
INFO - root - 2022-02-24 20:43:35.356114: step 130280, total loss = 0.70, batch loss = 0.44 (279.0 examples/sec; 0.029 sec/batch; 0h:33m:04s remains)
INFO - root - 2022-02-24 20:43:35.706179: step 130290, total loss = 0.63, batch loss = 0.37 (275.9 examples/sec; 0.029 sec/batch; 0h:33m:26s remains)
INFO - root - 2022-02-24 20:43:36.068715: step 130300, total loss = 0.50, batch loss = 0.24 (239.6 examples/sec; 0.033 sec/batch; 0h:38m:30s remains)
INFO - root - 2022-02-24 20:43:36.590038: step 130310, total loss = 0.48, batch loss = 0.23 (365.3 examples/sec; 0.022 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 20:43:37.034880: step 130320, total loss = 0.51, batch loss = 0.25 (197.5 examples/sec; 0.041 sec/batch; 0h:46m:42s remains)
INFO - root - 2022-02-24 20:43:37.469921: step 130330, total loss = 0.51, batch loss = 0.25 (289.8 examples/sec; 0.028 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 20:43:37.863223: step 130340, total loss = 0.57, batch loss = 0.31 (186.7 examples/sec; 0.043 sec/batch; 0h:49m:22s remains)
INFO - root - 2022-02-24 20:43:38.187022: step 130350, total loss = 0.50, batch loss = 0.24 (253.8 examples/sec; 0.032 sec/batch; 0h:36m:19s remains)
INFO - root - 2022-02-24 20:43:38.570943: step 130360, total loss = 0.52, batch loss = 0.26 (270.4 examples/sec; 0.030 sec/batch; 0h:34m:05s remains)
INFO - root - 2022-02-24 20:43:39.038185: step 130370, total loss = 0.50, batch loss = 0.24 (379.8 examples/sec; 0.021 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:43:39.407388: step 130380, total loss = 0.69, batch loss = 0.43 (317.1 examples/sec; 0.025 sec/batch; 0h:29m:03s remains)
INFO - root - 2022-02-24 20:43:39.730021: step 130390, total loss = 0.49, batch loss = 0.23 (224.3 examples/sec; 0.036 sec/batch; 0h:41m:05s remains)
INFO - root - 2022-02-24 20:43:40.035025: step 130400, total loss = 0.57, batch loss = 0.32 (226.7 examples/sec; 0.035 sec/batch; 0h:40m:38s remains)
INFO - root - 2022-02-24 20:43:40.412920: step 130410, total loss = 0.55, batch loss = 0.30 (351.0 examples/sec; 0.023 sec/batch; 0h:26m:14s remains)
INFO - root - 2022-02-24 20:43:40.821843: step 130420, total loss = 0.49, batch loss = 0.23 (185.0 examples/sec; 0.043 sec/batch; 0h:49m:47s remains)
INFO - root - 2022-02-24 20:43:41.329248: step 130430, total loss = 0.66, batch loss = 0.40 (169.8 examples/sec; 0.047 sec/batch; 0h:54m:13s remains)
INFO - root - 2022-02-24 20:43:42.008877: step 130440, total loss = 0.44, batch loss = 0.18 (29.6 examples/sec; 0.270 sec/batch; 5h:10m:48s remains)
INFO - root - 2022-02-24 20:43:42.437406: step 130450, total loss = 0.56, batch loss = 0.31 (223.6 examples/sec; 0.036 sec/batch; 0h:41m:10s remains)
INFO - root - 2022-02-24 20:43:42.838962: step 130460, total loss = 0.50, batch loss = 0.24 (127.0 examples/sec; 0.063 sec/batch; 1h:12m:29s remains)
INFO - root - 2022-02-24 20:43:43.253737: step 130470, total loss = 0.55, batch loss = 0.29 (229.7 examples/sec; 0.035 sec/batch; 0h:40m:04s remains)
INFO - root - 2022-02-24 20:43:43.630205: step 130480, total loss = 0.57, batch loss = 0.31 (305.6 examples/sec; 0.026 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:43:44.131807: step 130490, total loss = 0.46, batch loss = 0.20 (67.2 examples/sec; 0.119 sec/batch; 2h:16m:59s remains)
INFO - root - 2022-02-24 20:43:44.565088: step 130500, total loss = 0.50, batch loss = 0.25 (189.3 examples/sec; 0.042 sec/batch; 0h:48m:36s remains)
INFO - root - 2022-02-24 20:43:44.974361: step 130510, total loss = 0.61, batch loss = 0.35 (246.4 examples/sec; 0.032 sec/batch; 0h:37m:20s remains)
INFO - root - 2022-02-24 20:43:45.376770: step 130520, total loss = 0.49, batch loss = 0.23 (354.3 examples/sec; 0.023 sec/batch; 0h:25m:57s remains)
INFO - root - 2022-02-24 20:43:45.790270: step 130530, total loss = 0.56, batch loss = 0.30 (296.3 examples/sec; 0.027 sec/batch; 0h:31m:02s remains)
INFO - root - 2022-02-24 20:43:46.169816: step 130540, total loss = 0.42, batch loss = 0.16 (326.8 examples/sec; 0.024 sec/batch; 0h:28m:08s remains)
INFO - root - 2022-02-24 20:43:46.929131: step 130550, total loss = 0.56, batch loss = 0.30 (129.7 examples/sec; 0.062 sec/batch; 1h:10m:53s remains)
INFO - root - 2022-02-24 20:43:47.263549: step 130560, total loss = 0.59, batch loss = 0.33 (345.8 examples/sec; 0.023 sec/batch; 0h:26m:34s remains)
INFO - root - 2022-02-24 20:43:47.741540: step 130570, total loss = 0.60, batch loss = 0.34 (308.3 examples/sec; 0.026 sec/batch; 0h:29m:48s remains)
INFO - root - 2022-02-24 20:43:48.138884: step 130580, total loss = 0.53, batch loss = 0.27 (241.3 examples/sec; 0.033 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:43:48.526425: step 130590, total loss = 0.55, batch loss = 0.29 (303.1 examples/sec; 0.026 sec/batch; 0h:30m:18s remains)
INFO - root - 2022-02-24 20:43:48.838531: step 130600, total loss = 0.61, batch loss = 0.35 (235.9 examples/sec; 0.034 sec/batch; 0h:38m:56s remains)
INFO - root - 2022-02-24 20:43:49.334623: step 130610, total loss = 0.51, batch loss = 0.26 (94.2 examples/sec; 0.085 sec/batch; 1h:37m:31s remains)
INFO - root - 2022-02-24 20:43:49.798201: step 130620, total loss = 0.49, batch loss = 0.23 (270.0 examples/sec; 0.030 sec/batch; 0h:34m:00s remains)
INFO - root - 2022-02-24 20:43:50.135249: step 130630, total loss = 0.63, batch loss = 0.37 (332.4 examples/sec; 0.024 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 20:43:50.474217: step 130640, total loss = 0.55, batch loss = 0.29 (222.9 examples/sec; 0.036 sec/batch; 0h:41m:11s remains)
INFO - root - 2022-02-24 20:43:50.838171: step 130650, total loss = 0.48, batch loss = 0.22 (111.7 examples/sec; 0.072 sec/batch; 1h:22m:11s remains)
INFO - root - 2022-02-24 20:43:51.157627: step 130660, total loss = 0.46, batch loss = 0.20 (299.1 examples/sec; 0.027 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:43:51.555023: step 130670, total loss = 0.56, batch loss = 0.30 (135.2 examples/sec; 0.059 sec/batch; 1h:07m:53s remains)
INFO - root - 2022-02-24 20:43:52.027427: step 130680, total loss = 0.61, batch loss = 0.35 (330.3 examples/sec; 0.024 sec/batch; 0h:27m:46s remains)
INFO - root - 2022-02-24 20:43:52.397444: step 130690, total loss = 0.62, batch loss = 0.36 (200.6 examples/sec; 0.040 sec/batch; 0h:45m:44s remains)
INFO - root - 2022-02-24 20:43:52.739917: step 130700, total loss = 0.53, batch loss = 0.27 (283.4 examples/sec; 0.028 sec/batch; 0h:32m:21s remains)
INFO - root - 2022-02-24 20:43:53.141737: step 130710, total loss = 0.45, batch loss = 0.19 (317.1 examples/sec; 0.025 sec/batch; 0h:28m:55s remains)
INFO - root - 2022-02-24 20:43:53.613933: step 130720, total loss = 0.47, batch loss = 0.21 (125.5 examples/sec; 0.064 sec/batch; 1h:13m:04s remains)
INFO - root - 2022-02-24 20:43:53.984962: step 130730, total loss = 0.54, batch loss = 0.28 (217.1 examples/sec; 0.037 sec/batch; 0h:42m:14s remains)
INFO - root - 2022-02-24 20:43:54.437584: step 130740, total loss = 0.73, batch loss = 0.47 (269.1 examples/sec; 0.030 sec/batch; 0h:34m:04s remains)
INFO - root - 2022-02-24 20:43:54.775971: step 130750, total loss = 0.55, batch loss = 0.29 (158.0 examples/sec; 0.051 sec/batch; 0h:57m:59s remains)
INFO - root - 2022-02-24 20:43:55.084529: step 130760, total loss = 0.57, batch loss = 0.31 (312.8 examples/sec; 0.026 sec/batch; 0h:29m:17s remains)
INFO - root - 2022-02-24 20:43:55.473763: step 130770, total loss = 0.57, batch loss = 0.31 (233.9 examples/sec; 0.034 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 20:43:55.901162: step 130780, total loss = 0.51, batch loss = 0.25 (339.9 examples/sec; 0.024 sec/batch; 0h:26m:57s remains)
INFO - root - 2022-02-24 20:43:56.328840: step 130790, total loss = 0.52, batch loss = 0.26 (168.5 examples/sec; 0.047 sec/batch; 0h:54m:22s remains)
INFO - root - 2022-02-24 20:43:56.613503: step 130800, total loss = 0.60, batch loss = 0.34 (313.6 examples/sec; 0.026 sec/batch; 0h:29m:12s remains)
INFO - root - 2022-02-24 20:43:57.018496: step 130810, total loss = 0.58, batch loss = 0.32 (124.1 examples/sec; 0.064 sec/batch; 1h:13m:48s remains)
INFO - root - 2022-02-24 20:43:57.414428: step 130820, total loss = 0.60, batch loss = 0.34 (297.1 examples/sec; 0.027 sec/batch; 0h:30m:49s remains)
INFO - root - 2022-02-24 20:43:57.789890: step 130830, total loss = 0.48, batch loss = 0.22 (281.7 examples/sec; 0.028 sec/batch; 0h:32m:29s remains)
INFO - root - 2022-02-24 20:43:58.237796: step 130840, total loss = 0.49, batch loss = 0.23 (172.1 examples/sec; 0.046 sec/batch; 0h:53m:11s remains)
INFO - root - 2022-02-24 20:43:58.569367: step 130850, total loss = 0.56, batch loss = 0.30 (193.2 examples/sec; 0.041 sec/batch; 0h:47m:21s remains)
INFO - root - 2022-02-24 20:43:58.905898: step 130860, total loss = 0.59, batch loss = 0.33 (297.0 examples/sec; 0.027 sec/batch; 0h:30m:48s remains)
INFO - root - 2022-02-24 20:43:59.216580: step 130870, total loss = 0.52, batch loss = 0.26 (326.2 examples/sec; 0.025 sec/batch; 0h:28m:03s remains)
INFO - root - 2022-02-24 20:43:59.682752: step 130880, total loss = 0.58, batch loss = 0.32 (78.9 examples/sec; 0.101 sec/batch; 1h:55m:55s remains)
INFO - root - 2022-02-24 20:44:00.406082: step 130890, total loss = 0.58, batch loss = 0.32 (72.2 examples/sec; 0.111 sec/batch; 2h:06m:42s remains)
INFO - root - 2022-02-24 20:44:00.777168: step 130900, total loss = 0.46, batch loss = 0.20 (168.1 examples/sec; 0.048 sec/batch; 0h:54m:25s remains)
INFO - root - 2022-02-24 20:44:01.344206: step 130910, total loss = 0.50, batch loss = 0.24 (329.4 examples/sec; 0.024 sec/batch; 0h:27m:45s remains)
INFO - root - 2022-02-24 20:44:01.711322: step 130920, total loss = 0.52, batch loss = 0.26 (120.5 examples/sec; 0.066 sec/batch; 1h:15m:54s remains)
INFO - root - 2022-02-24 20:44:02.650595: step 130930, total loss = 0.71, batch loss = 0.46 (179.9 examples/sec; 0.044 sec/batch; 0h:50m:49s remains)
INFO - root - 2022-02-24 20:44:03.011223: step 130940, total loss = 0.53, batch loss = 0.27 (268.3 examples/sec; 0.030 sec/batch; 0h:34m:04s remains)
INFO - root - 2022-02-24 20:44:03.405713: step 130950, total loss = 0.51, batch loss = 0.25 (171.7 examples/sec; 0.047 sec/batch; 0h:53m:13s remains)
INFO - root - 2022-02-24 20:44:03.776918: step 130960, total loss = 0.71, batch loss = 0.45 (203.9 examples/sec; 0.039 sec/batch; 0h:44m:49s remains)
INFO - root - 2022-02-24 20:44:04.134650: step 130970, total loss = 0.52, batch loss = 0.26 (239.1 examples/sec; 0.033 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:44:04.612935: step 130980, total loss = 0.63, batch loss = 0.37 (273.9 examples/sec; 0.029 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:44:05.035177: step 130990, total loss = 0.52, batch loss = 0.26 (325.8 examples/sec; 0.025 sec/batch; 0h:28m:02s remains)
INFO - root - 2022-02-24 20:44:05.342860: step 131000, total loss = 0.63, batch loss = 0.37 (185.5 examples/sec; 0.043 sec/batch; 0h:49m:13s remains)
INFO - root - 2022-02-24 20:44:05.733378: step 131010, total loss = 0.51, batch loss = 0.25 (301.1 examples/sec; 0.027 sec/batch; 0h:30m:19s remains)
INFO - root - 2022-02-24 20:44:06.068493: step 131020, total loss = 0.53, batch loss = 0.27 (283.2 examples/sec; 0.028 sec/batch; 0h:32m:14s remains)
INFO - root - 2022-02-24 20:44:06.450302: step 131030, total loss = 0.60, batch loss = 0.34 (224.5 examples/sec; 0.036 sec/batch; 0h:40m:39s remains)
INFO - root - 2022-02-24 20:44:06.867564: step 131040, total loss = 0.57, batch loss = 0.31 (199.8 examples/sec; 0.040 sec/batch; 0h:45m:40s remains)
INFO - root - 2022-02-24 20:44:07.295375: step 131050, total loss = 0.62, batch loss = 0.36 (336.0 examples/sec; 0.024 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 20:44:07.624817: step 131060, total loss = 0.51, batch loss = 0.25 (161.0 examples/sec; 0.050 sec/batch; 0h:56m:40s remains)
INFO - root - 2022-02-24 20:44:08.015326: step 131070, total loss = 0.56, batch loss = 0.30 (331.1 examples/sec; 0.024 sec/batch; 0h:27m:33s remains)
INFO - root - 2022-02-24 20:44:08.453902: step 131080, total loss = 0.50, batch loss = 0.24 (150.2 examples/sec; 0.053 sec/batch; 1h:00m:45s remains)
INFO - root - 2022-02-24 20:44:08.977269: step 131090, total loss = 0.50, batch loss = 0.24 (80.7 examples/sec; 0.099 sec/batch; 1h:53m:04s remains)
INFO - root - 2022-02-24 20:44:09.292124: step 131100, total loss = 0.55, batch loss = 0.29 (203.1 examples/sec; 0.039 sec/batch; 0h:44m:54s remains)
INFO - root - 2022-02-24 20:44:09.754421: step 131110, total loss = 0.54, batch loss = 0.28 (138.7 examples/sec; 0.058 sec/batch; 1h:05m:45s remains)
INFO - root - 2022-02-24 20:44:10.075703: step 131120, total loss = 0.61, batch loss = 0.35 (335.3 examples/sec; 0.024 sec/batch; 0h:27m:11s remains)
INFO - root - 2022-02-24 20:44:10.419769: step 131130, total loss = 0.55, batch loss = 0.29 (219.0 examples/sec; 0.037 sec/batch; 0h:41m:37s remains)
INFO - root - 2022-02-24 20:44:10.843530: step 131140, total loss = 0.53, batch loss = 0.27 (227.8 examples/sec; 0.035 sec/batch; 0h:40m:00s remains)
INFO - root - 2022-02-24 20:44:11.286534: step 131150, total loss = 0.60, batch loss = 0.34 (255.6 examples/sec; 0.031 sec/batch; 0h:35m:39s remains)
INFO - root - 2022-02-24 20:44:11.630830: step 131160, total loss = 0.60, batch loss = 0.34 (157.5 examples/sec; 0.051 sec/batch; 0h:57m:52s remains)
INFO - root - 2022-02-24 20:44:12.008345: step 131170, total loss = 0.56, batch loss = 0.30 (268.6 examples/sec; 0.030 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:44:12.346627: step 131180, total loss = 0.59, batch loss = 0.33 (348.2 examples/sec; 0.023 sec/batch; 0h:26m:09s remains)
INFO - root - 2022-02-24 20:44:12.694935: step 131190, total loss = 0.52, batch loss = 0.26 (214.6 examples/sec; 0.037 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:44:13.150829: step 131200, total loss = 0.51, batch loss = 0.25 (176.4 examples/sec; 0.045 sec/batch; 0h:51m:37s remains)
INFO - root - 2022-02-24 20:44:13.593346: step 131210, total loss = 0.47, batch loss = 0.21 (340.0 examples/sec; 0.024 sec/batch; 0h:26m:46s remains)
INFO - root - 2022-02-24 20:44:13.959073: step 131220, total loss = 0.60, batch loss = 0.34 (353.5 examples/sec; 0.023 sec/batch; 0h:25m:45s remains)
INFO - root - 2022-02-24 20:44:14.294408: step 131230, total loss = 0.46, batch loss = 0.20 (354.8 examples/sec; 0.023 sec/batch; 0h:25m:39s remains)
INFO - root - 2022-02-24 20:44:14.635249: step 131240, total loss = 0.59, batch loss = 0.33 (346.7 examples/sec; 0.023 sec/batch; 0h:26m:15s remains)
INFO - root - 2022-02-24 20:44:14.976448: step 131250, total loss = 0.59, batch loss = 0.33 (280.5 examples/sec; 0.029 sec/batch; 0h:32m:26s remains)
INFO - root - 2022-02-24 20:44:15.386550: step 131260, total loss = 0.55, batch loss = 0.29 (322.1 examples/sec; 0.025 sec/batch; 0h:28m:14s remains)
INFO - root - 2022-02-24 20:44:15.819431: step 131270, total loss = 0.51, batch loss = 0.25 (296.8 examples/sec; 0.027 sec/batch; 0h:30m:38s remains)
INFO - root - 2022-02-24 20:44:16.401075: step 131280, total loss = 0.50, batch loss = 0.24 (209.3 examples/sec; 0.038 sec/batch; 0h:43m:26s remains)
INFO - root - 2022-02-24 20:44:16.933207: step 131290, total loss = 0.49, batch loss = 0.23 (145.6 examples/sec; 0.055 sec/batch; 1h:02m:26s remains)
INFO - root - 2022-02-24 20:44:17.881252: step 131300, total loss = 0.59, batch loss = 0.33 (285.0 examples/sec; 0.028 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 20:44:18.367574: step 131310, total loss = 0.48, batch loss = 0.22 (180.9 examples/sec; 0.044 sec/batch; 0h:50m:15s remains)
INFO - root - 2022-02-24 20:44:18.668568: step 131320, total loss = 0.63, batch loss = 0.38 (272.6 examples/sec; 0.029 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:44:18.999736: step 131330, total loss = 0.52, batch loss = 0.26 (325.5 examples/sec; 0.025 sec/batch; 0h:27m:55s remains)
INFO - root - 2022-02-24 20:44:19.332046: step 131340, total loss = 0.53, batch loss = 0.27 (143.8 examples/sec; 0.056 sec/batch; 1h:03m:12s remains)
INFO - root - 2022-02-24 20:44:19.698094: step 131350, total loss = 0.51, batch loss = 0.25 (246.9 examples/sec; 0.032 sec/batch; 0h:36m:48s remains)
INFO - root - 2022-02-24 20:44:20.166131: step 131360, total loss = 0.46, batch loss = 0.20 (167.2 examples/sec; 0.048 sec/batch; 0h:54m:19s remains)
INFO - root - 2022-02-24 20:44:20.456378: step 131370, total loss = 0.53, batch loss = 0.27 (359.6 examples/sec; 0.022 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 20:44:20.802473: step 131380, total loss = 0.52, batch loss = 0.26 (301.5 examples/sec; 0.027 sec/batch; 0h:30m:07s remains)
INFO - root - 2022-02-24 20:44:21.237529: step 131390, total loss = 0.56, batch loss = 0.30 (110.7 examples/sec; 0.072 sec/batch; 1h:22m:03s remains)
INFO - root - 2022-02-24 20:44:21.686618: step 131400, total loss = 0.52, batch loss = 0.26 (173.8 examples/sec; 0.046 sec/batch; 0h:52m:14s remains)
INFO - root - 2022-02-24 20:44:22.268719: step 131410, total loss = 0.52, batch loss = 0.27 (142.8 examples/sec; 0.056 sec/batch; 1h:03m:33s remains)
INFO - root - 2022-02-24 20:44:22.654549: step 131420, total loss = 0.55, batch loss = 0.29 (166.3 examples/sec; 0.048 sec/batch; 0h:54m:35s remains)
INFO - root - 2022-02-24 20:44:23.114997: step 131430, total loss = 0.72, batch loss = 0.46 (196.4 examples/sec; 0.041 sec/batch; 0h:46m:12s remains)
INFO - root - 2022-02-24 20:44:23.400486: step 131440, total loss = 0.56, batch loss = 0.30 (345.3 examples/sec; 0.023 sec/batch; 0h:26m:16s remains)
INFO - root - 2022-02-24 20:44:23.664804: step 131450, total loss = 0.56, batch loss = 0.30 (240.2 examples/sec; 0.033 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:44:23.979209: step 131460, total loss = 0.56, batch loss = 0.30 (253.4 examples/sec; 0.032 sec/batch; 0h:35m:47s remains)
INFO - root - 2022-02-24 20:44:24.451311: step 131470, total loss = 0.56, batch loss = 0.30 (178.7 examples/sec; 0.045 sec/batch; 0h:50m:46s remains)
INFO - root - 2022-02-24 20:44:24.841461: step 131480, total loss = 0.48, batch loss = 0.22 (337.6 examples/sec; 0.024 sec/batch; 0h:26m:51s remains)
INFO - root - 2022-02-24 20:44:25.161876: step 131490, total loss = 0.50, batch loss = 0.24 (332.2 examples/sec; 0.024 sec/batch; 0h:27m:17s remains)
INFO - root - 2022-02-24 20:44:25.499287: step 131500, total loss = 0.53, batch loss = 0.27 (322.5 examples/sec; 0.025 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 20:44:25.889450: step 131510, total loss = 0.53, batch loss = 0.27 (211.1 examples/sec; 0.038 sec/batch; 0h:42m:56s remains)
INFO - root - 2022-02-24 20:44:26.361670: step 131520, total loss = 0.54, batch loss = 0.28 (143.5 examples/sec; 0.056 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 20:44:26.778356: step 131530, total loss = 0.51, batch loss = 0.25 (284.5 examples/sec; 0.028 sec/batch; 0h:31m:51s remains)
INFO - root - 2022-02-24 20:44:27.086417: step 131540, total loss = 0.65, batch loss = 0.39 (204.6 examples/sec; 0.039 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:44:27.524076: step 131550, total loss = 0.63, batch loss = 0.37 (280.8 examples/sec; 0.028 sec/batch; 0h:32m:15s remains)
INFO - root - 2022-02-24 20:44:27.897598: step 131560, total loss = 0.53, batch loss = 0.27 (143.5 examples/sec; 0.056 sec/batch; 1h:03m:06s remains)
INFO - root - 2022-02-24 20:44:28.340691: step 131570, total loss = 0.63, batch loss = 0.37 (135.3 examples/sec; 0.059 sec/batch; 1h:06m:57s remains)
INFO - root - 2022-02-24 20:44:28.794890: step 131580, total loss = 0.45, batch loss = 0.19 (124.0 examples/sec; 0.065 sec/batch; 1h:13m:01s remains)
INFO - root - 2022-02-24 20:44:29.198472: step 131590, total loss = 0.54, batch loss = 0.28 (354.0 examples/sec; 0.023 sec/batch; 0h:25m:34s remains)
INFO - root - 2022-02-24 20:44:29.620708: step 131600, total loss = 0.49, batch loss = 0.23 (198.8 examples/sec; 0.040 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:44:30.014638: step 131610, total loss = 0.60, batch loss = 0.34 (251.4 examples/sec; 0.032 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 20:44:30.395136: step 131620, total loss = 0.57, batch loss = 0.31 (263.8 examples/sec; 0.030 sec/batch; 0h:34m:18s remains)
INFO - root - 2022-02-24 20:44:30.847606: step 131630, total loss = 0.65, batch loss = 0.39 (302.2 examples/sec; 0.026 sec/batch; 0h:29m:56s remains)
INFO - root - 2022-02-24 20:44:31.187848: step 131640, total loss = 0.56, batch loss = 0.30 (331.9 examples/sec; 0.024 sec/batch; 0h:27m:15s remains)
INFO - root - 2022-02-24 20:44:31.512752: step 131650, total loss = 0.67, batch loss = 0.41 (228.3 examples/sec; 0.035 sec/batch; 0h:39m:37s remains)
INFO - root - 2022-02-24 20:44:31.863200: step 131660, total loss = 0.48, batch loss = 0.22 (317.8 examples/sec; 0.025 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 20:44:32.846719: step 131670, total loss = 0.70, batch loss = 0.44 (179.6 examples/sec; 0.045 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:44:33.328917: step 131680, total loss = 0.49, batch loss = 0.23 (157.4 examples/sec; 0.051 sec/batch; 0h:57m:26s remains)
INFO - root - 2022-02-24 20:44:33.723209: step 131690, total loss = 0.57, batch loss = 0.31 (89.9 examples/sec; 0.089 sec/batch; 1h:40m:32s remains)
INFO - root - 2022-02-24 20:44:34.115911: step 131700, total loss = 0.55, batch loss = 0.29 (143.4 examples/sec; 0.056 sec/batch; 1h:03m:02s remains)
INFO - root - 2022-02-24 20:44:34.521388: step 131710, total loss = 0.52, batch loss = 0.26 (328.1 examples/sec; 0.024 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:44:34.865830: step 131720, total loss = 0.54, batch loss = 0.28 (304.3 examples/sec; 0.026 sec/batch; 0h:29m:41s remains)
INFO - root - 2022-02-24 20:44:35.252820: step 131730, total loss = 0.61, batch loss = 0.35 (132.6 examples/sec; 0.060 sec/batch; 1h:08m:07s remains)
INFO - root - 2022-02-24 20:44:35.666511: step 131740, total loss = 0.61, batch loss = 0.35 (216.7 examples/sec; 0.037 sec/batch; 0h:41m:41s remains)
INFO - root - 2022-02-24 20:44:35.962992: step 131750, total loss = 0.50, batch loss = 0.24 (287.1 examples/sec; 0.028 sec/batch; 0h:31m:27s remains)
INFO - root - 2022-02-24 20:44:36.326822: step 131760, total loss = 0.51, batch loss = 0.25 (332.1 examples/sec; 0.024 sec/batch; 0h:27m:11s remains)
INFO - root - 2022-02-24 20:44:36.719016: step 131770, total loss = 0.51, batch loss = 0.25 (154.3 examples/sec; 0.052 sec/batch; 0h:58m:32s remains)
INFO - root - 2022-02-24 20:44:37.063221: step 131780, total loss = 0.58, batch loss = 0.32 (350.9 examples/sec; 0.023 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 20:44:37.540390: step 131790, total loss = 0.66, batch loss = 0.40 (188.7 examples/sec; 0.042 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:44:38.146639: step 131800, total loss = 0.47, batch loss = 0.21 (147.8 examples/sec; 0.054 sec/batch; 1h:01m:03s remains)
INFO - root - 2022-02-24 20:44:38.575910: step 131810, total loss = 0.57, batch loss = 0.31 (206.7 examples/sec; 0.039 sec/batch; 0h:43m:40s remains)
INFO - root - 2022-02-24 20:44:38.915867: step 131820, total loss = 0.51, batch loss = 0.25 (207.8 examples/sec; 0.038 sec/batch; 0h:43m:25s remains)
INFO - root - 2022-02-24 20:44:39.329430: step 131830, total loss = 0.49, batch loss = 0.23 (187.3 examples/sec; 0.043 sec/batch; 0h:48m:10s remains)
INFO - root - 2022-02-24 20:44:39.783475: step 131840, total loss = 0.48, batch loss = 0.22 (250.2 examples/sec; 0.032 sec/batch; 0h:36m:02s remains)
INFO - root - 2022-02-24 20:44:40.194707: step 131850, total loss = 0.51, batch loss = 0.25 (328.7 examples/sec; 0.024 sec/batch; 0h:27m:26s remains)
INFO - root - 2022-02-24 20:44:40.506936: step 131860, total loss = 0.64, batch loss = 0.38 (285.0 examples/sec; 0.028 sec/batch; 0h:31m:38s remains)
INFO - root - 2022-02-24 20:44:40.808936: step 131870, total loss = 0.66, batch loss = 0.40 (171.2 examples/sec; 0.047 sec/batch; 0h:52m:40s remains)
INFO - root - 2022-02-24 20:44:41.111823: step 131880, total loss = 0.49, batch loss = 0.23 (254.3 examples/sec; 0.031 sec/batch; 0h:35m:27s remains)
INFO - root - 2022-02-24 20:44:41.575271: step 131890, total loss = 0.71, batch loss = 0.45 (100.9 examples/sec; 0.079 sec/batch; 1h:29m:21s remains)
INFO - root - 2022-02-24 20:44:42.042449: step 131900, total loss = 0.56, batch loss = 0.30 (114.3 examples/sec; 0.070 sec/batch; 1h:18m:53s remains)
INFO - root - 2022-02-24 20:44:42.430793: step 131910, total loss = 0.53, batch loss = 0.27 (220.1 examples/sec; 0.036 sec/batch; 0h:40m:57s remains)
INFO - root - 2022-02-24 20:44:42.761484: step 131920, total loss = 0.53, batch loss = 0.27 (294.1 examples/sec; 0.027 sec/batch; 0h:30m:38s remains)
INFO - root - 2022-02-24 20:44:43.057518: step 131930, total loss = 0.45, batch loss = 0.19 (271.6 examples/sec; 0.029 sec/batch; 0h:33m:10s remains)
INFO - root - 2022-02-24 20:44:43.443267: step 131940, total loss = 0.49, batch loss = 0.23 (270.2 examples/sec; 0.030 sec/batch; 0h:33m:20s remains)
INFO - root - 2022-02-24 20:44:43.914935: step 131950, total loss = 0.58, batch loss = 0.32 (283.2 examples/sec; 0.028 sec/batch; 0h:31m:48s remains)
INFO - root - 2022-02-24 20:44:44.361698: step 131960, total loss = 0.55, batch loss = 0.29 (227.0 examples/sec; 0.035 sec/batch; 0h:39m:40s remains)
INFO - root - 2022-02-24 20:44:44.723723: step 131970, total loss = 0.60, batch loss = 0.34 (306.0 examples/sec; 0.026 sec/batch; 0h:29m:25s remains)
INFO - root - 2022-02-24 20:44:45.016830: step 131980, total loss = 0.64, batch loss = 0.38 (368.7 examples/sec; 0.022 sec/batch; 0h:24m:25s remains)
INFO - root - 2022-02-24 20:44:45.343707: step 131990, total loss = 0.51, batch loss = 0.25 (158.9 examples/sec; 0.050 sec/batch; 0h:56m:38s remains)
INFO - root - 2022-02-24 20:44:45.784940: step 132000, total loss = 0.58, batch loss = 0.32 (103.3 examples/sec; 0.077 sec/batch; 1h:27m:08s remains)
INFO - root - 2022-02-24 20:44:46.279210: step 132010, total loss = 0.56, batch loss = 0.30 (258.0 examples/sec; 0.031 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:44:46.674005: step 132020, total loss = 0.56, batch loss = 0.30 (326.6 examples/sec; 0.024 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:44:46.987646: step 132030, total loss = 0.52, batch loss = 0.26 (300.9 examples/sec; 0.027 sec/batch; 0h:29m:53s remains)
INFO - root - 2022-02-24 20:44:47.321675: step 132040, total loss = 0.52, batch loss = 0.26 (256.1 examples/sec; 0.031 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:44:47.614275: step 132050, total loss = 0.52, batch loss = 0.26 (223.0 examples/sec; 0.036 sec/batch; 0h:40m:19s remains)
INFO - root - 2022-02-24 20:44:48.160951: step 132060, total loss = 0.68, batch loss = 0.42 (113.9 examples/sec; 0.070 sec/batch; 1h:18m:58s remains)
INFO - root - 2022-02-24 20:44:48.858511: step 132070, total loss = 0.49, batch loss = 0.23 (142.3 examples/sec; 0.056 sec/batch; 1h:03m:11s remains)
INFO - root - 2022-02-24 20:44:49.197848: step 132080, total loss = 0.67, batch loss = 0.41 (311.7 examples/sec; 0.026 sec/batch; 0h:28m:50s remains)
INFO - root - 2022-02-24 20:44:49.534507: step 132090, total loss = 0.51, batch loss = 0.25 (254.6 examples/sec; 0.031 sec/batch; 0h:35m:18s remains)
INFO - root - 2022-02-24 20:44:49.898889: step 132100, total loss = 0.52, batch loss = 0.26 (363.3 examples/sec; 0.022 sec/batch; 0h:24m:43s remains)
INFO - root - 2022-02-24 20:44:50.362934: step 132110, total loss = 0.58, batch loss = 0.32 (358.4 examples/sec; 0.022 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 20:44:50.843604: step 132120, total loss = 0.56, batch loss = 0.30 (153.4 examples/sec; 0.052 sec/batch; 0h:58m:33s remains)
INFO - root - 2022-02-24 20:44:51.392019: step 132130, total loss = 0.60, batch loss = 0.34 (359.7 examples/sec; 0.022 sec/batch; 0h:24m:58s remains)
INFO - root - 2022-02-24 20:44:51.841153: step 132140, total loss = 0.53, batch loss = 0.27 (201.8 examples/sec; 0.040 sec/batch; 0h:44m:30s remains)
INFO - root - 2022-02-24 20:44:52.193545: step 132150, total loss = 0.51, batch loss = 0.25 (143.0 examples/sec; 0.056 sec/batch; 1h:02m:46s remains)
INFO - root - 2022-02-24 20:44:52.541526: step 132160, total loss = 0.57, batch loss = 0.31 (294.7 examples/sec; 0.027 sec/batch; 0h:30m:27s remains)
INFO - root - 2022-02-24 20:44:53.009293: step 132170, total loss = 0.65, batch loss = 0.40 (320.2 examples/sec; 0.025 sec/batch; 0h:28m:02s remains)
INFO - root - 2022-02-24 20:44:53.427273: step 132180, total loss = 0.67, batch loss = 0.41 (346.0 examples/sec; 0.023 sec/batch; 0h:25m:56s remains)
INFO - root - 2022-02-24 20:44:54.224095: step 132190, total loss = 0.61, batch loss = 0.36 (141.6 examples/sec; 0.057 sec/batch; 1h:03m:23s remains)
INFO - root - 2022-02-24 20:44:54.725648: step 132200, total loss = 0.49, batch loss = 0.23 (186.1 examples/sec; 0.043 sec/batch; 0h:48m:13s remains)
INFO - root - 2022-02-24 20:44:55.132371: step 132210, total loss = 0.51, batch loss = 0.25 (325.7 examples/sec; 0.025 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:44:55.463220: step 132220, total loss = 0.55, batch loss = 0.29 (367.7 examples/sec; 0.022 sec/batch; 0h:24m:23s remains)
INFO - root - 2022-02-24 20:44:55.838511: step 132230, total loss = 0.57, batch loss = 0.31 (316.9 examples/sec; 0.025 sec/batch; 0h:28m:18s remains)
INFO - root - 2022-02-24 20:44:56.219191: step 132240, total loss = 0.54, batch loss = 0.28 (325.8 examples/sec; 0.025 sec/batch; 0h:27m:31s remains)
INFO - root - 2022-02-24 20:44:56.574846: step 132250, total loss = 0.72, batch loss = 0.46 (145.9 examples/sec; 0.055 sec/batch; 1h:01m:27s remains)
INFO - root - 2022-02-24 20:44:57.013258: step 132260, total loss = 0.54, batch loss = 0.28 (241.3 examples/sec; 0.033 sec/batch; 0h:37m:09s remains)
INFO - root - 2022-02-24 20:44:57.375144: step 132270, total loss = 0.57, batch loss = 0.31 (109.0 examples/sec; 0.073 sec/batch; 1h:22m:14s remains)
INFO - root - 2022-02-24 20:44:57.731225: step 132280, total loss = 0.50, batch loss = 0.24 (341.7 examples/sec; 0.023 sec/batch; 0h:26m:13s remains)
INFO - root - 2022-02-24 20:44:58.051728: step 132290, total loss = 0.55, batch loss = 0.29 (222.8 examples/sec; 0.036 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:44:58.353251: step 132300, total loss = 0.62, batch loss = 0.36 (240.8 examples/sec; 0.033 sec/batch; 0h:37m:12s remains)
INFO - root - 2022-02-24 20:44:58.852536: step 132310, total loss = 0.57, batch loss = 0.31 (145.1 examples/sec; 0.055 sec/batch; 1h:01m:44s remains)
INFO - root - 2022-02-24 20:44:59.318033: step 132320, total loss = 0.53, batch loss = 0.27 (370.6 examples/sec; 0.022 sec/batch; 0h:24m:10s remains)
INFO - root - 2022-02-24 20:44:59.672025: step 132330, total loss = 0.56, batch loss = 0.30 (139.2 examples/sec; 0.057 sec/batch; 1h:04m:19s remains)
INFO - root - 2022-02-24 20:45:00.021103: step 132340, total loss = 0.50, batch loss = 0.24 (189.9 examples/sec; 0.042 sec/batch; 0h:47m:08s remains)
INFO - root - 2022-02-24 20:45:00.366770: step 132350, total loss = 0.51, batch loss = 0.25 (320.9 examples/sec; 0.025 sec/batch; 0h:27m:53s remains)
INFO - root - 2022-02-24 20:45:00.736672: step 132360, total loss = 0.64, batch loss = 0.38 (211.0 examples/sec; 0.038 sec/batch; 0h:42m:25s remains)
INFO - root - 2022-02-24 20:45:01.147167: step 132370, total loss = 0.62, batch loss = 0.36 (186.1 examples/sec; 0.043 sec/batch; 0h:48m:05s remains)
INFO - root - 2022-02-24 20:45:01.505360: step 132380, total loss = 0.52, batch loss = 0.26 (359.3 examples/sec; 0.022 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 20:45:01.820721: step 132390, total loss = 0.57, batch loss = 0.31 (236.7 examples/sec; 0.034 sec/batch; 0h:37m:47s remains)
INFO - root - 2022-02-24 20:45:02.149973: step 132400, total loss = 0.61, batch loss = 0.35 (346.9 examples/sec; 0.023 sec/batch; 0h:25m:47s remains)
INFO - root - 2022-02-24 20:45:02.590008: step 132410, total loss = 0.55, batch loss = 0.29 (328.5 examples/sec; 0.024 sec/batch; 0h:27m:13s remains)
INFO - root - 2022-02-24 20:45:02.940672: step 132420, total loss = 0.60, batch loss = 0.34 (318.7 examples/sec; 0.025 sec/batch; 0h:28m:03s remains)
INFO - root - 2022-02-24 20:45:03.388059: step 132430, total loss = 0.55, batch loss = 0.29 (341.1 examples/sec; 0.023 sec/batch; 0h:26m:13s remains)
INFO - root - 2022-02-24 20:45:03.709645: step 132440, total loss = 0.50, batch loss = 0.24 (153.5 examples/sec; 0.052 sec/batch; 0h:58m:15s remains)
INFO - root - 2022-02-24 20:45:04.092405: step 132450, total loss = 0.46, batch loss = 0.20 (183.0 examples/sec; 0.044 sec/batch; 0h:48m:50s remains)
INFO - root - 2022-02-24 20:45:04.475196: step 132460, total loss = 0.56, batch loss = 0.30 (142.7 examples/sec; 0.056 sec/batch; 1h:02m:39s remains)
INFO - root - 2022-02-24 20:45:04.917448: step 132470, total loss = 0.55, batch loss = 0.29 (100.9 examples/sec; 0.079 sec/batch; 1h:28m:34s remains)
INFO - root - 2022-02-24 20:45:05.327548: step 132480, total loss = 0.52, batch loss = 0.26 (189.4 examples/sec; 0.042 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 20:45:05.598838: step 132490, total loss = 0.43, batch loss = 0.17 (265.0 examples/sec; 0.030 sec/batch; 0h:33m:42s remains)
INFO - root - 2022-02-24 20:45:05.972989: step 132500, total loss = 0.53, batch loss = 0.27 (279.1 examples/sec; 0.029 sec/batch; 0h:32m:00s remains)
INFO - root - 2022-02-24 20:45:06.546829: step 132510, total loss = 0.56, batch loss = 0.30 (154.3 examples/sec; 0.052 sec/batch; 0h:57m:53s remains)
INFO - root - 2022-02-24 20:45:06.921829: step 132520, total loss = 0.60, batch loss = 0.34 (160.2 examples/sec; 0.050 sec/batch; 0h:55m:44s remains)
INFO - root - 2022-02-24 20:45:07.390625: step 132530, total loss = 0.58, batch loss = 0.32 (141.6 examples/sec; 0.057 sec/batch; 1h:03m:04s remains)
INFO - root - 2022-02-24 20:45:07.918541: step 132540, total loss = 0.53, batch loss = 0.28 (207.8 examples/sec; 0.038 sec/batch; 0h:42m:57s remains)
INFO - root - 2022-02-24 20:45:08.424154: step 132550, total loss = 0.46, batch loss = 0.20 (136.8 examples/sec; 0.058 sec/batch; 1h:05m:14s remains)
INFO - root - 2022-02-24 20:45:08.993626: step 132560, total loss = 0.55, batch loss = 0.29 (194.7 examples/sec; 0.041 sec/batch; 0h:45m:50s remains)
INFO - root - 2022-02-24 20:45:09.993823: step 132570, total loss = 0.50, batch loss = 0.24 (13.5 examples/sec; 0.591 sec/batch; 10h:59m:03s remains)
INFO - root - 2022-02-24 20:45:10.363278: step 132580, total loss = 0.52, batch loss = 0.26 (177.0 examples/sec; 0.045 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:45:10.671249: step 132590, total loss = 0.50, batch loss = 0.24 (259.7 examples/sec; 0.031 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:45:11.007197: step 132600, total loss = 0.53, batch loss = 0.27 (146.9 examples/sec; 0.054 sec/batch; 1h:00m:42s remains)
INFO - root - 2022-02-24 20:45:11.474365: step 132610, total loss = 0.48, batch loss = 0.22 (172.5 examples/sec; 0.046 sec/batch; 0h:51m:42s remains)
INFO - root - 2022-02-24 20:45:11.887479: step 132620, total loss = 0.49, batch loss = 0.23 (338.9 examples/sec; 0.024 sec/batch; 0h:26m:18s remains)
INFO - root - 2022-02-24 20:45:12.288546: step 132630, total loss = 0.56, batch loss = 0.30 (173.6 examples/sec; 0.046 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:45:12.573899: step 132640, total loss = 0.60, batch loss = 0.34 (338.3 examples/sec; 0.024 sec/batch; 0h:26m:21s remains)
INFO - root - 2022-02-24 20:45:12.905235: step 132650, total loss = 0.51, batch loss = 0.25 (218.3 examples/sec; 0.037 sec/batch; 0h:40m:49s remains)
INFO - root - 2022-02-24 20:45:13.327633: step 132660, total loss = 0.52, batch loss = 0.26 (197.1 examples/sec; 0.041 sec/batch; 0h:45m:12s remains)
INFO - root - 2022-02-24 20:45:13.714661: step 132670, total loss = 0.52, batch loss = 0.26 (155.6 examples/sec; 0.051 sec/batch; 0h:57m:15s remains)
INFO - root - 2022-02-24 20:45:14.069849: step 132680, total loss = 0.48, batch loss = 0.22 (187.1 examples/sec; 0.043 sec/batch; 0h:47m:37s remains)
INFO - root - 2022-02-24 20:45:14.583844: step 132690, total loss = 0.55, batch loss = 0.29 (100.7 examples/sec; 0.079 sec/batch; 1h:28m:29s remains)
INFO - root - 2022-02-24 20:45:14.952139: step 132700, total loss = 0.46, batch loss = 0.20 (221.6 examples/sec; 0.036 sec/batch; 0h:40m:11s remains)
INFO - root - 2022-02-24 20:45:15.359322: step 132710, total loss = 0.47, batch loss = 0.21 (248.5 examples/sec; 0.032 sec/batch; 0h:35m:49s remains)
INFO - root - 2022-02-24 20:45:15.669403: step 132720, total loss = 0.50, batch loss = 0.24 (311.6 examples/sec; 0.026 sec/batch; 0h:28m:34s remains)
INFO - root - 2022-02-24 20:45:16.047076: step 132730, total loss = 0.52, batch loss = 0.26 (292.0 examples/sec; 0.027 sec/batch; 0h:30m:29s remains)
INFO - root - 2022-02-24 20:45:16.461467: step 132740, total loss = 0.56, batch loss = 0.30 (309.8 examples/sec; 0.026 sec/batch; 0h:28m:43s remains)
INFO - root - 2022-02-24 20:45:16.796668: step 132750, total loss = 0.51, batch loss = 0.25 (308.8 examples/sec; 0.026 sec/batch; 0h:28m:49s remains)
INFO - root - 2022-02-24 20:45:17.142878: step 132760, total loss = 0.48, batch loss = 0.22 (132.7 examples/sec; 0.060 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:45:17.469140: step 132770, total loss = 0.57, batch loss = 0.31 (214.2 examples/sec; 0.037 sec/batch; 0h:41m:32s remains)
INFO - root - 2022-02-24 20:45:17.829173: step 132780, total loss = 0.61, batch loss = 0.35 (176.9 examples/sec; 0.045 sec/batch; 0h:50m:16s remains)
INFO - root - 2022-02-24 20:45:18.179632: step 132790, total loss = 0.51, batch loss = 0.25 (385.9 examples/sec; 0.021 sec/batch; 0h:23m:03s remains)
INFO - root - 2022-02-24 20:45:18.637401: step 132800, total loss = 0.75, batch loss = 0.49 (349.6 examples/sec; 0.023 sec/batch; 0h:25m:26s remains)
INFO - root - 2022-02-24 20:45:18.998688: step 132810, total loss = 0.63, batch loss = 0.37 (321.6 examples/sec; 0.025 sec/batch; 0h:27m:39s remains)
INFO - root - 2022-02-24 20:45:19.262481: step 132820, total loss = 0.55, batch loss = 0.29 (216.9 examples/sec; 0.037 sec/batch; 0h:40m:59s remains)
INFO - root - 2022-02-24 20:45:19.628215: step 132830, total loss = 0.73, batch loss = 0.47 (309.6 examples/sec; 0.026 sec/batch; 0h:28m:42s remains)
INFO - root - 2022-02-24 20:45:20.036596: step 132840, total loss = 0.49, batch loss = 0.24 (174.9 examples/sec; 0.046 sec/batch; 0h:50m:49s remains)
INFO - root - 2022-02-24 20:45:20.510413: step 132850, total loss = 0.60, batch loss = 0.34 (241.9 examples/sec; 0.033 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:45:21.060146: step 132860, total loss = 0.54, batch loss = 0.28 (123.8 examples/sec; 0.065 sec/batch; 1h:11m:46s remains)
INFO - root - 2022-02-24 20:45:21.356291: step 132870, total loss = 0.65, batch loss = 0.39 (315.1 examples/sec; 0.025 sec/batch; 0h:28m:11s remains)
INFO - root - 2022-02-24 20:45:21.668349: step 132880, total loss = 0.57, batch loss = 0.31 (243.3 examples/sec; 0.033 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:45:22.028664: step 132890, total loss = 0.56, batch loss = 0.31 (207.3 examples/sec; 0.039 sec/batch; 0h:42m:50s remains)
INFO - root - 2022-02-24 20:45:22.414078: step 132900, total loss = 0.59, batch loss = 0.33 (264.6 examples/sec; 0.030 sec/batch; 0h:33m:33s remains)
INFO - root - 2022-02-24 20:45:22.869726: step 132910, total loss = 0.47, batch loss = 0.21 (156.5 examples/sec; 0.051 sec/batch; 0h:56m:44s remains)
INFO - root - 2022-02-24 20:45:23.242606: step 132920, total loss = 0.49, batch loss = 0.23 (185.5 examples/sec; 0.043 sec/batch; 0h:47m:51s remains)
INFO - root - 2022-02-24 20:45:23.548800: step 132930, total loss = 0.69, batch loss = 0.43 (265.0 examples/sec; 0.030 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:45:23.911936: step 132940, total loss = 0.51, batch loss = 0.25 (131.8 examples/sec; 0.061 sec/batch; 1h:07m:18s remains)
INFO - root - 2022-02-24 20:45:24.507692: step 132950, total loss = 0.53, batch loss = 0.27 (173.6 examples/sec; 0.046 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:45:25.398424: step 132960, total loss = 0.45, batch loss = 0.20 (343.1 examples/sec; 0.023 sec/batch; 0h:25m:51s remains)
INFO - root - 2022-02-24 20:45:25.891245: step 132970, total loss = 0.53, batch loss = 0.27 (221.8 examples/sec; 0.036 sec/batch; 0h:40m:00s remains)
INFO - root - 2022-02-24 20:45:26.258321: step 132980, total loss = 0.51, batch loss = 0.25 (153.1 examples/sec; 0.052 sec/batch; 0h:57m:55s remains)
INFO - root - 2022-02-24 20:45:26.603491: step 132990, total loss = 0.51, batch loss = 0.25 (202.6 examples/sec; 0.039 sec/batch; 0h:43m:45s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-132999 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-132999 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:45:27.338918: step 133000, total loss = 0.46, batch loss = 0.20 (321.9 examples/sec; 0.025 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:45:27.691003: step 133010, total loss = 0.54, batch loss = 0.28 (333.2 examples/sec; 0.024 sec/batch; 0h:26m:36s remains)
INFO - root - 2022-02-24 20:45:27.960575: step 133020, total loss = 0.53, batch loss = 0.27 (175.3 examples/sec; 0.046 sec/batch; 0h:50m:34s remains)
INFO - root - 2022-02-24 20:45:28.298620: step 133030, total loss = 0.51, batch loss = 0.25 (234.3 examples/sec; 0.034 sec/batch; 0h:37m:49s remains)
INFO - root - 2022-02-24 20:45:28.634198: step 133040, total loss = 0.52, batch loss = 0.26 (358.2 examples/sec; 0.022 sec/batch; 0h:24m:44s remains)
INFO - root - 2022-02-24 20:45:29.101999: step 133050, total loss = 0.66, batch loss = 0.41 (146.6 examples/sec; 0.055 sec/batch; 1h:00m:25s remains)
INFO - root - 2022-02-24 20:45:29.524322: step 133060, total loss = 0.60, batch loss = 0.34 (235.2 examples/sec; 0.034 sec/batch; 0h:37m:39s remains)
INFO - root - 2022-02-24 20:45:29.954423: step 133070, total loss = 0.56, batch loss = 0.30 (249.5 examples/sec; 0.032 sec/batch; 0h:35m:29s remains)
INFO - root - 2022-02-24 20:45:30.751033: step 133080, total loss = 0.54, batch loss = 0.28 (351.5 examples/sec; 0.023 sec/batch; 0h:25m:11s remains)
INFO - root - 2022-02-24 20:45:31.260860: step 133090, total loss = 0.49, batch loss = 0.23 (110.3 examples/sec; 0.073 sec/batch; 1h:20m:15s remains)
INFO - root - 2022-02-24 20:45:31.598732: step 133100, total loss = 0.56, batch loss = 0.30 (267.2 examples/sec; 0.030 sec/batch; 0h:33m:07s remains)
INFO - root - 2022-02-24 20:45:32.040806: step 133110, total loss = 0.62, batch loss = 0.36 (215.1 examples/sec; 0.037 sec/batch; 0h:41m:09s remains)
INFO - root - 2022-02-24 20:45:32.333063: step 133120, total loss = 0.51, batch loss = 0.25 (213.8 examples/sec; 0.037 sec/batch; 0h:41m:23s remains)
INFO - root - 2022-02-24 20:45:32.635689: step 133130, total loss = 0.59, batch loss = 0.33 (263.6 examples/sec; 0.030 sec/batch; 0h:33m:34s remains)
INFO - root - 2022-02-24 20:45:33.072920: step 133140, total loss = 0.69, batch loss = 0.43 (249.3 examples/sec; 0.032 sec/batch; 0h:35m:29s remains)
INFO - root - 2022-02-24 20:45:33.513848: step 133150, total loss = 0.54, batch loss = 0.28 (155.9 examples/sec; 0.051 sec/batch; 0h:56m:43s remains)
INFO - root - 2022-02-24 20:45:33.854325: step 133160, total loss = 0.56, batch loss = 0.30 (154.0 examples/sec; 0.052 sec/batch; 0h:57m:26s remains)
INFO - root - 2022-02-24 20:45:34.152378: step 133170, total loss = 0.54, batch loss = 0.28 (319.4 examples/sec; 0.025 sec/batch; 0h:27m:41s remains)
INFO - root - 2022-02-24 20:45:34.456730: step 133180, total loss = 0.47, batch loss = 0.21 (205.8 examples/sec; 0.039 sec/batch; 0h:42m:58s remains)
INFO - root - 2022-02-24 20:45:34.800406: step 133190, total loss = 0.58, batch loss = 0.32 (243.7 examples/sec; 0.033 sec/batch; 0h:36m:16s remains)
INFO - root - 2022-02-24 20:45:35.251051: step 133200, total loss = 0.58, batch loss = 0.32 (233.1 examples/sec; 0.034 sec/batch; 0h:37m:55s remains)
INFO - root - 2022-02-24 20:45:35.778566: step 133210, total loss = 0.58, batch loss = 0.32 (360.5 examples/sec; 0.022 sec/batch; 0h:24m:31s remains)
INFO - root - 2022-02-24 20:45:36.102762: step 133220, total loss = 0.58, batch loss = 0.32 (346.4 examples/sec; 0.023 sec/batch; 0h:25m:30s remains)
INFO - root - 2022-02-24 20:45:36.365619: step 133230, total loss = 0.55, batch loss = 0.29 (345.1 examples/sec; 0.023 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 20:45:36.679768: step 133240, total loss = 0.49, batch loss = 0.23 (310.4 examples/sec; 0.026 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 20:45:36.929366: step 133250, total loss = 0.55, batch loss = 0.29 (275.4 examples/sec; 0.029 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:45:37.254961: step 133260, total loss = 0.63, batch loss = 0.37 (350.9 examples/sec; 0.023 sec/batch; 0h:25m:10s remains)
INFO - root - 2022-02-24 20:45:37.693449: step 133270, total loss = 0.47, batch loss = 0.21 (128.0 examples/sec; 0.062 sec/batch; 1h:08m:59s remains)
INFO - root - 2022-02-24 20:45:38.115171: step 133280, total loss = 0.69, batch loss = 0.43 (333.1 examples/sec; 0.024 sec/batch; 0h:26m:30s remains)
INFO - root - 2022-02-24 20:45:38.457154: step 133290, total loss = 0.62, batch loss = 0.36 (347.6 examples/sec; 0.023 sec/batch; 0h:25m:23s remains)
INFO - root - 2022-02-24 20:45:38.825201: step 133300, total loss = 0.48, batch loss = 0.23 (289.8 examples/sec; 0.028 sec/batch; 0h:30m:27s remains)
INFO - root - 2022-02-24 20:45:39.298436: step 133310, total loss = 0.52, batch loss = 0.26 (280.2 examples/sec; 0.029 sec/batch; 0h:31m:29s remains)
INFO - root - 2022-02-24 20:45:39.798220: step 133320, total loss = 0.52, batch loss = 0.27 (315.8 examples/sec; 0.025 sec/batch; 0h:27m:56s remains)
INFO - root - 2022-02-24 20:45:40.284018: step 133330, total loss = 0.44, batch loss = 0.18 (249.3 examples/sec; 0.032 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 20:45:40.672785: step 133340, total loss = 0.61, batch loss = 0.36 (174.6 examples/sec; 0.046 sec/batch; 0h:50m:31s remains)
INFO - root - 2022-02-24 20:45:41.035513: step 133350, total loss = 0.57, batch loss = 0.31 (323.7 examples/sec; 0.025 sec/batch; 0h:27m:14s remains)
INFO - root - 2022-02-24 20:45:41.426400: step 133360, total loss = 0.48, batch loss = 0.22 (327.5 examples/sec; 0.024 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 20:45:41.863276: step 133370, total loss = 0.75, batch loss = 0.49 (113.1 examples/sec; 0.071 sec/batch; 1h:17m:57s remains)
INFO - root - 2022-02-24 20:45:42.222813: step 133380, total loss = 0.46, batch loss = 0.20 (227.3 examples/sec; 0.035 sec/batch; 0h:38m:47s remains)
INFO - root - 2022-02-24 20:45:42.527608: step 133390, total loss = 0.57, batch loss = 0.31 (180.0 examples/sec; 0.044 sec/batch; 0h:48m:58s remains)
INFO - root - 2022-02-24 20:45:42.840248: step 133400, total loss = 0.54, batch loss = 0.28 (368.5 examples/sec; 0.022 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 20:45:43.321359: step 133410, total loss = 0.50, batch loss = 0.24 (162.4 examples/sec; 0.049 sec/batch; 0h:54m:16s remains)
INFO - root - 2022-02-24 20:45:43.686645: step 133420, total loss = 0.63, batch loss = 0.38 (333.1 examples/sec; 0.024 sec/batch; 0h:26m:26s remains)
INFO - root - 2022-02-24 20:45:44.049078: step 133430, total loss = 0.55, batch loss = 0.29 (184.5 examples/sec; 0.043 sec/batch; 0h:47m:44s remains)
INFO - root - 2022-02-24 20:45:44.338519: step 133440, total loss = 0.56, batch loss = 0.31 (294.1 examples/sec; 0.027 sec/batch; 0h:29m:56s remains)
INFO - root - 2022-02-24 20:45:44.681566: step 133450, total loss = 0.54, batch loss = 0.28 (313.4 examples/sec; 0.026 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:45:45.034700: step 133460, total loss = 0.59, batch loss = 0.33 (113.5 examples/sec; 0.071 sec/batch; 1h:17m:36s remains)
INFO - root - 2022-02-24 20:45:45.312315: step 133470, total loss = 0.65, batch loss = 0.39 (323.7 examples/sec; 0.025 sec/batch; 0h:27m:11s remains)
INFO - root - 2022-02-24 20:45:45.743597: step 133480, total loss = 0.52, batch loss = 0.26 (181.5 examples/sec; 0.044 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:45:46.169202: step 133490, total loss = 0.46, batch loss = 0.20 (362.8 examples/sec; 0.022 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:45:46.505955: step 133500, total loss = 0.54, batch loss = 0.28 (291.6 examples/sec; 0.027 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 20:45:46.875829: step 133510, total loss = 0.54, batch loss = 0.28 (347.6 examples/sec; 0.023 sec/batch; 0h:25m:18s remains)
INFO - root - 2022-02-24 20:45:47.150782: step 133520, total loss = 0.51, batch loss = 0.25 (375.5 examples/sec; 0.021 sec/batch; 0h:23m:25s remains)
INFO - root - 2022-02-24 20:45:47.678583: step 133530, total loss = 0.59, batch loss = 0.33 (81.3 examples/sec; 0.098 sec/batch; 1h:48m:14s remains)
INFO - root - 2022-02-24 20:45:48.135009: step 133540, total loss = 0.46, batch loss = 0.20 (143.3 examples/sec; 0.056 sec/batch; 1h:01m:23s remains)
INFO - root - 2022-02-24 20:45:48.437182: step 133550, total loss = 0.57, batch loss = 0.31 (222.2 examples/sec; 0.036 sec/batch; 0h:39m:34s remains)
INFO - root - 2022-02-24 20:45:48.857241: step 133560, total loss = 0.54, batch loss = 0.28 (136.2 examples/sec; 0.059 sec/batch; 1h:04m:33s remains)
INFO - root - 2022-02-24 20:45:49.162375: step 133570, total loss = 0.58, batch loss = 0.32 (324.4 examples/sec; 0.025 sec/batch; 0h:27m:06s remains)
INFO - root - 2022-02-24 20:45:49.565798: step 133580, total loss = 0.57, batch loss = 0.31 (106.0 examples/sec; 0.075 sec/batch; 1h:22m:54s remains)
INFO - root - 2022-02-24 20:45:50.066377: step 133590, total loss = 0.64, batch loss = 0.38 (73.9 examples/sec; 0.108 sec/batch; 1h:58m:52s remains)
INFO - root - 2022-02-24 20:45:50.474587: step 133600, total loss = 0.58, batch loss = 0.32 (159.8 examples/sec; 0.050 sec/batch; 0h:54m:59s remains)
INFO - root - 2022-02-24 20:45:51.039780: step 133610, total loss = 0.57, batch loss = 0.31 (149.6 examples/sec; 0.053 sec/batch; 0h:58m:43s remains)
INFO - root - 2022-02-24 20:45:51.474700: step 133620, total loss = 0.65, batch loss = 0.39 (125.6 examples/sec; 0.064 sec/batch; 1h:09m:57s remains)
INFO - root - 2022-02-24 20:45:51.923290: step 133630, total loss = 0.52, batch loss = 0.26 (348.2 examples/sec; 0.023 sec/batch; 0h:25m:13s remains)
INFO - root - 2022-02-24 20:45:52.289495: step 133640, total loss = 0.53, batch loss = 0.27 (171.7 examples/sec; 0.047 sec/batch; 0h:51m:08s remains)
INFO - root - 2022-02-24 20:45:52.671679: step 133650, total loss = 0.54, batch loss = 0.28 (330.5 examples/sec; 0.024 sec/batch; 0h:26m:34s remains)
INFO - root - 2022-02-24 20:45:53.192521: step 133660, total loss = 0.55, batch loss = 0.29 (175.8 examples/sec; 0.046 sec/batch; 0h:49m:55s remains)
INFO - root - 2022-02-24 20:45:53.861970: step 133670, total loss = 0.64, batch loss = 0.38 (249.9 examples/sec; 0.032 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:45:54.356238: step 133680, total loss = 0.49, batch loss = 0.23 (359.6 examples/sec; 0.022 sec/batch; 0h:24m:24s remains)
INFO - root - 2022-02-24 20:45:54.749721: step 133690, total loss = 0.54, batch loss = 0.28 (237.9 examples/sec; 0.034 sec/batch; 0h:36m:53s remains)
INFO - root - 2022-02-24 20:45:55.050740: step 133700, total loss = 0.54, batch loss = 0.28 (350.6 examples/sec; 0.023 sec/batch; 0h:25m:01s remains)
INFO - root - 2022-02-24 20:45:56.057205: step 133710, total loss = 0.64, batch loss = 0.38 (155.3 examples/sec; 0.052 sec/batch; 0h:56m:29s remains)
INFO - root - 2022-02-24 20:45:56.481859: step 133720, total loss = 0.60, batch loss = 0.35 (196.1 examples/sec; 0.041 sec/batch; 0h:44m:43s remains)
INFO - root - 2022-02-24 20:45:56.852278: step 133730, total loss = 0.51, batch loss = 0.25 (309.9 examples/sec; 0.026 sec/batch; 0h:28m:17s remains)
INFO - root - 2022-02-24 20:45:57.227290: step 133740, total loss = 0.69, batch loss = 0.43 (327.9 examples/sec; 0.024 sec/batch; 0h:26m:44s remains)
INFO - root - 2022-02-24 20:45:57.516707: step 133750, total loss = 0.69, batch loss = 0.43 (202.6 examples/sec; 0.039 sec/batch; 0h:43m:15s remains)
INFO - root - 2022-02-24 20:45:57.789326: step 133760, total loss = 0.47, batch loss = 0.21 (311.8 examples/sec; 0.026 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 20:45:58.297369: step 133770, total loss = 0.62, batch loss = 0.37 (134.5 examples/sec; 0.059 sec/batch; 1h:05m:09s remains)
INFO - root - 2022-02-24 20:45:58.782904: step 133780, total loss = 0.52, batch loss = 0.26 (237.2 examples/sec; 0.034 sec/batch; 0h:36m:56s remains)
INFO - root - 2022-02-24 20:45:59.069548: step 133790, total loss = 0.57, batch loss = 0.31 (343.2 examples/sec; 0.023 sec/batch; 0h:25m:31s remains)
INFO - root - 2022-02-24 20:45:59.395598: step 133800, total loss = 0.57, batch loss = 0.31 (227.8 examples/sec; 0.035 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:45:59.851870: step 133810, total loss = 0.51, batch loss = 0.25 (214.2 examples/sec; 0.037 sec/batch; 0h:40m:53s remains)
INFO - root - 2022-02-24 20:46:00.373984: step 133820, total loss = 0.49, batch loss = 0.23 (187.3 examples/sec; 0.043 sec/batch; 0h:46m:44s remains)
INFO - root - 2022-02-24 20:46:00.773216: step 133830, total loss = 0.47, batch loss = 0.21 (304.2 examples/sec; 0.026 sec/batch; 0h:28m:47s remains)
INFO - root - 2022-02-24 20:46:01.193315: step 133840, total loss = 0.55, batch loss = 0.29 (231.3 examples/sec; 0.035 sec/batch; 0h:37m:50s remains)
INFO - root - 2022-02-24 20:46:01.614486: step 133850, total loss = 0.54, batch loss = 0.28 (172.1 examples/sec; 0.046 sec/batch; 0h:50m:51s remains)
INFO - root - 2022-02-24 20:46:01.978781: step 133860, total loss = 0.52, batch loss = 0.26 (156.8 examples/sec; 0.051 sec/batch; 0h:55m:48s remains)
INFO - root - 2022-02-24 20:46:02.336613: step 133870, total loss = 0.56, batch loss = 0.30 (259.7 examples/sec; 0.031 sec/batch; 0h:33m:42s remains)
INFO - root - 2022-02-24 20:46:02.720174: step 133880, total loss = 0.62, batch loss = 0.36 (144.6 examples/sec; 0.055 sec/batch; 1h:00m:29s remains)
INFO - root - 2022-02-24 20:46:03.084594: step 133890, total loss = 0.55, batch loss = 0.29 (298.6 examples/sec; 0.027 sec/batch; 0h:29m:17s remains)
INFO - root - 2022-02-24 20:46:03.445669: step 133900, total loss = 0.59, batch loss = 0.33 (200.2 examples/sec; 0.040 sec/batch; 0h:43m:41s remains)
INFO - root - 2022-02-24 20:46:03.837061: step 133910, total loss = 0.63, batch loss = 0.37 (138.3 examples/sec; 0.058 sec/batch; 1h:03m:13s remains)
INFO - root - 2022-02-24 20:46:04.233922: step 133920, total loss = 0.54, batch loss = 0.29 (145.8 examples/sec; 0.055 sec/batch; 0h:59m:59s remains)
INFO - root - 2022-02-24 20:46:04.679752: step 133930, total loss = 0.54, batch loss = 0.28 (239.4 examples/sec; 0.033 sec/batch; 0h:36m:30s remains)
INFO - root - 2022-02-24 20:46:05.005792: step 133940, total loss = 0.51, batch loss = 0.25 (305.4 examples/sec; 0.026 sec/batch; 0h:28m:37s remains)
INFO - root - 2022-02-24 20:46:05.352663: step 133950, total loss = 0.51, batch loss = 0.25 (265.0 examples/sec; 0.030 sec/batch; 0h:32m:58s remains)
INFO - root - 2022-02-24 20:46:05.666809: step 133960, total loss = 0.60, batch loss = 0.34 (174.1 examples/sec; 0.046 sec/batch; 0h:50m:10s remains)
INFO - root - 2022-02-24 20:46:06.034385: step 133970, total loss = 0.50, batch loss = 0.24 (108.0 examples/sec; 0.074 sec/batch; 1h:20m:52s remains)
INFO - root - 2022-02-24 20:46:06.410375: step 133980, total loss = 0.48, batch loss = 0.22 (181.6 examples/sec; 0.044 sec/batch; 0h:48m:06s remains)
INFO - root - 2022-02-24 20:46:06.829834: step 133990, total loss = 0.54, batch loss = 0.28 (219.8 examples/sec; 0.036 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:46:07.164717: step 134000, total loss = 0.49, batch loss = 0.23 (217.8 examples/sec; 0.037 sec/batch; 0h:40m:05s remains)
INFO - root - 2022-02-24 20:46:07.544971: step 134010, total loss = 0.63, batch loss = 0.37 (237.4 examples/sec; 0.034 sec/batch; 0h:36m:46s remains)
INFO - root - 2022-02-24 20:46:07.910937: step 134020, total loss = 0.55, batch loss = 0.29 (318.4 examples/sec; 0.025 sec/batch; 0h:27m:25s remains)
INFO - root - 2022-02-24 20:46:08.283594: step 134030, total loss = 0.55, batch loss = 0.29 (246.9 examples/sec; 0.032 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:46:08.747223: step 134040, total loss = 0.46, batch loss = 0.20 (310.6 examples/sec; 0.026 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:46:09.109698: step 134050, total loss = 0.46, batch loss = 0.20 (246.9 examples/sec; 0.032 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:46:09.451266: step 134060, total loss = 0.49, batch loss = 0.23 (253.9 examples/sec; 0.032 sec/batch; 0h:34m:21s remains)
INFO - root - 2022-02-24 20:46:09.919173: step 134070, total loss = 0.65, batch loss = 0.39 (312.7 examples/sec; 0.026 sec/batch; 0h:27m:53s remains)
INFO - root - 2022-02-24 20:46:10.464763: step 134080, total loss = 0.55, batch loss = 0.29 (116.0 examples/sec; 0.069 sec/batch; 1h:15m:11s remains)
INFO - root - 2022-02-24 20:46:10.958619: step 134090, total loss = 0.62, batch loss = 0.36 (345.3 examples/sec; 0.023 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 20:46:11.379131: step 134100, total loss = 0.58, batch loss = 0.32 (128.5 examples/sec; 0.062 sec/batch; 1h:07m:50s remains)
INFO - root - 2022-02-24 20:46:11.783587: step 134110, total loss = 0.53, batch loss = 0.28 (219.2 examples/sec; 0.037 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 20:46:12.166441: step 134120, total loss = 0.45, batch loss = 0.19 (282.4 examples/sec; 0.028 sec/batch; 0h:30m:52s remains)
INFO - root - 2022-02-24 20:46:12.643649: step 134130, total loss = 0.57, batch loss = 0.31 (127.2 examples/sec; 0.063 sec/batch; 1h:08m:32s remains)
INFO - root - 2022-02-24 20:46:12.954536: step 134140, total loss = 0.57, batch loss = 0.31 (277.5 examples/sec; 0.029 sec/batch; 0h:31m:24s remains)
INFO - root - 2022-02-24 20:46:13.267735: step 134150, total loss = 0.55, batch loss = 0.30 (256.2 examples/sec; 0.031 sec/batch; 0h:34m:00s remains)
INFO - root - 2022-02-24 20:46:13.694730: step 134160, total loss = 0.59, batch loss = 0.33 (90.4 examples/sec; 0.089 sec/batch; 1h:36m:23s remains)
INFO - root - 2022-02-24 20:46:14.353088: step 134170, total loss = 0.71, batch loss = 0.45 (229.1 examples/sec; 0.035 sec/batch; 0h:38m:01s remains)
INFO - root - 2022-02-24 20:46:14.836968: step 134180, total loss = 0.51, batch loss = 0.25 (346.7 examples/sec; 0.023 sec/batch; 0h:25m:07s remains)
INFO - root - 2022-02-24 20:46:15.264567: step 134190, total loss = 0.58, batch loss = 0.32 (250.8 examples/sec; 0.032 sec/batch; 0h:34m:43s remains)
INFO - root - 2022-02-24 20:46:15.604131: step 134200, total loss = 0.47, batch loss = 0.21 (238.9 examples/sec; 0.033 sec/batch; 0h:36m:26s remains)
INFO - root - 2022-02-24 20:46:16.135174: step 134210, total loss = 0.64, batch loss = 0.39 (192.4 examples/sec; 0.042 sec/batch; 0h:45m:15s remains)
INFO - root - 2022-02-24 20:46:16.598843: step 134220, total loss = 0.60, batch loss = 0.34 (357.6 examples/sec; 0.022 sec/batch; 0h:24m:20s remains)
INFO - root - 2022-02-24 20:46:16.990236: step 134230, total loss = 0.61, batch loss = 0.35 (92.2 examples/sec; 0.087 sec/batch; 1h:34m:20s remains)
INFO - root - 2022-02-24 20:46:17.448790: step 134240, total loss = 0.68, batch loss = 0.42 (138.3 examples/sec; 0.058 sec/batch; 1h:02m:56s remains)
INFO - root - 2022-02-24 20:46:17.839085: step 134250, total loss = 0.50, batch loss = 0.24 (272.2 examples/sec; 0.029 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:46:18.245106: step 134260, total loss = 0.49, batch loss = 0.23 (188.5 examples/sec; 0.042 sec/batch; 0h:46m:09s remains)
INFO - root - 2022-02-24 20:46:18.665368: step 134270, total loss = 0.54, batch loss = 0.28 (107.5 examples/sec; 0.074 sec/batch; 1h:20m:55s remains)
INFO - root - 2022-02-24 20:46:19.524683: step 134280, total loss = 0.55, batch loss = 0.29 (292.4 examples/sec; 0.027 sec/batch; 0h:29m:44s remains)
INFO - root - 2022-02-24 20:46:19.893384: step 134290, total loss = 0.51, batch loss = 0.26 (295.5 examples/sec; 0.027 sec/batch; 0h:29m:25s remains)
INFO - root - 2022-02-24 20:46:20.376951: step 134300, total loss = 0.54, batch loss = 0.28 (280.4 examples/sec; 0.029 sec/batch; 0h:31m:00s remains)
INFO - root - 2022-02-24 20:46:20.837750: step 134310, total loss = 0.48, batch loss = 0.22 (127.7 examples/sec; 0.063 sec/batch; 1h:08m:05s remains)
INFO - root - 2022-02-24 20:46:21.278426: step 134320, total loss = 0.50, batch loss = 0.24 (227.1 examples/sec; 0.035 sec/batch; 0h:38m:15s remains)
INFO - root - 2022-02-24 20:46:21.652545: step 134330, total loss = 0.62, batch loss = 0.36 (361.6 examples/sec; 0.022 sec/batch; 0h:24m:01s remains)
INFO - root - 2022-02-24 20:46:22.011303: step 134340, total loss = 0.62, batch loss = 0.36 (207.9 examples/sec; 0.038 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:46:22.405209: step 134350, total loss = 0.55, batch loss = 0.29 (288.6 examples/sec; 0.028 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:46:22.870565: step 134360, total loss = 0.62, batch loss = 0.36 (128.3 examples/sec; 0.062 sec/batch; 1h:07m:41s remains)
INFO - root - 2022-02-24 20:46:23.342869: step 134370, total loss = 0.56, batch loss = 0.30 (219.8 examples/sec; 0.036 sec/batch; 0h:39m:30s remains)
INFO - root - 2022-02-24 20:46:23.613216: step 134380, total loss = 0.55, batch loss = 0.29 (361.4 examples/sec; 0.022 sec/batch; 0h:24m:01s remains)
INFO - root - 2022-02-24 20:46:23.917733: step 134390, total loss = 0.49, batch loss = 0.23 (182.3 examples/sec; 0.044 sec/batch; 0h:47m:37s remains)
INFO - root - 2022-02-24 20:46:24.310369: step 134400, total loss = 0.52, batch loss = 0.26 (168.1 examples/sec; 0.048 sec/batch; 0h:51m:37s remains)
INFO - root - 2022-02-24 20:46:24.825437: step 134410, total loss = 0.47, batch loss = 0.21 (227.8 examples/sec; 0.035 sec/batch; 0h:38m:05s remains)
INFO - root - 2022-02-24 20:46:25.225663: step 134420, total loss = 0.46, batch loss = 0.20 (153.2 examples/sec; 0.052 sec/batch; 0h:56m:39s remains)
INFO - root - 2022-02-24 20:46:25.626527: step 134430, total loss = 0.52, batch loss = 0.26 (185.1 examples/sec; 0.043 sec/batch; 0h:46m:52s remains)
INFO - root - 2022-02-24 20:46:25.927749: step 134440, total loss = 0.60, batch loss = 0.34 (257.7 examples/sec; 0.031 sec/batch; 0h:33m:39s remains)
INFO - root - 2022-02-24 20:46:26.211009: step 134450, total loss = 0.58, batch loss = 0.32 (336.1 examples/sec; 0.024 sec/batch; 0h:25m:48s remains)
INFO - root - 2022-02-24 20:46:26.578328: step 134460, total loss = 0.51, batch loss = 0.25 (245.4 examples/sec; 0.033 sec/batch; 0h:35m:20s remains)
INFO - root - 2022-02-24 20:46:27.045243: step 134470, total loss = 0.50, batch loss = 0.24 (87.3 examples/sec; 0.092 sec/batch; 1h:39m:17s remains)
INFO - root - 2022-02-24 20:46:27.455605: step 134480, total loss = 0.66, batch loss = 0.40 (115.4 examples/sec; 0.069 sec/batch; 1h:15m:09s remains)
INFO - root - 2022-02-24 20:46:27.804196: step 134490, total loss = 0.63, batch loss = 0.37 (357.8 examples/sec; 0.022 sec/batch; 0h:24m:13s remains)
INFO - root - 2022-02-24 20:46:28.092900: step 134500, total loss = 0.59, batch loss = 0.33 (331.9 examples/sec; 0.024 sec/batch; 0h:26m:06s remains)
INFO - root - 2022-02-24 20:46:28.504030: step 134510, total loss = 0.53, batch loss = 0.27 (246.1 examples/sec; 0.033 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 20:46:28.908749: step 134520, total loss = 0.59, batch loss = 0.33 (338.7 examples/sec; 0.024 sec/batch; 0h:25m:34s remains)
INFO - root - 2022-02-24 20:46:29.340589: step 134530, total loss = 0.57, batch loss = 0.32 (189.3 examples/sec; 0.042 sec/batch; 0h:45m:46s remains)
INFO - root - 2022-02-24 20:46:29.848126: step 134540, total loss = 0.59, batch loss = 0.33 (247.7 examples/sec; 0.032 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 20:46:30.216576: step 134550, total loss = 0.56, batch loss = 0.30 (200.6 examples/sec; 0.040 sec/batch; 0h:43m:10s remains)
INFO - root - 2022-02-24 20:46:30.551796: step 134560, total loss = 0.52, batch loss = 0.26 (240.4 examples/sec; 0.033 sec/batch; 0h:36m:01s remains)
INFO - root - 2022-02-24 20:46:30.844367: step 134570, total loss = 0.55, batch loss = 0.29 (213.4 examples/sec; 0.037 sec/batch; 0h:40m:34s remains)
INFO - root - 2022-02-24 20:46:31.166025: step 134580, total loss = 0.54, batch loss = 0.28 (250.9 examples/sec; 0.032 sec/batch; 0h:34m:30s remains)
INFO - root - 2022-02-24 20:46:31.522618: step 134590, total loss = 0.66, batch loss = 0.40 (198.4 examples/sec; 0.040 sec/batch; 0h:43m:37s remains)
INFO - root - 2022-02-24 20:46:31.925276: step 134600, total loss = 0.54, batch loss = 0.28 (223.5 examples/sec; 0.036 sec/batch; 0h:38m:43s remains)
INFO - root - 2022-02-24 20:46:32.408278: step 134610, total loss = 0.65, batch loss = 0.39 (116.4 examples/sec; 0.069 sec/batch; 1h:14m:18s remains)
INFO - root - 2022-02-24 20:46:32.731084: step 134620, total loss = 0.46, batch loss = 0.20 (287.7 examples/sec; 0.028 sec/batch; 0h:30m:04s remains)
INFO - root - 2022-02-24 20:46:33.065050: step 134630, total loss = 0.53, batch loss = 0.27 (316.2 examples/sec; 0.025 sec/batch; 0h:27m:21s remains)
INFO - root - 2022-02-24 20:46:33.432535: step 134640, total loss = 0.56, batch loss = 0.30 (332.4 examples/sec; 0.024 sec/batch; 0h:26m:00s remains)
INFO - root - 2022-02-24 20:46:33.941753: step 134650, total loss = 0.59, batch loss = 0.33 (80.9 examples/sec; 0.099 sec/batch; 1h:46m:53s remains)
INFO - root - 2022-02-24 20:46:34.448064: step 134660, total loss = 0.57, batch loss = 0.31 (256.6 examples/sec; 0.031 sec/batch; 0h:33m:41s remains)
INFO - root - 2022-02-24 20:46:34.814010: step 134670, total loss = 0.69, batch loss = 0.43 (264.4 examples/sec; 0.030 sec/batch; 0h:32m:41s remains)
INFO - root - 2022-02-24 20:46:35.156037: step 134680, total loss = 0.54, batch loss = 0.28 (162.6 examples/sec; 0.049 sec/batch; 0h:53m:08s remains)
INFO - root - 2022-02-24 20:46:35.471679: step 134690, total loss = 0.62, batch loss = 0.36 (308.8 examples/sec; 0.026 sec/batch; 0h:27m:59s remains)
INFO - root - 2022-02-24 20:46:35.826894: step 134700, total loss = 0.68, batch loss = 0.42 (175.5 examples/sec; 0.046 sec/batch; 0h:49m:13s remains)
INFO - root - 2022-02-24 20:46:36.481138: step 134710, total loss = 0.54, batch loss = 0.28 (149.4 examples/sec; 0.054 sec/batch; 0h:57m:49s remains)
INFO - root - 2022-02-24 20:46:36.780070: step 134720, total loss = 0.61, batch loss = 0.35 (304.9 examples/sec; 0.026 sec/batch; 0h:28m:19s remains)
INFO - root - 2022-02-24 20:46:37.168021: step 134730, total loss = 0.51, batch loss = 0.25 (173.9 examples/sec; 0.046 sec/batch; 0h:49m:39s remains)
INFO - root - 2022-02-24 20:46:37.492097: step 134740, total loss = 0.51, batch loss = 0.25 (137.2 examples/sec; 0.058 sec/batch; 1h:02m:55s remains)
INFO - root - 2022-02-24 20:46:37.915777: step 134750, total loss = 0.62, batch loss = 0.36 (307.2 examples/sec; 0.026 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 20:46:38.456001: step 134760, total loss = 0.54, batch loss = 0.28 (219.0 examples/sec; 0.037 sec/batch; 0h:39m:25s remains)
INFO - root - 2022-02-24 20:46:39.184582: step 134770, total loss = 0.53, batch loss = 0.27 (297.8 examples/sec; 0.027 sec/batch; 0h:28m:59s remains)
INFO - root - 2022-02-24 20:46:39.734179: step 134780, total loss = 0.56, batch loss = 0.30 (61.7 examples/sec; 0.130 sec/batch; 2h:19m:46s remains)
INFO - root - 2022-02-24 20:46:40.621056: step 134790, total loss = 0.60, batch loss = 0.34 (176.2 examples/sec; 0.045 sec/batch; 0h:48m:58s remains)
INFO - root - 2022-02-24 20:46:41.059255: step 134800, total loss = 0.61, batch loss = 0.35 (220.8 examples/sec; 0.036 sec/batch; 0h:39m:04s remains)
INFO - root - 2022-02-24 20:46:41.570137: step 134810, total loss = 0.54, batch loss = 0.28 (348.8 examples/sec; 0.023 sec/batch; 0h:24m:43s remains)
INFO - root - 2022-02-24 20:46:41.935861: step 134820, total loss = 0.48, batch loss = 0.23 (175.6 examples/sec; 0.046 sec/batch; 0h:49m:06s remains)
INFO - root - 2022-02-24 20:46:42.364509: step 134830, total loss = 0.56, batch loss = 0.30 (176.3 examples/sec; 0.045 sec/batch; 0h:48m:53s remains)
INFO - root - 2022-02-24 20:46:42.716103: step 134840, total loss = 0.62, batch loss = 0.36 (118.7 examples/sec; 0.067 sec/batch; 1h:12m:38s remains)
INFO - root - 2022-02-24 20:46:43.133383: step 134850, total loss = 0.50, batch loss = 0.24 (208.6 examples/sec; 0.038 sec/batch; 0h:41m:19s remains)
INFO - root - 2022-02-24 20:46:43.537958: step 134860, total loss = 0.51, batch loss = 0.25 (210.4 examples/sec; 0.038 sec/batch; 0h:40m:58s remains)
INFO - root - 2022-02-24 20:46:43.850206: step 134870, total loss = 0.52, batch loss = 0.26 (325.4 examples/sec; 0.025 sec/batch; 0h:26m:29s remains)
INFO - root - 2022-02-24 20:46:44.141368: step 134880, total loss = 0.51, batch loss = 0.25 (282.9 examples/sec; 0.028 sec/batch; 0h:30m:27s remains)
INFO - root - 2022-02-24 20:46:44.455748: step 134890, total loss = 0.53, batch loss = 0.27 (269.6 examples/sec; 0.030 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:46:44.914978: step 134900, total loss = 0.62, batch loss = 0.36 (105.7 examples/sec; 0.076 sec/batch; 1h:21m:29s remains)
INFO - root - 2022-02-24 20:46:45.386972: step 134910, total loss = 0.56, batch loss = 0.30 (172.6 examples/sec; 0.046 sec/batch; 0h:49m:54s remains)
INFO - root - 2022-02-24 20:46:45.788533: step 134920, total loss = 0.47, batch loss = 0.22 (350.3 examples/sec; 0.023 sec/batch; 0h:24m:34s remains)
INFO - root - 2022-02-24 20:46:46.127239: step 134930, total loss = 0.63, batch loss = 0.37 (304.1 examples/sec; 0.026 sec/batch; 0h:28m:18s remains)
INFO - root - 2022-02-24 20:46:46.466571: step 134940, total loss = 0.58, batch loss = 0.32 (280.0 examples/sec; 0.029 sec/batch; 0h:30m:44s remains)
INFO - root - 2022-02-24 20:46:46.839649: step 134950, total loss = 0.53, batch loss = 0.27 (162.1 examples/sec; 0.049 sec/batch; 0h:53m:05s remains)
INFO - root - 2022-02-24 20:46:47.167308: step 134960, total loss = 0.59, batch loss = 0.33 (356.3 examples/sec; 0.022 sec/batch; 0h:24m:09s remains)
INFO - root - 2022-02-24 20:46:47.602572: step 134970, total loss = 0.56, batch loss = 0.30 (107.6 examples/sec; 0.074 sec/batch; 1h:19m:59s remains)
INFO - root - 2022-02-24 20:46:47.972719: step 134980, total loss = 0.58, batch loss = 0.32 (188.9 examples/sec; 0.042 sec/batch; 0h:45m:33s remains)
INFO - root - 2022-02-24 20:46:48.320621: step 134990, total loss = 0.51, batch loss = 0.25 (155.6 examples/sec; 0.051 sec/batch; 0h:55m:16s remains)
INFO - root - 2022-02-24 20:46:48.655948: step 135000, total loss = 0.57, batch loss = 0.31 (235.6 examples/sec; 0.034 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:46:49.128287: step 135010, total loss = 0.57, batch loss = 0.31 (331.3 examples/sec; 0.024 sec/batch; 0h:25m:57s remains)
INFO - root - 2022-02-24 20:46:49.506639: step 135020, total loss = 0.75, batch loss = 0.49 (334.6 examples/sec; 0.024 sec/batch; 0h:25m:41s remains)
INFO - root - 2022-02-24 20:46:50.057231: step 135030, total loss = 0.60, batch loss = 0.34 (330.7 examples/sec; 0.024 sec/batch; 0h:25m:59s remains)
INFO - root - 2022-02-24 20:46:50.469866: step 135040, total loss = 0.63, batch loss = 0.37 (218.3 examples/sec; 0.037 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:46:50.743087: step 135050, total loss = 0.59, batch loss = 0.33 (305.5 examples/sec; 0.026 sec/batch; 0h:28m:07s remains)
INFO - root - 2022-02-24 20:46:51.133479: step 135060, total loss = 0.54, batch loss = 0.28 (351.2 examples/sec; 0.023 sec/batch; 0h:24m:28s remains)
INFO - root - 2022-02-24 20:46:51.462142: step 135070, total loss = 0.50, batch loss = 0.24 (213.6 examples/sec; 0.037 sec/batch; 0h:40m:12s remains)
INFO - root - 2022-02-24 20:46:51.886249: step 135080, total loss = 0.66, batch loss = 0.40 (139.5 examples/sec; 0.057 sec/batch; 1h:01m:33s remains)
INFO - root - 2022-02-24 20:46:52.347141: step 135090, total loss = 0.51, batch loss = 0.25 (256.4 examples/sec; 0.031 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:46:52.770887: step 135100, total loss = 0.52, batch loss = 0.26 (227.8 examples/sec; 0.035 sec/batch; 0h:37m:41s remains)
INFO - root - 2022-02-24 20:46:53.146124: step 135110, total loss = 0.53, batch loss = 0.27 (320.2 examples/sec; 0.025 sec/batch; 0h:26m:48s remains)
INFO - root - 2022-02-24 20:46:53.512175: step 135120, total loss = 0.56, batch loss = 0.30 (213.4 examples/sec; 0.037 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:46:53.942844: step 135130, total loss = 0.60, batch loss = 0.34 (196.3 examples/sec; 0.041 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:46:54.440133: step 135140, total loss = 0.58, batch loss = 0.32 (118.9 examples/sec; 0.067 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 20:46:54.887489: step 135150, total loss = 0.57, batch loss = 0.31 (285.0 examples/sec; 0.028 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:46:55.192778: step 135160, total loss = 0.44, batch loss = 0.18 (247.7 examples/sec; 0.032 sec/batch; 0h:34m:38s remains)
INFO - root - 2022-02-24 20:46:55.763912: step 135170, total loss = 0.59, batch loss = 0.33 (343.5 examples/sec; 0.023 sec/batch; 0h:24m:58s remains)
INFO - root - 2022-02-24 20:46:56.088154: step 135180, total loss = 0.59, batch loss = 0.33 (140.9 examples/sec; 0.057 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 20:46:56.616715: step 135190, total loss = 0.58, batch loss = 0.32 (99.0 examples/sec; 0.081 sec/batch; 1h:26m:34s remains)
INFO - root - 2022-02-24 20:46:57.006120: step 135200, total loss = 0.57, batch loss = 0.31 (204.2 examples/sec; 0.039 sec/batch; 0h:41m:59s remains)
INFO - root - 2022-02-24 20:46:57.624352: step 135210, total loss = 0.57, batch loss = 0.31 (354.0 examples/sec; 0.023 sec/batch; 0h:24m:13s remains)
INFO - root - 2022-02-24 20:46:57.924658: step 135220, total loss = 0.51, batch loss = 0.25 (139.9 examples/sec; 0.057 sec/batch; 1h:01m:14s remains)
INFO - root - 2022-02-24 20:46:58.305458: step 135230, total loss = 0.51, batch loss = 0.25 (233.2 examples/sec; 0.034 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:46:58.707073: step 135240, total loss = 0.54, batch loss = 0.29 (206.3 examples/sec; 0.039 sec/batch; 0h:41m:31s remains)
INFO - root - 2022-02-24 20:46:59.133593: step 135250, total loss = 0.50, batch loss = 0.24 (325.4 examples/sec; 0.025 sec/batch; 0h:26m:19s remains)
INFO - root - 2022-02-24 20:46:59.497958: step 135260, total loss = 0.60, batch loss = 0.34 (323.0 examples/sec; 0.025 sec/batch; 0h:26m:31s remains)
INFO - root - 2022-02-24 20:46:59.953223: step 135270, total loss = 0.62, batch loss = 0.37 (146.1 examples/sec; 0.055 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 20:47:00.778224: step 135280, total loss = 0.52, batch loss = 0.26 (178.2 examples/sec; 0.045 sec/batch; 0h:48m:03s remains)
INFO - root - 2022-02-24 20:47:01.197394: step 135290, total loss = 0.46, batch loss = 0.20 (149.5 examples/sec; 0.054 sec/batch; 0h:57m:15s remains)
INFO - root - 2022-02-24 20:47:01.566150: step 135300, total loss = 0.50, batch loss = 0.24 (171.2 examples/sec; 0.047 sec/batch; 0h:50m:00s remains)
INFO - root - 2022-02-24 20:47:01.943602: step 135310, total loss = 0.65, batch loss = 0.39 (277.0 examples/sec; 0.029 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 20:47:02.361289: step 135320, total loss = 0.64, batch loss = 0.38 (268.3 examples/sec; 0.030 sec/batch; 0h:31m:53s remains)
INFO - root - 2022-02-24 20:47:02.683264: step 135330, total loss = 0.57, batch loss = 0.31 (164.5 examples/sec; 0.049 sec/batch; 0h:51m:59s remains)
INFO - root - 2022-02-24 20:47:03.087328: step 135340, total loss = 0.53, batch loss = 0.27 (159.8 examples/sec; 0.050 sec/batch; 0h:53m:32s remains)
INFO - root - 2022-02-24 20:47:03.471925: step 135350, total loss = 0.58, batch loss = 0.32 (226.1 examples/sec; 0.035 sec/batch; 0h:37m:49s remains)
INFO - root - 2022-02-24 20:47:03.799230: step 135360, total loss = 0.55, batch loss = 0.29 (309.5 examples/sec; 0.026 sec/batch; 0h:27m:38s remains)
INFO - root - 2022-02-24 20:47:04.173851: step 135370, total loss = 0.54, batch loss = 0.28 (115.6 examples/sec; 0.069 sec/batch; 1h:13m:57s remains)
INFO - root - 2022-02-24 20:47:04.552284: step 135380, total loss = 0.46, batch loss = 0.20 (158.6 examples/sec; 0.050 sec/batch; 0h:53m:54s remains)
INFO - root - 2022-02-24 20:47:05.066216: step 135390, total loss = 0.61, batch loss = 0.36 (115.3 examples/sec; 0.069 sec/batch; 1h:14m:06s remains)
INFO - root - 2022-02-24 20:47:05.435151: step 135400, total loss = 0.44, batch loss = 0.18 (325.7 examples/sec; 0.025 sec/batch; 0h:26m:14s remains)
INFO - root - 2022-02-24 20:47:05.900862: step 135410, total loss = 0.52, batch loss = 0.26 (280.4 examples/sec; 0.029 sec/batch; 0h:30m:28s remains)
INFO - root - 2022-02-24 20:47:06.249509: step 135420, total loss = 0.53, batch loss = 0.28 (170.2 examples/sec; 0.047 sec/batch; 0h:50m:11s remains)
INFO - root - 2022-02-24 20:47:06.722670: step 135430, total loss = 0.55, batch loss = 0.29 (99.0 examples/sec; 0.081 sec/batch; 1h:26m:18s remains)
INFO - root - 2022-02-24 20:47:07.149602: step 135440, total loss = 0.61, batch loss = 0.35 (358.2 examples/sec; 0.022 sec/batch; 0h:23m:50s remains)
INFO - root - 2022-02-24 20:47:07.535818: step 135450, total loss = 0.51, batch loss = 0.26 (223.3 examples/sec; 0.036 sec/batch; 0h:38m:14s remains)
INFO - root - 2022-02-24 20:47:07.882459: step 135460, total loss = 0.48, batch loss = 0.22 (306.9 examples/sec; 0.026 sec/batch; 0h:27m:49s remains)
INFO - root - 2022-02-24 20:47:08.262386: step 135470, total loss = 0.50, batch loss = 0.24 (166.3 examples/sec; 0.048 sec/batch; 0h:51m:19s remains)
INFO - root - 2022-02-24 20:47:08.560362: step 135480, total loss = 0.47, batch loss = 0.21 (367.6 examples/sec; 0.022 sec/batch; 0h:23m:13s remains)
INFO - root - 2022-02-24 20:47:08.933332: step 135490, total loss = 0.58, batch loss = 0.32 (144.3 examples/sec; 0.055 sec/batch; 0h:59m:08s remains)
INFO - root - 2022-02-24 20:47:09.394626: step 135500, total loss = 0.49, batch loss = 0.23 (137.9 examples/sec; 0.058 sec/batch; 1h:01m:51s remains)
INFO - root - 2022-02-24 20:47:09.960597: step 135510, total loss = 0.57, batch loss = 0.31 (162.7 examples/sec; 0.049 sec/batch; 0h:52m:25s remains)
INFO - root - 2022-02-24 20:47:10.317816: step 135520, total loss = 0.51, batch loss = 0.25 (204.4 examples/sec; 0.039 sec/batch; 0h:41m:44s remains)
INFO - root - 2022-02-24 20:47:10.672638: step 135530, total loss = 0.55, batch loss = 0.29 (295.8 examples/sec; 0.027 sec/batch; 0h:28m:50s remains)
INFO - root - 2022-02-24 20:47:11.018363: step 135540, total loss = 0.52, batch loss = 0.26 (187.4 examples/sec; 0.043 sec/batch; 0h:45m:30s remains)
INFO - root - 2022-02-24 20:47:11.473290: step 135550, total loss = 0.53, batch loss = 0.27 (188.2 examples/sec; 0.043 sec/batch; 0h:45m:18s remains)
INFO - root - 2022-02-24 20:47:11.859433: step 135560, total loss = 0.61, batch loss = 0.35 (190.7 examples/sec; 0.042 sec/batch; 0h:44m:43s remains)
INFO - root - 2022-02-24 20:47:12.169564: step 135570, total loss = 0.51, batch loss = 0.25 (346.0 examples/sec; 0.023 sec/batch; 0h:24m:38s remains)
INFO - root - 2022-02-24 20:47:12.493144: step 135580, total loss = 0.53, batch loss = 0.27 (164.4 examples/sec; 0.049 sec/batch; 0h:51m:50s remains)
INFO - root - 2022-02-24 20:47:12.805663: step 135590, total loss = 0.58, batch loss = 0.32 (173.6 examples/sec; 0.046 sec/batch; 0h:49m:04s remains)
INFO - root - 2022-02-24 20:47:13.209877: step 135600, total loss = 0.67, batch loss = 0.42 (110.7 examples/sec; 0.072 sec/batch; 1h:16m:59s remains)
INFO - root - 2022-02-24 20:47:13.681808: step 135610, total loss = 0.56, batch loss = 0.30 (128.2 examples/sec; 0.062 sec/batch; 1h:06m:25s remains)
INFO - root - 2022-02-24 20:47:14.030282: step 135620, total loss = 0.66, batch loss = 0.40 (174.5 examples/sec; 0.046 sec/batch; 0h:48m:48s remains)
INFO - root - 2022-02-24 20:47:14.395864: step 135630, total loss = 0.59, batch loss = 0.33 (174.3 examples/sec; 0.046 sec/batch; 0h:48m:50s remains)
INFO - root - 2022-02-24 20:47:14.756404: step 135640, total loss = 0.42, batch loss = 0.16 (157.9 examples/sec; 0.051 sec/batch; 0h:53m:56s remains)
INFO - root - 2022-02-24 20:47:15.138708: step 135650, total loss = 0.48, batch loss = 0.22 (294.0 examples/sec; 0.027 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 20:47:15.561889: step 135660, total loss = 0.48, batch loss = 0.22 (242.3 examples/sec; 0.033 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:47:16.006333: step 135670, total loss = 0.55, batch loss = 0.29 (218.9 examples/sec; 0.037 sec/batch; 0h:38m:52s remains)
INFO - root - 2022-02-24 20:47:16.371600: step 135680, total loss = 0.55, batch loss = 0.29 (279.0 examples/sec; 0.029 sec/batch; 0h:30m:30s remains)
INFO - root - 2022-02-24 20:47:16.712846: step 135690, total loss = 0.58, batch loss = 0.32 (281.3 examples/sec; 0.028 sec/batch; 0h:30m:14s remains)
INFO - root - 2022-02-24 20:47:17.081433: step 135700, total loss = 0.57, batch loss = 0.31 (249.4 examples/sec; 0.032 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:47:17.541450: step 135710, total loss = 0.55, batch loss = 0.29 (156.9 examples/sec; 0.051 sec/batch; 0h:54m:11s remains)
INFO - root - 2022-02-24 20:47:17.980352: step 135720, total loss = 0.58, batch loss = 0.32 (279.5 examples/sec; 0.029 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 20:47:18.611148: step 135730, total loss = 0.61, batch loss = 0.35 (170.3 examples/sec; 0.047 sec/batch; 0h:49m:56s remains)
INFO - root - 2022-02-24 20:47:19.266608: step 135740, total loss = 0.58, batch loss = 0.32 (66.8 examples/sec; 0.120 sec/batch; 2h:07m:14s remains)
INFO - root - 2022-02-24 20:47:19.737316: step 135750, total loss = 0.54, batch loss = 0.28 (99.4 examples/sec; 0.081 sec/batch; 1h:25m:33s remains)
INFO - root - 2022-02-24 20:47:20.138867: step 135760, total loss = 0.59, batch loss = 0.33 (193.8 examples/sec; 0.041 sec/batch; 0h:43m:51s remains)
INFO - root - 2022-02-24 20:47:21.006812: step 135770, total loss = 0.52, batch loss = 0.26 (241.1 examples/sec; 0.033 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 20:47:21.368626: step 135780, total loss = 0.50, batch loss = 0.24 (205.3 examples/sec; 0.039 sec/batch; 0h:41m:22s remains)
INFO - root - 2022-02-24 20:47:21.841759: step 135790, total loss = 0.48, batch loss = 0.22 (163.5 examples/sec; 0.049 sec/batch; 0h:51m:56s remains)
INFO - root - 2022-02-24 20:47:22.256338: step 135800, total loss = 0.55, batch loss = 0.29 (157.3 examples/sec; 0.051 sec/batch; 0h:53m:58s remains)
INFO - root - 2022-02-24 20:47:22.726978: step 135810, total loss = 0.60, batch loss = 0.34 (284.9 examples/sec; 0.028 sec/batch; 0h:29m:48s remains)
INFO - root - 2022-02-24 20:47:23.088986: step 135820, total loss = 0.57, batch loss = 0.31 (142.3 examples/sec; 0.056 sec/batch; 0h:59m:40s remains)
INFO - root - 2022-02-24 20:47:23.371400: step 135830, total loss = 0.47, batch loss = 0.21 (273.8 examples/sec; 0.029 sec/batch; 0h:31m:00s remains)
INFO - root - 2022-02-24 20:47:23.757674: step 135840, total loss = 0.54, batch loss = 0.28 (191.7 examples/sec; 0.042 sec/batch; 0h:44m:16s remains)
INFO - root - 2022-02-24 20:47:24.215299: step 135850, total loss = 0.53, batch loss = 0.28 (299.7 examples/sec; 0.027 sec/batch; 0h:28m:19s remains)
INFO - root - 2022-02-24 20:47:24.617211: step 135860, total loss = 0.53, batch loss = 0.27 (126.1 examples/sec; 0.063 sec/batch; 1h:07m:16s remains)
INFO - root - 2022-02-24 20:47:24.965745: step 135870, total loss = 0.51, batch loss = 0.25 (205.3 examples/sec; 0.039 sec/batch; 0h:41m:19s remains)
INFO - root - 2022-02-24 20:47:25.327926: step 135880, total loss = 0.59, batch loss = 0.33 (197.1 examples/sec; 0.041 sec/batch; 0h:43m:02s remains)
INFO - root - 2022-02-24 20:47:25.663470: step 135890, total loss = 0.51, batch loss = 0.26 (257.6 examples/sec; 0.031 sec/batch; 0h:32m:55s remains)
INFO - root - 2022-02-24 20:47:26.072993: step 135900, total loss = 0.52, batch loss = 0.27 (126.7 examples/sec; 0.063 sec/batch; 1h:06m:54s remains)
INFO - root - 2022-02-24 20:47:26.524558: step 135910, total loss = 0.73, batch loss = 0.47 (140.1 examples/sec; 0.057 sec/batch; 1h:00m:32s remains)
INFO - root - 2022-02-24 20:47:26.965911: step 135920, total loss = 0.57, batch loss = 0.31 (154.5 examples/sec; 0.052 sec/batch; 0h:54m:53s remains)
INFO - root - 2022-02-24 20:47:27.262011: step 135930, total loss = 0.54, batch loss = 0.28 (327.8 examples/sec; 0.024 sec/batch; 0h:25m:51s remains)
INFO - root - 2022-02-24 20:47:27.617769: step 135940, total loss = 0.60, batch loss = 0.34 (332.1 examples/sec; 0.024 sec/batch; 0h:25m:31s remains)
INFO - root - 2022-02-24 20:47:28.008593: step 135950, total loss = 0.51, batch loss = 0.25 (141.4 examples/sec; 0.057 sec/batch; 0h:59m:55s remains)
INFO - root - 2022-02-24 20:47:28.401869: step 135960, total loss = 0.52, batch loss = 0.26 (183.8 examples/sec; 0.044 sec/batch; 0h:46m:04s remains)
INFO - root - 2022-02-24 20:47:28.818856: step 135970, total loss = 0.47, batch loss = 0.21 (254.7 examples/sec; 0.031 sec/batch; 0h:33m:15s remains)
INFO - root - 2022-02-24 20:47:29.144526: step 135980, total loss = 0.64, batch loss = 0.38 (319.8 examples/sec; 0.025 sec/batch; 0h:26m:28s remains)
INFO - root - 2022-02-24 20:47:29.434847: step 135990, total loss = 0.48, batch loss = 0.23 (320.4 examples/sec; 0.025 sec/batch; 0h:26m:25s remains)
INFO - root - 2022-02-24 20:47:29.831983: step 136000, total loss = 0.52, batch loss = 0.26 (210.9 examples/sec; 0.038 sec/batch; 0h:40m:08s remains)
INFO - root - 2022-02-24 20:47:30.264141: step 136010, total loss = 0.50, batch loss = 0.24 (109.9 examples/sec; 0.073 sec/batch; 1h:16m:59s remains)
INFO - root - 2022-02-24 20:47:30.710890: step 136020, total loss = 0.54, batch loss = 0.28 (212.7 examples/sec; 0.038 sec/batch; 0h:39m:47s remains)
INFO - root - 2022-02-24 20:47:31.039610: step 136030, total loss = 0.51, batch loss = 0.25 (338.4 examples/sec; 0.024 sec/batch; 0h:25m:00s remains)
INFO - root - 2022-02-24 20:47:31.417515: step 136040, total loss = 0.53, batch loss = 0.27 (340.6 examples/sec; 0.023 sec/batch; 0h:24m:50s remains)
INFO - root - 2022-02-24 20:47:31.791186: step 136050, total loss = 0.61, batch loss = 0.36 (137.0 examples/sec; 0.058 sec/batch; 1h:01m:45s remains)
INFO - root - 2022-02-24 20:47:32.235864: step 136060, total loss = 0.54, batch loss = 0.28 (271.6 examples/sec; 0.029 sec/batch; 0h:31m:08s remains)
INFO - root - 2022-02-24 20:47:32.629285: step 136070, total loss = 0.48, batch loss = 0.22 (103.2 examples/sec; 0.078 sec/batch; 1h:21m:56s remains)
INFO - root - 2022-02-24 20:47:33.040378: step 136080, total loss = 0.67, batch loss = 0.42 (228.1 examples/sec; 0.035 sec/batch; 0h:37m:04s remains)
INFO - root - 2022-02-24 20:47:33.350330: step 136090, total loss = 0.55, batch loss = 0.29 (258.9 examples/sec; 0.031 sec/batch; 0h:32m:39s remains)
INFO - root - 2022-02-24 20:47:33.647374: step 136100, total loss = 0.58, batch loss = 0.33 (350.3 examples/sec; 0.023 sec/batch; 0h:24m:08s remains)
INFO - root - 2022-02-24 20:47:33.980444: step 136110, total loss = 0.50, batch loss = 0.24 (326.2 examples/sec; 0.025 sec/batch; 0h:25m:54s remains)
INFO - root - 2022-02-24 20:47:34.452483: step 136120, total loss = 0.67, batch loss = 0.41 (141.7 examples/sec; 0.056 sec/batch; 0h:59m:39s remains)
INFO - root - 2022-02-24 20:47:34.877828: step 136130, total loss = 0.52, batch loss = 0.26 (199.9 examples/sec; 0.040 sec/batch; 0h:42m:15s remains)
INFO - root - 2022-02-24 20:47:35.250023: step 136140, total loss = 0.65, batch loss = 0.39 (356.1 examples/sec; 0.022 sec/batch; 0h:23m:43s remains)
INFO - root - 2022-02-24 20:47:35.630424: step 136150, total loss = 0.78, batch loss = 0.52 (345.5 examples/sec; 0.023 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 20:47:36.016172: step 136160, total loss = 0.54, batch loss = 0.28 (277.0 examples/sec; 0.029 sec/batch; 0h:30m:29s remains)
INFO - root - 2022-02-24 20:47:37.033289: step 136170, total loss = 0.57, batch loss = 0.31 (96.1 examples/sec; 0.083 sec/batch; 1h:27m:50s remains)
INFO - root - 2022-02-24 20:47:37.433516: step 136180, total loss = 0.75, batch loss = 0.49 (296.0 examples/sec; 0.027 sec/batch; 0h:28m:31s remains)
INFO - root - 2022-02-24 20:47:37.858605: step 136190, total loss = 0.51, batch loss = 0.25 (175.2 examples/sec; 0.046 sec/batch; 0h:48m:11s remains)
INFO - root - 2022-02-24 20:47:38.255196: step 136200, total loss = 0.54, batch loss = 0.29 (295.5 examples/sec; 0.027 sec/batch; 0h:28m:33s remains)
INFO - root - 2022-02-24 20:47:38.630570: step 136210, total loss = 0.52, batch loss = 0.26 (342.0 examples/sec; 0.023 sec/batch; 0h:24m:40s remains)
INFO - root - 2022-02-24 20:47:39.160372: step 136220, total loss = 0.53, batch loss = 0.27 (68.1 examples/sec; 0.118 sec/batch; 2h:03m:57s remains)
INFO - root - 2022-02-24 20:47:39.604962: step 136230, total loss = 0.49, batch loss = 0.23 (210.2 examples/sec; 0.038 sec/batch; 0h:40m:08s remains)
INFO - root - 2022-02-24 20:47:39.992091: step 136240, total loss = 0.61, batch loss = 0.35 (137.9 examples/sec; 0.058 sec/batch; 1h:01m:10s remains)
INFO - root - 2022-02-24 20:47:40.343347: step 136250, total loss = 0.56, batch loss = 0.30 (337.7 examples/sec; 0.024 sec/batch; 0h:24m:58s remains)
INFO - root - 2022-02-24 20:47:40.767767: step 136260, total loss = 0.47, batch loss = 0.22 (128.8 examples/sec; 0.062 sec/batch; 1h:05m:26s remains)
INFO - root - 2022-02-24 20:47:41.288965: step 136270, total loss = 0.55, batch loss = 0.29 (121.1 examples/sec; 0.066 sec/batch; 1h:09m:36s remains)
INFO - root - 2022-02-24 20:47:41.682274: step 136280, total loss = 0.53, batch loss = 0.27 (103.1 examples/sec; 0.078 sec/batch; 1h:21m:44s remains)
INFO - root - 2022-02-24 20:47:42.321473: step 136290, total loss = 0.62, batch loss = 0.36 (198.5 examples/sec; 0.040 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:47:42.705763: step 136300, total loss = 0.58, batch loss = 0.33 (349.0 examples/sec; 0.023 sec/batch; 0h:24m:08s remains)
INFO - root - 2022-02-24 20:47:43.354805: step 136310, total loss = 0.54, batch loss = 0.28 (231.1 examples/sec; 0.035 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:47:43.817787: step 136320, total loss = 0.67, batch loss = 0.41 (103.4 examples/sec; 0.077 sec/batch; 1h:21m:27s remains)
INFO - root - 2022-02-24 20:47:44.223159: step 136330, total loss = 0.57, batch loss = 0.32 (148.1 examples/sec; 0.054 sec/batch; 0h:56m:51s remains)
INFO - root - 2022-02-24 20:47:44.506450: step 136340, total loss = 0.58, batch loss = 0.32 (387.3 examples/sec; 0.021 sec/batch; 0h:21m:44s remains)
INFO - root - 2022-02-24 20:47:44.807641: step 136350, total loss = 0.50, batch loss = 0.25 (191.2 examples/sec; 0.042 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:47:45.217752: step 136360, total loss = 0.56, batch loss = 0.30 (241.4 examples/sec; 0.033 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:47:45.625481: step 136370, total loss = 0.51, batch loss = 0.25 (361.8 examples/sec; 0.022 sec/batch; 0h:23m:16s remains)
INFO - root - 2022-02-24 20:47:46.007899: step 136380, total loss = 0.69, batch loss = 0.43 (348.2 examples/sec; 0.023 sec/batch; 0h:24m:10s remains)
INFO - root - 2022-02-24 20:47:46.318438: step 136390, total loss = 0.52, batch loss = 0.26 (158.6 examples/sec; 0.050 sec/batch; 0h:53m:02s remains)
INFO - root - 2022-02-24 20:47:46.706044: step 136400, total loss = 0.47, batch loss = 0.22 (190.2 examples/sec; 0.042 sec/batch; 0h:44m:13s remains)
INFO - root - 2022-02-24 20:47:47.181322: step 136410, total loss = 0.57, batch loss = 0.31 (293.7 examples/sec; 0.027 sec/batch; 0h:28m:38s remains)
INFO - root - 2022-02-24 20:47:47.694526: step 136420, total loss = 0.48, batch loss = 0.22 (104.1 examples/sec; 0.077 sec/batch; 1h:20m:48s remains)
INFO - root - 2022-02-24 20:47:48.125498: step 136430, total loss = 0.53, batch loss = 0.27 (143.7 examples/sec; 0.056 sec/batch; 0h:58m:30s remains)
INFO - root - 2022-02-24 20:47:48.448559: step 136440, total loss = 0.50, batch loss = 0.24 (221.8 examples/sec; 0.036 sec/batch; 0h:37m:54s remains)
INFO - root - 2022-02-24 20:47:48.753273: step 136450, total loss = 0.49, batch loss = 0.23 (302.9 examples/sec; 0.026 sec/batch; 0h:27m:45s remains)
INFO - root - 2022-02-24 20:47:49.076788: step 136460, total loss = 0.61, batch loss = 0.35 (240.3 examples/sec; 0.033 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 20:47:49.468189: step 136470, total loss = 0.46, batch loss = 0.20 (166.6 examples/sec; 0.048 sec/batch; 0h:50m:26s remains)
INFO - root - 2022-02-24 20:47:49.873785: step 136480, total loss = 0.52, batch loss = 0.26 (333.5 examples/sec; 0.024 sec/batch; 0h:25m:11s remains)
INFO - root - 2022-02-24 20:47:50.202361: step 136490, total loss = 0.55, batch loss = 0.29 (339.2 examples/sec; 0.024 sec/batch; 0h:24m:46s remains)
INFO - root - 2022-02-24 20:47:50.532675: step 136500, total loss = 0.53, batch loss = 0.27 (192.3 examples/sec; 0.042 sec/batch; 0h:43m:40s remains)
INFO - root - 2022-02-24 20:47:51.060386: step 136510, total loss = 0.47, batch loss = 0.21 (134.3 examples/sec; 0.060 sec/batch; 1h:02m:31s remains)
INFO - root - 2022-02-24 20:47:51.512916: step 136520, total loss = 0.53, batch loss = 0.28 (268.2 examples/sec; 0.030 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 20:47:51.930596: step 136530, total loss = 0.58, batch loss = 0.32 (189.3 examples/sec; 0.042 sec/batch; 0h:44m:21s remains)
INFO - root - 2022-02-24 20:47:52.246976: step 136540, total loss = 0.51, batch loss = 0.26 (214.9 examples/sec; 0.037 sec/batch; 0h:39m:03s remains)
INFO - root - 2022-02-24 20:47:52.580884: step 136550, total loss = 0.52, batch loss = 0.26 (176.0 examples/sec; 0.045 sec/batch; 0h:47m:41s remains)
INFO - root - 2022-02-24 20:47:52.968332: step 136560, total loss = 0.51, batch loss = 0.25 (316.7 examples/sec; 0.025 sec/batch; 0h:26m:29s remains)
INFO - root - 2022-02-24 20:47:53.385900: step 136570, total loss = 0.49, batch loss = 0.23 (364.7 examples/sec; 0.022 sec/batch; 0h:23m:00s remains)
INFO - root - 2022-02-24 20:47:54.043551: step 136580, total loss = 0.55, batch loss = 0.29 (132.7 examples/sec; 0.060 sec/batch; 1h:03m:13s remains)
INFO - root - 2022-02-24 20:47:54.692664: step 136590, total loss = 0.49, batch loss = 0.23 (178.2 examples/sec; 0.045 sec/batch; 0h:47m:03s remains)
INFO - root - 2022-02-24 20:47:55.063593: step 136600, total loss = 0.60, batch loss = 0.35 (343.4 examples/sec; 0.023 sec/batch; 0h:24m:25s remains)
INFO - root - 2022-02-24 20:47:55.523628: step 136610, total loss = 0.58, batch loss = 0.32 (146.4 examples/sec; 0.055 sec/batch; 0h:57m:17s remains)
INFO - root - 2022-02-24 20:47:55.908085: step 136620, total loss = 0.50, batch loss = 0.24 (227.9 examples/sec; 0.035 sec/batch; 0h:36m:47s remains)
INFO - root - 2022-02-24 20:47:56.237354: step 136630, total loss = 0.43, batch loss = 0.17 (261.4 examples/sec; 0.031 sec/batch; 0h:32m:03s remains)
INFO - root - 2022-02-24 20:47:56.605619: step 136640, total loss = 0.59, batch loss = 0.33 (282.8 examples/sec; 0.028 sec/batch; 0h:29m:38s remains)
INFO - root - 2022-02-24 20:47:56.989266: step 136650, total loss = 0.57, batch loss = 0.31 (231.6 examples/sec; 0.035 sec/batch; 0h:36m:10s remains)
INFO - root - 2022-02-24 20:47:57.838975: step 136660, total loss = 0.50, batch loss = 0.24 (168.7 examples/sec; 0.047 sec/batch; 0h:49m:39s remains)
INFO - root - 2022-02-24 20:47:58.302340: step 136670, total loss = 0.50, batch loss = 0.24 (332.6 examples/sec; 0.024 sec/batch; 0h:25m:11s remains)
INFO - root - 2022-02-24 20:47:58.756247: step 136680, total loss = 0.75, batch loss = 0.49 (310.2 examples/sec; 0.026 sec/batch; 0h:27m:00s remains)
INFO - root - 2022-02-24 20:47:59.085408: step 136690, total loss = 0.49, batch loss = 0.23 (305.2 examples/sec; 0.026 sec/batch; 0h:27m:26s remains)
INFO - root - 2022-02-24 20:47:59.515961: step 136700, total loss = 0.53, batch loss = 0.27 (223.6 examples/sec; 0.036 sec/batch; 0h:37m:27s remains)
INFO - root - 2022-02-24 20:48:00.190274: step 136710, total loss = 0.59, batch loss = 0.33 (340.7 examples/sec; 0.023 sec/batch; 0h:24m:34s remains)
INFO - root - 2022-02-24 20:48:00.614800: step 136720, total loss = 0.65, batch loss = 0.39 (249.2 examples/sec; 0.032 sec/batch; 0h:33m:35s remains)
INFO - root - 2022-02-24 20:48:00.921148: step 136730, total loss = 0.59, batch loss = 0.33 (213.5 examples/sec; 0.037 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 20:48:01.218421: step 136740, total loss = 0.51, batch loss = 0.25 (336.8 examples/sec; 0.024 sec/batch; 0h:24m:50s remains)
INFO - root - 2022-02-24 20:48:01.589397: step 136750, total loss = 0.55, batch loss = 0.29 (344.9 examples/sec; 0.023 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:48:01.944328: step 136760, total loss = 0.53, batch loss = 0.27 (117.4 examples/sec; 0.068 sec/batch; 1h:11m:15s remains)
INFO - root - 2022-02-24 20:48:02.315061: step 136770, total loss = 0.53, batch loss = 0.27 (321.5 examples/sec; 0.025 sec/batch; 0h:26m:00s remains)
INFO - root - 2022-02-24 20:48:02.767372: step 136780, total loss = 0.77, batch loss = 0.51 (374.1 examples/sec; 0.021 sec/batch; 0h:22m:21s remains)
INFO - root - 2022-02-24 20:48:03.133759: step 136790, total loss = 0.56, batch loss = 0.30 (210.0 examples/sec; 0.038 sec/batch; 0h:39m:48s remains)
INFO - root - 2022-02-24 20:48:03.444795: step 136800, total loss = 0.55, batch loss = 0.29 (338.1 examples/sec; 0.024 sec/batch; 0h:24m:43s remains)
INFO - root - 2022-02-24 20:48:03.830462: step 136810, total loss = 0.55, batch loss = 0.29 (306.8 examples/sec; 0.026 sec/batch; 0h:27m:14s remains)
INFO - root - 2022-02-24 20:48:04.130789: step 136820, total loss = 0.58, batch loss = 0.32 (172.4 examples/sec; 0.046 sec/batch; 0h:48m:27s remains)
INFO - root - 2022-02-24 20:48:04.584996: step 136830, total loss = 0.41, batch loss = 0.15 (135.6 examples/sec; 0.059 sec/batch; 1h:01m:38s remains)
INFO - root - 2022-02-24 20:48:05.043574: step 136840, total loss = 0.46, batch loss = 0.20 (170.0 examples/sec; 0.047 sec/batch; 0h:49m:08s remains)
INFO - root - 2022-02-24 20:48:05.352474: step 136850, total loss = 0.57, batch loss = 0.31 (239.9 examples/sec; 0.033 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:48:05.633631: step 136860, total loss = 0.52, batch loss = 0.26 (310.7 examples/sec; 0.026 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 20:48:06.011540: step 136870, total loss = 0.57, batch loss = 0.31 (165.2 examples/sec; 0.048 sec/batch; 0h:50m:32s remains)
INFO - root - 2022-02-24 20:48:06.421376: step 136880, total loss = 0.51, batch loss = 0.25 (185.6 examples/sec; 0.043 sec/batch; 0h:44m:59s remains)
INFO - root - 2022-02-24 20:48:06.905336: step 136890, total loss = 0.54, batch loss = 0.28 (116.8 examples/sec; 0.069 sec/batch; 1h:11m:29s remains)
INFO - root - 2022-02-24 20:48:07.191752: step 136900, total loss = 0.53, batch loss = 0.27 (346.3 examples/sec; 0.023 sec/batch; 0h:24m:06s remains)
INFO - root - 2022-02-24 20:48:07.610683: step 136910, total loss = 0.63, batch loss = 0.37 (309.0 examples/sec; 0.026 sec/batch; 0h:27m:00s remains)
INFO - root - 2022-02-24 20:48:07.942884: step 136920, total loss = 0.54, batch loss = 0.29 (280.0 examples/sec; 0.029 sec/batch; 0h:29m:47s remains)
INFO - root - 2022-02-24 20:48:08.243820: step 136930, total loss = 0.47, batch loss = 0.21 (141.3 examples/sec; 0.057 sec/batch; 0h:59m:02s remains)
INFO - root - 2022-02-24 20:48:08.684942: step 136940, total loss = 0.62, batch loss = 0.36 (126.1 examples/sec; 0.063 sec/batch; 1h:06m:09s remains)
INFO - root - 2022-02-24 20:48:09.106468: step 136950, total loss = 0.59, batch loss = 0.33 (202.2 examples/sec; 0.040 sec/batch; 0h:41m:14s remains)
INFO - root - 2022-02-24 20:48:09.479876: step 136960, total loss = 0.47, batch loss = 0.21 (140.8 examples/sec; 0.057 sec/batch; 0h:59m:12s remains)
INFO - root - 2022-02-24 20:48:09.815055: step 136970, total loss = 0.50, batch loss = 0.24 (269.7 examples/sec; 0.030 sec/batch; 0h:30m:55s remains)
INFO - root - 2022-02-24 20:48:10.191958: step 136980, total loss = 0.55, batch loss = 0.29 (176.2 examples/sec; 0.045 sec/batch; 0h:47m:18s remains)
INFO - root - 2022-02-24 20:48:10.630221: step 136990, total loss = 0.51, batch loss = 0.25 (177.8 examples/sec; 0.045 sec/batch; 0h:46m:53s remains)
INFO - root - 2022-02-24 20:48:11.118392: step 137000, total loss = 0.53, batch loss = 0.28 (112.8 examples/sec; 0.071 sec/batch; 1h:13m:51s remains)
INFO - root - 2022-02-24 20:48:12.136144: step 137010, total loss = 0.49, batch loss = 0.23 (247.7 examples/sec; 0.032 sec/batch; 0h:33m:38s remains)
INFO - root - 2022-02-24 20:48:12.377410: step 137020, total loss = 0.52, batch loss = 0.26 (358.1 examples/sec; 0.022 sec/batch; 0h:23m:15s remains)
INFO - root - 2022-02-24 20:48:12.601344: step 137030, total loss = 0.64, batch loss = 0.38 (371.8 examples/sec; 0.022 sec/batch; 0h:22m:24s remains)
INFO - root - 2022-02-24 20:48:13.532481: step 137040, total loss = 0.46, batch loss = 0.20 (142.8 examples/sec; 0.056 sec/batch; 0h:58m:19s remains)
INFO - root - 2022-02-24 20:48:13.893100: step 137050, total loss = 0.53, batch loss = 0.27 (159.8 examples/sec; 0.050 sec/batch; 0h:52m:05s remains)
INFO - root - 2022-02-24 20:48:14.259573: step 137060, total loss = 0.56, batch loss = 0.30 (247.6 examples/sec; 0.032 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:48:14.590495: step 137070, total loss = 0.60, batch loss = 0.34 (276.5 examples/sec; 0.029 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:48:15.144434: step 137080, total loss = 0.60, batch loss = 0.34 (125.5 examples/sec; 0.064 sec/batch; 1h:06m:18s remains)
INFO - root - 2022-02-24 20:48:15.589100: step 137090, total loss = 0.65, batch loss = 0.40 (115.3 examples/sec; 0.069 sec/batch; 1h:12m:10s remains)
INFO - root - 2022-02-24 20:48:15.979608: step 137100, total loss = 0.55, batch loss = 0.29 (126.1 examples/sec; 0.063 sec/batch; 1h:05m:57s remains)
INFO - root - 2022-02-24 20:48:16.380390: step 137110, total loss = 0.48, batch loss = 0.22 (266.4 examples/sec; 0.030 sec/batch; 0h:31m:13s remains)
INFO - root - 2022-02-24 20:48:16.802208: step 137120, total loss = 0.52, batch loss = 0.26 (232.9 examples/sec; 0.034 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 20:48:17.217483: step 137130, total loss = 0.52, batch loss = 0.26 (149.9 examples/sec; 0.053 sec/batch; 0h:55m:28s remains)
INFO - root - 2022-02-24 20:48:17.699538: step 137140, total loss = 0.47, batch loss = 0.21 (79.5 examples/sec; 0.101 sec/batch; 1h:44m:32s remains)
INFO - root - 2022-02-24 20:48:18.034003: step 137150, total loss = 0.69, batch loss = 0.43 (277.0 examples/sec; 0.029 sec/batch; 0h:30m:00s remains)
INFO - root - 2022-02-24 20:48:18.422835: step 137160, total loss = 0.49, batch loss = 0.23 (305.7 examples/sec; 0.026 sec/batch; 0h:27m:11s remains)
INFO - root - 2022-02-24 20:48:18.803962: step 137170, total loss = 0.54, batch loss = 0.28 (157.9 examples/sec; 0.051 sec/batch; 0h:52m:37s remains)
INFO - root - 2022-02-24 20:48:19.279558: step 137180, total loss = 0.48, batch loss = 0.23 (143.9 examples/sec; 0.056 sec/batch; 0h:57m:45s remains)
INFO - root - 2022-02-24 20:48:19.751310: step 137190, total loss = 0.64, batch loss = 0.38 (147.6 examples/sec; 0.054 sec/batch; 0h:56m:16s remains)
INFO - root - 2022-02-24 20:48:20.083150: step 137200, total loss = 0.53, batch loss = 0.27 (326.8 examples/sec; 0.024 sec/batch; 0h:25m:25s remains)
INFO - root - 2022-02-24 20:48:20.444730: step 137210, total loss = 0.52, batch loss = 0.26 (338.9 examples/sec; 0.024 sec/batch; 0h:24m:30s remains)
INFO - root - 2022-02-24 20:48:20.759340: step 137220, total loss = 0.56, batch loss = 0.30 (344.2 examples/sec; 0.023 sec/batch; 0h:24m:07s remains)
INFO - root - 2022-02-24 20:48:21.186620: step 137230, total loss = 0.51, batch loss = 0.25 (149.6 examples/sec; 0.053 sec/batch; 0h:55m:30s remains)
INFO - root - 2022-02-24 20:48:21.678747: step 137240, total loss = 0.47, batch loss = 0.21 (163.7 examples/sec; 0.049 sec/batch; 0h:50m:42s remains)
INFO - root - 2022-02-24 20:48:22.076246: step 137250, total loss = 0.59, batch loss = 0.33 (187.6 examples/sec; 0.043 sec/batch; 0h:44m:15s remains)
INFO - root - 2022-02-24 20:48:22.421315: step 137260, total loss = 0.57, batch loss = 0.31 (312.6 examples/sec; 0.026 sec/batch; 0h:26m:32s remains)
INFO - root - 2022-02-24 20:48:22.797504: step 137270, total loss = 0.64, batch loss = 0.38 (167.3 examples/sec; 0.048 sec/batch; 0h:49m:35s remains)
INFO - root - 2022-02-24 20:48:23.095236: step 137280, total loss = 0.61, batch loss = 0.35 (277.5 examples/sec; 0.029 sec/batch; 0h:29m:53s remains)
INFO - root - 2022-02-24 20:48:23.534171: step 137290, total loss = 0.52, batch loss = 0.26 (186.3 examples/sec; 0.043 sec/batch; 0h:44m:30s remains)
INFO - root - 2022-02-24 20:48:23.951345: step 137300, total loss = 0.52, batch loss = 0.26 (218.9 examples/sec; 0.037 sec/batch; 0h:37m:52s remains)
INFO - root - 2022-02-24 20:48:24.355158: step 137310, total loss = 0.47, batch loss = 0.22 (346.4 examples/sec; 0.023 sec/batch; 0h:23m:56s remains)
INFO - root - 2022-02-24 20:48:24.659065: step 137320, total loss = 0.57, batch loss = 0.31 (203.6 examples/sec; 0.039 sec/batch; 0h:40m:43s remains)
INFO - root - 2022-02-24 20:48:24.982909: step 137330, total loss = 0.55, batch loss = 0.29 (336.1 examples/sec; 0.024 sec/batch; 0h:24m:39s remains)
INFO - root - 2022-02-24 20:48:25.290594: step 137340, total loss = 0.62, batch loss = 0.36 (224.7 examples/sec; 0.036 sec/batch; 0h:36m:53s remains)
INFO - root - 2022-02-24 20:48:25.632031: step 137350, total loss = 0.51, batch loss = 0.25 (180.5 examples/sec; 0.044 sec/batch; 0h:45m:54s remains)
INFO - root - 2022-02-24 20:48:26.013560: step 137360, total loss = 0.49, batch loss = 0.23 (342.4 examples/sec; 0.023 sec/batch; 0h:24m:11s remains)
INFO - root - 2022-02-24 20:48:26.510801: step 137370, total loss = 0.52, batch loss = 0.26 (130.4 examples/sec; 0.061 sec/batch; 1h:03m:32s remains)
INFO - root - 2022-02-24 20:48:26.868410: step 137380, total loss = 0.56, batch loss = 0.30 (338.8 examples/sec; 0.024 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 20:48:27.542029: step 137390, total loss = 0.55, batch loss = 0.29 (294.2 examples/sec; 0.027 sec/batch; 0h:28m:08s remains)
INFO - root - 2022-02-24 20:48:28.623138: step 137400, total loss = 0.58, batch loss = 0.32 (168.4 examples/sec; 0.048 sec/batch; 0h:49m:10s remains)
INFO - root - 2022-02-24 20:48:29.141241: step 137410, total loss = 0.65, batch loss = 0.39 (167.7 examples/sec; 0.048 sec/batch; 0h:49m:21s remains)
INFO - root - 2022-02-24 20:48:29.551795: step 137420, total loss = 0.68, batch loss = 0.42 (186.5 examples/sec; 0.043 sec/batch; 0h:44m:23s remains)
INFO - root - 2022-02-24 20:48:29.899710: step 137430, total loss = 0.55, batch loss = 0.29 (271.1 examples/sec; 0.030 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 20:48:30.285462: step 137440, total loss = 0.42, batch loss = 0.16 (301.1 examples/sec; 0.027 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:48:30.643276: step 137450, total loss = 0.47, batch loss = 0.21 (191.1 examples/sec; 0.042 sec/batch; 0h:43m:16s remains)
INFO - root - 2022-02-24 20:48:31.066437: step 137460, total loss = 0.49, batch loss = 0.23 (315.6 examples/sec; 0.025 sec/batch; 0h:26m:12s remains)
INFO - root - 2022-02-24 20:48:31.524780: step 137470, total loss = 0.54, batch loss = 0.28 (141.9 examples/sec; 0.056 sec/batch; 0h:58m:16s remains)
INFO - root - 2022-02-24 20:48:31.924195: step 137480, total loss = 0.57, batch loss = 0.31 (197.2 examples/sec; 0.041 sec/batch; 0h:41m:55s remains)
INFO - root - 2022-02-24 20:48:32.283254: step 137490, total loss = 0.54, batch loss = 0.29 (315.4 examples/sec; 0.025 sec/batch; 0h:26m:12s remains)
INFO - root - 2022-02-24 20:48:32.772725: step 137500, total loss = 0.45, batch loss = 0.20 (174.1 examples/sec; 0.046 sec/batch; 0h:47m:28s remains)
INFO - root - 2022-02-24 20:48:33.311048: step 137510, total loss = 0.52, batch loss = 0.27 (222.3 examples/sec; 0.036 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:48:33.657475: step 137520, total loss = 0.51, batch loss = 0.26 (338.3 examples/sec; 0.024 sec/batch; 0h:24m:25s remains)
INFO - root - 2022-02-24 20:48:33.908977: step 137530, total loss = 0.48, batch loss = 0.22 (235.3 examples/sec; 0.034 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:48:34.258579: step 137540, total loss = 0.64, batch loss = 0.38 (265.1 examples/sec; 0.030 sec/batch; 0h:31m:09s remains)
INFO - root - 2022-02-24 20:48:34.728041: step 137550, total loss = 0.50, batch loss = 0.24 (136.9 examples/sec; 0.058 sec/batch; 1h:00m:18s remains)
INFO - root - 2022-02-24 20:48:35.116428: step 137560, total loss = 0.71, batch loss = 0.45 (341.5 examples/sec; 0.023 sec/batch; 0h:24m:10s remains)
INFO - root - 2022-02-24 20:48:35.554492: step 137570, total loss = 0.55, batch loss = 0.29 (335.3 examples/sec; 0.024 sec/batch; 0h:24m:37s remains)
INFO - root - 2022-02-24 20:48:35.812509: step 137580, total loss = 0.64, batch loss = 0.38 (325.4 examples/sec; 0.025 sec/batch; 0h:25m:22s remains)
INFO - root - 2022-02-24 20:48:36.134757: step 137590, total loss = 0.58, batch loss = 0.33 (145.9 examples/sec; 0.055 sec/batch; 0h:56m:35s remains)
INFO - root - 2022-02-24 20:48:36.434791: step 137600, total loss = 0.57, batch loss = 0.31 (170.7 examples/sec; 0.047 sec/batch; 0h:48m:20s remains)
INFO - root - 2022-02-24 20:48:36.829282: step 137610, total loss = 0.52, batch loss = 0.26 (282.7 examples/sec; 0.028 sec/batch; 0h:29m:11s remains)
INFO - root - 2022-02-24 20:48:37.287984: step 137620, total loss = 0.65, batch loss = 0.39 (196.9 examples/sec; 0.041 sec/batch; 0h:41m:54s remains)
INFO - root - 2022-02-24 20:48:37.586982: step 137630, total loss = 0.59, batch loss = 0.33 (337.8 examples/sec; 0.024 sec/batch; 0h:24m:25s remains)
INFO - root - 2022-02-24 20:48:37.928975: step 137640, total loss = 0.54, batch loss = 0.28 (207.1 examples/sec; 0.039 sec/batch; 0h:39m:49s remains)
INFO - root - 2022-02-24 20:48:38.296673: step 137650, total loss = 0.51, batch loss = 0.26 (209.5 examples/sec; 0.038 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:48:38.730465: step 137660, total loss = 0.47, batch loss = 0.21 (258.5 examples/sec; 0.031 sec/batch; 0h:31m:53s remains)
INFO - root - 2022-02-24 20:48:39.169748: step 137670, total loss = 0.55, batch loss = 0.29 (224.4 examples/sec; 0.036 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:48:39.567390: step 137680, total loss = 0.66, batch loss = 0.40 (271.9 examples/sec; 0.029 sec/batch; 0h:30m:18s remains)
INFO - root - 2022-02-24 20:48:39.922562: step 137690, total loss = 0.52, batch loss = 0.26 (162.2 examples/sec; 0.049 sec/batch; 0h:50m:48s remains)
INFO - root - 2022-02-24 20:48:40.241870: step 137700, total loss = 0.87, batch loss = 0.62 (175.2 examples/sec; 0.046 sec/batch; 0h:47m:02s remains)
INFO - root - 2022-02-24 20:48:40.612128: step 137710, total loss = 0.69, batch loss = 0.43 (295.8 examples/sec; 0.027 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 20:48:41.032533: step 137720, total loss = 0.49, batch loss = 0.23 (218.0 examples/sec; 0.037 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:48:41.535980: step 137730, total loss = 0.55, batch loss = 0.29 (203.3 examples/sec; 0.039 sec/batch; 0h:40m:30s remains)
INFO - root - 2022-02-24 20:48:41.944537: step 137740, total loss = 0.55, batch loss = 0.30 (371.7 examples/sec; 0.022 sec/batch; 0h:22m:09s remains)
INFO - root - 2022-02-24 20:48:42.307030: step 137750, total loss = 0.55, batch loss = 0.29 (203.2 examples/sec; 0.039 sec/batch; 0h:40m:30s remains)
INFO - root - 2022-02-24 20:48:42.577981: step 137760, total loss = 0.61, batch loss = 0.35 (336.3 examples/sec; 0.024 sec/batch; 0h:24m:28s remains)
INFO - root - 2022-02-24 20:48:42.906083: step 137770, total loss = 0.55, batch loss = 0.29 (336.0 examples/sec; 0.024 sec/batch; 0h:24m:29s remains)
INFO - root - 2022-02-24 20:48:43.314737: step 137780, total loss = 0.51, batch loss = 0.25 (292.9 examples/sec; 0.027 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:48:44.274373: step 137790, total loss = 0.63, batch loss = 0.37 (169.5 examples/sec; 0.047 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 20:48:44.678113: step 137800, total loss = 0.51, batch loss = 0.25 (159.6 examples/sec; 0.050 sec/batch; 0h:51m:33s remains)
INFO - root - 2022-02-24 20:48:45.046748: step 137810, total loss = 0.51, batch loss = 0.25 (310.2 examples/sec; 0.026 sec/batch; 0h:26m:30s remains)
INFO - root - 2022-02-24 20:48:45.484979: step 137820, total loss = 0.52, batch loss = 0.26 (198.0 examples/sec; 0.040 sec/batch; 0h:41m:32s remains)
INFO - root - 2022-02-24 20:48:45.895862: step 137830, total loss = 0.57, batch loss = 0.32 (187.7 examples/sec; 0.043 sec/batch; 0h:43m:49s remains)
INFO - root - 2022-02-24 20:48:46.372549: step 137840, total loss = 0.64, batch loss = 0.38 (144.5 examples/sec; 0.055 sec/batch; 0h:56m:53s remains)
INFO - root - 2022-02-24 20:48:46.759309: step 137850, total loss = 0.49, batch loss = 0.24 (253.4 examples/sec; 0.032 sec/batch; 0h:32m:25s remains)
INFO - root - 2022-02-24 20:48:47.096414: step 137860, total loss = 0.57, batch loss = 0.31 (182.0 examples/sec; 0.044 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:48:47.518969: step 137870, total loss = 0.54, batch loss = 0.28 (225.4 examples/sec; 0.035 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:48:47.944305: step 137880, total loss = 0.64, batch loss = 0.38 (343.4 examples/sec; 0.023 sec/batch; 0h:23m:55s remains)
INFO - root - 2022-02-24 20:48:48.446563: step 137890, total loss = 0.59, batch loss = 0.33 (149.4 examples/sec; 0.054 sec/batch; 0h:55m:00s remains)
INFO - root - 2022-02-24 20:48:48.780055: step 137900, total loss = 0.59, batch loss = 0.33 (349.4 examples/sec; 0.023 sec/batch; 0h:23m:30s remains)
INFO - root - 2022-02-24 20:48:49.425877: step 137910, total loss = 0.56, batch loss = 0.30 (259.1 examples/sec; 0.031 sec/batch; 0h:31m:41s remains)
INFO - root - 2022-02-24 20:48:49.926128: step 137920, total loss = 0.43, batch loss = 0.17 (102.7 examples/sec; 0.078 sec/batch; 1h:19m:56s remains)
INFO - root - 2022-02-24 20:48:50.331636: step 137930, total loss = 0.53, batch loss = 0.27 (336.2 examples/sec; 0.024 sec/batch; 0h:24m:24s remains)
INFO - root - 2022-02-24 20:48:50.684473: step 137940, total loss = 0.65, batch loss = 0.40 (78.3 examples/sec; 0.102 sec/batch; 1h:44m:47s remains)
INFO - root - 2022-02-24 20:48:51.001849: step 137950, total loss = 0.53, batch loss = 0.27 (293.4 examples/sec; 0.027 sec/batch; 0h:27m:58s remains)
INFO - root - 2022-02-24 20:48:51.403960: step 137960, total loss = 0.55, batch loss = 0.29 (298.1 examples/sec; 0.027 sec/batch; 0h:27m:31s remains)
INFO - root - 2022-02-24 20:48:51.770598: step 137970, total loss = 0.62, batch loss = 0.37 (277.9 examples/sec; 0.029 sec/batch; 0h:29m:31s remains)
INFO - root - 2022-02-24 20:48:52.147520: step 137980, total loss = 0.50, batch loss = 0.24 (307.5 examples/sec; 0.026 sec/batch; 0h:26m:40s remains)
INFO - root - 2022-02-24 20:48:52.546391: step 137990, total loss = 0.55, batch loss = 0.30 (211.3 examples/sec; 0.038 sec/batch; 0h:38m:49s remains)
INFO - root - 2022-02-24 20:48:52.973163: step 138000, total loss = 0.61, batch loss = 0.35 (157.7 examples/sec; 0.051 sec/batch; 0h:51m:59s remains)
INFO - root - 2022-02-24 20:48:53.360165: step 138010, total loss = 0.76, batch loss = 0.50 (323.1 examples/sec; 0.025 sec/batch; 0h:25m:22s remains)
INFO - root - 2022-02-24 20:48:53.699156: step 138020, total loss = 0.45, batch loss = 0.19 (208.2 examples/sec; 0.038 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:48:54.124579: step 138030, total loss = 0.57, batch loss = 0.31 (122.6 examples/sec; 0.065 sec/batch; 1h:06m:50s remains)
INFO - root - 2022-02-24 20:48:54.563519: step 138040, total loss = 0.52, batch loss = 0.26 (354.5 examples/sec; 0.023 sec/batch; 0h:23m:06s remains)
INFO - root - 2022-02-24 20:48:54.926681: step 138050, total loss = 0.47, batch loss = 0.21 (183.4 examples/sec; 0.044 sec/batch; 0h:44m:40s remains)
INFO - root - 2022-02-24 20:48:55.245699: step 138060, total loss = 0.54, batch loss = 0.28 (117.3 examples/sec; 0.068 sec/batch; 1h:09m:51s remains)
INFO - root - 2022-02-24 20:48:55.549068: step 138070, total loss = 0.63, batch loss = 0.37 (300.6 examples/sec; 0.027 sec/batch; 0h:27m:15s remains)
INFO - root - 2022-02-24 20:48:55.880383: step 138080, total loss = 0.50, batch loss = 0.24 (308.8 examples/sec; 0.026 sec/batch; 0h:26m:30s remains)
INFO - root - 2022-02-24 20:48:56.303017: step 138090, total loss = 0.55, batch loss = 0.29 (105.6 examples/sec; 0.076 sec/batch; 1h:17m:32s remains)
INFO - root - 2022-02-24 20:48:56.718533: step 138100, total loss = 0.54, batch loss = 0.28 (350.6 examples/sec; 0.023 sec/batch; 0h:23m:20s remains)
INFO - root - 2022-02-24 20:48:57.085525: step 138110, total loss = 0.56, batch loss = 0.31 (362.0 examples/sec; 0.022 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 20:48:57.382450: step 138120, total loss = 0.50, batch loss = 0.24 (279.6 examples/sec; 0.029 sec/batch; 0h:29m:16s remains)
INFO - root - 2022-02-24 20:48:57.711308: step 138130, total loss = 0.57, batch loss = 0.31 (320.0 examples/sec; 0.025 sec/batch; 0h:25m:34s remains)
INFO - root - 2022-02-24 20:48:58.005057: step 138140, total loss = 0.48, batch loss = 0.22 (206.2 examples/sec; 0.039 sec/batch; 0h:39m:40s remains)
INFO - root - 2022-02-24 20:48:58.383204: step 138150, total loss = 0.62, batch loss = 0.37 (223.3 examples/sec; 0.036 sec/batch; 0h:36m:37s remains)
INFO - root - 2022-02-24 20:48:58.846219: step 138160, total loss = 0.53, batch loss = 0.27 (309.1 examples/sec; 0.026 sec/batch; 0h:26m:27s remains)
INFO - root - 2022-02-24 20:48:59.211142: step 138170, total loss = 0.54, batch loss = 0.28 (180.8 examples/sec; 0.044 sec/batch; 0h:45m:13s remains)
INFO - root - 2022-02-24 20:48:59.596881: step 138180, total loss = 0.53, batch loss = 0.27 (326.0 examples/sec; 0.025 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 20:49:00.076365: step 138190, total loss = 0.49, batch loss = 0.24 (200.2 examples/sec; 0.040 sec/batch; 0h:40m:50s remains)
INFO - root - 2022-02-24 20:49:00.522509: step 138200, total loss = 0.54, batch loss = 0.28 (209.5 examples/sec; 0.038 sec/batch; 0h:39m:01s remains)
INFO - root - 2022-02-24 20:49:00.904002: step 138210, total loss = 0.54, batch loss = 0.28 (367.6 examples/sec; 0.022 sec/batch; 0h:22m:14s remains)
INFO - root - 2022-02-24 20:49:01.284022: step 138220, total loss = 0.49, batch loss = 0.23 (108.6 examples/sec; 0.074 sec/batch; 1h:15m:15s remains)
INFO - root - 2022-02-24 20:49:01.628655: step 138230, total loss = 0.53, batch loss = 0.27 (356.7 examples/sec; 0.022 sec/batch; 0h:22m:54s remains)
INFO - root - 2022-02-24 20:49:01.948506: step 138240, total loss = 0.50, batch loss = 0.24 (323.7 examples/sec; 0.025 sec/batch; 0h:25m:13s remains)
INFO - root - 2022-02-24 20:49:02.268629: step 138250, total loss = 0.63, batch loss = 0.37 (352.7 examples/sec; 0.023 sec/batch; 0h:23m:09s remains)
INFO - root - 2022-02-24 20:49:02.650168: step 138260, total loss = 0.50, batch loss = 0.24 (318.9 examples/sec; 0.025 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 20:49:03.062562: step 138270, total loss = 0.62, batch loss = 0.36 (318.8 examples/sec; 0.025 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 20:49:03.397885: step 138280, total loss = 0.53, batch loss = 0.27 (303.1 examples/sec; 0.026 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 20:49:03.711240: step 138290, total loss = 0.61, batch loss = 0.35 (264.8 examples/sec; 0.030 sec/batch; 0h:30m:49s remains)
INFO - root - 2022-02-24 20:49:04.070088: step 138300, total loss = 0.58, batch loss = 0.32 (289.3 examples/sec; 0.028 sec/batch; 0h:28m:12s remains)
INFO - root - 2022-02-24 20:49:04.547963: step 138310, total loss = 0.49, batch loss = 0.23 (235.6 examples/sec; 0.034 sec/batch; 0h:34m:38s remains)
INFO - root - 2022-02-24 20:49:04.959219: step 138320, total loss = 0.63, batch loss = 0.38 (347.3 examples/sec; 0.023 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:49:05.309809: step 138330, total loss = 0.56, batch loss = 0.30 (230.9 examples/sec; 0.035 sec/batch; 0h:35m:19s remains)
INFO - root - 2022-02-24 20:49:05.715920: step 138340, total loss = 0.57, batch loss = 0.31 (296.5 examples/sec; 0.027 sec/batch; 0h:27m:30s remains)
INFO - root - 2022-02-24 20:49:06.231616: step 138350, total loss = 0.56, batch loss = 0.31 (206.7 examples/sec; 0.039 sec/batch; 0h:39m:26s remains)
INFO - root - 2022-02-24 20:49:06.682158: step 138360, total loss = 0.78, batch loss = 0.53 (205.2 examples/sec; 0.039 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:49:07.200713: step 138370, total loss = 0.51, batch loss = 0.25 (126.6 examples/sec; 0.063 sec/batch; 1h:04m:22s remains)
INFO - root - 2022-02-24 20:49:07.855173: step 138380, total loss = 0.47, batch loss = 0.22 (331.9 examples/sec; 0.024 sec/batch; 0h:24m:33s remains)
INFO - root - 2022-02-24 20:49:08.254619: step 138390, total loss = 0.58, batch loss = 0.32 (220.6 examples/sec; 0.036 sec/batch; 0h:36m:56s remains)
INFO - root - 2022-02-24 20:49:08.702760: step 138400, total loss = 0.49, batch loss = 0.23 (132.1 examples/sec; 0.061 sec/batch; 1h:01m:41s remains)
INFO - root - 2022-02-24 20:49:09.162194: step 138410, total loss = 0.50, batch loss = 0.24 (126.2 examples/sec; 0.063 sec/batch; 1h:04m:32s remains)
INFO - root - 2022-02-24 20:49:10.027733: step 138420, total loss = 0.57, batch loss = 0.31 (169.3 examples/sec; 0.047 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:49:10.416979: step 138430, total loss = 0.55, batch loss = 0.29 (209.4 examples/sec; 0.038 sec/batch; 0h:38m:52s remains)
INFO - root - 2022-02-24 20:49:10.833157: step 138440, total loss = 0.48, batch loss = 0.22 (330.3 examples/sec; 0.024 sec/batch; 0h:24m:38s remains)
INFO - root - 2022-02-24 20:49:11.252683: step 138450, total loss = 0.56, batch loss = 0.30 (289.7 examples/sec; 0.028 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:49:11.637379: step 138460, total loss = 0.46, batch loss = 0.20 (325.3 examples/sec; 0.025 sec/batch; 0h:25m:01s remains)
INFO - root - 2022-02-24 20:49:11.994028: step 138470, total loss = 0.50, batch loss = 0.24 (236.2 examples/sec; 0.034 sec/batch; 0h:34m:27s remains)
INFO - root - 2022-02-24 20:49:12.334808: step 138480, total loss = 0.56, batch loss = 0.30 (176.9 examples/sec; 0.045 sec/batch; 0h:45m:59s remains)
INFO - root - 2022-02-24 20:49:12.665167: step 138490, total loss = 0.48, batch loss = 0.22 (161.4 examples/sec; 0.050 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:49:13.061166: step 138500, total loss = 0.57, batch loss = 0.32 (230.2 examples/sec; 0.035 sec/batch; 0h:35m:19s remains)
INFO - root - 2022-02-24 20:49:13.524432: step 138510, total loss = 0.52, batch loss = 0.26 (183.0 examples/sec; 0.044 sec/batch; 0h:44m:26s remains)
INFO - root - 2022-02-24 20:49:13.932740: step 138520, total loss = 0.59, batch loss = 0.33 (217.8 examples/sec; 0.037 sec/batch; 0h:37m:19s remains)
INFO - root - 2022-02-24 20:49:14.251492: step 138530, total loss = 0.53, batch loss = 0.27 (319.1 examples/sec; 0.025 sec/batch; 0h:25m:28s remains)
INFO - root - 2022-02-24 20:49:14.658217: step 138540, total loss = 0.57, batch loss = 0.31 (207.4 examples/sec; 0.039 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 20:49:15.142341: step 138550, total loss = 0.53, batch loss = 0.27 (222.0 examples/sec; 0.036 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:49:15.586836: step 138560, total loss = 0.51, batch loss = 0.25 (257.3 examples/sec; 0.031 sec/batch; 0h:31m:34s remains)
INFO - root - 2022-02-24 20:49:15.980715: step 138570, total loss = 0.48, batch loss = 0.22 (152.8 examples/sec; 0.052 sec/batch; 0h:53m:10s remains)
INFO - root - 2022-02-24 20:49:16.321978: step 138580, total loss = 0.50, batch loss = 0.24 (262.8 examples/sec; 0.030 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 20:49:16.668108: step 138590, total loss = 0.57, batch loss = 0.31 (178.8 examples/sec; 0.045 sec/batch; 0h:45m:25s remains)
INFO - root - 2022-02-24 20:49:17.035643: step 138600, total loss = 0.50, batch loss = 0.24 (226.4 examples/sec; 0.035 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 20:49:17.585957: step 138610, total loss = 0.55, batch loss = 0.29 (116.7 examples/sec; 0.069 sec/batch; 1h:09m:33s remains)
INFO - root - 2022-02-24 20:49:17.923691: step 138620, total loss = 0.55, batch loss = 0.29 (349.5 examples/sec; 0.023 sec/batch; 0h:23m:13s remains)
INFO - root - 2022-02-24 20:49:18.223590: step 138630, total loss = 0.50, batch loss = 0.24 (334.6 examples/sec; 0.024 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:49:18.498572: step 138640, total loss = 0.52, batch loss = 0.26 (211.0 examples/sec; 0.038 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:49:18.920626: step 138650, total loss = 0.52, batch loss = 0.27 (246.5 examples/sec; 0.032 sec/batch; 0h:32m:54s remains)
INFO - root - 2022-02-24 20:49:19.416874: step 138660, total loss = 0.66, batch loss = 0.40 (367.4 examples/sec; 0.022 sec/batch; 0h:22m:04s remains)
INFO - root - 2022-02-24 20:49:19.818957: step 138670, total loss = 0.62, batch loss = 0.36 (330.1 examples/sec; 0.024 sec/batch; 0h:24m:34s remains)
INFO - root - 2022-02-24 20:49:20.140798: step 138680, total loss = 0.53, batch loss = 0.27 (320.5 examples/sec; 0.025 sec/batch; 0h:25m:18s remains)
INFO - root - 2022-02-24 20:49:20.507152: step 138690, total loss = 0.53, batch loss = 0.27 (231.9 examples/sec; 0.035 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 20:49:20.824028: step 138700, total loss = 0.58, batch loss = 0.32 (291.1 examples/sec; 0.027 sec/batch; 0h:27m:50s remains)
INFO - root - 2022-02-24 20:49:21.301577: step 138710, total loss = 0.55, batch loss = 0.30 (342.7 examples/sec; 0.023 sec/batch; 0h:23m:38s remains)
INFO - root - 2022-02-24 20:49:21.760078: step 138720, total loss = 0.60, batch loss = 0.34 (264.5 examples/sec; 0.030 sec/batch; 0h:30m:38s remains)
INFO - root - 2022-02-24 20:49:22.106458: step 138730, total loss = 0.51, batch loss = 0.25 (324.1 examples/sec; 0.025 sec/batch; 0h:25m:00s remains)
INFO - root - 2022-02-24 20:49:22.415617: step 138740, total loss = 0.58, batch loss = 0.32 (322.0 examples/sec; 0.025 sec/batch; 0h:25m:09s remains)
INFO - root - 2022-02-24 20:49:22.797445: step 138750, total loss = 0.44, batch loss = 0.18 (280.4 examples/sec; 0.029 sec/batch; 0h:28m:53s remains)
INFO - root - 2022-02-24 20:49:23.280216: step 138760, total loss = 0.49, batch loss = 0.23 (151.3 examples/sec; 0.053 sec/batch; 0h:53m:32s remains)
INFO - root - 2022-02-24 20:49:23.688702: step 138770, total loss = 0.55, batch loss = 0.29 (333.2 examples/sec; 0.024 sec/batch; 0h:24m:18s remains)
INFO - root - 2022-02-24 20:49:24.003787: step 138780, total loss = 0.60, batch loss = 0.34 (184.4 examples/sec; 0.043 sec/batch; 0h:43m:54s remains)
INFO - root - 2022-02-24 20:49:24.382217: step 138790, total loss = 0.47, batch loss = 0.21 (117.3 examples/sec; 0.068 sec/batch; 1h:08m:59s remains)
INFO - root - 2022-02-24 20:49:24.741818: step 138800, total loss = 0.55, batch loss = 0.29 (217.0 examples/sec; 0.037 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 20:49:25.275729: step 138810, total loss = 0.63, batch loss = 0.37 (164.7 examples/sec; 0.049 sec/batch; 0h:49m:08s remains)
INFO - root - 2022-02-24 20:49:25.735134: step 138820, total loss = 0.53, batch loss = 0.27 (157.8 examples/sec; 0.051 sec/batch; 0h:51m:17s remains)
INFO - root - 2022-02-24 20:49:26.300114: step 138830, total loss = 0.56, batch loss = 0.31 (102.4 examples/sec; 0.078 sec/batch; 1h:18m:59s remains)
INFO - root - 2022-02-24 20:49:26.791833: step 138840, total loss = 0.51, batch loss = 0.25 (141.3 examples/sec; 0.057 sec/batch; 0h:57m:14s remains)
INFO - root - 2022-02-24 20:49:27.179901: step 138850, total loss = 0.56, batch loss = 0.30 (256.0 examples/sec; 0.031 sec/batch; 0h:31m:35s remains)
INFO - root - 2022-02-24 20:49:27.614312: step 138860, total loss = 0.55, batch loss = 0.29 (213.0 examples/sec; 0.038 sec/batch; 0h:37m:57s remains)
INFO - root - 2022-02-24 20:49:28.143852: step 138870, total loss = 0.51, batch loss = 0.25 (102.7 examples/sec; 0.078 sec/batch; 1h:18m:42s remains)
INFO - root - 2022-02-24 20:49:28.565850: step 138880, total loss = 0.64, batch loss = 0.38 (320.6 examples/sec; 0.025 sec/batch; 0h:25m:12s remains)
INFO - root - 2022-02-24 20:49:28.871821: step 138890, total loss = 0.60, batch loss = 0.34 (303.0 examples/sec; 0.026 sec/batch; 0h:26m:40s remains)
INFO - root - 2022-02-24 20:49:29.174926: step 138900, total loss = 0.77, batch loss = 0.51 (202.5 examples/sec; 0.039 sec/batch; 0h:39m:53s remains)
INFO - root - 2022-02-24 20:49:30.039464: step 138910, total loss = 0.49, batch loss = 0.24 (149.5 examples/sec; 0.053 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 20:49:31.139296: step 138920, total loss = 0.56, batch loss = 0.30 (247.4 examples/sec; 0.032 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 20:49:31.511769: step 138930, total loss = 0.61, batch loss = 0.35 (318.0 examples/sec; 0.025 sec/batch; 0h:25m:23s remains)
INFO - root - 2022-02-24 20:49:31.852437: step 138940, total loss = 0.51, batch loss = 0.25 (295.8 examples/sec; 0.027 sec/batch; 0h:27m:17s remains)
INFO - root - 2022-02-24 20:49:32.184407: step 138950, total loss = 0.58, batch loss = 0.32 (321.8 examples/sec; 0.025 sec/batch; 0h:25m:05s remains)
INFO - root - 2022-02-24 20:49:32.482383: step 138960, total loss = 0.69, batch loss = 0.43 (273.5 examples/sec; 0.029 sec/batch; 0h:29m:30s remains)
INFO - root - 2022-02-24 20:49:32.831051: step 138970, total loss = 0.66, batch loss = 0.40 (188.6 examples/sec; 0.042 sec/batch; 0h:42m:47s remains)
INFO - root - 2022-02-24 20:49:33.251500: step 138980, total loss = 0.62, batch loss = 0.37 (245.3 examples/sec; 0.033 sec/batch; 0h:32m:53s remains)
INFO - root - 2022-02-24 20:49:33.643548: step 138990, total loss = 0.61, batch loss = 0.35 (350.5 examples/sec; 0.023 sec/batch; 0h:23m:00s remains)
INFO - root - 2022-02-24 20:49:33.992035: step 139000, total loss = 0.57, batch loss = 0.31 (120.7 examples/sec; 0.066 sec/batch; 1h:06m:51s remains)
INFO - root - 2022-02-24 20:49:34.437278: step 139010, total loss = 0.53, batch loss = 0.27 (294.5 examples/sec; 0.027 sec/batch; 0h:27m:23s remains)
INFO - root - 2022-02-24 20:49:34.820165: step 139020, total loss = 0.50, batch loss = 0.24 (198.3 examples/sec; 0.040 sec/batch; 0h:40m:40s remains)
INFO - root - 2022-02-24 20:49:35.236730: step 139030, total loss = 0.65, batch loss = 0.39 (166.4 examples/sec; 0.048 sec/batch; 0h:48m:26s remains)
INFO - root - 2022-02-24 20:49:35.626585: step 139040, total loss = 0.60, batch loss = 0.34 (189.9 examples/sec; 0.042 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:49:35.891054: step 139050, total loss = 0.59, batch loss = 0.34 (340.6 examples/sec; 0.023 sec/batch; 0h:23m:39s remains)
INFO - root - 2022-02-24 20:49:36.269402: step 139060, total loss = 0.72, batch loss = 0.46 (364.0 examples/sec; 0.022 sec/batch; 0h:22m:08s remains)
INFO - root - 2022-02-24 20:49:36.925868: step 139070, total loss = 0.51, batch loss = 0.25 (75.6 examples/sec; 0.106 sec/batch; 1h:46m:37s remains)
INFO - root - 2022-02-24 20:49:37.513333: step 139080, total loss = 0.55, batch loss = 0.29 (190.5 examples/sec; 0.042 sec/batch; 0h:42m:16s remains)
INFO - root - 2022-02-24 20:49:38.057312: step 139090, total loss = 0.52, batch loss = 0.26 (189.2 examples/sec; 0.042 sec/batch; 0h:42m:34s remains)
INFO - root - 2022-02-24 20:49:38.562287: step 139100, total loss = 0.75, batch loss = 0.49 (95.4 examples/sec; 0.084 sec/batch; 1h:24m:27s remains)
INFO - root - 2022-02-24 20:49:39.083873: step 139110, total loss = 0.54, batch loss = 0.28 (261.0 examples/sec; 0.031 sec/batch; 0h:30m:51s remains)
INFO - root - 2022-02-24 20:49:39.579436: step 139120, total loss = 0.61, batch loss = 0.35 (50.5 examples/sec; 0.158 sec/batch; 2h:39m:22s remains)
INFO - root - 2022-02-24 20:49:40.334622: step 139130, total loss = 0.73, batch loss = 0.47 (43.5 examples/sec; 0.184 sec/batch; 3h:05m:00s remains)
INFO - root - 2022-02-24 20:49:40.994483: step 139140, total loss = 0.57, batch loss = 0.31 (75.1 examples/sec; 0.106 sec/batch; 1h:47m:05s remains)
INFO - root - 2022-02-24 20:49:41.551756: step 139150, total loss = 0.50, batch loss = 0.24 (334.3 examples/sec; 0.024 sec/batch; 0h:24m:04s remains)
INFO - root - 2022-02-24 20:49:41.846998: step 139160, total loss = 0.47, batch loss = 0.21 (248.8 examples/sec; 0.032 sec/batch; 0h:32m:20s remains)
INFO - root - 2022-02-24 20:49:42.474459: step 139170, total loss = 0.58, batch loss = 0.32 (277.2 examples/sec; 0.029 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 20:49:43.140568: step 139180, total loss = 0.67, batch loss = 0.41 (178.7 examples/sec; 0.045 sec/batch; 0h:45m:00s remains)
INFO - root - 2022-02-24 20:49:43.677767: step 139190, total loss = 0.55, batch loss = 0.29 (88.0 examples/sec; 0.091 sec/batch; 1h:31m:20s remains)
INFO - root - 2022-02-24 20:49:44.194463: step 139200, total loss = 0.54, batch loss = 0.28 (263.4 examples/sec; 0.030 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 20:49:44.979078: step 139210, total loss = 0.73, batch loss = 0.47 (348.7 examples/sec; 0.023 sec/batch; 0h:23m:03s remains)
INFO - root - 2022-02-24 20:49:45.475348: step 139220, total loss = 0.53, batch loss = 0.27 (208.4 examples/sec; 0.038 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 20:49:46.239731: step 139230, total loss = 0.56, batch loss = 0.30 (85.5 examples/sec; 0.094 sec/batch; 1h:33m:59s remains)
INFO - root - 2022-02-24 20:49:46.678161: step 139240, total loss = 0.59, batch loss = 0.33 (277.2 examples/sec; 0.029 sec/batch; 0h:28m:58s remains)
INFO - root - 2022-02-24 20:49:47.162280: step 139250, total loss = 0.53, batch loss = 0.27 (288.4 examples/sec; 0.028 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 20:49:47.835474: step 139260, total loss = 0.50, batch loss = 0.24 (317.0 examples/sec; 0.025 sec/batch; 0h:25m:20s remains)
INFO - root - 2022-02-24 20:49:48.230028: step 139270, total loss = 0.52, batch loss = 0.27 (322.5 examples/sec; 0.025 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 20:49:48.619049: step 139280, total loss = 0.47, batch loss = 0.21 (170.9 examples/sec; 0.047 sec/batch; 0h:46m:58s remains)
INFO - root - 2022-02-24 20:49:48.994517: step 139290, total loss = 0.60, batch loss = 0.34 (162.8 examples/sec; 0.049 sec/batch; 0h:49m:17s remains)
INFO - root - 2022-02-24 20:49:49.303384: step 139300, total loss = 0.68, batch loss = 0.42 (304.7 examples/sec; 0.026 sec/batch; 0h:26m:20s remains)
INFO - root - 2022-02-24 20:49:49.835805: step 139310, total loss = 0.50, batch loss = 0.24 (122.5 examples/sec; 0.065 sec/batch; 1h:05m:31s remains)
INFO - root - 2022-02-24 20:49:50.357156: step 139320, total loss = 0.53, batch loss = 0.27 (97.0 examples/sec; 0.083 sec/batch; 1h:22m:45s remains)
INFO - root - 2022-02-24 20:49:50.772472: step 139330, total loss = 0.55, batch loss = 0.29 (340.3 examples/sec; 0.024 sec/batch; 0h:23m:34s remains)
INFO - root - 2022-02-24 20:49:51.055043: step 139340, total loss = 0.51, batch loss = 0.25 (343.2 examples/sec; 0.023 sec/batch; 0h:23m:22s remains)
INFO - root - 2022-02-24 20:49:51.372607: step 139350, total loss = 0.58, batch loss = 0.32 (310.2 examples/sec; 0.026 sec/batch; 0h:25m:51s remains)
INFO - root - 2022-02-24 20:49:51.686931: step 139360, total loss = 0.46, batch loss = 0.20 (192.3 examples/sec; 0.042 sec/batch; 0h:41m:42s remains)
INFO - root - 2022-02-24 20:49:52.072372: step 139370, total loss = 0.58, batch loss = 0.32 (372.2 examples/sec; 0.021 sec/batch; 0h:21m:32s remains)
INFO - root - 2022-02-24 20:49:52.499883: step 139380, total loss = 0.49, batch loss = 0.23 (192.6 examples/sec; 0.042 sec/batch; 0h:41m:37s remains)
INFO - root - 2022-02-24 20:49:52.902002: step 139390, total loss = 0.51, batch loss = 0.25 (124.8 examples/sec; 0.064 sec/batch; 1h:04m:13s remains)
INFO - root - 2022-02-24 20:49:53.218638: step 139400, total loss = 0.53, batch loss = 0.27 (341.0 examples/sec; 0.023 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:49:53.676328: step 139410, total loss = 0.58, batch loss = 0.32 (281.8 examples/sec; 0.028 sec/batch; 0h:28m:25s remains)
INFO - root - 2022-02-24 20:49:54.115120: step 139420, total loss = 0.62, batch loss = 0.36 (344.6 examples/sec; 0.023 sec/batch; 0h:23m:14s remains)
INFO - root - 2022-02-24 20:49:54.676668: step 139430, total loss = 0.49, batch loss = 0.23 (120.4 examples/sec; 0.066 sec/batch; 1h:06m:32s remains)
INFO - root - 2022-02-24 20:49:55.028184: step 139440, total loss = 0.56, batch loss = 0.30 (318.7 examples/sec; 0.025 sec/batch; 0h:25m:07s remains)
INFO - root - 2022-02-24 20:49:55.313425: step 139450, total loss = 0.56, batch loss = 0.30 (287.9 examples/sec; 0.028 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 20:49:55.623750: step 139460, total loss = 0.56, batch loss = 0.30 (186.3 examples/sec; 0.043 sec/batch; 0h:42m:57s remains)
INFO - root - 2022-02-24 20:49:56.007580: step 139470, total loss = 0.61, batch loss = 0.35 (260.4 examples/sec; 0.031 sec/batch; 0h:30m:44s remains)
INFO - root - 2022-02-24 20:49:56.402792: step 139480, total loss = 0.52, batch loss = 0.26 (250.8 examples/sec; 0.032 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 20:49:56.827030: step 139490, total loss = 0.63, batch loss = 0.37 (328.6 examples/sec; 0.024 sec/batch; 0h:24m:20s remains)
INFO - root - 2022-02-24 20:49:57.159442: step 139500, total loss = 0.54, batch loss = 0.28 (340.5 examples/sec; 0.023 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:49:57.541390: step 139510, total loss = 0.50, batch loss = 0.24 (251.5 examples/sec; 0.032 sec/batch; 0h:31m:47s remains)
INFO - root - 2022-02-24 20:49:57.876120: step 139520, total loss = 0.49, batch loss = 0.24 (292.2 examples/sec; 0.027 sec/batch; 0h:27m:22s remains)
INFO - root - 2022-02-24 20:49:58.347050: step 139530, total loss = 0.54, batch loss = 0.28 (175.0 examples/sec; 0.046 sec/batch; 0h:45m:42s remains)
INFO - root - 2022-02-24 20:49:58.806702: step 139540, total loss = 0.54, batch loss = 0.28 (156.4 examples/sec; 0.051 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:49:59.227090: step 139550, total loss = 0.59, batch loss = 0.34 (197.3 examples/sec; 0.041 sec/batch; 0h:40m:31s remains)
INFO - root - 2022-02-24 20:49:59.577815: step 139560, total loss = 0.61, batch loss = 0.35 (251.7 examples/sec; 0.032 sec/batch; 0h:31m:44s remains)
INFO - root - 2022-02-24 20:49:59.996900: step 139570, total loss = 0.49, batch loss = 0.23 (158.1 examples/sec; 0.051 sec/batch; 0h:50m:32s remains)
INFO - root - 2022-02-24 20:50:00.400370: step 139580, total loss = 0.48, batch loss = 0.22 (190.4 examples/sec; 0.042 sec/batch; 0h:41m:57s remains)
INFO - root - 2022-02-24 20:50:00.889186: step 139590, total loss = 0.54, batch loss = 0.28 (222.2 examples/sec; 0.036 sec/batch; 0h:35m:57s remains)
INFO - root - 2022-02-24 20:50:01.286160: step 139600, total loss = 0.60, batch loss = 0.34 (231.4 examples/sec; 0.035 sec/batch; 0h:34m:30s remains)
INFO - root - 2022-02-24 20:50:01.711827: step 139610, total loss = 0.53, batch loss = 0.27 (309.7 examples/sec; 0.026 sec/batch; 0h:25m:46s remains)
INFO - root - 2022-02-24 20:50:02.049566: step 139620, total loss = 0.57, batch loss = 0.32 (335.1 examples/sec; 0.024 sec/batch; 0h:23m:49s remains)
INFO - root - 2022-02-24 20:50:02.481679: step 139630, total loss = 0.52, batch loss = 0.26 (222.9 examples/sec; 0.036 sec/batch; 0h:35m:48s remains)
INFO - root - 2022-02-24 20:50:02.859210: step 139640, total loss = 0.48, batch loss = 0.23 (337.6 examples/sec; 0.024 sec/batch; 0h:23m:38s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-139649 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-139649 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:50:03.748429: step 139650, total loss = 0.52, batch loss = 0.26 (318.9 examples/sec; 0.025 sec/batch; 0h:25m:01s remains)
INFO - root - 2022-02-24 20:50:03.992847: step 139660, total loss = 0.60, batch loss = 0.34 (341.2 examples/sec; 0.023 sec/batch; 0h:23m:23s remains)
INFO - root - 2022-02-24 20:50:04.220990: step 139670, total loss = 0.56, batch loss = 0.30 (332.9 examples/sec; 0.024 sec/batch; 0h:23m:57s remains)
INFO - root - 2022-02-24 20:50:04.641784: step 139680, total loss = 0.51, batch loss = 0.25 (139.5 examples/sec; 0.057 sec/batch; 0h:57m:10s remains)
INFO - root - 2022-02-24 20:50:05.038181: step 139690, total loss = 0.65, batch loss = 0.39 (225.0 examples/sec; 0.036 sec/batch; 0h:35m:26s remains)
INFO - root - 2022-02-24 20:50:05.363075: step 139700, total loss = 0.52, batch loss = 0.26 (268.0 examples/sec; 0.030 sec/batch; 0h:29m:45s remains)
INFO - root - 2022-02-24 20:50:05.959698: step 139710, total loss = 0.52, batch loss = 0.27 (252.1 examples/sec; 0.032 sec/batch; 0h:31m:37s remains)
INFO - root - 2022-02-24 20:50:06.505406: step 139720, total loss = 0.78, batch loss = 0.52 (210.9 examples/sec; 0.038 sec/batch; 0h:37m:47s remains)
INFO - root - 2022-02-24 20:50:06.993990: step 139730, total loss = 0.58, batch loss = 0.32 (198.9 examples/sec; 0.040 sec/batch; 0h:40m:03s remains)
INFO - root - 2022-02-24 20:50:07.363490: step 139740, total loss = 0.46, batch loss = 0.20 (272.4 examples/sec; 0.029 sec/batch; 0h:29m:14s remains)
INFO - root - 2022-02-24 20:50:07.694297: step 139750, total loss = 0.50, batch loss = 0.24 (194.0 examples/sec; 0.041 sec/batch; 0h:41m:04s remains)
INFO - root - 2022-02-24 20:50:08.149564: step 139760, total loss = 0.47, batch loss = 0.21 (212.8 examples/sec; 0.038 sec/batch; 0h:37m:26s remains)
INFO - root - 2022-02-24 20:50:08.534467: step 139770, total loss = 0.54, batch loss = 0.28 (208.3 examples/sec; 0.038 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:50:09.052389: step 139780, total loss = 0.57, batch loss = 0.31 (218.2 examples/sec; 0.037 sec/batch; 0h:36m:29s remains)
INFO - root - 2022-02-24 20:50:09.472153: step 139790, total loss = 0.65, batch loss = 0.39 (299.0 examples/sec; 0.027 sec/batch; 0h:26m:37s remains)
INFO - root - 2022-02-24 20:50:09.908086: step 139800, total loss = 0.48, batch loss = 0.22 (158.0 examples/sec; 0.051 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 20:50:10.418640: step 139810, total loss = 0.55, batch loss = 0.29 (88.5 examples/sec; 0.090 sec/batch; 1h:29m:54s remains)
INFO - root - 2022-02-24 20:50:10.922933: step 139820, total loss = 0.59, batch loss = 0.33 (128.3 examples/sec; 0.062 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:50:11.787746: step 139830, total loss = 0.50, batch loss = 0.24 (238.4 examples/sec; 0.034 sec/batch; 0h:33m:22s remains)
INFO - root - 2022-02-24 20:50:12.201668: step 139840, total loss = 0.50, batch loss = 0.24 (235.4 examples/sec; 0.034 sec/batch; 0h:33m:47s remains)
INFO - root - 2022-02-24 20:50:12.581670: step 139850, total loss = 0.57, batch loss = 0.32 (215.1 examples/sec; 0.037 sec/batch; 0h:36m:58s remains)
INFO - root - 2022-02-24 20:50:13.000193: step 139860, total loss = 0.54, batch loss = 0.28 (266.6 examples/sec; 0.030 sec/batch; 0h:29m:49s remains)
INFO - root - 2022-02-24 20:50:13.528336: step 139870, total loss = 0.62, batch loss = 0.36 (128.1 examples/sec; 0.062 sec/batch; 1h:02m:03s remains)
INFO - root - 2022-02-24 20:50:13.927414: step 139880, total loss = 0.56, batch loss = 0.30 (246.7 examples/sec; 0.032 sec/batch; 0h:32m:13s remains)
INFO - root - 2022-02-24 20:50:14.361483: step 139890, total loss = 0.50, batch loss = 0.25 (197.7 examples/sec; 0.040 sec/batch; 0h:40m:12s remains)
INFO - root - 2022-02-24 20:50:14.666158: step 139900, total loss = 0.59, batch loss = 0.33 (234.2 examples/sec; 0.034 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 20:50:15.161613: step 139910, total loss = 0.57, batch loss = 0.31 (149.6 examples/sec; 0.053 sec/batch; 0h:53m:07s remains)
INFO - root - 2022-02-24 20:50:15.536285: step 139920, total loss = 0.58, batch loss = 0.32 (113.3 examples/sec; 0.071 sec/batch; 1h:10m:07s remains)
INFO - root - 2022-02-24 20:50:15.979073: step 139930, total loss = 0.79, batch loss = 0.54 (341.1 examples/sec; 0.023 sec/batch; 0h:23m:17s remains)
INFO - root - 2022-02-24 20:50:16.806915: step 139940, total loss = 0.50, batch loss = 0.25 (185.3 examples/sec; 0.043 sec/batch; 0h:42m:51s remains)
INFO - root - 2022-02-24 20:50:17.207632: step 139950, total loss = 0.45, batch loss = 0.20 (132.9 examples/sec; 0.060 sec/batch; 0h:59m:45s remains)
INFO - root - 2022-02-24 20:50:17.504132: step 139960, total loss = 0.50, batch loss = 0.24 (333.5 examples/sec; 0.024 sec/batch; 0h:23m:48s remains)
INFO - root - 2022-02-24 20:50:17.849124: step 139970, total loss = 0.52, batch loss = 0.26 (173.5 examples/sec; 0.046 sec/batch; 0h:45m:44s remains)
INFO - root - 2022-02-24 20:50:18.235041: step 139980, total loss = 0.50, batch loss = 0.24 (288.3 examples/sec; 0.028 sec/batch; 0h:27m:31s remains)
INFO - root - 2022-02-24 20:50:18.769537: step 139990, total loss = 0.57, batch loss = 0.31 (200.4 examples/sec; 0.040 sec/batch; 0h:39m:35s remains)
INFO - root - 2022-02-24 20:50:19.135887: step 140000, total loss = 0.55, batch loss = 0.29 (222.7 examples/sec; 0.036 sec/batch; 0h:35m:37s remains)
INFO - root - 2022-02-24 20:50:19.504346: step 140010, total loss = 0.50, batch loss = 0.24 (315.3 examples/sec; 0.025 sec/batch; 0h:25m:09s remains)
INFO - root - 2022-02-24 20:50:19.827188: step 140020, total loss = 0.47, batch loss = 0.21 (169.6 examples/sec; 0.047 sec/batch; 0h:46m:45s remains)
INFO - root - 2022-02-24 20:50:20.203443: step 140030, total loss = 0.58, batch loss = 0.32 (153.3 examples/sec; 0.052 sec/batch; 0h:51m:42s remains)
INFO - root - 2022-02-24 20:50:20.660752: step 140040, total loss = 0.56, batch loss = 0.30 (116.3 examples/sec; 0.069 sec/batch; 1h:08m:10s remains)
INFO - root - 2022-02-24 20:50:21.119592: step 140050, total loss = 0.57, batch loss = 0.31 (350.1 examples/sec; 0.023 sec/batch; 0h:22m:38s remains)
INFO - root - 2022-02-24 20:50:21.415938: step 140060, total loss = 0.48, batch loss = 0.22 (363.4 examples/sec; 0.022 sec/batch; 0h:21m:48s remains)
INFO - root - 2022-02-24 20:50:21.742215: step 140070, total loss = 0.56, batch loss = 0.31 (261.9 examples/sec; 0.031 sec/batch; 0h:30m:15s remains)
INFO - root - 2022-02-24 20:50:22.046341: step 140080, total loss = 0.52, batch loss = 0.27 (342.0 examples/sec; 0.023 sec/batch; 0h:23m:09s remains)
INFO - root - 2022-02-24 20:50:22.413591: step 140090, total loss = 0.64, batch loss = 0.38 (194.5 examples/sec; 0.041 sec/batch; 0h:40m:44s remains)
INFO - root - 2022-02-24 20:50:22.803174: step 140100, total loss = 0.48, batch loss = 0.22 (317.5 examples/sec; 0.025 sec/batch; 0h:24m:56s remains)
INFO - root - 2022-02-24 20:50:23.304064: step 140110, total loss = 0.62, batch loss = 0.36 (199.8 examples/sec; 0.040 sec/batch; 0h:39m:38s remains)
INFO - root - 2022-02-24 20:50:23.705211: step 140120, total loss = 0.64, batch loss = 0.38 (161.3 examples/sec; 0.050 sec/batch; 0h:49m:05s remains)
INFO - root - 2022-02-24 20:50:24.011707: step 140130, total loss = 0.61, batch loss = 0.35 (318.4 examples/sec; 0.025 sec/batch; 0h:24m:51s remains)
INFO - root - 2022-02-24 20:50:24.373476: step 140140, total loss = 0.54, batch loss = 0.28 (212.2 examples/sec; 0.038 sec/batch; 0h:37m:18s remains)
INFO - root - 2022-02-24 20:50:24.898597: step 140150, total loss = 0.54, batch loss = 0.28 (106.0 examples/sec; 0.075 sec/batch; 1h:14m:39s remains)
INFO - root - 2022-02-24 20:50:25.306209: step 140160, total loss = 0.52, batch loss = 0.26 (332.5 examples/sec; 0.024 sec/batch; 0h:23m:47s remains)
INFO - root - 2022-02-24 20:50:25.679238: step 140170, total loss = 0.47, batch loss = 0.21 (157.4 examples/sec; 0.051 sec/batch; 0h:50m:14s remains)
INFO - root - 2022-02-24 20:50:25.978014: step 140180, total loss = 0.54, batch loss = 0.28 (379.2 examples/sec; 0.021 sec/batch; 0h:20m:51s remains)
INFO - root - 2022-02-24 20:50:26.280625: step 140190, total loss = 0.58, batch loss = 0.33 (346.6 examples/sec; 0.023 sec/batch; 0h:22m:49s remains)
INFO - root - 2022-02-24 20:50:26.739989: step 140200, total loss = 0.68, batch loss = 0.42 (87.2 examples/sec; 0.092 sec/batch; 1h:30m:41s remains)
INFO - root - 2022-02-24 20:50:27.148499: step 140210, total loss = 0.52, batch loss = 0.26 (186.7 examples/sec; 0.043 sec/batch; 0h:42m:20s remains)
INFO - root - 2022-02-24 20:50:27.643187: step 140220, total loss = 0.52, batch loss = 0.26 (346.9 examples/sec; 0.023 sec/batch; 0h:22m:47s remains)
INFO - root - 2022-02-24 20:50:27.934684: step 140230, total loss = 0.51, batch loss = 0.25 (235.8 examples/sec; 0.034 sec/batch; 0h:33m:30s remains)
INFO - root - 2022-02-24 20:50:28.336179: step 140240, total loss = 0.48, batch loss = 0.22 (290.3 examples/sec; 0.028 sec/batch; 0h:27m:13s remains)
INFO - root - 2022-02-24 20:50:28.629042: step 140250, total loss = 0.49, batch loss = 0.23 (265.2 examples/sec; 0.030 sec/batch; 0h:29m:47s remains)
INFO - root - 2022-02-24 20:50:29.070875: step 140260, total loss = 0.51, batch loss = 0.25 (170.8 examples/sec; 0.047 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 20:50:29.590652: step 140270, total loss = 0.55, batch loss = 0.29 (101.9 examples/sec; 0.078 sec/batch; 1h:17m:28s remains)
INFO - root - 2022-02-24 20:50:29.980218: step 140280, total loss = 0.48, batch loss = 0.22 (176.6 examples/sec; 0.045 sec/batch; 0h:44m:42s remains)
INFO - root - 2022-02-24 20:50:30.393314: step 140290, total loss = 0.51, batch loss = 0.25 (84.2 examples/sec; 0.095 sec/batch; 1h:33m:44s remains)
INFO - root - 2022-02-24 20:50:30.918552: step 140300, total loss = 0.49, batch loss = 0.24 (267.8 examples/sec; 0.030 sec/batch; 0h:29m:28s remains)
INFO - root - 2022-02-24 20:50:31.494301: step 140310, total loss = 0.52, batch loss = 0.26 (219.0 examples/sec; 0.037 sec/batch; 0h:36m:02s remains)
INFO - root - 2022-02-24 20:50:32.554243: step 140320, total loss = 0.53, batch loss = 0.27 (207.2 examples/sec; 0.039 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:50:32.878748: step 140330, total loss = 0.58, batch loss = 0.32 (347.5 examples/sec; 0.023 sec/batch; 0h:22m:42s remains)
INFO - root - 2022-02-24 20:50:33.251367: step 140340, total loss = 0.58, batch loss = 0.32 (137.5 examples/sec; 0.058 sec/batch; 0h:57m:21s remains)
INFO - root - 2022-02-24 20:50:33.620477: step 140350, total loss = 0.51, batch loss = 0.25 (252.4 examples/sec; 0.032 sec/batch; 0h:31m:15s remains)
INFO - root - 2022-02-24 20:50:34.067274: step 140360, total loss = 0.55, batch loss = 0.29 (260.8 examples/sec; 0.031 sec/batch; 0h:30m:14s remains)
INFO - root - 2022-02-24 20:50:34.421303: step 140370, total loss = 0.50, batch loss = 0.24 (166.0 examples/sec; 0.048 sec/batch; 0h:47m:30s remains)
INFO - root - 2022-02-24 20:50:34.742079: step 140380, total loss = 0.51, batch loss = 0.25 (241.8 examples/sec; 0.033 sec/batch; 0h:32m:36s remains)
INFO - root - 2022-02-24 20:50:35.106820: step 140390, total loss = 0.55, batch loss = 0.29 (217.9 examples/sec; 0.037 sec/batch; 0h:36m:09s remains)
INFO - root - 2022-02-24 20:50:35.448005: step 140400, total loss = 0.54, batch loss = 0.28 (167.2 examples/sec; 0.048 sec/batch; 0h:47m:07s remains)
INFO - root - 2022-02-24 20:50:35.854803: step 140410, total loss = 0.54, batch loss = 0.28 (186.6 examples/sec; 0.043 sec/batch; 0h:42m:13s remains)
INFO - root - 2022-02-24 20:50:36.289040: step 140420, total loss = 0.69, batch loss = 0.43 (84.3 examples/sec; 0.095 sec/batch; 1h:33m:28s remains)
INFO - root - 2022-02-24 20:50:36.793638: step 140430, total loss = 0.55, batch loss = 0.29 (191.8 examples/sec; 0.042 sec/batch; 0h:41m:03s remains)
INFO - root - 2022-02-24 20:50:37.290062: step 140440, total loss = 0.48, batch loss = 0.22 (316.8 examples/sec; 0.025 sec/batch; 0h:24m:51s remains)
INFO - root - 2022-02-24 20:50:37.671135: step 140450, total loss = 0.60, batch loss = 0.34 (138.9 examples/sec; 0.058 sec/batch; 0h:56m:39s remains)
INFO - root - 2022-02-24 20:50:38.000501: step 140460, total loss = 0.49, batch loss = 0.24 (319.2 examples/sec; 0.025 sec/batch; 0h:24m:39s remains)
INFO - root - 2022-02-24 20:50:38.321989: step 140470, total loss = 0.50, batch loss = 0.24 (203.8 examples/sec; 0.039 sec/batch; 0h:38m:37s remains)
INFO - root - 2022-02-24 20:50:38.733724: step 140480, total loss = 0.57, batch loss = 0.31 (214.2 examples/sec; 0.037 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 20:50:39.051029: step 140490, total loss = 0.52, batch loss = 0.26 (371.1 examples/sec; 0.022 sec/batch; 0h:21m:12s remains)
INFO - root - 2022-02-24 20:50:39.416275: step 140500, total loss = 0.49, batch loss = 0.23 (201.9 examples/sec; 0.040 sec/batch; 0h:38m:57s remains)
INFO - root - 2022-02-24 20:50:39.830585: step 140510, total loss = 0.50, batch loss = 0.24 (153.6 examples/sec; 0.052 sec/batch; 0h:51m:12s remains)
INFO - root - 2022-02-24 20:50:40.161454: step 140520, total loss = 0.43, batch loss = 0.17 (184.6 examples/sec; 0.043 sec/batch; 0h:42m:35s remains)
INFO - root - 2022-02-24 20:50:40.602280: step 140530, total loss = 0.50, batch loss = 0.24 (179.8 examples/sec; 0.044 sec/batch; 0h:43m:43s remains)
INFO - root - 2022-02-24 20:50:41.005322: step 140540, total loss = 0.51, batch loss = 0.25 (187.8 examples/sec; 0.043 sec/batch; 0h:41m:51s remains)
INFO - root - 2022-02-24 20:50:41.358591: step 140550, total loss = 0.57, batch loss = 0.31 (249.1 examples/sec; 0.032 sec/batch; 0h:31m:33s remains)
INFO - root - 2022-02-24 20:50:41.702848: step 140560, total loss = 0.55, batch loss = 0.29 (320.7 examples/sec; 0.025 sec/batch; 0h:24m:30s remains)
INFO - root - 2022-02-24 20:50:42.043352: step 140570, total loss = 0.47, batch loss = 0.21 (322.2 examples/sec; 0.025 sec/batch; 0h:24m:23s remains)
INFO - root - 2022-02-24 20:50:42.541824: step 140580, total loss = 0.53, batch loss = 0.27 (197.4 examples/sec; 0.041 sec/batch; 0h:39m:48s remains)
INFO - root - 2022-02-24 20:50:43.029454: step 140590, total loss = 0.67, batch loss = 0.41 (151.3 examples/sec; 0.053 sec/batch; 0h:51m:54s remains)
INFO - root - 2022-02-24 20:50:43.364024: step 140600, total loss = 0.54, batch loss = 0.28 (312.2 examples/sec; 0.026 sec/batch; 0h:25m:09s remains)
INFO - root - 2022-02-24 20:50:43.762954: step 140610, total loss = 0.59, batch loss = 0.33 (169.8 examples/sec; 0.047 sec/batch; 0h:46m:13s remains)
INFO - root - 2022-02-24 20:50:44.066245: step 140620, total loss = 0.70, batch loss = 0.44 (353.8 examples/sec; 0.023 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 20:50:44.467087: step 140630, total loss = 0.54, batch loss = 0.28 (129.9 examples/sec; 0.062 sec/batch; 1h:00m:25s remains)
INFO - root - 2022-02-24 20:50:44.871307: step 140640, total loss = 0.58, batch loss = 0.32 (230.1 examples/sec; 0.035 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:50:45.201479: step 140650, total loss = 0.54, batch loss = 0.28 (280.5 examples/sec; 0.029 sec/batch; 0h:27m:58s remains)
INFO - root - 2022-02-24 20:50:45.542775: step 140660, total loss = 0.65, batch loss = 0.39 (350.3 examples/sec; 0.023 sec/batch; 0h:22m:23s remains)
INFO - root - 2022-02-24 20:50:45.853957: step 140670, total loss = 0.55, batch loss = 0.29 (278.3 examples/sec; 0.029 sec/batch; 0h:28m:10s remains)
INFO - root - 2022-02-24 20:50:46.262084: step 140680, total loss = 0.56, batch loss = 0.31 (325.8 examples/sec; 0.025 sec/batch; 0h:24m:04s remains)
INFO - root - 2022-02-24 20:50:46.636882: step 140690, total loss = 0.57, batch loss = 0.31 (353.9 examples/sec; 0.023 sec/batch; 0h:22m:09s remains)
INFO - root - 2022-02-24 20:50:47.147128: step 140700, total loss = 0.45, batch loss = 0.19 (110.6 examples/sec; 0.072 sec/batch; 1h:10m:51s remains)
INFO - root - 2022-02-24 20:50:47.620881: step 140710, total loss = 0.65, batch loss = 0.39 (312.9 examples/sec; 0.026 sec/batch; 0h:25m:03s remains)
INFO - root - 2022-02-24 20:50:47.939439: step 140720, total loss = 0.58, batch loss = 0.32 (346.3 examples/sec; 0.023 sec/batch; 0h:22m:37s remains)
INFO - root - 2022-02-24 20:50:48.291904: step 140730, total loss = 0.48, batch loss = 0.22 (193.2 examples/sec; 0.041 sec/batch; 0h:40m:33s remains)
INFO - root - 2022-02-24 20:50:48.660389: step 140740, total loss = 0.54, batch loss = 0.28 (225.2 examples/sec; 0.036 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:50:49.069972: step 140750, total loss = 0.52, batch loss = 0.27 (303.2 examples/sec; 0.026 sec/batch; 0h:25m:49s remains)
INFO - root - 2022-02-24 20:50:49.479336: step 140760, total loss = 0.49, batch loss = 0.23 (265.4 examples/sec; 0.030 sec/batch; 0h:29m:30s remains)
INFO - root - 2022-02-24 20:50:49.814262: step 140770, total loss = 0.65, batch loss = 0.40 (184.8 examples/sec; 0.043 sec/batch; 0h:42m:22s remains)
INFO - root - 2022-02-24 20:50:50.174708: step 140780, total loss = 0.59, batch loss = 0.33 (267.7 examples/sec; 0.030 sec/batch; 0h:29m:14s remains)
INFO - root - 2022-02-24 20:50:50.669683: step 140790, total loss = 0.67, batch loss = 0.41 (126.0 examples/sec; 0.063 sec/batch; 1h:02m:06s remains)
INFO - root - 2022-02-24 20:50:51.063773: step 140800, total loss = 0.53, batch loss = 0.27 (253.6 examples/sec; 0.032 sec/batch; 0h:30m:51s remains)
INFO - root - 2022-02-24 20:50:51.446244: step 140810, total loss = 0.51, batch loss = 0.26 (191.4 examples/sec; 0.042 sec/batch; 0h:40m:52s remains)
INFO - root - 2022-02-24 20:50:51.754263: step 140820, total loss = 0.54, batch loss = 0.28 (288.9 examples/sec; 0.028 sec/batch; 0h:27m:05s remains)
INFO - root - 2022-02-24 20:50:52.067592: step 140830, total loss = 0.47, batch loss = 0.21 (177.3 examples/sec; 0.045 sec/batch; 0h:44m:06s remains)
INFO - root - 2022-02-24 20:50:52.539723: step 140840, total loss = 0.52, batch loss = 0.26 (132.3 examples/sec; 0.060 sec/batch; 0h:59m:06s remains)
INFO - root - 2022-02-24 20:50:52.922114: step 140850, total loss = 0.59, batch loss = 0.33 (143.2 examples/sec; 0.056 sec/batch; 0h:54m:37s remains)
INFO - root - 2022-02-24 20:50:53.278206: step 140860, total loss = 0.56, batch loss = 0.30 (289.1 examples/sec; 0.028 sec/batch; 0h:27m:02s remains)
INFO - root - 2022-02-24 20:50:53.618365: step 140870, total loss = 0.59, batch loss = 0.33 (334.0 examples/sec; 0.024 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:50:54.042500: step 140880, total loss = 0.58, batch loss = 0.33 (348.0 examples/sec; 0.023 sec/batch; 0h:22m:27s remains)
INFO - root - 2022-02-24 20:50:54.397988: step 140890, total loss = 0.53, batch loss = 0.27 (185.3 examples/sec; 0.043 sec/batch; 0h:42m:11s remains)
INFO - root - 2022-02-24 20:50:54.784964: step 140900, total loss = 0.55, batch loss = 0.29 (144.9 examples/sec; 0.055 sec/batch; 0h:53m:56s remains)
INFO - root - 2022-02-24 20:50:55.249477: step 140910, total loss = 0.54, batch loss = 0.28 (291.6 examples/sec; 0.027 sec/batch; 0h:26m:47s remains)
INFO - root - 2022-02-24 20:50:55.659990: step 140920, total loss = 0.53, batch loss = 0.27 (305.5 examples/sec; 0.026 sec/batch; 0h:25m:33s remains)
INFO - root - 2022-02-24 20:50:55.984416: step 140930, total loss = 0.61, batch loss = 0.35 (207.9 examples/sec; 0.038 sec/batch; 0h:37m:33s remains)
INFO - root - 2022-02-24 20:50:56.325526: step 140940, total loss = 0.48, batch loss = 0.22 (187.2 examples/sec; 0.043 sec/batch; 0h:41m:42s remains)
INFO - root - 2022-02-24 20:50:56.670702: step 140950, total loss = 0.56, batch loss = 0.30 (334.9 examples/sec; 0.024 sec/batch; 0h:23m:18s remains)
INFO - root - 2022-02-24 20:50:57.082770: step 140960, total loss = 0.48, batch loss = 0.23 (220.3 examples/sec; 0.036 sec/batch; 0h:35m:25s remains)
INFO - root - 2022-02-24 20:50:57.562010: step 140970, total loss = 0.60, batch loss = 0.34 (232.1 examples/sec; 0.034 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 20:50:58.354031: step 140980, total loss = 0.54, batch loss = 0.28 (214.5 examples/sec; 0.037 sec/batch; 0h:36m:22s remains)
INFO - root - 2022-02-24 20:50:58.743538: step 140990, total loss = 0.54, batch loss = 0.28 (148.2 examples/sec; 0.054 sec/batch; 0h:52m:39s remains)
INFO - root - 2022-02-24 20:50:59.268575: step 141000, total loss = 0.57, batch loss = 0.31 (154.7 examples/sec; 0.052 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:50:59.692911: step 141010, total loss = 0.54, batch loss = 0.28 (327.1 examples/sec; 0.024 sec/batch; 0h:23m:50s remains)
INFO - root - 2022-02-24 20:51:00.236349: step 141020, total loss = 0.49, batch loss = 0.23 (209.8 examples/sec; 0.038 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:51:00.735563: step 141030, total loss = 0.50, batch loss = 0.24 (180.3 examples/sec; 0.044 sec/batch; 0h:43m:13s remains)
INFO - root - 2022-02-24 20:51:01.207428: step 141040, total loss = 0.48, batch loss = 0.22 (176.9 examples/sec; 0.045 sec/batch; 0h:44m:04s remains)
INFO - root - 2022-02-24 20:51:01.626752: step 141050, total loss = 0.62, batch loss = 0.36 (323.0 examples/sec; 0.025 sec/batch; 0h:24m:07s remains)
INFO - root - 2022-02-24 20:51:01.986583: step 141060, total loss = 0.57, batch loss = 0.31 (325.9 examples/sec; 0.025 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 20:51:02.394249: step 141070, total loss = 0.44, batch loss = 0.18 (255.2 examples/sec; 0.031 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 20:51:03.233290: step 141080, total loss = 0.45, batch loss = 0.19 (129.1 examples/sec; 0.062 sec/batch; 1h:00m:20s remains)
INFO - root - 2022-02-24 20:51:03.728009: step 141090, total loss = 0.55, batch loss = 0.29 (155.7 examples/sec; 0.051 sec/batch; 0h:50m:01s remains)
INFO - root - 2022-02-24 20:51:04.146508: step 141100, total loss = 0.55, batch loss = 0.29 (243.2 examples/sec; 0.033 sec/batch; 0h:32m:01s remains)
INFO - root - 2022-02-24 20:51:04.598517: step 141110, total loss = 0.48, batch loss = 0.22 (221.6 examples/sec; 0.036 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 20:51:04.930675: step 141120, total loss = 0.53, batch loss = 0.27 (282.4 examples/sec; 0.028 sec/batch; 0h:27m:33s remains)
INFO - root - 2022-02-24 20:51:05.264834: step 141130, total loss = 0.52, batch loss = 0.26 (201.7 examples/sec; 0.040 sec/batch; 0h:38m:35s remains)
INFO - root - 2022-02-24 20:51:05.696258: step 141140, total loss = 0.55, batch loss = 0.29 (148.6 examples/sec; 0.054 sec/batch; 0h:52m:20s remains)
INFO - root - 2022-02-24 20:51:06.148191: step 141150, total loss = 0.54, batch loss = 0.28 (139.4 examples/sec; 0.057 sec/batch; 0h:55m:48s remains)
INFO - root - 2022-02-24 20:51:06.495228: step 141160, total loss = 0.65, batch loss = 0.39 (332.8 examples/sec; 0.024 sec/batch; 0h:23m:22s remains)
INFO - root - 2022-02-24 20:51:06.821039: step 141170, total loss = 0.48, batch loss = 0.22 (220.9 examples/sec; 0.036 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 20:51:07.114390: step 141180, total loss = 0.53, batch loss = 0.27 (342.5 examples/sec; 0.023 sec/batch; 0h:22m:42s remains)
INFO - root - 2022-02-24 20:51:07.577439: step 141190, total loss = 0.50, batch loss = 0.24 (120.7 examples/sec; 0.066 sec/batch; 1h:04m:25s remains)
INFO - root - 2022-02-24 20:51:08.014957: step 141200, total loss = 0.52, batch loss = 0.27 (327.1 examples/sec; 0.024 sec/batch; 0h:23m:45s remains)
INFO - root - 2022-02-24 20:51:08.558438: step 141210, total loss = 0.53, batch loss = 0.27 (348.7 examples/sec; 0.023 sec/batch; 0h:22m:17s remains)
INFO - root - 2022-02-24 20:51:08.920853: step 141220, total loss = 0.52, batch loss = 0.26 (151.7 examples/sec; 0.053 sec/batch; 0h:51m:14s remains)
INFO - root - 2022-02-24 20:51:09.319738: step 141230, total loss = 0.52, batch loss = 0.26 (184.7 examples/sec; 0.043 sec/batch; 0h:42m:04s remains)
INFO - root - 2022-02-24 20:51:09.622334: step 141240, total loss = 0.57, batch loss = 0.31 (191.6 examples/sec; 0.042 sec/batch; 0h:40m:32s remains)
INFO - root - 2022-02-24 20:51:10.034577: step 141250, total loss = 0.56, batch loss = 0.31 (181.9 examples/sec; 0.044 sec/batch; 0h:42m:41s remains)
INFO - root - 2022-02-24 20:51:10.493094: step 141260, total loss = 0.51, batch loss = 0.25 (199.4 examples/sec; 0.040 sec/batch; 0h:38m:56s remains)
INFO - root - 2022-02-24 20:51:10.852442: step 141270, total loss = 0.53, batch loss = 0.27 (302.5 examples/sec; 0.026 sec/batch; 0h:25m:40s remains)
INFO - root - 2022-02-24 20:51:11.235514: step 141280, total loss = 0.56, batch loss = 0.30 (351.0 examples/sec; 0.023 sec/batch; 0h:22m:06s remains)
INFO - root - 2022-02-24 20:51:11.584068: step 141290, total loss = 0.60, batch loss = 0.34 (287.2 examples/sec; 0.028 sec/batch; 0h:27m:01s remains)
INFO - root - 2022-02-24 20:51:11.998049: step 141300, total loss = 0.50, batch loss = 0.24 (349.3 examples/sec; 0.023 sec/batch; 0h:22m:12s remains)
INFO - root - 2022-02-24 20:51:12.496874: step 141310, total loss = 0.54, batch loss = 0.28 (181.3 examples/sec; 0.044 sec/batch; 0h:42m:47s remains)
INFO - root - 2022-02-24 20:51:12.799830: step 141320, total loss = 0.63, batch loss = 0.37 (319.2 examples/sec; 0.025 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 20:51:13.052870: step 141330, total loss = 0.60, batch loss = 0.34 (331.3 examples/sec; 0.024 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:51:13.375977: step 141340, total loss = 0.45, batch loss = 0.20 (206.3 examples/sec; 0.039 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 20:51:13.689082: step 141350, total loss = 0.58, batch loss = 0.32 (238.8 examples/sec; 0.034 sec/batch; 0h:32m:28s remains)
INFO - root - 2022-02-24 20:51:14.147870: step 141360, total loss = 0.53, batch loss = 0.27 (197.1 examples/sec; 0.041 sec/batch; 0h:39m:20s remains)
INFO - root - 2022-02-24 20:51:14.594673: step 141370, total loss = 0.61, batch loss = 0.35 (123.5 examples/sec; 0.065 sec/batch; 1h:02m:45s remains)
INFO - root - 2022-02-24 20:51:14.983011: step 141380, total loss = 0.55, batch loss = 0.29 (330.1 examples/sec; 0.024 sec/batch; 0h:23m:28s remains)
INFO - root - 2022-02-24 20:51:15.287371: step 141390, total loss = 0.70, batch loss = 0.44 (344.8 examples/sec; 0.023 sec/batch; 0h:22m:28s remains)
INFO - root - 2022-02-24 20:51:15.628781: step 141400, total loss = 0.55, batch loss = 0.29 (334.7 examples/sec; 0.024 sec/batch; 0h:23m:08s remains)
INFO - root - 2022-02-24 20:51:16.122904: step 141410, total loss = 0.51, batch loss = 0.26 (127.2 examples/sec; 0.063 sec/batch; 1h:00m:53s remains)
INFO - root - 2022-02-24 20:51:16.542582: step 141420, total loss = 0.60, batch loss = 0.35 (155.2 examples/sec; 0.052 sec/batch; 0h:49m:53s remains)
INFO - root - 2022-02-24 20:51:16.957976: step 141430, total loss = 0.57, batch loss = 0.31 (226.7 examples/sec; 0.035 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:51:17.313276: step 141440, total loss = 0.51, batch loss = 0.25 (146.5 examples/sec; 0.055 sec/batch; 0h:52m:49s remains)
INFO - root - 2022-02-24 20:51:17.883283: step 141450, total loss = 0.51, batch loss = 0.25 (157.9 examples/sec; 0.051 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 20:51:18.999728: step 141460, total loss = 0.58, batch loss = 0.32 (293.1 examples/sec; 0.027 sec/batch; 0h:26m:24s remains)
INFO - root - 2022-02-24 20:51:19.492612: step 141470, total loss = 0.48, batch loss = 0.22 (283.4 examples/sec; 0.028 sec/batch; 0h:27m:18s remains)
INFO - root - 2022-02-24 20:51:19.848907: step 141480, total loss = 0.52, batch loss = 0.26 (226.2 examples/sec; 0.035 sec/batch; 0h:34m:11s remains)
INFO - root - 2022-02-24 20:51:20.186694: step 141490, total loss = 0.53, batch loss = 0.27 (283.4 examples/sec; 0.028 sec/batch; 0h:27m:17s remains)
INFO - root - 2022-02-24 20:51:20.529410: step 141500, total loss = 0.59, batch loss = 0.34 (166.5 examples/sec; 0.048 sec/batch; 0h:46m:26s remains)
INFO - root - 2022-02-24 20:51:21.056263: step 141510, total loss = 0.68, batch loss = 0.42 (223.6 examples/sec; 0.036 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:51:21.487313: step 141520, total loss = 0.51, batch loss = 0.25 (194.5 examples/sec; 0.041 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:51:21.886344: step 141530, total loss = 0.66, batch loss = 0.40 (299.5 examples/sec; 0.027 sec/batch; 0h:25m:48s remains)
INFO - root - 2022-02-24 20:51:22.178085: step 141540, total loss = 0.66, batch loss = 0.40 (338.9 examples/sec; 0.024 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 20:51:22.509002: step 141550, total loss = 0.62, batch loss = 0.36 (239.1 examples/sec; 0.033 sec/batch; 0h:32m:19s remains)
INFO - root - 2022-02-24 20:51:22.976486: step 141560, total loss = 0.56, batch loss = 0.30 (97.8 examples/sec; 0.082 sec/batch; 1h:18m:58s remains)
INFO - root - 2022-02-24 20:51:23.443201: step 141570, total loss = 0.52, batch loss = 0.26 (241.7 examples/sec; 0.033 sec/batch; 0h:31m:57s remains)
INFO - root - 2022-02-24 20:51:23.807246: step 141580, total loss = 0.45, batch loss = 0.19 (206.6 examples/sec; 0.039 sec/batch; 0h:37m:22s remains)
INFO - root - 2022-02-24 20:51:24.175033: step 141590, total loss = 0.53, batch loss = 0.27 (223.8 examples/sec; 0.036 sec/batch; 0h:34m:29s remains)
INFO - root - 2022-02-24 20:51:24.476971: step 141600, total loss = 0.48, batch loss = 0.22 (250.8 examples/sec; 0.032 sec/batch; 0h:30m:46s remains)
INFO - root - 2022-02-24 20:51:24.967168: step 141610, total loss = 0.63, batch loss = 0.37 (190.7 examples/sec; 0.042 sec/batch; 0h:40m:28s remains)
INFO - root - 2022-02-24 20:51:25.393503: step 141620, total loss = 0.50, batch loss = 0.24 (130.2 examples/sec; 0.061 sec/batch; 0h:59m:15s remains)
INFO - root - 2022-02-24 20:51:25.763720: step 141630, total loss = 0.55, batch loss = 0.29 (178.6 examples/sec; 0.045 sec/batch; 0h:43m:12s remains)
INFO - root - 2022-02-24 20:51:26.086631: step 141640, total loss = 0.63, batch loss = 0.38 (328.6 examples/sec; 0.024 sec/batch; 0h:23m:28s remains)
INFO - root - 2022-02-24 20:51:26.425499: step 141650, total loss = 0.46, batch loss = 0.21 (339.1 examples/sec; 0.024 sec/batch; 0h:22m:44s remains)
INFO - root - 2022-02-24 20:51:26.765976: step 141660, total loss = 0.56, batch loss = 0.30 (231.8 examples/sec; 0.035 sec/batch; 0h:33m:15s remains)
INFO - root - 2022-02-24 20:51:27.111220: step 141670, total loss = 0.47, batch loss = 0.21 (212.5 examples/sec; 0.038 sec/batch; 0h:36m:17s remains)
INFO - root - 2022-02-24 20:51:27.550947: step 141680, total loss = 0.59, batch loss = 0.33 (349.5 examples/sec; 0.023 sec/batch; 0h:22m:03s remains)
INFO - root - 2022-02-24 20:51:28.029974: step 141690, total loss = 0.51, batch loss = 0.25 (331.0 examples/sec; 0.024 sec/batch; 0h:23m:17s remains)
INFO - root - 2022-02-24 20:51:28.381835: step 141700, total loss = 0.54, batch loss = 0.28 (191.0 examples/sec; 0.042 sec/batch; 0h:40m:20s remains)
INFO - root - 2022-02-24 20:51:28.866751: step 141710, total loss = 0.51, batch loss = 0.25 (155.0 examples/sec; 0.052 sec/batch; 0h:49m:42s remains)
INFO - root - 2022-02-24 20:51:29.298684: step 141720, total loss = 0.51, batch loss = 0.25 (367.3 examples/sec; 0.022 sec/batch; 0h:20m:58s remains)
INFO - root - 2022-02-24 20:51:29.765356: step 141730, total loss = 0.69, batch loss = 0.43 (195.6 examples/sec; 0.041 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 20:51:30.138685: step 141740, total loss = 0.50, batch loss = 0.24 (359.8 examples/sec; 0.022 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 20:51:30.506521: step 141750, total loss = 0.52, batch loss = 0.26 (203.8 examples/sec; 0.039 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:51:30.865453: step 141760, total loss = 0.47, batch loss = 0.21 (242.4 examples/sec; 0.033 sec/batch; 0h:31m:45s remains)
INFO - root - 2022-02-24 20:51:31.225967: step 141770, total loss = 0.58, batch loss = 0.32 (185.6 examples/sec; 0.043 sec/batch; 0h:41m:27s remains)
INFO - root - 2022-02-24 20:51:31.785292: step 141780, total loss = 0.61, batch loss = 0.35 (136.4 examples/sec; 0.059 sec/batch; 0h:56m:25s remains)
INFO - root - 2022-02-24 20:51:32.188448: step 141790, total loss = 0.62, batch loss = 0.36 (273.7 examples/sec; 0.029 sec/batch; 0h:28m:07s remains)
INFO - root - 2022-02-24 20:51:32.464721: step 141800, total loss = 0.55, batch loss = 0.29 (286.7 examples/sec; 0.028 sec/batch; 0h:26m:50s remains)
INFO - root - 2022-02-24 20:51:32.863122: step 141810, total loss = 0.47, batch loss = 0.21 (335.9 examples/sec; 0.024 sec/batch; 0h:22m:54s remains)
INFO - root - 2022-02-24 20:51:33.202194: step 141820, total loss = 0.55, batch loss = 0.29 (200.2 examples/sec; 0.040 sec/batch; 0h:38m:25s remains)
INFO - root - 2022-02-24 20:51:33.654060: step 141830, total loss = 0.52, batch loss = 0.26 (210.5 examples/sec; 0.038 sec/batch; 0h:36m:31s remains)
INFO - root - 2022-02-24 20:51:34.055795: step 141840, total loss = 0.57, batch loss = 0.31 (117.1 examples/sec; 0.068 sec/batch; 1h:05m:39s remains)
INFO - root - 2022-02-24 20:51:34.443083: step 141850, total loss = 0.54, batch loss = 0.28 (269.9 examples/sec; 0.030 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 20:51:34.806304: step 141860, total loss = 0.66, batch loss = 0.41 (195.6 examples/sec; 0.041 sec/batch; 0h:39m:16s remains)
INFO - root - 2022-02-24 20:51:35.104008: step 141870, total loss = 0.58, batch loss = 0.32 (246.8 examples/sec; 0.032 sec/batch; 0h:31m:08s remains)
INFO - root - 2022-02-24 20:51:35.395981: step 141880, total loss = 0.44, batch loss = 0.18 (191.0 examples/sec; 0.042 sec/batch; 0h:40m:13s remains)
INFO - root - 2022-02-24 20:51:35.896765: step 141890, total loss = 0.66, batch loss = 0.40 (330.1 examples/sec; 0.024 sec/batch; 0h:23m:16s remains)
INFO - root - 2022-02-24 20:51:36.314385: step 141900, total loss = 0.58, batch loss = 0.32 (109.5 examples/sec; 0.073 sec/batch; 1h:10m:09s remains)
INFO - root - 2022-02-24 20:51:36.687735: step 141910, total loss = 0.60, batch loss = 0.34 (227.6 examples/sec; 0.035 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 20:51:36.990316: step 141920, total loss = 0.48, batch loss = 0.23 (287.4 examples/sec; 0.028 sec/batch; 0h:26m:42s remains)
INFO - root - 2022-02-24 20:51:37.305645: step 141930, total loss = 0.52, batch loss = 0.26 (157.7 examples/sec; 0.051 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 20:51:37.618271: step 141940, total loss = 0.50, batch loss = 0.24 (224.8 examples/sec; 0.036 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 20:51:38.038204: step 141950, total loss = 0.60, batch loss = 0.34 (144.9 examples/sec; 0.055 sec/batch; 0h:52m:57s remains)
INFO - root - 2022-02-24 20:51:38.443304: step 141960, total loss = 0.48, batch loss = 0.22 (232.2 examples/sec; 0.034 sec/batch; 0h:33m:02s remains)
INFO - root - 2022-02-24 20:51:38.894583: step 141970, total loss = 0.62, batch loss = 0.36 (186.0 examples/sec; 0.043 sec/batch; 0h:41m:14s remains)
INFO - root - 2022-02-24 20:51:39.461487: step 141980, total loss = 0.55, batch loss = 0.30 (318.4 examples/sec; 0.025 sec/batch; 0h:24m:05s remains)
INFO - root - 2022-02-24 20:51:40.009868: step 141990, total loss = 0.62, batch loss = 0.36 (119.7 examples/sec; 0.067 sec/batch; 1h:04m:05s remains)
INFO - root - 2022-02-24 20:51:40.438028: step 142000, total loss = 0.61, batch loss = 0.35 (315.3 examples/sec; 0.025 sec/batch; 0h:24m:18s remains)
INFO - root - 2022-02-24 20:51:41.003521: step 142010, total loss = 0.52, batch loss = 0.26 (121.6 examples/sec; 0.066 sec/batch; 1h:03m:03s remains)
INFO - root - 2022-02-24 20:51:41.376007: step 142020, total loss = 0.64, batch loss = 0.38 (322.4 examples/sec; 0.025 sec/batch; 0h:23m:46s remains)
INFO - root - 2022-02-24 20:51:41.756096: step 142030, total loss = 0.61, batch loss = 0.35 (217.5 examples/sec; 0.037 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:51:42.262367: step 142040, total loss = 0.67, batch loss = 0.41 (203.7 examples/sec; 0.039 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 20:51:42.900937: step 142050, total loss = 0.54, batch loss = 0.28 (60.3 examples/sec; 0.133 sec/batch; 2h:06m:57s remains)
INFO - root - 2022-02-24 20:51:43.346027: step 142060, total loss = 0.67, batch loss = 0.41 (212.0 examples/sec; 0.038 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:51:43.661188: step 142070, total loss = 0.54, batch loss = 0.28 (226.8 examples/sec; 0.035 sec/batch; 0h:33m:45s remains)
INFO - root - 2022-02-24 20:51:44.026846: step 142080, total loss = 0.64, batch loss = 0.38 (142.7 examples/sec; 0.056 sec/batch; 0h:53m:37s remains)
INFO - root - 2022-02-24 20:51:44.871627: step 142090, total loss = 0.77, batch loss = 0.51 (195.7 examples/sec; 0.041 sec/batch; 0h:39m:07s remains)
INFO - root - 2022-02-24 20:51:45.320043: step 142100, total loss = 0.47, batch loss = 0.21 (108.4 examples/sec; 0.074 sec/batch; 1h:10m:37s remains)
INFO - root - 2022-02-24 20:51:45.703603: step 142110, total loss = 0.51, batch loss = 0.25 (153.8 examples/sec; 0.052 sec/batch; 0h:49m:44s remains)
INFO - root - 2022-02-24 20:51:46.087497: step 142120, total loss = 0.50, batch loss = 0.24 (244.6 examples/sec; 0.033 sec/batch; 0h:31m:16s remains)
INFO - root - 2022-02-24 20:51:46.405589: step 142130, total loss = 0.63, batch loss = 0.38 (354.5 examples/sec; 0.023 sec/batch; 0h:21m:34s remains)
INFO - root - 2022-02-24 20:51:46.826766: step 142140, total loss = 0.46, batch loss = 0.20 (185.5 examples/sec; 0.043 sec/batch; 0h:41m:13s remains)
INFO - root - 2022-02-24 20:51:47.218948: step 142150, total loss = 0.59, batch loss = 0.34 (365.9 examples/sec; 0.022 sec/batch; 0h:20m:53s remains)
INFO - root - 2022-02-24 20:51:47.678472: step 142160, total loss = 0.53, batch loss = 0.27 (246.7 examples/sec; 0.032 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 20:51:48.020958: step 142170, total loss = 0.55, batch loss = 0.29 (139.3 examples/sec; 0.057 sec/batch; 0h:54m:52s remains)
INFO - root - 2022-02-24 20:51:48.426318: step 142180, total loss = 0.49, batch loss = 0.23 (345.1 examples/sec; 0.023 sec/batch; 0h:22m:08s remains)
INFO - root - 2022-02-24 20:51:48.726776: step 142190, total loss = 0.57, batch loss = 0.31 (204.6 examples/sec; 0.039 sec/batch; 0h:37m:21s remains)
INFO - root - 2022-02-24 20:51:49.192852: step 142200, total loss = 0.49, batch loss = 0.23 (244.9 examples/sec; 0.033 sec/batch; 0h:31m:11s remains)
INFO - root - 2022-02-24 20:51:49.673978: step 142210, total loss = 0.57, batch loss = 0.31 (371.7 examples/sec; 0.022 sec/batch; 0h:20m:33s remains)
INFO - root - 2022-02-24 20:51:50.013063: step 142220, total loss = 0.58, batch loss = 0.32 (252.2 examples/sec; 0.032 sec/batch; 0h:30m:16s remains)
INFO - root - 2022-02-24 20:51:50.385753: step 142230, total loss = 0.55, batch loss = 0.29 (193.2 examples/sec; 0.041 sec/batch; 0h:39m:31s remains)
INFO - root - 2022-02-24 20:51:50.737480: step 142240, total loss = 0.60, batch loss = 0.34 (187.3 examples/sec; 0.043 sec/batch; 0h:40m:45s remains)
INFO - root - 2022-02-24 20:51:51.154086: step 142250, total loss = 0.49, batch loss = 0.23 (166.0 examples/sec; 0.048 sec/batch; 0h:45m:59s remains)
INFO - root - 2022-02-24 20:51:51.567414: step 142260, total loss = 0.57, batch loss = 0.31 (200.4 examples/sec; 0.040 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:51:52.011878: step 142270, total loss = 0.58, batch loss = 0.32 (278.7 examples/sec; 0.029 sec/batch; 0h:27m:22s remains)
INFO - root - 2022-02-24 20:51:52.327503: step 142280, total loss = 0.59, batch loss = 0.33 (363.8 examples/sec; 0.022 sec/batch; 0h:20m:58s remains)
INFO - root - 2022-02-24 20:51:52.660740: step 142290, total loss = 0.71, batch loss = 0.45 (247.8 examples/sec; 0.032 sec/batch; 0h:30m:47s remains)
INFO - root - 2022-02-24 20:51:53.035890: step 142300, total loss = 0.52, batch loss = 0.26 (304.2 examples/sec; 0.026 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 20:51:53.579222: step 142310, total loss = 0.61, batch loss = 0.35 (290.7 examples/sec; 0.028 sec/batch; 0h:26m:13s remains)
INFO - root - 2022-02-24 20:51:53.993087: step 142320, total loss = 0.51, batch loss = 0.25 (328.9 examples/sec; 0.024 sec/batch; 0h:23m:10s remains)
INFO - root - 2022-02-24 20:51:54.420446: step 142330, total loss = 0.44, batch loss = 0.18 (170.3 examples/sec; 0.047 sec/batch; 0h:44m:45s remains)
INFO - root - 2022-02-24 20:51:54.770474: step 142340, total loss = 0.54, batch loss = 0.28 (149.8 examples/sec; 0.053 sec/batch; 0h:50m:52s remains)
INFO - root - 2022-02-24 20:51:55.091577: step 142350, total loss = 0.52, batch loss = 0.26 (283.8 examples/sec; 0.028 sec/batch; 0h:26m:51s remains)
INFO - root - 2022-02-24 20:51:55.443147: step 142360, total loss = 0.47, batch loss = 0.21 (346.8 examples/sec; 0.023 sec/batch; 0h:21m:57s remains)
INFO - root - 2022-02-24 20:51:55.968105: step 142370, total loss = 0.63, batch loss = 0.38 (207.6 examples/sec; 0.039 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 20:51:56.453600: step 142380, total loss = 0.51, batch loss = 0.25 (157.1 examples/sec; 0.051 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:51:56.861063: step 142390, total loss = 0.46, batch loss = 0.21 (164.8 examples/sec; 0.049 sec/batch; 0h:46m:12s remains)
INFO - root - 2022-02-24 20:51:57.169509: step 142400, total loss = 0.58, batch loss = 0.32 (125.1 examples/sec; 0.064 sec/batch; 1h:00m:51s remains)
INFO - root - 2022-02-24 20:51:57.583301: step 142410, total loss = 0.48, batch loss = 0.22 (167.5 examples/sec; 0.048 sec/batch; 0h:45m:27s remains)
INFO - root - 2022-02-24 20:51:57.990484: step 142420, total loss = 0.61, batch loss = 0.35 (174.4 examples/sec; 0.046 sec/batch; 0h:43m:38s remains)
INFO - root - 2022-02-24 20:51:58.429365: step 142430, total loss = 0.53, batch loss = 0.27 (316.1 examples/sec; 0.025 sec/batch; 0h:24m:04s remains)
INFO - root - 2022-02-24 20:51:58.770628: step 142440, total loss = 0.69, batch loss = 0.43 (135.0 examples/sec; 0.059 sec/batch; 0h:56m:21s remains)
INFO - root - 2022-02-24 20:51:59.325465: step 142450, total loss = 0.50, batch loss = 0.24 (351.9 examples/sec; 0.023 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 20:52:00.439199: step 142460, total loss = 0.45, batch loss = 0.19 (147.2 examples/sec; 0.054 sec/batch; 0h:51m:39s remains)
INFO - root - 2022-02-24 20:52:00.857432: step 142470, total loss = 0.54, batch loss = 0.28 (121.5 examples/sec; 0.066 sec/batch; 1h:02m:35s remains)
INFO - root - 2022-02-24 20:52:01.285964: step 142480, total loss = 0.48, batch loss = 0.23 (320.5 examples/sec; 0.025 sec/batch; 0h:23m:43s remains)
INFO - root - 2022-02-24 20:52:01.657448: step 142490, total loss = 0.54, batch loss = 0.28 (306.9 examples/sec; 0.026 sec/batch; 0h:24m:46s remains)
INFO - root - 2022-02-24 20:52:02.033027: step 142500, total loss = 0.54, batch loss = 0.28 (126.8 examples/sec; 0.063 sec/batch; 0h:59m:56s remains)
INFO - root - 2022-02-24 20:52:02.463393: step 142510, total loss = 0.58, batch loss = 0.32 (328.4 examples/sec; 0.024 sec/batch; 0h:23m:08s remains)
INFO - root - 2022-02-24 20:52:02.957943: step 142520, total loss = 0.70, batch loss = 0.44 (179.5 examples/sec; 0.045 sec/batch; 0h:42m:20s remains)
INFO - root - 2022-02-24 20:52:03.352549: step 142530, total loss = 0.55, batch loss = 0.29 (219.5 examples/sec; 0.036 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:52:03.637104: step 142540, total loss = 0.53, batch loss = 0.27 (282.9 examples/sec; 0.028 sec/batch; 0h:26m:50s remains)
INFO - root - 2022-02-24 20:52:03.966527: step 142550, total loss = 0.60, batch loss = 0.34 (241.7 examples/sec; 0.033 sec/batch; 0h:31m:24s remains)
INFO - root - 2022-02-24 20:52:04.273980: step 142560, total loss = 0.52, batch loss = 0.26 (349.9 examples/sec; 0.023 sec/batch; 0h:21m:41s remains)
INFO - root - 2022-02-24 20:52:04.871831: step 142570, total loss = 0.57, batch loss = 0.32 (172.1 examples/sec; 0.046 sec/batch; 0h:44m:05s remains)
INFO - root - 2022-02-24 20:52:05.348506: step 142580, total loss = 0.50, batch loss = 0.24 (65.3 examples/sec; 0.123 sec/batch; 1h:56m:16s remains)
INFO - root - 2022-02-24 20:52:05.732425: step 142590, total loss = 0.45, batch loss = 0.20 (334.7 examples/sec; 0.024 sec/batch; 0h:22m:40s remains)
INFO - root - 2022-02-24 20:52:06.033788: step 142600, total loss = 0.54, batch loss = 0.29 (387.5 examples/sec; 0.021 sec/batch; 0h:19m:34s remains)
INFO - root - 2022-02-24 20:52:06.465082: step 142610, total loss = 0.53, batch loss = 0.27 (330.6 examples/sec; 0.024 sec/batch; 0h:22m:56s remains)
INFO - root - 2022-02-24 20:52:06.828226: step 142620, total loss = 0.55, batch loss = 0.29 (192.8 examples/sec; 0.041 sec/batch; 0h:39m:19s remains)
INFO - root - 2022-02-24 20:52:07.273072: step 142630, total loss = 0.44, batch loss = 0.18 (135.1 examples/sec; 0.059 sec/batch; 0h:56m:08s remains)
INFO - root - 2022-02-24 20:52:07.629828: step 142640, total loss = 0.54, batch loss = 0.28 (315.4 examples/sec; 0.025 sec/batch; 0h:24m:02s remains)
INFO - root - 2022-02-24 20:52:08.029576: step 142650, total loss = 0.50, batch loss = 0.24 (231.1 examples/sec; 0.035 sec/batch; 0h:32m:48s remains)
INFO - root - 2022-02-24 20:52:08.431173: step 142660, total loss = 0.62, batch loss = 0.36 (359.4 examples/sec; 0.022 sec/batch; 0h:21m:05s remains)
INFO - root - 2022-02-24 20:52:08.758866: step 142670, total loss = 0.52, batch loss = 0.27 (162.6 examples/sec; 0.049 sec/batch; 0h:46m:36s remains)
INFO - root - 2022-02-24 20:52:09.193510: step 142680, total loss = 0.51, batch loss = 0.26 (350.6 examples/sec; 0.023 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 20:52:09.669066: step 142690, total loss = 0.60, batch loss = 0.34 (273.4 examples/sec; 0.029 sec/batch; 0h:27m:42s remains)
INFO - root - 2022-02-24 20:52:10.020740: step 142700, total loss = 0.50, batch loss = 0.24 (329.6 examples/sec; 0.024 sec/batch; 0h:22m:58s remains)
INFO - root - 2022-02-24 20:52:10.496774: step 142710, total loss = 0.50, batch loss = 0.24 (127.6 examples/sec; 0.063 sec/batch; 0h:59m:19s remains)
INFO - root - 2022-02-24 20:52:10.807071: step 142720, total loss = 0.62, batch loss = 0.36 (274.8 examples/sec; 0.029 sec/batch; 0h:27m:33s remains)
INFO - root - 2022-02-24 20:52:11.287687: step 142730, total loss = 0.55, batch loss = 0.30 (118.6 examples/sec; 0.067 sec/batch; 1h:03m:50s remains)
INFO - root - 2022-02-24 20:52:11.645359: step 142740, total loss = 0.49, batch loss = 0.23 (248.6 examples/sec; 0.032 sec/batch; 0h:30m:26s remains)
INFO - root - 2022-02-24 20:52:12.051773: step 142750, total loss = 0.48, batch loss = 0.22 (224.2 examples/sec; 0.036 sec/batch; 0h:33m:45s remains)
INFO - root - 2022-02-24 20:52:12.347758: step 142760, total loss = 0.56, batch loss = 0.31 (261.2 examples/sec; 0.031 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 20:52:12.700348: step 142770, total loss = 0.64, batch loss = 0.38 (136.1 examples/sec; 0.059 sec/batch; 0h:55m:35s remains)
INFO - root - 2022-02-24 20:52:13.043740: step 142780, total loss = 0.48, batch loss = 0.22 (168.9 examples/sec; 0.047 sec/batch; 0h:44m:46s remains)
INFO - root - 2022-02-24 20:52:13.356517: step 142790, total loss = 0.58, batch loss = 0.32 (261.2 examples/sec; 0.031 sec/batch; 0h:28m:56s remains)
INFO - root - 2022-02-24 20:52:13.753279: step 142800, total loss = 0.47, batch loss = 0.21 (147.2 examples/sec; 0.054 sec/batch; 0h:51m:20s remains)
INFO - root - 2022-02-24 20:52:14.151576: step 142810, total loss = 0.53, batch loss = 0.27 (311.2 examples/sec; 0.026 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 20:52:14.483839: step 142820, total loss = 0.59, batch loss = 0.34 (265.2 examples/sec; 0.030 sec/batch; 0h:28m:29s remains)
INFO - root - 2022-02-24 20:52:14.786662: step 142830, total loss = 0.56, batch loss = 0.30 (261.5 examples/sec; 0.031 sec/batch; 0h:28m:53s remains)
INFO - root - 2022-02-24 20:52:15.187354: step 142840, total loss = 0.46, batch loss = 0.20 (175.0 examples/sec; 0.046 sec/batch; 0h:43m:09s remains)
INFO - root - 2022-02-24 20:52:15.573214: step 142850, total loss = 0.55, batch loss = 0.29 (115.2 examples/sec; 0.069 sec/batch; 1h:05m:35s remains)
INFO - root - 2022-02-24 20:52:16.069939: step 142860, total loss = 0.49, batch loss = 0.23 (191.9 examples/sec; 0.042 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:52:16.437840: step 142870, total loss = 0.60, batch loss = 0.34 (311.1 examples/sec; 0.026 sec/batch; 0h:24m:16s remains)
INFO - root - 2022-02-24 20:52:16.779120: step 142880, total loss = 0.56, batch loss = 0.30 (313.0 examples/sec; 0.026 sec/batch; 0h:24m:06s remains)
INFO - root - 2022-02-24 20:52:17.073503: step 142890, total loss = 0.55, batch loss = 0.29 (340.8 examples/sec; 0.023 sec/batch; 0h:22m:08s remains)
INFO - root - 2022-02-24 20:52:17.451542: step 142900, total loss = 0.61, batch loss = 0.35 (106.0 examples/sec; 0.075 sec/batch; 1h:11m:10s remains)
INFO - root - 2022-02-24 20:52:17.900884: step 142910, total loss = 0.54, batch loss = 0.28 (144.8 examples/sec; 0.055 sec/batch; 0h:52m:06s remains)
INFO - root - 2022-02-24 20:52:18.416504: step 142920, total loss = 0.67, batch loss = 0.41 (103.8 examples/sec; 0.077 sec/batch; 1h:12m:41s remains)
INFO - root - 2022-02-24 20:52:18.752272: step 142930, total loss = 0.52, batch loss = 0.26 (114.4 examples/sec; 0.070 sec/batch; 1h:05m:55s remains)
INFO - root - 2022-02-24 20:52:19.066754: step 142940, total loss = 0.60, batch loss = 0.34 (198.6 examples/sec; 0.040 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 20:52:19.377423: step 142950, total loss = 0.50, batch loss = 0.24 (302.4 examples/sec; 0.026 sec/batch; 0h:24m:55s remains)
INFO - root - 2022-02-24 20:52:19.708701: step 142960, total loss = 0.50, batch loss = 0.24 (157.6 examples/sec; 0.051 sec/batch; 0h:47m:49s remains)
INFO - root - 2022-02-24 20:52:20.406387: step 142970, total loss = 0.54, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 3h:31m:39s remains)
INFO - root - 2022-02-24 20:52:20.732927: step 142980, total loss = 0.60, batch loss = 0.34 (317.2 examples/sec; 0.025 sec/batch; 0h:23m:45s remains)
INFO - root - 2022-02-24 20:52:21.053343: step 142990, total loss = 0.63, batch loss = 0.38 (330.9 examples/sec; 0.024 sec/batch; 0h:22m:46s remains)
INFO - root - 2022-02-24 20:52:21.415073: step 143000, total loss = 0.56, batch loss = 0.31 (170.4 examples/sec; 0.047 sec/batch; 0h:44m:12s remains)
INFO - root - 2022-02-24 20:52:21.876368: step 143010, total loss = 0.53, batch loss = 0.27 (97.9 examples/sec; 0.082 sec/batch; 1h:16m:54s remains)
INFO - root - 2022-02-24 20:52:22.417930: step 143020, total loss = 0.50, batch loss = 0.24 (169.5 examples/sec; 0.047 sec/batch; 0h:44m:26s remains)
INFO - root - 2022-02-24 20:52:22.918095: step 143030, total loss = 0.54, batch loss = 0.28 (117.3 examples/sec; 0.068 sec/batch; 1h:04m:10s remains)
INFO - root - 2022-02-24 20:52:23.403555: step 143040, total loss = 0.57, batch loss = 0.31 (226.2 examples/sec; 0.035 sec/batch; 0h:33m:16s remains)
INFO - root - 2022-02-24 20:52:23.916989: step 143050, total loss = 0.57, batch loss = 0.31 (177.5 examples/sec; 0.045 sec/batch; 0h:42m:23s remains)
INFO - root - 2022-02-24 20:52:24.402308: step 143060, total loss = 0.49, batch loss = 0.23 (311.1 examples/sec; 0.026 sec/batch; 0h:24m:11s remains)
INFO - root - 2022-02-24 20:52:24.861260: step 143070, total loss = 0.47, batch loss = 0.21 (107.4 examples/sec; 0.074 sec/batch; 1h:10m:03s remains)
INFO - root - 2022-02-24 20:52:25.655466: step 143080, total loss = 0.61, batch loss = 0.35 (195.9 examples/sec; 0.041 sec/batch; 0h:38m:24s remains)
INFO - root - 2022-02-24 20:52:26.085337: step 143090, total loss = 0.52, batch loss = 0.27 (330.1 examples/sec; 0.024 sec/batch; 0h:22m:46s remains)
INFO - root - 2022-02-24 20:52:26.620563: step 143100, total loss = 0.61, batch loss = 0.36 (149.4 examples/sec; 0.054 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 20:52:27.062665: step 143110, total loss = 0.65, batch loss = 0.39 (210.8 examples/sec; 0.038 sec/batch; 0h:35m:40s remains)
INFO - root - 2022-02-24 20:52:27.421323: step 143120, total loss = 0.49, batch loss = 0.23 (215.5 examples/sec; 0.037 sec/batch; 0h:34m:53s remains)
INFO - root - 2022-02-24 20:52:27.771264: step 143130, total loss = 0.53, batch loss = 0.27 (239.6 examples/sec; 0.033 sec/batch; 0h:31m:22s remains)
INFO - root - 2022-02-24 20:52:28.116070: step 143140, total loss = 0.55, batch loss = 0.29 (225.1 examples/sec; 0.036 sec/batch; 0h:33m:22s remains)
INFO - root - 2022-02-24 20:52:28.506726: step 143150, total loss = 0.51, batch loss = 0.25 (247.9 examples/sec; 0.032 sec/batch; 0h:30m:18s remains)
INFO - root - 2022-02-24 20:52:28.853778: step 143160, total loss = 0.50, batch loss = 0.24 (156.1 examples/sec; 0.051 sec/batch; 0h:48m:07s remains)
INFO - root - 2022-02-24 20:52:29.242468: step 143170, total loss = 0.56, batch loss = 0.30 (323.8 examples/sec; 0.025 sec/batch; 0h:23m:11s remains)
INFO - root - 2022-02-24 20:52:29.587480: step 143180, total loss = 0.53, batch loss = 0.27 (261.8 examples/sec; 0.031 sec/batch; 0h:28m:40s remains)
INFO - root - 2022-02-24 20:52:29.927241: step 143190, total loss = 0.51, batch loss = 0.25 (139.8 examples/sec; 0.057 sec/batch; 0h:53m:41s remains)
INFO - root - 2022-02-24 20:52:30.351536: step 143200, total loss = 0.51, batch loss = 0.26 (238.2 examples/sec; 0.034 sec/batch; 0h:31m:30s remains)
INFO - root - 2022-02-24 20:52:30.959408: step 143210, total loss = 0.71, batch loss = 0.46 (225.0 examples/sec; 0.036 sec/batch; 0h:33m:21s remains)
INFO - root - 2022-02-24 20:52:31.316819: step 143220, total loss = 0.49, batch loss = 0.23 (319.4 examples/sec; 0.025 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:52:31.718268: step 143230, total loss = 0.46, batch loss = 0.20 (292.6 examples/sec; 0.027 sec/batch; 0h:25m:38s remains)
INFO - root - 2022-02-24 20:52:32.093504: step 143240, total loss = 0.53, batch loss = 0.28 (317.7 examples/sec; 0.025 sec/batch; 0h:23m:36s remains)
INFO - root - 2022-02-24 20:52:32.502513: step 143250, total loss = 0.49, batch loss = 0.24 (249.4 examples/sec; 0.032 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 20:52:32.881606: step 143260, total loss = 0.49, batch loss = 0.23 (254.2 examples/sec; 0.031 sec/batch; 0h:29m:30s remains)
INFO - root - 2022-02-24 20:52:33.300799: step 143270, total loss = 0.55, batch loss = 0.30 (212.8 examples/sec; 0.038 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 20:52:33.665845: step 143280, total loss = 0.56, batch loss = 0.30 (144.9 examples/sec; 0.055 sec/batch; 0h:51m:44s remains)
INFO - root - 2022-02-24 20:52:33.994833: step 143290, total loss = 0.54, batch loss = 0.28 (228.5 examples/sec; 0.035 sec/batch; 0h:32m:48s remains)
INFO - root - 2022-02-24 20:52:34.352043: step 143300, total loss = 0.55, batch loss = 0.29 (263.2 examples/sec; 0.030 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 20:52:34.912815: step 143310, total loss = 0.54, batch loss = 0.28 (112.0 examples/sec; 0.071 sec/batch; 1h:06m:52s remains)
INFO - root - 2022-02-24 20:52:35.355560: step 143320, total loss = 0.49, batch loss = 0.24 (197.3 examples/sec; 0.041 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 20:52:35.744447: step 143330, total loss = 0.47, batch loss = 0.21 (222.6 examples/sec; 0.036 sec/batch; 0h:33m:38s remains)
INFO - root - 2022-02-24 20:52:36.098570: step 143340, total loss = 0.56, batch loss = 0.30 (201.4 examples/sec; 0.040 sec/batch; 0h:37m:10s remains)
INFO - root - 2022-02-24 20:52:36.407749: step 143350, total loss = 0.55, batch loss = 0.29 (343.2 examples/sec; 0.023 sec/batch; 0h:21m:48s remains)
INFO - root - 2022-02-24 20:52:36.831182: step 143360, total loss = 0.60, batch loss = 0.34 (142.0 examples/sec; 0.056 sec/batch; 0h:52m:42s remains)
INFO - root - 2022-02-24 20:52:37.309907: step 143370, total loss = 0.57, batch loss = 0.31 (127.5 examples/sec; 0.063 sec/batch; 0h:58m:42s remains)
INFO - root - 2022-02-24 20:52:37.676852: step 143380, total loss = 0.66, batch loss = 0.40 (323.7 examples/sec; 0.025 sec/batch; 0h:23m:06s remains)
INFO - root - 2022-02-24 20:52:38.003453: step 143390, total loss = 0.57, batch loss = 0.32 (323.3 examples/sec; 0.025 sec/batch; 0h:23m:08s remains)
INFO - root - 2022-02-24 20:52:38.311434: step 143400, total loss = 0.60, batch loss = 0.34 (337.2 examples/sec; 0.024 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 20:52:38.760378: step 143410, total loss = 0.56, batch loss = 0.31 (148.7 examples/sec; 0.054 sec/batch; 0h:50m:18s remains)
INFO - root - 2022-02-24 20:52:39.159124: step 143420, total loss = 0.51, batch loss = 0.25 (92.1 examples/sec; 0.087 sec/batch; 1h:21m:10s remains)
INFO - root - 2022-02-24 20:52:39.639040: step 143430, total loss = 0.54, batch loss = 0.29 (185.7 examples/sec; 0.043 sec/batch; 0h:40m:16s remains)
INFO - root - 2022-02-24 20:52:40.024699: step 143440, total loss = 0.55, batch loss = 0.29 (286.1 examples/sec; 0.028 sec/batch; 0h:26m:07s remains)
INFO - root - 2022-02-24 20:52:40.494397: step 143450, total loss = 0.48, batch loss = 0.22 (230.4 examples/sec; 0.035 sec/batch; 0h:32m:26s remains)
INFO - root - 2022-02-24 20:52:40.894707: step 143460, total loss = 0.49, batch loss = 0.23 (178.1 examples/sec; 0.045 sec/batch; 0h:41m:56s remains)
INFO - root - 2022-02-24 20:52:41.319303: step 143470, total loss = 0.47, batch loss = 0.22 (261.1 examples/sec; 0.031 sec/batch; 0h:28m:36s remains)
INFO - root - 2022-02-24 20:52:41.805422: step 143480, total loss = 0.52, batch loss = 0.27 (224.8 examples/sec; 0.036 sec/batch; 0h:33m:13s remains)
INFO - root - 2022-02-24 20:52:42.111123: step 143490, total loss = 0.53, batch loss = 0.27 (242.6 examples/sec; 0.033 sec/batch; 0h:30m:47s remains)
INFO - root - 2022-02-24 20:52:42.435946: step 143500, total loss = 0.56, batch loss = 0.30 (245.5 examples/sec; 0.033 sec/batch; 0h:30m:24s remains)
INFO - root - 2022-02-24 20:52:42.867859: step 143510, total loss = 0.52, batch loss = 0.26 (294.4 examples/sec; 0.027 sec/batch; 0h:25m:21s remains)
INFO - root - 2022-02-24 20:52:43.245110: step 143520, total loss = 0.56, batch loss = 0.30 (386.9 examples/sec; 0.021 sec/batch; 0h:19m:17s remains)
INFO - root - 2022-02-24 20:52:43.672387: step 143530, total loss = 0.55, batch loss = 0.30 (140.0 examples/sec; 0.057 sec/batch; 0h:53m:17s remains)
INFO - root - 2022-02-24 20:52:44.279865: step 143540, total loss = 0.51, batch loss = 0.25 (82.7 examples/sec; 0.097 sec/batch; 1h:30m:14s remains)
INFO - root - 2022-02-24 20:52:44.786237: step 143550, total loss = 0.63, batch loss = 0.37 (106.8 examples/sec; 0.075 sec/batch; 1h:09m:49s remains)
INFO - root - 2022-02-24 20:52:45.881048: step 143560, total loss = 0.63, batch loss = 0.37 (154.4 examples/sec; 0.052 sec/batch; 0h:48m:18s remains)
INFO - root - 2022-02-24 20:52:46.355703: step 143570, total loss = 0.52, batch loss = 0.26 (203.8 examples/sec; 0.039 sec/batch; 0h:36m:35s remains)
INFO - root - 2022-02-24 20:52:46.729961: step 143580, total loss = 0.58, batch loss = 0.32 (271.6 examples/sec; 0.029 sec/batch; 0h:27m:27s remains)
INFO - root - 2022-02-24 20:52:47.132856: step 143590, total loss = 0.59, batch loss = 0.34 (311.1 examples/sec; 0.026 sec/batch; 0h:23m:57s remains)
INFO - root - 2022-02-24 20:52:47.565556: step 143600, total loss = 0.43, batch loss = 0.17 (111.2 examples/sec; 0.072 sec/batch; 1h:07m:00s remains)
INFO - root - 2022-02-24 20:52:48.045404: step 143610, total loss = 0.53, batch loss = 0.27 (126.1 examples/sec; 0.063 sec/batch; 0h:59m:06s remains)
INFO - root - 2022-02-24 20:52:48.486129: step 143620, total loss = 0.63, batch loss = 0.37 (192.6 examples/sec; 0.042 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:52:48.869482: step 143630, total loss = 0.48, batch loss = 0.23 (252.7 examples/sec; 0.032 sec/batch; 0h:29m:28s remains)
INFO - root - 2022-02-24 20:52:49.231315: step 143640, total loss = 0.58, batch loss = 0.32 (161.2 examples/sec; 0.050 sec/batch; 0h:46m:12s remains)
INFO - root - 2022-02-24 20:52:49.669197: step 143650, total loss = 0.63, batch loss = 0.37 (93.0 examples/sec; 0.086 sec/batch; 1h:20m:05s remains)
INFO - root - 2022-02-24 20:52:49.999510: step 143660, total loss = 0.43, batch loss = 0.17 (264.4 examples/sec; 0.030 sec/batch; 0h:28m:09s remains)
INFO - root - 2022-02-24 20:52:50.434965: step 143670, total loss = 0.57, batch loss = 0.31 (190.2 examples/sec; 0.042 sec/batch; 0h:39m:07s remains)
INFO - root - 2022-02-24 20:52:50.987482: step 143680, total loss = 0.47, batch loss = 0.21 (235.7 examples/sec; 0.034 sec/batch; 0h:31m:34s remains)
INFO - root - 2022-02-24 20:52:51.313132: step 143690, total loss = 0.56, batch loss = 0.30 (261.4 examples/sec; 0.031 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 20:52:51.623594: step 143700, total loss = 0.53, batch loss = 0.27 (217.6 examples/sec; 0.037 sec/batch; 0h:34m:11s remains)
INFO - root - 2022-02-24 20:52:52.016388: step 143710, total loss = 0.46, batch loss = 0.20 (260.5 examples/sec; 0.031 sec/batch; 0h:28m:33s remains)
INFO - root - 2022-02-24 20:52:52.464193: step 143720, total loss = 0.51, batch loss = 0.25 (210.7 examples/sec; 0.038 sec/batch; 0h:35m:17s remains)
INFO - root - 2022-02-24 20:52:52.820845: step 143730, total loss = 0.60, batch loss = 0.35 (298.4 examples/sec; 0.027 sec/batch; 0h:24m:55s remains)
INFO - root - 2022-02-24 20:52:53.200077: step 143740, total loss = 0.49, batch loss = 0.23 (336.1 examples/sec; 0.024 sec/batch; 0h:22m:07s remains)
INFO - root - 2022-02-24 20:52:53.528264: step 143750, total loss = 0.60, batch loss = 0.34 (207.0 examples/sec; 0.039 sec/batch; 0h:35m:54s remains)
INFO - root - 2022-02-24 20:52:53.871486: step 143760, total loss = 0.49, batch loss = 0.23 (365.3 examples/sec; 0.022 sec/batch; 0h:20m:20s remains)
INFO - root - 2022-02-24 20:52:54.182677: step 143770, total loss = 0.60, batch loss = 0.34 (216.2 examples/sec; 0.037 sec/batch; 0h:34m:21s remains)
INFO - root - 2022-02-24 20:52:54.574086: step 143780, total loss = 0.59, batch loss = 0.34 (222.9 examples/sec; 0.036 sec/batch; 0h:33m:19s remains)
INFO - root - 2022-02-24 20:52:55.006889: step 143790, total loss = 0.47, batch loss = 0.21 (219.2 examples/sec; 0.036 sec/batch; 0h:33m:52s remains)
INFO - root - 2022-02-24 20:52:55.493215: step 143800, total loss = 0.53, batch loss = 0.27 (138.0 examples/sec; 0.058 sec/batch; 0h:53m:49s remains)
INFO - root - 2022-02-24 20:52:56.027803: step 143810, total loss = 0.54, batch loss = 0.29 (135.6 examples/sec; 0.059 sec/batch; 0h:54m:44s remains)
INFO - root - 2022-02-24 20:52:56.358812: step 143820, total loss = 0.62, batch loss = 0.36 (192.7 examples/sec; 0.042 sec/batch; 0h:38m:31s remains)
INFO - root - 2022-02-24 20:52:56.751931: step 143830, total loss = 0.52, batch loss = 0.26 (119.4 examples/sec; 0.067 sec/batch; 1h:02m:10s remains)
INFO - root - 2022-02-24 20:52:57.159367: step 143840, total loss = 0.48, batch loss = 0.22 (96.3 examples/sec; 0.083 sec/batch; 1h:17m:05s remains)
INFO - root - 2022-02-24 20:52:57.570922: step 143850, total loss = 0.52, batch loss = 0.26 (349.8 examples/sec; 0.023 sec/batch; 0h:21m:12s remains)
INFO - root - 2022-02-24 20:52:57.880973: step 143860, total loss = 0.54, batch loss = 0.28 (369.6 examples/sec; 0.022 sec/batch; 0h:20m:04s remains)
INFO - root - 2022-02-24 20:52:58.265090: step 143870, total loss = 0.45, batch loss = 0.19 (299.6 examples/sec; 0.027 sec/batch; 0h:24m:45s remains)
INFO - root - 2022-02-24 20:52:58.595116: step 143880, total loss = 0.60, batch loss = 0.34 (166.4 examples/sec; 0.048 sec/batch; 0h:44m:33s remains)
INFO - root - 2022-02-24 20:52:58.974363: step 143890, total loss = 0.62, batch loss = 0.36 (346.3 examples/sec; 0.023 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 20:52:59.429077: step 143900, total loss = 0.53, batch loss = 0.27 (353.7 examples/sec; 0.023 sec/batch; 0h:20m:57s remains)
INFO - root - 2022-02-24 20:52:59.928337: step 143910, total loss = 0.50, batch loss = 0.24 (318.6 examples/sec; 0.025 sec/batch; 0h:23m:16s remains)
INFO - root - 2022-02-24 20:53:00.241694: step 143920, total loss = 0.62, batch loss = 0.36 (341.0 examples/sec; 0.023 sec/batch; 0h:21m:43s remains)
INFO - root - 2022-02-24 20:53:00.647981: step 143930, total loss = 0.50, batch loss = 0.24 (351.9 examples/sec; 0.023 sec/batch; 0h:21m:03s remains)
INFO - root - 2022-02-24 20:53:00.970487: step 143940, total loss = 0.50, batch loss = 0.24 (337.8 examples/sec; 0.024 sec/batch; 0h:21m:55s remains)
INFO - root - 2022-02-24 20:53:01.466653: step 143950, total loss = 0.49, batch loss = 0.23 (159.2 examples/sec; 0.050 sec/batch; 0h:46m:31s remains)
INFO - root - 2022-02-24 20:53:01.899067: step 143960, total loss = 0.57, batch loss = 0.31 (223.7 examples/sec; 0.036 sec/batch; 0h:33m:06s remains)
INFO - root - 2022-02-24 20:53:02.296133: step 143970, total loss = 0.54, batch loss = 0.28 (209.0 examples/sec; 0.038 sec/batch; 0h:35m:25s remains)
INFO - root - 2022-02-24 20:53:02.645547: step 143980, total loss = 0.52, batch loss = 0.26 (196.8 examples/sec; 0.041 sec/batch; 0h:37m:37s remains)
INFO - root - 2022-02-24 20:53:02.939336: step 143990, total loss = 0.52, batch loss = 0.26 (247.7 examples/sec; 0.032 sec/batch; 0h:29m:52s remains)
INFO - root - 2022-02-24 20:53:03.298435: step 144000, total loss = 0.52, batch loss = 0.26 (269.0 examples/sec; 0.030 sec/batch; 0h:27m:30s remains)
INFO - root - 2022-02-24 20:53:03.762077: step 144010, total loss = 0.53, batch loss = 0.28 (213.6 examples/sec; 0.037 sec/batch; 0h:34m:37s remains)
INFO - root - 2022-02-24 20:53:04.158294: step 144020, total loss = 0.53, batch loss = 0.27 (355.1 examples/sec; 0.023 sec/batch; 0h:20m:49s remains)
INFO - root - 2022-02-24 20:53:04.514152: step 144030, total loss = 0.56, batch loss = 0.31 (245.9 examples/sec; 0.033 sec/batch; 0h:30m:04s remains)
INFO - root - 2022-02-24 20:53:04.919255: step 144040, total loss = 0.45, batch loss = 0.20 (324.7 examples/sec; 0.025 sec/batch; 0h:22m:46s remains)
INFO - root - 2022-02-24 20:53:05.266290: step 144050, total loss = 0.49, batch loss = 0.23 (278.2 examples/sec; 0.029 sec/batch; 0h:26m:34s remains)
INFO - root - 2022-02-24 20:53:05.731124: step 144060, total loss = 0.57, batch loss = 0.31 (230.7 examples/sec; 0.035 sec/batch; 0h:32m:02s remains)
INFO - root - 2022-02-24 20:53:06.188043: step 144070, total loss = 0.57, batch loss = 0.31 (310.7 examples/sec; 0.026 sec/batch; 0h:23m:47s remains)
INFO - root - 2022-02-24 20:53:06.847821: step 144080, total loss = 0.75, batch loss = 0.49 (162.1 examples/sec; 0.049 sec/batch; 0h:45m:35s remains)
INFO - root - 2022-02-24 20:53:07.180728: step 144090, total loss = 0.47, batch loss = 0.21 (328.0 examples/sec; 0.024 sec/batch; 0h:22m:31s remains)
INFO - root - 2022-02-24 20:53:07.580342: step 144100, total loss = 0.56, batch loss = 0.30 (175.3 examples/sec; 0.046 sec/batch; 0h:42m:08s remains)
INFO - root - 2022-02-24 20:53:08.186145: step 144110, total loss = 0.65, batch loss = 0.39 (229.7 examples/sec; 0.035 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 20:53:08.651839: step 144120, total loss = 0.58, batch loss = 0.32 (105.3 examples/sec; 0.076 sec/batch; 1h:10m:05s remains)
INFO - root - 2022-02-24 20:53:09.101691: step 144130, total loss = 0.48, batch loss = 0.22 (105.2 examples/sec; 0.076 sec/batch; 1h:10m:10s remains)
INFO - root - 2022-02-24 20:53:09.660590: step 144140, total loss = 0.58, batch loss = 0.33 (247.3 examples/sec; 0.032 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 20:53:10.028791: step 144150, total loss = 0.55, batch loss = 0.29 (314.1 examples/sec; 0.025 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:53:10.338131: step 144160, total loss = 0.61, batch loss = 0.35 (276.0 examples/sec; 0.029 sec/batch; 0h:26m:44s remains)
INFO - root - 2022-02-24 20:53:10.759081: step 144170, total loss = 0.53, batch loss = 0.28 (118.0 examples/sec; 0.068 sec/batch; 1h:02m:29s remains)
INFO - root - 2022-02-24 20:53:11.190136: step 144180, total loss = 0.57, batch loss = 0.31 (219.7 examples/sec; 0.036 sec/batch; 0h:33m:34s remains)
INFO - root - 2022-02-24 20:53:11.961003: step 144190, total loss = 0.60, batch loss = 0.35 (137.9 examples/sec; 0.058 sec/batch; 0h:53m:29s remains)
INFO - root - 2022-02-24 20:53:12.334577: step 144200, total loss = 0.60, batch loss = 0.34 (359.1 examples/sec; 0.022 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 20:53:12.864413: step 144210, total loss = 0.61, batch loss = 0.35 (158.4 examples/sec; 0.051 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:53:13.278651: step 144220, total loss = 0.66, batch loss = 0.41 (255.2 examples/sec; 0.031 sec/batch; 0h:28m:52s remains)
INFO - root - 2022-02-24 20:53:13.671025: step 144230, total loss = 0.49, batch loss = 0.23 (158.7 examples/sec; 0.050 sec/batch; 0h:46m:25s remains)
INFO - root - 2022-02-24 20:53:13.991922: step 144240, total loss = 0.50, batch loss = 0.24 (354.9 examples/sec; 0.023 sec/batch; 0h:20m:45s remains)
INFO - root - 2022-02-24 20:53:14.388826: step 144250, total loss = 0.55, batch loss = 0.29 (151.5 examples/sec; 0.053 sec/batch; 0h:48m:38s remains)
INFO - root - 2022-02-24 20:53:14.840154: step 144260, total loss = 0.47, batch loss = 0.21 (176.8 examples/sec; 0.045 sec/batch; 0h:41m:39s remains)
INFO - root - 2022-02-24 20:53:15.269958: step 144270, total loss = 0.58, batch loss = 0.32 (164.4 examples/sec; 0.049 sec/batch; 0h:44m:47s remains)
INFO - root - 2022-02-24 20:53:15.697242: step 144280, total loss = 0.53, batch loss = 0.27 (282.9 examples/sec; 0.028 sec/batch; 0h:26m:01s remains)
INFO - root - 2022-02-24 20:53:16.109122: step 144290, total loss = 0.64, batch loss = 0.39 (119.2 examples/sec; 0.067 sec/batch; 1h:01m:46s remains)
INFO - root - 2022-02-24 20:53:16.426095: step 144300, total loss = 0.56, batch loss = 0.30 (292.6 examples/sec; 0.027 sec/batch; 0h:25m:09s remains)
INFO - root - 2022-02-24 20:53:16.875608: step 144310, total loss = 0.61, batch loss = 0.35 (207.9 examples/sec; 0.038 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 20:53:17.252687: step 144320, total loss = 0.45, batch loss = 0.19 (258.4 examples/sec; 0.031 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 20:53:17.673440: step 144330, total loss = 0.51, batch loss = 0.25 (277.4 examples/sec; 0.029 sec/batch; 0h:26m:31s remains)
INFO - root - 2022-02-24 20:53:18.050096: step 144340, total loss = 0.56, batch loss = 0.30 (337.8 examples/sec; 0.024 sec/batch; 0h:21m:46s remains)
INFO - root - 2022-02-24 20:53:18.382126: step 144350, total loss = 0.49, batch loss = 0.23 (313.7 examples/sec; 0.026 sec/batch; 0h:23m:26s remains)
INFO - root - 2022-02-24 20:53:18.741110: step 144360, total loss = 0.54, batch loss = 0.28 (309.1 examples/sec; 0.026 sec/batch; 0h:23m:47s remains)
INFO - root - 2022-02-24 20:53:19.151082: step 144370, total loss = 0.60, batch loss = 0.34 (332.4 examples/sec; 0.024 sec/batch; 0h:22m:06s remains)
INFO - root - 2022-02-24 20:53:19.631304: step 144380, total loss = 0.49, batch loss = 0.24 (151.6 examples/sec; 0.053 sec/batch; 0h:48m:29s remains)
INFO - root - 2022-02-24 20:53:19.904524: step 144390, total loss = 0.67, batch loss = 0.41 (241.2 examples/sec; 0.033 sec/batch; 0h:30m:27s remains)
INFO - root - 2022-02-24 20:53:20.245228: step 144400, total loss = 0.55, batch loss = 0.29 (236.2 examples/sec; 0.034 sec/batch; 0h:31m:06s remains)
INFO - root - 2022-02-24 20:53:20.616474: step 144410, total loss = 0.54, batch loss = 0.28 (313.9 examples/sec; 0.025 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:53:20.951872: step 144420, total loss = 0.59, batch loss = 0.33 (189.3 examples/sec; 0.042 sec/batch; 0h:38m:48s remains)
INFO - root - 2022-02-24 20:53:21.412614: step 144430, total loss = 0.49, batch loss = 0.23 (174.8 examples/sec; 0.046 sec/batch; 0h:42m:00s remains)
INFO - root - 2022-02-24 20:53:21.908331: step 144440, total loss = 0.58, batch loss = 0.32 (77.4 examples/sec; 0.103 sec/batch; 1h:34m:53s remains)
INFO - root - 2022-02-24 20:53:22.267538: step 144450, total loss = 0.53, batch loss = 0.27 (194.6 examples/sec; 0.041 sec/batch; 0h:37m:43s remains)
INFO - root - 2022-02-24 20:53:22.659496: step 144460, total loss = 0.57, batch loss = 0.31 (250.1 examples/sec; 0.032 sec/batch; 0h:29m:20s remains)
INFO - root - 2022-02-24 20:53:23.022699: step 144470, total loss = 0.58, batch loss = 0.32 (188.0 examples/sec; 0.043 sec/batch; 0h:39m:01s remains)
INFO - root - 2022-02-24 20:53:23.370832: step 144480, total loss = 0.49, batch loss = 0.23 (144.0 examples/sec; 0.056 sec/batch; 0h:50m:55s remains)
INFO - root - 2022-02-24 20:53:23.779277: step 144490, total loss = 0.72, batch loss = 0.46 (306.8 examples/sec; 0.026 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 20:53:24.184259: step 144500, total loss = 0.59, batch loss = 0.33 (352.6 examples/sec; 0.023 sec/batch; 0h:20m:47s remains)
INFO - root - 2022-02-24 20:53:24.556062: step 144510, total loss = 0.57, batch loss = 0.32 (362.4 examples/sec; 0.022 sec/batch; 0h:20m:14s remains)
INFO - root - 2022-02-24 20:53:24.826760: step 144520, total loss = 0.53, batch loss = 0.27 (219.4 examples/sec; 0.036 sec/batch; 0h:33m:25s remains)
INFO - root - 2022-02-24 20:53:25.164297: step 144530, total loss = 0.56, batch loss = 0.30 (310.1 examples/sec; 0.026 sec/batch; 0h:23m:38s remains)
INFO - root - 2022-02-24 20:53:25.547788: step 144540, total loss = 0.60, batch loss = 0.34 (349.1 examples/sec; 0.023 sec/batch; 0h:20m:59s remains)
INFO - root - 2022-02-24 20:53:26.041295: step 144550, total loss = 0.53, batch loss = 0.27 (266.1 examples/sec; 0.030 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 20:53:26.353961: step 144560, total loss = 0.69, batch loss = 0.43 (205.6 examples/sec; 0.039 sec/batch; 0h:35m:37s remains)
INFO - root - 2022-02-24 20:53:26.703965: step 144570, total loss = 0.59, batch loss = 0.33 (206.1 examples/sec; 0.039 sec/batch; 0h:35m:32s remains)
INFO - root - 2022-02-24 20:53:27.042656: step 144580, total loss = 0.46, batch loss = 0.20 (356.6 examples/sec; 0.022 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 20:53:27.458474: step 144590, total loss = 0.53, batch loss = 0.27 (174.9 examples/sec; 0.046 sec/batch; 0h:41m:51s remains)
INFO - root - 2022-02-24 20:53:27.851532: step 144600, total loss = 0.60, batch loss = 0.34 (338.9 examples/sec; 0.024 sec/batch; 0h:21m:35s remains)
INFO - root - 2022-02-24 20:53:28.272315: step 144610, total loss = 0.48, batch loss = 0.22 (329.8 examples/sec; 0.024 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 20:53:28.603643: step 144620, total loss = 0.56, batch loss = 0.30 (196.2 examples/sec; 0.041 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 20:53:28.953206: step 144630, total loss = 0.48, batch loss = 0.22 (217.4 examples/sec; 0.037 sec/batch; 0h:33m:39s remains)
INFO - root - 2022-02-24 20:53:29.295467: step 144640, total loss = 0.56, batch loss = 0.31 (320.1 examples/sec; 0.025 sec/batch; 0h:22m:51s remains)
INFO - root - 2022-02-24 20:53:29.675173: step 144650, total loss = 0.53, batch loss = 0.27 (191.7 examples/sec; 0.042 sec/batch; 0h:38m:08s remains)
INFO - root - 2022-02-24 20:53:30.062335: step 144660, total loss = 0.56, batch loss = 0.30 (216.1 examples/sec; 0.037 sec/batch; 0h:33m:50s remains)
INFO - root - 2022-02-24 20:53:30.431207: step 144670, total loss = 0.49, batch loss = 0.23 (252.4 examples/sec; 0.032 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 20:53:31.092612: step 144680, total loss = 0.55, batch loss = 0.29 (88.9 examples/sec; 0.090 sec/batch; 1h:22m:14s remains)
INFO - root - 2022-02-24 20:53:31.599210: step 144690, total loss = 0.48, batch loss = 0.23 (156.7 examples/sec; 0.051 sec/batch; 0h:46m:37s remains)
INFO - root - 2022-02-24 20:53:32.204407: step 144700, total loss = 0.49, batch loss = 0.23 (113.4 examples/sec; 0.071 sec/batch; 1h:04m:26s remains)
INFO - root - 2022-02-24 20:53:33.148066: step 144710, total loss = 0.53, batch loss = 0.27 (271.5 examples/sec; 0.029 sec/batch; 0h:26m:54s remains)
INFO - root - 2022-02-24 20:53:33.574247: step 144720, total loss = 0.55, batch loss = 0.29 (233.5 examples/sec; 0.034 sec/batch; 0h:31m:17s remains)
INFO - root - 2022-02-24 20:53:33.969944: step 144730, total loss = 0.52, batch loss = 0.26 (214.1 examples/sec; 0.037 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 20:53:34.225416: step 144740, total loss = 0.55, batch loss = 0.30 (345.5 examples/sec; 0.023 sec/batch; 0h:21m:08s remains)
INFO - root - 2022-02-24 20:53:34.511947: step 144750, total loss = 0.54, batch loss = 0.28 (270.8 examples/sec; 0.030 sec/batch; 0h:26m:57s remains)
INFO - root - 2022-02-24 20:53:34.914885: step 144760, total loss = 0.54, batch loss = 0.28 (179.8 examples/sec; 0.044 sec/batch; 0h:40m:35s remains)
INFO - root - 2022-02-24 20:53:35.228538: step 144770, total loss = 0.54, batch loss = 0.28 (320.6 examples/sec; 0.025 sec/batch; 0h:22m:45s remains)
INFO - root - 2022-02-24 20:53:35.652890: step 144780, total loss = 0.69, batch loss = 0.43 (191.6 examples/sec; 0.042 sec/batch; 0h:38m:04s remains)
INFO - root - 2022-02-24 20:53:36.056813: step 144790, total loss = 0.58, batch loss = 0.32 (349.3 examples/sec; 0.023 sec/batch; 0h:20m:52s remains)
INFO - root - 2022-02-24 20:53:36.356681: step 144800, total loss = 0.49, batch loss = 0.24 (226.4 examples/sec; 0.035 sec/batch; 0h:32m:13s remains)
INFO - root - 2022-02-24 20:53:36.836443: step 144810, total loss = 0.50, batch loss = 0.24 (84.0 examples/sec; 0.095 sec/batch; 1h:26m:50s remains)
INFO - root - 2022-02-24 20:53:37.217763: step 144820, total loss = 0.58, batch loss = 0.33 (161.3 examples/sec; 0.050 sec/batch; 0h:45m:11s remains)
INFO - root - 2022-02-24 20:53:37.697685: step 144830, total loss = 0.54, batch loss = 0.28 (139.2 examples/sec; 0.057 sec/batch; 0h:52m:21s remains)
INFO - root - 2022-02-24 20:53:38.158243: step 144840, total loss = 0.56, batch loss = 0.30 (261.5 examples/sec; 0.031 sec/batch; 0h:27m:52s remains)
INFO - root - 2022-02-24 20:53:38.518047: step 144850, total loss = 0.49, batch loss = 0.23 (193.4 examples/sec; 0.041 sec/batch; 0h:37m:41s remains)
INFO - root - 2022-02-24 20:53:38.844810: step 144860, total loss = 0.55, batch loss = 0.29 (348.7 examples/sec; 0.023 sec/batch; 0h:20m:53s remains)
INFO - root - 2022-02-24 20:53:39.166390: step 144870, total loss = 0.55, batch loss = 0.29 (268.8 examples/sec; 0.030 sec/batch; 0h:27m:05s remains)
INFO - root - 2022-02-24 20:53:39.607532: step 144880, total loss = 0.53, batch loss = 0.27 (221.1 examples/sec; 0.036 sec/batch; 0h:32m:56s remains)
INFO - root - 2022-02-24 20:53:40.135497: step 144890, total loss = 0.61, batch loss = 0.35 (104.1 examples/sec; 0.077 sec/batch; 1h:09m:55s remains)
INFO - root - 2022-02-24 20:53:40.461191: step 144900, total loss = 0.55, batch loss = 0.29 (325.0 examples/sec; 0.025 sec/batch; 0h:22m:23s remains)
INFO - root - 2022-02-24 20:53:40.946525: step 144910, total loss = 0.49, batch loss = 0.23 (165.6 examples/sec; 0.048 sec/batch; 0h:43m:57s remains)
INFO - root - 2022-02-24 20:53:41.292214: step 144920, total loss = 0.47, batch loss = 0.21 (170.9 examples/sec; 0.047 sec/batch; 0h:42m:34s remains)
INFO - root - 2022-02-24 20:53:41.624149: step 144930, total loss = 0.46, batch loss = 0.20 (334.7 examples/sec; 0.024 sec/batch; 0h:21m:44s remains)
INFO - root - 2022-02-24 20:53:42.094797: step 144940, total loss = 0.54, batch loss = 0.28 (241.8 examples/sec; 0.033 sec/batch; 0h:30m:04s remains)
INFO - root - 2022-02-24 20:53:42.551796: step 144950, total loss = 0.58, batch loss = 0.32 (106.1 examples/sec; 0.075 sec/batch; 1h:08m:32s remains)
INFO - root - 2022-02-24 20:53:42.927175: step 144960, total loss = 0.48, batch loss = 0.22 (144.0 examples/sec; 0.056 sec/batch; 0h:50m:30s remains)
INFO - root - 2022-02-24 20:53:43.246823: step 144970, total loss = 0.53, batch loss = 0.28 (297.6 examples/sec; 0.027 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 20:53:43.704570: step 144980, total loss = 0.70, batch loss = 0.45 (214.4 examples/sec; 0.037 sec/batch; 0h:33m:54s remains)
INFO - root - 2022-02-24 20:53:44.147680: step 144990, total loss = 0.51, batch loss = 0.26 (252.5 examples/sec; 0.032 sec/batch; 0h:28m:47s remains)
INFO - root - 2022-02-24 20:53:44.564668: step 145000, total loss = 0.48, batch loss = 0.23 (207.4 examples/sec; 0.039 sec/batch; 0h:35m:02s remains)
INFO - root - 2022-02-24 20:53:44.925726: step 145010, total loss = 0.42, batch loss = 0.16 (245.4 examples/sec; 0.033 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 20:53:45.271841: step 145020, total loss = 0.59, batch loss = 0.33 (201.1 examples/sec; 0.040 sec/batch; 0h:36m:07s remains)
INFO - root - 2022-02-24 20:53:45.574369: step 145030, total loss = 0.59, batch loss = 0.33 (305.9 examples/sec; 0.026 sec/batch; 0h:23m:44s remains)
INFO - root - 2022-02-24 20:53:45.908067: step 145040, total loss = 0.61, batch loss = 0.35 (232.8 examples/sec; 0.034 sec/batch; 0h:31m:11s remains)
INFO - root - 2022-02-24 20:53:46.348990: step 145050, total loss = 0.48, batch loss = 0.23 (121.9 examples/sec; 0.066 sec/batch; 0h:59m:34s remains)
INFO - root - 2022-02-24 20:53:46.746369: step 145060, total loss = 0.59, batch loss = 0.33 (304.2 examples/sec; 0.026 sec/batch; 0h:23m:51s remains)
INFO - root - 2022-02-24 20:53:47.108302: step 145070, total loss = 0.46, batch loss = 0.20 (236.4 examples/sec; 0.034 sec/batch; 0h:30m:41s remains)
INFO - root - 2022-02-24 20:53:47.506300: step 145080, total loss = 0.60, batch loss = 0.34 (170.0 examples/sec; 0.047 sec/batch; 0h:42m:40s remains)
INFO - root - 2022-02-24 20:53:48.386569: step 145090, total loss = 0.53, batch loss = 0.27 (327.4 examples/sec; 0.024 sec/batch; 0h:22m:09s remains)
INFO - root - 2022-02-24 20:53:48.751512: step 145100, total loss = 0.49, batch loss = 0.23 (168.5 examples/sec; 0.047 sec/batch; 0h:43m:03s remains)
INFO - root - 2022-02-24 20:53:49.609424: step 145110, total loss = 0.70, batch loss = 0.44 (303.4 examples/sec; 0.026 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 20:53:49.856814: step 145120, total loss = 0.67, batch loss = 0.41 (336.9 examples/sec; 0.024 sec/batch; 0h:21m:31s remains)
INFO - root - 2022-02-24 20:53:50.080720: step 145130, total loss = 0.54, batch loss = 0.29 (354.9 examples/sec; 0.023 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 20:53:50.306506: step 145140, total loss = 0.68, batch loss = 0.42 (358.3 examples/sec; 0.022 sec/batch; 0h:20m:13s remains)
INFO - root - 2022-02-24 20:53:50.718253: step 145150, total loss = 0.58, batch loss = 0.32 (197.4 examples/sec; 0.041 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:53:51.164709: step 145160, total loss = 0.44, batch loss = 0.18 (216.1 examples/sec; 0.037 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:53:51.607297: step 145170, total loss = 0.56, batch loss = 0.30 (110.7 examples/sec; 0.072 sec/batch; 1h:05m:26s remains)
INFO - root - 2022-02-24 20:53:52.095016: step 145180, total loss = 0.54, batch loss = 0.28 (158.3 examples/sec; 0.051 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 20:53:52.535724: step 145190, total loss = 0.48, batch loss = 0.22 (193.3 examples/sec; 0.041 sec/batch; 0h:37m:27s remains)
INFO - root - 2022-02-24 20:53:53.184051: step 145200, total loss = 0.63, batch loss = 0.37 (313.6 examples/sec; 0.026 sec/batch; 0h:23m:05s remains)
INFO - root - 2022-02-24 20:53:53.608451: step 145210, total loss = 0.47, batch loss = 0.21 (332.4 examples/sec; 0.024 sec/batch; 0h:21m:46s remains)
INFO - root - 2022-02-24 20:53:54.039060: step 145220, total loss = 0.58, batch loss = 0.32 (194.2 examples/sec; 0.041 sec/batch; 0h:37m:15s remains)
INFO - root - 2022-02-24 20:53:54.542717: step 145230, total loss = 0.57, batch loss = 0.32 (129.3 examples/sec; 0.062 sec/batch; 0h:55m:58s remains)
INFO - root - 2022-02-24 20:53:54.875800: step 145240, total loss = 0.65, batch loss = 0.39 (260.9 examples/sec; 0.031 sec/batch; 0h:27m:43s remains)
INFO - root - 2022-02-24 20:53:55.225258: step 145250, total loss = 0.53, batch loss = 0.27 (260.2 examples/sec; 0.031 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 20:53:55.548526: step 145260, total loss = 0.60, batch loss = 0.34 (331.1 examples/sec; 0.024 sec/batch; 0h:21m:50s remains)
INFO - root - 2022-02-24 20:53:55.819979: step 145270, total loss = 0.52, batch loss = 0.26 (273.2 examples/sec; 0.029 sec/batch; 0h:26m:28s remains)
INFO - root - 2022-02-24 20:53:56.319500: step 145280, total loss = 0.67, batch loss = 0.42 (154.1 examples/sec; 0.052 sec/batch; 0h:46m:54s remains)
INFO - root - 2022-02-24 20:53:56.700406: step 145290, total loss = 0.63, batch loss = 0.37 (371.3 examples/sec; 0.022 sec/batch; 0h:19m:28s remains)
INFO - root - 2022-02-24 20:53:57.030429: step 145300, total loss = 0.59, batch loss = 0.33 (133.5 examples/sec; 0.060 sec/batch; 0h:54m:06s remains)
INFO - root - 2022-02-24 20:53:57.454082: step 145310, total loss = 0.61, batch loss = 0.35 (181.4 examples/sec; 0.044 sec/batch; 0h:39m:49s remains)
INFO - root - 2022-02-24 20:53:57.819911: step 145320, total loss = 0.50, batch loss = 0.24 (317.8 examples/sec; 0.025 sec/batch; 0h:22m:43s remains)
INFO - root - 2022-02-24 20:53:58.310912: step 145330, total loss = 0.47, batch loss = 0.21 (301.9 examples/sec; 0.026 sec/batch; 0h:23m:55s remains)
INFO - root - 2022-02-24 20:53:58.727970: step 145340, total loss = 0.55, batch loss = 0.29 (244.3 examples/sec; 0.033 sec/batch; 0h:29m:33s remains)
INFO - root - 2022-02-24 20:53:59.127341: step 145350, total loss = 0.49, batch loss = 0.23 (311.9 examples/sec; 0.026 sec/batch; 0h:23m:08s remains)
INFO - root - 2022-02-24 20:53:59.463826: step 145360, total loss = 0.62, batch loss = 0.36 (264.2 examples/sec; 0.030 sec/batch; 0h:27m:19s remains)
INFO - root - 2022-02-24 20:53:59.767814: step 145370, total loss = 0.51, batch loss = 0.25 (321.0 examples/sec; 0.025 sec/batch; 0h:22m:29s remains)
INFO - root - 2022-02-24 20:54:00.132415: step 145380, total loss = 0.52, batch loss = 0.26 (150.8 examples/sec; 0.053 sec/batch; 0h:47m:50s remains)
INFO - root - 2022-02-24 20:54:00.528267: step 145390, total loss = 0.54, batch loss = 0.28 (294.8 examples/sec; 0.027 sec/batch; 0h:24m:28s remains)
INFO - root - 2022-02-24 20:54:01.006660: step 145400, total loss = 0.54, batch loss = 0.28 (288.4 examples/sec; 0.028 sec/batch; 0h:25m:00s remains)
INFO - root - 2022-02-24 20:54:01.447760: step 145410, total loss = 0.59, batch loss = 0.33 (141.1 examples/sec; 0.057 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:54:01.812474: step 145420, total loss = 0.55, batch loss = 0.29 (354.8 examples/sec; 0.023 sec/batch; 0h:20m:19s remains)
INFO - root - 2022-02-24 20:54:02.071250: step 145430, total loss = 0.55, batch loss = 0.29 (331.3 examples/sec; 0.024 sec/batch; 0h:21m:45s remains)
INFO - root - 2022-02-24 20:54:02.483642: step 145440, total loss = 0.60, batch loss = 0.34 (135.8 examples/sec; 0.059 sec/batch; 0h:53m:04s remains)
INFO - root - 2022-02-24 20:54:02.899205: step 145450, total loss = 0.45, batch loss = 0.19 (162.6 examples/sec; 0.049 sec/batch; 0h:44m:19s remains)
INFO - root - 2022-02-24 20:54:03.212927: step 145460, total loss = 0.53, batch loss = 0.27 (374.7 examples/sec; 0.021 sec/batch; 0h:19m:13s remains)
INFO - root - 2022-02-24 20:54:03.560663: step 145470, total loss = 0.71, batch loss = 0.46 (304.1 examples/sec; 0.026 sec/batch; 0h:23m:41s remains)
INFO - root - 2022-02-24 20:54:03.823062: step 145480, total loss = 0.57, batch loss = 0.31 (337.7 examples/sec; 0.024 sec/batch; 0h:21m:19s remains)
INFO - root - 2022-02-24 20:54:04.264323: step 145490, total loss = 0.57, batch loss = 0.31 (174.0 examples/sec; 0.046 sec/batch; 0h:41m:22s remains)
INFO - root - 2022-02-24 20:54:04.814056: step 145500, total loss = 0.57, batch loss = 0.31 (154.0 examples/sec; 0.052 sec/batch; 0h:46m:44s remains)
INFO - root - 2022-02-24 20:54:05.270021: step 145510, total loss = 0.56, batch loss = 0.30 (219.3 examples/sec; 0.036 sec/batch; 0h:32m:49s remains)
INFO - root - 2022-02-24 20:54:05.638504: step 145520, total loss = 0.45, batch loss = 0.20 (354.9 examples/sec; 0.023 sec/batch; 0h:20m:16s remains)
INFO - root - 2022-02-24 20:54:05.951265: step 145530, total loss = 0.54, batch loss = 0.28 (341.4 examples/sec; 0.023 sec/batch; 0h:21m:04s remains)
INFO - root - 2022-02-24 20:54:06.349791: step 145540, total loss = 0.50, batch loss = 0.24 (196.4 examples/sec; 0.041 sec/batch; 0h:36m:37s remains)
INFO - root - 2022-02-24 20:54:06.717082: step 145550, total loss = 0.54, batch loss = 0.28 (247.9 examples/sec; 0.032 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 20:54:07.166660: step 145560, total loss = 0.61, batch loss = 0.35 (302.9 examples/sec; 0.026 sec/batch; 0h:23m:44s remains)
INFO - root - 2022-02-24 20:54:07.521767: step 145570, total loss = 0.50, batch loss = 0.24 (186.7 examples/sec; 0.043 sec/batch; 0h:38m:31s remains)
INFO - root - 2022-02-24 20:54:07.821835: step 145580, total loss = 0.47, batch loss = 0.21 (310.3 examples/sec; 0.026 sec/batch; 0h:23m:10s remains)
INFO - root - 2022-02-24 20:54:08.170505: step 145590, total loss = 0.62, batch loss = 0.37 (142.1 examples/sec; 0.056 sec/batch; 0h:50m:35s remains)
INFO - root - 2022-02-24 20:54:08.604596: step 145600, total loss = 0.56, batch loss = 0.31 (161.1 examples/sec; 0.050 sec/batch; 0h:44m:36s remains)
INFO - root - 2022-02-24 20:54:08.954667: step 145610, total loss = 0.53, batch loss = 0.27 (250.5 examples/sec; 0.032 sec/batch; 0h:28m:41s remains)
INFO - root - 2022-02-24 20:54:09.470050: step 145620, total loss = 0.54, batch loss = 0.28 (85.6 examples/sec; 0.093 sec/batch; 1h:23m:55s remains)
INFO - root - 2022-02-24 20:54:09.826868: step 145630, total loss = 0.52, batch loss = 0.26 (237.5 examples/sec; 0.034 sec/batch; 0h:30m:14s remains)
INFO - root - 2022-02-24 20:54:10.217415: step 145640, total loss = 0.51, batch loss = 0.25 (229.8 examples/sec; 0.035 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:54:10.531432: step 145650, total loss = 0.62, batch loss = 0.36 (173.3 examples/sec; 0.046 sec/batch; 0h:41m:25s remains)
INFO - root - 2022-02-24 20:54:10.910524: step 145660, total loss = 0.56, batch loss = 0.31 (83.8 examples/sec; 0.095 sec/batch; 1h:25m:37s remains)
INFO - root - 2022-02-24 20:54:11.303547: step 145670, total loss = 0.60, batch loss = 0.34 (277.7 examples/sec; 0.029 sec/batch; 0h:25m:50s remains)
INFO - root - 2022-02-24 20:54:11.706518: step 145680, total loss = 0.57, batch loss = 0.32 (176.9 examples/sec; 0.045 sec/batch; 0h:40m:33s remains)
INFO - root - 2022-02-24 20:54:12.029348: step 145690, total loss = 0.56, batch loss = 0.30 (224.7 examples/sec; 0.036 sec/batch; 0h:31m:55s remains)
INFO - root - 2022-02-24 20:54:12.444874: step 145700, total loss = 0.57, batch loss = 0.31 (337.2 examples/sec; 0.024 sec/batch; 0h:21m:16s remains)
INFO - root - 2022-02-24 20:54:12.926160: step 145710, total loss = 0.48, batch loss = 0.22 (120.4 examples/sec; 0.066 sec/batch; 0h:59m:33s remains)
INFO - root - 2022-02-24 20:54:13.270930: step 145720, total loss = 0.56, batch loss = 0.31 (276.0 examples/sec; 0.029 sec/batch; 0h:25m:59s remains)
INFO - root - 2022-02-24 20:54:13.728045: step 145730, total loss = 0.53, batch loss = 0.27 (88.5 examples/sec; 0.090 sec/batch; 1h:21m:00s remains)
INFO - root - 2022-02-24 20:54:14.108128: step 145740, total loss = 0.61, batch loss = 0.35 (303.4 examples/sec; 0.026 sec/batch; 0h:23m:37s remains)
INFO - root - 2022-02-24 20:54:14.503134: step 145750, total loss = 0.47, batch loss = 0.22 (89.5 examples/sec; 0.089 sec/batch; 1h:20m:05s remains)
INFO - root - 2022-02-24 20:54:14.801927: step 145760, total loss = 0.55, batch loss = 0.30 (266.4 examples/sec; 0.030 sec/batch; 0h:26m:53s remains)
INFO - root - 2022-02-24 20:54:15.231457: step 145770, total loss = 0.61, batch loss = 0.35 (304.8 examples/sec; 0.026 sec/batch; 0h:23m:30s remains)
INFO - root - 2022-02-24 20:54:15.708909: step 145780, total loss = 0.54, batch loss = 0.29 (153.9 examples/sec; 0.052 sec/batch; 0h:46m:33s remains)
INFO - root - 2022-02-24 20:54:16.058147: step 145790, total loss = 0.50, batch loss = 0.24 (232.5 examples/sec; 0.034 sec/batch; 0h:30m:48s remains)
INFO - root - 2022-02-24 20:54:16.420044: step 145800, total loss = 0.45, batch loss = 0.19 (327.4 examples/sec; 0.024 sec/batch; 0h:21m:52s remains)
INFO - root - 2022-02-24 20:54:16.806149: step 145810, total loss = 0.75, batch loss = 0.49 (306.1 examples/sec; 0.026 sec/batch; 0h:23m:23s remains)
INFO - root - 2022-02-24 20:54:17.204705: step 145820, total loss = 0.61, batch loss = 0.35 (291.5 examples/sec; 0.027 sec/batch; 0h:24m:33s remains)
INFO - root - 2022-02-24 20:54:17.580044: step 145830, total loss = 0.53, batch loss = 0.27 (163.8 examples/sec; 0.049 sec/batch; 0h:43m:40s remains)
INFO - root - 2022-02-24 20:54:17.931030: step 145840, total loss = 0.69, batch loss = 0.43 (206.7 examples/sec; 0.039 sec/batch; 0h:34m:36s remains)
INFO - root - 2022-02-24 20:54:18.222890: step 145850, total loss = 0.52, batch loss = 0.27 (171.8 examples/sec; 0.047 sec/batch; 0h:41m:38s remains)
INFO - root - 2022-02-24 20:54:18.600467: step 145860, total loss = 0.54, batch loss = 0.28 (298.0 examples/sec; 0.027 sec/batch; 0h:24m:00s remains)
INFO - root - 2022-02-24 20:54:18.931724: step 145870, total loss = 0.58, batch loss = 0.32 (325.3 examples/sec; 0.025 sec/batch; 0h:21m:58s remains)
INFO - root - 2022-02-24 20:54:19.349248: step 145880, total loss = 0.58, batch loss = 0.32 (258.4 examples/sec; 0.031 sec/batch; 0h:27m:39s remains)
INFO - root - 2022-02-24 20:54:19.881065: step 145890, total loss = 0.58, batch loss = 0.32 (88.8 examples/sec; 0.090 sec/batch; 1h:20m:28s remains)
INFO - root - 2022-02-24 20:54:20.193985: step 145900, total loss = 0.47, batch loss = 0.21 (172.6 examples/sec; 0.046 sec/batch; 0h:41m:24s remains)
INFO - root - 2022-02-24 20:54:20.759544: step 145910, total loss = 0.52, batch loss = 0.26 (119.2 examples/sec; 0.067 sec/batch; 0h:59m:57s remains)
INFO - root - 2022-02-24 20:54:21.214523: step 145920, total loss = 0.44, batch loss = 0.18 (288.0 examples/sec; 0.028 sec/batch; 0h:24m:48s remains)
INFO - root - 2022-02-24 20:54:21.735238: step 145930, total loss = 0.50, batch loss = 0.25 (235.6 examples/sec; 0.034 sec/batch; 0h:30m:19s remains)
INFO - root - 2022-02-24 20:54:22.312398: step 145940, total loss = 0.48, batch loss = 0.22 (86.6 examples/sec; 0.092 sec/batch; 1h:22m:29s remains)
INFO - root - 2022-02-24 20:54:22.918482: step 145950, total loss = 0.62, batch loss = 0.36 (242.8 examples/sec; 0.033 sec/batch; 0h:29m:24s remains)
INFO - root - 2022-02-24 20:54:23.399812: step 145960, total loss = 0.63, batch loss = 0.37 (94.7 examples/sec; 0.084 sec/batch; 1h:15m:21s remains)
INFO - root - 2022-02-24 20:54:24.358584: step 145970, total loss = 0.73, batch loss = 0.48 (301.0 examples/sec; 0.027 sec/batch; 0h:23m:42s remains)
INFO - root - 2022-02-24 20:54:24.789625: step 145980, total loss = 0.61, batch loss = 0.35 (164.4 examples/sec; 0.049 sec/batch; 0h:43m:24s remains)
INFO - root - 2022-02-24 20:54:25.272606: step 145990, total loss = 0.62, batch loss = 0.36 (73.3 examples/sec; 0.109 sec/batch; 1h:37m:22s remains)
INFO - root - 2022-02-24 20:54:25.776360: step 146000, total loss = 0.55, batch loss = 0.29 (120.6 examples/sec; 0.066 sec/batch; 0h:59m:08s remains)
INFO - root - 2022-02-24 20:54:26.303695: step 146010, total loss = 0.52, batch loss = 0.27 (143.0 examples/sec; 0.056 sec/batch; 0h:49m:52s remains)
INFO - root - 2022-02-24 20:54:26.766718: step 146020, total loss = 0.57, batch loss = 0.31 (340.1 examples/sec; 0.024 sec/batch; 0h:20m:57s remains)
INFO - root - 2022-02-24 20:54:27.140300: step 146030, total loss = 0.61, batch loss = 0.35 (322.4 examples/sec; 0.025 sec/batch; 0h:22m:06s remains)
INFO - root - 2022-02-24 20:54:27.515520: step 146040, total loss = 0.54, batch loss = 0.28 (239.4 examples/sec; 0.033 sec/batch; 0h:29m:46s remains)
INFO - root - 2022-02-24 20:54:27.865874: step 146050, total loss = 0.54, batch loss = 0.28 (328.9 examples/sec; 0.024 sec/batch; 0h:21m:39s remains)
INFO - root - 2022-02-24 20:54:28.340377: step 146060, total loss = 0.54, batch loss = 0.28 (139.4 examples/sec; 0.057 sec/batch; 0h:51m:06s remains)
INFO - root - 2022-02-24 20:54:28.978449: step 146070, total loss = 0.50, batch loss = 0.25 (196.2 examples/sec; 0.041 sec/batch; 0h:36m:18s remains)
INFO - root - 2022-02-24 20:54:29.292015: step 146080, total loss = 0.50, batch loss = 0.25 (336.4 examples/sec; 0.024 sec/batch; 0h:21m:10s remains)
INFO - root - 2022-02-24 20:54:29.631380: step 146090, total loss = 0.52, batch loss = 0.26 (132.3 examples/sec; 0.060 sec/batch; 0h:53m:49s remains)
INFO - root - 2022-02-24 20:54:30.057268: step 146100, total loss = 0.48, batch loss = 0.23 (215.1 examples/sec; 0.037 sec/batch; 0h:33m:05s remains)
INFO - root - 2022-02-24 20:54:30.491364: step 146110, total loss = 0.45, batch loss = 0.20 (175.6 examples/sec; 0.046 sec/batch; 0h:40m:32s remains)
INFO - root - 2022-02-24 20:54:30.955034: step 146120, total loss = 0.60, batch loss = 0.34 (219.0 examples/sec; 0.037 sec/batch; 0h:32m:30s remains)
INFO - root - 2022-02-24 20:54:31.233573: step 146130, total loss = 0.53, batch loss = 0.27 (287.5 examples/sec; 0.028 sec/batch; 0h:24m:45s remains)
INFO - root - 2022-02-24 20:54:31.581692: step 146140, total loss = 0.55, batch loss = 0.29 (323.1 examples/sec; 0.025 sec/batch; 0h:22m:01s remains)
INFO - root - 2022-02-24 20:54:31.889322: step 146150, total loss = 0.61, batch loss = 0.35 (229.1 examples/sec; 0.035 sec/batch; 0h:31m:02s remains)
INFO - root - 2022-02-24 20:54:32.248285: step 146160, total loss = 0.55, batch loss = 0.30 (177.7 examples/sec; 0.045 sec/batch; 0h:40m:01s remains)
INFO - root - 2022-02-24 20:54:32.747646: step 146170, total loss = 0.63, batch loss = 0.37 (118.4 examples/sec; 0.068 sec/batch; 1h:00m:04s remains)
INFO - root - 2022-02-24 20:54:33.234946: step 146180, total loss = 0.54, batch loss = 0.28 (237.4 examples/sec; 0.034 sec/batch; 0h:29m:56s remains)
INFO - root - 2022-02-24 20:54:33.509578: step 146190, total loss = 0.50, batch loss = 0.24 (174.2 examples/sec; 0.046 sec/batch; 0h:40m:47s remains)
INFO - root - 2022-02-24 20:54:33.920134: step 146200, total loss = 0.45, batch loss = 0.19 (155.8 examples/sec; 0.051 sec/batch; 0h:45m:37s remains)
INFO - root - 2022-02-24 20:54:34.339769: step 146210, total loss = 0.52, batch loss = 0.26 (303.1 examples/sec; 0.026 sec/batch; 0h:23m:26s remains)
INFO - root - 2022-02-24 20:54:34.710308: step 146220, total loss = 0.54, batch loss = 0.28 (86.9 examples/sec; 0.092 sec/batch; 1h:21m:46s remains)
INFO - root - 2022-02-24 20:54:35.094985: step 146230, total loss = 0.55, batch loss = 0.29 (94.2 examples/sec; 0.085 sec/batch; 1h:15m:25s remains)
INFO - root - 2022-02-24 20:54:35.442764: step 146240, total loss = 0.59, batch loss = 0.33 (258.4 examples/sec; 0.031 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:54:35.716458: step 146250, total loss = 0.55, batch loss = 0.29 (332.9 examples/sec; 0.024 sec/batch; 0h:21m:19s remains)
INFO - root - 2022-02-24 20:54:35.958872: step 146260, total loss = 0.49, batch loss = 0.24 (326.1 examples/sec; 0.025 sec/batch; 0h:21m:46s remains)
INFO - root - 2022-02-24 20:54:36.356827: step 146270, total loss = 0.54, batch loss = 0.28 (100.3 examples/sec; 0.080 sec/batch; 1h:10m:44s remains)
INFO - root - 2022-02-24 20:54:36.754057: step 146280, total loss = 0.56, batch loss = 0.30 (246.9 examples/sec; 0.032 sec/batch; 0h:28m:44s remains)
INFO - root - 2022-02-24 20:54:37.141896: step 146290, total loss = 0.51, batch loss = 0.25 (302.2 examples/sec; 0.026 sec/batch; 0h:23m:28s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-146299 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-146299 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:54:37.831623: step 146300, total loss = 0.51, batch loss = 0.25 (333.3 examples/sec; 0.024 sec/batch; 0h:21m:16s remains)
INFO - root - 2022-02-24 20:54:38.202808: step 146310, total loss = 0.53, batch loss = 0.27 (355.0 examples/sec; 0.023 sec/batch; 0h:19m:58s remains)
INFO - root - 2022-02-24 20:54:38.624977: step 146320, total loss = 0.53, batch loss = 0.27 (201.7 examples/sec; 0.040 sec/batch; 0h:35m:09s remains)
INFO - root - 2022-02-24 20:54:39.019541: step 146330, total loss = 0.46, batch loss = 0.20 (223.7 examples/sec; 0.036 sec/batch; 0h:31m:41s remains)
INFO - root - 2022-02-24 20:54:39.371625: step 146340, total loss = 0.58, batch loss = 0.32 (186.2 examples/sec; 0.043 sec/batch; 0h:38m:03s remains)
INFO - root - 2022-02-24 20:54:39.728231: step 146350, total loss = 0.59, batch loss = 0.33 (141.4 examples/sec; 0.057 sec/batch; 0h:50m:07s remains)
INFO - root - 2022-02-24 20:54:40.165538: step 146360, total loss = 0.50, batch loss = 0.25 (190.0 examples/sec; 0.042 sec/batch; 0h:37m:18s remains)
INFO - root - 2022-02-24 20:54:40.628970: step 146370, total loss = 0.59, batch loss = 0.33 (116.1 examples/sec; 0.069 sec/batch; 1h:01m:00s remains)
INFO - root - 2022-02-24 20:54:40.945653: step 146380, total loss = 0.53, batch loss = 0.28 (206.2 examples/sec; 0.039 sec/batch; 0h:34m:20s remains)
INFO - root - 2022-02-24 20:54:41.302613: step 146390, total loss = 0.51, batch loss = 0.26 (204.8 examples/sec; 0.039 sec/batch; 0h:34m:35s remains)
INFO - root - 2022-02-24 20:54:41.665828: step 146400, total loss = 0.53, batch loss = 0.27 (137.5 examples/sec; 0.058 sec/batch; 0h:51m:30s remains)
INFO - root - 2022-02-24 20:54:42.144675: step 146410, total loss = 0.45, batch loss = 0.20 (254.1 examples/sec; 0.031 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 20:54:42.486491: step 146420, total loss = 0.50, batch loss = 0.24 (346.4 examples/sec; 0.023 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 20:54:42.978217: step 146430, total loss = 0.57, batch loss = 0.31 (256.1 examples/sec; 0.031 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 20:54:43.305401: step 146440, total loss = 0.51, batch loss = 0.25 (224.1 examples/sec; 0.036 sec/batch; 0h:31m:34s remains)
INFO - root - 2022-02-24 20:54:43.578416: step 146450, total loss = 0.48, batch loss = 0.22 (288.4 examples/sec; 0.028 sec/batch; 0h:24m:31s remains)
INFO - root - 2022-02-24 20:54:43.966148: step 146460, total loss = 0.58, batch loss = 0.32 (209.6 examples/sec; 0.038 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 20:54:44.443049: step 146470, total loss = 0.58, batch loss = 0.32 (181.0 examples/sec; 0.044 sec/batch; 0h:39m:03s remains)
INFO - root - 2022-02-24 20:54:44.923765: step 146480, total loss = 0.54, batch loss = 0.28 (138.4 examples/sec; 0.058 sec/batch; 0h:51m:04s remains)
INFO - root - 2022-02-24 20:54:45.239582: step 146490, total loss = 0.63, batch loss = 0.37 (309.6 examples/sec; 0.026 sec/batch; 0h:22m:49s remains)
INFO - root - 2022-02-24 20:54:45.545906: step 146500, total loss = 0.46, batch loss = 0.20 (236.6 examples/sec; 0.034 sec/batch; 0h:29m:52s remains)
INFO - root - 2022-02-24 20:54:46.014413: step 146510, total loss = 0.52, batch loss = 0.26 (120.0 examples/sec; 0.067 sec/batch; 0h:58m:51s remains)
INFO - root - 2022-02-24 20:54:46.356317: step 146520, total loss = 0.67, batch loss = 0.41 (98.4 examples/sec; 0.081 sec/batch; 1h:11m:48s remains)
INFO - root - 2022-02-24 20:54:46.776766: step 146530, total loss = 0.58, batch loss = 0.32 (163.8 examples/sec; 0.049 sec/batch; 0h:43m:07s remains)
INFO - root - 2022-02-24 20:54:47.139572: step 146540, total loss = 0.58, batch loss = 0.32 (335.3 examples/sec; 0.024 sec/batch; 0h:21m:03s remains)
INFO - root - 2022-02-24 20:54:47.470786: step 146550, total loss = 0.55, batch loss = 0.30 (310.5 examples/sec; 0.026 sec/batch; 0h:22m:44s remains)
INFO - root - 2022-02-24 20:54:47.754393: step 146560, total loss = 0.58, batch loss = 0.32 (335.2 examples/sec; 0.024 sec/batch; 0h:21m:03s remains)
INFO - root - 2022-02-24 20:54:48.138792: step 146570, total loss = 0.51, batch loss = 0.25 (141.4 examples/sec; 0.057 sec/batch; 0h:49m:53s remains)
INFO - root - 2022-02-24 20:54:48.574066: step 146580, total loss = 0.58, batch loss = 0.33 (362.9 examples/sec; 0.022 sec/batch; 0h:19m:26s remains)
INFO - root - 2022-02-24 20:54:49.032122: step 146590, total loss = 0.55, batch loss = 0.29 (96.5 examples/sec; 0.083 sec/batch; 1h:13m:06s remains)
INFO - root - 2022-02-24 20:54:49.458720: step 146600, total loss = 0.50, batch loss = 0.24 (161.1 examples/sec; 0.050 sec/batch; 0h:43m:46s remains)
INFO - root - 2022-02-24 20:54:49.838885: step 146610, total loss = 0.55, batch loss = 0.29 (295.5 examples/sec; 0.027 sec/batch; 0h:23m:51s remains)
INFO - root - 2022-02-24 20:54:50.118643: step 146620, total loss = 0.50, batch loss = 0.24 (300.5 examples/sec; 0.027 sec/batch; 0h:23m:27s remains)
INFO - root - 2022-02-24 20:54:50.496484: step 146630, total loss = 0.69, batch loss = 0.43 (190.5 examples/sec; 0.042 sec/batch; 0h:37m:00s remains)
INFO - root - 2022-02-24 20:54:50.894965: step 146640, total loss = 0.52, batch loss = 0.26 (129.9 examples/sec; 0.062 sec/batch; 0h:54m:14s remains)
INFO - root - 2022-02-24 20:54:51.366064: step 146650, total loss = 0.60, batch loss = 0.34 (106.1 examples/sec; 0.075 sec/batch; 1h:06m:25s remains)
INFO - root - 2022-02-24 20:54:51.785768: step 146660, total loss = 0.51, batch loss = 0.25 (261.7 examples/sec; 0.031 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 20:54:52.208615: step 146670, total loss = 0.46, batch loss = 0.20 (191.3 examples/sec; 0.042 sec/batch; 0h:36m:49s remains)
INFO - root - 2022-02-24 20:54:52.624264: step 146680, total loss = 0.51, batch loss = 0.26 (346.5 examples/sec; 0.023 sec/batch; 0h:20m:19s remains)
INFO - root - 2022-02-24 20:54:52.986501: step 146690, total loss = 0.47, batch loss = 0.21 (242.4 examples/sec; 0.033 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 20:54:53.458884: step 146700, total loss = 0.55, batch loss = 0.29 (92.4 examples/sec; 0.087 sec/batch; 1h:16m:10s remains)
INFO - root - 2022-02-24 20:54:53.918026: step 146710, total loss = 0.54, batch loss = 0.29 (162.2 examples/sec; 0.049 sec/batch; 0h:43m:23s remains)
INFO - root - 2022-02-24 20:54:54.301297: step 146720, total loss = 0.66, batch loss = 0.40 (187.8 examples/sec; 0.043 sec/batch; 0h:37m:28s remains)
INFO - root - 2022-02-24 20:54:54.613910: step 146730, total loss = 0.61, batch loss = 0.35 (234.9 examples/sec; 0.034 sec/batch; 0h:29m:57s remains)
INFO - root - 2022-02-24 20:54:55.016337: step 146740, total loss = 0.66, batch loss = 0.40 (181.8 examples/sec; 0.044 sec/batch; 0h:38m:41s remains)
INFO - root - 2022-02-24 20:54:55.462769: step 146750, total loss = 0.44, batch loss = 0.18 (139.7 examples/sec; 0.057 sec/batch; 0h:50m:21s remains)
INFO - root - 2022-02-24 20:54:55.925261: step 146760, total loss = 0.55, batch loss = 0.29 (202.1 examples/sec; 0.040 sec/batch; 0h:34m:47s remains)
INFO - root - 2022-02-24 20:54:56.434678: step 146770, total loss = 0.53, batch loss = 0.28 (119.4 examples/sec; 0.067 sec/batch; 0h:58m:52s remains)
INFO - root - 2022-02-24 20:54:56.774727: step 146780, total loss = 0.54, batch loss = 0.28 (251.9 examples/sec; 0.032 sec/batch; 0h:27m:54s remains)
INFO - root - 2022-02-24 20:54:57.187666: step 146790, total loss = 0.47, batch loss = 0.21 (182.5 examples/sec; 0.044 sec/batch; 0h:38m:30s remains)
INFO - root - 2022-02-24 20:54:57.767674: step 146800, total loss = 0.61, batch loss = 0.35 (139.4 examples/sec; 0.057 sec/batch; 0h:50m:24s remains)
INFO - root - 2022-02-24 20:54:58.329348: step 146810, total loss = 0.54, batch loss = 0.28 (187.2 examples/sec; 0.043 sec/batch; 0h:37m:32s remains)
INFO - root - 2022-02-24 20:54:58.683801: step 146820, total loss = 0.58, batch loss = 0.32 (125.3 examples/sec; 0.064 sec/batch; 0h:56m:02s remains)
INFO - root - 2022-02-24 20:54:59.618768: step 146830, total loss = 0.53, batch loss = 0.27 (15.3 examples/sec; 0.522 sec/batch; 7h:38m:05s remains)
INFO - root - 2022-02-24 20:55:00.091551: step 146840, total loss = 0.52, batch loss = 0.27 (132.7 examples/sec; 0.060 sec/batch; 0h:52m:54s remains)
INFO - root - 2022-02-24 20:55:00.535847: step 146850, total loss = 0.56, batch loss = 0.30 (336.0 examples/sec; 0.024 sec/batch; 0h:20m:53s remains)
INFO - root - 2022-02-24 20:55:00.899995: step 146860, total loss = 0.50, batch loss = 0.24 (240.9 examples/sec; 0.033 sec/batch; 0h:29m:08s remains)
INFO - root - 2022-02-24 20:55:01.262653: step 146870, total loss = 0.54, batch loss = 0.28 (167.9 examples/sec; 0.048 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 20:55:01.629676: step 146880, total loss = 0.55, batch loss = 0.29 (135.5 examples/sec; 0.059 sec/batch; 0h:51m:46s remains)
INFO - root - 2022-02-24 20:55:02.118479: step 146890, total loss = 0.75, batch loss = 0.49 (129.8 examples/sec; 0.062 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 20:55:02.509951: step 146900, total loss = 0.51, batch loss = 0.25 (193.5 examples/sec; 0.041 sec/batch; 0h:36m:14s remains)
INFO - root - 2022-02-24 20:55:03.564601: step 146910, total loss = 0.52, batch loss = 0.27 (373.6 examples/sec; 0.021 sec/batch; 0h:18m:46s remains)
INFO - root - 2022-02-24 20:55:03.808861: step 146920, total loss = 0.52, batch loss = 0.26 (327.5 examples/sec; 0.024 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 20:55:04.059819: step 146930, total loss = 0.55, batch loss = 0.29 (311.6 examples/sec; 0.026 sec/batch; 0h:22m:29s remains)
INFO - root - 2022-02-24 20:55:04.677593: step 146940, total loss = 0.49, batch loss = 0.23 (354.1 examples/sec; 0.023 sec/batch; 0h:19m:47s remains)
INFO - root - 2022-02-24 20:55:05.162156: step 146950, total loss = 0.55, batch loss = 0.30 (200.6 examples/sec; 0.040 sec/batch; 0h:34m:55s remains)
INFO - root - 2022-02-24 20:55:05.503929: step 146960, total loss = 0.58, batch loss = 0.32 (265.1 examples/sec; 0.030 sec/batch; 0h:26m:25s remains)
INFO - root - 2022-02-24 20:55:05.855861: step 146970, total loss = 0.52, batch loss = 0.26 (295.8 examples/sec; 0.027 sec/batch; 0h:23m:40s remains)
INFO - root - 2022-02-24 20:55:06.203085: step 146980, total loss = 0.53, batch loss = 0.27 (282.2 examples/sec; 0.028 sec/batch; 0h:24m:49s remains)
INFO - root - 2022-02-24 20:55:06.590079: step 146990, total loss = 0.60, batch loss = 0.34 (214.0 examples/sec; 0.037 sec/batch; 0h:32m:43s remains)
INFO - root - 2022-02-24 20:55:07.027171: step 147000, total loss = 0.50, batch loss = 0.24 (137.3 examples/sec; 0.058 sec/batch; 0h:50m:59s remains)
INFO - root - 2022-02-24 20:55:07.485287: step 147010, total loss = 0.50, batch loss = 0.24 (230.5 examples/sec; 0.035 sec/batch; 0h:30m:21s remains)
INFO - root - 2022-02-24 20:55:07.787324: step 147020, total loss = 0.55, batch loss = 0.29 (332.9 examples/sec; 0.024 sec/batch; 0h:21m:01s remains)
INFO - root - 2022-02-24 20:55:08.143326: step 147030, total loss = 0.60, batch loss = 0.34 (278.0 examples/sec; 0.029 sec/batch; 0h:25m:09s remains)
INFO - root - 2022-02-24 20:55:08.479430: step 147040, total loss = 0.64, batch loss = 0.38 (146.6 examples/sec; 0.055 sec/batch; 0h:47m:42s remains)
INFO - root - 2022-02-24 20:55:08.815171: step 147050, total loss = 0.62, batch loss = 0.36 (297.4 examples/sec; 0.027 sec/batch; 0h:23m:30s remains)
INFO - root - 2022-02-24 20:55:09.199138: step 147060, total loss = 0.61, batch loss = 0.35 (296.3 examples/sec; 0.027 sec/batch; 0h:23m:36s remains)
INFO - root - 2022-02-24 20:55:09.560009: step 147070, total loss = 0.56, batch loss = 0.30 (207.8 examples/sec; 0.039 sec/batch; 0h:33m:38s remains)
INFO - root - 2022-02-24 20:55:10.162936: step 147080, total loss = 0.54, batch loss = 0.28 (279.0 examples/sec; 0.029 sec/batch; 0h:25m:03s remains)
INFO - root - 2022-02-24 20:55:10.462442: step 147090, total loss = 0.62, batch loss = 0.36 (308.9 examples/sec; 0.026 sec/batch; 0h:22m:37s remains)
INFO - root - 2022-02-24 20:55:10.713747: step 147100, total loss = 0.47, batch loss = 0.22 (335.7 examples/sec; 0.024 sec/batch; 0h:20m:48s remains)
INFO - root - 2022-02-24 20:55:11.168327: step 147110, total loss = 0.56, batch loss = 0.30 (235.6 examples/sec; 0.034 sec/batch; 0h:29m:38s remains)
INFO - root - 2022-02-24 20:55:11.597989: step 147120, total loss = 0.58, batch loss = 0.32 (270.0 examples/sec; 0.030 sec/batch; 0h:25m:52s remains)
INFO - root - 2022-02-24 20:55:12.106584: step 147130, total loss = 0.53, batch loss = 0.27 (197.2 examples/sec; 0.041 sec/batch; 0h:35m:24s remains)
INFO - root - 2022-02-24 20:55:12.461215: step 147140, total loss = 0.47, batch loss = 0.21 (254.2 examples/sec; 0.031 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:55:12.831522: step 147150, total loss = 0.58, batch loss = 0.32 (335.4 examples/sec; 0.024 sec/batch; 0h:20m:48s remains)
INFO - root - 2022-02-24 20:55:13.111842: step 147160, total loss = 0.54, batch loss = 0.29 (335.4 examples/sec; 0.024 sec/batch; 0h:20m:48s remains)
INFO - root - 2022-02-24 20:55:13.605652: step 147170, total loss = 0.54, batch loss = 0.28 (329.8 examples/sec; 0.024 sec/batch; 0h:21m:09s remains)
INFO - root - 2022-02-24 20:55:13.994070: step 147180, total loss = 0.52, batch loss = 0.26 (352.1 examples/sec; 0.023 sec/batch; 0h:19m:48s remains)
INFO - root - 2022-02-24 20:55:14.289597: step 147190, total loss = 0.58, batch loss = 0.32 (251.7 examples/sec; 0.032 sec/batch; 0h:27m:42s remains)
INFO - root - 2022-02-24 20:55:14.679052: step 147200, total loss = 0.51, batch loss = 0.25 (364.0 examples/sec; 0.022 sec/batch; 0h:19m:09s remains)
INFO - root - 2022-02-24 20:55:15.200084: step 147210, total loss = 0.60, batch loss = 0.34 (135.8 examples/sec; 0.059 sec/batch; 0h:51m:21s remains)
INFO - root - 2022-02-24 20:55:15.634534: step 147220, total loss = 0.63, batch loss = 0.37 (227.3 examples/sec; 0.035 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:55:16.026910: step 147230, total loss = 0.52, batch loss = 0.26 (137.2 examples/sec; 0.058 sec/batch; 0h:50m:48s remains)
INFO - root - 2022-02-24 20:55:16.299260: step 147240, total loss = 0.52, batch loss = 0.26 (276.2 examples/sec; 0.029 sec/batch; 0h:25m:13s remains)
INFO - root - 2022-02-24 20:55:16.634034: step 147250, total loss = 0.63, batch loss = 0.38 (289.6 examples/sec; 0.028 sec/batch; 0h:24m:03s remains)
INFO - root - 2022-02-24 20:55:16.966663: step 147260, total loss = 0.62, batch loss = 0.36 (121.5 examples/sec; 0.066 sec/batch; 0h:57m:19s remains)
INFO - root - 2022-02-24 20:55:17.366533: step 147270, total loss = 0.60, batch loss = 0.35 (382.9 examples/sec; 0.021 sec/batch; 0h:18m:11s remains)
INFO - root - 2022-02-24 20:55:17.785047: step 147280, total loss = 0.50, batch loss = 0.24 (157.5 examples/sec; 0.051 sec/batch; 0h:44m:12s remains)
INFO - root - 2022-02-24 20:55:18.172040: step 147290, total loss = 0.54, batch loss = 0.28 (356.4 examples/sec; 0.022 sec/batch; 0h:19m:32s remains)
INFO - root - 2022-02-24 20:55:18.508064: step 147300, total loss = 0.47, batch loss = 0.22 (121.0 examples/sec; 0.066 sec/batch; 0h:57m:31s remains)
INFO - root - 2022-02-24 20:55:18.950687: step 147310, total loss = 0.53, batch loss = 0.27 (182.0 examples/sec; 0.044 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 20:55:19.455473: step 147320, total loss = 0.62, batch loss = 0.36 (60.0 examples/sec; 0.133 sec/batch; 1h:55m:59s remains)
INFO - root - 2022-02-24 20:55:19.887900: step 147330, total loss = 0.55, batch loss = 0.29 (136.0 examples/sec; 0.059 sec/batch; 0h:51m:07s remains)
INFO - root - 2022-02-24 20:55:20.197754: step 147340, total loss = 0.48, batch loss = 0.22 (297.2 examples/sec; 0.027 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:55:20.484730: step 147350, total loss = 0.50, batch loss = 0.24 (187.7 examples/sec; 0.043 sec/batch; 0h:37m:03s remains)
INFO - root - 2022-02-24 20:55:20.836551: step 147360, total loss = 0.60, batch loss = 0.34 (142.7 examples/sec; 0.056 sec/batch; 0h:48m:42s remains)
INFO - root - 2022-02-24 20:55:21.160018: step 147370, total loss = 0.50, batch loss = 0.24 (187.3 examples/sec; 0.043 sec/batch; 0h:37m:06s remains)
INFO - root - 2022-02-24 20:55:21.602799: step 147380, total loss = 0.61, batch loss = 0.35 (337.2 examples/sec; 0.024 sec/batch; 0h:20m:36s remains)
INFO - root - 2022-02-24 20:55:22.078736: step 147390, total loss = 0.57, batch loss = 0.31 (127.3 examples/sec; 0.063 sec/batch; 0h:54m:35s remains)
INFO - root - 2022-02-24 20:55:22.398706: step 147400, total loss = 0.63, batch loss = 0.37 (307.2 examples/sec; 0.026 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 20:55:22.829755: step 147410, total loss = 0.52, batch loss = 0.26 (273.9 examples/sec; 0.029 sec/batch; 0h:25m:21s remains)
INFO - root - 2022-02-24 20:55:23.131752: step 147420, total loss = 0.62, batch loss = 0.36 (344.6 examples/sec; 0.023 sec/batch; 0h:20m:08s remains)
INFO - root - 2022-02-24 20:55:23.537679: step 147430, total loss = 0.58, batch loss = 0.32 (239.4 examples/sec; 0.033 sec/batch; 0h:29m:00s remains)
INFO - root - 2022-02-24 20:55:23.993501: step 147440, total loss = 0.56, batch loss = 0.30 (193.9 examples/sec; 0.041 sec/batch; 0h:35m:47s remains)
INFO - root - 2022-02-24 20:55:24.474794: step 147450, total loss = 0.54, batch loss = 0.28 (140.9 examples/sec; 0.057 sec/batch; 0h:49m:15s remains)
INFO - root - 2022-02-24 20:55:24.832764: step 147460, total loss = 0.52, batch loss = 0.26 (246.9 examples/sec; 0.032 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 20:55:25.149303: step 147470, total loss = 0.43, batch loss = 0.18 (186.0 examples/sec; 0.043 sec/batch; 0h:37m:18s remains)
INFO - root - 2022-02-24 20:55:25.466703: step 147480, total loss = 0.58, batch loss = 0.32 (243.5 examples/sec; 0.033 sec/batch; 0h:28m:29s remains)
INFO - root - 2022-02-24 20:55:25.813644: step 147490, total loss = 0.49, batch loss = 0.23 (161.9 examples/sec; 0.049 sec/batch; 0h:42m:49s remains)
INFO - root - 2022-02-24 20:55:26.210497: step 147500, total loss = 0.60, batch loss = 0.35 (122.3 examples/sec; 0.065 sec/batch; 0h:56m:40s remains)
INFO - root - 2022-02-24 20:55:26.721651: step 147510, total loss = 0.45, batch loss = 0.20 (205.8 examples/sec; 0.039 sec/batch; 0h:33m:41s remains)
INFO - root - 2022-02-24 20:55:27.086314: step 147520, total loss = 0.55, batch loss = 0.29 (321.2 examples/sec; 0.025 sec/batch; 0h:21m:34s remains)
INFO - root - 2022-02-24 20:55:27.470611: step 147530, total loss = 0.61, batch loss = 0.35 (190.0 examples/sec; 0.042 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:55:28.039409: step 147540, total loss = 0.52, batch loss = 0.26 (89.3 examples/sec; 0.090 sec/batch; 1h:17m:35s remains)
INFO - root - 2022-02-24 20:55:28.457736: step 147550, total loss = 0.49, batch loss = 0.23 (154.8 examples/sec; 0.052 sec/batch; 0h:44m:44s remains)
INFO - root - 2022-02-24 20:55:28.798338: step 147560, total loss = 0.60, batch loss = 0.34 (251.9 examples/sec; 0.032 sec/batch; 0h:27m:29s remains)
INFO - root - 2022-02-24 20:55:29.110762: step 147570, total loss = 0.59, batch loss = 0.34 (307.7 examples/sec; 0.026 sec/batch; 0h:22m:30s remains)
INFO - root - 2022-02-24 20:55:29.402943: step 147580, total loss = 0.62, batch loss = 0.36 (310.2 examples/sec; 0.026 sec/batch; 0h:22m:18s remains)
INFO - root - 2022-02-24 20:55:29.738321: step 147590, total loss = 0.69, batch loss = 0.43 (247.8 examples/sec; 0.032 sec/batch; 0h:27m:55s remains)
INFO - root - 2022-02-24 20:55:30.154357: step 147600, total loss = 0.59, batch loss = 0.34 (247.5 examples/sec; 0.032 sec/batch; 0h:27m:57s remains)
INFO - root - 2022-02-24 20:55:30.615030: step 147610, total loss = 0.71, batch loss = 0.45 (285.1 examples/sec; 0.028 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:55:30.975864: step 147620, total loss = 0.55, batch loss = 0.29 (166.2 examples/sec; 0.048 sec/batch; 0h:41m:37s remains)
INFO - root - 2022-02-24 20:55:31.343561: step 147630, total loss = 0.59, batch loss = 0.34 (223.4 examples/sec; 0.036 sec/batch; 0h:30m:57s remains)
INFO - root - 2022-02-24 20:55:31.706857: step 147640, total loss = 0.55, batch loss = 0.29 (179.5 examples/sec; 0.045 sec/batch; 0h:38m:30s remains)
INFO - root - 2022-02-24 20:55:32.175592: step 147650, total loss = 0.58, batch loss = 0.32 (99.0 examples/sec; 0.081 sec/batch; 1h:09m:48s remains)
INFO - root - 2022-02-24 20:55:32.556412: step 147660, total loss = 0.47, batch loss = 0.21 (238.6 examples/sec; 0.034 sec/batch; 0h:28m:58s remains)
INFO - root - 2022-02-24 20:55:32.983019: step 147670, total loss = 0.50, batch loss = 0.24 (362.9 examples/sec; 0.022 sec/batch; 0h:19m:02s remains)
INFO - root - 2022-02-24 20:55:33.340644: step 147680, total loss = 0.53, batch loss = 0.28 (199.8 examples/sec; 0.040 sec/batch; 0h:34m:35s remains)
INFO - root - 2022-02-24 20:55:33.612452: step 147690, total loss = 0.56, batch loss = 0.30 (357.2 examples/sec; 0.022 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 20:55:33.894194: step 147700, total loss = 0.53, batch loss = 0.27 (301.0 examples/sec; 0.027 sec/batch; 0h:22m:56s remains)
INFO - root - 2022-02-24 20:55:34.400862: step 147710, total loss = 0.62, batch loss = 0.36 (142.7 examples/sec; 0.056 sec/batch; 0h:48m:23s remains)
INFO - root - 2022-02-24 20:55:35.113271: step 147720, total loss = 0.55, batch loss = 0.29 (133.7 examples/sec; 0.060 sec/batch; 0h:51m:38s remains)
INFO - root - 2022-02-24 20:55:35.519066: step 147730, total loss = 0.48, batch loss = 0.23 (152.6 examples/sec; 0.052 sec/batch; 0h:45m:13s remains)
INFO - root - 2022-02-24 20:55:35.910633: step 147740, total loss = 0.59, batch loss = 0.33 (104.6 examples/sec; 0.077 sec/batch; 1h:06m:00s remains)
INFO - root - 2022-02-24 20:55:36.358883: step 147750, total loss = 0.51, batch loss = 0.26 (227.6 examples/sec; 0.035 sec/batch; 0h:30m:18s remains)
INFO - root - 2022-02-24 20:55:36.803455: step 147760, total loss = 0.60, batch loss = 0.34 (149.7 examples/sec; 0.053 sec/batch; 0h:46m:04s remains)
INFO - root - 2022-02-24 20:55:37.394764: step 147770, total loss = 0.54, batch loss = 0.28 (128.5 examples/sec; 0.062 sec/batch; 0h:53m:39s remains)
INFO - root - 2022-02-24 20:55:38.007794: step 147780, total loss = 0.57, batch loss = 0.31 (235.8 examples/sec; 0.034 sec/batch; 0h:29m:14s remains)
INFO - root - 2022-02-24 20:55:38.497746: step 147790, total loss = 0.56, batch loss = 0.30 (335.5 examples/sec; 0.024 sec/batch; 0h:20m:32s remains)
INFO - root - 2022-02-24 20:55:38.871213: step 147800, total loss = 0.68, batch loss = 0.43 (325.9 examples/sec; 0.025 sec/batch; 0h:21m:09s remains)
INFO - root - 2022-02-24 20:55:39.333336: step 147810, total loss = 0.67, batch loss = 0.42 (378.3 examples/sec; 0.021 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 20:55:39.727706: step 147820, total loss = 0.47, batch loss = 0.21 (153.1 examples/sec; 0.052 sec/batch; 0h:45m:00s remains)
INFO - root - 2022-02-24 20:55:40.476947: step 147830, total loss = 0.55, batch loss = 0.29 (355.0 examples/sec; 0.023 sec/batch; 0h:19m:24s remains)
INFO - root - 2022-02-24 20:55:40.985184: step 147840, total loss = 0.56, batch loss = 0.31 (156.4 examples/sec; 0.051 sec/batch; 0h:44m:02s remains)
INFO - root - 2022-02-24 20:55:41.338294: step 147850, total loss = 0.59, batch loss = 0.33 (337.3 examples/sec; 0.024 sec/batch; 0h:20m:24s remains)
INFO - root - 2022-02-24 20:55:41.782509: step 147860, total loss = 0.49, batch loss = 0.24 (90.1 examples/sec; 0.089 sec/batch; 1h:16m:26s remains)
INFO - root - 2022-02-24 20:55:42.148789: step 147870, total loss = 0.62, batch loss = 0.37 (96.1 examples/sec; 0.083 sec/batch; 1h:11m:36s remains)
INFO - root - 2022-02-24 20:55:42.542033: step 147880, total loss = 0.54, batch loss = 0.28 (145.2 examples/sec; 0.055 sec/batch; 0h:47m:24s remains)
INFO - root - 2022-02-24 20:55:42.973923: step 147890, total loss = 0.55, batch loss = 0.30 (330.1 examples/sec; 0.024 sec/batch; 0h:20m:50s remains)
INFO - root - 2022-02-24 20:55:43.331419: step 147900, total loss = 0.52, batch loss = 0.26 (356.1 examples/sec; 0.022 sec/batch; 0h:19m:19s remains)
INFO - root - 2022-02-24 20:55:43.733279: step 147910, total loss = 0.56, batch loss = 0.30 (209.6 examples/sec; 0.038 sec/batch; 0h:32m:48s remains)
INFO - root - 2022-02-24 20:55:44.324509: step 147920, total loss = 0.49, batch loss = 0.23 (97.8 examples/sec; 0.082 sec/batch; 1h:10m:18s remains)
INFO - root - 2022-02-24 20:55:44.830090: step 147930, total loss = 0.54, batch loss = 0.28 (134.0 examples/sec; 0.060 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 20:55:45.213101: step 147940, total loss = 0.60, batch loss = 0.34 (211.1 examples/sec; 0.038 sec/batch; 0h:32m:33s remains)
INFO - root - 2022-02-24 20:55:45.540074: step 147950, total loss = 0.48, batch loss = 0.23 (243.5 examples/sec; 0.033 sec/batch; 0h:28m:13s remains)
INFO - root - 2022-02-24 20:55:45.890672: step 147960, total loss = 0.52, batch loss = 0.27 (321.2 examples/sec; 0.025 sec/batch; 0h:21m:23s remains)
INFO - root - 2022-02-24 20:55:46.419677: step 147970, total loss = 0.47, batch loss = 0.21 (302.4 examples/sec; 0.026 sec/batch; 0h:22m:43s remains)
INFO - root - 2022-02-24 20:55:46.827910: step 147980, total loss = 0.52, batch loss = 0.26 (206.8 examples/sec; 0.039 sec/batch; 0h:33m:13s remains)
INFO - root - 2022-02-24 20:55:47.181244: step 147990, total loss = 0.59, batch loss = 0.33 (305.4 examples/sec; 0.026 sec/batch; 0h:22m:29s remains)
INFO - root - 2022-02-24 20:55:47.565500: step 148000, total loss = 0.46, batch loss = 0.20 (365.3 examples/sec; 0.022 sec/batch; 0h:18m:47s remains)
INFO - root - 2022-02-24 20:55:47.932352: step 148010, total loss = 0.50, batch loss = 0.25 (159.4 examples/sec; 0.050 sec/batch; 0h:43m:03s remains)
INFO - root - 2022-02-24 20:55:48.295527: step 148020, total loss = 0.61, batch loss = 0.35 (231.8 examples/sec; 0.035 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 20:55:48.763909: step 148030, total loss = 0.64, batch loss = 0.38 (212.4 examples/sec; 0.038 sec/batch; 0h:32m:18s remains)
INFO - root - 2022-02-24 20:55:49.104446: step 148040, total loss = 0.53, batch loss = 0.27 (361.8 examples/sec; 0.022 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 20:55:49.470465: step 148050, total loss = 0.52, batch loss = 0.26 (134.5 examples/sec; 0.060 sec/batch; 0h:51m:01s remains)
INFO - root - 2022-02-24 20:55:49.823069: step 148060, total loss = 0.50, batch loss = 0.24 (103.0 examples/sec; 0.078 sec/batch; 1h:06m:34s remains)
INFO - root - 2022-02-24 20:55:50.253557: step 148070, total loss = 0.59, batch loss = 0.33 (197.3 examples/sec; 0.041 sec/batch; 0h:34m:45s remains)
INFO - root - 2022-02-24 20:55:50.617365: step 148080, total loss = 0.60, batch loss = 0.35 (283.2 examples/sec; 0.028 sec/batch; 0h:24m:12s remains)
INFO - root - 2022-02-24 20:55:51.116494: step 148090, total loss = 0.52, batch loss = 0.26 (127.8 examples/sec; 0.063 sec/batch; 0h:53m:38s remains)
INFO - root - 2022-02-24 20:55:51.399066: step 148100, total loss = 0.58, batch loss = 0.32 (351.0 examples/sec; 0.023 sec/batch; 0h:19m:31s remains)
INFO - root - 2022-02-24 20:55:51.786396: step 148110, total loss = 0.48, batch loss = 0.22 (156.1 examples/sec; 0.051 sec/batch; 0h:43m:52s remains)
INFO - root - 2022-02-24 20:55:52.074807: step 148120, total loss = 0.60, batch loss = 0.34 (318.5 examples/sec; 0.025 sec/batch; 0h:21m:30s remains)
INFO - root - 2022-02-24 20:55:52.438113: step 148130, total loss = 0.45, batch loss = 0.19 (263.1 examples/sec; 0.030 sec/batch; 0h:26m:02s remains)
INFO - root - 2022-02-24 20:55:52.843538: step 148140, total loss = 0.51, batch loss = 0.25 (270.7 examples/sec; 0.030 sec/batch; 0h:25m:18s remains)
INFO - root - 2022-02-24 20:55:53.282248: step 148150, total loss = 0.59, batch loss = 0.33 (331.2 examples/sec; 0.024 sec/batch; 0h:20m:40s remains)
INFO - root - 2022-02-24 20:55:53.604439: step 148160, total loss = 0.63, batch loss = 0.37 (170.6 examples/sec; 0.047 sec/batch; 0h:40m:07s remains)
INFO - root - 2022-02-24 20:55:53.926600: step 148170, total loss = 0.47, batch loss = 0.21 (336.1 examples/sec; 0.024 sec/batch; 0h:20m:21s remains)
INFO - root - 2022-02-24 20:55:54.264376: step 148180, total loss = 0.59, batch loss = 0.33 (289.9 examples/sec; 0.028 sec/batch; 0h:23m:36s remains)
INFO - root - 2022-02-24 20:55:54.657017: step 148190, total loss = 0.47, batch loss = 0.21 (136.7 examples/sec; 0.059 sec/batch; 0h:50m:02s remains)
INFO - root - 2022-02-24 20:55:55.034064: step 148200, total loss = 0.57, batch loss = 0.31 (262.1 examples/sec; 0.031 sec/batch; 0h:26m:05s remains)
INFO - root - 2022-02-24 20:55:55.512754: step 148210, total loss = 0.56, batch loss = 0.31 (381.0 examples/sec; 0.021 sec/batch; 0h:17m:56s remains)
INFO - root - 2022-02-24 20:55:55.849553: step 148220, total loss = 0.58, batch loss = 0.32 (272.4 examples/sec; 0.029 sec/batch; 0h:25m:06s remains)
INFO - root - 2022-02-24 20:55:56.240873: step 148230, total loss = 0.51, batch loss = 0.26 (142.4 examples/sec; 0.056 sec/batch; 0h:48m:00s remains)
INFO - root - 2022-02-24 20:55:56.571341: step 148240, total loss = 0.55, batch loss = 0.30 (124.1 examples/sec; 0.064 sec/batch; 0h:55m:03s remains)
INFO - root - 2022-02-24 20:55:57.038076: step 148250, total loss = 0.48, batch loss = 0.22 (304.1 examples/sec; 0.026 sec/batch; 0h:22m:28s remains)
INFO - root - 2022-02-24 20:55:57.478995: step 148260, total loss = 0.57, batch loss = 0.31 (319.2 examples/sec; 0.025 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 20:55:57.868495: step 148270, total loss = 0.45, batch loss = 0.19 (342.3 examples/sec; 0.023 sec/batch; 0h:19m:57s remains)
INFO - root - 2022-02-24 20:55:58.219173: step 148280, total loss = 0.58, batch loss = 0.33 (349.0 examples/sec; 0.023 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 20:55:58.594552: step 148290, total loss = 0.48, batch loss = 0.22 (134.2 examples/sec; 0.060 sec/batch; 0h:50m:51s remains)
INFO - root - 2022-02-24 20:55:59.016656: step 148300, total loss = 0.60, batch loss = 0.34 (136.9 examples/sec; 0.058 sec/batch; 0h:49m:51s remains)
INFO - root - 2022-02-24 20:55:59.510988: step 148310, total loss = 0.52, batch loss = 0.26 (217.1 examples/sec; 0.037 sec/batch; 0h:31m:26s remains)
INFO - root - 2022-02-24 20:55:59.840134: step 148320, total loss = 0.58, batch loss = 0.32 (150.3 examples/sec; 0.053 sec/batch; 0h:45m:23s remains)
INFO - root - 2022-02-24 20:56:00.306624: step 148330, total loss = 0.55, batch loss = 0.29 (102.5 examples/sec; 0.078 sec/batch; 1h:06m:33s remains)
INFO - root - 2022-02-24 20:56:00.705400: step 148340, total loss = 0.54, batch loss = 0.28 (278.0 examples/sec; 0.029 sec/batch; 0h:24m:32s remains)
INFO - root - 2022-02-24 20:56:01.173644: step 148350, total loss = 0.49, batch loss = 0.24 (326.7 examples/sec; 0.024 sec/batch; 0h:20m:52s remains)
INFO - root - 2022-02-24 20:56:01.509781: step 148360, total loss = 0.52, batch loss = 0.26 (308.2 examples/sec; 0.026 sec/batch; 0h:22m:07s remains)
INFO - root - 2022-02-24 20:56:01.799904: step 148370, total loss = 0.50, batch loss = 0.24 (332.3 examples/sec; 0.024 sec/batch; 0h:20m:30s remains)
INFO - root - 2022-02-24 20:56:02.094034: step 148380, total loss = 0.51, batch loss = 0.25 (193.4 examples/sec; 0.041 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 20:56:02.429073: step 148390, total loss = 0.54, batch loss = 0.28 (129.1 examples/sec; 0.062 sec/batch; 0h:52m:46s remains)
INFO - root - 2022-02-24 20:56:02.879971: step 148400, total loss = 0.58, batch loss = 0.32 (369.4 examples/sec; 0.022 sec/batch; 0h:18m:26s remains)
INFO - root - 2022-02-24 20:56:03.317210: step 148410, total loss = 0.55, batch loss = 0.29 (342.5 examples/sec; 0.023 sec/batch; 0h:19m:53s remains)
INFO - root - 2022-02-24 20:56:03.733078: step 148420, total loss = 0.66, batch loss = 0.40 (290.9 examples/sec; 0.028 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:56:04.050609: step 148430, total loss = 0.58, batch loss = 0.32 (337.5 examples/sec; 0.024 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 20:56:04.360417: step 148440, total loss = 0.60, batch loss = 0.34 (326.2 examples/sec; 0.025 sec/batch; 0h:20m:52s remains)
INFO - root - 2022-02-24 20:56:04.598605: step 148450, total loss = 0.47, batch loss = 0.21 (334.5 examples/sec; 0.024 sec/batch; 0h:20m:20s remains)
INFO - root - 2022-02-24 20:56:05.053733: step 148460, total loss = 0.46, batch loss = 0.20 (108.9 examples/sec; 0.073 sec/batch; 1h:02m:27s remains)
INFO - root - 2022-02-24 20:56:05.523397: step 148470, total loss = 0.57, batch loss = 0.31 (356.7 examples/sec; 0.022 sec/batch; 0h:19m:04s remains)
INFO - root - 2022-02-24 20:56:05.876245: step 148480, total loss = 0.46, batch loss = 0.21 (225.4 examples/sec; 0.035 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 20:56:06.228631: step 148490, total loss = 0.72, batch loss = 0.46 (195.4 examples/sec; 0.041 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 20:56:06.575797: step 148500, total loss = 0.55, batch loss = 0.29 (200.0 examples/sec; 0.040 sec/batch; 0h:33m:59s remains)
INFO - root - 2022-02-24 20:56:07.123634: step 148510, total loss = 0.47, batch loss = 0.21 (150.8 examples/sec; 0.053 sec/batch; 0h:45m:04s remains)
INFO - root - 2022-02-24 20:56:07.578666: step 148520, total loss = 0.52, batch loss = 0.27 (318.5 examples/sec; 0.025 sec/batch; 0h:21m:20s remains)
INFO - root - 2022-02-24 20:56:07.981540: step 148530, total loss = 0.54, batch loss = 0.28 (317.5 examples/sec; 0.025 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 20:56:08.369194: step 148540, total loss = 0.70, batch loss = 0.44 (218.6 examples/sec; 0.037 sec/batch; 0h:31m:04s remains)
INFO - root - 2022-02-24 20:56:08.791262: step 148550, total loss = 0.53, batch loss = 0.27 (117.6 examples/sec; 0.068 sec/batch; 0h:57m:44s remains)
INFO - root - 2022-02-24 20:56:09.202601: step 148560, total loss = 0.54, batch loss = 0.28 (173.6 examples/sec; 0.046 sec/batch; 0h:39m:07s remains)
INFO - root - 2022-02-24 20:56:09.649674: step 148570, total loss = 0.56, batch loss = 0.30 (183.6 examples/sec; 0.044 sec/batch; 0h:36m:59s remains)
INFO - root - 2022-02-24 20:56:10.071973: step 148580, total loss = 0.53, batch loss = 0.27 (281.0 examples/sec; 0.028 sec/batch; 0h:24m:09s remains)
INFO - root - 2022-02-24 20:56:10.419947: step 148590, total loss = 0.50, batch loss = 0.24 (294.8 examples/sec; 0.027 sec/batch; 0h:23m:01s remains)
INFO - root - 2022-02-24 20:56:10.779314: step 148600, total loss = 0.54, batch loss = 0.28 (315.0 examples/sec; 0.025 sec/batch; 0h:21m:32s remains)
INFO - root - 2022-02-24 20:56:11.264184: step 148610, total loss = 0.55, batch loss = 0.30 (242.9 examples/sec; 0.033 sec/batch; 0h:27m:56s remains)
INFO - root - 2022-02-24 20:56:11.706561: step 148620, total loss = 0.55, batch loss = 0.29 (136.2 examples/sec; 0.059 sec/batch; 0h:49m:48s remains)
INFO - root - 2022-02-24 20:56:12.060933: step 148630, total loss = 0.50, batch loss = 0.24 (267.0 examples/sec; 0.030 sec/batch; 0h:25m:24s remains)
INFO - root - 2022-02-24 20:56:12.428268: step 148640, total loss = 0.58, batch loss = 0.32 (171.3 examples/sec; 0.047 sec/batch; 0h:39m:35s remains)
INFO - root - 2022-02-24 20:56:12.791512: step 148650, total loss = 0.54, batch loss = 0.28 (303.6 examples/sec; 0.026 sec/batch; 0h:22m:19s remains)
INFO - root - 2022-02-24 20:56:13.170120: step 148660, total loss = 0.48, batch loss = 0.22 (172.3 examples/sec; 0.046 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:56:13.789247: step 148670, total loss = 0.55, batch loss = 0.29 (106.3 examples/sec; 0.075 sec/batch; 1h:03m:45s remains)
INFO - root - 2022-02-24 20:56:14.311517: step 148680, total loss = 0.59, batch loss = 0.34 (115.6 examples/sec; 0.069 sec/batch; 0h:58m:36s remains)
INFO - root - 2022-02-24 20:56:14.734421: step 148690, total loss = 0.60, batch loss = 0.34 (258.4 examples/sec; 0.031 sec/batch; 0h:26m:12s remains)
INFO - root - 2022-02-24 20:56:15.852504: step 148700, total loss = 0.58, batch loss = 0.32 (19.5 examples/sec; 0.410 sec/batch; 5h:47m:23s remains)
INFO - root - 2022-02-24 20:56:16.420709: step 148710, total loss = 0.53, batch loss = 0.27 (323.8 examples/sec; 0.025 sec/batch; 0h:20m:54s remains)
INFO - root - 2022-02-24 20:56:16.737835: step 148720, total loss = 0.51, batch loss = 0.25 (289.8 examples/sec; 0.028 sec/batch; 0h:23m:22s remains)
INFO - root - 2022-02-24 20:56:17.074310: step 148730, total loss = 0.52, batch loss = 0.27 (271.3 examples/sec; 0.029 sec/batch; 0h:24m:57s remains)
INFO - root - 2022-02-24 20:56:17.486000: step 148740, total loss = 0.45, batch loss = 0.19 (227.4 examples/sec; 0.035 sec/batch; 0h:29m:45s remains)
INFO - root - 2022-02-24 20:56:17.881061: step 148750, total loss = 0.46, batch loss = 0.20 (157.8 examples/sec; 0.051 sec/batch; 0h:42m:53s remains)
INFO - root - 2022-02-24 20:56:18.375086: step 148760, total loss = 0.54, batch loss = 0.28 (137.9 examples/sec; 0.058 sec/batch; 0h:49m:02s remains)
INFO - root - 2022-02-24 20:56:18.753651: step 148770, total loss = 0.67, batch loss = 0.41 (185.6 examples/sec; 0.043 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:56:19.140049: step 148780, total loss = 0.63, batch loss = 0.37 (361.1 examples/sec; 0.022 sec/batch; 0h:18m:43s remains)
INFO - root - 2022-02-24 20:56:19.467755: step 148790, total loss = 0.43, batch loss = 0.17 (357.8 examples/sec; 0.022 sec/batch; 0h:18m:53s remains)
INFO - root - 2022-02-24 20:56:19.965337: step 148800, total loss = 0.61, batch loss = 0.35 (146.7 examples/sec; 0.055 sec/batch; 0h:46m:05s remains)
INFO - root - 2022-02-24 20:56:20.405833: step 148810, total loss = 0.49, batch loss = 0.23 (251.0 examples/sec; 0.032 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 20:56:21.025976: step 148820, total loss = 0.54, batch loss = 0.28 (186.7 examples/sec; 0.043 sec/batch; 0h:36m:12s remains)
INFO - root - 2022-02-24 20:56:21.382810: step 148830, total loss = 0.51, batch loss = 0.25 (251.3 examples/sec; 0.032 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 20:56:21.825778: step 148840, total loss = 0.49, batch loss = 0.23 (121.1 examples/sec; 0.066 sec/batch; 0h:55m:46s remains)
INFO - root - 2022-02-24 20:56:22.220971: step 148850, total loss = 0.61, batch loss = 0.36 (347.0 examples/sec; 0.023 sec/batch; 0h:19m:27s remains)
INFO - root - 2022-02-24 20:56:22.586062: step 148860, total loss = 0.53, batch loss = 0.27 (143.9 examples/sec; 0.056 sec/batch; 0h:46m:54s remains)
INFO - root - 2022-02-24 20:56:22.960983: step 148870, total loss = 0.58, batch loss = 0.32 (323.1 examples/sec; 0.025 sec/batch; 0h:20m:53s remains)
INFO - root - 2022-02-24 20:56:23.308643: step 148880, total loss = 0.59, batch loss = 0.34 (344.7 examples/sec; 0.023 sec/batch; 0h:19m:34s remains)
INFO - root - 2022-02-24 20:56:23.812556: step 148890, total loss = 0.64, batch loss = 0.38 (109.4 examples/sec; 0.073 sec/batch; 1h:01m:40s remains)
INFO - root - 2022-02-24 20:56:24.301938: step 148900, total loss = 0.55, batch loss = 0.29 (323.7 examples/sec; 0.025 sec/batch; 0h:20m:50s remains)
INFO - root - 2022-02-24 20:56:24.687001: step 148910, total loss = 0.43, batch loss = 0.18 (181.9 examples/sec; 0.044 sec/batch; 0h:37m:04s remains)
INFO - root - 2022-02-24 20:56:25.006619: step 148920, total loss = 0.53, batch loss = 0.27 (341.7 examples/sec; 0.023 sec/batch; 0h:19m:44s remains)
INFO - root - 2022-02-24 20:56:25.418911: step 148930, total loss = 0.46, batch loss = 0.20 (199.3 examples/sec; 0.040 sec/batch; 0h:33m:49s remains)
INFO - root - 2022-02-24 20:56:25.802198: step 148940, total loss = 0.50, batch loss = 0.25 (171.6 examples/sec; 0.047 sec/batch; 0h:39m:16s remains)
INFO - root - 2022-02-24 20:56:26.216229: step 148950, total loss = 0.54, batch loss = 0.28 (148.1 examples/sec; 0.054 sec/batch; 0h:45m:30s remains)
INFO - root - 2022-02-24 20:56:26.676026: step 148960, total loss = 0.59, batch loss = 0.33 (167.9 examples/sec; 0.048 sec/batch; 0h:40m:08s remains)
INFO - root - 2022-02-24 20:56:27.013809: step 148970, total loss = 0.49, batch loss = 0.23 (264.7 examples/sec; 0.030 sec/batch; 0h:25m:27s remains)
INFO - root - 2022-02-24 20:56:27.354613: step 148980, total loss = 0.51, batch loss = 0.25 (304.5 examples/sec; 0.026 sec/batch; 0h:22m:07s remains)
INFO - root - 2022-02-24 20:56:27.709616: step 148990, total loss = 0.74, batch loss = 0.48 (247.0 examples/sec; 0.032 sec/batch; 0h:27m:16s remains)
INFO - root - 2022-02-24 20:56:28.131952: step 149000, total loss = 0.55, batch loss = 0.29 (123.9 examples/sec; 0.065 sec/batch; 0h:54m:21s remains)
INFO - root - 2022-02-24 20:56:28.520033: step 149010, total loss = 0.62, batch loss = 0.36 (312.8 examples/sec; 0.026 sec/batch; 0h:21m:31s remains)
INFO - root - 2022-02-24 20:56:28.907193: step 149020, total loss = 0.83, batch loss = 0.57 (188.8 examples/sec; 0.042 sec/batch; 0h:35m:38s remains)
INFO - root - 2022-02-24 20:56:29.254529: step 149030, total loss = 0.74, batch loss = 0.48 (324.1 examples/sec; 0.025 sec/batch; 0h:20m:45s remains)
INFO - root - 2022-02-24 20:56:29.639453: step 149040, total loss = 0.61, batch loss = 0.35 (241.4 examples/sec; 0.033 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 20:56:30.036591: step 149050, total loss = 0.56, batch loss = 0.30 (142.4 examples/sec; 0.056 sec/batch; 0h:47m:13s remains)
INFO - root - 2022-02-24 20:56:30.429283: step 149060, total loss = 0.50, batch loss = 0.24 (171.7 examples/sec; 0.047 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 20:56:30.928877: step 149070, total loss = 0.67, batch loss = 0.41 (159.1 examples/sec; 0.050 sec/batch; 0h:42m:15s remains)
INFO - root - 2022-02-24 20:56:31.353931: step 149080, total loss = 0.53, batch loss = 0.27 (142.8 examples/sec; 0.056 sec/batch; 0h:47m:03s remains)
INFO - root - 2022-02-24 20:56:31.705197: step 149090, total loss = 0.56, batch loss = 0.30 (286.2 examples/sec; 0.028 sec/batch; 0h:23m:28s remains)
INFO - root - 2022-02-24 20:56:32.030319: step 149100, total loss = 0.60, batch loss = 0.34 (154.1 examples/sec; 0.052 sec/batch; 0h:43m:36s remains)
INFO - root - 2022-02-24 20:56:32.392625: step 149110, total loss = 0.63, batch loss = 0.37 (233.2 examples/sec; 0.034 sec/batch; 0h:28m:48s remains)
INFO - root - 2022-02-24 20:56:32.777560: step 149120, total loss = 0.57, batch loss = 0.32 (156.0 examples/sec; 0.051 sec/batch; 0h:43m:04s remains)
INFO - root - 2022-02-24 20:56:33.185515: step 149130, total loss = 0.54, batch loss = 0.28 (226.8 examples/sec; 0.035 sec/batch; 0h:29m:37s remains)
INFO - root - 2022-02-24 20:56:33.625233: step 149140, total loss = 0.63, batch loss = 0.38 (172.8 examples/sec; 0.046 sec/batch; 0h:38m:51s remains)
INFO - root - 2022-02-24 20:56:33.974538: step 149150, total loss = 0.70, batch loss = 0.44 (340.6 examples/sec; 0.023 sec/batch; 0h:19m:42s remains)
INFO - root - 2022-02-24 20:56:34.328296: step 149160, total loss = 0.48, batch loss = 0.22 (219.1 examples/sec; 0.037 sec/batch; 0h:30m:37s remains)
INFO - root - 2022-02-24 20:56:34.666125: step 149170, total loss = 0.52, batch loss = 0.27 (255.2 examples/sec; 0.031 sec/batch; 0h:26m:17s remains)
INFO - root - 2022-02-24 20:56:35.058747: step 149180, total loss = 0.64, batch loss = 0.38 (189.7 examples/sec; 0.042 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:56:35.482786: step 149190, total loss = 0.52, batch loss = 0.26 (341.8 examples/sec; 0.023 sec/batch; 0h:19m:37s remains)
INFO - root - 2022-02-24 20:56:35.890380: step 149200, total loss = 0.53, batch loss = 0.27 (332.0 examples/sec; 0.024 sec/batch; 0h:20m:12s remains)
INFO - root - 2022-02-24 20:56:36.302521: step 149210, total loss = 0.57, batch loss = 0.31 (188.7 examples/sec; 0.042 sec/batch; 0h:35m:32s remains)
INFO - root - 2022-02-24 20:56:36.664826: step 149220, total loss = 0.60, batch loss = 0.34 (220.8 examples/sec; 0.036 sec/batch; 0h:30m:21s remains)
INFO - root - 2022-02-24 20:56:37.043105: step 149230, total loss = 0.47, batch loss = 0.21 (154.1 examples/sec; 0.052 sec/batch; 0h:43m:30s remains)
INFO - root - 2022-02-24 20:56:37.495846: step 149240, total loss = 0.58, batch loss = 0.32 (76.1 examples/sec; 0.105 sec/batch; 1h:28m:03s remains)
INFO - root - 2022-02-24 20:56:37.932084: step 149250, total loss = 0.54, batch loss = 0.28 (208.9 examples/sec; 0.038 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:56:38.492843: step 149260, total loss = 0.57, batch loss = 0.32 (39.8 examples/sec; 0.201 sec/batch; 2h:48m:24s remains)
INFO - root - 2022-02-24 20:56:38.923872: step 149270, total loss = 0.49, batch loss = 0.23 (204.1 examples/sec; 0.039 sec/batch; 0h:32m:48s remains)
INFO - root - 2022-02-24 20:56:39.394782: step 149280, total loss = 0.68, batch loss = 0.42 (157.0 examples/sec; 0.051 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 20:56:39.783069: step 149290, total loss = 0.57, batch loss = 0.31 (328.8 examples/sec; 0.024 sec/batch; 0h:20m:21s remains)
INFO - root - 2022-02-24 20:56:40.254124: step 149300, total loss = 0.47, batch loss = 0.21 (293.6 examples/sec; 0.027 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 20:56:41.182032: step 149310, total loss = 0.51, batch loss = 0.25 (199.9 examples/sec; 0.040 sec/batch; 0h:33m:28s remains)
INFO - root - 2022-02-24 20:56:41.612653: step 149320, total loss = 0.60, batch loss = 0.34 (190.4 examples/sec; 0.042 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:56:42.011939: step 149330, total loss = 0.56, batch loss = 0.30 (190.4 examples/sec; 0.042 sec/batch; 0h:35m:08s remains)
INFO - root - 2022-02-24 20:56:42.337675: step 149340, total loss = 0.77, batch loss = 0.51 (279.2 examples/sec; 0.029 sec/batch; 0h:23m:57s remains)
INFO - root - 2022-02-24 20:56:42.729826: step 149350, total loss = 0.48, batch loss = 0.23 (320.6 examples/sec; 0.025 sec/batch; 0h:20m:51s remains)
INFO - root - 2022-02-24 20:56:43.128489: step 149360, total loss = 0.54, batch loss = 0.28 (208.8 examples/sec; 0.038 sec/batch; 0h:32m:01s remains)
INFO - root - 2022-02-24 20:56:43.508590: step 149370, total loss = 0.48, batch loss = 0.22 (139.6 examples/sec; 0.057 sec/batch; 0h:47m:53s remains)
INFO - root - 2022-02-24 20:56:43.906733: step 149380, total loss = 0.53, batch loss = 0.27 (107.8 examples/sec; 0.074 sec/batch; 1h:01m:59s remains)
INFO - root - 2022-02-24 20:56:44.249699: step 149390, total loss = 0.54, batch loss = 0.28 (314.2 examples/sec; 0.025 sec/batch; 0h:21m:15s remains)
INFO - root - 2022-02-24 20:56:44.637134: step 149400, total loss = 0.56, batch loss = 0.31 (350.1 examples/sec; 0.023 sec/batch; 0h:19m:04s remains)
INFO - root - 2022-02-24 20:56:45.087986: step 149410, total loss = 0.69, batch loss = 0.43 (272.6 examples/sec; 0.029 sec/batch; 0h:24m:30s remains)
INFO - root - 2022-02-24 20:56:45.524098: step 149420, total loss = 0.53, batch loss = 0.27 (212.6 examples/sec; 0.038 sec/batch; 0h:31m:24s remains)
INFO - root - 2022-02-24 20:56:46.084968: step 149430, total loss = 0.60, batch loss = 0.34 (95.9 examples/sec; 0.083 sec/batch; 1h:09m:34s remains)
INFO - root - 2022-02-24 20:56:46.540567: step 149440, total loss = 0.61, batch loss = 0.35 (317.9 examples/sec; 0.025 sec/batch; 0h:20m:59s remains)
INFO - root - 2022-02-24 20:56:46.871474: step 149450, total loss = 0.48, batch loss = 0.23 (330.0 examples/sec; 0.024 sec/batch; 0h:20m:13s remains)
INFO - root - 2022-02-24 20:56:47.192929: step 149460, total loss = 0.64, batch loss = 0.38 (138.2 examples/sec; 0.058 sec/batch; 0h:48m:16s remains)
INFO - root - 2022-02-24 20:56:47.475031: step 149470, total loss = 0.47, batch loss = 0.21 (298.7 examples/sec; 0.027 sec/batch; 0h:22m:19s remains)
INFO - root - 2022-02-24 20:56:47.869319: step 149480, total loss = 0.56, batch loss = 0.31 (159.0 examples/sec; 0.050 sec/batch; 0h:41m:56s remains)
INFO - root - 2022-02-24 20:56:48.329453: step 149490, total loss = 0.54, batch loss = 0.29 (162.4 examples/sec; 0.049 sec/batch; 0h:41m:03s remains)
INFO - root - 2022-02-24 20:56:48.743774: step 149500, total loss = 0.51, batch loss = 0.25 (233.5 examples/sec; 0.034 sec/batch; 0h:28m:33s remains)
INFO - root - 2022-02-24 20:56:49.137845: step 149510, total loss = 0.62, batch loss = 0.36 (299.3 examples/sec; 0.027 sec/batch; 0h:22m:16s remains)
INFO - root - 2022-02-24 20:56:49.432712: step 149520, total loss = 0.65, batch loss = 0.39 (325.0 examples/sec; 0.025 sec/batch; 0h:20m:30s remains)
INFO - root - 2022-02-24 20:56:49.850691: step 149530, total loss = 0.53, batch loss = 0.27 (141.0 examples/sec; 0.057 sec/batch; 0h:47m:16s remains)
INFO - root - 2022-02-24 20:56:50.338807: step 149540, total loss = 0.50, batch loss = 0.25 (206.3 examples/sec; 0.039 sec/batch; 0h:32m:17s remains)
INFO - root - 2022-02-24 20:56:50.800491: step 149550, total loss = 0.47, batch loss = 0.22 (160.6 examples/sec; 0.050 sec/batch; 0h:41m:27s remains)
INFO - root - 2022-02-24 20:56:51.076826: step 149560, total loss = 0.51, batch loss = 0.26 (327.4 examples/sec; 0.024 sec/batch; 0h:20m:20s remains)
INFO - root - 2022-02-24 20:56:51.357864: step 149570, total loss = 0.53, batch loss = 0.27 (243.3 examples/sec; 0.033 sec/batch; 0h:27m:21s remains)
INFO - root - 2022-02-24 20:56:51.716629: step 149580, total loss = 0.55, batch loss = 0.30 (242.2 examples/sec; 0.033 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 20:56:52.065113: step 149590, total loss = 0.44, batch loss = 0.18 (145.2 examples/sec; 0.055 sec/batch; 0h:45m:50s remains)
INFO - root - 2022-02-24 20:56:52.611114: step 149600, total loss = 0.49, batch loss = 0.24 (88.6 examples/sec; 0.090 sec/batch; 1h:15m:05s remains)
INFO - root - 2022-02-24 20:56:53.020354: step 149610, total loss = 0.45, batch loss = 0.19 (166.9 examples/sec; 0.048 sec/batch; 0h:39m:50s remains)
INFO - root - 2022-02-24 20:56:53.360661: step 149620, total loss = 0.53, batch loss = 0.28 (312.0 examples/sec; 0.026 sec/batch; 0h:21m:19s remains)
INFO - root - 2022-02-24 20:56:53.799036: step 149630, total loss = 0.48, batch loss = 0.22 (336.7 examples/sec; 0.024 sec/batch; 0h:19m:45s remains)
INFO - root - 2022-02-24 20:56:54.098937: step 149640, total loss = 0.56, batch loss = 0.30 (283.0 examples/sec; 0.028 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 20:56:54.578084: step 149650, total loss = 0.52, batch loss = 0.26 (157.4 examples/sec; 0.051 sec/batch; 0h:42m:14s remains)
INFO - root - 2022-02-24 20:56:55.119007: step 149660, total loss = 0.64, batch loss = 0.39 (136.1 examples/sec; 0.059 sec/batch; 0h:48m:49s remains)
INFO - root - 2022-02-24 20:56:55.503934: step 149670, total loss = 0.61, batch loss = 0.35 (208.2 examples/sec; 0.038 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 20:56:55.876800: step 149680, total loss = 0.56, batch loss = 0.30 (253.8 examples/sec; 0.032 sec/batch; 0h:26m:10s remains)
INFO - root - 2022-02-24 20:56:56.237678: step 149690, total loss = 0.55, batch loss = 0.29 (171.0 examples/sec; 0.047 sec/batch; 0h:38m:50s remains)
INFO - root - 2022-02-24 20:56:56.577912: step 149700, total loss = 0.63, batch loss = 0.37 (347.3 examples/sec; 0.023 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 20:56:57.105944: step 149710, total loss = 0.54, batch loss = 0.28 (158.0 examples/sec; 0.051 sec/batch; 0h:42m:01s remains)
INFO - root - 2022-02-24 20:56:57.503876: step 149720, total loss = 0.68, batch loss = 0.42 (358.4 examples/sec; 0.022 sec/batch; 0h:18m:31s remains)
INFO - root - 2022-02-24 20:56:57.833476: step 149730, total loss = 0.54, batch loss = 0.28 (233.1 examples/sec; 0.034 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 20:56:58.142110: step 149740, total loss = 0.59, batch loss = 0.33 (231.1 examples/sec; 0.035 sec/batch; 0h:28m:42s remains)
INFO - root - 2022-02-24 20:56:58.522922: step 149750, total loss = 0.57, batch loss = 0.32 (265.1 examples/sec; 0.030 sec/batch; 0h:25m:01s remains)
INFO - root - 2022-02-24 20:56:58.955166: step 149760, total loss = 0.58, batch loss = 0.32 (111.1 examples/sec; 0.072 sec/batch; 0h:59m:41s remains)
INFO - root - 2022-02-24 20:56:59.396730: step 149770, total loss = 0.60, batch loss = 0.34 (142.6 examples/sec; 0.056 sec/batch; 0h:46m:29s remains)
INFO - root - 2022-02-24 20:56:59.723186: step 149780, total loss = 0.46, batch loss = 0.20 (305.2 examples/sec; 0.026 sec/batch; 0h:21m:43s remains)
INFO - root - 2022-02-24 20:57:00.082680: step 149790, total loss = 0.59, batch loss = 0.34 (300.4 examples/sec; 0.027 sec/batch; 0h:22m:04s remains)
INFO - root - 2022-02-24 20:57:00.411622: step 149800, total loss = 0.52, batch loss = 0.26 (165.9 examples/sec; 0.048 sec/batch; 0h:39m:57s remains)
INFO - root - 2022-02-24 20:57:00.844491: step 149810, total loss = 0.64, batch loss = 0.38 (172.3 examples/sec; 0.046 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:57:01.331527: step 149820, total loss = 0.44, batch loss = 0.19 (123.3 examples/sec; 0.065 sec/batch; 0h:53m:44s remains)
INFO - root - 2022-02-24 20:57:01.703864: step 149830, total loss = 0.51, batch loss = 0.25 (265.3 examples/sec; 0.030 sec/batch; 0h:24m:57s remains)
INFO - root - 2022-02-24 20:57:02.092117: step 149840, total loss = 0.67, batch loss = 0.41 (285.6 examples/sec; 0.028 sec/batch; 0h:23m:11s remains)
INFO - root - 2022-02-24 20:57:02.403757: step 149850, total loss = 0.56, batch loss = 0.30 (140.9 examples/sec; 0.057 sec/batch; 0h:46m:59s remains)
INFO - root - 2022-02-24 20:57:02.740218: step 149860, total loss = 0.59, batch loss = 0.33 (322.5 examples/sec; 0.025 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 20:57:03.279721: step 149870, total loss = 0.57, batch loss = 0.31 (186.4 examples/sec; 0.043 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:57:03.702352: step 149880, total loss = 0.54, batch loss = 0.28 (314.9 examples/sec; 0.025 sec/batch; 0h:21m:00s remains)
INFO - root - 2022-02-24 20:57:03.987181: step 149890, total loss = 0.47, batch loss = 0.21 (245.6 examples/sec; 0.033 sec/batch; 0h:26m:56s remains)
INFO - root - 2022-02-24 20:57:04.352009: step 149900, total loss = 0.59, batch loss = 0.33 (274.6 examples/sec; 0.029 sec/batch; 0h:24m:05s remains)
INFO - root - 2022-02-24 20:57:04.826460: step 149910, total loss = 0.66, batch loss = 0.41 (98.6 examples/sec; 0.081 sec/batch; 1h:07m:03s remains)
INFO - root - 2022-02-24 20:57:05.211055: step 149920, total loss = 0.52, batch loss = 0.26 (219.7 examples/sec; 0.036 sec/batch; 0h:30m:05s remains)
INFO - root - 2022-02-24 20:57:05.638397: step 149930, total loss = 0.61, batch loss = 0.35 (348.9 examples/sec; 0.023 sec/batch; 0h:18m:56s remains)
INFO - root - 2022-02-24 20:57:06.033313: step 149940, total loss = 0.49, batch loss = 0.23 (256.7 examples/sec; 0.031 sec/batch; 0h:25m:44s remains)
INFO - root - 2022-02-24 20:57:06.351452: step 149950, total loss = 0.52, batch loss = 0.26 (332.4 examples/sec; 0.024 sec/batch; 0h:19m:52s remains)
INFO - root - 2022-02-24 20:57:06.615866: step 149960, total loss = 0.47, batch loss = 0.21 (317.2 examples/sec; 0.025 sec/batch; 0h:20m:49s remains)
INFO - root - 2022-02-24 20:57:07.031633: step 149970, total loss = 0.49, batch loss = 0.23 (153.9 examples/sec; 0.052 sec/batch; 0h:42m:54s remains)
INFO - root - 2022-02-24 20:57:07.492178: step 149980, total loss = 0.50, batch loss = 0.24 (118.0 examples/sec; 0.068 sec/batch; 0h:55m:58s remains)
INFO - root - 2022-02-24 20:57:07.898158: step 149990, total loss = 0.64, batch loss = 0.38 (134.2 examples/sec; 0.060 sec/batch; 0h:49m:10s remains)
INFO - root - 2022-02-24 20:57:08.273813: step 150000, total loss = 0.49, batch loss = 0.23 (111.0 examples/sec; 0.072 sec/batch; 0h:59m:29s remains)
INFO - root - 2022-02-24 20:57:08.686620: step 150010, total loss = 0.56, batch loss = 0.30 (150.9 examples/sec; 0.053 sec/batch; 0h:43m:44s remains)
INFO - root - 2022-02-24 20:57:09.109193: step 150020, total loss = 0.53, batch loss = 0.27 (126.9 examples/sec; 0.063 sec/batch; 0h:51m:59s remains)
INFO - root - 2022-02-24 20:57:09.557981: step 150030, total loss = 0.54, batch loss = 0.28 (277.1 examples/sec; 0.029 sec/batch; 0h:23m:47s remains)
INFO - root - 2022-02-24 20:57:09.892749: step 150040, total loss = 0.55, batch loss = 0.29 (341.7 examples/sec; 0.023 sec/batch; 0h:19m:18s remains)
INFO - root - 2022-02-24 20:57:10.251547: step 150050, total loss = 0.59, batch loss = 0.34 (335.2 examples/sec; 0.024 sec/batch; 0h:19m:40s remains)
INFO - root - 2022-02-24 20:57:10.608415: step 150060, total loss = 0.57, batch loss = 0.31 (155.3 examples/sec; 0.051 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 20:57:11.068419: step 150070, total loss = 0.54, batch loss = 0.28 (246.8 examples/sec; 0.032 sec/batch; 0h:26m:42s remains)
INFO - root - 2022-02-24 20:57:11.491087: step 150080, total loss = 0.60, batch loss = 0.34 (349.0 examples/sec; 0.023 sec/batch; 0h:18m:52s remains)
INFO - root - 2022-02-24 20:57:11.855622: step 150090, total loss = 0.58, batch loss = 0.32 (159.5 examples/sec; 0.050 sec/batch; 0h:41m:18s remains)
INFO - root - 2022-02-24 20:57:12.158684: step 150100, total loss = 0.58, batch loss = 0.32 (336.5 examples/sec; 0.024 sec/batch; 0h:19m:34s remains)
INFO - root - 2022-02-24 20:57:12.535712: step 150110, total loss = 0.57, batch loss = 0.31 (263.9 examples/sec; 0.030 sec/batch; 0h:24m:57s remains)
INFO - root - 2022-02-24 20:57:13.150548: step 150120, total loss = 0.58, batch loss = 0.32 (87.6 examples/sec; 0.091 sec/batch; 1h:15m:08s remains)
INFO - root - 2022-02-24 20:57:13.645787: step 150130, total loss = 0.53, batch loss = 0.27 (209.9 examples/sec; 0.038 sec/batch; 0h:31m:21s remains)
INFO - root - 2022-02-24 20:57:14.330189: step 150140, total loss = 0.62, batch loss = 0.36 (254.6 examples/sec; 0.031 sec/batch; 0h:25m:51s remains)
INFO - root - 2022-02-24 20:57:14.960263: step 150150, total loss = 0.55, batch loss = 0.29 (100.5 examples/sec; 0.080 sec/batch; 1h:05m:27s remains)
INFO - root - 2022-02-24 20:57:15.421957: step 150160, total loss = 0.49, batch loss = 0.24 (111.3 examples/sec; 0.072 sec/batch; 0h:59m:05s remains)
INFO - root - 2022-02-24 20:57:15.876182: step 150170, total loss = 0.54, batch loss = 0.28 (82.2 examples/sec; 0.097 sec/batch; 1h:20m:01s remains)
INFO - root - 2022-02-24 20:57:16.665705: step 150180, total loss = 0.49, batch loss = 0.23 (199.7 examples/sec; 0.040 sec/batch; 0h:32m:56s remains)
INFO - root - 2022-02-24 20:57:17.123225: step 150190, total loss = 0.46, batch loss = 0.20 (346.9 examples/sec; 0.023 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 20:57:17.575377: step 150200, total loss = 0.48, batch loss = 0.22 (131.5 examples/sec; 0.061 sec/batch; 0h:49m:59s remains)
INFO - root - 2022-02-24 20:57:18.092806: step 150210, total loss = 0.50, batch loss = 0.24 (107.9 examples/sec; 0.074 sec/batch; 1h:00m:55s remains)
INFO - root - 2022-02-24 20:57:18.474167: step 150220, total loss = 0.53, batch loss = 0.27 (280.8 examples/sec; 0.028 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:57:18.875228: step 150230, total loss = 0.51, batch loss = 0.25 (220.0 examples/sec; 0.036 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 20:57:19.206630: step 150240, total loss = 0.63, batch loss = 0.38 (323.9 examples/sec; 0.025 sec/batch; 0h:20m:16s remains)
INFO - root - 2022-02-24 20:57:19.549316: step 150250, total loss = 0.57, batch loss = 0.31 (195.9 examples/sec; 0.041 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:57:19.941934: step 150260, total loss = 0.61, batch loss = 0.35 (214.8 examples/sec; 0.037 sec/batch; 0h:30m:34s remains)
INFO - root - 2022-02-24 20:57:20.359574: step 150270, total loss = 0.57, batch loss = 0.31 (264.1 examples/sec; 0.030 sec/batch; 0h:24m:51s remains)
INFO - root - 2022-02-24 20:57:20.798670: step 150280, total loss = 0.50, batch loss = 0.25 (104.7 examples/sec; 0.076 sec/batch; 1h:02m:40s remains)
INFO - root - 2022-02-24 20:57:21.207522: step 150290, total loss = 0.46, batch loss = 0.20 (280.3 examples/sec; 0.029 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 20:57:21.504249: step 150300, total loss = 0.60, batch loss = 0.34 (339.2 examples/sec; 0.024 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 20:57:22.000788: step 150310, total loss = 0.62, batch loss = 0.36 (161.0 examples/sec; 0.050 sec/batch; 0h:40m:44s remains)
INFO - root - 2022-02-24 20:57:22.365768: step 150320, total loss = 0.64, batch loss = 0.38 (214.8 examples/sec; 0.037 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 20:57:22.744237: step 150330, total loss = 0.46, batch loss = 0.20 (158.4 examples/sec; 0.051 sec/batch; 0h:41m:23s remains)
INFO - root - 2022-02-24 20:57:23.271524: step 150340, total loss = 0.62, batch loss = 0.37 (319.0 examples/sec; 0.025 sec/batch; 0h:20m:33s remains)
INFO - root - 2022-02-24 20:57:23.685538: step 150350, total loss = 0.54, batch loss = 0.29 (115.6 examples/sec; 0.069 sec/batch; 0h:56m:41s remains)
INFO - root - 2022-02-24 20:57:24.117027: step 150360, total loss = 0.62, batch loss = 0.36 (336.5 examples/sec; 0.024 sec/batch; 0h:19m:28s remains)
INFO - root - 2022-02-24 20:57:24.591267: step 150370, total loss = 0.59, batch loss = 0.33 (348.3 examples/sec; 0.023 sec/batch; 0h:18m:48s remains)
INFO - root - 2022-02-24 20:57:24.927452: step 150380, total loss = 0.47, batch loss = 0.22 (269.1 examples/sec; 0.030 sec/batch; 0h:24m:20s remains)
INFO - root - 2022-02-24 20:57:25.372557: step 150390, total loss = 0.48, batch loss = 0.23 (128.3 examples/sec; 0.062 sec/batch; 0h:51m:03s remains)
INFO - root - 2022-02-24 20:57:25.737168: step 150400, total loss = 0.57, batch loss = 0.31 (307.5 examples/sec; 0.026 sec/batch; 0h:21m:17s remains)
INFO - root - 2022-02-24 20:57:26.280805: step 150410, total loss = 0.56, batch loss = 0.30 (215.7 examples/sec; 0.037 sec/batch; 0h:30m:20s remains)
INFO - root - 2022-02-24 20:57:26.831248: step 150420, total loss = 0.49, batch loss = 0.23 (133.4 examples/sec; 0.060 sec/batch; 0h:49m:03s remains)
INFO - root - 2022-02-24 20:57:27.095008: step 150430, total loss = 0.51, batch loss = 0.25 (297.5 examples/sec; 0.027 sec/batch; 0h:21m:59s remains)
INFO - root - 2022-02-24 20:57:27.388709: step 150440, total loss = 0.59, batch loss = 0.33 (307.7 examples/sec; 0.026 sec/batch; 0h:21m:15s remains)
INFO - root - 2022-02-24 20:57:27.739152: step 150450, total loss = 0.53, batch loss = 0.27 (324.9 examples/sec; 0.025 sec/batch; 0h:20m:07s remains)
INFO - root - 2022-02-24 20:57:28.153473: step 150460, total loss = 0.46, batch loss = 0.20 (117.2 examples/sec; 0.068 sec/batch; 0h:55m:47s remains)
INFO - root - 2022-02-24 20:57:28.596693: step 150470, total loss = 0.50, batch loss = 0.24 (324.3 examples/sec; 0.025 sec/batch; 0h:20m:09s remains)
INFO - root - 2022-02-24 20:57:28.994414: step 150480, total loss = 0.60, batch loss = 0.34 (243.3 examples/sec; 0.033 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 20:57:29.319357: step 150490, total loss = 0.62, batch loss = 0.36 (170.4 examples/sec; 0.047 sec/batch; 0h:38m:20s remains)
INFO - root - 2022-02-24 20:57:29.684242: step 150500, total loss = 0.49, batch loss = 0.23 (283.8 examples/sec; 0.028 sec/batch; 0h:23m:01s remains)
INFO - root - 2022-02-24 20:57:30.147310: step 150510, total loss = 0.54, batch loss = 0.28 (161.1 examples/sec; 0.050 sec/batch; 0h:40m:32s remains)
INFO - root - 2022-02-24 20:57:30.540198: step 150520, total loss = 0.48, batch loss = 0.22 (210.5 examples/sec; 0.038 sec/batch; 0h:31m:01s remains)
INFO - root - 2022-02-24 20:57:30.950318: step 150530, total loss = 0.55, batch loss = 0.29 (216.4 examples/sec; 0.037 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 20:57:31.262950: step 150540, total loss = 0.60, batch loss = 0.34 (350.7 examples/sec; 0.023 sec/batch; 0h:18m:36s remains)
INFO - root - 2022-02-24 20:57:31.620772: step 150550, total loss = 0.56, batch loss = 0.31 (137.2 examples/sec; 0.058 sec/batch; 0h:47m:34s remains)
INFO - root - 2022-02-24 20:57:32.050426: step 150560, total loss = 0.43, batch loss = 0.17 (129.5 examples/sec; 0.062 sec/batch; 0h:50m:22s remains)
INFO - root - 2022-02-24 20:57:32.534705: step 150570, total loss = 0.51, batch loss = 0.26 (190.3 examples/sec; 0.042 sec/batch; 0h:34m:17s remains)
INFO - root - 2022-02-24 20:57:32.893463: step 150580, total loss = 0.55, batch loss = 0.29 (176.5 examples/sec; 0.045 sec/batch; 0h:36m:57s remains)
INFO - root - 2022-02-24 20:57:33.227128: step 150590, total loss = 0.43, batch loss = 0.18 (131.5 examples/sec; 0.061 sec/batch; 0h:49m:34s remains)
INFO - root - 2022-02-24 20:57:33.552785: step 150600, total loss = 0.58, batch loss = 0.32 (166.2 examples/sec; 0.048 sec/batch; 0h:39m:13s remains)
INFO - root - 2022-02-24 20:57:33.903090: step 150610, total loss = 0.55, batch loss = 0.29 (317.7 examples/sec; 0.025 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 20:57:34.451565: step 150620, total loss = 0.58, batch loss = 0.32 (134.2 examples/sec; 0.060 sec/batch; 0h:48m:33s remains)
INFO - root - 2022-02-24 20:57:34.801763: step 150630, total loss = 0.55, batch loss = 0.30 (294.6 examples/sec; 0.027 sec/batch; 0h:22m:06s remains)
INFO - root - 2022-02-24 20:57:35.160789: step 150640, total loss = 0.49, batch loss = 0.23 (181.9 examples/sec; 0.044 sec/batch; 0h:35m:49s remains)
INFO - root - 2022-02-24 20:57:35.460400: step 150650, total loss = 0.60, batch loss = 0.34 (358.3 examples/sec; 0.022 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 20:57:35.726936: step 150660, total loss = 0.50, batch loss = 0.24 (284.7 examples/sec; 0.028 sec/batch; 0h:22m:52s remains)
INFO - root - 2022-02-24 20:57:36.168765: step 150670, total loss = 0.56, batch loss = 0.30 (340.4 examples/sec; 0.023 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 20:57:36.638476: step 150680, total loss = 0.55, batch loss = 0.29 (114.6 examples/sec; 0.070 sec/batch; 0h:56m:48s remains)
INFO - root - 2022-02-24 20:57:36.974467: step 150690, total loss = 0.55, batch loss = 0.29 (237.2 examples/sec; 0.034 sec/batch; 0h:27m:26s remains)
INFO - root - 2022-02-24 20:57:37.313335: step 150700, total loss = 0.48, batch loss = 0.22 (345.6 examples/sec; 0.023 sec/batch; 0h:18m:49s remains)
INFO - root - 2022-02-24 20:57:37.700301: step 150710, total loss = 0.57, batch loss = 0.31 (313.7 examples/sec; 0.026 sec/batch; 0h:20m:44s remains)
INFO - root - 2022-02-24 20:57:38.059239: step 150720, total loss = 0.64, batch loss = 0.38 (353.9 examples/sec; 0.023 sec/batch; 0h:18m:22s remains)
INFO - root - 2022-02-24 20:57:38.481611: step 150730, total loss = 0.54, batch loss = 0.28 (125.8 examples/sec; 0.064 sec/batch; 0h:51m:40s remains)
INFO - root - 2022-02-24 20:57:38.936213: step 150740, total loss = 0.55, batch loss = 0.29 (352.0 examples/sec; 0.023 sec/batch; 0h:18m:28s remains)
INFO - root - 2022-02-24 20:57:39.257585: step 150750, total loss = 0.52, batch loss = 0.26 (141.9 examples/sec; 0.056 sec/batch; 0h:45m:48s remains)
INFO - root - 2022-02-24 20:57:39.580249: step 150760, total loss = 0.56, batch loss = 0.31 (256.2 examples/sec; 0.031 sec/batch; 0h:25m:21s remains)
INFO - root - 2022-02-24 20:57:39.882684: step 150770, total loss = 0.55, batch loss = 0.30 (253.2 examples/sec; 0.032 sec/batch; 0h:25m:39s remains)
INFO - root - 2022-02-24 20:57:40.288641: step 150780, total loss = 0.55, batch loss = 0.29 (173.0 examples/sec; 0.046 sec/batch; 0h:37m:33s remains)
INFO - root - 2022-02-24 20:57:40.773749: step 150790, total loss = 0.52, batch loss = 0.27 (186.3 examples/sec; 0.043 sec/batch; 0h:34m:51s remains)
INFO - root - 2022-02-24 20:57:41.197249: step 150800, total loss = 0.52, batch loss = 0.27 (263.6 examples/sec; 0.030 sec/batch; 0h:24m:37s remains)
INFO - root - 2022-02-24 20:57:41.566818: step 150810, total loss = 0.50, batch loss = 0.24 (339.5 examples/sec; 0.024 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 20:57:41.912636: step 150820, total loss = 0.48, batch loss = 0.22 (331.9 examples/sec; 0.024 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 20:57:42.236583: step 150830, total loss = 0.52, batch loss = 0.27 (316.4 examples/sec; 0.025 sec/batch; 0h:20m:30s remains)
INFO - root - 2022-02-24 20:57:42.655701: step 150840, total loss = 0.54, batch loss = 0.28 (253.4 examples/sec; 0.032 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 20:57:43.067636: step 150850, total loss = 0.55, batch loss = 0.29 (343.7 examples/sec; 0.023 sec/batch; 0h:18m:52s remains)
INFO - root - 2022-02-24 20:57:43.477087: step 150860, total loss = 0.62, batch loss = 0.37 (192.1 examples/sec; 0.042 sec/batch; 0h:33m:45s remains)
INFO - root - 2022-02-24 20:57:43.902117: step 150870, total loss = 0.49, batch loss = 0.23 (210.9 examples/sec; 0.038 sec/batch; 0h:30m:44s remains)
INFO - root - 2022-02-24 20:57:44.283490: step 150880, total loss = 0.56, batch loss = 0.31 (361.0 examples/sec; 0.022 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 20:57:44.581218: step 150890, total loss = 0.55, batch loss = 0.29 (327.2 examples/sec; 0.024 sec/batch; 0h:19m:48s remains)
INFO - root - 2022-02-24 20:57:45.019555: step 150900, total loss = 0.53, batch loss = 0.27 (125.2 examples/sec; 0.064 sec/batch; 0h:51m:46s remains)
INFO - root - 2022-02-24 20:57:45.419281: step 150910, total loss = 0.61, batch loss = 0.36 (337.1 examples/sec; 0.024 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 20:57:45.742829: step 150920, total loss = 0.46, batch loss = 0.21 (185.4 examples/sec; 0.043 sec/batch; 0h:34m:56s remains)
INFO - root - 2022-02-24 20:57:46.114117: step 150930, total loss = 0.54, batch loss = 0.29 (343.5 examples/sec; 0.023 sec/batch; 0h:18m:51s remains)
INFO - root - 2022-02-24 20:57:46.428348: step 150940, total loss = 0.64, batch loss = 0.38 (134.4 examples/sec; 0.060 sec/batch; 0h:48m:09s remains)
INFO - root - 2022-02-24 20:57:46.903467: step 150950, total loss = 0.60, batch loss = 0.34 (171.1 examples/sec; 0.047 sec/batch; 0h:37m:50s remains)
INFO - root - 2022-02-24 20:57:47.336764: step 150960, total loss = 0.53, batch loss = 0.27 (179.0 examples/sec; 0.045 sec/batch; 0h:36m:09s remains)
INFO - root - 2022-02-24 20:57:47.666194: step 150970, total loss = 0.46, batch loss = 0.20 (186.3 examples/sec; 0.043 sec/batch; 0h:34m:44s remains)
INFO - root - 2022-02-24 20:57:47.958358: step 150980, total loss = 0.53, batch loss = 0.27 (299.4 examples/sec; 0.027 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 20:57:48.318186: step 150990, total loss = 0.48, batch loss = 0.22 (182.9 examples/sec; 0.044 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 20:57:48.698513: step 151000, total loss = 0.51, batch loss = 0.25 (235.8 examples/sec; 0.034 sec/batch; 0h:27m:25s remains)
INFO - root - 2022-02-24 20:57:49.191695: step 151010, total loss = 0.53, batch loss = 0.28 (166.5 examples/sec; 0.048 sec/batch; 0h:38m:49s remains)
INFO - root - 2022-02-24 20:57:49.687132: step 151020, total loss = 0.55, batch loss = 0.29 (270.0 examples/sec; 0.030 sec/batch; 0h:23m:56s remains)
INFO - root - 2022-02-24 20:57:50.267884: step 151030, total loss = 0.54, batch loss = 0.28 (60.4 examples/sec; 0.132 sec/batch; 1h:46m:58s remains)
INFO - root - 2022-02-24 20:57:50.806035: step 151040, total loss = 0.41, batch loss = 0.16 (76.8 examples/sec; 0.104 sec/batch; 1h:24m:05s remains)
INFO - root - 2022-02-24 20:57:51.193624: step 151050, total loss = 0.66, batch loss = 0.40 (145.4 examples/sec; 0.055 sec/batch; 0h:44m:25s remains)
INFO - root - 2022-02-24 20:57:52.075341: step 151060, total loss = 0.55, batch loss = 0.29 (185.9 examples/sec; 0.043 sec/batch; 0h:34m:44s remains)
INFO - root - 2022-02-24 20:57:52.437940: step 151070, total loss = 0.52, batch loss = 0.26 (164.1 examples/sec; 0.049 sec/batch; 0h:39m:21s remains)
INFO - root - 2022-02-24 20:57:52.835578: step 151080, total loss = 0.51, batch loss = 0.26 (233.9 examples/sec; 0.034 sec/batch; 0h:27m:36s remains)
INFO - root - 2022-02-24 20:57:53.218434: step 151090, total loss = 0.59, batch loss = 0.34 (255.5 examples/sec; 0.031 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 20:57:53.579464: step 151100, total loss = 0.52, batch loss = 0.26 (210.5 examples/sec; 0.038 sec/batch; 0h:30m:39s remains)
INFO - root - 2022-02-24 20:57:54.102222: step 151110, total loss = 0.56, batch loss = 0.30 (118.7 examples/sec; 0.067 sec/batch; 0h:54m:21s remains)
INFO - root - 2022-02-24 20:57:54.445719: step 151120, total loss = 0.54, batch loss = 0.29 (328.9 examples/sec; 0.024 sec/batch; 0h:19m:36s remains)
INFO - root - 2022-02-24 20:57:54.779918: step 151130, total loss = 0.48, batch loss = 0.23 (271.8 examples/sec; 0.029 sec/batch; 0h:23m:43s remains)
INFO - root - 2022-02-24 20:57:55.125659: step 151140, total loss = 0.49, batch loss = 0.23 (188.8 examples/sec; 0.042 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 20:57:55.598751: step 151150, total loss = 0.62, batch loss = 0.36 (99.3 examples/sec; 0.081 sec/batch; 1h:04m:55s remains)
INFO - root - 2022-02-24 20:57:56.025812: step 151160, total loss = 0.62, batch loss = 0.36 (294.7 examples/sec; 0.027 sec/batch; 0h:21m:52s remains)
INFO - root - 2022-02-24 20:57:56.434092: step 151170, total loss = 0.57, batch loss = 0.31 (221.9 examples/sec; 0.036 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 20:57:57.026864: step 151180, total loss = 0.49, batch loss = 0.23 (275.1 examples/sec; 0.029 sec/batch; 0h:23m:25s remains)
INFO - root - 2022-02-24 20:57:57.313950: step 151190, total loss = 0.56, batch loss = 0.31 (264.1 examples/sec; 0.030 sec/batch; 0h:24m:23s remains)
INFO - root - 2022-02-24 20:57:57.671227: step 151200, total loss = 0.61, batch loss = 0.35 (278.0 examples/sec; 0.029 sec/batch; 0h:23m:09s remains)
INFO - root - 2022-02-24 20:57:58.175482: step 151210, total loss = 0.55, batch loss = 0.30 (231.7 examples/sec; 0.035 sec/batch; 0h:27m:47s remains)
INFO - root - 2022-02-24 20:57:58.570324: step 151220, total loss = 0.53, batch loss = 0.27 (179.9 examples/sec; 0.044 sec/batch; 0h:35m:47s remains)
INFO - root - 2022-02-24 20:57:58.956488: step 151230, total loss = 0.54, batch loss = 0.28 (227.8 examples/sec; 0.035 sec/batch; 0h:28m:14s remains)
INFO - root - 2022-02-24 20:57:59.299461: step 151240, total loss = 0.59, batch loss = 0.33 (177.0 examples/sec; 0.045 sec/batch; 0h:36m:20s remains)
INFO - root - 2022-02-24 20:57:59.715239: step 151250, total loss = 0.67, batch loss = 0.41 (237.4 examples/sec; 0.034 sec/batch; 0h:27m:05s remains)
INFO - root - 2022-02-24 20:58:00.191116: step 151260, total loss = 0.67, batch loss = 0.41 (137.3 examples/sec; 0.058 sec/batch; 0h:46m:50s remains)
INFO - root - 2022-02-24 20:58:00.555308: step 151270, total loss = 0.64, batch loss = 0.38 (181.1 examples/sec; 0.044 sec/batch; 0h:35m:30s remains)
INFO - root - 2022-02-24 20:58:00.907806: step 151280, total loss = 0.48, batch loss = 0.22 (204.8 examples/sec; 0.039 sec/batch; 0h:31m:23s remains)
INFO - root - 2022-02-24 20:58:01.225906: step 151290, total loss = 0.58, batch loss = 0.32 (189.7 examples/sec; 0.042 sec/batch; 0h:33m:53s remains)
INFO - root - 2022-02-24 20:58:01.694044: step 151300, total loss = 0.54, batch loss = 0.29 (161.7 examples/sec; 0.049 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 20:58:02.116564: step 151310, total loss = 0.63, batch loss = 0.37 (151.2 examples/sec; 0.053 sec/batch; 0h:42m:30s remains)
INFO - root - 2022-02-24 20:58:02.435659: step 151320, total loss = 0.58, batch loss = 0.32 (345.1 examples/sec; 0.023 sec/batch; 0h:18m:36s remains)
INFO - root - 2022-02-24 20:58:02.800863: step 151330, total loss = 0.60, batch loss = 0.35 (217.1 examples/sec; 0.037 sec/batch; 0h:29m:34s remains)
INFO - root - 2022-02-24 20:58:03.129223: step 151340, total loss = 0.65, batch loss = 0.40 (212.9 examples/sec; 0.038 sec/batch; 0h:30m:09s remains)
INFO - root - 2022-02-24 20:58:03.556022: step 151350, total loss = 0.47, batch loss = 0.21 (161.3 examples/sec; 0.050 sec/batch; 0h:39m:47s remains)
INFO - root - 2022-02-24 20:58:03.923457: step 151360, total loss = 0.63, batch loss = 0.38 (347.5 examples/sec; 0.023 sec/batch; 0h:18m:28s remains)
INFO - root - 2022-02-24 20:58:04.296577: step 151370, total loss = 0.49, batch loss = 0.23 (353.0 examples/sec; 0.023 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 20:58:04.676581: step 151380, total loss = 0.61, batch loss = 0.35 (185.6 examples/sec; 0.043 sec/batch; 0h:34m:34s remains)
INFO - root - 2022-02-24 20:58:05.016583: step 151390, total loss = 0.54, batch loss = 0.29 (242.0 examples/sec; 0.033 sec/batch; 0h:26m:30s remains)
INFO - root - 2022-02-24 20:58:05.411081: step 151400, total loss = 0.51, batch loss = 0.26 (209.6 examples/sec; 0.038 sec/batch; 0h:30m:35s remains)
INFO - root - 2022-02-24 20:58:05.775788: step 151410, total loss = 0.50, batch loss = 0.25 (147.8 examples/sec; 0.054 sec/batch; 0h:43m:22s remains)
INFO - root - 2022-02-24 20:58:06.175806: step 151420, total loss = 0.46, batch loss = 0.21 (154.2 examples/sec; 0.052 sec/batch; 0h:41m:33s remains)
INFO - root - 2022-02-24 20:58:06.628789: step 151430, total loss = 0.54, batch loss = 0.28 (317.6 examples/sec; 0.025 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 20:58:06.992035: step 151440, total loss = 0.48, batch loss = 0.22 (229.7 examples/sec; 0.035 sec/batch; 0h:27m:53s remains)
INFO - root - 2022-02-24 20:58:07.394474: step 151450, total loss = 0.51, batch loss = 0.26 (141.9 examples/sec; 0.056 sec/batch; 0h:45m:09s remains)
INFO - root - 2022-02-24 20:58:07.700203: step 151460, total loss = 0.50, batch loss = 0.24 (378.4 examples/sec; 0.021 sec/batch; 0h:16m:55s remains)
INFO - root - 2022-02-24 20:58:08.073871: step 151470, total loss = 0.60, batch loss = 0.34 (187.9 examples/sec; 0.043 sec/batch; 0h:34m:05s remains)
INFO - root - 2022-02-24 20:58:08.444568: step 151480, total loss = 0.62, batch loss = 0.36 (141.2 examples/sec; 0.057 sec/batch; 0h:45m:20s remains)
INFO - root - 2022-02-24 20:58:08.910680: step 151490, total loss = 0.51, batch loss = 0.25 (307.5 examples/sec; 0.026 sec/batch; 0h:20m:48s remains)
INFO - root - 2022-02-24 20:58:09.277765: step 151500, total loss = 0.57, batch loss = 0.32 (331.6 examples/sec; 0.024 sec/batch; 0h:19m:18s remains)
INFO - root - 2022-02-24 20:58:09.793314: step 151510, total loss = 0.61, batch loss = 0.36 (335.3 examples/sec; 0.024 sec/batch; 0h:19m:05s remains)
INFO - root - 2022-02-24 20:58:10.279423: step 151520, total loss = 0.56, batch loss = 0.30 (178.7 examples/sec; 0.045 sec/batch; 0h:35m:48s remains)
INFO - root - 2022-02-24 20:58:10.851685: step 151530, total loss = 0.66, batch loss = 0.41 (110.9 examples/sec; 0.072 sec/batch; 0h:57m:40s remains)
INFO - root - 2022-02-24 20:58:11.399060: step 151540, total loss = 0.50, batch loss = 0.24 (123.8 examples/sec; 0.065 sec/batch; 0h:51m:39s remains)
INFO - root - 2022-02-24 20:58:11.906239: step 151550, total loss = 0.53, batch loss = 0.28 (281.0 examples/sec; 0.028 sec/batch; 0h:22m:45s remains)
INFO - root - 2022-02-24 20:58:12.398307: step 151560, total loss = 0.52, batch loss = 0.26 (198.6 examples/sec; 0.040 sec/batch; 0h:32m:11s remains)
INFO - root - 2022-02-24 20:58:12.811609: step 151570, total loss = 0.60, batch loss = 0.34 (261.5 examples/sec; 0.031 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 20:58:13.143822: step 151580, total loss = 0.50, batch loss = 0.24 (357.1 examples/sec; 0.022 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 20:58:13.445899: step 151590, total loss = 0.52, batch loss = 0.26 (296.0 examples/sec; 0.027 sec/batch; 0h:21m:34s remains)
INFO - root - 2022-02-24 20:58:13.723464: step 151600, total loss = 0.54, batch loss = 0.28 (341.8 examples/sec; 0.023 sec/batch; 0h:18m:41s remains)
INFO - root - 2022-02-24 20:58:14.275391: step 151610, total loss = 0.57, batch loss = 0.31 (114.1 examples/sec; 0.070 sec/batch; 0h:55m:58s remains)
INFO - root - 2022-02-24 20:58:14.717877: step 151620, total loss = 0.56, batch loss = 0.30 (251.7 examples/sec; 0.032 sec/batch; 0h:25m:21s remains)
INFO - root - 2022-02-24 20:58:15.067390: step 151630, total loss = 0.57, batch loss = 0.31 (208.1 examples/sec; 0.038 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 20:58:15.389893: step 151640, total loss = 0.55, batch loss = 0.29 (161.8 examples/sec; 0.049 sec/batch; 0h:39m:26s remains)
INFO - root - 2022-02-24 20:58:15.714328: step 151650, total loss = 0.63, batch loss = 0.38 (173.6 examples/sec; 0.046 sec/batch; 0h:36m:45s remains)
INFO - root - 2022-02-24 20:58:16.063359: step 151660, total loss = 0.54, batch loss = 0.28 (128.3 examples/sec; 0.062 sec/batch; 0h:49m:44s remains)
INFO - root - 2022-02-24 20:58:16.560448: step 151670, total loss = 0.71, batch loss = 0.45 (102.3 examples/sec; 0.078 sec/batch; 1h:02m:20s remains)
INFO - root - 2022-02-24 20:58:17.014270: step 151680, total loss = 0.52, batch loss = 0.27 (356.4 examples/sec; 0.022 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 20:58:17.356352: step 151690, total loss = 0.55, batch loss = 0.29 (214.9 examples/sec; 0.037 sec/batch; 0h:29m:39s remains)
INFO - root - 2022-02-24 20:58:17.693116: step 151700, total loss = 0.55, batch loss = 0.29 (356.1 examples/sec; 0.022 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 20:58:18.149880: step 151710, total loss = 0.59, batch loss = 0.33 (255.0 examples/sec; 0.031 sec/batch; 0h:24m:59s remains)
INFO - root - 2022-02-24 20:58:18.584911: step 151720, total loss = 0.58, batch loss = 0.32 (211.5 examples/sec; 0.038 sec/batch; 0h:30m:06s remains)
INFO - root - 2022-02-24 20:58:18.979601: step 151730, total loss = 0.67, batch loss = 0.41 (214.5 examples/sec; 0.037 sec/batch; 0h:29m:41s remains)
INFO - root - 2022-02-24 20:58:19.333763: step 151740, total loss = 0.54, batch loss = 0.28 (371.9 examples/sec; 0.022 sec/batch; 0h:17m:07s remains)
INFO - root - 2022-02-24 20:58:19.718944: step 151750, total loss = 0.51, batch loss = 0.25 (182.6 examples/sec; 0.044 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 20:58:20.086208: step 151760, total loss = 0.52, batch loss = 0.26 (353.3 examples/sec; 0.023 sec/batch; 0h:18m:00s remains)
INFO - root - 2022-02-24 20:58:20.558665: step 151770, total loss = 0.54, batch loss = 0.29 (345.9 examples/sec; 0.023 sec/batch; 0h:18m:24s remains)
INFO - root - 2022-02-24 20:58:21.002422: step 151780, total loss = 0.59, batch loss = 0.33 (360.1 examples/sec; 0.022 sec/batch; 0h:17m:40s remains)
INFO - root - 2022-02-24 20:58:21.331726: step 151790, total loss = 0.47, batch loss = 0.22 (267.6 examples/sec; 0.030 sec/batch; 0h:23m:46s remains)
INFO - root - 2022-02-24 20:58:21.657029: step 151800, total loss = 0.54, batch loss = 0.28 (207.1 examples/sec; 0.039 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 20:58:22.129087: step 151810, total loss = 0.57, batch loss = 0.31 (313.4 examples/sec; 0.026 sec/batch; 0h:20m:17s remains)
INFO - root - 2022-02-24 20:58:22.515457: step 151820, total loss = 0.69, batch loss = 0.43 (282.0 examples/sec; 0.028 sec/batch; 0h:22m:32s remains)
INFO - root - 2022-02-24 20:58:23.027232: step 151830, total loss = 0.59, batch loss = 0.33 (131.6 examples/sec; 0.061 sec/batch; 0h:48m:17s remains)
INFO - root - 2022-02-24 20:58:23.416602: step 151840, total loss = 0.51, batch loss = 0.25 (198.2 examples/sec; 0.040 sec/batch; 0h:32m:03s remains)
INFO - root - 2022-02-24 20:58:23.826900: step 151850, total loss = 0.67, batch loss = 0.42 (326.5 examples/sec; 0.025 sec/batch; 0h:19m:27s remains)
INFO - root - 2022-02-24 20:58:24.251304: step 151860, total loss = 0.50, batch loss = 0.24 (333.6 examples/sec; 0.024 sec/batch; 0h:19m:02s remains)
INFO - root - 2022-02-24 20:58:24.787331: step 151870, total loss = 0.57, batch loss = 0.31 (236.7 examples/sec; 0.034 sec/batch; 0h:26m:49s remains)
INFO - root - 2022-02-24 20:58:25.203557: step 151880, total loss = 0.53, batch loss = 0.27 (226.3 examples/sec; 0.035 sec/batch; 0h:28m:03s remains)
INFO - root - 2022-02-24 20:58:25.829617: step 151890, total loss = 0.66, batch loss = 0.40 (211.7 examples/sec; 0.038 sec/batch; 0h:29m:58s remains)
INFO - root - 2022-02-24 20:58:26.281918: step 151900, total loss = 0.61, batch loss = 0.35 (107.7 examples/sec; 0.074 sec/batch; 0h:58m:54s remains)
INFO - root - 2022-02-24 20:58:27.212007: step 151910, total loss = 0.51, batch loss = 0.25 (136.4 examples/sec; 0.059 sec/batch; 0h:46m:31s remains)
INFO - root - 2022-02-24 20:58:27.587783: step 151920, total loss = 0.52, batch loss = 0.26 (297.4 examples/sec; 0.027 sec/batch; 0h:21m:19s remains)
INFO - root - 2022-02-24 20:58:27.921949: step 151930, total loss = 0.70, batch loss = 0.44 (370.9 examples/sec; 0.022 sec/batch; 0h:17m:05s remains)
INFO - root - 2022-02-24 20:58:28.299574: step 151940, total loss = 0.69, batch loss = 0.43 (212.0 examples/sec; 0.038 sec/batch; 0h:29m:54s remains)
INFO - root - 2022-02-24 20:58:28.734983: step 151950, total loss = 0.48, batch loss = 0.23 (173.8 examples/sec; 0.046 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:58:29.088171: step 151960, total loss = 0.56, batch loss = 0.30 (139.2 examples/sec; 0.057 sec/batch; 0h:45m:32s remains)
INFO - root - 2022-02-24 20:58:29.474716: step 151970, total loss = 0.51, batch loss = 0.26 (252.7 examples/sec; 0.032 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 20:58:29.851970: step 151980, total loss = 0.44, batch loss = 0.18 (168.5 examples/sec; 0.047 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 20:58:30.227704: step 151990, total loss = 0.50, batch loss = 0.25 (149.6 examples/sec; 0.053 sec/batch; 0h:42m:20s remains)
INFO - root - 2022-02-24 20:58:30.571017: step 152000, total loss = 0.51, batch loss = 0.25 (167.5 examples/sec; 0.048 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 20:58:30.953761: step 152010, total loss = 0.54, batch loss = 0.29 (154.4 examples/sec; 0.052 sec/batch; 0h:41m:00s remains)
INFO - root - 2022-02-24 20:58:31.426172: step 152020, total loss = 0.61, batch loss = 0.35 (139.2 examples/sec; 0.057 sec/batch; 0h:45m:29s remains)
INFO - root - 2022-02-24 20:58:31.845372: step 152030, total loss = 0.58, batch loss = 0.32 (135.6 examples/sec; 0.059 sec/batch; 0h:46m:39s remains)
INFO - root - 2022-02-24 20:58:32.450291: step 152040, total loss = 0.65, batch loss = 0.40 (141.7 examples/sec; 0.056 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 20:58:32.738547: step 152050, total loss = 0.54, batch loss = 0.28 (182.2 examples/sec; 0.044 sec/batch; 0h:34m:42s remains)
INFO - root - 2022-02-24 20:58:33.151228: step 152060, total loss = 0.64, batch loss = 0.38 (137.9 examples/sec; 0.058 sec/batch; 0h:45m:51s remains)
INFO - root - 2022-02-24 20:58:33.543935: step 152070, total loss = 0.46, batch loss = 0.20 (301.2 examples/sec; 0.027 sec/batch; 0h:20m:59s remains)
INFO - root - 2022-02-24 20:58:33.948422: step 152080, total loss = 0.55, batch loss = 0.29 (237.7 examples/sec; 0.034 sec/batch; 0h:26m:35s remains)
INFO - root - 2022-02-24 20:58:34.378482: step 152090, total loss = 0.48, batch loss = 0.22 (204.0 examples/sec; 0.039 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 20:58:34.715133: step 152100, total loss = 0.49, batch loss = 0.23 (324.0 examples/sec; 0.025 sec/batch; 0h:19m:30s remains)
INFO - root - 2022-02-24 20:58:35.132072: step 152110, total loss = 0.54, batch loss = 0.28 (287.9 examples/sec; 0.028 sec/batch; 0h:21m:56s remains)
INFO - root - 2022-02-24 20:58:35.498242: step 152120, total loss = 0.63, batch loss = 0.38 (384.0 examples/sec; 0.021 sec/batch; 0h:16m:27s remains)
INFO - root - 2022-02-24 20:58:36.024425: step 152130, total loss = 0.52, batch loss = 0.26 (136.1 examples/sec; 0.059 sec/batch; 0h:46m:23s remains)
INFO - root - 2022-02-24 20:58:36.383630: step 152140, total loss = 0.56, batch loss = 0.30 (322.3 examples/sec; 0.025 sec/batch; 0h:19m:35s remains)
INFO - root - 2022-02-24 20:58:36.716153: step 152150, total loss = 0.53, batch loss = 0.27 (325.4 examples/sec; 0.025 sec/batch; 0h:19m:23s remains)
INFO - root - 2022-02-24 20:58:37.024357: step 152160, total loss = 0.58, batch loss = 0.32 (324.6 examples/sec; 0.025 sec/batch; 0h:19m:26s remains)
INFO - root - 2022-02-24 20:58:37.390817: step 152170, total loss = 0.52, batch loss = 0.27 (161.4 examples/sec; 0.050 sec/batch; 0h:39m:06s remains)
INFO - root - 2022-02-24 20:58:37.849852: step 152180, total loss = 0.57, batch loss = 0.32 (281.6 examples/sec; 0.028 sec/batch; 0h:22m:24s remains)
INFO - root - 2022-02-24 20:58:38.352234: step 152190, total loss = 0.60, batch loss = 0.35 (333.9 examples/sec; 0.024 sec/batch; 0h:18m:53s remains)
INFO - root - 2022-02-24 20:58:38.765166: step 152200, total loss = 0.47, batch loss = 0.22 (204.8 examples/sec; 0.039 sec/batch; 0h:30m:47s remains)
INFO - root - 2022-02-24 20:58:39.253369: step 152210, total loss = 0.51, batch loss = 0.25 (316.9 examples/sec; 0.025 sec/batch; 0h:19m:53s remains)
INFO - root - 2022-02-24 20:58:39.574027: step 152220, total loss = 0.68, batch loss = 0.43 (246.1 examples/sec; 0.033 sec/batch; 0h:25m:37s remains)
INFO - root - 2022-02-24 20:58:39.960682: step 152230, total loss = 0.50, batch loss = 0.24 (126.8 examples/sec; 0.063 sec/batch; 0h:49m:43s remains)
INFO - root - 2022-02-24 20:58:40.439955: step 152240, total loss = 0.50, batch loss = 0.24 (313.3 examples/sec; 0.026 sec/batch; 0h:20m:06s remains)
INFO - root - 2022-02-24 20:58:40.772738: step 152250, total loss = 0.53, batch loss = 0.27 (285.5 examples/sec; 0.028 sec/batch; 0h:22m:04s remains)
INFO - root - 2022-02-24 20:58:41.106063: step 152260, total loss = 0.59, batch loss = 0.34 (295.1 examples/sec; 0.027 sec/batch; 0h:21m:20s remains)
INFO - root - 2022-02-24 20:58:41.445260: step 152270, total loss = 0.54, batch loss = 0.28 (266.7 examples/sec; 0.030 sec/batch; 0h:23m:36s remains)
INFO - root - 2022-02-24 20:58:41.730629: step 152280, total loss = 0.50, batch loss = 0.25 (187.4 examples/sec; 0.043 sec/batch; 0h:33m:35s remains)
INFO - root - 2022-02-24 20:58:42.124421: step 152290, total loss = 0.60, batch loss = 0.34 (107.1 examples/sec; 0.075 sec/batch; 0h:58m:46s remains)
INFO - root - 2022-02-24 20:58:42.462245: step 152300, total loss = 0.54, batch loss = 0.29 (87.2 examples/sec; 0.092 sec/batch; 1h:12m:10s remains)
INFO - root - 2022-02-24 20:58:42.964937: step 152310, total loss = 0.52, batch loss = 0.26 (99.7 examples/sec; 0.080 sec/batch; 1h:03m:07s remains)
INFO - root - 2022-02-24 20:58:43.700792: step 152320, total loss = 0.72, batch loss = 0.46 (222.7 examples/sec; 0.036 sec/batch; 0h:28m:15s remains)
INFO - root - 2022-02-24 20:58:44.584492: step 152330, total loss = 0.59, batch loss = 0.33 (60.4 examples/sec; 0.133 sec/batch; 1h:44m:10s remains)
INFO - root - 2022-02-24 20:58:44.909415: step 152340, total loss = 0.59, batch loss = 0.33 (357.9 examples/sec; 0.022 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 20:58:45.353906: step 152350, total loss = 0.51, batch loss = 0.25 (281.7 examples/sec; 0.028 sec/batch; 0h:22m:19s remains)
INFO - root - 2022-02-24 20:58:45.909916: step 152360, total loss = 0.53, batch loss = 0.27 (236.2 examples/sec; 0.034 sec/batch; 0h:26m:36s remains)
INFO - root - 2022-02-24 20:58:46.466281: step 152370, total loss = 0.59, batch loss = 0.33 (101.4 examples/sec; 0.079 sec/batch; 1h:01m:56s remains)
INFO - root - 2022-02-24 20:58:47.172025: step 152380, total loss = 0.51, batch loss = 0.25 (100.6 examples/sec; 0.080 sec/batch; 1h:02m:27s remains)
INFO - root - 2022-02-24 20:58:47.811051: step 152390, total loss = 0.50, batch loss = 0.24 (128.9 examples/sec; 0.062 sec/batch; 0h:48m:44s remains)
INFO - root - 2022-02-24 20:58:48.259609: step 152400, total loss = 0.54, batch loss = 0.28 (123.7 examples/sec; 0.065 sec/batch; 0h:50m:46s remains)
INFO - root - 2022-02-24 20:58:48.887718: step 152410, total loss = 0.53, batch loss = 0.27 (330.4 examples/sec; 0.024 sec/batch; 0h:19m:00s remains)
INFO - root - 2022-02-24 20:58:49.570317: step 152420, total loss = 0.51, batch loss = 0.25 (325.5 examples/sec; 0.025 sec/batch; 0h:19m:17s remains)
INFO - root - 2022-02-24 20:58:50.203271: step 152430, total loss = 0.53, batch loss = 0.27 (187.1 examples/sec; 0.043 sec/batch; 0h:33m:32s remains)
INFO - root - 2022-02-24 20:58:50.674510: step 152440, total loss = 0.48, batch loss = 0.23 (358.5 examples/sec; 0.022 sec/batch; 0h:17m:30s remains)
INFO - root - 2022-02-24 20:58:51.298342: step 152450, total loss = 0.60, batch loss = 0.35 (211.0 examples/sec; 0.038 sec/batch; 0h:29m:43s remains)
INFO - root - 2022-02-24 20:58:51.893045: step 152460, total loss = 0.48, batch loss = 0.23 (275.1 examples/sec; 0.029 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 20:58:52.325144: step 152470, total loss = 0.51, batch loss = 0.25 (117.6 examples/sec; 0.068 sec/batch; 0h:53m:19s remains)
INFO - root - 2022-02-24 20:58:52.904815: step 152480, total loss = 0.50, batch loss = 0.24 (147.6 examples/sec; 0.054 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:58:53.475681: step 152490, total loss = 0.64, batch loss = 0.38 (183.2 examples/sec; 0.044 sec/batch; 0h:34m:12s remains)
INFO - root - 2022-02-24 20:58:53.966141: step 152500, total loss = 0.56, batch loss = 0.30 (183.8 examples/sec; 0.044 sec/batch; 0h:34m:05s remains)
INFO - root - 2022-02-24 20:58:54.440039: step 152510, total loss = 0.59, batch loss = 0.34 (141.9 examples/sec; 0.056 sec/batch; 0h:44m:08s remains)
INFO - root - 2022-02-24 20:58:55.125038: step 152520, total loss = 0.52, batch loss = 0.26 (187.9 examples/sec; 0.043 sec/batch; 0h:33m:20s remains)
INFO - root - 2022-02-24 20:58:55.461846: step 152530, total loss = 0.63, batch loss = 0.38 (209.0 examples/sec; 0.038 sec/batch; 0h:29m:57s remains)
INFO - root - 2022-02-24 20:58:55.795764: step 152540, total loss = 0.55, batch loss = 0.29 (320.3 examples/sec; 0.025 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 20:58:56.136913: step 152550, total loss = 0.60, batch loss = 0.34 (228.4 examples/sec; 0.035 sec/batch; 0h:27m:24s remains)
INFO - root - 2022-02-24 20:58:56.509889: step 152560, total loss = 0.56, batch loss = 0.30 (306.5 examples/sec; 0.026 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 20:58:56.902510: step 152570, total loss = 0.54, batch loss = 0.29 (195.1 examples/sec; 0.041 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:58:57.247925: step 152580, total loss = 0.48, batch loss = 0.22 (147.3 examples/sec; 0.054 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:58:57.540398: step 152590, total loss = 0.52, batch loss = 0.26 (246.4 examples/sec; 0.032 sec/batch; 0h:25m:23s remains)
INFO - root - 2022-02-24 20:58:57.828695: step 152600, total loss = 0.48, batch loss = 0.23 (327.7 examples/sec; 0.024 sec/batch; 0h:19m:05s remains)
INFO - root - 2022-02-24 20:58:58.313506: step 152610, total loss = 0.63, batch loss = 0.37 (121.7 examples/sec; 0.066 sec/batch; 0h:51m:23s remains)
INFO - root - 2022-02-24 20:58:58.744271: step 152620, total loss = 0.48, batch loss = 0.23 (212.8 examples/sec; 0.038 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 20:58:59.155615: step 152630, total loss = 0.55, batch loss = 0.29 (322.0 examples/sec; 0.025 sec/batch; 0h:19m:24s remains)
INFO - root - 2022-02-24 20:58:59.618214: step 152640, total loss = 0.57, batch loss = 0.31 (62.7 examples/sec; 0.128 sec/batch; 1h:39m:40s remains)
INFO - root - 2022-02-24 20:59:00.012894: step 152650, total loss = 0.63, batch loss = 0.37 (211.6 examples/sec; 0.038 sec/batch; 0h:29m:31s remains)
INFO - root - 2022-02-24 20:59:00.571804: step 152660, total loss = 0.51, batch loss = 0.25 (166.9 examples/sec; 0.048 sec/batch; 0h:37m:25s remains)
INFO - root - 2022-02-24 20:59:01.020009: step 152670, total loss = 0.51, batch loss = 0.25 (303.3 examples/sec; 0.026 sec/batch; 0h:20m:35s remains)
INFO - root - 2022-02-24 20:59:01.545274: step 152680, total loss = 0.59, batch loss = 0.33 (250.6 examples/sec; 0.032 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 20:59:01.897186: step 152690, total loss = 0.51, batch loss = 0.25 (211.8 examples/sec; 0.038 sec/batch; 0h:29m:28s remains)
INFO - root - 2022-02-24 20:59:02.396405: step 152700, total loss = 0.54, batch loss = 0.29 (334.6 examples/sec; 0.024 sec/batch; 0h:18m:39s remains)
INFO - root - 2022-02-24 20:59:02.951129: step 152710, total loss = 0.53, batch loss = 0.28 (110.8 examples/sec; 0.072 sec/batch; 0h:56m:19s remains)
INFO - root - 2022-02-24 20:59:03.791788: step 152720, total loss = 0.51, batch loss = 0.25 (229.7 examples/sec; 0.035 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 20:59:04.162109: step 152730, total loss = 0.65, batch loss = 0.39 (327.7 examples/sec; 0.024 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 20:59:04.551456: step 152740, total loss = 0.57, batch loss = 0.31 (128.9 examples/sec; 0.062 sec/batch; 0h:48m:21s remains)
INFO - root - 2022-02-24 20:59:04.908167: step 152750, total loss = 0.61, batch loss = 0.36 (218.9 examples/sec; 0.037 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 20:59:05.366773: step 152760, total loss = 0.48, batch loss = 0.22 (188.2 examples/sec; 0.042 sec/batch; 0h:33m:06s remains)
INFO - root - 2022-02-24 20:59:05.825270: step 152770, total loss = 0.48, batch loss = 0.23 (188.7 examples/sec; 0.042 sec/batch; 0h:33m:00s remains)
INFO - root - 2022-02-24 20:59:06.260495: step 152780, total loss = 0.53, batch loss = 0.27 (325.2 examples/sec; 0.025 sec/batch; 0h:19m:09s remains)
INFO - root - 2022-02-24 20:59:06.595316: step 152790, total loss = 0.50, batch loss = 0.24 (320.0 examples/sec; 0.025 sec/batch; 0h:19m:27s remains)
INFO - root - 2022-02-24 20:59:06.926474: step 152800, total loss = 0.52, batch loss = 0.26 (154.6 examples/sec; 0.052 sec/batch; 0h:40m:17s remains)
INFO - root - 2022-02-24 20:59:07.558294: step 152810, total loss = 0.62, batch loss = 0.36 (138.4 examples/sec; 0.058 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 20:59:07.971466: step 152820, total loss = 0.49, batch loss = 0.24 (166.9 examples/sec; 0.048 sec/batch; 0h:37m:16s remains)
INFO - root - 2022-02-24 20:59:08.380235: step 152830, total loss = 0.55, batch loss = 0.29 (176.4 examples/sec; 0.045 sec/batch; 0h:35m:16s remains)
INFO - root - 2022-02-24 20:59:08.923367: step 152840, total loss = 0.58, batch loss = 0.32 (242.9 examples/sec; 0.033 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 20:59:09.436551: step 152850, total loss = 0.49, batch loss = 0.23 (305.9 examples/sec; 0.026 sec/batch; 0h:20m:20s remains)
INFO - root - 2022-02-24 20:59:09.880364: step 152860, total loss = 0.54, batch loss = 0.28 (185.5 examples/sec; 0.043 sec/batch; 0h:33m:31s remains)
INFO - root - 2022-02-24 20:59:10.209955: step 152870, total loss = 0.56, batch loss = 0.30 (338.0 examples/sec; 0.024 sec/batch; 0h:18m:23s remains)
INFO - root - 2022-02-24 20:59:10.534301: step 152880, total loss = 0.54, batch loss = 0.28 (327.7 examples/sec; 0.024 sec/batch; 0h:18m:58s remains)
INFO - root - 2022-02-24 20:59:10.928451: step 152890, total loss = 0.50, batch loss = 0.25 (133.0 examples/sec; 0.060 sec/batch; 0h:46m:43s remains)
INFO - root - 2022-02-24 20:59:11.316353: step 152900, total loss = 0.50, batch loss = 0.24 (129.2 examples/sec; 0.062 sec/batch; 0h:48m:04s remains)
INFO - root - 2022-02-24 20:59:11.802817: step 152910, total loss = 0.48, batch loss = 0.22 (295.8 examples/sec; 0.027 sec/batch; 0h:21m:00s remains)
INFO - root - 2022-02-24 20:59:12.179453: step 152920, total loss = 0.50, batch loss = 0.24 (171.5 examples/sec; 0.047 sec/batch; 0h:36m:12s remains)
INFO - root - 2022-02-24 20:59:12.519973: step 152930, total loss = 0.58, batch loss = 0.32 (345.5 examples/sec; 0.023 sec/batch; 0h:17m:58s remains)
INFO - root - 2022-02-24 20:59:12.873076: step 152940, total loss = 0.48, batch loss = 0.22 (188.3 examples/sec; 0.042 sec/batch; 0h:32m:57s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-152949 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-152949 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 20:59:13.738027: step 152950, total loss = 0.47, batch loss = 0.22 (370.2 examples/sec; 0.022 sec/batch; 0h:16m:46s remains)
INFO - root - 2022-02-24 20:59:13.979694: step 152960, total loss = 0.58, batch loss = 0.32 (372.9 examples/sec; 0.021 sec/batch; 0h:16m:38s remains)
INFO - root - 2022-02-24 20:59:14.332634: step 152970, total loss = 0.43, batch loss = 0.18 (224.0 examples/sec; 0.036 sec/batch; 0h:27m:41s remains)
INFO - root - 2022-02-24 20:59:14.589080: step 152980, total loss = 0.59, batch loss = 0.33 (349.8 examples/sec; 0.023 sec/batch; 0h:17m:43s remains)
INFO - root - 2022-02-24 20:59:14.997688: step 152990, total loss = 0.60, batch loss = 0.35 (143.0 examples/sec; 0.056 sec/batch; 0h:43m:22s remains)
INFO - root - 2022-02-24 20:59:15.348652: step 153000, total loss = 0.48, batch loss = 0.22 (322.7 examples/sec; 0.025 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 20:59:15.934244: step 153010, total loss = 0.81, batch loss = 0.56 (160.7 examples/sec; 0.050 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 20:59:16.292317: step 153020, total loss = 0.57, batch loss = 0.31 (119.1 examples/sec; 0.067 sec/batch; 0h:52m:01s remains)
INFO - root - 2022-02-24 20:59:16.644920: step 153030, total loss = 0.46, batch loss = 0.20 (164.0 examples/sec; 0.049 sec/batch; 0h:37m:46s remains)
INFO - root - 2022-02-24 20:59:16.996909: step 153040, total loss = 0.52, batch loss = 0.26 (343.7 examples/sec; 0.023 sec/batch; 0h:18m:01s remains)
INFO - root - 2022-02-24 20:59:17.410665: step 153050, total loss = 0.52, batch loss = 0.26 (147.7 examples/sec; 0.054 sec/batch; 0h:41m:56s remains)
INFO - root - 2022-02-24 20:59:17.953278: step 153060, total loss = 0.58, batch loss = 0.32 (177.2 examples/sec; 0.045 sec/batch; 0h:34m:57s remains)
INFO - root - 2022-02-24 20:59:18.457088: step 153070, total loss = 0.53, batch loss = 0.27 (161.7 examples/sec; 0.049 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 20:59:18.845179: step 153080, total loss = 0.55, batch loss = 0.29 (130.7 examples/sec; 0.061 sec/batch; 0h:47m:22s remains)
INFO - root - 2022-02-24 20:59:19.248784: step 153090, total loss = 0.52, batch loss = 0.26 (192.3 examples/sec; 0.042 sec/batch; 0h:32m:10s remains)
INFO - root - 2022-02-24 20:59:19.720029: step 153100, total loss = 0.52, batch loss = 0.26 (224.4 examples/sec; 0.036 sec/batch; 0h:27m:33s remains)
INFO - root - 2022-02-24 20:59:20.141776: step 153110, total loss = 0.60, batch loss = 0.35 (78.7 examples/sec; 0.102 sec/batch; 1h:18m:34s remains)
INFO - root - 2022-02-24 20:59:20.549864: step 153120, total loss = 0.61, batch loss = 0.35 (357.1 examples/sec; 0.022 sec/batch; 0h:17m:19s remains)
INFO - root - 2022-02-24 20:59:20.877759: step 153130, total loss = 0.65, batch loss = 0.40 (141.8 examples/sec; 0.056 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 20:59:21.210106: step 153140, total loss = 0.55, batch loss = 0.29 (312.7 examples/sec; 0.026 sec/batch; 0h:19m:46s remains)
INFO - root - 2022-02-24 20:59:21.531543: step 153150, total loss = 0.52, batch loss = 0.26 (288.2 examples/sec; 0.028 sec/batch; 0h:21m:26s remains)
INFO - root - 2022-02-24 20:59:21.981852: step 153160, total loss = 0.47, batch loss = 0.21 (210.7 examples/sec; 0.038 sec/batch; 0h:29m:19s remains)
INFO - root - 2022-02-24 20:59:22.424650: step 153170, total loss = 0.44, batch loss = 0.19 (199.3 examples/sec; 0.040 sec/batch; 0h:31m:00s remains)
INFO - root - 2022-02-24 20:59:22.700322: step 153180, total loss = 0.64, batch loss = 0.38 (340.9 examples/sec; 0.023 sec/batch; 0h:18m:06s remains)
INFO - root - 2022-02-24 20:59:23.036706: step 153190, total loss = 0.49, batch loss = 0.23 (287.8 examples/sec; 0.028 sec/batch; 0h:21m:27s remains)
INFO - root - 2022-02-24 20:59:23.369741: step 153200, total loss = 0.46, batch loss = 0.20 (341.6 examples/sec; 0.023 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 20:59:23.817555: step 153210, total loss = 0.52, batch loss = 0.26 (275.1 examples/sec; 0.029 sec/batch; 0h:22m:26s remains)
INFO - root - 2022-02-24 20:59:24.249493: step 153220, total loss = 0.61, batch loss = 0.36 (229.5 examples/sec; 0.035 sec/batch; 0h:26m:53s remains)
INFO - root - 2022-02-24 20:59:24.674607: step 153230, total loss = 0.65, batch loss = 0.39 (317.6 examples/sec; 0.025 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 20:59:24.991356: step 153240, total loss = 0.57, batch loss = 0.31 (300.2 examples/sec; 0.027 sec/batch; 0h:20m:32s remains)
INFO - root - 2022-02-24 20:59:25.327154: step 153250, total loss = 0.50, batch loss = 0.24 (317.1 examples/sec; 0.025 sec/batch; 0h:19m:26s remains)
INFO - root - 2022-02-24 20:59:25.663979: step 153260, total loss = 0.55, batch loss = 0.30 (294.3 examples/sec; 0.027 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 20:59:26.050589: step 153270, total loss = 0.69, batch loss = 0.43 (346.3 examples/sec; 0.023 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 20:59:26.490566: step 153280, total loss = 0.54, batch loss = 0.28 (209.7 examples/sec; 0.038 sec/batch; 0h:29m:23s remains)
INFO - root - 2022-02-24 20:59:26.836392: step 153290, total loss = 0.51, batch loss = 0.25 (352.6 examples/sec; 0.023 sec/batch; 0h:17m:28s remains)
INFO - root - 2022-02-24 20:59:27.198375: step 153300, total loss = 0.47, batch loss = 0.22 (335.0 examples/sec; 0.024 sec/batch; 0h:18m:23s remains)
INFO - root - 2022-02-24 20:59:27.596977: step 153310, total loss = 0.59, batch loss = 0.33 (309.4 examples/sec; 0.026 sec/batch; 0h:19m:54s remains)
INFO - root - 2022-02-24 20:59:27.920877: step 153320, total loss = 0.59, batch loss = 0.34 (172.5 examples/sec; 0.046 sec/batch; 0h:35m:41s remains)
INFO - root - 2022-02-24 20:59:28.326257: step 153330, total loss = 0.52, batch loss = 0.26 (251.9 examples/sec; 0.032 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 20:59:28.817319: step 153340, total loss = 0.52, batch loss = 0.26 (94.2 examples/sec; 0.085 sec/batch; 1h:05m:20s remains)
INFO - root - 2022-02-24 20:59:29.286057: step 153350, total loss = 0.51, batch loss = 0.25 (325.8 examples/sec; 0.025 sec/batch; 0h:18m:53s remains)
INFO - root - 2022-02-24 20:59:29.580658: step 153360, total loss = 0.53, batch loss = 0.27 (268.3 examples/sec; 0.030 sec/batch; 0h:22m:55s remains)
INFO - root - 2022-02-24 20:59:29.900314: step 153370, total loss = 0.57, batch loss = 0.31 (283.7 examples/sec; 0.028 sec/batch; 0h:21m:40s remains)
INFO - root - 2022-02-24 20:59:30.231631: step 153380, total loss = 0.51, batch loss = 0.25 (331.1 examples/sec; 0.024 sec/batch; 0h:18m:34s remains)
INFO - root - 2022-02-24 20:59:30.587989: step 153390, total loss = 0.60, batch loss = 0.34 (137.2 examples/sec; 0.058 sec/batch; 0h:44m:48s remains)
INFO - root - 2022-02-24 20:59:31.079413: step 153400, total loss = 0.59, batch loss = 0.33 (61.9 examples/sec; 0.129 sec/batch; 1h:39m:21s remains)
INFO - root - 2022-02-24 20:59:31.590265: step 153410, total loss = 0.62, batch loss = 0.37 (173.0 examples/sec; 0.046 sec/batch; 0h:35m:31s remains)
INFO - root - 2022-02-24 20:59:31.958893: step 153420, total loss = 0.49, batch loss = 0.24 (270.2 examples/sec; 0.030 sec/batch; 0h:22m:44s remains)
INFO - root - 2022-02-24 20:59:32.315248: step 153430, total loss = 0.59, batch loss = 0.33 (196.3 examples/sec; 0.041 sec/batch; 0h:31m:17s remains)
INFO - root - 2022-02-24 20:59:32.681807: step 153440, total loss = 0.47, batch loss = 0.21 (167.7 examples/sec; 0.048 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 20:59:33.165570: step 153450, total loss = 0.63, batch loss = 0.37 (168.4 examples/sec; 0.047 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 20:59:33.593999: step 153460, total loss = 0.61, batch loss = 0.36 (377.9 examples/sec; 0.021 sec/batch; 0h:16m:14s remains)
INFO - root - 2022-02-24 20:59:33.897579: step 153470, total loss = 0.55, batch loss = 0.29 (209.0 examples/sec; 0.038 sec/batch; 0h:29m:21s remains)
INFO - root - 2022-02-24 20:59:34.316397: step 153480, total loss = 0.60, batch loss = 0.34 (253.0 examples/sec; 0.032 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 20:59:34.660766: step 153490, total loss = 0.47, batch loss = 0.22 (249.6 examples/sec; 0.032 sec/batch; 0h:24m:34s remains)
INFO - root - 2022-02-24 20:59:35.039924: step 153500, total loss = 0.47, batch loss = 0.22 (144.4 examples/sec; 0.055 sec/batch; 0h:42m:27s remains)
INFO - root - 2022-02-24 20:59:35.569198: step 153510, total loss = 0.58, batch loss = 0.33 (167.0 examples/sec; 0.048 sec/batch; 0h:36m:43s remains)
INFO - root - 2022-02-24 20:59:36.137790: step 153520, total loss = 0.56, batch loss = 0.30 (168.1 examples/sec; 0.048 sec/batch; 0h:36m:28s remains)
INFO - root - 2022-02-24 20:59:36.670941: step 153530, total loss = 0.58, batch loss = 0.32 (110.8 examples/sec; 0.072 sec/batch; 0h:55m:20s remains)
INFO - root - 2022-02-24 20:59:37.104894: step 153540, total loss = 0.49, batch loss = 0.23 (265.8 examples/sec; 0.030 sec/batch; 0h:23m:03s remains)
INFO - root - 2022-02-24 20:59:37.595144: step 153550, total loss = 0.51, batch loss = 0.26 (98.6 examples/sec; 0.081 sec/batch; 1h:02m:09s remains)
INFO - root - 2022-02-24 20:59:38.234735: step 153560, total loss = 0.51, batch loss = 0.25 (182.9 examples/sec; 0.044 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 20:59:38.877475: step 153570, total loss = 0.65, batch loss = 0.39 (329.7 examples/sec; 0.024 sec/batch; 0h:18m:34s remains)
INFO - root - 2022-02-24 20:59:39.842693: step 153580, total loss = 0.56, batch loss = 0.30 (229.8 examples/sec; 0.035 sec/batch; 0h:26m:38s remains)
INFO - root - 2022-02-24 20:59:40.317155: step 153590, total loss = 0.47, batch loss = 0.21 (240.5 examples/sec; 0.033 sec/batch; 0h:25m:27s remains)
INFO - root - 2022-02-24 20:59:40.849877: step 153600, total loss = 0.54, batch loss = 0.28 (154.4 examples/sec; 0.052 sec/batch; 0h:39m:37s remains)
INFO - root - 2022-02-24 20:59:41.270906: step 153610, total loss = 0.51, batch loss = 0.25 (292.1 examples/sec; 0.027 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 20:59:41.693721: step 153620, total loss = 0.46, batch loss = 0.21 (304.8 examples/sec; 0.026 sec/batch; 0h:20m:04s remains)
INFO - root - 2022-02-24 20:59:42.013898: step 153630, total loss = 0.59, batch loss = 0.33 (190.6 examples/sec; 0.042 sec/batch; 0h:32m:04s remains)
INFO - root - 2022-02-24 20:59:42.425263: step 153640, total loss = 0.49, batch loss = 0.24 (219.5 examples/sec; 0.036 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 20:59:42.798622: step 153650, total loss = 0.58, batch loss = 0.32 (321.4 examples/sec; 0.025 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 20:59:43.142726: step 153660, total loss = 0.56, batch loss = 0.30 (213.9 examples/sec; 0.037 sec/batch; 0h:28m:34s remains)
INFO - root - 2022-02-24 20:59:43.519985: step 153670, total loss = 0.58, batch loss = 0.32 (174.1 examples/sec; 0.046 sec/batch; 0h:35m:05s remains)
INFO - root - 2022-02-24 20:59:43.839397: step 153680, total loss = 0.49, batch loss = 0.23 (313.1 examples/sec; 0.026 sec/batch; 0h:19m:30s remains)
INFO - root - 2022-02-24 20:59:44.209758: step 153690, total loss = 0.72, batch loss = 0.46 (169.5 examples/sec; 0.047 sec/batch; 0h:36m:02s remains)
INFO - root - 2022-02-24 20:59:44.747709: step 153700, total loss = 0.49, batch loss = 0.24 (203.1 examples/sec; 0.039 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 20:59:45.274470: step 153710, total loss = 0.59, batch loss = 0.33 (123.0 examples/sec; 0.065 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 20:59:45.650335: step 153720, total loss = 0.65, batch loss = 0.40 (314.3 examples/sec; 0.025 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 20:59:45.966182: step 153730, total loss = 0.50, batch loss = 0.24 (280.3 examples/sec; 0.029 sec/batch; 0h:21m:46s remains)
INFO - root - 2022-02-24 20:59:46.265165: step 153740, total loss = 0.50, batch loss = 0.25 (335.1 examples/sec; 0.024 sec/batch; 0h:18m:12s remains)
INFO - root - 2022-02-24 20:59:46.600505: step 153750, total loss = 0.52, batch loss = 0.27 (225.8 examples/sec; 0.035 sec/batch; 0h:27m:00s remains)
INFO - root - 2022-02-24 20:59:47.108007: step 153760, total loss = 0.47, batch loss = 0.21 (116.8 examples/sec; 0.069 sec/batch; 0h:52m:14s remains)
INFO - root - 2022-02-24 20:59:47.472427: step 153770, total loss = 0.54, batch loss = 0.28 (185.0 examples/sec; 0.043 sec/batch; 0h:32m:57s remains)
INFO - root - 2022-02-24 20:59:47.868577: step 153780, total loss = 0.48, batch loss = 0.22 (175.3 examples/sec; 0.046 sec/batch; 0h:34m:45s remains)
INFO - root - 2022-02-24 20:59:48.205001: step 153790, total loss = 0.59, batch loss = 0.33 (297.7 examples/sec; 0.027 sec/batch; 0h:20m:28s remains)
INFO - root - 2022-02-24 20:59:48.487446: step 153800, total loss = 0.60, batch loss = 0.35 (316.8 examples/sec; 0.025 sec/batch; 0h:19m:14s remains)
INFO - root - 2022-02-24 20:59:48.890867: step 153810, total loss = 0.53, batch loss = 0.27 (147.7 examples/sec; 0.054 sec/batch; 0h:41m:14s remains)
INFO - root - 2022-02-24 20:59:49.257551: step 153820, total loss = 0.49, batch loss = 0.23 (194.9 examples/sec; 0.041 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 20:59:49.733764: step 153830, total loss = 0.54, batch loss = 0.28 (320.4 examples/sec; 0.025 sec/batch; 0h:19m:00s remains)
INFO - root - 2022-02-24 20:59:50.178443: step 153840, total loss = 0.57, batch loss = 0.31 (163.1 examples/sec; 0.049 sec/batch; 0h:37m:20s remains)
INFO - root - 2022-02-24 20:59:50.484283: step 153850, total loss = 0.51, batch loss = 0.25 (329.4 examples/sec; 0.024 sec/batch; 0h:18m:28s remains)
INFO - root - 2022-02-24 20:59:50.855741: step 153860, total loss = 0.57, batch loss = 0.32 (188.6 examples/sec; 0.042 sec/batch; 0h:32m:15s remains)
INFO - root - 2022-02-24 20:59:51.244661: step 153870, total loss = 0.51, batch loss = 0.25 (221.9 examples/sec; 0.036 sec/batch; 0h:27m:25s remains)
INFO - root - 2022-02-24 20:59:51.672067: step 153880, total loss = 0.50, batch loss = 0.24 (244.2 examples/sec; 0.033 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 20:59:52.118057: step 153890, total loss = 0.42, batch loss = 0.16 (172.2 examples/sec; 0.046 sec/batch; 0h:35m:18s remains)
INFO - root - 2022-02-24 20:59:52.431837: step 153900, total loss = 0.50, batch loss = 0.24 (355.4 examples/sec; 0.023 sec/batch; 0h:17m:06s remains)
INFO - root - 2022-02-24 20:59:52.854573: step 153910, total loss = 0.50, batch loss = 0.24 (290.3 examples/sec; 0.028 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 20:59:53.126925: step 153920, total loss = 0.69, batch loss = 0.44 (309.5 examples/sec; 0.026 sec/batch; 0h:19m:38s remains)
INFO - root - 2022-02-24 20:59:53.482316: step 153930, total loss = 0.45, batch loss = 0.19 (391.5 examples/sec; 0.020 sec/batch; 0h:15m:31s remains)
INFO - root - 2022-02-24 20:59:53.969811: step 153940, total loss = 0.64, batch loss = 0.38 (200.7 examples/sec; 0.040 sec/batch; 0h:30m:15s remains)
INFO - root - 2022-02-24 20:59:54.304102: step 153950, total loss = 0.55, batch loss = 0.30 (327.0 examples/sec; 0.024 sec/batch; 0h:18m:34s remains)
INFO - root - 2022-02-24 20:59:54.657578: step 153960, total loss = 0.48, batch loss = 0.22 (316.3 examples/sec; 0.025 sec/batch; 0h:19m:11s remains)
INFO - root - 2022-02-24 20:59:55.068383: step 153970, total loss = 0.49, batch loss = 0.23 (157.9 examples/sec; 0.051 sec/batch; 0h:38m:27s remains)
INFO - root - 2022-02-24 20:59:55.446338: step 153980, total loss = 0.64, batch loss = 0.39 (323.6 examples/sec; 0.025 sec/batch; 0h:18m:45s remains)
INFO - root - 2022-02-24 20:59:55.927804: step 153990, total loss = 0.49, batch loss = 0.23 (132.3 examples/sec; 0.060 sec/batch; 0h:45m:51s remains)
INFO - root - 2022-02-24 20:59:56.350699: step 154000, total loss = 0.46, batch loss = 0.20 (294.7 examples/sec; 0.027 sec/batch; 0h:20m:35s remains)
INFO - root - 2022-02-24 20:59:56.738264: step 154010, total loss = 0.67, batch loss = 0.41 (320.7 examples/sec; 0.025 sec/batch; 0h:18m:54s remains)
INFO - root - 2022-02-24 20:59:57.127185: step 154020, total loss = 0.57, batch loss = 0.31 (352.1 examples/sec; 0.023 sec/batch; 0h:17m:13s remains)
INFO - root - 2022-02-24 20:59:57.526954: step 154030, total loss = 0.65, batch loss = 0.39 (186.5 examples/sec; 0.043 sec/batch; 0h:32m:30s remains)
INFO - root - 2022-02-24 20:59:57.991296: step 154040, total loss = 0.64, batch loss = 0.38 (152.8 examples/sec; 0.052 sec/batch; 0h:39m:40s remains)
INFO - root - 2022-02-24 20:59:58.460155: step 154050, total loss = 0.46, batch loss = 0.21 (184.9 examples/sec; 0.043 sec/batch; 0h:32m:46s remains)
INFO - root - 2022-02-24 20:59:58.752300: step 154060, total loss = 0.51, batch loss = 0.25 (322.3 examples/sec; 0.025 sec/batch; 0h:18m:47s remains)
INFO - root - 2022-02-24 20:59:59.104541: step 154070, total loss = 0.48, batch loss = 0.22 (194.6 examples/sec; 0.041 sec/batch; 0h:31m:07s remains)
INFO - root - 2022-02-24 20:59:59.447197: step 154080, total loss = 0.56, batch loss = 0.30 (170.2 examples/sec; 0.047 sec/batch; 0h:35m:34s remains)
INFO - root - 2022-02-24 20:59:59.968039: step 154090, total loss = 0.66, batch loss = 0.40 (225.8 examples/sec; 0.035 sec/batch; 0h:26m:48s remains)
INFO - root - 2022-02-24 21:00:00.473120: step 154100, total loss = 0.52, batch loss = 0.26 (261.4 examples/sec; 0.031 sec/batch; 0h:23m:09s remains)
INFO - root - 2022-02-24 21:00:00.907812: step 154110, total loss = 0.63, batch loss = 0.38 (173.0 examples/sec; 0.046 sec/batch; 0h:34m:59s remains)
INFO - root - 2022-02-24 21:00:01.243238: step 154120, total loss = 0.53, batch loss = 0.27 (364.8 examples/sec; 0.022 sec/batch; 0h:16m:35s remains)
INFO - root - 2022-02-24 21:00:01.638926: step 154130, total loss = 0.59, batch loss = 0.33 (272.8 examples/sec; 0.029 sec/batch; 0h:22m:10s remains)
INFO - root - 2022-02-24 21:00:02.044704: step 154140, total loss = 0.51, batch loss = 0.25 (243.0 examples/sec; 0.033 sec/batch; 0h:24m:53s remains)
INFO - root - 2022-02-24 21:00:02.448089: step 154150, total loss = 0.49, batch loss = 0.24 (188.1 examples/sec; 0.043 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 21:00:02.808780: step 154160, total loss = 0.52, batch loss = 0.26 (129.4 examples/sec; 0.062 sec/batch; 0h:46m:43s remains)
INFO - root - 2022-02-24 21:00:03.086751: step 154170, total loss = 0.66, batch loss = 0.40 (300.9 examples/sec; 0.027 sec/batch; 0h:20m:05s remains)
INFO - root - 2022-02-24 21:00:03.472714: step 154180, total loss = 0.47, batch loss = 0.22 (216.6 examples/sec; 0.037 sec/batch; 0h:27m:53s remains)
INFO - root - 2022-02-24 21:00:03.970528: step 154190, total loss = 0.45, batch loss = 0.19 (135.3 examples/sec; 0.059 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 21:00:04.318934: step 154200, total loss = 0.63, batch loss = 0.37 (245.0 examples/sec; 0.033 sec/batch; 0h:24m:39s remains)
INFO - root - 2022-02-24 21:00:04.734285: step 154210, total loss = 0.50, batch loss = 0.24 (259.8 examples/sec; 0.031 sec/batch; 0h:23m:14s remains)
INFO - root - 2022-02-24 21:00:05.174560: step 154220, total loss = 0.50, batch loss = 0.24 (140.9 examples/sec; 0.057 sec/batch; 0h:42m:50s remains)
INFO - root - 2022-02-24 21:00:05.581869: step 154230, total loss = 0.57, batch loss = 0.31 (138.4 examples/sec; 0.058 sec/batch; 0h:43m:35s remains)
INFO - root - 2022-02-24 21:00:05.950116: step 154240, total loss = 0.58, batch loss = 0.33 (172.9 examples/sec; 0.046 sec/batch; 0h:34m:53s remains)
INFO - root - 2022-02-24 21:00:06.340650: step 154250, total loss = 0.59, batch loss = 0.33 (299.1 examples/sec; 0.027 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:00:06.696357: step 154260, total loss = 0.53, batch loss = 0.27 (185.6 examples/sec; 0.043 sec/batch; 0h:32m:30s remains)
INFO - root - 2022-02-24 21:00:07.035240: step 154270, total loss = 0.57, batch loss = 0.32 (269.7 examples/sec; 0.030 sec/batch; 0h:22m:21s remains)
INFO - root - 2022-02-24 21:00:07.421408: step 154280, total loss = 0.69, batch loss = 0.44 (185.5 examples/sec; 0.043 sec/batch; 0h:32m:29s remains)
INFO - root - 2022-02-24 21:00:07.935942: step 154290, total loss = 0.55, batch loss = 0.29 (169.3 examples/sec; 0.047 sec/batch; 0h:35m:36s remains)
INFO - root - 2022-02-24 21:00:08.401863: step 154300, total loss = 0.63, batch loss = 0.37 (224.1 examples/sec; 0.036 sec/batch; 0h:26m:53s remains)
INFO - root - 2022-02-24 21:00:08.795388: step 154310, total loss = 0.57, batch loss = 0.31 (351.6 examples/sec; 0.023 sec/batch; 0h:17m:08s remains)
INFO - root - 2022-02-24 21:00:09.094609: step 154320, total loss = 0.50, batch loss = 0.24 (344.8 examples/sec; 0.023 sec/batch; 0h:17m:28s remains)
INFO - root - 2022-02-24 21:00:09.479315: step 154330, total loss = 0.51, batch loss = 0.26 (356.3 examples/sec; 0.022 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:00:09.865382: step 154340, total loss = 0.55, batch loss = 0.29 (167.2 examples/sec; 0.048 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 21:00:10.311649: step 154350, total loss = 0.60, batch loss = 0.34 (86.9 examples/sec; 0.092 sec/batch; 1h:09m:16s remains)
INFO - root - 2022-02-24 21:00:10.660920: step 154360, total loss = 0.54, batch loss = 0.28 (343.9 examples/sec; 0.023 sec/batch; 0h:17m:29s remains)
INFO - root - 2022-02-24 21:00:11.000588: step 154370, total loss = 0.60, batch loss = 0.35 (251.6 examples/sec; 0.032 sec/batch; 0h:23m:55s remains)
INFO - root - 2022-02-24 21:00:11.316337: step 154380, total loss = 0.60, batch loss = 0.35 (342.6 examples/sec; 0.023 sec/batch; 0h:17m:33s remains)
INFO - root - 2022-02-24 21:00:11.655647: step 154390, total loss = 0.60, batch loss = 0.34 (295.5 examples/sec; 0.027 sec/batch; 0h:20m:21s remains)
INFO - root - 2022-02-24 21:00:11.971010: step 154400, total loss = 0.48, batch loss = 0.22 (143.8 examples/sec; 0.056 sec/batch; 0h:41m:48s remains)
INFO - root - 2022-02-24 21:00:12.480216: step 154410, total loss = 0.61, batch loss = 0.35 (142.1 examples/sec; 0.056 sec/batch; 0h:42m:18s remains)
INFO - root - 2022-02-24 21:00:12.891043: step 154420, total loss = 0.57, batch loss = 0.32 (325.0 examples/sec; 0.025 sec/batch; 0h:18m:29s remains)
INFO - root - 2022-02-24 21:00:13.237126: step 154430, total loss = 0.43, batch loss = 0.18 (363.5 examples/sec; 0.022 sec/batch; 0h:16m:31s remains)
INFO - root - 2022-02-24 21:00:13.545261: step 154440, total loss = 0.67, batch loss = 0.41 (334.5 examples/sec; 0.024 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:00:13.950826: step 154450, total loss = 0.55, batch loss = 0.29 (347.0 examples/sec; 0.023 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:00:14.365822: step 154460, total loss = 0.58, batch loss = 0.32 (301.2 examples/sec; 0.027 sec/batch; 0h:19m:56s remains)
INFO - root - 2022-02-24 21:00:14.893270: step 154470, total loss = 0.47, batch loss = 0.21 (239.5 examples/sec; 0.033 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 21:00:15.231924: step 154480, total loss = 0.56, batch loss = 0.30 (353.4 examples/sec; 0.023 sec/batch; 0h:16m:59s remains)
INFO - root - 2022-02-24 21:00:16.076666: step 154490, total loss = 0.47, batch loss = 0.21 (358.1 examples/sec; 0.022 sec/batch; 0h:16m:45s remains)
INFO - root - 2022-02-24 21:00:16.533698: step 154500, total loss = 0.49, batch loss = 0.24 (201.7 examples/sec; 0.040 sec/batch; 0h:29m:45s remains)
INFO - root - 2022-02-24 21:00:17.024190: step 154510, total loss = 0.48, batch loss = 0.22 (82.7 examples/sec; 0.097 sec/batch; 1h:12m:33s remains)
INFO - root - 2022-02-24 21:00:17.427479: step 154520, total loss = 0.45, batch loss = 0.19 (143.1 examples/sec; 0.056 sec/batch; 0h:41m:54s remains)
INFO - root - 2022-02-24 21:00:17.839336: step 154530, total loss = 0.54, batch loss = 0.29 (335.9 examples/sec; 0.024 sec/batch; 0h:17m:50s remains)
INFO - root - 2022-02-24 21:00:18.263846: step 154540, total loss = 0.55, batch loss = 0.29 (313.1 examples/sec; 0.026 sec/batch; 0h:19m:08s remains)
INFO - root - 2022-02-24 21:00:18.762560: step 154550, total loss = 0.57, batch loss = 0.32 (305.4 examples/sec; 0.026 sec/batch; 0h:19m:37s remains)
INFO - root - 2022-02-24 21:00:19.268712: step 154560, total loss = 0.56, batch loss = 0.30 (116.8 examples/sec; 0.069 sec/batch; 0h:51m:18s remains)
INFO - root - 2022-02-24 21:00:19.773523: step 154570, total loss = 0.55, batch loss = 0.29 (107.8 examples/sec; 0.074 sec/batch; 0h:55m:35s remains)
INFO - root - 2022-02-24 21:00:20.291663: step 154580, total loss = 0.63, batch loss = 0.37 (166.3 examples/sec; 0.048 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 21:00:21.309821: step 154590, total loss = 0.65, batch loss = 0.39 (14.3 examples/sec; 0.561 sec/batch; 6h:59m:58s remains)
INFO - root - 2022-02-24 21:00:21.692999: step 154600, total loss = 0.52, batch loss = 0.26 (361.1 examples/sec; 0.022 sec/batch; 0h:16m:34s remains)
INFO - root - 2022-02-24 21:00:22.079461: step 154610, total loss = 0.58, batch loss = 0.32 (339.6 examples/sec; 0.024 sec/batch; 0h:17m:37s remains)
INFO - root - 2022-02-24 21:00:22.341089: step 154620, total loss = 0.50, batch loss = 0.24 (324.2 examples/sec; 0.025 sec/batch; 0h:18m:27s remains)
INFO - root - 2022-02-24 21:00:22.702602: step 154630, total loss = 0.52, batch loss = 0.27 (152.4 examples/sec; 0.052 sec/batch; 0h:39m:15s remains)
INFO - root - 2022-02-24 21:00:23.081405: step 154640, total loss = 0.52, batch loss = 0.26 (175.5 examples/sec; 0.046 sec/batch; 0h:34m:04s remains)
INFO - root - 2022-02-24 21:00:23.478025: step 154650, total loss = 0.50, batch loss = 0.24 (233.6 examples/sec; 0.034 sec/batch; 0h:25m:35s remains)
INFO - root - 2022-02-24 21:00:23.851093: step 154660, total loss = 0.52, batch loss = 0.26 (138.1 examples/sec; 0.058 sec/batch; 0h:43m:18s remains)
INFO - root - 2022-02-24 21:00:24.147232: step 154670, total loss = 0.49, batch loss = 0.23 (257.6 examples/sec; 0.031 sec/batch; 0h:23m:12s remains)
INFO - root - 2022-02-24 21:00:24.491072: step 154680, total loss = 0.50, batch loss = 0.24 (187.3 examples/sec; 0.043 sec/batch; 0h:31m:53s remains)
INFO - root - 2022-02-24 21:00:24.800985: step 154690, total loss = 0.49, batch loss = 0.24 (251.1 examples/sec; 0.032 sec/batch; 0h:23m:47s remains)
INFO - root - 2022-02-24 21:00:25.202597: step 154700, total loss = 0.50, batch loss = 0.24 (174.9 examples/sec; 0.046 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 21:00:25.703811: step 154710, total loss = 0.56, batch loss = 0.31 (127.8 examples/sec; 0.063 sec/batch; 0h:46m:44s remains)
INFO - root - 2022-02-24 21:00:26.081826: step 154720, total loss = 0.56, batch loss = 0.30 (284.7 examples/sec; 0.028 sec/batch; 0h:20m:58s remains)
INFO - root - 2022-02-24 21:00:26.406784: step 154730, total loss = 0.51, batch loss = 0.25 (327.3 examples/sec; 0.024 sec/batch; 0h:18m:14s remains)
INFO - root - 2022-02-24 21:00:26.787322: step 154740, total loss = 0.51, batch loss = 0.26 (312.7 examples/sec; 0.026 sec/batch; 0h:19m:05s remains)
INFO - root - 2022-02-24 21:00:27.150311: step 154750, total loss = 0.57, batch loss = 0.31 (166.8 examples/sec; 0.048 sec/batch; 0h:35m:46s remains)
INFO - root - 2022-02-24 21:00:27.589510: step 154760, total loss = 0.55, batch loss = 0.29 (199.8 examples/sec; 0.040 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 21:00:28.010519: step 154770, total loss = 0.50, batch loss = 0.24 (301.5 examples/sec; 0.027 sec/batch; 0h:19m:46s remains)
INFO - root - 2022-02-24 21:00:28.357178: step 154780, total loss = 0.59, batch loss = 0.34 (202.1 examples/sec; 0.040 sec/batch; 0h:29m:30s remains)
INFO - root - 2022-02-24 21:00:28.754400: step 154790, total loss = 0.57, batch loss = 0.31 (188.4 examples/sec; 0.042 sec/batch; 0h:31m:38s remains)
INFO - root - 2022-02-24 21:00:29.080583: step 154800, total loss = 0.64, batch loss = 0.38 (349.2 examples/sec; 0.023 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:00:29.582793: step 154810, total loss = 0.65, batch loss = 0.39 (270.3 examples/sec; 0.030 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:00:30.022908: step 154820, total loss = 0.52, batch loss = 0.26 (271.4 examples/sec; 0.029 sec/batch; 0h:21m:57s remains)
INFO - root - 2022-02-24 21:00:30.326999: step 154830, total loss = 0.50, batch loss = 0.24 (329.2 examples/sec; 0.024 sec/batch; 0h:18m:05s remains)
INFO - root - 2022-02-24 21:00:30.648715: step 154840, total loss = 0.60, batch loss = 0.34 (224.2 examples/sec; 0.036 sec/batch; 0h:26m:33s remains)
INFO - root - 2022-02-24 21:00:30.984651: step 154850, total loss = 0.68, batch loss = 0.42 (119.3 examples/sec; 0.067 sec/batch; 0h:49m:54s remains)
INFO - root - 2022-02-24 21:00:31.506641: step 154860, total loss = 0.63, batch loss = 0.37 (146.2 examples/sec; 0.055 sec/batch; 0h:40m:43s remains)
INFO - root - 2022-02-24 21:00:31.974988: step 154870, total loss = 0.46, batch loss = 0.20 (136.5 examples/sec; 0.059 sec/batch; 0h:43m:36s remains)
INFO - root - 2022-02-24 21:00:32.310752: step 154880, total loss = 0.55, batch loss = 0.29 (229.2 examples/sec; 0.035 sec/batch; 0h:25m:57s remains)
INFO - root - 2022-02-24 21:00:32.644874: step 154890, total loss = 0.50, batch loss = 0.24 (231.9 examples/sec; 0.034 sec/batch; 0h:25m:38s remains)
INFO - root - 2022-02-24 21:00:32.911838: step 154900, total loss = 0.68, batch loss = 0.43 (338.6 examples/sec; 0.024 sec/batch; 0h:17m:33s remains)
INFO - root - 2022-02-24 21:00:33.326356: step 154910, total loss = 0.52, batch loss = 0.26 (114.7 examples/sec; 0.070 sec/batch; 0h:51m:50s remains)
INFO - root - 2022-02-24 21:00:33.678727: step 154920, total loss = 0.56, batch loss = 0.30 (324.8 examples/sec; 0.025 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:00:34.046048: step 154930, total loss = 0.56, batch loss = 0.30 (332.2 examples/sec; 0.024 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 21:00:34.415460: step 154940, total loss = 0.54, batch loss = 0.28 (171.2 examples/sec; 0.047 sec/batch; 0h:34m:42s remains)
INFO - root - 2022-02-24 21:00:34.698120: step 154950, total loss = 0.47, batch loss = 0.21 (331.7 examples/sec; 0.024 sec/batch; 0h:17m:54s remains)
INFO - root - 2022-02-24 21:00:35.105950: step 154960, total loss = 0.52, batch loss = 0.26 (120.1 examples/sec; 0.067 sec/batch; 0h:49m:27s remains)
INFO - root - 2022-02-24 21:00:35.521340: step 154970, total loss = 0.57, batch loss = 0.32 (139.3 examples/sec; 0.057 sec/batch; 0h:42m:36s remains)
INFO - root - 2022-02-24 21:00:35.856923: step 154980, total loss = 0.51, batch loss = 0.25 (348.3 examples/sec; 0.023 sec/batch; 0h:17m:02s remains)
INFO - root - 2022-02-24 21:00:36.300057: step 154990, total loss = 0.50, batch loss = 0.25 (257.7 examples/sec; 0.031 sec/batch; 0h:23m:01s remains)
INFO - root - 2022-02-24 21:00:36.727664: step 155000, total loss = 0.58, batch loss = 0.32 (351.9 examples/sec; 0.023 sec/batch; 0h:16m:51s remains)
INFO - root - 2022-02-24 21:00:37.233067: step 155010, total loss = 0.56, batch loss = 0.31 (280.8 examples/sec; 0.028 sec/batch; 0h:21m:07s remains)
INFO - root - 2022-02-24 21:00:37.651315: step 155020, total loss = 0.48, batch loss = 0.23 (286.7 examples/sec; 0.028 sec/batch; 0h:20m:41s remains)
INFO - root - 2022-02-24 21:00:38.079038: step 155030, total loss = 0.57, batch loss = 0.31 (164.6 examples/sec; 0.049 sec/batch; 0h:36m:01s remains)
INFO - root - 2022-02-24 21:00:38.438206: step 155040, total loss = 0.60, batch loss = 0.34 (332.3 examples/sec; 0.024 sec/batch; 0h:17m:50s remains)
INFO - root - 2022-02-24 21:00:38.791181: step 155050, total loss = 0.55, batch loss = 0.30 (207.3 examples/sec; 0.039 sec/batch; 0h:28m:35s remains)
INFO - root - 2022-02-24 21:00:39.173225: step 155060, total loss = 0.54, batch loss = 0.29 (312.6 examples/sec; 0.026 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 21:00:39.540944: step 155070, total loss = 0.56, batch loss = 0.31 (128.0 examples/sec; 0.062 sec/batch; 0h:46m:16s remains)
INFO - root - 2022-02-24 21:00:40.138714: step 155080, total loss = 0.63, batch loss = 0.37 (202.4 examples/sec; 0.040 sec/batch; 0h:29m:15s remains)
INFO - root - 2022-02-24 21:00:40.562766: step 155090, total loss = 0.55, batch loss = 0.29 (119.2 examples/sec; 0.067 sec/batch; 0h:49m:40s remains)
INFO - root - 2022-02-24 21:00:40.953258: step 155100, total loss = 0.49, batch loss = 0.23 (321.2 examples/sec; 0.025 sec/batch; 0h:18m:25s remains)
INFO - root - 2022-02-24 21:00:41.481939: step 155110, total loss = 0.52, batch loss = 0.26 (234.5 examples/sec; 0.034 sec/batch; 0h:25m:14s remains)
INFO - root - 2022-02-24 21:00:41.912782: step 155120, total loss = 0.51, batch loss = 0.26 (208.2 examples/sec; 0.038 sec/batch; 0h:28m:25s remains)
INFO - root - 2022-02-24 21:00:42.272771: step 155130, total loss = 0.57, batch loss = 0.32 (232.1 examples/sec; 0.034 sec/batch; 0h:25m:29s remains)
INFO - root - 2022-02-24 21:00:42.636796: step 155140, total loss = 0.46, batch loss = 0.20 (335.3 examples/sec; 0.024 sec/batch; 0h:17m:38s remains)
INFO - root - 2022-02-24 21:00:42.985046: step 155150, total loss = 0.51, batch loss = 0.26 (343.6 examples/sec; 0.023 sec/batch; 0h:17m:12s remains)
INFO - root - 2022-02-24 21:00:43.353674: step 155160, total loss = 0.47, batch loss = 0.21 (323.0 examples/sec; 0.025 sec/batch; 0h:18m:18s remains)
INFO - root - 2022-02-24 21:00:43.665351: step 155170, total loss = 0.53, batch loss = 0.27 (263.0 examples/sec; 0.030 sec/batch; 0h:22m:28s remains)
INFO - root - 2022-02-24 21:00:44.039822: step 155180, total loss = 0.57, batch loss = 0.31 (190.6 examples/sec; 0.042 sec/batch; 0h:31m:00s remains)
INFO - root - 2022-02-24 21:00:44.474288: step 155190, total loss = 0.50, batch loss = 0.25 (301.3 examples/sec; 0.027 sec/batch; 0h:19m:36s remains)
INFO - root - 2022-02-24 21:00:44.858026: step 155200, total loss = 0.54, batch loss = 0.29 (200.6 examples/sec; 0.040 sec/batch; 0h:29m:26s remains)
INFO - root - 2022-02-24 21:00:45.337439: step 155210, total loss = 0.57, batch loss = 0.32 (199.6 examples/sec; 0.040 sec/batch; 0h:29m:35s remains)
INFO - root - 2022-02-24 21:00:45.730210: step 155220, total loss = 0.54, batch loss = 0.28 (313.6 examples/sec; 0.026 sec/batch; 0h:18m:49s remains)
INFO - root - 2022-02-24 21:00:46.166121: step 155230, total loss = 0.49, batch loss = 0.24 (235.2 examples/sec; 0.034 sec/batch; 0h:25m:05s remains)
INFO - root - 2022-02-24 21:00:46.572992: step 155240, total loss = 0.45, batch loss = 0.19 (190.9 examples/sec; 0.042 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 21:00:46.919476: step 155250, total loss = 0.49, batch loss = 0.23 (290.7 examples/sec; 0.028 sec/batch; 0h:20m:17s remains)
INFO - root - 2022-02-24 21:00:47.277374: step 155260, total loss = 0.55, batch loss = 0.29 (244.3 examples/sec; 0.033 sec/batch; 0h:24m:09s remains)
INFO - root - 2022-02-24 21:00:47.604568: step 155270, total loss = 0.54, batch loss = 0.28 (296.8 examples/sec; 0.027 sec/batch; 0h:19m:52s remains)
INFO - root - 2022-02-24 21:00:47.986989: step 155280, total loss = 0.61, batch loss = 0.35 (130.5 examples/sec; 0.061 sec/batch; 0h:45m:11s remains)
INFO - root - 2022-02-24 21:00:48.436377: step 155290, total loss = 0.54, batch loss = 0.28 (145.3 examples/sec; 0.055 sec/batch; 0h:40m:33s remains)
INFO - root - 2022-02-24 21:00:48.960638: step 155300, total loss = 0.62, batch loss = 0.36 (184.2 examples/sec; 0.043 sec/batch; 0h:31m:59s remains)
INFO - root - 2022-02-24 21:00:49.383365: step 155310, total loss = 0.55, batch loss = 0.29 (282.8 examples/sec; 0.028 sec/batch; 0h:20m:50s remains)
INFO - root - 2022-02-24 21:00:49.684141: step 155320, total loss = 0.58, batch loss = 0.33 (369.3 examples/sec; 0.022 sec/batch; 0h:15m:57s remains)
INFO - root - 2022-02-24 21:00:49.989761: step 155330, total loss = 0.49, batch loss = 0.24 (348.3 examples/sec; 0.023 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:00:50.415258: step 155340, total loss = 0.55, batch loss = 0.29 (103.3 examples/sec; 0.077 sec/batch; 0h:56m:59s remains)
INFO - root - 2022-02-24 21:00:50.838965: step 155350, total loss = 0.66, batch loss = 0.41 (265.2 examples/sec; 0.030 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 21:00:51.243754: step 155360, total loss = 0.52, batch loss = 0.26 (156.2 examples/sec; 0.051 sec/batch; 0h:37m:40s remains)
INFO - root - 2022-02-24 21:00:51.714465: step 155370, total loss = 0.61, batch loss = 0.35 (186.6 examples/sec; 0.043 sec/batch; 0h:31m:31s remains)
INFO - root - 2022-02-24 21:00:52.144499: step 155380, total loss = 0.72, batch loss = 0.46 (200.5 examples/sec; 0.040 sec/batch; 0h:29m:20s remains)
INFO - root - 2022-02-24 21:00:52.608490: step 155390, total loss = 0.51, batch loss = 0.26 (141.9 examples/sec; 0.056 sec/batch; 0h:41m:27s remains)
INFO - root - 2022-02-24 21:00:53.130196: step 155400, total loss = 0.62, batch loss = 0.36 (356.6 examples/sec; 0.022 sec/batch; 0h:16m:29s remains)
INFO - root - 2022-02-24 21:00:53.600461: step 155410, total loss = 0.50, batch loss = 0.24 (237.8 examples/sec; 0.034 sec/batch; 0h:24m:43s remains)
INFO - root - 2022-02-24 21:00:53.972564: step 155420, total loss = 0.52, batch loss = 0.26 (144.5 examples/sec; 0.055 sec/batch; 0h:40m:40s remains)
INFO - root - 2022-02-24 21:00:54.449754: step 155430, total loss = 0.54, batch loss = 0.28 (335.5 examples/sec; 0.024 sec/batch; 0h:17m:30s remains)
INFO - root - 2022-02-24 21:00:54.872928: step 155440, total loss = 0.51, batch loss = 0.25 (154.8 examples/sec; 0.052 sec/batch; 0h:37m:57s remains)
INFO - root - 2022-02-24 21:00:55.391641: step 155450, total loss = 0.61, batch loss = 0.35 (100.4 examples/sec; 0.080 sec/batch; 0h:58m:30s remains)
INFO - root - 2022-02-24 21:00:55.943819: step 155460, total loss = 0.53, batch loss = 0.27 (298.4 examples/sec; 0.027 sec/batch; 0h:19m:40s remains)
INFO - root - 2022-02-24 21:00:57.426808: step 155470, total loss = 0.61, batch loss = 0.35 (154.5 examples/sec; 0.052 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 21:00:57.894763: step 155480, total loss = 0.48, batch loss = 0.22 (191.7 examples/sec; 0.042 sec/batch; 0h:30m:36s remains)
INFO - root - 2022-02-24 21:00:58.238834: step 155490, total loss = 0.53, batch loss = 0.27 (254.8 examples/sec; 0.031 sec/batch; 0h:23m:02s remains)
INFO - root - 2022-02-24 21:00:58.625717: step 155500, total loss = 0.50, batch loss = 0.25 (343.9 examples/sec; 0.023 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:00:59.083406: step 155510, total loss = 0.70, batch loss = 0.44 (160.2 examples/sec; 0.050 sec/batch; 0h:36m:36s remains)
INFO - root - 2022-02-24 21:00:59.525611: step 155520, total loss = 0.64, batch loss = 0.38 (148.2 examples/sec; 0.054 sec/batch; 0h:39m:34s remains)
INFO - root - 2022-02-24 21:00:59.960228: step 155530, total loss = 0.61, batch loss = 0.35 (90.8 examples/sec; 0.088 sec/batch; 1h:04m:34s remains)
INFO - root - 2022-02-24 21:01:00.300732: step 155540, total loss = 0.50, batch loss = 0.25 (116.3 examples/sec; 0.069 sec/batch; 0h:50m:23s remains)
INFO - root - 2022-02-24 21:01:00.643519: step 155550, total loss = 0.56, batch loss = 0.30 (108.5 examples/sec; 0.074 sec/batch; 0h:54m:01s remains)
INFO - root - 2022-02-24 21:01:00.923266: step 155560, total loss = 0.50, batch loss = 0.24 (354.9 examples/sec; 0.023 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:01:01.436149: step 155570, total loss = 0.51, batch loss = 0.26 (120.4 examples/sec; 0.066 sec/batch; 0h:48m:39s remains)
INFO - root - 2022-02-24 21:01:01.837903: step 155580, total loss = 0.50, batch loss = 0.25 (213.1 examples/sec; 0.038 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 21:01:02.172204: step 155590, total loss = 0.53, batch loss = 0.27 (266.4 examples/sec; 0.030 sec/batch; 0h:21m:58s remains)
INFO - root - 2022-02-24 21:01:02.524849: step 155600, total loss = 0.56, batch loss = 0.30 (183.8 examples/sec; 0.044 sec/batch; 0h:31m:50s remains)
INFO - root - 2022-02-24 21:01:02.902285: step 155610, total loss = 0.54, batch loss = 0.28 (336.1 examples/sec; 0.024 sec/batch; 0h:17m:24s remains)
INFO - root - 2022-02-24 21:01:03.326359: step 155620, total loss = 0.56, batch loss = 0.30 (129.8 examples/sec; 0.062 sec/batch; 0h:45m:04s remains)
INFO - root - 2022-02-24 21:01:03.716933: step 155630, total loss = 0.57, batch loss = 0.31 (220.5 examples/sec; 0.036 sec/batch; 0h:26m:31s remains)
INFO - root - 2022-02-24 21:01:04.103470: step 155640, total loss = 0.45, batch loss = 0.19 (331.4 examples/sec; 0.024 sec/batch; 0h:17m:38s remains)
INFO - root - 2022-02-24 21:01:04.453383: step 155650, total loss = 0.54, batch loss = 0.28 (138.9 examples/sec; 0.058 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 21:01:04.743960: step 155660, total loss = 0.54, batch loss = 0.28 (286.3 examples/sec; 0.028 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 21:01:05.094100: step 155670, total loss = 0.50, batch loss = 0.24 (367.9 examples/sec; 0.022 sec/batch; 0h:15m:53s remains)
INFO - root - 2022-02-24 21:01:05.533836: step 155680, total loss = 0.61, batch loss = 0.35 (348.3 examples/sec; 0.023 sec/batch; 0h:16m:46s remains)
INFO - root - 2022-02-24 21:01:06.024922: step 155690, total loss = 0.58, batch loss = 0.32 (243.9 examples/sec; 0.033 sec/batch; 0h:23m:56s remains)
INFO - root - 2022-02-24 21:01:06.369801: step 155700, total loss = 0.61, batch loss = 0.36 (249.4 examples/sec; 0.032 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 21:01:06.807057: step 155710, total loss = 0.57, batch loss = 0.31 (250.9 examples/sec; 0.032 sec/batch; 0h:23m:16s remains)
INFO - root - 2022-02-24 21:01:07.144034: step 155720, total loss = 0.47, batch loss = 0.21 (151.4 examples/sec; 0.053 sec/batch; 0h:38m:32s remains)
INFO - root - 2022-02-24 21:01:07.636459: step 155730, total loss = 0.46, batch loss = 0.21 (336.5 examples/sec; 0.024 sec/batch; 0h:17m:20s remains)
INFO - root - 2022-02-24 21:01:07.966941: step 155740, total loss = 0.55, batch loss = 0.29 (175.2 examples/sec; 0.046 sec/batch; 0h:33m:18s remains)
INFO - root - 2022-02-24 21:01:08.375158: step 155750, total loss = 0.45, batch loss = 0.19 (156.6 examples/sec; 0.051 sec/batch; 0h:37m:14s remains)
INFO - root - 2022-02-24 21:01:08.711516: step 155760, total loss = 0.48, batch loss = 0.23 (313.8 examples/sec; 0.025 sec/batch; 0h:18m:34s remains)
INFO - root - 2022-02-24 21:01:09.051408: step 155770, total loss = 0.62, batch loss = 0.36 (153.3 examples/sec; 0.052 sec/batch; 0h:38m:02s remains)
INFO - root - 2022-02-24 21:01:09.394719: step 155780, total loss = 0.57, batch loss = 0.31 (186.1 examples/sec; 0.043 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 21:01:09.872591: step 155790, total loss = 0.50, batch loss = 0.24 (163.8 examples/sec; 0.049 sec/batch; 0h:35m:34s remains)
INFO - root - 2022-02-24 21:01:10.222630: step 155800, total loss = 0.49, batch loss = 0.23 (143.4 examples/sec; 0.056 sec/batch; 0h:40m:37s remains)
INFO - root - 2022-02-24 21:01:10.620011: step 155810, total loss = 0.51, batch loss = 0.25 (288.5 examples/sec; 0.028 sec/batch; 0h:20m:11s remains)
INFO - root - 2022-02-24 21:01:10.967608: step 155820, total loss = 0.70, batch loss = 0.45 (135.0 examples/sec; 0.059 sec/batch; 0h:43m:08s remains)
INFO - root - 2022-02-24 21:01:11.341394: step 155830, total loss = 0.50, batch loss = 0.24 (385.4 examples/sec; 0.021 sec/batch; 0h:15m:06s remains)
INFO - root - 2022-02-24 21:01:11.824646: step 155840, total loss = 0.56, batch loss = 0.30 (181.2 examples/sec; 0.044 sec/batch; 0h:32m:07s remains)
INFO - root - 2022-02-24 21:01:12.171125: step 155850, total loss = 0.56, batch loss = 0.31 (334.8 examples/sec; 0.024 sec/batch; 0h:17m:22s remains)
INFO - root - 2022-02-24 21:01:12.489348: step 155860, total loss = 0.56, batch loss = 0.30 (331.2 examples/sec; 0.024 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 21:01:12.811102: step 155870, total loss = 0.55, batch loss = 0.30 (295.8 examples/sec; 0.027 sec/batch; 0h:19m:39s remains)
INFO - root - 2022-02-24 21:01:13.162828: step 155880, total loss = 0.55, batch loss = 0.29 (205.4 examples/sec; 0.039 sec/batch; 0h:28m:18s remains)
INFO - root - 2022-02-24 21:01:13.592537: step 155890, total loss = 0.65, batch loss = 0.40 (174.6 examples/sec; 0.046 sec/batch; 0h:33m:17s remains)
INFO - root - 2022-02-24 21:01:13.996783: step 155900, total loss = 0.58, batch loss = 0.32 (280.9 examples/sec; 0.028 sec/batch; 0h:20m:41s remains)
INFO - root - 2022-02-24 21:01:14.443234: step 155910, total loss = 0.49, batch loss = 0.23 (256.4 examples/sec; 0.031 sec/batch; 0h:22m:39s remains)
INFO - root - 2022-02-24 21:01:14.756661: step 155920, total loss = 0.59, batch loss = 0.34 (162.8 examples/sec; 0.049 sec/batch; 0h:35m:42s remains)
INFO - root - 2022-02-24 21:01:15.093900: step 155930, total loss = 0.59, batch loss = 0.33 (298.5 examples/sec; 0.027 sec/batch; 0h:19m:27s remains)
INFO - root - 2022-02-24 21:01:15.544455: step 155940, total loss = 0.59, batch loss = 0.33 (273.8 examples/sec; 0.029 sec/batch; 0h:21m:12s remains)
INFO - root - 2022-02-24 21:01:16.003336: step 155950, total loss = 0.56, batch loss = 0.30 (256.8 examples/sec; 0.031 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 21:01:16.602058: step 155960, total loss = 0.52, batch loss = 0.27 (207.6 examples/sec; 0.039 sec/batch; 0h:27m:58s remains)
INFO - root - 2022-02-24 21:01:17.360059: step 155970, total loss = 0.49, batch loss = 0.24 (193.5 examples/sec; 0.041 sec/batch; 0h:29m:59s remains)
INFO - root - 2022-02-24 21:01:17.793570: step 155980, total loss = 0.58, batch loss = 0.33 (317.8 examples/sec; 0.025 sec/batch; 0h:18m:15s remains)
INFO - root - 2022-02-24 21:01:18.203747: step 155990, total loss = 0.51, batch loss = 0.25 (329.0 examples/sec; 0.024 sec/batch; 0h:17m:38s remains)
INFO - root - 2022-02-24 21:01:18.540497: step 156000, total loss = 0.50, batch loss = 0.25 (214.0 examples/sec; 0.037 sec/batch; 0h:27m:06s remains)
INFO - root - 2022-02-24 21:01:19.070775: step 156010, total loss = 0.63, batch loss = 0.37 (310.5 examples/sec; 0.026 sec/batch; 0h:18m:40s remains)
INFO - root - 2022-02-24 21:01:19.494228: step 156020, total loss = 0.51, batch loss = 0.26 (242.9 examples/sec; 0.033 sec/batch; 0h:23m:52s remains)
INFO - root - 2022-02-24 21:01:19.998269: step 156030, total loss = 0.58, batch loss = 0.33 (148.0 examples/sec; 0.054 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 21:01:20.325539: step 156040, total loss = 0.49, batch loss = 0.23 (364.9 examples/sec; 0.022 sec/batch; 0h:15m:52s remains)
INFO - root - 2022-02-24 21:01:20.715424: step 156050, total loss = 0.69, batch loss = 0.43 (224.2 examples/sec; 0.036 sec/batch; 0h:25m:50s remains)
INFO - root - 2022-02-24 21:01:21.015216: step 156060, total loss = 0.51, batch loss = 0.25 (258.0 examples/sec; 0.031 sec/batch; 0h:22m:27s remains)
INFO - root - 2022-02-24 21:01:21.396607: step 156070, total loss = 0.55, batch loss = 0.29 (101.7 examples/sec; 0.079 sec/batch; 0h:56m:55s remains)
INFO - root - 2022-02-24 21:01:21.836984: step 156080, total loss = 0.48, batch loss = 0.22 (131.5 examples/sec; 0.061 sec/batch; 0h:44m:00s remains)
INFO - root - 2022-02-24 21:01:22.380365: step 156090, total loss = 0.60, batch loss = 0.34 (224.0 examples/sec; 0.036 sec/batch; 0h:25m:50s remains)
INFO - root - 2022-02-24 21:01:22.750078: step 156100, total loss = 0.50, batch loss = 0.24 (251.1 examples/sec; 0.032 sec/batch; 0h:23m:02s remains)
INFO - root - 2022-02-24 21:01:23.197002: step 156110, total loss = 0.60, batch loss = 0.34 (203.0 examples/sec; 0.039 sec/batch; 0h:28m:29s remains)
INFO - root - 2022-02-24 21:01:23.576668: step 156120, total loss = 0.57, batch loss = 0.31 (343.6 examples/sec; 0.023 sec/batch; 0h:16m:49s remains)
INFO - root - 2022-02-24 21:01:23.900609: step 156130, total loss = 0.57, batch loss = 0.31 (222.7 examples/sec; 0.036 sec/batch; 0h:25m:58s remains)
INFO - root - 2022-02-24 21:01:24.297832: step 156140, total loss = 0.67, batch loss = 0.41 (236.3 examples/sec; 0.034 sec/batch; 0h:24m:27s remains)
INFO - root - 2022-02-24 21:01:24.689705: step 156150, total loss = 0.50, batch loss = 0.24 (365.8 examples/sec; 0.022 sec/batch; 0h:15m:48s remains)
INFO - root - 2022-02-24 21:01:24.997564: step 156160, total loss = 0.55, batch loss = 0.30 (356.4 examples/sec; 0.022 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:01:25.300264: step 156170, total loss = 0.55, batch loss = 0.29 (317.2 examples/sec; 0.025 sec/batch; 0h:18m:12s remains)
INFO - root - 2022-02-24 21:01:25.637922: step 156180, total loss = 0.51, batch loss = 0.25 (354.8 examples/sec; 0.023 sec/batch; 0h:16m:16s remains)
INFO - root - 2022-02-24 21:01:26.060816: step 156190, total loss = 0.50, batch loss = 0.24 (316.9 examples/sec; 0.025 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 21:01:26.540343: step 156200, total loss = 0.74, batch loss = 0.49 (122.1 examples/sec; 0.065 sec/batch; 0h:47m:15s remains)
INFO - root - 2022-02-24 21:01:27.073589: step 156210, total loss = 0.51, batch loss = 0.25 (157.2 examples/sec; 0.051 sec/batch; 0h:36m:42s remains)
INFO - root - 2022-02-24 21:01:27.447396: step 156220, total loss = 0.79, batch loss = 0.53 (300.7 examples/sec; 0.027 sec/batch; 0h:19m:11s remains)
INFO - root - 2022-02-24 21:01:27.745204: step 156230, total loss = 0.63, batch loss = 0.37 (226.6 examples/sec; 0.035 sec/batch; 0h:25m:27s remains)
INFO - root - 2022-02-24 21:01:28.197244: step 156240, total loss = 0.59, batch loss = 0.34 (379.7 examples/sec; 0.021 sec/batch; 0h:15m:11s remains)
INFO - root - 2022-02-24 21:01:28.623191: step 156250, total loss = 0.63, batch loss = 0.37 (208.0 examples/sec; 0.038 sec/batch; 0h:27m:43s remains)
INFO - root - 2022-02-24 21:01:28.962439: step 156260, total loss = 0.53, batch loss = 0.28 (318.6 examples/sec; 0.025 sec/batch; 0h:18m:05s remains)
INFO - root - 2022-02-24 21:01:29.293620: step 156270, total loss = 0.64, batch loss = 0.38 (348.7 examples/sec; 0.023 sec/batch; 0h:16m:31s remains)
INFO - root - 2022-02-24 21:01:29.648230: step 156280, total loss = 0.58, batch loss = 0.33 (136.8 examples/sec; 0.058 sec/batch; 0h:42m:06s remains)
INFO - root - 2022-02-24 21:01:30.055308: step 156290, total loss = 0.58, batch loss = 0.32 (235.7 examples/sec; 0.034 sec/batch; 0h:24m:26s remains)
INFO - root - 2022-02-24 21:01:30.510002: step 156300, total loss = 0.53, batch loss = 0.28 (212.8 examples/sec; 0.038 sec/batch; 0h:27m:03s remains)
INFO - root - 2022-02-24 21:01:30.998626: step 156310, total loss = 0.61, batch loss = 0.36 (315.9 examples/sec; 0.025 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 21:01:31.403361: step 156320, total loss = 0.51, batch loss = 0.26 (325.7 examples/sec; 0.025 sec/batch; 0h:17m:40s remains)
INFO - root - 2022-02-24 21:01:31.829527: step 156330, total loss = 0.53, batch loss = 0.27 (156.4 examples/sec; 0.051 sec/batch; 0h:36m:47s remains)
INFO - root - 2022-02-24 21:01:32.281236: step 156340, total loss = 0.62, batch loss = 0.36 (290.1 examples/sec; 0.028 sec/batch; 0h:19m:50s remains)
INFO - root - 2022-02-24 21:01:32.696773: step 156350, total loss = 0.52, batch loss = 0.27 (214.7 examples/sec; 0.037 sec/batch; 0h:26m:47s remains)
INFO - root - 2022-02-24 21:01:33.213870: step 156360, total loss = 0.49, batch loss = 0.23 (116.6 examples/sec; 0.069 sec/batch; 0h:49m:20s remains)
INFO - root - 2022-02-24 21:01:33.756473: step 156370, total loss = 0.55, batch loss = 0.29 (185.7 examples/sec; 0.043 sec/batch; 0h:30m:57s remains)
INFO - root - 2022-02-24 21:01:34.366117: step 156380, total loss = 0.53, batch loss = 0.27 (233.4 examples/sec; 0.034 sec/batch; 0h:24m:38s remains)
INFO - root - 2022-02-24 21:01:34.851139: step 156390, total loss = 0.56, batch loss = 0.30 (308.4 examples/sec; 0.026 sec/batch; 0h:18m:38s remains)
INFO - root - 2022-02-24 21:01:35.378363: step 156400, total loss = 0.47, batch loss = 0.21 (157.1 examples/sec; 0.051 sec/batch; 0h:36m:34s remains)
INFO - root - 2022-02-24 21:01:35.827184: step 156410, total loss = 0.57, batch loss = 0.31 (209.3 examples/sec; 0.038 sec/batch; 0h:27m:27s remains)
INFO - root - 2022-02-24 21:01:36.226537: step 156420, total loss = 0.51, batch loss = 0.25 (224.4 examples/sec; 0.036 sec/batch; 0h:25m:36s remains)
INFO - root - 2022-02-24 21:01:36.686209: step 156430, total loss = 0.55, batch loss = 0.29 (191.6 examples/sec; 0.042 sec/batch; 0h:29m:58s remains)
INFO - root - 2022-02-24 21:01:37.023041: step 156440, total loss = 0.56, batch loss = 0.30 (283.5 examples/sec; 0.028 sec/batch; 0h:20m:15s remains)
INFO - root - 2022-02-24 21:01:38.030080: step 156450, total loss = 0.61, batch loss = 0.35 (158.8 examples/sec; 0.050 sec/batch; 0h:36m:09s remains)
INFO - root - 2022-02-24 21:01:38.582455: step 156460, total loss = 0.54, batch loss = 0.29 (260.6 examples/sec; 0.031 sec/batch; 0h:22m:01s remains)
INFO - root - 2022-02-24 21:01:38.993057: step 156470, total loss = 0.52, batch loss = 0.27 (293.5 examples/sec; 0.027 sec/batch; 0h:19m:32s remains)
INFO - root - 2022-02-24 21:01:39.444517: step 156480, total loss = 0.54, batch loss = 0.29 (315.8 examples/sec; 0.025 sec/batch; 0h:18m:09s remains)
INFO - root - 2022-02-24 21:01:39.770555: step 156490, total loss = 0.54, batch loss = 0.29 (208.6 examples/sec; 0.038 sec/batch; 0h:27m:29s remains)
INFO - root - 2022-02-24 21:01:40.093994: step 156500, total loss = 0.59, batch loss = 0.34 (170.2 examples/sec; 0.047 sec/batch; 0h:33m:40s remains)
INFO - root - 2022-02-24 21:01:40.633038: step 156510, total loss = 0.47, batch loss = 0.22 (120.4 examples/sec; 0.066 sec/batch; 0h:47m:36s remains)
INFO - root - 2022-02-24 21:01:40.990308: step 156520, total loss = 0.57, batch loss = 0.32 (280.5 examples/sec; 0.029 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 21:01:41.300600: step 156530, total loss = 0.57, batch loss = 0.31 (298.3 examples/sec; 0.027 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 21:01:41.615081: step 156540, total loss = 0.48, batch loss = 0.22 (233.6 examples/sec; 0.034 sec/batch; 0h:24m:31s remains)
INFO - root - 2022-02-24 21:01:42.030892: step 156550, total loss = 0.58, batch loss = 0.32 (259.8 examples/sec; 0.031 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:01:42.496236: step 156560, total loss = 0.52, batch loss = 0.27 (66.7 examples/sec; 0.120 sec/batch; 1h:25m:49s remains)
INFO - root - 2022-02-24 21:01:42.900564: step 156570, total loss = 0.69, batch loss = 0.43 (286.0 examples/sec; 0.028 sec/batch; 0h:20m:00s remains)
INFO - root - 2022-02-24 21:01:43.410102: step 156580, total loss = 0.50, batch loss = 0.24 (157.6 examples/sec; 0.051 sec/batch; 0h:36m:18s remains)
INFO - root - 2022-02-24 21:01:43.733079: step 156590, total loss = 0.56, batch loss = 0.30 (260.2 examples/sec; 0.031 sec/batch; 0h:21m:59s remains)
INFO - root - 2022-02-24 21:01:44.120631: step 156600, total loss = 0.58, batch loss = 0.32 (160.1 examples/sec; 0.050 sec/batch; 0h:35m:43s remains)
INFO - root - 2022-02-24 21:01:44.586022: step 156610, total loss = 0.56, batch loss = 0.30 (82.1 examples/sec; 0.097 sec/batch; 1h:09m:38s remains)
INFO - root - 2022-02-24 21:01:45.000237: step 156620, total loss = 0.50, batch loss = 0.25 (186.1 examples/sec; 0.043 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:01:45.342830: step 156630, total loss = 0.54, batch loss = 0.29 (358.8 examples/sec; 0.022 sec/batch; 0h:15m:55s remains)
INFO - root - 2022-02-24 21:01:45.693063: step 156640, total loss = 0.55, batch loss = 0.29 (215.7 examples/sec; 0.037 sec/batch; 0h:26m:29s remains)
INFO - root - 2022-02-24 21:01:46.043658: step 156650, total loss = 0.49, batch loss = 0.23 (362.2 examples/sec; 0.022 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:01:46.388057: step 156660, total loss = 0.52, batch loss = 0.26 (165.7 examples/sec; 0.048 sec/batch; 0h:34m:28s remains)
INFO - root - 2022-02-24 21:01:46.703569: step 156670, total loss = 0.63, batch loss = 0.37 (194.0 examples/sec; 0.041 sec/batch; 0h:29m:26s remains)
INFO - root - 2022-02-24 21:01:47.081222: step 156680, total loss = 0.58, batch loss = 0.33 (378.4 examples/sec; 0.021 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:01:47.525244: step 156690, total loss = 0.55, batch loss = 0.30 (208.6 examples/sec; 0.038 sec/batch; 0h:27m:21s remains)
INFO - root - 2022-02-24 21:01:47.952640: step 156700, total loss = 0.54, batch loss = 0.28 (202.3 examples/sec; 0.040 sec/batch; 0h:28m:12s remains)
INFO - root - 2022-02-24 21:01:48.321217: step 156710, total loss = 0.58, batch loss = 0.32 (334.2 examples/sec; 0.024 sec/batch; 0h:17m:04s remains)
INFO - root - 2022-02-24 21:01:48.613069: step 156720, total loss = 0.53, batch loss = 0.27 (260.4 examples/sec; 0.031 sec/batch; 0h:21m:54s remains)
INFO - root - 2022-02-24 21:01:49.075068: step 156730, total loss = 0.58, batch loss = 0.32 (90.3 examples/sec; 0.089 sec/batch; 1h:03m:10s remains)
INFO - root - 2022-02-24 21:01:49.492530: step 156740, total loss = 0.56, batch loss = 0.30 (196.3 examples/sec; 0.041 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 21:01:49.858649: step 156750, total loss = 0.47, batch loss = 0.21 (191.9 examples/sec; 0.042 sec/batch; 0h:29m:42s remains)
INFO - root - 2022-02-24 21:01:50.288264: step 156760, total loss = 0.50, batch loss = 0.24 (146.6 examples/sec; 0.055 sec/batch; 0h:38m:52s remains)
INFO - root - 2022-02-24 21:01:50.604129: step 156770, total loss = 0.56, batch loss = 0.30 (177.3 examples/sec; 0.045 sec/batch; 0h:32m:07s remains)
INFO - root - 2022-02-24 21:01:50.954400: step 156780, total loss = 0.71, batch loss = 0.46 (348.4 examples/sec; 0.023 sec/batch; 0h:16m:21s remains)
INFO - root - 2022-02-24 21:01:51.348140: step 156790, total loss = 0.53, batch loss = 0.28 (350.9 examples/sec; 0.023 sec/batch; 0h:16m:13s remains)
INFO - root - 2022-02-24 21:01:51.728537: step 156800, total loss = 0.60, batch loss = 0.34 (326.8 examples/sec; 0.024 sec/batch; 0h:17m:25s remains)
INFO - root - 2022-02-24 21:01:52.122952: step 156810, total loss = 0.46, batch loss = 0.20 (282.2 examples/sec; 0.028 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:01:52.451653: step 156820, total loss = 0.60, batch loss = 0.34 (117.5 examples/sec; 0.068 sec/batch; 0h:48m:26s remains)
INFO - root - 2022-02-24 21:01:52.743354: step 156830, total loss = 0.54, batch loss = 0.29 (258.2 examples/sec; 0.031 sec/batch; 0h:22m:01s remains)
INFO - root - 2022-02-24 21:01:53.127500: step 156840, total loss = 0.64, batch loss = 0.38 (199.1 examples/sec; 0.040 sec/batch; 0h:28m:34s remains)
INFO - root - 2022-02-24 21:01:53.612908: step 156850, total loss = 0.62, batch loss = 0.36 (399.0 examples/sec; 0.020 sec/batch; 0h:14m:15s remains)
INFO - root - 2022-02-24 21:01:54.013534: step 156860, total loss = 0.62, batch loss = 0.36 (229.1 examples/sec; 0.035 sec/batch; 0h:24m:49s remains)
INFO - root - 2022-02-24 21:01:54.308807: step 156870, total loss = 0.55, batch loss = 0.29 (160.7 examples/sec; 0.050 sec/batch; 0h:35m:21s remains)
INFO - root - 2022-02-24 21:01:54.690881: step 156880, total loss = 0.48, batch loss = 0.22 (324.9 examples/sec; 0.025 sec/batch; 0h:17m:29s remains)
INFO - root - 2022-02-24 21:01:55.122938: step 156890, total loss = 0.53, batch loss = 0.28 (354.8 examples/sec; 0.023 sec/batch; 0h:16m:00s remains)
INFO - root - 2022-02-24 21:01:55.546026: step 156900, total loss = 0.50, batch loss = 0.24 (146.9 examples/sec; 0.054 sec/batch; 0h:38m:40s remains)
INFO - root - 2022-02-24 21:01:56.020563: step 156910, total loss = 0.53, batch loss = 0.27 (183.3 examples/sec; 0.044 sec/batch; 0h:30m:59s remains)
INFO - root - 2022-02-24 21:01:56.347125: step 156920, total loss = 0.64, batch loss = 0.39 (243.3 examples/sec; 0.033 sec/batch; 0h:23m:20s remains)
INFO - root - 2022-02-24 21:01:56.705352: step 156930, total loss = 0.60, batch loss = 0.34 (258.0 examples/sec; 0.031 sec/batch; 0h:21m:59s remains)
INFO - root - 2022-02-24 21:01:57.030834: step 156940, total loss = 0.50, batch loss = 0.24 (344.0 examples/sec; 0.023 sec/batch; 0h:16m:29s remains)
INFO - root - 2022-02-24 21:01:57.388849: step 156950, total loss = 0.73, batch loss = 0.47 (318.5 examples/sec; 0.025 sec/batch; 0h:17m:48s remains)
INFO - root - 2022-02-24 21:01:57.882131: step 156960, total loss = 0.47, batch loss = 0.21 (112.1 examples/sec; 0.071 sec/batch; 0h:50m:36s remains)
INFO - root - 2022-02-24 21:01:58.338856: step 156970, total loss = 0.55, batch loss = 0.30 (192.6 examples/sec; 0.042 sec/batch; 0h:29m:26s remains)
INFO - root - 2022-02-24 21:01:58.680948: step 156980, total loss = 0.58, batch loss = 0.32 (154.4 examples/sec; 0.052 sec/batch; 0h:36m:42s remains)
INFO - root - 2022-02-24 21:01:59.003004: step 156990, total loss = 0.50, batch loss = 0.24 (335.2 examples/sec; 0.024 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:01:59.392145: step 157000, total loss = 0.60, batch loss = 0.35 (122.5 examples/sec; 0.065 sec/batch; 0h:46m:14s remains)
INFO - root - 2022-02-24 21:01:59.898179: step 157010, total loss = 0.48, batch loss = 0.23 (230.5 examples/sec; 0.035 sec/batch; 0h:24m:34s remains)
INFO - root - 2022-02-24 21:02:00.290878: step 157020, total loss = 0.60, batch loss = 0.34 (316.3 examples/sec; 0.025 sec/batch; 0h:17m:54s remains)
INFO - root - 2022-02-24 21:02:00.724238: step 157030, total loss = 0.47, batch loss = 0.21 (148.3 examples/sec; 0.054 sec/batch; 0h:38m:10s remains)
INFO - root - 2022-02-24 21:02:01.091375: step 157040, total loss = 0.50, batch loss = 0.24 (180.5 examples/sec; 0.044 sec/batch; 0h:31m:21s remains)
INFO - root - 2022-02-24 21:02:01.471392: step 157050, total loss = 0.47, batch loss = 0.21 (293.5 examples/sec; 0.027 sec/batch; 0h:19m:16s remains)
INFO - root - 2022-02-24 21:02:01.825934: step 157060, total loss = 0.56, batch loss = 0.31 (192.6 examples/sec; 0.042 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 21:02:02.256074: step 157070, total loss = 0.52, batch loss = 0.27 (237.4 examples/sec; 0.034 sec/batch; 0h:23m:49s remains)
INFO - root - 2022-02-24 21:02:02.649915: step 157080, total loss = 0.56, batch loss = 0.30 (340.8 examples/sec; 0.023 sec/batch; 0h:16m:35s remains)
INFO - root - 2022-02-24 21:02:03.044056: step 157090, total loss = 0.54, batch loss = 0.28 (351.6 examples/sec; 0.023 sec/batch; 0h:16m:05s remains)
INFO - root - 2022-02-24 21:02:03.372008: step 157100, total loss = 0.46, batch loss = 0.21 (248.1 examples/sec; 0.032 sec/batch; 0h:22m:46s remains)
INFO - root - 2022-02-24 21:02:03.834344: step 157110, total loss = 0.51, batch loss = 0.25 (143.6 examples/sec; 0.056 sec/batch; 0h:39m:22s remains)
INFO - root - 2022-02-24 21:02:04.358137: step 157120, total loss = 0.46, batch loss = 0.21 (125.3 examples/sec; 0.064 sec/batch; 0h:45m:04s remains)
INFO - root - 2022-02-24 21:02:04.814255: step 157130, total loss = 0.69, batch loss = 0.44 (342.2 examples/sec; 0.023 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:02:05.168828: step 157140, total loss = 0.53, batch loss = 0.27 (370.2 examples/sec; 0.022 sec/batch; 0h:15m:15s remains)
INFO - root - 2022-02-24 21:02:05.532502: step 157150, total loss = 0.64, batch loss = 0.38 (151.6 examples/sec; 0.053 sec/batch; 0h:37m:14s remains)
INFO - root - 2022-02-24 21:02:05.890021: step 157160, total loss = 0.55, batch loss = 0.30 (314.7 examples/sec; 0.025 sec/batch; 0h:17m:56s remains)
INFO - root - 2022-02-24 21:02:06.314987: step 157170, total loss = 0.52, batch loss = 0.26 (142.0 examples/sec; 0.056 sec/batch; 0h:39m:44s remains)
INFO - root - 2022-02-24 21:02:06.801158: step 157180, total loss = 0.54, batch loss = 0.28 (360.1 examples/sec; 0.022 sec/batch; 0h:15m:40s remains)
INFO - root - 2022-02-24 21:02:07.217465: step 157190, total loss = 0.56, batch loss = 0.30 (356.6 examples/sec; 0.022 sec/batch; 0h:15m:49s remains)
INFO - root - 2022-02-24 21:02:07.636864: step 157200, total loss = 0.46, batch loss = 0.20 (283.9 examples/sec; 0.028 sec/batch; 0h:19m:52s remains)
INFO - root - 2022-02-24 21:02:08.030570: step 157210, total loss = 0.48, batch loss = 0.23 (207.8 examples/sec; 0.038 sec/batch; 0h:27m:08s remains)
INFO - root - 2022-02-24 21:02:08.372363: step 157220, total loss = 0.58, batch loss = 0.32 (183.6 examples/sec; 0.044 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:02:08.836957: step 157230, total loss = 0.63, batch loss = 0.38 (306.6 examples/sec; 0.026 sec/batch; 0h:18m:23s remains)
INFO - root - 2022-02-24 21:02:09.231673: step 157240, total loss = 0.55, batch loss = 0.30 (239.5 examples/sec; 0.033 sec/batch; 0h:23m:31s remains)
INFO - root - 2022-02-24 21:02:09.600552: step 157250, total loss = 0.53, batch loss = 0.28 (333.2 examples/sec; 0.024 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:02:09.976465: step 157260, total loss = 0.57, batch loss = 0.31 (347.5 examples/sec; 0.023 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:02:10.252784: step 157270, total loss = 0.51, batch loss = 0.25 (366.0 examples/sec; 0.022 sec/batch; 0h:15m:23s remains)
INFO - root - 2022-02-24 21:02:10.683418: step 157280, total loss = 0.58, batch loss = 0.32 (117.9 examples/sec; 0.068 sec/batch; 0h:47m:45s remains)
INFO - root - 2022-02-24 21:02:11.123208: step 157290, total loss = 0.58, batch loss = 0.32 (202.0 examples/sec; 0.040 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 21:02:11.514639: step 157300, total loss = 0.55, batch loss = 0.29 (181.1 examples/sec; 0.044 sec/batch; 0h:31m:04s remains)
INFO - root - 2022-02-24 21:02:11.887123: step 157310, total loss = 0.49, batch loss = 0.23 (315.9 examples/sec; 0.025 sec/batch; 0h:17m:48s remains)
INFO - root - 2022-02-24 21:02:12.209142: step 157320, total loss = 0.68, batch loss = 0.42 (207.8 examples/sec; 0.039 sec/batch; 0h:27m:03s remains)
INFO - root - 2022-02-24 21:02:12.807338: step 157330, total loss = 0.52, batch loss = 0.26 (54.5 examples/sec; 0.147 sec/batch; 1h:43m:05s remains)
INFO - root - 2022-02-24 21:02:13.247039: step 157340, total loss = 0.52, batch loss = 0.26 (316.3 examples/sec; 0.025 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:02:13.797537: step 157350, total loss = 0.54, batch loss = 0.28 (167.4 examples/sec; 0.048 sec/batch; 0h:33m:34s remains)
INFO - root - 2022-02-24 21:02:14.530602: step 157360, total loss = 0.56, batch loss = 0.31 (114.1 examples/sec; 0.070 sec/batch; 0h:49m:15s remains)
INFO - root - 2022-02-24 21:02:15.151333: step 157370, total loss = 0.52, batch loss = 0.27 (304.0 examples/sec; 0.026 sec/batch; 0h:18m:28s remains)
INFO - root - 2022-02-24 21:02:15.808165: step 157380, total loss = 0.56, batch loss = 0.30 (85.4 examples/sec; 0.094 sec/batch; 1h:05m:47s remains)
INFO - root - 2022-02-24 21:02:16.296276: step 157390, total loss = 0.52, batch loss = 0.26 (270.4 examples/sec; 0.030 sec/batch; 0h:20m:45s remains)
INFO - root - 2022-02-24 21:02:16.705892: step 157400, total loss = 0.52, batch loss = 0.27 (173.1 examples/sec; 0.046 sec/batch; 0h:32m:25s remains)
INFO - root - 2022-02-24 21:02:17.228182: step 157410, total loss = 0.49, batch loss = 0.23 (325.2 examples/sec; 0.025 sec/batch; 0h:17m:15s remains)
INFO - root - 2022-02-24 21:02:17.636579: step 157420, total loss = 0.45, batch loss = 0.20 (164.3 examples/sec; 0.049 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 21:02:18.419420: step 157430, total loss = 0.62, batch loss = 0.37 (106.3 examples/sec; 0.075 sec/batch; 0h:52m:44s remains)
INFO - root - 2022-02-24 21:02:18.835971: step 157440, total loss = 0.63, batch loss = 0.37 (196.3 examples/sec; 0.041 sec/batch; 0h:28m:34s remains)
INFO - root - 2022-02-24 21:02:19.291012: step 157450, total loss = 0.47, batch loss = 0.21 (176.5 examples/sec; 0.045 sec/batch; 0h:31m:46s remains)
INFO - root - 2022-02-24 21:02:19.715935: step 157460, total loss = 0.49, batch loss = 0.23 (327.8 examples/sec; 0.024 sec/batch; 0h:17m:05s remains)
INFO - root - 2022-02-24 21:02:20.104707: step 157470, total loss = 0.59, batch loss = 0.33 (141.3 examples/sec; 0.057 sec/batch; 0h:39m:39s remains)
INFO - root - 2022-02-24 21:02:20.429434: step 157480, total loss = 0.54, batch loss = 0.28 (323.8 examples/sec; 0.025 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:02:20.797659: step 157490, total loss = 0.50, batch loss = 0.25 (255.5 examples/sec; 0.031 sec/batch; 0h:21m:55s remains)
INFO - root - 2022-02-24 21:02:21.164505: step 157500, total loss = 0.66, batch loss = 0.40 (195.7 examples/sec; 0.041 sec/batch; 0h:28m:36s remains)
INFO - root - 2022-02-24 21:02:21.570631: step 157510, total loss = 0.50, batch loss = 0.24 (184.0 examples/sec; 0.043 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 21:02:21.887120: step 157520, total loss = 0.54, batch loss = 0.28 (323.4 examples/sec; 0.025 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:02:22.171741: step 157530, total loss = 0.48, batch loss = 0.23 (245.0 examples/sec; 0.033 sec/batch; 0h:22m:50s remains)
INFO - root - 2022-02-24 21:02:22.502055: step 157540, total loss = 0.58, batch loss = 0.32 (195.2 examples/sec; 0.041 sec/batch; 0h:28m:40s remains)
INFO - root - 2022-02-24 21:02:22.812050: step 157550, total loss = 0.55, batch loss = 0.30 (352.8 examples/sec; 0.023 sec/batch; 0h:15m:51s remains)
INFO - root - 2022-02-24 21:02:23.324557: step 157560, total loss = 0.73, batch loss = 0.47 (130.7 examples/sec; 0.061 sec/batch; 0h:42m:47s remains)
INFO - root - 2022-02-24 21:02:23.788533: step 157570, total loss = 0.52, batch loss = 0.26 (163.1 examples/sec; 0.049 sec/batch; 0h:34m:16s remains)
INFO - root - 2022-02-24 21:02:24.153660: step 157580, total loss = 0.52, batch loss = 0.26 (191.6 examples/sec; 0.042 sec/batch; 0h:29m:10s remains)
INFO - root - 2022-02-24 21:02:24.474248: step 157590, total loss = 0.48, batch loss = 0.23 (171.8 examples/sec; 0.047 sec/batch; 0h:32m:31s remains)
INFO - root - 2022-02-24 21:02:24.797454: step 157600, total loss = 0.54, batch loss = 0.29 (266.2 examples/sec; 0.030 sec/batch; 0h:20m:59s remains)
INFO - root - 2022-02-24 21:02:25.245258: step 157610, total loss = 0.63, batch loss = 0.38 (284.4 examples/sec; 0.028 sec/batch; 0h:19m:38s remains)
INFO - root - 2022-02-24 21:02:25.668385: step 157620, total loss = 0.50, batch loss = 0.25 (223.4 examples/sec; 0.036 sec/batch; 0h:24m:59s remains)
INFO - root - 2022-02-24 21:02:25.955117: step 157630, total loss = 0.49, batch loss = 0.24 (342.9 examples/sec; 0.023 sec/batch; 0h:16m:16s remains)
INFO - root - 2022-02-24 21:02:26.263165: step 157640, total loss = 0.52, batch loss = 0.26 (271.2 examples/sec; 0.029 sec/batch; 0h:20m:34s remains)
INFO - root - 2022-02-24 21:02:26.587707: step 157650, total loss = 0.60, batch loss = 0.34 (363.0 examples/sec; 0.022 sec/batch; 0h:15m:22s remains)
INFO - root - 2022-02-24 21:02:26.955030: step 157660, total loss = 0.50, batch loss = 0.24 (229.4 examples/sec; 0.035 sec/batch; 0h:24m:18s remains)
INFO - root - 2022-02-24 21:02:27.417910: step 157670, total loss = 0.51, batch loss = 0.26 (229.7 examples/sec; 0.035 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 21:02:27.766972: step 157680, total loss = 0.50, batch loss = 0.24 (313.5 examples/sec; 0.026 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 21:02:28.107846: step 157690, total loss = 0.54, batch loss = 0.28 (333.9 examples/sec; 0.024 sec/batch; 0h:16m:41s remains)
INFO - root - 2022-02-24 21:02:28.460879: step 157700, total loss = 0.55, batch loss = 0.29 (241.5 examples/sec; 0.033 sec/batch; 0h:23m:04s remains)
INFO - root - 2022-02-24 21:02:28.898871: step 157710, total loss = 0.50, batch loss = 0.24 (290.4 examples/sec; 0.028 sec/batch; 0h:19m:11s remains)
INFO - root - 2022-02-24 21:02:29.376434: step 157720, total loss = 0.56, batch loss = 0.30 (172.0 examples/sec; 0.047 sec/batch; 0h:32m:23s remains)
INFO - root - 2022-02-24 21:02:29.834698: step 157730, total loss = 0.52, batch loss = 0.27 (251.2 examples/sec; 0.032 sec/batch; 0h:22m:10s remains)
INFO - root - 2022-02-24 21:02:30.162644: step 157740, total loss = 0.61, batch loss = 0.35 (351.1 examples/sec; 0.023 sec/batch; 0h:15m:51s remains)
INFO - root - 2022-02-24 21:02:30.538895: step 157750, total loss = 0.50, batch loss = 0.24 (340.8 examples/sec; 0.023 sec/batch; 0h:16m:20s remains)
INFO - root - 2022-02-24 21:02:30.860031: step 157760, total loss = 0.68, batch loss = 0.43 (302.4 examples/sec; 0.026 sec/batch; 0h:18m:24s remains)
INFO - root - 2022-02-24 21:02:31.217802: step 157770, total loss = 0.50, batch loss = 0.24 (178.1 examples/sec; 0.045 sec/batch; 0h:31m:14s remains)
INFO - root - 2022-02-24 21:02:31.706854: step 157780, total loss = 0.52, batch loss = 0.26 (165.5 examples/sec; 0.048 sec/batch; 0h:33m:37s remains)
INFO - root - 2022-02-24 21:02:32.104122: step 157790, total loss = 0.64, batch loss = 0.38 (232.1 examples/sec; 0.034 sec/batch; 0h:23m:57s remains)
INFO - root - 2022-02-24 21:02:32.517750: step 157800, total loss = 0.75, batch loss = 0.49 (133.0 examples/sec; 0.060 sec/batch; 0h:41m:47s remains)
INFO - root - 2022-02-24 21:02:32.858951: step 157810, total loss = 0.56, batch loss = 0.31 (329.8 examples/sec; 0.024 sec/batch; 0h:16m:51s remains)
INFO - root - 2022-02-24 21:02:33.314608: step 157820, total loss = 0.51, batch loss = 0.26 (114.7 examples/sec; 0.070 sec/batch; 0h:48m:27s remains)
INFO - root - 2022-02-24 21:02:33.773862: step 157830, total loss = 0.68, batch loss = 0.43 (139.6 examples/sec; 0.057 sec/batch; 0h:39m:48s remains)
INFO - root - 2022-02-24 21:02:34.166761: step 157840, total loss = 0.54, batch loss = 0.28 (263.8 examples/sec; 0.030 sec/batch; 0h:21m:03s remains)
INFO - root - 2022-02-24 21:02:34.464881: step 157850, total loss = 0.64, batch loss = 0.38 (289.3 examples/sec; 0.028 sec/batch; 0h:19m:11s remains)
INFO - root - 2022-02-24 21:02:34.817578: step 157860, total loss = 0.53, batch loss = 0.27 (358.1 examples/sec; 0.022 sec/batch; 0h:15m:30s remains)
INFO - root - 2022-02-24 21:02:35.165155: step 157870, total loss = 0.57, batch loss = 0.32 (305.4 examples/sec; 0.026 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 21:02:35.571366: step 157880, total loss = 0.55, batch loss = 0.30 (102.4 examples/sec; 0.078 sec/batch; 0h:54m:10s remains)
INFO - root - 2022-02-24 21:02:35.960157: step 157890, total loss = 0.44, batch loss = 0.19 (223.6 examples/sec; 0.036 sec/batch; 0h:24m:48s remains)
INFO - root - 2022-02-24 21:02:36.346811: step 157900, total loss = 0.70, batch loss = 0.44 (168.9 examples/sec; 0.047 sec/batch; 0h:32m:50s remains)
INFO - root - 2022-02-24 21:02:36.751960: step 157910, total loss = 0.50, batch loss = 0.25 (312.1 examples/sec; 0.026 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:02:37.122635: step 157920, total loss = 0.46, batch loss = 0.20 (213.8 examples/sec; 0.037 sec/batch; 0h:25m:55s remains)
INFO - root - 2022-02-24 21:02:37.621276: step 157930, total loss = 0.50, batch loss = 0.25 (185.3 examples/sec; 0.043 sec/batch; 0h:29m:54s remains)
INFO - root - 2022-02-24 21:02:38.092241: step 157940, total loss = 0.58, batch loss = 0.33 (222.7 examples/sec; 0.036 sec/batch; 0h:24m:53s remains)
INFO - root - 2022-02-24 21:02:38.530783: step 157950, total loss = 0.46, batch loss = 0.20 (309.5 examples/sec; 0.026 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 21:02:38.882316: step 157960, total loss = 0.50, batch loss = 0.24 (324.4 examples/sec; 0.025 sec/batch; 0h:17m:04s remains)
INFO - root - 2022-02-24 21:02:39.265902: step 157970, total loss = 0.52, batch loss = 0.26 (314.3 examples/sec; 0.025 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:02:39.580323: step 157980, total loss = 0.51, batch loss = 0.25 (211.4 examples/sec; 0.038 sec/batch; 0h:26m:11s remains)
INFO - root - 2022-02-24 21:02:39.982439: step 157990, total loss = 0.63, batch loss = 0.37 (205.7 examples/sec; 0.039 sec/batch; 0h:26m:54s remains)
INFO - root - 2022-02-24 21:02:40.400614: step 158000, total loss = 0.50, batch loss = 0.25 (295.7 examples/sec; 0.027 sec/batch; 0h:18m:42s remains)
INFO - root - 2022-02-24 21:02:40.750492: step 158010, total loss = 0.49, batch loss = 0.24 (357.1 examples/sec; 0.022 sec/batch; 0h:15m:29s remains)
INFO - root - 2022-02-24 21:02:41.109235: step 158020, total loss = 0.56, batch loss = 0.30 (169.8 examples/sec; 0.047 sec/batch; 0h:32m:34s remains)
INFO - root - 2022-02-24 21:02:41.523877: step 158030, total loss = 0.65, batch loss = 0.39 (108.5 examples/sec; 0.074 sec/batch; 0h:50m:58s remains)
INFO - root - 2022-02-24 21:02:42.134550: step 158040, total loss = 0.52, batch loss = 0.27 (332.9 examples/sec; 0.024 sec/batch; 0h:16m:36s remains)
INFO - root - 2022-02-24 21:02:42.602515: step 158050, total loss = 0.56, batch loss = 0.30 (333.1 examples/sec; 0.024 sec/batch; 0h:16m:35s remains)
INFO - root - 2022-02-24 21:02:42.923620: step 158060, total loss = 0.50, batch loss = 0.24 (225.3 examples/sec; 0.036 sec/batch; 0h:24m:31s remains)
INFO - root - 2022-02-24 21:02:43.831570: step 158070, total loss = 0.57, batch loss = 0.32 (264.3 examples/sec; 0.030 sec/batch; 0h:20m:53s remains)
INFO - root - 2022-02-24 21:02:44.322923: step 158080, total loss = 0.75, batch loss = 0.49 (112.7 examples/sec; 0.071 sec/batch; 0h:49m:00s remains)
INFO - root - 2022-02-24 21:02:44.703503: step 158090, total loss = 0.52, batch loss = 0.27 (199.6 examples/sec; 0.040 sec/batch; 0h:27m:40s remains)
INFO - root - 2022-02-24 21:02:45.081110: step 158100, total loss = 0.59, batch loss = 0.33 (186.2 examples/sec; 0.043 sec/batch; 0h:29m:38s remains)
INFO - root - 2022-02-24 21:02:45.677697: step 158110, total loss = 0.56, batch loss = 0.30 (349.9 examples/sec; 0.023 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:02:46.062788: step 158120, total loss = 0.48, batch loss = 0.22 (212.7 examples/sec; 0.038 sec/batch; 0h:25m:56s remains)
INFO - root - 2022-02-24 21:02:46.587436: step 158130, total loss = 0.54, batch loss = 0.28 (153.8 examples/sec; 0.052 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 21:02:47.026031: step 158140, total loss = 0.55, batch loss = 0.30 (207.1 examples/sec; 0.039 sec/batch; 0h:26m:37s remains)
INFO - root - 2022-02-24 21:02:47.376585: step 158150, total loss = 0.46, batch loss = 0.20 (309.8 examples/sec; 0.026 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 21:02:47.771791: step 158160, total loss = 0.55, batch loss = 0.30 (281.5 examples/sec; 0.028 sec/batch; 0h:19m:34s remains)
INFO - root - 2022-02-24 21:02:48.236025: step 158170, total loss = 0.49, batch loss = 0.23 (134.3 examples/sec; 0.060 sec/batch; 0h:41m:01s remains)
INFO - root - 2022-02-24 21:02:49.016108: step 158180, total loss = 0.53, batch loss = 0.28 (210.6 examples/sec; 0.038 sec/batch; 0h:26m:09s remains)
INFO - root - 2022-02-24 21:02:49.372644: step 158190, total loss = 0.54, batch loss = 0.28 (249.6 examples/sec; 0.032 sec/batch; 0h:22m:04s remains)
INFO - root - 2022-02-24 21:02:49.698096: step 158200, total loss = 0.46, batch loss = 0.20 (140.5 examples/sec; 0.057 sec/batch; 0h:39m:11s remains)
INFO - root - 2022-02-24 21:02:50.101932: step 158210, total loss = 0.68, batch loss = 0.42 (327.4 examples/sec; 0.024 sec/batch; 0h:16m:48s remains)
INFO - root - 2022-02-24 21:02:50.624870: step 158220, total loss = 0.59, batch loss = 0.33 (192.4 examples/sec; 0.042 sec/batch; 0h:28m:36s remains)
INFO - root - 2022-02-24 21:02:50.961649: step 158230, total loss = 0.60, batch loss = 0.34 (323.8 examples/sec; 0.025 sec/batch; 0h:16m:59s remains)
INFO - root - 2022-02-24 21:02:51.299015: step 158240, total loss = 0.56, batch loss = 0.31 (246.1 examples/sec; 0.033 sec/batch; 0h:22m:21s remains)
INFO - root - 2022-02-24 21:02:51.602610: step 158250, total loss = 0.54, batch loss = 0.29 (364.0 examples/sec; 0.022 sec/batch; 0h:15m:06s remains)
INFO - root - 2022-02-24 21:02:51.914625: step 158260, total loss = 0.56, batch loss = 0.30 (352.1 examples/sec; 0.023 sec/batch; 0h:15m:36s remains)
INFO - root - 2022-02-24 21:02:52.362456: step 158270, total loss = 0.49, batch loss = 0.23 (186.0 examples/sec; 0.043 sec/batch; 0h:29m:33s remains)
INFO - root - 2022-02-24 21:02:52.778703: step 158280, total loss = 0.56, batch loss = 0.30 (143.5 examples/sec; 0.056 sec/batch; 0h:38m:17s remains)
INFO - root - 2022-02-24 21:02:53.120388: step 158290, total loss = 0.51, batch loss = 0.25 (234.7 examples/sec; 0.034 sec/batch; 0h:23m:24s remains)
INFO - root - 2022-02-24 21:02:53.439879: step 158300, total loss = 0.57, batch loss = 0.32 (182.0 examples/sec; 0.044 sec/batch; 0h:30m:11s remains)
INFO - root - 2022-02-24 21:02:53.834119: step 158310, total loss = 0.60, batch loss = 0.34 (193.1 examples/sec; 0.041 sec/batch; 0h:28m:26s remains)
INFO - root - 2022-02-24 21:02:54.291757: step 158320, total loss = 0.52, batch loss = 0.26 (247.4 examples/sec; 0.032 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 21:02:54.759886: step 158330, total loss = 0.52, batch loss = 0.26 (170.6 examples/sec; 0.047 sec/batch; 0h:32m:10s remains)
INFO - root - 2022-02-24 21:02:55.196308: step 158340, total loss = 0.52, batch loss = 0.27 (371.7 examples/sec; 0.022 sec/batch; 0h:14m:45s remains)
INFO - root - 2022-02-24 21:02:55.493120: step 158350, total loss = 0.55, batch loss = 0.30 (300.6 examples/sec; 0.027 sec/batch; 0h:18m:15s remains)
INFO - root - 2022-02-24 21:02:55.876448: step 158360, total loss = 0.67, batch loss = 0.42 (209.7 examples/sec; 0.038 sec/batch; 0h:26m:09s remains)
INFO - root - 2022-02-24 21:02:56.246876: step 158370, total loss = 0.56, batch loss = 0.30 (212.4 examples/sec; 0.038 sec/batch; 0h:25m:49s remains)
INFO - root - 2022-02-24 21:02:56.620433: step 158380, total loss = 0.56, batch loss = 0.31 (213.2 examples/sec; 0.038 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 21:02:56.986496: step 158390, total loss = 0.54, batch loss = 0.28 (340.4 examples/sec; 0.024 sec/batch; 0h:16m:06s remains)
INFO - root - 2022-02-24 21:02:57.423703: step 158400, total loss = 0.54, batch loss = 0.28 (111.6 examples/sec; 0.072 sec/batch; 0h:49m:05s remains)
INFO - root - 2022-02-24 21:02:57.961503: step 158410, total loss = 0.50, batch loss = 0.25 (252.8 examples/sec; 0.032 sec/batch; 0h:21m:40s remains)
INFO - root - 2022-02-24 21:02:58.361906: step 158420, total loss = 0.56, batch loss = 0.30 (242.6 examples/sec; 0.033 sec/batch; 0h:22m:34s remains)
INFO - root - 2022-02-24 21:02:58.693596: step 158430, total loss = 0.46, batch loss = 0.20 (314.9 examples/sec; 0.025 sec/batch; 0h:17m:23s remains)
INFO - root - 2022-02-24 21:02:59.173072: step 158440, total loss = 0.45, batch loss = 0.19 (267.5 examples/sec; 0.030 sec/batch; 0h:20m:27s remains)
INFO - root - 2022-02-24 21:02:59.515354: step 158450, total loss = 0.48, batch loss = 0.22 (116.0 examples/sec; 0.069 sec/batch; 0h:47m:11s remains)
INFO - root - 2022-02-24 21:02:59.980726: step 158460, total loss = 0.50, batch loss = 0.25 (339.8 examples/sec; 0.024 sec/batch; 0h:16m:06s remains)
INFO - root - 2022-02-24 21:03:00.386925: step 158470, total loss = 0.47, batch loss = 0.22 (214.6 examples/sec; 0.037 sec/batch; 0h:25m:29s remains)
INFO - root - 2022-02-24 21:03:00.740187: step 158480, total loss = 0.60, batch loss = 0.35 (189.2 examples/sec; 0.042 sec/batch; 0h:28m:54s remains)
INFO - root - 2022-02-24 21:03:01.205280: step 158490, total loss = 0.52, batch loss = 0.26 (105.0 examples/sec; 0.076 sec/batch; 0h:52m:03s remains)
INFO - root - 2022-02-24 21:03:01.675096: step 158500, total loss = 0.50, batch loss = 0.24 (174.2 examples/sec; 0.046 sec/batch; 0h:31m:22s remains)
INFO - root - 2022-02-24 21:03:02.199603: step 158510, total loss = 0.55, batch loss = 0.29 (256.3 examples/sec; 0.031 sec/batch; 0h:21m:19s remains)
INFO - root - 2022-02-24 21:03:02.514767: step 158520, total loss = 0.59, batch loss = 0.33 (295.3 examples/sec; 0.027 sec/batch; 0h:18m:30s remains)
INFO - root - 2022-02-24 21:03:02.801772: step 158530, total loss = 0.59, batch loss = 0.33 (264.7 examples/sec; 0.030 sec/batch; 0h:20m:38s remains)
INFO - root - 2022-02-24 21:03:03.195690: step 158540, total loss = 0.54, batch loss = 0.28 (145.3 examples/sec; 0.055 sec/batch; 0h:37m:34s remains)
INFO - root - 2022-02-24 21:03:03.675614: step 158550, total loss = 0.50, batch loss = 0.24 (152.4 examples/sec; 0.052 sec/batch; 0h:35m:49s remains)
INFO - root - 2022-02-24 21:03:04.138044: step 158560, total loss = 0.49, batch loss = 0.23 (154.7 examples/sec; 0.052 sec/batch; 0h:35m:17s remains)
INFO - root - 2022-02-24 21:03:04.447653: step 158570, total loss = 0.59, batch loss = 0.33 (276.2 examples/sec; 0.029 sec/batch; 0h:19m:45s remains)
INFO - root - 2022-02-24 21:03:04.809756: step 158580, total loss = 0.61, batch loss = 0.36 (334.8 examples/sec; 0.024 sec/batch; 0h:16m:17s remains)
INFO - root - 2022-02-24 21:03:05.094246: step 158590, total loss = 0.45, batch loss = 0.20 (287.7 examples/sec; 0.028 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 21:03:05.509071: step 158600, total loss = 0.58, batch loss = 0.33 (142.7 examples/sec; 0.056 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 21:03:06.030080: step 158610, total loss = 0.49, batch loss = 0.23 (154.6 examples/sec; 0.052 sec/batch; 0h:35m:16s remains)
INFO - root - 2022-02-24 21:03:06.451109: step 158620, total loss = 0.48, batch loss = 0.23 (217.0 examples/sec; 0.037 sec/batch; 0h:25m:07s remains)
INFO - root - 2022-02-24 21:03:06.819967: step 158630, total loss = 0.60, batch loss = 0.34 (218.8 examples/sec; 0.037 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 21:03:07.217813: step 158640, total loss = 0.65, batch loss = 0.39 (298.8 examples/sec; 0.027 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 21:03:07.690430: step 158650, total loss = 0.51, batch loss = 0.25 (214.6 examples/sec; 0.037 sec/batch; 0h:25m:22s remains)
INFO - root - 2022-02-24 21:03:08.124605: step 158660, total loss = 0.63, batch loss = 0.37 (271.5 examples/sec; 0.029 sec/batch; 0h:20m:03s remains)
INFO - root - 2022-02-24 21:03:08.570923: step 158670, total loss = 0.60, batch loss = 0.34 (224.4 examples/sec; 0.036 sec/batch; 0h:24m:15s remains)
INFO - root - 2022-02-24 21:03:08.959063: step 158680, total loss = 0.58, batch loss = 0.32 (200.5 examples/sec; 0.040 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 21:03:09.849252: step 158690, total loss = 0.55, batch loss = 0.29 (141.8 examples/sec; 0.056 sec/batch; 0h:38m:22s remains)
INFO - root - 2022-02-24 21:03:10.277596: step 158700, total loss = 0.53, batch loss = 0.27 (111.3 examples/sec; 0.072 sec/batch; 0h:48m:52s remains)
INFO - root - 2022-02-24 21:03:11.151182: step 158710, total loss = 0.66, batch loss = 0.41 (343.9 examples/sec; 0.023 sec/batch; 0h:15m:49s remains)
INFO - root - 2022-02-24 21:03:11.397864: step 158720, total loss = 0.47, batch loss = 0.22 (335.8 examples/sec; 0.024 sec/batch; 0h:16m:11s remains)
INFO - root - 2022-02-24 21:03:11.648858: step 158730, total loss = 0.56, batch loss = 0.30 (363.6 examples/sec; 0.022 sec/batch; 0h:14m:57s remains)
INFO - root - 2022-02-24 21:03:11.920800: step 158740, total loss = 0.58, batch loss = 0.32 (207.3 examples/sec; 0.039 sec/batch; 0h:26m:13s remains)
INFO - root - 2022-02-24 21:03:12.408239: step 158750, total loss = 0.51, batch loss = 0.25 (151.0 examples/sec; 0.053 sec/batch; 0h:35m:59s remains)
INFO - root - 2022-02-24 21:03:12.850950: step 158760, total loss = 0.51, batch loss = 0.26 (280.1 examples/sec; 0.029 sec/batch; 0h:19m:23s remains)
INFO - root - 2022-02-24 21:03:13.220548: step 158770, total loss = 0.52, batch loss = 0.26 (300.5 examples/sec; 0.027 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:03:13.585379: step 158780, total loss = 0.51, batch loss = 0.25 (285.4 examples/sec; 0.028 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:03:13.967914: step 158790, total loss = 0.50, batch loss = 0.24 (329.2 examples/sec; 0.024 sec/batch; 0h:16m:29s remains)
INFO - root - 2022-02-24 21:03:14.565336: step 158800, total loss = 0.49, batch loss = 0.23 (126.1 examples/sec; 0.063 sec/batch; 0h:43m:01s remains)
INFO - root - 2022-02-24 21:03:15.074585: step 158810, total loss = 0.50, batch loss = 0.24 (357.3 examples/sec; 0.022 sec/batch; 0h:15m:11s remains)
INFO - root - 2022-02-24 21:03:15.457678: step 158820, total loss = 0.52, batch loss = 0.26 (164.3 examples/sec; 0.049 sec/batch; 0h:33m:00s remains)
INFO - root - 2022-02-24 21:03:15.858015: step 158830, total loss = 0.44, batch loss = 0.19 (327.7 examples/sec; 0.024 sec/batch; 0h:16m:32s remains)
INFO - root - 2022-02-24 21:03:16.186498: step 158840, total loss = 0.62, batch loss = 0.37 (245.9 examples/sec; 0.033 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:03:16.661651: step 158850, total loss = 0.51, batch loss = 0.25 (154.7 examples/sec; 0.052 sec/batch; 0h:35m:02s remains)
INFO - root - 2022-02-24 21:03:17.152660: step 158860, total loss = 0.47, batch loss = 0.21 (132.5 examples/sec; 0.060 sec/batch; 0h:40m:53s remains)
INFO - root - 2022-02-24 21:03:17.530508: step 158870, total loss = 0.50, batch loss = 0.24 (328.5 examples/sec; 0.024 sec/batch; 0h:16m:29s remains)
INFO - root - 2022-02-24 21:03:18.077323: step 158880, total loss = 0.52, batch loss = 0.26 (102.3 examples/sec; 0.078 sec/batch; 0h:52m:55s remains)
INFO - root - 2022-02-24 21:03:18.480657: step 158890, total loss = 0.63, batch loss = 0.38 (362.1 examples/sec; 0.022 sec/batch; 0h:14m:57s remains)
INFO - root - 2022-02-24 21:03:18.934203: step 158900, total loss = 0.57, batch loss = 0.31 (236.9 examples/sec; 0.034 sec/batch; 0h:22m:51s remains)
INFO - root - 2022-02-24 21:03:19.528959: step 158910, total loss = 0.67, batch loss = 0.42 (127.4 examples/sec; 0.063 sec/batch; 0h:42m:29s remains)
INFO - root - 2022-02-24 21:03:19.904343: step 158920, total loss = 0.61, batch loss = 0.35 (208.5 examples/sec; 0.038 sec/batch; 0h:25m:56s remains)
INFO - root - 2022-02-24 21:03:20.209539: step 158930, total loss = 0.50, batch loss = 0.24 (313.6 examples/sec; 0.026 sec/batch; 0h:17m:15s remains)
INFO - root - 2022-02-24 21:03:20.501475: step 158940, total loss = 0.58, batch loss = 0.33 (356.3 examples/sec; 0.022 sec/batch; 0h:15m:10s remains)
INFO - root - 2022-02-24 21:03:20.823114: step 158950, total loss = 0.83, batch loss = 0.57 (333.5 examples/sec; 0.024 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:03:21.152145: step 158960, total loss = 0.58, batch loss = 0.33 (285.7 examples/sec; 0.028 sec/batch; 0h:18m:54s remains)
INFO - root - 2022-02-24 21:03:21.526272: step 158970, total loss = 0.61, batch loss = 0.36 (335.2 examples/sec; 0.024 sec/batch; 0h:16m:07s remains)
INFO - root - 2022-02-24 21:03:21.939554: step 158980, total loss = 0.65, batch loss = 0.40 (297.2 examples/sec; 0.027 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 21:03:22.232175: step 158990, total loss = 0.49, batch loss = 0.24 (350.4 examples/sec; 0.023 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:03:22.622071: step 159000, total loss = 0.53, batch loss = 0.27 (126.6 examples/sec; 0.063 sec/batch; 0h:42m:39s remains)
INFO - root - 2022-02-24 21:03:22.968923: step 159010, total loss = 0.62, batch loss = 0.36 (358.8 examples/sec; 0.022 sec/batch; 0h:15m:02s remains)
INFO - root - 2022-02-24 21:03:23.316342: step 159020, total loss = 0.49, batch loss = 0.23 (158.2 examples/sec; 0.051 sec/batch; 0h:34m:07s remains)
INFO - root - 2022-02-24 21:03:23.728156: step 159030, total loss = 0.66, batch loss = 0.41 (268.6 examples/sec; 0.030 sec/batch; 0h:20m:05s remains)
INFO - root - 2022-02-24 21:03:24.122167: step 159040, total loss = 0.54, batch loss = 0.28 (156.3 examples/sec; 0.051 sec/batch; 0h:34m:31s remains)
INFO - root - 2022-02-24 21:03:24.490040: step 159050, total loss = 0.50, batch loss = 0.25 (350.6 examples/sec; 0.023 sec/batch; 0h:15m:22s remains)
INFO - root - 2022-02-24 21:03:24.838307: step 159060, total loss = 0.54, batch loss = 0.29 (140.3 examples/sec; 0.057 sec/batch; 0h:38m:25s remains)
INFO - root - 2022-02-24 21:03:25.206387: step 159070, total loss = 0.51, batch loss = 0.25 (88.2 examples/sec; 0.091 sec/batch; 1h:01m:06s remains)
INFO - root - 2022-02-24 21:03:25.595441: step 159080, total loss = 0.52, batch loss = 0.26 (266.6 examples/sec; 0.030 sec/batch; 0h:20m:12s remains)
INFO - root - 2022-02-24 21:03:26.055789: step 159090, total loss = 0.48, batch loss = 0.23 (122.6 examples/sec; 0.065 sec/batch; 0h:43m:57s remains)
INFO - root - 2022-02-24 21:03:26.368861: step 159100, total loss = 0.57, batch loss = 0.31 (342.5 examples/sec; 0.023 sec/batch; 0h:15m:43s remains)
INFO - root - 2022-02-24 21:03:26.832203: step 159110, total loss = 0.55, batch loss = 0.29 (198.3 examples/sec; 0.040 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 21:03:27.175666: step 159120, total loss = 0.49, batch loss = 0.24 (182.8 examples/sec; 0.044 sec/batch; 0h:29m:27s remains)
INFO - root - 2022-02-24 21:03:27.517996: step 159130, total loss = 0.52, batch loss = 0.26 (302.6 examples/sec; 0.026 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 21:03:27.956666: step 159140, total loss = 0.52, batch loss = 0.26 (205.9 examples/sec; 0.039 sec/batch; 0h:26m:08s remains)
INFO - root - 2022-02-24 21:03:28.419603: step 159150, total loss = 0.48, batch loss = 0.23 (181.2 examples/sec; 0.044 sec/batch; 0h:29m:41s remains)
INFO - root - 2022-02-24 21:03:28.861099: step 159160, total loss = 0.48, batch loss = 0.23 (177.1 examples/sec; 0.045 sec/batch; 0h:30m:22s remains)
INFO - root - 2022-02-24 21:03:29.187986: step 159170, total loss = 0.56, batch loss = 0.31 (217.8 examples/sec; 0.037 sec/batch; 0h:24m:41s remains)
INFO - root - 2022-02-24 21:03:29.487778: step 159180, total loss = 0.49, batch loss = 0.23 (199.5 examples/sec; 0.040 sec/batch; 0h:26m:56s remains)
INFO - root - 2022-02-24 21:03:29.927553: step 159190, total loss = 0.62, batch loss = 0.37 (126.6 examples/sec; 0.063 sec/batch; 0h:42m:26s remains)
INFO - root - 2022-02-24 21:03:30.378533: step 159200, total loss = 0.69, batch loss = 0.44 (149.0 examples/sec; 0.054 sec/batch; 0h:36m:03s remains)
INFO - root - 2022-02-24 21:03:30.902110: step 159210, total loss = 0.56, batch loss = 0.31 (314.6 examples/sec; 0.025 sec/batch; 0h:17m:04s remains)
INFO - root - 2022-02-24 21:03:31.246689: step 159220, total loss = 0.55, batch loss = 0.29 (119.4 examples/sec; 0.067 sec/batch; 0h:44m:58s remains)
INFO - root - 2022-02-24 21:03:31.578575: step 159230, total loss = 0.49, batch loss = 0.23 (223.0 examples/sec; 0.036 sec/batch; 0h:24m:04s remains)
INFO - root - 2022-02-24 21:03:31.919651: step 159240, total loss = 0.67, batch loss = 0.42 (209.0 examples/sec; 0.038 sec/batch; 0h:25m:40s remains)
INFO - root - 2022-02-24 21:03:32.309342: step 159250, total loss = 0.57, batch loss = 0.31 (256.3 examples/sec; 0.031 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 21:03:32.727773: step 159260, total loss = 0.58, batch loss = 0.32 (368.4 examples/sec; 0.022 sec/batch; 0h:14m:33s remains)
INFO - root - 2022-02-24 21:03:33.142352: step 159270, total loss = 0.57, batch loss = 0.31 (176.3 examples/sec; 0.045 sec/batch; 0h:30m:25s remains)
INFO - root - 2022-02-24 21:03:33.478448: step 159280, total loss = 0.54, batch loss = 0.28 (301.8 examples/sec; 0.027 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:03:33.824924: step 159290, total loss = 0.48, batch loss = 0.22 (168.4 examples/sec; 0.048 sec/batch; 0h:31m:50s remains)
INFO - root - 2022-02-24 21:03:34.149738: step 159300, total loss = 0.60, batch loss = 0.34 (199.6 examples/sec; 0.040 sec/batch; 0h:26m:51s remains)
INFO - root - 2022-02-24 21:03:34.685657: step 159310, total loss = 0.48, batch loss = 0.22 (231.8 examples/sec; 0.035 sec/batch; 0h:23m:07s remains)
INFO - root - 2022-02-24 21:03:35.179740: step 159320, total loss = 0.49, batch loss = 0.23 (293.6 examples/sec; 0.027 sec/batch; 0h:18m:14s remains)
INFO - root - 2022-02-24 21:03:35.537351: step 159330, total loss = 0.64, batch loss = 0.38 (366.9 examples/sec; 0.022 sec/batch; 0h:14m:35s remains)
INFO - root - 2022-02-24 21:03:35.839362: step 159340, total loss = 0.56, batch loss = 0.30 (147.8 examples/sec; 0.054 sec/batch; 0h:36m:14s remains)
INFO - root - 2022-02-24 21:03:36.198185: step 159350, total loss = 0.72, batch loss = 0.46 (316.2 examples/sec; 0.025 sec/batch; 0h:16m:55s remains)
INFO - root - 2022-02-24 21:03:36.615746: step 159360, total loss = 0.57, batch loss = 0.31 (277.0 examples/sec; 0.029 sec/batch; 0h:19m:19s remains)
INFO - root - 2022-02-24 21:03:37.125695: step 159370, total loss = 0.49, batch loss = 0.23 (346.1 examples/sec; 0.023 sec/batch; 0h:15m:27s remains)
INFO - root - 2022-02-24 21:03:37.495990: step 159380, total loss = 0.56, batch loss = 0.31 (178.6 examples/sec; 0.045 sec/batch; 0h:29m:57s remains)
INFO - root - 2022-02-24 21:03:37.786355: step 159390, total loss = 0.48, batch loss = 0.23 (338.8 examples/sec; 0.024 sec/batch; 0h:15m:47s remains)
INFO - root - 2022-02-24 21:03:38.027661: step 159400, total loss = 0.51, batch loss = 0.25 (368.4 examples/sec; 0.022 sec/batch; 0h:14m:30s remains)
INFO - root - 2022-02-24 21:03:38.557150: step 159410, total loss = 0.58, batch loss = 0.32 (343.3 examples/sec; 0.023 sec/batch; 0h:15m:34s remains)
INFO - root - 2022-02-24 21:03:39.014936: step 159420, total loss = 0.64, batch loss = 0.39 (157.6 examples/sec; 0.051 sec/batch; 0h:33m:53s remains)
INFO - root - 2022-02-24 21:03:39.381073: step 159430, total loss = 0.51, batch loss = 0.25 (253.0 examples/sec; 0.032 sec/batch; 0h:21m:06s remains)
INFO - root - 2022-02-24 21:03:39.701304: step 159440, total loss = 0.47, batch loss = 0.21 (237.8 examples/sec; 0.034 sec/batch; 0h:22m:27s remains)
INFO - root - 2022-02-24 21:03:40.095714: step 159450, total loss = 0.55, batch loss = 0.30 (225.7 examples/sec; 0.035 sec/batch; 0h:23m:39s remains)
INFO - root - 2022-02-24 21:03:40.520221: step 159460, total loss = 0.49, batch loss = 0.23 (93.3 examples/sec; 0.086 sec/batch; 0h:57m:14s remains)
INFO - root - 2022-02-24 21:03:40.926719: step 159470, total loss = 0.58, batch loss = 0.33 (177.4 examples/sec; 0.045 sec/batch; 0h:30m:05s remains)
INFO - root - 2022-02-24 21:03:41.357771: step 159480, total loss = 0.57, batch loss = 0.31 (123.4 examples/sec; 0.065 sec/batch; 0h:43m:14s remains)
INFO - root - 2022-02-24 21:03:41.868621: step 159490, total loss = 0.54, batch loss = 0.28 (117.7 examples/sec; 0.068 sec/batch; 0h:45m:19s remains)
INFO - root - 2022-02-24 21:03:42.489172: step 159500, total loss = 0.52, batch loss = 0.26 (198.4 examples/sec; 0.040 sec/batch; 0h:26m:52s remains)
INFO - root - 2022-02-24 21:03:43.100865: step 159510, total loss = 0.58, batch loss = 0.32 (197.4 examples/sec; 0.041 sec/batch; 0h:27m:00s remains)
INFO - root - 2022-02-24 21:03:43.592671: step 159520, total loss = 0.62, batch loss = 0.36 (210.5 examples/sec; 0.038 sec/batch; 0h:25m:19s remains)
INFO - root - 2022-02-24 21:03:44.182453: step 159530, total loss = 0.57, batch loss = 0.31 (73.9 examples/sec; 0.108 sec/batch; 1h:12m:08s remains)
INFO - root - 2022-02-24 21:03:44.784090: step 159540, total loss = 0.54, batch loss = 0.28 (173.6 examples/sec; 0.046 sec/batch; 0h:30m:41s remains)
INFO - root - 2022-02-24 21:03:45.685211: step 159550, total loss = 0.48, batch loss = 0.22 (105.3 examples/sec; 0.076 sec/batch; 0h:50m:34s remains)
INFO - root - 2022-02-24 21:03:46.040659: step 159560, total loss = 0.56, batch loss = 0.31 (158.9 examples/sec; 0.050 sec/batch; 0h:33m:30s remains)
INFO - root - 2022-02-24 21:03:46.350616: step 159570, total loss = 0.55, batch loss = 0.30 (345.5 examples/sec; 0.023 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:03:46.670596: step 159580, total loss = 0.55, batch loss = 0.29 (290.9 examples/sec; 0.028 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:03:46.982177: step 159590, total loss = 0.58, batch loss = 0.32 (251.4 examples/sec; 0.032 sec/batch; 0h:21m:09s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-159599 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-159599 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:03:47.703400: step 159600, total loss = 0.58, batch loss = 0.32 (315.4 examples/sec; 0.025 sec/batch; 0h:16m:51s remains)
INFO - root - 2022-02-24 21:03:48.018280: step 159610, total loss = 0.51, batch loss = 0.25 (324.2 examples/sec; 0.025 sec/batch; 0h:16m:24s remains)
INFO - root - 2022-02-24 21:03:48.265186: step 159620, total loss = 0.59, batch loss = 0.33 (306.0 examples/sec; 0.026 sec/batch; 0h:17m:22s remains)
INFO - root - 2022-02-24 21:03:48.536695: step 159630, total loss = 0.65, batch loss = 0.40 (294.1 examples/sec; 0.027 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:03:48.849299: step 159640, total loss = 0.48, batch loss = 0.22 (273.6 examples/sec; 0.029 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 21:03:49.333385: step 159650, total loss = 0.54, batch loss = 0.29 (179.1 examples/sec; 0.045 sec/batch; 0h:29m:40s remains)
INFO - root - 2022-02-24 21:03:49.760450: step 159660, total loss = 0.48, batch loss = 0.22 (111.3 examples/sec; 0.072 sec/batch; 0h:47m:44s remains)
INFO - root - 2022-02-24 21:03:50.316638: step 159670, total loss = 0.56, batch loss = 0.30 (110.8 examples/sec; 0.072 sec/batch; 0h:47m:54s remains)
INFO - root - 2022-02-24 21:03:50.758111: step 159680, total loss = 0.50, batch loss = 0.25 (177.8 examples/sec; 0.045 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 21:03:51.140635: step 159690, total loss = 0.55, batch loss = 0.30 (141.9 examples/sec; 0.056 sec/batch; 0h:37m:25s remains)
INFO - root - 2022-02-24 21:03:51.528302: step 159700, total loss = 0.51, batch loss = 0.25 (290.8 examples/sec; 0.028 sec/batch; 0h:18m:14s remains)
INFO - root - 2022-02-24 21:03:52.119244: step 159710, total loss = 0.62, batch loss = 0.37 (309.7 examples/sec; 0.026 sec/batch; 0h:17m:07s remains)
INFO - root - 2022-02-24 21:03:52.420015: step 159720, total loss = 0.48, batch loss = 0.23 (138.1 examples/sec; 0.058 sec/batch; 0h:38m:24s remains)
INFO - root - 2022-02-24 21:03:52.756936: step 159730, total loss = 0.53, batch loss = 0.27 (212.3 examples/sec; 0.038 sec/batch; 0h:24m:58s remains)
INFO - root - 2022-02-24 21:03:53.151461: step 159740, total loss = 0.52, batch loss = 0.26 (246.6 examples/sec; 0.032 sec/batch; 0h:21m:30s remains)
INFO - root - 2022-02-24 21:03:53.555486: step 159750, total loss = 0.54, batch loss = 0.28 (187.0 examples/sec; 0.043 sec/batch; 0h:28m:20s remains)
INFO - root - 2022-02-24 21:03:53.925854: step 159760, total loss = 0.49, batch loss = 0.24 (253.4 examples/sec; 0.032 sec/batch; 0h:20m:54s remains)
INFO - root - 2022-02-24 21:03:54.355920: step 159770, total loss = 0.50, batch loss = 0.24 (126.9 examples/sec; 0.063 sec/batch; 0h:41m:45s remains)
INFO - root - 2022-02-24 21:03:54.660001: step 159780, total loss = 0.47, batch loss = 0.22 (213.3 examples/sec; 0.038 sec/batch; 0h:24m:50s remains)
INFO - root - 2022-02-24 21:03:54.977933: step 159790, total loss = 0.47, batch loss = 0.21 (273.5 examples/sec; 0.029 sec/batch; 0h:19m:21s remains)
INFO - root - 2022-02-24 21:03:55.277177: step 159800, total loss = 0.81, batch loss = 0.55 (335.7 examples/sec; 0.024 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:03:55.920183: step 159810, total loss = 0.55, batch loss = 0.29 (95.4 examples/sec; 0.084 sec/batch; 0h:55m:28s remains)
INFO - root - 2022-02-24 21:03:56.290160: step 159820, total loss = 0.52, batch loss = 0.26 (153.8 examples/sec; 0.052 sec/batch; 0h:34m:23s remains)
INFO - root - 2022-02-24 21:03:56.747391: step 159830, total loss = 0.50, batch loss = 0.25 (255.4 examples/sec; 0.031 sec/batch; 0h:20m:42s remains)
INFO - root - 2022-02-24 21:03:57.091228: step 159840, total loss = 0.66, batch loss = 0.40 (151.9 examples/sec; 0.053 sec/batch; 0h:34m:48s remains)
INFO - root - 2022-02-24 21:03:57.407339: step 159850, total loss = 0.52, batch loss = 0.27 (328.9 examples/sec; 0.024 sec/batch; 0h:16m:04s remains)
INFO - root - 2022-02-24 21:03:57.711673: step 159860, total loss = 0.55, batch loss = 0.29 (310.4 examples/sec; 0.026 sec/batch; 0h:17m:01s remains)
INFO - root - 2022-02-24 21:03:58.109397: step 159870, total loss = 0.55, batch loss = 0.29 (257.3 examples/sec; 0.031 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 21:03:58.567639: step 159880, total loss = 0.65, batch loss = 0.39 (259.1 examples/sec; 0.031 sec/batch; 0h:20m:23s remains)
INFO - root - 2022-02-24 21:03:58.955602: step 159890, total loss = 0.64, batch loss = 0.39 (238.6 examples/sec; 0.034 sec/batch; 0h:22m:07s remains)
INFO - root - 2022-02-24 21:03:59.279977: step 159900, total loss = 0.51, batch loss = 0.25 (140.5 examples/sec; 0.057 sec/batch; 0h:37m:34s remains)
INFO - root - 2022-02-24 21:03:59.736791: step 159910, total loss = 0.53, batch loss = 0.27 (304.6 examples/sec; 0.026 sec/batch; 0h:17m:19s remains)
INFO - root - 2022-02-24 21:04:00.062409: step 159920, total loss = 0.51, batch loss = 0.26 (283.0 examples/sec; 0.028 sec/batch; 0h:18m:38s remains)
INFO - root - 2022-02-24 21:04:00.582946: step 159930, total loss = 0.51, batch loss = 0.25 (172.5 examples/sec; 0.046 sec/batch; 0h:30m:35s remains)
INFO - root - 2022-02-24 21:04:01.014904: step 159940, total loss = 0.49, batch loss = 0.23 (178.9 examples/sec; 0.045 sec/batch; 0h:29m:28s remains)
INFO - root - 2022-02-24 21:04:01.380342: step 159950, total loss = 0.57, batch loss = 0.31 (219.6 examples/sec; 0.036 sec/batch; 0h:24m:00s remains)
INFO - root - 2022-02-24 21:04:01.764470: step 159960, total loss = 0.55, batch loss = 0.29 (290.8 examples/sec; 0.028 sec/batch; 0h:18m:07s remains)
INFO - root - 2022-02-24 21:04:02.088818: step 159970, total loss = 0.58, batch loss = 0.33 (350.0 examples/sec; 0.023 sec/batch; 0h:15m:03s remains)
INFO - root - 2022-02-24 21:04:02.425153: step 159980, total loss = 0.58, batch loss = 0.32 (304.7 examples/sec; 0.026 sec/batch; 0h:17m:17s remains)
INFO - root - 2022-02-24 21:04:02.829305: step 159990, total loss = 0.59, batch loss = 0.34 (341.9 examples/sec; 0.023 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:04:03.380405: step 160000, total loss = 0.58, batch loss = 0.33 (106.1 examples/sec; 0.075 sec/batch; 0h:49m:39s remains)
INFO - root - 2022-02-24 21:04:03.790974: step 160010, total loss = 0.49, batch loss = 0.24 (179.9 examples/sec; 0.044 sec/batch; 0h:29m:16s remains)
INFO - root - 2022-02-24 21:04:04.084536: step 160020, total loss = 0.49, batch loss = 0.23 (352.8 examples/sec; 0.023 sec/batch; 0h:14m:55s remains)
INFO - root - 2022-02-24 21:04:04.426445: step 160030, total loss = 0.49, batch loss = 0.23 (240.1 examples/sec; 0.033 sec/batch; 0h:21m:55s remains)
INFO - root - 2022-02-24 21:04:04.795748: step 160040, total loss = 0.51, batch loss = 0.25 (207.7 examples/sec; 0.039 sec/batch; 0h:25m:19s remains)
INFO - root - 2022-02-24 21:04:05.311491: step 160050, total loss = 0.52, batch loss = 0.26 (117.8 examples/sec; 0.068 sec/batch; 0h:44m:38s remains)
INFO - root - 2022-02-24 21:04:06.034756: step 160060, total loss = 0.44, batch loss = 0.19 (332.7 examples/sec; 0.024 sec/batch; 0h:15m:48s remains)
INFO - root - 2022-02-24 21:04:06.336560: step 160070, total loss = 0.45, batch loss = 0.20 (160.8 examples/sec; 0.050 sec/batch; 0h:32m:41s remains)
INFO - root - 2022-02-24 21:04:06.750689: step 160080, total loss = 0.55, batch loss = 0.29 (96.0 examples/sec; 0.083 sec/batch; 0h:54m:46s remains)
INFO - root - 2022-02-24 21:04:07.268864: step 160090, total loss = 0.53, batch loss = 0.27 (104.4 examples/sec; 0.077 sec/batch; 0h:50m:19s remains)
INFO - root - 2022-02-24 21:04:07.684263: step 160100, total loss = 0.69, batch loss = 0.44 (185.4 examples/sec; 0.043 sec/batch; 0h:28m:19s remains)
INFO - root - 2022-02-24 21:04:08.156447: step 160110, total loss = 0.60, batch loss = 0.34 (157.3 examples/sec; 0.051 sec/batch; 0h:33m:23s remains)
INFO - root - 2022-02-24 21:04:08.615885: step 160120, total loss = 0.50, batch loss = 0.24 (276.0 examples/sec; 0.029 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:04:09.084301: step 160130, total loss = 0.61, batch loss = 0.35 (189.2 examples/sec; 0.042 sec/batch; 0h:27m:44s remains)
INFO - root - 2022-02-24 21:04:09.626686: step 160140, total loss = 0.52, batch loss = 0.26 (271.0 examples/sec; 0.030 sec/batch; 0h:19m:22s remains)
INFO - root - 2022-02-24 21:04:10.062713: step 160150, total loss = 0.44, batch loss = 0.19 (130.0 examples/sec; 0.062 sec/batch; 0h:40m:20s remains)
INFO - root - 2022-02-24 21:04:10.508251: step 160160, total loss = 0.64, batch loss = 0.38 (156.8 examples/sec; 0.051 sec/batch; 0h:33m:27s remains)
INFO - root - 2022-02-24 21:04:11.310053: step 160170, total loss = 0.51, batch loss = 0.26 (197.8 examples/sec; 0.040 sec/batch; 0h:26m:30s remains)
INFO - root - 2022-02-24 21:04:11.738449: step 160180, total loss = 0.58, batch loss = 0.32 (124.0 examples/sec; 0.065 sec/batch; 0h:42m:17s remains)
INFO - root - 2022-02-24 21:04:12.191311: step 160190, total loss = 0.60, batch loss = 0.34 (324.5 examples/sec; 0.025 sec/batch; 0h:16m:09s remains)
INFO - root - 2022-02-24 21:04:12.524399: step 160200, total loss = 0.50, batch loss = 0.24 (298.6 examples/sec; 0.027 sec/batch; 0h:17m:33s remains)
INFO - root - 2022-02-24 21:04:12.917164: step 160210, total loss = 0.47, batch loss = 0.21 (171.6 examples/sec; 0.047 sec/batch; 0h:30m:31s remains)
INFO - root - 2022-02-24 21:04:13.254161: step 160220, total loss = 0.53, batch loss = 0.27 (204.8 examples/sec; 0.039 sec/batch; 0h:25m:34s remains)
INFO - root - 2022-02-24 21:04:13.586996: step 160230, total loss = 0.59, batch loss = 0.33 (350.2 examples/sec; 0.023 sec/batch; 0h:14m:57s remains)
INFO - root - 2022-02-24 21:04:14.052522: step 160240, total loss = 0.58, batch loss = 0.32 (229.5 examples/sec; 0.035 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 21:04:14.459573: step 160250, total loss = 0.50, batch loss = 0.24 (238.2 examples/sec; 0.034 sec/batch; 0h:21m:58s remains)
INFO - root - 2022-02-24 21:04:15.001725: step 160260, total loss = 0.66, batch loss = 0.40 (259.3 examples/sec; 0.031 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:04:15.365777: step 160270, total loss = 0.51, batch loss = 0.26 (186.1 examples/sec; 0.043 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 21:04:15.867774: step 160280, total loss = 0.65, batch loss = 0.39 (291.9 examples/sec; 0.027 sec/batch; 0h:17m:54s remains)
INFO - root - 2022-02-24 21:04:16.316645: step 160290, total loss = 0.72, batch loss = 0.46 (241.2 examples/sec; 0.033 sec/batch; 0h:21m:40s remains)
INFO - root - 2022-02-24 21:04:16.692457: step 160300, total loss = 0.53, batch loss = 0.27 (240.3 examples/sec; 0.033 sec/batch; 0h:21m:45s remains)
INFO - root - 2022-02-24 21:04:17.133727: step 160310, total loss = 0.48, batch loss = 0.22 (233.7 examples/sec; 0.034 sec/batch; 0h:22m:21s remains)
INFO - root - 2022-02-24 21:04:17.466834: step 160320, total loss = 0.58, batch loss = 0.32 (296.7 examples/sec; 0.027 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:04:17.833169: step 160330, total loss = 0.55, batch loss = 0.29 (255.4 examples/sec; 0.031 sec/batch; 0h:20m:27s remains)
INFO - root - 2022-02-24 21:04:18.338068: step 160340, total loss = 0.52, batch loss = 0.26 (246.0 examples/sec; 0.033 sec/batch; 0h:21m:13s remains)
INFO - root - 2022-02-24 21:04:18.750027: step 160350, total loss = 0.59, batch loss = 0.33 (318.7 examples/sec; 0.025 sec/batch; 0h:16m:22s remains)
INFO - root - 2022-02-24 21:04:19.127227: step 160360, total loss = 0.56, batch loss = 0.30 (142.6 examples/sec; 0.056 sec/batch; 0h:36m:35s remains)
INFO - root - 2022-02-24 21:04:19.510416: step 160370, total loss = 0.51, batch loss = 0.25 (134.0 examples/sec; 0.060 sec/batch; 0h:38m:56s remains)
INFO - root - 2022-02-24 21:04:19.768476: step 160380, total loss = 0.50, batch loss = 0.25 (347.0 examples/sec; 0.023 sec/batch; 0h:15m:01s remains)
INFO - root - 2022-02-24 21:04:20.105837: step 160390, total loss = 0.49, batch loss = 0.23 (289.0 examples/sec; 0.028 sec/batch; 0h:18m:02s remains)
INFO - root - 2022-02-24 21:04:20.570466: step 160400, total loss = 0.55, batch loss = 0.29 (296.1 examples/sec; 0.027 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:04:21.030640: step 160410, total loss = 0.54, batch loss = 0.29 (136.6 examples/sec; 0.059 sec/batch; 0h:38m:08s remains)
INFO - root - 2022-02-24 21:04:21.368355: step 160420, total loss = 0.65, batch loss = 0.40 (207.6 examples/sec; 0.039 sec/batch; 0h:25m:06s remains)
INFO - root - 2022-02-24 21:04:21.631170: step 160430, total loss = 0.56, batch loss = 0.30 (377.3 examples/sec; 0.021 sec/batch; 0h:13m:48s remains)
INFO - root - 2022-02-24 21:04:22.025140: step 160440, total loss = 0.56, batch loss = 0.30 (113.8 examples/sec; 0.070 sec/batch; 0h:45m:45s remains)
INFO - root - 2022-02-24 21:04:22.370803: step 160450, total loss = 0.53, batch loss = 0.27 (169.6 examples/sec; 0.047 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:04:22.813371: step 160460, total loss = 0.59, batch loss = 0.33 (222.1 examples/sec; 0.036 sec/batch; 0h:23m:26s remains)
INFO - root - 2022-02-24 21:04:23.175967: step 160470, total loss = 0.53, batch loss = 0.27 (354.1 examples/sec; 0.023 sec/batch; 0h:14m:41s remains)
INFO - root - 2022-02-24 21:04:23.485618: step 160480, total loss = 0.53, batch loss = 0.27 (330.5 examples/sec; 0.024 sec/batch; 0h:15m:44s remains)
INFO - root - 2022-02-24 21:04:23.827604: step 160490, total loss = 0.53, batch loss = 0.27 (282.2 examples/sec; 0.028 sec/batch; 0h:18m:25s remains)
INFO - root - 2022-02-24 21:04:24.318634: step 160500, total loss = 0.51, batch loss = 0.25 (154.7 examples/sec; 0.052 sec/batch; 0h:33m:36s remains)
INFO - root - 2022-02-24 21:04:24.833772: step 160510, total loss = 0.49, batch loss = 0.24 (161.1 examples/sec; 0.050 sec/batch; 0h:32m:16s remains)
INFO - root - 2022-02-24 21:04:25.207857: step 160520, total loss = 0.61, batch loss = 0.36 (331.5 examples/sec; 0.024 sec/batch; 0h:15m:40s remains)
INFO - root - 2022-02-24 21:04:25.537865: step 160530, total loss = 0.56, batch loss = 0.31 (349.2 examples/sec; 0.023 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:04:25.944363: step 160540, total loss = 0.55, batch loss = 0.30 (193.8 examples/sec; 0.041 sec/batch; 0h:26m:48s remains)
INFO - root - 2022-02-24 21:04:26.280639: step 160550, total loss = 0.50, batch loss = 0.24 (351.2 examples/sec; 0.023 sec/batch; 0h:14m:47s remains)
INFO - root - 2022-02-24 21:04:26.766881: step 160560, total loss = 0.55, batch loss = 0.29 (144.1 examples/sec; 0.056 sec/batch; 0h:36m:01s remains)
INFO - root - 2022-02-24 21:04:27.221198: step 160570, total loss = 0.49, batch loss = 0.23 (311.9 examples/sec; 0.026 sec/batch; 0h:16m:38s remains)
INFO - root - 2022-02-24 21:04:27.528086: step 160580, total loss = 0.50, batch loss = 0.24 (284.3 examples/sec; 0.028 sec/batch; 0h:18m:15s remains)
INFO - root - 2022-02-24 21:04:27.870128: step 160590, total loss = 0.46, batch loss = 0.20 (221.9 examples/sec; 0.036 sec/batch; 0h:23m:22s remains)
INFO - root - 2022-02-24 21:04:28.155414: step 160600, total loss = 0.62, batch loss = 0.37 (277.5 examples/sec; 0.029 sec/batch; 0h:18m:41s remains)
INFO - root - 2022-02-24 21:04:28.694258: step 160610, total loss = 0.52, batch loss = 0.26 (159.8 examples/sec; 0.050 sec/batch; 0h:32m:26s remains)
INFO - root - 2022-02-24 21:04:29.140171: step 160620, total loss = 0.55, batch loss = 0.29 (189.9 examples/sec; 0.042 sec/batch; 0h:27m:18s remains)
INFO - root - 2022-02-24 21:04:29.581883: step 160630, total loss = 0.54, batch loss = 0.29 (192.7 examples/sec; 0.042 sec/batch; 0h:26m:53s remains)
INFO - root - 2022-02-24 21:04:29.904580: step 160640, total loss = 0.56, batch loss = 0.30 (320.9 examples/sec; 0.025 sec/batch; 0h:16m:08s remains)
INFO - root - 2022-02-24 21:04:30.238552: step 160650, total loss = 0.54, batch loss = 0.28 (235.3 examples/sec; 0.034 sec/batch; 0h:22m:00s remains)
INFO - root - 2022-02-24 21:04:30.593716: step 160660, total loss = 0.52, batch loss = 0.27 (310.3 examples/sec; 0.026 sec/batch; 0h:16m:41s remains)
INFO - root - 2022-02-24 21:04:31.086866: step 160670, total loss = 0.56, batch loss = 0.30 (130.2 examples/sec; 0.061 sec/batch; 0h:39m:46s remains)
INFO - root - 2022-02-24 21:04:31.483723: step 160680, total loss = 0.44, batch loss = 0.18 (290.3 examples/sec; 0.028 sec/batch; 0h:17m:49s remains)
INFO - root - 2022-02-24 21:04:31.923976: step 160690, total loss = 0.50, batch loss = 0.25 (324.0 examples/sec; 0.025 sec/batch; 0h:15m:58s remains)
INFO - root - 2022-02-24 21:04:32.293717: step 160700, total loss = 0.50, batch loss = 0.25 (245.8 examples/sec; 0.033 sec/batch; 0h:21m:02s remains)
INFO - root - 2022-02-24 21:04:32.745272: step 160710, total loss = 0.52, batch loss = 0.26 (123.2 examples/sec; 0.065 sec/batch; 0h:41m:58s remains)
INFO - root - 2022-02-24 21:04:33.126503: step 160720, total loss = 0.60, batch loss = 0.35 (117.1 examples/sec; 0.068 sec/batch; 0h:44m:10s remains)
INFO - root - 2022-02-24 21:04:33.617507: step 160730, total loss = 0.61, batch loss = 0.36 (153.4 examples/sec; 0.052 sec/batch; 0h:33m:41s remains)
INFO - root - 2022-02-24 21:04:33.975077: step 160740, total loss = 0.52, batch loss = 0.26 (233.3 examples/sec; 0.034 sec/batch; 0h:22m:09s remains)
INFO - root - 2022-02-24 21:04:34.322827: step 160750, total loss = 0.55, batch loss = 0.29 (318.8 examples/sec; 0.025 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:04:34.607199: step 160760, total loss = 0.56, batch loss = 0.30 (244.8 examples/sec; 0.033 sec/batch; 0h:21m:05s remains)
INFO - root - 2022-02-24 21:04:34.940066: step 160770, total loss = 0.58, batch loss = 0.32 (253.0 examples/sec; 0.032 sec/batch; 0h:20m:24s remains)
INFO - root - 2022-02-24 21:04:35.327331: step 160780, total loss = 0.45, batch loss = 0.20 (134.5 examples/sec; 0.059 sec/batch; 0h:38m:23s remains)
INFO - root - 2022-02-24 21:04:35.759195: step 160790, total loss = 0.53, batch loss = 0.27 (341.5 examples/sec; 0.023 sec/batch; 0h:15m:06s remains)
INFO - root - 2022-02-24 21:04:36.227868: step 160800, total loss = 0.55, batch loss = 0.30 (229.2 examples/sec; 0.035 sec/batch; 0h:22m:30s remains)
INFO - root - 2022-02-24 21:04:36.627344: step 160810, total loss = 0.46, batch loss = 0.21 (295.3 examples/sec; 0.027 sec/batch; 0h:17m:28s remains)
INFO - root - 2022-02-24 21:04:37.021163: step 160820, total loss = 0.51, batch loss = 0.26 (166.2 examples/sec; 0.048 sec/batch; 0h:31m:02s remains)
INFO - root - 2022-02-24 21:04:37.481183: step 160830, total loss = 0.69, batch loss = 0.43 (131.6 examples/sec; 0.061 sec/batch; 0h:39m:10s remains)
INFO - root - 2022-02-24 21:04:37.927638: step 160840, total loss = 0.48, batch loss = 0.22 (234.9 examples/sec; 0.034 sec/batch; 0h:21m:56s remains)
INFO - root - 2022-02-24 21:04:38.280069: step 160850, total loss = 0.50, batch loss = 0.25 (221.2 examples/sec; 0.036 sec/batch; 0h:23m:17s remains)
INFO - root - 2022-02-24 21:04:38.614525: step 160860, total loss = 0.68, batch loss = 0.43 (183.2 examples/sec; 0.044 sec/batch; 0h:28m:07s remains)
INFO - root - 2022-02-24 21:04:38.986963: step 160870, total loss = 0.46, batch loss = 0.20 (257.4 examples/sec; 0.031 sec/batch; 0h:20m:00s remains)
INFO - root - 2022-02-24 21:04:39.422753: step 160880, total loss = 0.47, batch loss = 0.22 (300.3 examples/sec; 0.027 sec/batch; 0h:17m:08s remains)
INFO - root - 2022-02-24 21:04:39.869840: step 160890, total loss = 0.60, batch loss = 0.34 (123.9 examples/sec; 0.065 sec/batch; 0h:41m:32s remains)
INFO - root - 2022-02-24 21:04:40.342114: step 160900, total loss = 0.54, batch loss = 0.29 (155.6 examples/sec; 0.051 sec/batch; 0h:33m:04s remains)
INFO - root - 2022-02-24 21:04:40.905649: step 160910, total loss = 0.51, batch loss = 0.25 (161.4 examples/sec; 0.050 sec/batch; 0h:31m:52s remains)
INFO - root - 2022-02-24 21:04:41.746432: step 160920, total loss = 0.53, batch loss = 0.27 (249.1 examples/sec; 0.032 sec/batch; 0h:20m:38s remains)
INFO - root - 2022-02-24 21:04:42.084350: step 160930, total loss = 0.56, batch loss = 0.30 (202.6 examples/sec; 0.039 sec/batch; 0h:25m:22s remains)
INFO - root - 2022-02-24 21:04:42.592192: step 160940, total loss = 0.52, batch loss = 0.27 (107.3 examples/sec; 0.075 sec/batch; 0h:47m:55s remains)
INFO - root - 2022-02-24 21:04:42.919977: step 160950, total loss = 0.46, batch loss = 0.20 (259.2 examples/sec; 0.031 sec/batch; 0h:19m:50s remains)
INFO - root - 2022-02-24 21:04:43.312862: step 160960, total loss = 0.44, batch loss = 0.18 (365.8 examples/sec; 0.022 sec/batch; 0h:14m:02s remains)
INFO - root - 2022-02-24 21:04:43.721579: step 160970, total loss = 0.60, batch loss = 0.34 (327.6 examples/sec; 0.024 sec/batch; 0h:15m:41s remains)
INFO - root - 2022-02-24 21:04:44.301201: step 160980, total loss = 0.64, batch loss = 0.38 (184.7 examples/sec; 0.043 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 21:04:44.738670: step 160990, total loss = 0.53, batch loss = 0.28 (110.0 examples/sec; 0.073 sec/batch; 0h:46m:41s remains)
INFO - root - 2022-02-24 21:04:45.175386: step 161000, total loss = 0.57, batch loss = 0.31 (129.4 examples/sec; 0.062 sec/batch; 0h:39m:39s remains)
INFO - root - 2022-02-24 21:04:45.662487: step 161010, total loss = 0.67, batch loss = 0.41 (93.5 examples/sec; 0.086 sec/batch; 0h:54m:53s remains)
INFO - root - 2022-02-24 21:04:45.933571: step 161020, total loss = 0.57, batch loss = 0.31 (315.5 examples/sec; 0.025 sec/batch; 0h:16m:15s remains)
INFO - root - 2022-02-24 21:04:46.768863: step 161030, total loss = 0.49, batch loss = 0.23 (192.5 examples/sec; 0.042 sec/batch; 0h:26m:38s remains)
INFO - root - 2022-02-24 21:04:47.177405: step 161040, total loss = 0.51, batch loss = 0.26 (345.7 examples/sec; 0.023 sec/batch; 0h:14m:49s remains)
INFO - root - 2022-02-24 21:04:47.582004: step 161050, total loss = 0.61, batch loss = 0.36 (176.6 examples/sec; 0.045 sec/batch; 0h:29m:01s remains)
INFO - root - 2022-02-24 21:04:47.983783: step 161060, total loss = 0.61, batch loss = 0.36 (163.8 examples/sec; 0.049 sec/batch; 0h:31m:17s remains)
INFO - root - 2022-02-24 21:04:48.299510: step 161070, total loss = 0.49, batch loss = 0.24 (276.9 examples/sec; 0.029 sec/batch; 0h:18m:30s remains)
INFO - root - 2022-02-24 21:04:48.643658: step 161080, total loss = 0.51, batch loss = 0.25 (325.9 examples/sec; 0.025 sec/batch; 0h:15m:43s remains)
INFO - root - 2022-02-24 21:04:49.007836: step 161090, total loss = 0.53, batch loss = 0.27 (283.3 examples/sec; 0.028 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:04:49.386851: step 161100, total loss = 0.54, batch loss = 0.28 (278.7 examples/sec; 0.029 sec/batch; 0h:18m:22s remains)
INFO - root - 2022-02-24 21:04:49.862678: step 161110, total loss = 0.53, batch loss = 0.27 (119.7 examples/sec; 0.067 sec/batch; 0h:42m:45s remains)
INFO - root - 2022-02-24 21:04:50.217001: step 161120, total loss = 0.51, batch loss = 0.25 (138.5 examples/sec; 0.058 sec/batch; 0h:36m:57s remains)
INFO - root - 2022-02-24 21:04:50.551247: step 161130, total loss = 0.59, batch loss = 0.34 (129.5 examples/sec; 0.062 sec/batch; 0h:39m:30s remains)
INFO - root - 2022-02-24 21:04:50.969182: step 161140, total loss = 0.54, batch loss = 0.28 (238.5 examples/sec; 0.034 sec/batch; 0h:21m:26s remains)
INFO - root - 2022-02-24 21:04:51.435252: step 161150, total loss = 0.57, batch loss = 0.31 (194.1 examples/sec; 0.041 sec/batch; 0h:26m:20s remains)
INFO - root - 2022-02-24 21:04:51.871875: step 161160, total loss = 0.62, batch loss = 0.36 (307.3 examples/sec; 0.026 sec/batch; 0h:16m:38s remains)
INFO - root - 2022-02-24 21:04:52.188792: step 161170, total loss = 0.59, batch loss = 0.34 (285.9 examples/sec; 0.028 sec/batch; 0h:17m:52s remains)
INFO - root - 2022-02-24 21:04:52.590561: step 161180, total loss = 0.52, batch loss = 0.27 (305.3 examples/sec; 0.026 sec/batch; 0h:16m:44s remains)
INFO - root - 2022-02-24 21:04:52.944715: step 161190, total loss = 0.50, batch loss = 0.24 (208.1 examples/sec; 0.038 sec/batch; 0h:24m:32s remains)
INFO - root - 2022-02-24 21:04:53.318938: step 161200, total loss = 0.57, batch loss = 0.32 (247.5 examples/sec; 0.032 sec/batch; 0h:20m:37s remains)
INFO - root - 2022-02-24 21:04:53.794089: step 161210, total loss = 0.50, batch loss = 0.25 (344.8 examples/sec; 0.023 sec/batch; 0h:14m:48s remains)
INFO - root - 2022-02-24 21:04:54.257053: step 161220, total loss = 0.47, batch loss = 0.21 (116.7 examples/sec; 0.069 sec/batch; 0h:43m:44s remains)
INFO - root - 2022-02-24 21:04:54.604026: step 161230, total loss = 0.70, batch loss = 0.44 (304.2 examples/sec; 0.026 sec/batch; 0h:16m:46s remains)
INFO - root - 2022-02-24 21:04:54.919807: step 161240, total loss = 0.53, batch loss = 0.28 (296.3 examples/sec; 0.027 sec/batch; 0h:17m:12s remains)
INFO - root - 2022-02-24 21:04:55.277975: step 161250, total loss = 0.74, batch loss = 0.48 (317.6 examples/sec; 0.025 sec/batch; 0h:16m:03s remains)
INFO - root - 2022-02-24 21:04:55.691874: step 161260, total loss = 0.51, batch loss = 0.26 (265.5 examples/sec; 0.030 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 21:04:56.177391: step 161270, total loss = 0.52, batch loss = 0.27 (155.6 examples/sec; 0.051 sec/batch; 0h:32m:45s remains)
INFO - root - 2022-02-24 21:04:56.489627: step 161280, total loss = 0.59, batch loss = 0.33 (204.2 examples/sec; 0.039 sec/batch; 0h:24m:57s remains)
INFO - root - 2022-02-24 21:04:56.841074: step 161290, total loss = 0.54, batch loss = 0.29 (172.1 examples/sec; 0.046 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 21:04:57.214983: step 161300, total loss = 0.68, batch loss = 0.43 (273.2 examples/sec; 0.029 sec/batch; 0h:18m:38s remains)
INFO - root - 2022-02-24 21:04:57.663478: step 161310, total loss = 0.50, batch loss = 0.24 (315.1 examples/sec; 0.025 sec/batch; 0h:16m:09s remains)
INFO - root - 2022-02-24 21:04:58.007342: step 161320, total loss = 0.56, batch loss = 0.31 (233.3 examples/sec; 0.034 sec/batch; 0h:21m:49s remains)
INFO - root - 2022-02-24 21:04:58.511310: step 161330, total loss = 0.46, batch loss = 0.20 (110.4 examples/sec; 0.072 sec/batch; 0h:46m:05s remains)
INFO - root - 2022-02-24 21:04:58.850068: step 161340, total loss = 0.68, batch loss = 0.42 (147.8 examples/sec; 0.054 sec/batch; 0h:34m:24s remains)
INFO - root - 2022-02-24 21:04:59.128090: step 161350, total loss = 0.52, batch loss = 0.26 (353.5 examples/sec; 0.023 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:04:59.431482: step 161360, total loss = 0.56, batch loss = 0.31 (327.3 examples/sec; 0.024 sec/batch; 0h:15m:32s remains)
INFO - root - 2022-02-24 21:04:59.852960: step 161370, total loss = 0.54, batch loss = 0.28 (235.3 examples/sec; 0.034 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 21:05:00.364071: step 161380, total loss = 0.50, batch loss = 0.24 (209.2 examples/sec; 0.038 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 21:05:00.786138: step 161390, total loss = 0.59, batch loss = 0.34 (175.0 examples/sec; 0.046 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 21:05:01.104512: step 161400, total loss = 0.53, batch loss = 0.27 (184.2 examples/sec; 0.043 sec/batch; 0h:27m:34s remains)
INFO - root - 2022-02-24 21:05:01.604589: step 161410, total loss = 0.60, batch loss = 0.34 (164.6 examples/sec; 0.049 sec/batch; 0h:30m:50s remains)
INFO - root - 2022-02-24 21:05:02.006548: step 161420, total loss = 0.48, batch loss = 0.23 (354.7 examples/sec; 0.023 sec/batch; 0h:14m:18s remains)
INFO - root - 2022-02-24 21:05:02.385106: step 161430, total loss = 0.47, batch loss = 0.22 (316.8 examples/sec; 0.025 sec/batch; 0h:16m:01s remains)
INFO - root - 2022-02-24 21:05:02.713726: step 161440, total loss = 0.64, batch loss = 0.39 (329.3 examples/sec; 0.024 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:05:03.031355: step 161450, total loss = 0.54, batch loss = 0.28 (316.5 examples/sec; 0.025 sec/batch; 0h:16m:01s remains)
INFO - root - 2022-02-24 21:05:03.302744: step 161460, total loss = 0.56, batch loss = 0.31 (287.0 examples/sec; 0.028 sec/batch; 0h:17m:40s remains)
INFO - root - 2022-02-24 21:05:03.781379: step 161470, total loss = 0.54, batch loss = 0.28 (326.2 examples/sec; 0.025 sec/batch; 0h:15m:32s remains)
INFO - root - 2022-02-24 21:05:04.207964: step 161480, total loss = 0.73, batch loss = 0.47 (319.9 examples/sec; 0.025 sec/batch; 0h:15m:50s remains)
INFO - root - 2022-02-24 21:05:04.500857: step 161490, total loss = 0.49, batch loss = 0.23 (208.6 examples/sec; 0.038 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 21:05:04.757864: step 161500, total loss = 0.47, batch loss = 0.21 (283.6 examples/sec; 0.028 sec/batch; 0h:17m:51s remains)
INFO - root - 2022-02-24 21:05:05.143154: step 161510, total loss = 0.56, batch loss = 0.30 (252.8 examples/sec; 0.032 sec/batch; 0h:20m:02s remains)
INFO - root - 2022-02-24 21:05:05.521639: step 161520, total loss = 0.50, batch loss = 0.25 (100.4 examples/sec; 0.080 sec/batch; 0h:50m:26s remains)
INFO - root - 2022-02-24 21:05:06.042566: step 161530, total loss = 0.55, batch loss = 0.30 (159.2 examples/sec; 0.050 sec/batch; 0h:31m:48s remains)
INFO - root - 2022-02-24 21:05:06.561537: step 161540, total loss = 0.65, batch loss = 0.39 (230.4 examples/sec; 0.035 sec/batch; 0h:21m:57s remains)
INFO - root - 2022-02-24 21:05:06.883189: step 161550, total loss = 0.51, batch loss = 0.25 (279.0 examples/sec; 0.029 sec/batch; 0h:18m:08s remains)
INFO - root - 2022-02-24 21:05:07.292712: step 161560, total loss = 0.55, batch loss = 0.29 (320.2 examples/sec; 0.025 sec/batch; 0h:15m:47s remains)
INFO - root - 2022-02-24 21:05:07.637761: step 161570, total loss = 0.60, batch loss = 0.34 (241.6 examples/sec; 0.033 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 21:05:08.144805: step 161580, total loss = 0.51, batch loss = 0.25 (128.1 examples/sec; 0.062 sec/batch; 0h:39m:28s remains)
INFO - root - 2022-02-24 21:05:08.484230: step 161590, total loss = 0.57, batch loss = 0.31 (262.2 examples/sec; 0.031 sec/batch; 0h:19m:16s remains)
INFO - root - 2022-02-24 21:05:08.922175: step 161600, total loss = 0.55, batch loss = 0.29 (308.8 examples/sec; 0.026 sec/batch; 0h:16m:21s remains)
INFO - root - 2022-02-24 21:05:09.349795: step 161610, total loss = 0.49, batch loss = 0.24 (197.9 examples/sec; 0.040 sec/batch; 0h:25m:31s remains)
INFO - root - 2022-02-24 21:05:09.654741: step 161620, total loss = 0.50, batch loss = 0.24 (252.6 examples/sec; 0.032 sec/batch; 0h:19m:59s remains)
INFO - root - 2022-02-24 21:05:10.105242: step 161630, total loss = 0.56, batch loss = 0.31 (241.3 examples/sec; 0.033 sec/batch; 0h:20m:55s remains)
INFO - root - 2022-02-24 21:05:10.470470: step 161640, total loss = 0.59, batch loss = 0.33 (179.6 examples/sec; 0.045 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 21:05:10.856022: step 161650, total loss = 0.46, batch loss = 0.21 (205.5 examples/sec; 0.039 sec/batch; 0h:24m:33s remains)
INFO - root - 2022-02-24 21:05:11.210288: step 161660, total loss = 0.48, batch loss = 0.23 (263.6 examples/sec; 0.030 sec/batch; 0h:19m:08s remains)
INFO - root - 2022-02-24 21:05:11.595347: step 161670, total loss = 0.58, batch loss = 0.32 (277.8 examples/sec; 0.029 sec/batch; 0h:18m:09s remains)
INFO - root - 2022-02-24 21:05:11.969972: step 161680, total loss = 0.57, batch loss = 0.31 (384.2 examples/sec; 0.021 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:05:12.504596: step 161690, total loss = 0.47, batch loss = 0.21 (166.8 examples/sec; 0.048 sec/batch; 0h:30m:13s remains)
INFO - root - 2022-02-24 21:05:12.855390: step 161700, total loss = 0.61, batch loss = 0.35 (260.6 examples/sec; 0.031 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 21:05:13.256262: step 161710, total loss = 0.47, batch loss = 0.21 (283.8 examples/sec; 0.028 sec/batch; 0h:17m:45s remains)
INFO - root - 2022-02-24 21:05:13.658390: step 161720, total loss = 0.56, batch loss = 0.30 (103.0 examples/sec; 0.078 sec/batch; 0h:48m:55s remains)
INFO - root - 2022-02-24 21:05:14.048883: step 161730, total loss = 0.46, batch loss = 0.20 (155.1 examples/sec; 0.052 sec/batch; 0h:32m:27s remains)
INFO - root - 2022-02-24 21:05:14.491794: step 161740, total loss = 0.58, batch loss = 0.33 (142.2 examples/sec; 0.056 sec/batch; 0h:35m:23s remains)
INFO - root - 2022-02-24 21:05:14.945084: step 161750, total loss = 0.52, batch loss = 0.26 (324.7 examples/sec; 0.025 sec/batch; 0h:15m:30s remains)
INFO - root - 2022-02-24 21:05:15.229600: step 161760, total loss = 0.51, batch loss = 0.26 (342.2 examples/sec; 0.023 sec/batch; 0h:14m:42s remains)
INFO - root - 2022-02-24 21:05:15.570538: step 161770, total loss = 0.48, batch loss = 0.23 (157.7 examples/sec; 0.051 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 21:05:15.958003: step 161780, total loss = 0.51, batch loss = 0.25 (208.7 examples/sec; 0.038 sec/batch; 0h:24m:05s remains)
INFO - root - 2022-02-24 21:05:16.376243: step 161790, total loss = 0.52, batch loss = 0.26 (162.3 examples/sec; 0.049 sec/batch; 0h:30m:58s remains)
INFO - root - 2022-02-24 21:05:17.130775: step 161800, total loss = 0.52, batch loss = 0.26 (188.2 examples/sec; 0.043 sec/batch; 0h:26m:42s remains)
INFO - root - 2022-02-24 21:05:17.519759: step 161810, total loss = 0.53, batch loss = 0.28 (264.1 examples/sec; 0.030 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:05:17.895275: step 161820, total loss = 0.49, batch loss = 0.23 (318.8 examples/sec; 0.025 sec/batch; 0h:15m:45s remains)
INFO - root - 2022-02-24 21:05:18.278579: step 161830, total loss = 0.54, batch loss = 0.29 (277.3 examples/sec; 0.029 sec/batch; 0h:18m:06s remains)
INFO - root - 2022-02-24 21:05:18.707461: step 161840, total loss = 0.57, batch loss = 0.32 (134.4 examples/sec; 0.060 sec/batch; 0h:37m:20s remains)
INFO - root - 2022-02-24 21:05:19.159402: step 161850, total loss = 0.51, batch loss = 0.26 (210.6 examples/sec; 0.038 sec/batch; 0h:23m:50s remains)
INFO - root - 2022-02-24 21:05:19.669095: step 161860, total loss = 0.55, batch loss = 0.29 (328.4 examples/sec; 0.024 sec/batch; 0h:15m:16s remains)
INFO - root - 2022-02-24 21:05:20.071666: step 161870, total loss = 0.59, batch loss = 0.33 (230.5 examples/sec; 0.035 sec/batch; 0h:21m:46s remains)
INFO - root - 2022-02-24 21:05:20.705912: step 161880, total loss = 0.48, batch loss = 0.23 (229.5 examples/sec; 0.035 sec/batch; 0h:21m:51s remains)
INFO - root - 2022-02-24 21:05:21.404331: step 161890, total loss = 0.75, batch loss = 0.50 (86.8 examples/sec; 0.092 sec/batch; 0h:57m:47s remains)
INFO - root - 2022-02-24 21:05:21.773884: step 161900, total loss = 0.58, batch loss = 0.32 (143.3 examples/sec; 0.056 sec/batch; 0h:34m:58s remains)
INFO - root - 2022-02-24 21:05:22.582971: step 161910, total loss = 0.59, batch loss = 0.33 (359.2 examples/sec; 0.022 sec/batch; 0h:13m:57s remains)
INFO - root - 2022-02-24 21:05:22.885786: step 161920, total loss = 0.48, batch loss = 0.23 (346.0 examples/sec; 0.023 sec/batch; 0h:14m:28s remains)
INFO - root - 2022-02-24 21:05:23.335875: step 161930, total loss = 0.51, batch loss = 0.25 (214.3 examples/sec; 0.037 sec/batch; 0h:23m:22s remains)
INFO - root - 2022-02-24 21:05:23.633194: step 161940, total loss = 0.55, batch loss = 0.29 (324.4 examples/sec; 0.025 sec/batch; 0h:15m:26s remains)
INFO - root - 2022-02-24 21:05:24.020476: step 161950, total loss = 0.58, batch loss = 0.33 (354.2 examples/sec; 0.023 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:05:24.412581: step 161960, total loss = 0.53, batch loss = 0.27 (171.9 examples/sec; 0.047 sec/batch; 0h:29m:07s remains)
INFO - root - 2022-02-24 21:05:24.727404: step 161970, total loss = 0.47, batch loss = 0.21 (214.3 examples/sec; 0.037 sec/batch; 0h:23m:21s remains)
INFO - root - 2022-02-24 21:05:25.099292: step 161980, total loss = 0.47, batch loss = 0.22 (196.0 examples/sec; 0.041 sec/batch; 0h:25m:31s remains)
INFO - root - 2022-02-24 21:05:25.604724: step 161990, total loss = 0.60, batch loss = 0.34 (103.0 examples/sec; 0.078 sec/batch; 0h:48m:32s remains)
INFO - root - 2022-02-24 21:05:25.959968: step 162000, total loss = 0.58, batch loss = 0.32 (217.1 examples/sec; 0.037 sec/batch; 0h:23m:01s remains)
INFO - root - 2022-02-24 21:05:26.472529: step 162010, total loss = 0.49, batch loss = 0.24 (217.3 examples/sec; 0.037 sec/batch; 0h:23m:00s remains)
INFO - root - 2022-02-24 21:05:26.911477: step 162020, total loss = 0.56, batch loss = 0.30 (127.2 examples/sec; 0.063 sec/batch; 0h:39m:17s remains)
INFO - root - 2022-02-24 21:05:27.446430: step 162030, total loss = 0.50, batch loss = 0.24 (168.7 examples/sec; 0.047 sec/batch; 0h:29m:37s remains)
INFO - root - 2022-02-24 21:05:27.856299: step 162040, total loss = 0.54, batch loss = 0.29 (151.2 examples/sec; 0.053 sec/batch; 0h:33m:01s remains)
INFO - root - 2022-02-24 21:05:28.216800: step 162050, total loss = 0.57, batch loss = 0.32 (150.0 examples/sec; 0.053 sec/batch; 0h:33m:16s remains)
INFO - root - 2022-02-24 21:05:28.538612: step 162060, total loss = 0.56, batch loss = 0.30 (226.3 examples/sec; 0.035 sec/batch; 0h:22m:03s remains)
INFO - root - 2022-02-24 21:05:28.974185: step 162070, total loss = 0.49, batch loss = 0.24 (155.8 examples/sec; 0.051 sec/batch; 0h:32m:02s remains)
INFO - root - 2022-02-24 21:05:29.376699: step 162080, total loss = 0.52, batch loss = 0.27 (288.1 examples/sec; 0.028 sec/batch; 0h:17m:19s remains)
INFO - root - 2022-02-24 21:05:29.707246: step 162090, total loss = 0.60, batch loss = 0.35 (157.0 examples/sec; 0.051 sec/batch; 0h:31m:46s remains)
INFO - root - 2022-02-24 21:05:29.995690: step 162100, total loss = 0.42, batch loss = 0.17 (318.5 examples/sec; 0.025 sec/batch; 0h:15m:39s remains)
INFO - root - 2022-02-24 21:05:30.414787: step 162110, total loss = 0.55, batch loss = 0.29 (329.1 examples/sec; 0.024 sec/batch; 0h:15m:09s remains)
INFO - root - 2022-02-24 21:05:30.845211: step 162120, total loss = 0.54, batch loss = 0.28 (181.0 examples/sec; 0.044 sec/batch; 0h:27m:32s remains)
INFO - root - 2022-02-24 21:05:31.260403: step 162130, total loss = 0.56, batch loss = 0.30 (145.6 examples/sec; 0.055 sec/batch; 0h:34m:12s remains)
INFO - root - 2022-02-24 21:05:31.563753: step 162140, total loss = 0.51, batch loss = 0.25 (240.2 examples/sec; 0.033 sec/batch; 0h:20m:44s remains)
INFO - root - 2022-02-24 21:05:31.891685: step 162150, total loss = 0.54, batch loss = 0.28 (190.4 examples/sec; 0.042 sec/batch; 0h:26m:09s remains)
INFO - root - 2022-02-24 21:05:32.216198: step 162160, total loss = 0.53, batch loss = 0.27 (359.0 examples/sec; 0.022 sec/batch; 0h:13m:52s remains)
INFO - root - 2022-02-24 21:05:32.578052: step 162170, total loss = 0.62, batch loss = 0.37 (318.3 examples/sec; 0.025 sec/batch; 0h:15m:38s remains)
INFO - root - 2022-02-24 21:05:32.938727: step 162180, total loss = 0.70, batch loss = 0.44 (281.5 examples/sec; 0.028 sec/batch; 0h:17m:40s remains)
INFO - root - 2022-02-24 21:05:33.414318: step 162190, total loss = 0.59, batch loss = 0.33 (290.4 examples/sec; 0.028 sec/batch; 0h:17m:07s remains)
INFO - root - 2022-02-24 21:05:33.714798: step 162200, total loss = 0.54, batch loss = 0.28 (210.4 examples/sec; 0.038 sec/batch; 0h:23m:38s remains)
INFO - root - 2022-02-24 21:05:34.203155: step 162210, total loss = 0.50, batch loss = 0.24 (272.0 examples/sec; 0.029 sec/batch; 0h:18m:16s remains)
INFO - root - 2022-02-24 21:05:34.527065: step 162220, total loss = 0.57, batch loss = 0.32 (282.4 examples/sec; 0.028 sec/batch; 0h:17m:35s remains)
INFO - root - 2022-02-24 21:05:34.999873: step 162230, total loss = 0.58, batch loss = 0.32 (145.5 examples/sec; 0.055 sec/batch; 0h:34m:09s remains)
INFO - root - 2022-02-24 21:05:35.451026: step 162240, total loss = 0.55, batch loss = 0.29 (99.0 examples/sec; 0.081 sec/batch; 0h:50m:09s remains)
INFO - root - 2022-02-24 21:05:35.859571: step 162250, total loss = 0.57, batch loss = 0.31 (228.0 examples/sec; 0.035 sec/batch; 0h:21m:47s remains)
INFO - root - 2022-02-24 21:05:36.236033: step 162260, total loss = 0.45, batch loss = 0.19 (149.2 examples/sec; 0.054 sec/batch; 0h:33m:17s remains)
INFO - root - 2022-02-24 21:05:36.538533: step 162270, total loss = 0.50, batch loss = 0.24 (282.5 examples/sec; 0.028 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 21:05:36.808861: step 162280, total loss = 0.58, batch loss = 0.32 (328.7 examples/sec; 0.024 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:05:37.218704: step 162290, total loss = 0.52, batch loss = 0.26 (269.9 examples/sec; 0.030 sec/batch; 0h:18m:22s remains)
INFO - root - 2022-02-24 21:05:37.672379: step 162300, total loss = 0.53, batch loss = 0.28 (231.8 examples/sec; 0.035 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 21:05:38.134843: step 162310, total loss = 0.58, batch loss = 0.33 (255.5 examples/sec; 0.031 sec/batch; 0h:19m:24s remains)
INFO - root - 2022-02-24 21:05:38.494149: step 162320, total loss = 0.55, batch loss = 0.30 (314.6 examples/sec; 0.025 sec/batch; 0h:15m:45s remains)
INFO - root - 2022-02-24 21:05:38.777749: step 162330, total loss = 0.53, batch loss = 0.28 (326.3 examples/sec; 0.025 sec/batch; 0h:15m:11s remains)
INFO - root - 2022-02-24 21:05:39.104516: step 162340, total loss = 0.56, batch loss = 0.31 (237.3 examples/sec; 0.034 sec/batch; 0h:20m:52s remains)
INFO - root - 2022-02-24 21:05:39.423952: step 162350, total loss = 0.56, batch loss = 0.30 (161.5 examples/sec; 0.050 sec/batch; 0h:30m:40s remains)
INFO - root - 2022-02-24 21:05:39.793648: step 162360, total loss = 0.56, batch loss = 0.30 (258.5 examples/sec; 0.031 sec/batch; 0h:19m:09s remains)
INFO - root - 2022-02-24 21:05:40.185038: step 162370, total loss = 0.50, batch loss = 0.25 (133.0 examples/sec; 0.060 sec/batch; 0h:37m:13s remains)
INFO - root - 2022-02-24 21:05:40.498796: step 162380, total loss = 0.51, batch loss = 0.25 (370.4 examples/sec; 0.022 sec/batch; 0h:13m:21s remains)
INFO - root - 2022-02-24 21:05:40.850906: step 162390, total loss = 0.54, batch loss = 0.28 (166.9 examples/sec; 0.048 sec/batch; 0h:29m:39s remains)
INFO - root - 2022-02-24 21:05:41.204661: step 162400, total loss = 0.55, batch loss = 0.29 (146.9 examples/sec; 0.054 sec/batch; 0h:33m:40s remains)
INFO - root - 2022-02-24 21:05:41.585977: step 162410, total loss = 0.55, batch loss = 0.29 (312.3 examples/sec; 0.026 sec/batch; 0h:15m:50s remains)
INFO - root - 2022-02-24 21:05:42.026212: step 162420, total loss = 0.60, batch loss = 0.34 (130.2 examples/sec; 0.061 sec/batch; 0h:37m:58s remains)
INFO - root - 2022-02-24 21:05:42.577104: step 162430, total loss = 0.46, batch loss = 0.20 (204.4 examples/sec; 0.039 sec/batch; 0h:24m:11s remains)
INFO - root - 2022-02-24 21:05:43.019140: step 162440, total loss = 0.51, batch loss = 0.25 (204.8 examples/sec; 0.039 sec/batch; 0h:24m:07s remains)
INFO - root - 2022-02-24 21:05:43.308125: step 162450, total loss = 0.63, batch loss = 0.37 (292.4 examples/sec; 0.027 sec/batch; 0h:16m:53s remains)
INFO - root - 2022-02-24 21:05:43.686818: step 162460, total loss = 0.47, batch loss = 0.22 (157.0 examples/sec; 0.051 sec/batch; 0h:31m:27s remains)
INFO - root - 2022-02-24 21:05:44.228008: step 162470, total loss = 0.44, batch loss = 0.19 (110.6 examples/sec; 0.072 sec/batch; 0h:44m:39s remains)
INFO - root - 2022-02-24 21:05:44.651894: step 162480, total loss = 0.51, batch loss = 0.25 (277.4 examples/sec; 0.029 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 21:05:44.953830: step 162490, total loss = 0.56, batch loss = 0.31 (338.7 examples/sec; 0.024 sec/batch; 0h:14m:34s remains)
INFO - root - 2022-02-24 21:05:45.241664: step 162500, total loss = 0.61, batch loss = 0.36 (291.3 examples/sec; 0.027 sec/batch; 0h:16m:56s remains)
INFO - root - 2022-02-24 21:05:45.621709: step 162510, total loss = 0.55, batch loss = 0.30 (333.7 examples/sec; 0.024 sec/batch; 0h:14m:46s remains)
INFO - root - 2022-02-24 21:05:46.028262: step 162520, total loss = 0.60, batch loss = 0.34 (218.8 examples/sec; 0.037 sec/batch; 0h:22m:32s remains)
INFO - root - 2022-02-24 21:05:46.490264: step 162530, total loss = 0.55, batch loss = 0.30 (252.5 examples/sec; 0.032 sec/batch; 0h:19m:31s remains)
INFO - root - 2022-02-24 21:05:46.855059: step 162540, total loss = 0.57, batch loss = 0.31 (352.6 examples/sec; 0.023 sec/batch; 0h:13m:58s remains)
INFO - root - 2022-02-24 21:05:47.184073: step 162550, total loss = 0.53, batch loss = 0.27 (368.5 examples/sec; 0.022 sec/batch; 0h:13m:22s remains)
INFO - root - 2022-02-24 21:05:47.591256: step 162560, total loss = 0.50, batch loss = 0.24 (154.2 examples/sec; 0.052 sec/batch; 0h:31m:56s remains)
INFO - root - 2022-02-24 21:05:47.993481: step 162570, total loss = 0.49, batch loss = 0.23 (209.6 examples/sec; 0.038 sec/batch; 0h:23m:29s remains)
INFO - root - 2022-02-24 21:05:48.429848: step 162580, total loss = 0.45, batch loss = 0.19 (228.7 examples/sec; 0.035 sec/batch; 0h:21m:31s remains)
INFO - root - 2022-02-24 21:05:48.840188: step 162590, total loss = 0.50, batch loss = 0.24 (123.5 examples/sec; 0.065 sec/batch; 0h:39m:50s remains)
INFO - root - 2022-02-24 21:05:49.302548: step 162600, total loss = 0.49, batch loss = 0.24 (111.3 examples/sec; 0.072 sec/batch; 0h:44m:11s remains)
INFO - root - 2022-02-24 21:05:49.706909: step 162610, total loss = 0.50, batch loss = 0.25 (346.1 examples/sec; 0.023 sec/batch; 0h:14m:12s remains)
INFO - root - 2022-02-24 21:05:50.043256: step 162620, total loss = 0.56, batch loss = 0.30 (401.7 examples/sec; 0.020 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:05:50.415138: step 162630, total loss = 0.52, batch loss = 0.27 (286.7 examples/sec; 0.028 sec/batch; 0h:17m:08s remains)
INFO - root - 2022-02-24 21:05:50.844679: step 162640, total loss = 0.51, batch loss = 0.25 (221.8 examples/sec; 0.036 sec/batch; 0h:22m:09s remains)
INFO - root - 2022-02-24 21:05:51.214777: step 162650, total loss = 0.54, batch loss = 0.28 (207.1 examples/sec; 0.039 sec/batch; 0h:23m:43s remains)
INFO - root - 2022-02-24 21:05:51.664683: step 162660, total loss = 0.60, batch loss = 0.34 (358.4 examples/sec; 0.022 sec/batch; 0h:13m:42s remains)
INFO - root - 2022-02-24 21:05:52.049335: step 162670, total loss = 0.58, batch loss = 0.32 (217.8 examples/sec; 0.037 sec/batch; 0h:22m:32s remains)
INFO - root - 2022-02-24 21:05:52.373156: step 162680, total loss = 0.49, batch loss = 0.23 (328.7 examples/sec; 0.024 sec/batch; 0h:14m:56s remains)
INFO - root - 2022-02-24 21:05:53.137572: step 162690, total loss = 0.49, batch loss = 0.24 (116.6 examples/sec; 0.069 sec/batch; 0h:42m:05s remains)
INFO - root - 2022-02-24 21:05:53.590499: step 162700, total loss = 0.45, batch loss = 0.19 (74.8 examples/sec; 0.107 sec/batch; 1h:05m:36s remains)
INFO - root - 2022-02-24 21:05:54.038415: step 162710, total loss = 0.43, batch loss = 0.17 (355.0 examples/sec; 0.023 sec/batch; 0h:13m:49s remains)
INFO - root - 2022-02-24 21:05:54.433703: step 162720, total loss = 0.50, batch loss = 0.25 (81.7 examples/sec; 0.098 sec/batch; 1h:00m:01s remains)
INFO - root - 2022-02-24 21:05:54.832750: step 162730, total loss = 0.56, batch loss = 0.31 (353.1 examples/sec; 0.023 sec/batch; 0h:13m:52s remains)
INFO - root - 2022-02-24 21:05:55.246382: step 162740, total loss = 0.44, batch loss = 0.18 (141.0 examples/sec; 0.057 sec/batch; 0h:34m:46s remains)
INFO - root - 2022-02-24 21:05:55.748932: step 162750, total loss = 0.47, batch loss = 0.22 (322.2 examples/sec; 0.025 sec/batch; 0h:15m:12s remains)
INFO - root - 2022-02-24 21:05:56.168406: step 162760, total loss = 0.52, batch loss = 0.26 (352.1 examples/sec; 0.023 sec/batch; 0h:13m:54s remains)
INFO - root - 2022-02-24 21:05:56.636542: step 162770, total loss = 0.45, batch loss = 0.19 (122.2 examples/sec; 0.065 sec/batch; 0h:40m:03s remains)
INFO - root - 2022-02-24 21:05:57.223001: step 162780, total loss = 0.54, batch loss = 0.28 (105.7 examples/sec; 0.076 sec/batch; 0h:46m:18s remains)
INFO - root - 2022-02-24 21:05:57.679687: step 162790, total loss = 0.54, batch loss = 0.29 (98.6 examples/sec; 0.081 sec/batch; 0h:49m:37s remains)
INFO - root - 2022-02-24 21:05:58.658197: step 162800, total loss = 0.61, batch loss = 0.35 (185.3 examples/sec; 0.043 sec/batch; 0h:26m:24s remains)
INFO - root - 2022-02-24 21:05:59.138722: step 162810, total loss = 0.49, batch loss = 0.24 (186.7 examples/sec; 0.043 sec/batch; 0h:26m:11s remains)
INFO - root - 2022-02-24 21:05:59.496030: step 162820, total loss = 0.48, batch loss = 0.23 (196.6 examples/sec; 0.041 sec/batch; 0h:24m:52s remains)
INFO - root - 2022-02-24 21:05:59.866798: step 162830, total loss = 0.51, batch loss = 0.26 (230.0 examples/sec; 0.035 sec/batch; 0h:21m:15s remains)
INFO - root - 2022-02-24 21:06:00.273110: step 162840, total loss = 0.55, batch loss = 0.29 (304.9 examples/sec; 0.026 sec/batch; 0h:16m:02s remains)
INFO - root - 2022-02-24 21:06:00.718424: step 162850, total loss = 0.62, batch loss = 0.36 (274.5 examples/sec; 0.029 sec/batch; 0h:17m:47s remains)
INFO - root - 2022-02-24 21:06:01.053549: step 162860, total loss = 0.59, batch loss = 0.33 (191.7 examples/sec; 0.042 sec/batch; 0h:25m:29s remains)
INFO - root - 2022-02-24 21:06:01.415180: step 162870, total loss = 0.49, batch loss = 0.23 (243.3 examples/sec; 0.033 sec/batch; 0h:20m:04s remains)
INFO - root - 2022-02-24 21:06:01.742314: step 162880, total loss = 0.52, batch loss = 0.27 (186.3 examples/sec; 0.043 sec/batch; 0h:26m:12s remains)
INFO - root - 2022-02-24 21:06:02.184922: step 162890, total loss = 0.57, batch loss = 0.31 (105.0 examples/sec; 0.076 sec/batch; 0h:46m:28s remains)
INFO - root - 2022-02-24 21:06:02.577732: step 162900, total loss = 0.52, batch loss = 0.27 (370.5 examples/sec; 0.022 sec/batch; 0h:13m:10s remains)
INFO - root - 2022-02-24 21:06:03.097781: step 162910, total loss = 0.72, batch loss = 0.46 (279.1 examples/sec; 0.029 sec/batch; 0h:17m:28s remains)
INFO - root - 2022-02-24 21:06:03.435811: step 162920, total loss = 0.59, batch loss = 0.34 (161.2 examples/sec; 0.050 sec/batch; 0h:30m:15s remains)
INFO - root - 2022-02-24 21:06:03.775663: step 162930, total loss = 0.49, batch loss = 0.23 (177.2 examples/sec; 0.045 sec/batch; 0h:27m:30s remains)
INFO - root - 2022-02-24 21:06:04.266899: step 162940, total loss = 0.51, batch loss = 0.25 (129.7 examples/sec; 0.062 sec/batch; 0h:37m:35s remains)
INFO - root - 2022-02-24 21:06:04.817070: step 162950, total loss = 0.51, batch loss = 0.25 (69.0 examples/sec; 0.116 sec/batch; 1h:10m:38s remains)
INFO - root - 2022-02-24 21:06:05.284800: step 162960, total loss = 0.58, batch loss = 0.33 (331.8 examples/sec; 0.024 sec/batch; 0h:14m:40s remains)
INFO - root - 2022-02-24 21:06:05.613667: step 162970, total loss = 0.61, batch loss = 0.36 (305.0 examples/sec; 0.026 sec/batch; 0h:15m:58s remains)
INFO - root - 2022-02-24 21:06:05.960494: step 162980, total loss = 0.56, batch loss = 0.31 (225.2 examples/sec; 0.036 sec/batch; 0h:21m:37s remains)
INFO - root - 2022-02-24 21:06:06.273453: step 162990, total loss = 0.51, batch loss = 0.25 (174.8 examples/sec; 0.046 sec/batch; 0h:27m:51s remains)
INFO - root - 2022-02-24 21:06:06.627267: step 163000, total loss = 0.53, batch loss = 0.28 (240.4 examples/sec; 0.033 sec/batch; 0h:20m:14s remains)
INFO - root - 2022-02-24 21:06:07.091347: step 163010, total loss = 0.60, batch loss = 0.35 (161.9 examples/sec; 0.049 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 21:06:07.391413: step 163020, total loss = 0.57, batch loss = 0.31 (241.1 examples/sec; 0.033 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:06:07.722129: step 163030, total loss = 0.60, batch loss = 0.35 (266.4 examples/sec; 0.030 sec/batch; 0h:18m:15s remains)
INFO - root - 2022-02-24 21:06:08.090930: step 163040, total loss = 0.56, batch loss = 0.30 (143.9 examples/sec; 0.056 sec/batch; 0h:33m:47s remains)
INFO - root - 2022-02-24 21:06:08.423763: step 163050, total loss = 0.45, batch loss = 0.19 (148.2 examples/sec; 0.054 sec/batch; 0h:32m:47s remains)
INFO - root - 2022-02-24 21:06:08.914612: step 163060, total loss = 0.49, batch loss = 0.24 (329.0 examples/sec; 0.024 sec/batch; 0h:14m:46s remains)
INFO - root - 2022-02-24 21:06:09.333263: step 163070, total loss = 0.48, batch loss = 0.22 (214.3 examples/sec; 0.037 sec/batch; 0h:22m:40s remains)
INFO - root - 2022-02-24 21:06:09.741526: step 163080, total loss = 0.53, batch loss = 0.27 (330.5 examples/sec; 0.024 sec/batch; 0h:14m:41s remains)
INFO - root - 2022-02-24 21:06:10.078216: step 163090, total loss = 0.53, batch loss = 0.27 (195.1 examples/sec; 0.041 sec/batch; 0h:24m:53s remains)
INFO - root - 2022-02-24 21:06:10.419180: step 163100, total loss = 0.52, batch loss = 0.27 (258.0 examples/sec; 0.031 sec/batch; 0h:18m:48s remains)
INFO - root - 2022-02-24 21:06:10.841573: step 163110, total loss = 0.54, batch loss = 0.28 (257.2 examples/sec; 0.031 sec/batch; 0h:18m:51s remains)
INFO - root - 2022-02-24 21:06:11.214011: step 163120, total loss = 0.57, batch loss = 0.31 (321.4 examples/sec; 0.025 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:06:11.664565: step 163130, total loss = 0.52, batch loss = 0.26 (298.8 examples/sec; 0.027 sec/batch; 0h:16m:13s remains)
INFO - root - 2022-02-24 21:06:12.038944: step 163140, total loss = 0.53, batch loss = 0.27 (244.3 examples/sec; 0.033 sec/batch; 0h:19m:50s remains)
INFO - root - 2022-02-24 21:06:12.375302: step 163150, total loss = 0.49, batch loss = 0.23 (157.3 examples/sec; 0.051 sec/batch; 0h:30m:48s remains)
INFO - root - 2022-02-24 21:06:12.752093: step 163160, total loss = 0.48, batch loss = 0.23 (302.3 examples/sec; 0.026 sec/batch; 0h:16m:01s remains)
INFO - root - 2022-02-24 21:06:13.116539: step 163170, total loss = 0.56, batch loss = 0.30 (173.3 examples/sec; 0.046 sec/batch; 0h:27m:57s remains)
INFO - root - 2022-02-24 21:06:13.544279: step 163180, total loss = 0.45, batch loss = 0.19 (119.8 examples/sec; 0.067 sec/batch; 0h:40m:25s remains)
INFO - root - 2022-02-24 21:06:13.989960: step 163190, total loss = 0.53, batch loss = 0.28 (179.8 examples/sec; 0.044 sec/batch; 0h:26m:55s remains)
INFO - root - 2022-02-24 21:06:14.287807: step 163200, total loss = 0.55, batch loss = 0.29 (285.4 examples/sec; 0.028 sec/batch; 0h:16m:57s remains)
INFO - root - 2022-02-24 21:06:14.698056: step 163210, total loss = 0.52, batch loss = 0.27 (140.9 examples/sec; 0.057 sec/batch; 0h:34m:21s remains)
INFO - root - 2022-02-24 21:06:15.010015: step 163220, total loss = 0.45, batch loss = 0.20 (166.9 examples/sec; 0.048 sec/batch; 0h:28m:58s remains)
INFO - root - 2022-02-24 21:06:15.460674: step 163230, total loss = 0.48, batch loss = 0.22 (157.2 examples/sec; 0.051 sec/batch; 0h:30m:45s remains)
INFO - root - 2022-02-24 21:06:15.951225: step 163240, total loss = 0.51, batch loss = 0.25 (163.1 examples/sec; 0.049 sec/batch; 0h:29m:38s remains)
INFO - root - 2022-02-24 21:06:16.297424: step 163250, total loss = 0.50, batch loss = 0.24 (337.0 examples/sec; 0.024 sec/batch; 0h:14m:20s remains)
INFO - root - 2022-02-24 21:06:16.665870: step 163260, total loss = 0.55, batch loss = 0.29 (223.5 examples/sec; 0.036 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 21:06:16.995798: step 163270, total loss = 0.58, batch loss = 0.32 (333.2 examples/sec; 0.024 sec/batch; 0h:14m:29s remains)
INFO - root - 2022-02-24 21:06:17.428685: step 163280, total loss = 0.54, batch loss = 0.28 (199.3 examples/sec; 0.040 sec/batch; 0h:24m:13s remains)
INFO - root - 2022-02-24 21:06:17.863551: step 163290, total loss = 0.49, batch loss = 0.23 (260.6 examples/sec; 0.031 sec/batch; 0h:18m:31s remains)
INFO - root - 2022-02-24 21:06:18.348143: step 163300, total loss = 0.58, batch loss = 0.32 (336.0 examples/sec; 0.024 sec/batch; 0h:14m:21s remains)
INFO - root - 2022-02-24 21:06:18.725998: step 163310, total loss = 0.68, batch loss = 0.42 (340.8 examples/sec; 0.023 sec/batch; 0h:14m:09s remains)
INFO - root - 2022-02-24 21:06:19.112607: step 163320, total loss = 0.49, batch loss = 0.24 (239.0 examples/sec; 0.033 sec/batch; 0h:20m:11s remains)
INFO - root - 2022-02-24 21:06:19.429593: step 163330, total loss = 0.47, batch loss = 0.21 (178.9 examples/sec; 0.045 sec/batch; 0h:26m:57s remains)
INFO - root - 2022-02-24 21:06:19.785583: step 163340, total loss = 0.62, batch loss = 0.37 (356.1 examples/sec; 0.022 sec/batch; 0h:13m:32s remains)
INFO - root - 2022-02-24 21:06:20.264370: step 163350, total loss = 0.47, batch loss = 0.21 (164.1 examples/sec; 0.049 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 21:06:20.720582: step 163360, total loss = 0.64, batch loss = 0.39 (330.0 examples/sec; 0.024 sec/batch; 0h:14m:35s remains)
INFO - root - 2022-02-24 21:06:21.135224: step 163370, total loss = 0.53, batch loss = 0.27 (168.7 examples/sec; 0.047 sec/batch; 0h:28m:32s remains)
INFO - root - 2022-02-24 21:06:21.507542: step 163380, total loss = 0.62, batch loss = 0.36 (332.8 examples/sec; 0.024 sec/batch; 0h:14m:28s remains)
INFO - root - 2022-02-24 21:06:21.813788: step 163390, total loss = 0.51, batch loss = 0.25 (331.3 examples/sec; 0.024 sec/batch; 0h:14m:31s remains)
INFO - root - 2022-02-24 21:06:22.208411: step 163400, total loss = 0.47, batch loss = 0.22 (345.4 examples/sec; 0.023 sec/batch; 0h:13m:56s remains)
INFO - root - 2022-02-24 21:06:22.755848: step 163410, total loss = 0.61, batch loss = 0.35 (126.6 examples/sec; 0.063 sec/batch; 0h:38m:00s remains)
INFO - root - 2022-02-24 21:06:23.111903: step 163420, total loss = 0.59, batch loss = 0.33 (347.5 examples/sec; 0.023 sec/batch; 0h:13m:50s remains)
INFO - root - 2022-02-24 21:06:23.531307: step 163430, total loss = 0.57, batch loss = 0.32 (227.9 examples/sec; 0.035 sec/batch; 0h:21m:06s remains)
INFO - root - 2022-02-24 21:06:23.897883: step 163440, total loss = 0.47, batch loss = 0.21 (201.0 examples/sec; 0.040 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 21:06:24.277608: step 163450, total loss = 0.52, batch loss = 0.26 (159.0 examples/sec; 0.050 sec/batch; 0h:30m:13s remains)
INFO - root - 2022-02-24 21:06:24.714369: step 163460, total loss = 0.52, batch loss = 0.27 (194.4 examples/sec; 0.041 sec/batch; 0h:24m:42s remains)
INFO - root - 2022-02-24 21:06:25.044204: step 163470, total loss = 0.55, batch loss = 0.29 (306.2 examples/sec; 0.026 sec/batch; 0h:15m:41s remains)
INFO - root - 2022-02-24 21:06:25.442509: step 163480, total loss = 0.58, batch loss = 0.32 (127.7 examples/sec; 0.063 sec/batch; 0h:37m:36s remains)
INFO - root - 2022-02-24 21:06:25.765142: step 163490, total loss = 0.53, batch loss = 0.27 (152.0 examples/sec; 0.053 sec/batch; 0h:31m:34s remains)
INFO - root - 2022-02-24 21:06:26.226947: step 163500, total loss = 0.62, batch loss = 0.37 (223.5 examples/sec; 0.036 sec/batch; 0h:21m:28s remains)
INFO - root - 2022-02-24 21:06:26.698852: step 163510, total loss = 0.44, batch loss = 0.18 (302.6 examples/sec; 0.026 sec/batch; 0h:15m:51s remains)
INFO - root - 2022-02-24 21:06:27.106666: step 163520, total loss = 0.56, batch loss = 0.30 (155.2 examples/sec; 0.052 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 21:06:27.445323: step 163530, total loss = 0.55, batch loss = 0.29 (346.2 examples/sec; 0.023 sec/batch; 0h:13m:51s remains)
INFO - root - 2022-02-24 21:06:27.777767: step 163540, total loss = 0.44, batch loss = 0.18 (268.4 examples/sec; 0.030 sec/batch; 0h:17m:51s remains)
INFO - root - 2022-02-24 21:06:28.463650: step 163550, total loss = 0.51, batch loss = 0.25 (25.1 examples/sec; 0.319 sec/batch; 3h:11m:11s remains)
INFO - root - 2022-02-24 21:06:28.945167: step 163560, total loss = 0.52, batch loss = 0.26 (113.1 examples/sec; 0.071 sec/batch; 0h:42m:22s remains)
INFO - root - 2022-02-24 21:06:29.339343: step 163570, total loss = 0.52, batch loss = 0.26 (137.4 examples/sec; 0.058 sec/batch; 0h:34m:52s remains)
INFO - root - 2022-02-24 21:06:29.707982: step 163580, total loss = 0.46, batch loss = 0.20 (266.3 examples/sec; 0.030 sec/batch; 0h:17m:58s remains)
INFO - root - 2022-02-24 21:06:30.078656: step 163590, total loss = 0.65, batch loss = 0.40 (125.2 examples/sec; 0.064 sec/batch; 0h:38m:13s remains)
INFO - root - 2022-02-24 21:06:30.538271: step 163600, total loss = 0.55, batch loss = 0.29 (177.9 examples/sec; 0.045 sec/batch; 0h:26m:54s remains)
INFO - root - 2022-02-24 21:06:30.979166: step 163610, total loss = 0.51, batch loss = 0.25 (328.1 examples/sec; 0.024 sec/batch; 0h:14m:35s remains)
INFO - root - 2022-02-24 21:06:31.706520: step 163620, total loss = 0.58, batch loss = 0.33 (324.8 examples/sec; 0.025 sec/batch; 0h:14m:43s remains)
INFO - root - 2022-02-24 21:06:32.125696: step 163630, total loss = 0.48, batch loss = 0.23 (299.2 examples/sec; 0.027 sec/batch; 0h:15m:58s remains)
INFO - root - 2022-02-24 21:06:32.554464: step 163640, total loss = 0.62, batch loss = 0.36 (316.8 examples/sec; 0.025 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:06:32.990833: step 163650, total loss = 0.49, batch loss = 0.23 (93.6 examples/sec; 0.086 sec/batch; 0h:51m:05s remains)
INFO - root - 2022-02-24 21:06:33.777003: step 163660, total loss = 0.58, batch loss = 0.33 (250.8 examples/sec; 0.032 sec/batch; 0h:19m:03s remains)
INFO - root - 2022-02-24 21:06:34.147039: step 163670, total loss = 0.59, batch loss = 0.33 (268.2 examples/sec; 0.030 sec/batch; 0h:17m:48s remains)
INFO - root - 2022-02-24 21:06:34.597454: step 163680, total loss = 0.62, batch loss = 0.37 (109.0 examples/sec; 0.073 sec/batch; 0h:43m:48s remains)
INFO - root - 2022-02-24 21:06:35.036643: step 163690, total loss = 0.47, batch loss = 0.21 (111.8 examples/sec; 0.072 sec/batch; 0h:42m:42s remains)
INFO - root - 2022-02-24 21:06:35.409258: step 163700, total loss = 0.57, batch loss = 0.31 (235.4 examples/sec; 0.034 sec/batch; 0h:20m:16s remains)
INFO - root - 2022-02-24 21:06:35.786832: step 163710, total loss = 0.61, batch loss = 0.35 (236.4 examples/sec; 0.034 sec/batch; 0h:20m:11s remains)
INFO - root - 2022-02-24 21:06:36.116945: step 163720, total loss = 0.45, batch loss = 0.19 (286.0 examples/sec; 0.028 sec/batch; 0h:16m:40s remains)
INFO - root - 2022-02-24 21:06:36.554064: step 163730, total loss = 0.46, batch loss = 0.20 (126.1 examples/sec; 0.063 sec/batch; 0h:37m:48s remains)
INFO - root - 2022-02-24 21:06:37.009057: step 163740, total loss = 0.49, batch loss = 0.23 (360.8 examples/sec; 0.022 sec/batch; 0h:13m:12s remains)
INFO - root - 2022-02-24 21:06:37.516807: step 163750, total loss = 0.53, batch loss = 0.28 (250.0 examples/sec; 0.032 sec/batch; 0h:19m:03s remains)
INFO - root - 2022-02-24 21:06:37.823121: step 163760, total loss = 0.53, batch loss = 0.27 (334.2 examples/sec; 0.024 sec/batch; 0h:14m:15s remains)
INFO - root - 2022-02-24 21:06:38.198630: step 163770, total loss = 0.56, batch loss = 0.31 (206.5 examples/sec; 0.039 sec/batch; 0h:23m:04s remains)
INFO - root - 2022-02-24 21:06:38.607755: step 163780, total loss = 0.58, batch loss = 0.32 (233.4 examples/sec; 0.034 sec/batch; 0h:20m:24s remains)
INFO - root - 2022-02-24 21:06:39.068628: step 163790, total loss = 0.56, batch loss = 0.30 (264.0 examples/sec; 0.030 sec/batch; 0h:18m:02s remains)
INFO - root - 2022-02-24 21:06:39.453939: step 163800, total loss = 0.56, batch loss = 0.30 (164.4 examples/sec; 0.049 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 21:06:39.866449: step 163810, total loss = 0.47, batch loss = 0.21 (155.5 examples/sec; 0.051 sec/batch; 0h:30m:36s remains)
INFO - root - 2022-02-24 21:06:40.262723: step 163820, total loss = 0.59, batch loss = 0.33 (210.4 examples/sec; 0.038 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 21:06:40.558744: step 163830, total loss = 0.59, batch loss = 0.34 (288.1 examples/sec; 0.028 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:06:40.918274: step 163840, total loss = 0.55, batch loss = 0.29 (157.3 examples/sec; 0.051 sec/batch; 0h:30m:13s remains)
INFO - root - 2022-02-24 21:06:41.314398: step 163850, total loss = 0.50, batch loss = 0.24 (141.9 examples/sec; 0.056 sec/batch; 0h:33m:29s remains)
INFO - root - 2022-02-24 21:06:41.666736: step 163860, total loss = 0.61, batch loss = 0.35 (184.7 examples/sec; 0.043 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 21:06:42.031471: step 163870, total loss = 0.54, batch loss = 0.29 (297.0 examples/sec; 0.027 sec/batch; 0h:15m:59s remains)
INFO - root - 2022-02-24 21:06:42.342430: step 163880, total loss = 0.50, batch loss = 0.24 (347.4 examples/sec; 0.023 sec/batch; 0h:13m:40s remains)
INFO - root - 2022-02-24 21:06:42.689789: step 163890, total loss = 0.57, batch loss = 0.31 (275.6 examples/sec; 0.029 sec/batch; 0h:17m:13s remains)
INFO - root - 2022-02-24 21:06:43.115153: step 163900, total loss = 0.49, batch loss = 0.24 (269.7 examples/sec; 0.030 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:06:43.515025: step 163910, total loss = 0.59, batch loss = 0.33 (231.0 examples/sec; 0.035 sec/batch; 0h:20m:32s remains)
INFO - root - 2022-02-24 21:06:44.015728: step 163920, total loss = 0.49, batch loss = 0.23 (331.1 examples/sec; 0.024 sec/batch; 0h:14m:19s remains)
INFO - root - 2022-02-24 21:06:44.420443: step 163930, total loss = 0.59, batch loss = 0.33 (216.1 examples/sec; 0.037 sec/batch; 0h:21m:56s remains)
INFO - root - 2022-02-24 21:06:44.750609: step 163940, total loss = 0.51, batch loss = 0.25 (362.1 examples/sec; 0.022 sec/batch; 0h:13m:05s remains)
INFO - root - 2022-02-24 21:06:45.164165: step 163950, total loss = 0.49, batch loss = 0.23 (133.9 examples/sec; 0.060 sec/batch; 0h:35m:24s remains)
INFO - root - 2022-02-24 21:06:45.556560: step 163960, total loss = 0.54, batch loss = 0.29 (246.7 examples/sec; 0.032 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 21:06:45.991839: step 163970, total loss = 0.58, batch loss = 0.32 (290.2 examples/sec; 0.028 sec/batch; 0h:16m:19s remains)
INFO - root - 2022-02-24 21:06:46.328663: step 163980, total loss = 0.68, batch loss = 0.43 (240.7 examples/sec; 0.033 sec/batch; 0h:19m:40s remains)
INFO - root - 2022-02-24 21:06:46.625132: step 163990, total loss = 0.77, batch loss = 0.51 (351.9 examples/sec; 0.023 sec/batch; 0h:13m:27s remains)
INFO - root - 2022-02-24 21:06:47.027590: step 164000, total loss = 0.50, batch loss = 0.25 (211.9 examples/sec; 0.038 sec/batch; 0h:22m:20s remains)
INFO - root - 2022-02-24 21:06:47.434038: step 164010, total loss = 0.52, batch loss = 0.27 (172.3 examples/sec; 0.046 sec/batch; 0h:27m:28s remains)
INFO - root - 2022-02-24 21:06:47.837096: step 164020, total loss = 0.59, batch loss = 0.34 (144.1 examples/sec; 0.056 sec/batch; 0h:32m:49s remains)
INFO - root - 2022-02-24 21:06:48.166681: step 164030, total loss = 0.49, batch loss = 0.23 (243.7 examples/sec; 0.033 sec/batch; 0h:19m:24s remains)
INFO - root - 2022-02-24 21:06:48.482343: step 164040, total loss = 0.56, batch loss = 0.30 (332.1 examples/sec; 0.024 sec/batch; 0h:14m:14s remains)
INFO - root - 2022-02-24 21:06:48.825719: step 164050, total loss = 0.52, batch loss = 0.26 (325.1 examples/sec; 0.025 sec/batch; 0h:14m:32s remains)
INFO - root - 2022-02-24 21:06:49.328849: step 164060, total loss = 0.51, batch loss = 0.26 (220.8 examples/sec; 0.036 sec/batch; 0h:21m:24s remains)
INFO - root - 2022-02-24 21:06:49.780571: step 164070, total loss = 0.46, batch loss = 0.20 (202.9 examples/sec; 0.039 sec/batch; 0h:23m:17s remains)
INFO - root - 2022-02-24 21:06:50.148172: step 164080, total loss = 0.57, batch loss = 0.31 (367.4 examples/sec; 0.022 sec/batch; 0h:12m:51s remains)
INFO - root - 2022-02-24 21:06:50.597325: step 164090, total loss = 0.59, batch loss = 0.33 (131.1 examples/sec; 0.061 sec/batch; 0h:36m:00s remains)
INFO - root - 2022-02-24 21:06:50.875854: step 164100, total loss = 0.49, batch loss = 0.23 (324.1 examples/sec; 0.025 sec/batch; 0h:14m:33s remains)
INFO - root - 2022-02-24 21:06:51.357858: step 164110, total loss = 0.49, batch loss = 0.23 (365.4 examples/sec; 0.022 sec/batch; 0h:12m:54s remains)
INFO - root - 2022-02-24 21:06:51.816190: step 164120, total loss = 0.50, batch loss = 0.24 (245.8 examples/sec; 0.033 sec/batch; 0h:19m:11s remains)
INFO - root - 2022-02-24 21:06:52.369817: step 164130, total loss = 0.50, batch loss = 0.24 (169.9 examples/sec; 0.047 sec/batch; 0h:27m:45s remains)
INFO - root - 2022-02-24 21:06:52.923725: step 164140, total loss = 0.50, batch loss = 0.25 (122.8 examples/sec; 0.065 sec/batch; 0h:38m:22s remains)
INFO - root - 2022-02-24 21:06:53.434795: step 164150, total loss = 0.60, batch loss = 0.34 (70.3 examples/sec; 0.114 sec/batch; 1h:07m:00s remains)
INFO - root - 2022-02-24 21:06:53.823767: step 164160, total loss = 0.50, batch loss = 0.24 (274.5 examples/sec; 0.029 sec/batch; 0h:17m:09s remains)
INFO - root - 2022-02-24 21:06:54.416749: step 164170, total loss = 0.55, batch loss = 0.30 (121.1 examples/sec; 0.066 sec/batch; 0h:38m:54s remains)
INFO - root - 2022-02-24 21:06:54.704347: step 164180, total loss = 0.55, batch loss = 0.29 (370.5 examples/sec; 0.022 sec/batch; 0h:12m:42s remains)
INFO - root - 2022-02-24 21:06:55.171959: step 164190, total loss = 0.63, batch loss = 0.37 (156.0 examples/sec; 0.051 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 21:06:55.555802: step 164200, total loss = 0.51, batch loss = 0.26 (162.2 examples/sec; 0.049 sec/batch; 0h:29m:00s remains)
INFO - root - 2022-02-24 21:06:55.938538: step 164210, total loss = 0.49, batch loss = 0.23 (319.6 examples/sec; 0.025 sec/batch; 0h:14m:43s remains)
INFO - root - 2022-02-24 21:06:56.206873: step 164220, total loss = 0.64, batch loss = 0.39 (240.6 examples/sec; 0.033 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 21:06:56.704281: step 164230, total loss = 0.52, batch loss = 0.26 (93.5 examples/sec; 0.086 sec/batch; 0h:50m:16s remains)
INFO - root - 2022-02-24 21:06:57.152203: step 164240, total loss = 0.53, batch loss = 0.27 (128.9 examples/sec; 0.062 sec/batch; 0h:36m:27s remains)
INFO - root - 2022-02-24 21:06:57.520603: step 164250, total loss = 0.54, batch loss = 0.29 (342.5 examples/sec; 0.023 sec/batch; 0h:13m:43s remains)
INFO - root - 2022-02-24 21:06:57.899071: step 164260, total loss = 0.47, batch loss = 0.21 (129.7 examples/sec; 0.062 sec/batch; 0h:36m:13s remains)
INFO - root - 2022-02-24 21:06:58.326219: step 164270, total loss = 0.58, batch loss = 0.33 (365.9 examples/sec; 0.022 sec/batch; 0h:12m:50s remains)
INFO - root - 2022-02-24 21:06:58.817194: step 164280, total loss = 0.59, batch loss = 0.33 (132.5 examples/sec; 0.060 sec/batch; 0h:35m:26s remains)
INFO - root - 2022-02-24 21:06:59.388124: step 164290, total loss = 0.55, batch loss = 0.29 (175.7 examples/sec; 0.046 sec/batch; 0h:26m:43s remains)
INFO - root - 2022-02-24 21:06:59.786267: step 164300, total loss = 0.47, batch loss = 0.21 (299.9 examples/sec; 0.027 sec/batch; 0h:15m:38s remains)
INFO - root - 2022-02-24 21:07:00.249167: step 164310, total loss = 0.53, batch loss = 0.28 (124.5 examples/sec; 0.064 sec/batch; 0h:37m:41s remains)
INFO - root - 2022-02-24 21:07:00.664600: step 164320, total loss = 0.61, batch loss = 0.35 (231.4 examples/sec; 0.035 sec/batch; 0h:20m:16s remains)
INFO - root - 2022-02-24 21:07:01.095055: step 164330, total loss = 0.58, batch loss = 0.32 (287.8 examples/sec; 0.028 sec/batch; 0h:16m:17s remains)
INFO - root - 2022-02-24 21:07:01.654720: step 164340, total loss = 0.60, batch loss = 0.35 (151.6 examples/sec; 0.053 sec/batch; 0h:30m:54s remains)
INFO - root - 2022-02-24 21:07:02.189731: step 164350, total loss = 0.63, batch loss = 0.37 (102.4 examples/sec; 0.078 sec/batch; 0h:45m:46s remains)
INFO - root - 2022-02-24 21:07:02.699794: step 164360, total loss = 0.58, batch loss = 0.33 (331.8 examples/sec; 0.024 sec/batch; 0h:14m:07s remains)
INFO - root - 2022-02-24 21:07:03.085518: step 164370, total loss = 0.59, batch loss = 0.33 (207.6 examples/sec; 0.039 sec/batch; 0h:22m:33s remains)
INFO - root - 2022-02-24 21:07:03.433430: step 164380, total loss = 0.58, batch loss = 0.33 (309.3 examples/sec; 0.026 sec/batch; 0h:15m:08s remains)
INFO - root - 2022-02-24 21:07:03.921809: step 164390, total loss = 0.53, batch loss = 0.28 (264.0 examples/sec; 0.030 sec/batch; 0h:17m:43s remains)
INFO - root - 2022-02-24 21:07:04.951727: step 164400, total loss = 0.62, batch loss = 0.36 (314.7 examples/sec; 0.025 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:07:05.332555: step 164410, total loss = 0.48, batch loss = 0.23 (199.7 examples/sec; 0.040 sec/batch; 0h:23m:25s remains)
INFO - root - 2022-02-24 21:07:05.691795: step 164420, total loss = 0.53, batch loss = 0.27 (212.1 examples/sec; 0.038 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:07:06.024099: step 164430, total loss = 0.78, batch loss = 0.53 (257.4 examples/sec; 0.031 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 21:07:06.480615: step 164440, total loss = 0.52, batch loss = 0.27 (286.2 examples/sec; 0.028 sec/batch; 0h:16m:19s remains)
INFO - root - 2022-02-24 21:07:06.857253: step 164450, total loss = 0.48, batch loss = 0.23 (352.0 examples/sec; 0.023 sec/batch; 0h:13m:16s remains)
INFO - root - 2022-02-24 21:07:07.124727: step 164460, total loss = 0.47, batch loss = 0.21 (327.4 examples/sec; 0.024 sec/batch; 0h:14m:16s remains)
INFO - root - 2022-02-24 21:07:07.520352: step 164470, total loss = 0.61, batch loss = 0.35 (191.2 examples/sec; 0.042 sec/batch; 0h:24m:25s remains)
INFO - root - 2022-02-24 21:07:07.895248: step 164480, total loss = 0.52, batch loss = 0.26 (241.3 examples/sec; 0.033 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 21:07:08.315043: step 164490, total loss = 0.61, batch loss = 0.36 (214.7 examples/sec; 0.037 sec/batch; 0h:21m:44s remains)
INFO - root - 2022-02-24 21:07:08.758748: step 164500, total loss = 0.64, batch loss = 0.38 (184.9 examples/sec; 0.043 sec/batch; 0h:25m:13s remains)
INFO - root - 2022-02-24 21:07:09.277965: step 164510, total loss = 0.51, batch loss = 0.26 (181.6 examples/sec; 0.044 sec/batch; 0h:25m:41s remains)
INFO - root - 2022-02-24 21:07:09.722664: step 164520, total loss = 0.53, batch loss = 0.28 (197.5 examples/sec; 0.041 sec/batch; 0h:23m:36s remains)
INFO - root - 2022-02-24 21:07:10.025091: step 164530, total loss = 0.50, batch loss = 0.24 (323.1 examples/sec; 0.025 sec/batch; 0h:14m:25s remains)
INFO - root - 2022-02-24 21:07:10.407691: step 164540, total loss = 0.59, batch loss = 0.34 (237.1 examples/sec; 0.034 sec/batch; 0h:19m:39s remains)
INFO - root - 2022-02-24 21:07:10.812012: step 164550, total loss = 0.52, batch loss = 0.26 (361.7 examples/sec; 0.022 sec/batch; 0h:12m:52s remains)
INFO - root - 2022-02-24 21:07:11.205025: step 164560, total loss = 0.55, batch loss = 0.30 (182.9 examples/sec; 0.044 sec/batch; 0h:25m:28s remains)
INFO - root - 2022-02-24 21:07:11.540381: step 164570, total loss = 0.56, batch loss = 0.30 (295.2 examples/sec; 0.027 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:07:11.862094: step 164580, total loss = 0.52, batch loss = 0.27 (296.2 examples/sec; 0.027 sec/batch; 0h:15m:43s remains)
INFO - root - 2022-02-24 21:07:12.165092: step 164590, total loss = 0.48, batch loss = 0.22 (316.7 examples/sec; 0.025 sec/batch; 0h:14m:41s remains)
INFO - root - 2022-02-24 21:07:12.490227: step 164600, total loss = 0.49, batch loss = 0.24 (166.4 examples/sec; 0.048 sec/batch; 0h:27m:58s remains)
INFO - root - 2022-02-24 21:07:12.912442: step 164610, total loss = 0.47, batch loss = 0.21 (279.6 examples/sec; 0.029 sec/batch; 0h:16m:38s remains)
INFO - root - 2022-02-24 21:07:13.392571: step 164620, total loss = 0.54, batch loss = 0.28 (350.3 examples/sec; 0.023 sec/batch; 0h:13m:16s remains)
INFO - root - 2022-02-24 21:07:13.702134: step 164630, total loss = 0.49, batch loss = 0.23 (338.9 examples/sec; 0.024 sec/batch; 0h:13m:43s remains)
INFO - root - 2022-02-24 21:07:14.041856: step 164640, total loss = 0.58, batch loss = 0.32 (216.1 examples/sec; 0.037 sec/batch; 0h:21m:30s remains)
INFO - root - 2022-02-24 21:07:14.388965: step 164650, total loss = 0.55, batch loss = 0.29 (257.1 examples/sec; 0.031 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:07:14.852318: step 164660, total loss = 0.49, batch loss = 0.23 (234.2 examples/sec; 0.034 sec/batch; 0h:19m:49s remains)
INFO - root - 2022-02-24 21:07:15.306929: step 164670, total loss = 0.49, batch loss = 0.24 (305.2 examples/sec; 0.026 sec/batch; 0h:15m:13s remains)
INFO - root - 2022-02-24 21:07:15.614458: step 164680, total loss = 0.59, batch loss = 0.34 (339.4 examples/sec; 0.024 sec/batch; 0h:13m:40s remains)
INFO - root - 2022-02-24 21:07:15.974199: step 164690, total loss = 0.48, batch loss = 0.22 (337.0 examples/sec; 0.024 sec/batch; 0h:13m:46s remains)
INFO - root - 2022-02-24 21:07:16.310753: step 164700, total loss = 0.56, batch loss = 0.30 (261.0 examples/sec; 0.031 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:07:16.792163: step 164710, total loss = 0.52, batch loss = 0.27 (128.5 examples/sec; 0.062 sec/batch; 0h:36m:05s remains)
INFO - root - 2022-02-24 21:07:17.339600: step 164720, total loss = 0.53, batch loss = 0.27 (260.9 examples/sec; 0.031 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:07:17.728044: step 164730, total loss = 0.49, batch loss = 0.23 (355.8 examples/sec; 0.022 sec/batch; 0h:13m:01s remains)
INFO - root - 2022-02-24 21:07:18.058530: step 164740, total loss = 0.51, batch loss = 0.25 (135.9 examples/sec; 0.059 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 21:07:18.405654: step 164750, total loss = 0.49, batch loss = 0.23 (235.3 examples/sec; 0.034 sec/batch; 0h:19m:41s remains)
INFO - root - 2022-02-24 21:07:18.834191: step 164760, total loss = 0.59, batch loss = 0.33 (135.7 examples/sec; 0.059 sec/batch; 0h:34m:08s remains)
INFO - root - 2022-02-24 21:07:19.261864: step 164770, total loss = 0.51, batch loss = 0.25 (248.0 examples/sec; 0.032 sec/batch; 0h:18m:40s remains)
INFO - root - 2022-02-24 21:07:19.639954: step 164780, total loss = 0.46, batch loss = 0.20 (370.7 examples/sec; 0.022 sec/batch; 0h:12m:29s remains)
INFO - root - 2022-02-24 21:07:20.006521: step 164790, total loss = 0.54, batch loss = 0.29 (292.4 examples/sec; 0.027 sec/batch; 0h:15m:49s remains)
INFO - root - 2022-02-24 21:07:20.319208: step 164800, total loss = 0.59, batch loss = 0.33 (159.1 examples/sec; 0.050 sec/batch; 0h:29m:04s remains)
INFO - root - 2022-02-24 21:07:20.816135: step 164810, total loss = 0.53, batch loss = 0.28 (113.1 examples/sec; 0.071 sec/batch; 0h:40m:53s remains)
INFO - root - 2022-02-24 21:07:21.298302: step 164820, total loss = 0.67, batch loss = 0.41 (75.7 examples/sec; 0.106 sec/batch; 1h:01m:04s remains)
INFO - root - 2022-02-24 21:07:21.660752: step 164830, total loss = 0.70, batch loss = 0.44 (138.8 examples/sec; 0.058 sec/batch; 0h:33m:18s remains)
INFO - root - 2022-02-24 21:07:21.974209: step 164840, total loss = 0.50, batch loss = 0.24 (236.3 examples/sec; 0.034 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 21:07:22.315779: step 164850, total loss = 0.49, batch loss = 0.24 (306.8 examples/sec; 0.026 sec/batch; 0h:15m:03s remains)
INFO - root - 2022-02-24 21:07:22.634172: step 164860, total loss = 0.54, batch loss = 0.28 (337.3 examples/sec; 0.024 sec/batch; 0h:13m:41s remains)
INFO - root - 2022-02-24 21:07:23.019385: step 164870, total loss = 0.51, batch loss = 0.25 (248.3 examples/sec; 0.032 sec/batch; 0h:18m:35s remains)
INFO - root - 2022-02-24 21:07:23.508477: step 164880, total loss = 0.58, batch loss = 0.32 (186.2 examples/sec; 0.043 sec/batch; 0h:24m:47s remains)
INFO - root - 2022-02-24 21:07:23.811879: step 164890, total loss = 0.68, batch loss = 0.42 (232.2 examples/sec; 0.034 sec/batch; 0h:19m:52s remains)
INFO - root - 2022-02-24 21:07:24.174741: step 164900, total loss = 0.49, batch loss = 0.23 (206.5 examples/sec; 0.039 sec/batch; 0h:22m:20s remains)
INFO - root - 2022-02-24 21:07:24.619611: step 164910, total loss = 0.41, batch loss = 0.15 (283.6 examples/sec; 0.028 sec/batch; 0h:16m:15s remains)
INFO - root - 2022-02-24 21:07:25.079461: step 164920, total loss = 0.52, batch loss = 0.26 (156.2 examples/sec; 0.051 sec/batch; 0h:29m:30s remains)
INFO - root - 2022-02-24 21:07:25.507397: step 164930, total loss = 0.51, batch loss = 0.26 (190.2 examples/sec; 0.042 sec/batch; 0h:24m:13s remains)
INFO - root - 2022-02-24 21:07:25.871355: step 164940, total loss = 0.61, batch loss = 0.35 (304.5 examples/sec; 0.026 sec/batch; 0h:15m:08s remains)
INFO - root - 2022-02-24 21:07:26.230420: step 164950, total loss = 0.54, batch loss = 0.29 (279.9 examples/sec; 0.029 sec/batch; 0h:16m:27s remains)
INFO - root - 2022-02-24 21:07:26.610283: step 164960, total loss = 0.52, batch loss = 0.27 (184.4 examples/sec; 0.043 sec/batch; 0h:24m:58s remains)
INFO - root - 2022-02-24 21:07:27.015470: step 164970, total loss = 0.62, batch loss = 0.36 (209.1 examples/sec; 0.038 sec/batch; 0h:22m:01s remains)
INFO - root - 2022-02-24 21:07:27.451960: step 164980, total loss = 0.49, batch loss = 0.23 (149.9 examples/sec; 0.053 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:07:27.941704: step 164990, total loss = 0.55, batch loss = 0.30 (239.6 examples/sec; 0.033 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 21:07:28.344885: step 165000, total loss = 0.57, batch loss = 0.31 (137.5 examples/sec; 0.058 sec/batch; 0h:33m:27s remains)
INFO - root - 2022-02-24 21:07:28.914044: step 165010, total loss = 0.46, batch loss = 0.21 (270.0 examples/sec; 0.030 sec/batch; 0h:17m:01s remains)
INFO - root - 2022-02-24 21:07:29.495324: step 165020, total loss = 0.53, batch loss = 0.27 (266.8 examples/sec; 0.030 sec/batch; 0h:17m:13s remains)
INFO - root - 2022-02-24 21:07:30.202155: step 165030, total loss = 0.51, batch loss = 0.26 (112.2 examples/sec; 0.071 sec/batch; 0h:40m:58s remains)
INFO - root - 2022-02-24 21:07:31.001118: step 165040, total loss = 0.57, batch loss = 0.32 (206.0 examples/sec; 0.039 sec/batch; 0h:22m:18s remains)
INFO - root - 2022-02-24 21:07:31.414915: step 165050, total loss = 0.50, batch loss = 0.24 (237.4 examples/sec; 0.034 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 21:07:31.878154: step 165060, total loss = 0.55, batch loss = 0.29 (166.8 examples/sec; 0.048 sec/batch; 0h:27m:31s remains)
INFO - root - 2022-02-24 21:07:32.260903: step 165070, total loss = 0.49, batch loss = 0.23 (308.4 examples/sec; 0.026 sec/batch; 0h:14m:53s remains)
INFO - root - 2022-02-24 21:07:32.690194: step 165080, total loss = 0.49, batch loss = 0.23 (290.9 examples/sec; 0.027 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:07:33.012205: step 165090, total loss = 0.42, batch loss = 0.16 (254.0 examples/sec; 0.032 sec/batch; 0h:18m:03s remains)
INFO - root - 2022-02-24 21:07:33.381986: step 165100, total loss = 0.52, batch loss = 0.26 (298.9 examples/sec; 0.027 sec/batch; 0h:15m:20s remains)
INFO - root - 2022-02-24 21:07:33.894995: step 165110, total loss = 0.49, batch loss = 0.24 (191.7 examples/sec; 0.042 sec/batch; 0h:23m:55s remains)
INFO - root - 2022-02-24 21:07:34.269317: step 165120, total loss = 0.64, batch loss = 0.38 (268.6 examples/sec; 0.030 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:07:34.703067: step 165130, total loss = 0.49, batch loss = 0.23 (256.3 examples/sec; 0.031 sec/batch; 0h:17m:52s remains)
INFO - root - 2022-02-24 21:07:35.007324: step 165140, total loss = 0.65, batch loss = 0.39 (381.7 examples/sec; 0.021 sec/batch; 0h:12m:00s remains)
INFO - root - 2022-02-24 21:07:35.443258: step 165150, total loss = 0.68, batch loss = 0.42 (152.8 examples/sec; 0.052 sec/batch; 0h:29m:58s remains)
INFO - root - 2022-02-24 21:07:35.904025: step 165160, total loss = 0.55, batch loss = 0.29 (103.2 examples/sec; 0.078 sec/batch; 0h:44m:22s remains)
INFO - root - 2022-02-24 21:07:36.301691: step 165170, total loss = 0.50, batch loss = 0.24 (156.3 examples/sec; 0.051 sec/batch; 0h:29m:17s remains)
INFO - root - 2022-02-24 21:07:36.726734: step 165180, total loss = 0.48, batch loss = 0.23 (178.6 examples/sec; 0.045 sec/batch; 0h:25m:37s remains)
INFO - root - 2022-02-24 21:07:37.044900: step 165190, total loss = 0.50, batch loss = 0.25 (364.8 examples/sec; 0.022 sec/batch; 0h:12m:32s remains)
INFO - root - 2022-02-24 21:07:37.351456: step 165200, total loss = 0.50, batch loss = 0.24 (315.2 examples/sec; 0.025 sec/batch; 0h:14m:30s remains)
INFO - root - 2022-02-24 21:07:37.931780: step 165210, total loss = 0.65, batch loss = 0.39 (185.2 examples/sec; 0.043 sec/batch; 0h:24m:40s remains)
INFO - root - 2022-02-24 21:07:38.391220: step 165220, total loss = 0.48, batch loss = 0.22 (127.4 examples/sec; 0.063 sec/batch; 0h:35m:52s remains)
INFO - root - 2022-02-24 21:07:38.783849: step 165230, total loss = 0.45, batch loss = 0.20 (211.5 examples/sec; 0.038 sec/batch; 0h:21m:36s remains)
INFO - root - 2022-02-24 21:07:39.073786: step 165240, total loss = 0.63, batch loss = 0.37 (187.9 examples/sec; 0.043 sec/batch; 0h:24m:18s remains)
INFO - root - 2022-02-24 21:07:39.475113: step 165250, total loss = 0.61, batch loss = 0.36 (197.9 examples/sec; 0.040 sec/batch; 0h:23m:04s remains)
INFO - root - 2022-02-24 21:07:39.948795: step 165260, total loss = 0.52, batch loss = 0.26 (124.4 examples/sec; 0.064 sec/batch; 0h:36m:41s remains)
INFO - root - 2022-02-24 21:07:40.476819: step 165270, total loss = 0.55, batch loss = 0.29 (100.8 examples/sec; 0.079 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 21:07:40.798691: step 165280, total loss = 0.52, batch loss = 0.26 (346.6 examples/sec; 0.023 sec/batch; 0h:13m:09s remains)
INFO - root - 2022-02-24 21:07:41.118276: step 165290, total loss = 0.69, batch loss = 0.43 (325.7 examples/sec; 0.025 sec/batch; 0h:14m:00s remains)
INFO - root - 2022-02-24 21:07:41.494653: step 165300, total loss = 0.50, batch loss = 0.24 (304.7 examples/sec; 0.026 sec/batch; 0h:14m:57s remains)
INFO - root - 2022-02-24 21:07:41.972337: step 165310, total loss = 0.55, batch loss = 0.30 (149.6 examples/sec; 0.053 sec/batch; 0h:30m:28s remains)
INFO - root - 2022-02-24 21:07:42.390232: step 165320, total loss = 0.51, batch loss = 0.25 (317.0 examples/sec; 0.025 sec/batch; 0h:14m:22s remains)
INFO - root - 2022-02-24 21:07:42.688838: step 165330, total loss = 0.59, batch loss = 0.33 (250.6 examples/sec; 0.032 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 21:07:43.006179: step 165340, total loss = 0.53, batch loss = 0.27 (289.5 examples/sec; 0.028 sec/batch; 0h:15m:44s remains)
INFO - root - 2022-02-24 21:07:43.275428: step 165350, total loss = 0.58, batch loss = 0.33 (353.9 examples/sec; 0.023 sec/batch; 0h:12m:52s remains)
INFO - root - 2022-02-24 21:07:43.629391: step 165360, total loss = 0.47, batch loss = 0.21 (309.4 examples/sec; 0.026 sec/batch; 0h:14m:42s remains)
INFO - root - 2022-02-24 21:07:44.052003: step 165370, total loss = 0.46, batch loss = 0.21 (232.9 examples/sec; 0.034 sec/batch; 0h:19m:32s remains)
INFO - root - 2022-02-24 21:07:44.477306: step 165380, total loss = 0.55, batch loss = 0.30 (163.8 examples/sec; 0.049 sec/batch; 0h:27m:46s remains)
INFO - root - 2022-02-24 21:07:44.835795: step 165390, total loss = 0.68, batch loss = 0.43 (347.1 examples/sec; 0.023 sec/batch; 0h:13m:06s remains)
INFO - root - 2022-02-24 21:07:45.184283: step 165400, total loss = 0.54, batch loss = 0.29 (295.2 examples/sec; 0.027 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:07:45.562870: step 165410, total loss = 0.73, batch loss = 0.47 (203.0 examples/sec; 0.039 sec/batch; 0h:22m:23s remains)
INFO - root - 2022-02-24 21:07:46.039281: step 165420, total loss = 0.56, batch loss = 0.31 (105.7 examples/sec; 0.076 sec/batch; 0h:42m:58s remains)
INFO - root - 2022-02-24 21:07:46.469466: step 165430, total loss = 0.52, batch loss = 0.27 (196.2 examples/sec; 0.041 sec/batch; 0h:23m:09s remains)
INFO - root - 2022-02-24 21:07:46.788923: step 165440, total loss = 0.49, batch loss = 0.23 (330.3 examples/sec; 0.024 sec/batch; 0h:13m:44s remains)
INFO - root - 2022-02-24 21:07:47.111093: step 165450, total loss = 0.48, batch loss = 0.22 (291.3 examples/sec; 0.027 sec/batch; 0h:15m:34s remains)
INFO - root - 2022-02-24 21:07:47.421948: step 165460, total loss = 0.52, batch loss = 0.26 (222.2 examples/sec; 0.036 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 21:07:47.902397: step 165470, total loss = 0.50, batch loss = 0.24 (134.5 examples/sec; 0.059 sec/batch; 0h:33m:43s remains)
INFO - root - 2022-02-24 21:07:48.283096: step 165480, total loss = 0.54, batch loss = 0.28 (243.1 examples/sec; 0.033 sec/batch; 0h:18m:39s remains)
INFO - root - 2022-02-24 21:07:48.706958: step 165490, total loss = 0.45, batch loss = 0.20 (211.0 examples/sec; 0.038 sec/batch; 0h:21m:29s remains)
INFO - root - 2022-02-24 21:07:49.080760: step 165500, total loss = 0.48, batch loss = 0.23 (157.9 examples/sec; 0.051 sec/batch; 0h:28m:42s remains)
INFO - root - 2022-02-24 21:07:49.446030: step 165510, total loss = 0.49, batch loss = 0.23 (369.7 examples/sec; 0.022 sec/batch; 0h:12m:15s remains)
INFO - root - 2022-02-24 21:07:49.799532: step 165520, total loss = 0.53, batch loss = 0.27 (203.4 examples/sec; 0.039 sec/batch; 0h:22m:16s remains)
INFO - root - 2022-02-24 21:07:50.126994: step 165530, total loss = 0.51, batch loss = 0.25 (339.7 examples/sec; 0.024 sec/batch; 0h:13m:19s remains)
INFO - root - 2022-02-24 21:07:50.443595: step 165540, total loss = 0.56, batch loss = 0.30 (160.3 examples/sec; 0.050 sec/batch; 0h:28m:14s remains)
INFO - root - 2022-02-24 21:07:50.796215: step 165550, total loss = 0.56, batch loss = 0.30 (213.3 examples/sec; 0.037 sec/batch; 0h:21m:13s remains)
INFO - root - 2022-02-24 21:07:51.096857: step 165560, total loss = 0.54, batch loss = 0.29 (339.2 examples/sec; 0.024 sec/batch; 0h:13m:20s remains)
INFO - root - 2022-02-24 21:07:51.792743: step 165570, total loss = 0.75, batch loss = 0.49 (151.5 examples/sec; 0.053 sec/batch; 0h:29m:51s remains)
INFO - root - 2022-02-24 21:07:52.370405: step 165580, total loss = 0.51, batch loss = 0.26 (121.3 examples/sec; 0.066 sec/batch; 0h:37m:16s remains)
INFO - root - 2022-02-24 21:07:52.883221: step 165590, total loss = 0.57, batch loss = 0.31 (343.6 examples/sec; 0.023 sec/batch; 0h:13m:09s remains)
INFO - root - 2022-02-24 21:07:53.547267: step 165600, total loss = 0.53, batch loss = 0.27 (58.4 examples/sec; 0.137 sec/batch; 1h:17m:21s remains)
INFO - root - 2022-02-24 21:07:54.195261: step 165610, total loss = 0.56, batch loss = 0.31 (107.9 examples/sec; 0.074 sec/batch; 0h:41m:52s remains)
INFO - root - 2022-02-24 21:07:54.763493: step 165620, total loss = 0.53, batch loss = 0.27 (94.5 examples/sec; 0.085 sec/batch; 0h:47m:47s remains)
INFO - root - 2022-02-24 21:07:55.468848: step 165630, total loss = 0.54, batch loss = 0.29 (86.3 examples/sec; 0.093 sec/batch; 0h:52m:18s remains)
INFO - root - 2022-02-24 21:07:55.975914: step 165640, total loss = 0.55, batch loss = 0.29 (201.1 examples/sec; 0.040 sec/batch; 0h:22m:27s remains)
INFO - root - 2022-02-24 21:07:56.443749: step 165650, total loss = 0.51, batch loss = 0.25 (220.7 examples/sec; 0.036 sec/batch; 0h:20m:27s remains)
INFO - root - 2022-02-24 21:07:56.985536: step 165660, total loss = 0.50, batch loss = 0.24 (192.4 examples/sec; 0.042 sec/batch; 0h:23m:26s remains)
INFO - root - 2022-02-24 21:07:57.566086: step 165670, total loss = 0.48, batch loss = 0.23 (358.0 examples/sec; 0.022 sec/batch; 0h:12m:35s remains)
INFO - root - 2022-02-24 21:07:57.882691: step 165680, total loss = 0.73, batch loss = 0.47 (360.8 examples/sec; 0.022 sec/batch; 0h:12m:29s remains)
INFO - root - 2022-02-24 21:07:58.492348: step 165690, total loss = 0.60, batch loss = 0.35 (305.6 examples/sec; 0.026 sec/batch; 0h:14m:45s remains)
INFO - root - 2022-02-24 21:07:59.067248: step 165700, total loss = 0.52, batch loss = 0.26 (211.1 examples/sec; 0.038 sec/batch; 0h:21m:20s remains)
INFO - root - 2022-02-24 21:07:59.757437: step 165710, total loss = 0.54, batch loss = 0.29 (250.9 examples/sec; 0.032 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:08:00.548007: step 165720, total loss = 0.57, batch loss = 0.31 (127.0 examples/sec; 0.063 sec/batch; 0h:35m:27s remains)
INFO - root - 2022-02-24 21:08:01.157449: step 165730, total loss = 0.66, batch loss = 0.40 (162.0 examples/sec; 0.049 sec/batch; 0h:27m:47s remains)
INFO - root - 2022-02-24 21:08:01.667835: step 165740, total loss = 0.55, batch loss = 0.29 (73.9 examples/sec; 0.108 sec/batch; 1h:00m:56s remains)
INFO - root - 2022-02-24 21:08:02.175208: step 165750, total loss = 0.54, batch loss = 0.28 (137.9 examples/sec; 0.058 sec/batch; 0h:32m:38s remains)
INFO - root - 2022-02-24 21:08:02.571960: step 165760, total loss = 0.57, batch loss = 0.31 (334.0 examples/sec; 0.024 sec/batch; 0h:13m:28s remains)
INFO - root - 2022-02-24 21:08:03.144768: step 165770, total loss = 0.56, batch loss = 0.30 (279.5 examples/sec; 0.029 sec/batch; 0h:16m:05s remains)
INFO - root - 2022-02-24 21:08:03.534110: step 165780, total loss = 0.50, batch loss = 0.24 (169.0 examples/sec; 0.047 sec/batch; 0h:26m:36s remains)
INFO - root - 2022-02-24 21:08:03.852843: step 165790, total loss = 0.53, batch loss = 0.27 (201.1 examples/sec; 0.040 sec/batch; 0h:22m:20s remains)
INFO - root - 2022-02-24 21:08:04.174799: step 165800, total loss = 0.49, batch loss = 0.24 (298.9 examples/sec; 0.027 sec/batch; 0h:15m:01s remains)
INFO - root - 2022-02-24 21:08:04.707953: step 165810, total loss = 0.49, batch loss = 0.23 (99.2 examples/sec; 0.081 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 21:08:05.177988: step 165820, total loss = 0.54, batch loss = 0.29 (150.0 examples/sec; 0.053 sec/batch; 0h:29m:55s remains)
INFO - root - 2022-02-24 21:08:05.473055: step 165830, total loss = 0.57, batch loss = 0.32 (168.1 examples/sec; 0.048 sec/batch; 0h:26m:42s remains)
INFO - root - 2022-02-24 21:08:05.800071: step 165840, total loss = 0.59, batch loss = 0.33 (234.6 examples/sec; 0.034 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 21:08:06.193142: step 165850, total loss = 0.57, batch loss = 0.32 (178.8 examples/sec; 0.045 sec/batch; 0h:25m:05s remains)
INFO - root - 2022-02-24 21:08:06.604876: step 165860, total loss = 0.54, batch loss = 0.28 (353.3 examples/sec; 0.023 sec/batch; 0h:12m:41s remains)
INFO - root - 2022-02-24 21:08:07.148638: step 165870, total loss = 0.65, batch loss = 0.39 (77.1 examples/sec; 0.104 sec/batch; 0h:58m:09s remains)
INFO - root - 2022-02-24 21:08:07.684087: step 165880, total loss = 0.51, batch loss = 0.25 (99.4 examples/sec; 0.081 sec/batch; 0h:45m:06s remains)
INFO - root - 2022-02-24 21:08:08.125037: step 165890, total loss = 0.56, batch loss = 0.30 (307.6 examples/sec; 0.026 sec/batch; 0h:14m:34s remains)
INFO - root - 2022-02-24 21:08:08.706395: step 165900, total loss = 0.52, batch loss = 0.27 (73.2 examples/sec; 0.109 sec/batch; 1h:01m:11s remains)
INFO - root - 2022-02-24 21:08:09.149158: step 165910, total loss = 0.61, batch loss = 0.35 (127.5 examples/sec; 0.063 sec/batch; 0h:35m:07s remains)
INFO - root - 2022-02-24 21:08:09.765883: step 165920, total loss = 0.51, batch loss = 0.25 (138.3 examples/sec; 0.058 sec/batch; 0h:32m:22s remains)
INFO - root - 2022-02-24 21:08:10.174228: step 165930, total loss = 0.57, batch loss = 0.32 (225.8 examples/sec; 0.035 sec/batch; 0h:19m:49s remains)
INFO - root - 2022-02-24 21:08:10.523401: step 165940, total loss = 0.54, batch loss = 0.28 (288.0 examples/sec; 0.028 sec/batch; 0h:15m:32s remains)
INFO - root - 2022-02-24 21:08:11.791388: step 165950, total loss = 0.57, batch loss = 0.32 (14.3 examples/sec; 0.558 sec/batch; 5h:11m:54s remains)
INFO - root - 2022-02-24 21:08:12.269132: step 165960, total loss = 0.54, batch loss = 0.28 (155.1 examples/sec; 0.052 sec/batch; 0h:28m:50s remains)
INFO - root - 2022-02-24 21:08:12.654731: step 165970, total loss = 0.54, batch loss = 0.28 (321.1 examples/sec; 0.025 sec/batch; 0h:13m:55s remains)
INFO - root - 2022-02-24 21:08:12.983022: step 165980, total loss = 0.45, batch loss = 0.19 (346.2 examples/sec; 0.023 sec/batch; 0h:12m:54s remains)
INFO - root - 2022-02-24 21:08:13.298425: step 165990, total loss = 0.51, batch loss = 0.26 (228.8 examples/sec; 0.035 sec/batch; 0h:19m:31s remains)
INFO - root - 2022-02-24 21:08:13.607544: step 166000, total loss = 0.67, batch loss = 0.41 (143.8 examples/sec; 0.056 sec/batch; 0h:31m:03s remains)
INFO - root - 2022-02-24 21:08:14.053707: step 166010, total loss = 0.47, batch loss = 0.22 (166.6 examples/sec; 0.048 sec/batch; 0h:26m:48s remains)
INFO - root - 2022-02-24 21:08:14.439193: step 166020, total loss = 0.48, batch loss = 0.22 (288.9 examples/sec; 0.028 sec/batch; 0h:15m:27s remains)
INFO - root - 2022-02-24 21:08:14.766119: step 166030, total loss = 0.49, batch loss = 0.23 (225.5 examples/sec; 0.035 sec/batch; 0h:19m:47s remains)
INFO - root - 2022-02-24 21:08:15.097095: step 166040, total loss = 0.52, batch loss = 0.26 (299.6 examples/sec; 0.027 sec/batch; 0h:14m:53s remains)
INFO - root - 2022-02-24 21:08:15.427300: step 166050, total loss = 0.55, batch loss = 0.29 (167.7 examples/sec; 0.048 sec/batch; 0h:26m:36s remains)
INFO - root - 2022-02-24 21:08:15.816477: step 166060, total loss = 0.51, batch loss = 0.26 (172.1 examples/sec; 0.046 sec/batch; 0h:25m:54s remains)
INFO - root - 2022-02-24 21:08:16.286734: step 166070, total loss = 0.49, batch loss = 0.23 (142.0 examples/sec; 0.056 sec/batch; 0h:31m:23s remains)
INFO - root - 2022-02-24 21:08:16.677972: step 166080, total loss = 0.52, batch loss = 0.26 (269.2 examples/sec; 0.030 sec/batch; 0h:16m:33s remains)
INFO - root - 2022-02-24 21:08:16.982596: step 166090, total loss = 0.62, batch loss = 0.37 (229.4 examples/sec; 0.035 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 21:08:17.309108: step 166100, total loss = 0.57, batch loss = 0.31 (301.2 examples/sec; 0.027 sec/batch; 0h:14m:47s remains)
INFO - root - 2022-02-24 21:08:17.737275: step 166110, total loss = 0.66, batch loss = 0.40 (110.3 examples/sec; 0.073 sec/batch; 0h:40m:21s remains)
INFO - root - 2022-02-24 21:08:18.160853: step 166120, total loss = 0.63, batch loss = 0.38 (246.5 examples/sec; 0.032 sec/batch; 0h:18m:03s remains)
INFO - root - 2022-02-24 21:08:18.572476: step 166130, total loss = 0.44, batch loss = 0.18 (186.1 examples/sec; 0.043 sec/batch; 0h:23m:54s remains)
INFO - root - 2022-02-24 21:08:18.908193: step 166140, total loss = 0.45, batch loss = 0.19 (282.5 examples/sec; 0.028 sec/batch; 0h:15m:44s remains)
INFO - root - 2022-02-24 21:08:19.275257: step 166150, total loss = 0.64, batch loss = 0.38 (171.4 examples/sec; 0.047 sec/batch; 0h:25m:56s remains)
INFO - root - 2022-02-24 21:08:19.639261: step 166160, total loss = 0.65, batch loss = 0.39 (234.6 examples/sec; 0.034 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 21:08:20.067534: step 166170, total loss = 0.53, batch loss = 0.27 (314.1 examples/sec; 0.025 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:08:20.383056: step 166180, total loss = 0.60, batch loss = 0.35 (212.9 examples/sec; 0.038 sec/batch; 0h:20m:51s remains)
INFO - root - 2022-02-24 21:08:20.817800: step 166190, total loss = 0.54, batch loss = 0.29 (189.4 examples/sec; 0.042 sec/batch; 0h:23m:27s remains)
INFO - root - 2022-02-24 21:08:21.175216: step 166200, total loss = 0.48, batch loss = 0.22 (207.3 examples/sec; 0.039 sec/batch; 0h:21m:25s remains)
INFO - root - 2022-02-24 21:08:21.716652: step 166210, total loss = 0.48, batch loss = 0.23 (243.7 examples/sec; 0.033 sec/batch; 0h:18m:12s remains)
INFO - root - 2022-02-24 21:08:22.128238: step 166220, total loss = 0.58, batch loss = 0.32 (274.6 examples/sec; 0.029 sec/batch; 0h:16m:09s remains)
INFO - root - 2022-02-24 21:08:22.568548: step 166230, total loss = 0.59, batch loss = 0.33 (361.5 examples/sec; 0.022 sec/batch; 0h:12m:16s remains)
INFO - root - 2022-02-24 21:08:23.005226: step 166240, total loss = 0.69, batch loss = 0.44 (271.8 examples/sec; 0.029 sec/batch; 0h:16m:19s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-166249 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-166249 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:08:23.674674: step 166250, total loss = 0.51, batch loss = 0.25 (309.6 examples/sec; 0.026 sec/batch; 0h:14m:19s remains)
INFO - root - 2022-02-24 21:08:23.912446: step 166260, total loss = 0.51, batch loss = 0.25 (328.2 examples/sec; 0.024 sec/batch; 0h:13m:30s remains)
INFO - root - 2022-02-24 21:08:24.171683: step 166270, total loss = 0.51, batch loss = 0.26 (171.3 examples/sec; 0.047 sec/batch; 0h:25m:52s remains)
INFO - root - 2022-02-24 21:08:24.593110: step 166280, total loss = 0.57, batch loss = 0.32 (219.6 examples/sec; 0.036 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:08:24.980669: step 166290, total loss = 0.60, batch loss = 0.35 (232.7 examples/sec; 0.034 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:08:25.357123: step 166300, total loss = 0.49, batch loss = 0.24 (333.9 examples/sec; 0.024 sec/batch; 0h:13m:15s remains)
INFO - root - 2022-02-24 21:08:25.831688: step 166310, total loss = 0.55, batch loss = 0.29 (239.5 examples/sec; 0.033 sec/batch; 0h:18m:28s remains)
INFO - root - 2022-02-24 21:08:26.183970: step 166320, total loss = 0.48, batch loss = 0.22 (335.0 examples/sec; 0.024 sec/batch; 0h:13m:12s remains)
INFO - root - 2022-02-24 21:08:26.654413: step 166330, total loss = 0.52, batch loss = 0.26 (203.8 examples/sec; 0.039 sec/batch; 0h:21m:41s remains)
INFO - root - 2022-02-24 21:08:27.046757: step 166340, total loss = 0.62, batch loss = 0.36 (332.2 examples/sec; 0.024 sec/batch; 0h:13m:18s remains)
INFO - root - 2022-02-24 21:08:27.374592: step 166350, total loss = 0.54, batch loss = 0.28 (353.8 examples/sec; 0.023 sec/batch; 0h:12m:29s remains)
INFO - root - 2022-02-24 21:08:27.648536: step 166360, total loss = 0.53, batch loss = 0.28 (329.5 examples/sec; 0.024 sec/batch; 0h:13m:24s remains)
INFO - root - 2022-02-24 21:08:27.985046: step 166370, total loss = 0.55, batch loss = 0.29 (258.5 examples/sec; 0.031 sec/batch; 0h:17m:05s remains)
INFO - root - 2022-02-24 21:08:28.309594: step 166380, total loss = 0.52, batch loss = 0.26 (353.0 examples/sec; 0.023 sec/batch; 0h:12m:30s remains)
INFO - root - 2022-02-24 21:08:28.710551: step 166390, total loss = 0.58, batch loss = 0.33 (113.0 examples/sec; 0.071 sec/batch; 0h:39m:04s remains)
INFO - root - 2022-02-24 21:08:29.084798: step 166400, total loss = 0.49, batch loss = 0.24 (275.3 examples/sec; 0.029 sec/batch; 0h:16m:01s remains)
INFO - root - 2022-02-24 21:08:29.647592: step 166410, total loss = 0.49, batch loss = 0.23 (207.1 examples/sec; 0.039 sec/batch; 0h:21m:18s remains)
INFO - root - 2022-02-24 21:08:30.023098: step 166420, total loss = 0.53, batch loss = 0.28 (143.6 examples/sec; 0.056 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:08:30.318644: step 166430, total loss = 0.52, batch loss = 0.27 (322.0 examples/sec; 0.025 sec/batch; 0h:13m:41s remains)
INFO - root - 2022-02-24 21:08:30.654688: step 166440, total loss = 0.50, batch loss = 0.24 (120.0 examples/sec; 0.067 sec/batch; 0h:36m:44s remains)
INFO - root - 2022-02-24 21:08:30.974311: step 166450, total loss = 0.52, batch loss = 0.26 (263.6 examples/sec; 0.030 sec/batch; 0h:16m:43s remains)
INFO - root - 2022-02-24 21:08:31.453651: step 166460, total loss = 0.51, batch loss = 0.26 (167.9 examples/sec; 0.048 sec/batch; 0h:26m:14s remains)
INFO - root - 2022-02-24 21:08:31.823863: step 166470, total loss = 0.50, batch loss = 0.25 (369.0 examples/sec; 0.022 sec/batch; 0h:11m:56s remains)
INFO - root - 2022-02-24 21:08:32.175924: step 166480, total loss = 0.55, batch loss = 0.30 (247.7 examples/sec; 0.032 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:08:32.492158: step 166490, total loss = 0.59, batch loss = 0.33 (261.6 examples/sec; 0.031 sec/batch; 0h:16m:49s remains)
INFO - root - 2022-02-24 21:08:32.795459: step 166500, total loss = 0.63, batch loss = 0.37 (284.5 examples/sec; 0.028 sec/batch; 0h:15m:28s remains)
INFO - root - 2022-02-24 21:08:33.312270: step 166510, total loss = 0.59, batch loss = 0.33 (237.8 examples/sec; 0.034 sec/batch; 0h:18m:29s remains)
INFO - root - 2022-02-24 21:08:33.809509: step 166520, total loss = 0.54, batch loss = 0.28 (155.9 examples/sec; 0.051 sec/batch; 0h:28m:11s remains)
INFO - root - 2022-02-24 21:08:34.197384: step 166530, total loss = 0.52, batch loss = 0.26 (325.8 examples/sec; 0.025 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:08:34.543816: step 166540, total loss = 0.54, batch loss = 0.28 (313.4 examples/sec; 0.026 sec/batch; 0h:14m:01s remains)
INFO - root - 2022-02-24 21:08:34.873990: step 166550, total loss = 0.47, batch loss = 0.22 (335.1 examples/sec; 0.024 sec/batch; 0h:13m:06s remains)
INFO - root - 2022-02-24 21:08:35.352281: step 166560, total loss = 0.49, batch loss = 0.24 (195.3 examples/sec; 0.041 sec/batch; 0h:22m:29s remains)
INFO - root - 2022-02-24 21:08:35.748220: step 166570, total loss = 0.51, batch loss = 0.26 (213.1 examples/sec; 0.038 sec/batch; 0h:20m:36s remains)
INFO - root - 2022-02-24 21:08:36.070090: step 166580, total loss = 0.55, batch loss = 0.29 (221.1 examples/sec; 0.036 sec/batch; 0h:19m:50s remains)
INFO - root - 2022-02-24 21:08:36.396942: step 166590, total loss = 0.56, batch loss = 0.31 (156.2 examples/sec; 0.051 sec/batch; 0h:28m:05s remains)
INFO - root - 2022-02-24 21:08:36.762407: step 166600, total loss = 0.59, batch loss = 0.33 (332.4 examples/sec; 0.024 sec/batch; 0h:13m:11s remains)
INFO - root - 2022-02-24 21:08:37.316152: step 166610, total loss = 0.53, batch loss = 0.27 (242.3 examples/sec; 0.033 sec/batch; 0h:18m:06s remains)
INFO - root - 2022-02-24 21:08:37.733205: step 166620, total loss = 0.45, batch loss = 0.19 (247.1 examples/sec; 0.032 sec/batch; 0h:17m:44s remains)
INFO - root - 2022-02-24 21:08:38.049245: step 166630, total loss = 0.60, batch loss = 0.34 (331.0 examples/sec; 0.024 sec/batch; 0h:13m:14s remains)
INFO - root - 2022-02-24 21:08:38.505787: step 166640, total loss = 0.51, batch loss = 0.25 (125.0 examples/sec; 0.064 sec/batch; 0h:35m:03s remains)
INFO - root - 2022-02-24 21:08:38.839356: step 166650, total loss = 0.57, batch loss = 0.31 (182.5 examples/sec; 0.044 sec/batch; 0h:24m:00s remains)
INFO - root - 2022-02-24 21:08:39.315104: step 166660, total loss = 0.50, batch loss = 0.24 (278.5 examples/sec; 0.029 sec/batch; 0h:15m:43s remains)
INFO - root - 2022-02-24 21:08:39.755068: step 166670, total loss = 0.61, batch loss = 0.35 (142.6 examples/sec; 0.056 sec/batch; 0h:30m:42s remains)
INFO - root - 2022-02-24 21:08:40.128285: step 166680, total loss = 0.49, batch loss = 0.24 (179.3 examples/sec; 0.045 sec/batch; 0h:24m:24s remains)
INFO - root - 2022-02-24 21:08:40.503208: step 166690, total loss = 0.65, batch loss = 0.40 (274.2 examples/sec; 0.029 sec/batch; 0h:15m:57s remains)
INFO - root - 2022-02-24 21:08:40.846098: step 166700, total loss = 0.50, batch loss = 0.25 (322.6 examples/sec; 0.025 sec/batch; 0h:13m:33s remains)
INFO - root - 2022-02-24 21:08:41.339460: step 166710, total loss = 0.54, batch loss = 0.28 (274.1 examples/sec; 0.029 sec/batch; 0h:15m:57s remains)
INFO - root - 2022-02-24 21:08:41.829321: step 166720, total loss = 0.54, batch loss = 0.29 (109.5 examples/sec; 0.073 sec/batch; 0h:39m:54s remains)
INFO - root - 2022-02-24 21:08:42.185197: step 166730, total loss = 0.52, batch loss = 0.26 (289.4 examples/sec; 0.028 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:08:42.530775: step 166740, total loss = 0.51, batch loss = 0.25 (212.8 examples/sec; 0.038 sec/batch; 0h:20m:31s remains)
INFO - root - 2022-02-24 21:08:42.863348: step 166750, total loss = 0.60, batch loss = 0.35 (337.9 examples/sec; 0.024 sec/batch; 0h:12m:55s remains)
INFO - root - 2022-02-24 21:08:43.185998: step 166760, total loss = 0.67, batch loss = 0.41 (261.1 examples/sec; 0.031 sec/batch; 0h:16m:42s remains)
INFO - root - 2022-02-24 21:08:43.598585: step 166770, total loss = 0.55, batch loss = 0.30 (118.5 examples/sec; 0.067 sec/batch; 0h:36m:49s remains)
INFO - root - 2022-02-24 21:08:44.088604: step 166780, total loss = 0.50, batch loss = 0.24 (91.1 examples/sec; 0.088 sec/batch; 0h:47m:52s remains)
INFO - root - 2022-02-24 21:08:44.633631: step 166790, total loss = 0.54, batch loss = 0.29 (109.8 examples/sec; 0.073 sec/batch; 0h:39m:42s remains)
INFO - root - 2022-02-24 21:08:45.073400: step 166800, total loss = 0.55, batch loss = 0.29 (186.2 examples/sec; 0.043 sec/batch; 0h:23m:25s remains)
INFO - root - 2022-02-24 21:08:45.694444: step 166810, total loss = 0.55, batch loss = 0.29 (155.7 examples/sec; 0.051 sec/batch; 0h:27m:59s remains)
INFO - root - 2022-02-24 21:08:46.246257: step 166820, total loss = 0.45, batch loss = 0.19 (345.3 examples/sec; 0.023 sec/batch; 0h:12m:37s remains)
INFO - root - 2022-02-24 21:08:47.395760: step 166830, total loss = 0.56, batch loss = 0.31 (177.0 examples/sec; 0.045 sec/batch; 0h:24m:36s remains)
INFO - root - 2022-02-24 21:08:47.857770: step 166840, total loss = 0.52, batch loss = 0.26 (155.1 examples/sec; 0.052 sec/batch; 0h:28m:04s remains)
INFO - root - 2022-02-24 21:08:48.242942: step 166850, total loss = 0.52, batch loss = 0.26 (309.6 examples/sec; 0.026 sec/batch; 0h:14m:03s remains)
INFO - root - 2022-02-24 21:08:48.567433: step 166860, total loss = 0.46, batch loss = 0.21 (310.5 examples/sec; 0.026 sec/batch; 0h:14m:00s remains)
INFO - root - 2022-02-24 21:08:48.870320: step 166870, total loss = 0.63, batch loss = 0.37 (224.6 examples/sec; 0.036 sec/batch; 0h:19m:22s remains)
INFO - root - 2022-02-24 21:08:49.133217: step 166880, total loss = 0.52, batch loss = 0.27 (334.7 examples/sec; 0.024 sec/batch; 0h:12m:59s remains)
INFO - root - 2022-02-24 21:08:49.525292: step 166890, total loss = 0.60, batch loss = 0.34 (115.5 examples/sec; 0.069 sec/batch; 0h:37m:39s remains)
INFO - root - 2022-02-24 21:08:50.013363: step 166900, total loss = 0.39, batch loss = 0.13 (188.4 examples/sec; 0.042 sec/batch; 0h:23m:04s remains)
INFO - root - 2022-02-24 21:08:50.474312: step 166910, total loss = 0.56, batch loss = 0.30 (212.7 examples/sec; 0.038 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 21:08:50.812781: step 166920, total loss = 0.46, batch loss = 0.21 (184.6 examples/sec; 0.043 sec/batch; 0h:23m:31s remains)
INFO - root - 2022-02-24 21:08:51.165322: step 166930, total loss = 0.55, batch loss = 0.29 (188.9 examples/sec; 0.042 sec/batch; 0h:22m:59s remains)
INFO - root - 2022-02-24 21:08:51.590643: step 166940, total loss = 0.50, batch loss = 0.25 (321.6 examples/sec; 0.025 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:08:52.081881: step 166950, total loss = 0.48, batch loss = 0.22 (135.6 examples/sec; 0.059 sec/batch; 0h:32m:00s remains)
INFO - root - 2022-02-24 21:08:52.454268: step 166960, total loss = 0.60, batch loss = 0.34 (178.5 examples/sec; 0.045 sec/batch; 0h:24m:18s remains)
INFO - root - 2022-02-24 21:08:52.767872: step 166970, total loss = 0.52, batch loss = 0.26 (220.3 examples/sec; 0.036 sec/batch; 0h:19m:41s remains)
INFO - root - 2022-02-24 21:08:53.173776: step 166980, total loss = 0.65, batch loss = 0.40 (133.7 examples/sec; 0.060 sec/batch; 0h:32m:25s remains)
INFO - root - 2022-02-24 21:08:53.537750: step 166990, total loss = 0.50, batch loss = 0.24 (212.6 examples/sec; 0.038 sec/batch; 0h:20m:23s remains)
INFO - root - 2022-02-24 21:08:53.886425: step 167000, total loss = 0.63, batch loss = 0.38 (310.9 examples/sec; 0.026 sec/batch; 0h:13m:56s remains)
INFO - root - 2022-02-24 21:08:54.341554: step 167010, total loss = 0.50, batch loss = 0.25 (158.5 examples/sec; 0.050 sec/batch; 0h:27m:20s remains)
INFO - root - 2022-02-24 21:08:54.611522: step 167020, total loss = 0.59, batch loss = 0.33 (289.0 examples/sec; 0.028 sec/batch; 0h:14m:59s remains)
INFO - root - 2022-02-24 21:08:54.950874: step 167030, total loss = 0.62, batch loss = 0.37 (318.4 examples/sec; 0.025 sec/batch; 0h:13m:35s remains)
INFO - root - 2022-02-24 21:08:55.275201: step 167040, total loss = 0.50, batch loss = 0.24 (320.2 examples/sec; 0.025 sec/batch; 0h:13m:30s remains)
INFO - root - 2022-02-24 21:08:55.562628: step 167050, total loss = 0.55, batch loss = 0.30 (269.0 examples/sec; 0.030 sec/batch; 0h:16m:05s remains)
INFO - root - 2022-02-24 21:08:55.964817: step 167060, total loss = 0.57, batch loss = 0.32 (286.7 examples/sec; 0.028 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:08:56.360858: step 167070, total loss = 0.55, batch loss = 0.29 (132.1 examples/sec; 0.061 sec/batch; 0h:32m:43s remains)
INFO - root - 2022-02-24 21:08:56.723603: step 167080, total loss = 0.43, batch loss = 0.17 (320.5 examples/sec; 0.025 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:08:57.117153: step 167090, total loss = 0.50, batch loss = 0.24 (92.2 examples/sec; 0.087 sec/batch; 0h:46m:51s remains)
INFO - root - 2022-02-24 21:08:57.727037: step 167100, total loss = 0.51, batch loss = 0.25 (203.4 examples/sec; 0.039 sec/batch; 0h:21m:14s remains)
INFO - root - 2022-02-24 21:08:58.192089: step 167110, total loss = 0.60, batch loss = 0.34 (291.9 examples/sec; 0.027 sec/batch; 0h:14m:47s remains)
INFO - root - 2022-02-24 21:08:58.611523: step 167120, total loss = 0.49, batch loss = 0.23 (144.1 examples/sec; 0.056 sec/batch; 0h:29m:57s remains)
INFO - root - 2022-02-24 21:08:58.886574: step 167130, total loss = 0.54, batch loss = 0.29 (343.4 examples/sec; 0.023 sec/batch; 0h:12m:34s remains)
INFO - root - 2022-02-24 21:08:59.249992: step 167140, total loss = 0.54, batch loss = 0.29 (372.2 examples/sec; 0.021 sec/batch; 0h:11m:35s remains)
INFO - root - 2022-02-24 21:08:59.534590: step 167150, total loss = 0.55, batch loss = 0.30 (264.2 examples/sec; 0.030 sec/batch; 0h:16m:19s remains)
INFO - root - 2022-02-24 21:08:59.928184: step 167160, total loss = 0.50, batch loss = 0.24 (106.1 examples/sec; 0.075 sec/batch; 0h:40m:39s remains)
INFO - root - 2022-02-24 21:09:00.340250: step 167170, total loss = 0.54, batch loss = 0.29 (200.7 examples/sec; 0.040 sec/batch; 0h:21m:28s remains)
INFO - root - 2022-02-24 21:09:00.772185: step 167180, total loss = 0.50, batch loss = 0.24 (257.2 examples/sec; 0.031 sec/batch; 0h:16m:45s remains)
INFO - root - 2022-02-24 21:09:01.090806: step 167190, total loss = 0.71, batch loss = 0.46 (283.9 examples/sec; 0.028 sec/batch; 0h:15m:10s remains)
INFO - root - 2022-02-24 21:09:01.360891: step 167200, total loss = 0.60, batch loss = 0.35 (244.6 examples/sec; 0.033 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:09:01.821598: step 167210, total loss = 0.58, batch loss = 0.33 (310.1 examples/sec; 0.026 sec/batch; 0h:13m:53s remains)
INFO - root - 2022-02-24 21:09:02.226510: step 167220, total loss = 0.48, batch loss = 0.22 (228.0 examples/sec; 0.035 sec/batch; 0h:18m:52s remains)
INFO - root - 2022-02-24 21:09:02.674317: step 167230, total loss = 0.55, batch loss = 0.30 (363.7 examples/sec; 0.022 sec/batch; 0h:11m:49s remains)
INFO - root - 2022-02-24 21:09:02.942003: step 167240, total loss = 0.50, batch loss = 0.24 (215.0 examples/sec; 0.037 sec/batch; 0h:20m:00s remains)
INFO - root - 2022-02-24 21:09:03.296961: step 167250, total loss = 0.56, batch loss = 0.30 (308.0 examples/sec; 0.026 sec/batch; 0h:13m:57s remains)
INFO - root - 2022-02-24 21:09:03.634550: step 167260, total loss = 0.56, batch loss = 0.30 (213.1 examples/sec; 0.038 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:09:04.125391: step 167270, total loss = 0.49, batch loss = 0.23 (163.2 examples/sec; 0.049 sec/batch; 0h:26m:19s remains)
INFO - root - 2022-02-24 21:09:04.469656: step 167280, total loss = 0.56, batch loss = 0.31 (191.4 examples/sec; 0.042 sec/batch; 0h:22m:26s remains)
INFO - root - 2022-02-24 21:09:04.782607: step 167290, total loss = 0.54, batch loss = 0.28 (325.2 examples/sec; 0.025 sec/batch; 0h:13m:12s remains)
INFO - root - 2022-02-24 21:09:05.091732: step 167300, total loss = 0.58, batch loss = 0.32 (305.7 examples/sec; 0.026 sec/batch; 0h:14m:02s remains)
INFO - root - 2022-02-24 21:09:05.510847: step 167310, total loss = 0.51, batch loss = 0.25 (337.1 examples/sec; 0.024 sec/batch; 0h:12m:43s remains)
INFO - root - 2022-02-24 21:09:05.759504: step 167320, total loss = 0.48, batch loss = 0.22 (330.9 examples/sec; 0.024 sec/batch; 0h:12m:57s remains)
INFO - root - 2022-02-24 21:09:06.204448: step 167330, total loss = 0.53, batch loss = 0.27 (174.2 examples/sec; 0.046 sec/batch; 0h:24m:37s remains)
INFO - root - 2022-02-24 21:09:06.569570: step 167340, total loss = 0.56, batch loss = 0.31 (121.8 examples/sec; 0.066 sec/batch; 0h:35m:12s remains)
INFO - root - 2022-02-24 21:09:06.936765: step 167350, total loss = 0.49, batch loss = 0.24 (309.0 examples/sec; 0.026 sec/batch; 0h:13m:52s remains)
INFO - root - 2022-02-24 21:09:07.277760: step 167360, total loss = 0.52, batch loss = 0.26 (340.4 examples/sec; 0.024 sec/batch; 0h:12m:35s remains)
INFO - root - 2022-02-24 21:09:07.574203: step 167370, total loss = 0.48, batch loss = 0.23 (121.6 examples/sec; 0.066 sec/batch; 0h:35m:13s remains)
INFO - root - 2022-02-24 21:09:07.906048: step 167380, total loss = 0.51, batch loss = 0.25 (236.9 examples/sec; 0.034 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:09:08.304437: step 167390, total loss = 0.65, batch loss = 0.39 (283.8 examples/sec; 0.028 sec/batch; 0h:15m:05s remains)
INFO - root - 2022-02-24 21:09:08.752540: step 167400, total loss = 0.53, batch loss = 0.27 (213.2 examples/sec; 0.038 sec/batch; 0h:20m:04s remains)
INFO - root - 2022-02-24 21:09:09.238401: step 167410, total loss = 0.52, batch loss = 0.27 (116.7 examples/sec; 0.069 sec/batch; 0h:36m:40s remains)
INFO - root - 2022-02-24 21:09:09.539802: step 167420, total loss = 0.57, batch loss = 0.31 (296.7 examples/sec; 0.027 sec/batch; 0h:14m:24s remains)
INFO - root - 2022-02-24 21:09:09.869703: step 167430, total loss = 0.59, batch loss = 0.33 (352.9 examples/sec; 0.023 sec/batch; 0h:12m:06s remains)
INFO - root - 2022-02-24 21:09:10.189583: step 167440, total loss = 0.56, batch loss = 0.30 (246.8 examples/sec; 0.032 sec/batch; 0h:17m:19s remains)
INFO - root - 2022-02-24 21:09:10.544672: step 167450, total loss = 0.53, batch loss = 0.27 (124.2 examples/sec; 0.064 sec/batch; 0h:34m:23s remains)
INFO - root - 2022-02-24 21:09:10.983993: step 167460, total loss = 0.59, batch loss = 0.34 (179.1 examples/sec; 0.045 sec/batch; 0h:23m:50s remains)
INFO - root - 2022-02-24 21:09:11.435189: step 167470, total loss = 0.54, batch loss = 0.28 (150.1 examples/sec; 0.053 sec/batch; 0h:28m:27s remains)
INFO - root - 2022-02-24 21:09:11.770696: step 167480, total loss = 0.59, batch loss = 0.33 (235.6 examples/sec; 0.034 sec/batch; 0h:18m:07s remains)
INFO - root - 2022-02-24 21:09:12.152877: step 167490, total loss = 0.56, batch loss = 0.31 (277.1 examples/sec; 0.029 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:09:12.583596: step 167500, total loss = 0.51, batch loss = 0.25 (177.3 examples/sec; 0.045 sec/batch; 0h:24m:03s remains)
INFO - root - 2022-02-24 21:09:13.076418: step 167510, total loss = 0.53, batch loss = 0.27 (291.2 examples/sec; 0.027 sec/batch; 0h:14m:38s remains)
INFO - root - 2022-02-24 21:09:13.480840: step 167520, total loss = 0.48, batch loss = 0.22 (290.3 examples/sec; 0.028 sec/batch; 0h:14m:41s remains)
INFO - root - 2022-02-24 21:09:13.920689: step 167530, total loss = 0.57, batch loss = 0.31 (270.4 examples/sec; 0.030 sec/batch; 0h:15m:45s remains)
INFO - root - 2022-02-24 21:09:14.198545: step 167540, total loss = 0.57, batch loss = 0.31 (262.0 examples/sec; 0.031 sec/batch; 0h:16m:16s remains)
INFO - root - 2022-02-24 21:09:14.576138: step 167550, total loss = 0.55, batch loss = 0.29 (193.4 examples/sec; 0.041 sec/batch; 0h:22m:01s remains)
INFO - root - 2022-02-24 21:09:15.003354: step 167560, total loss = 0.66, batch loss = 0.40 (189.2 examples/sec; 0.042 sec/batch; 0h:22m:30s remains)
INFO - root - 2022-02-24 21:09:15.490951: step 167570, total loss = 0.49, batch loss = 0.24 (345.5 examples/sec; 0.023 sec/batch; 0h:12m:19s remains)
INFO - root - 2022-02-24 21:09:15.882811: step 167580, total loss = 0.66, batch loss = 0.41 (175.7 examples/sec; 0.046 sec/batch; 0h:24m:13s remains)
INFO - root - 2022-02-24 21:09:16.216311: step 167590, total loss = 0.53, batch loss = 0.28 (257.5 examples/sec; 0.031 sec/batch; 0h:16m:31s remains)
INFO - root - 2022-02-24 21:09:16.514407: step 167600, total loss = 0.67, batch loss = 0.41 (338.8 examples/sec; 0.024 sec/batch; 0h:12m:33s remains)
INFO - root - 2022-02-24 21:09:16.908209: step 167610, total loss = 0.73, batch loss = 0.48 (313.1 examples/sec; 0.026 sec/batch; 0h:13m:34s remains)
INFO - root - 2022-02-24 21:09:17.389323: step 167620, total loss = 0.67, batch loss = 0.41 (104.6 examples/sec; 0.077 sec/batch; 0h:40m:39s remains)
INFO - root - 2022-02-24 21:09:17.812177: step 167630, total loss = 0.62, batch loss = 0.37 (228.9 examples/sec; 0.035 sec/batch; 0h:18m:34s remains)
INFO - root - 2022-02-24 21:09:18.181858: step 167640, total loss = 0.54, batch loss = 0.28 (137.8 examples/sec; 0.058 sec/batch; 0h:30m:49s remains)
INFO - root - 2022-02-24 21:09:18.671075: step 167650, total loss = 0.52, batch loss = 0.27 (90.4 examples/sec; 0.088 sec/batch; 0h:46m:58s remains)
INFO - root - 2022-02-24 21:09:19.344573: step 167660, total loss = 0.56, batch loss = 0.30 (168.5 examples/sec; 0.047 sec/batch; 0h:25m:11s remains)
INFO - root - 2022-02-24 21:09:19.867760: step 167670, total loss = 0.52, batch loss = 0.26 (110.0 examples/sec; 0.073 sec/batch; 0h:38m:34s remains)
INFO - root - 2022-02-24 21:09:20.498958: step 167680, total loss = 0.67, batch loss = 0.41 (194.4 examples/sec; 0.041 sec/batch; 0h:21m:49s remains)
INFO - root - 2022-02-24 21:09:20.918446: step 167690, total loss = 0.46, batch loss = 0.20 (215.1 examples/sec; 0.037 sec/batch; 0h:19m:43s remains)
INFO - root - 2022-02-24 21:09:21.323155: step 167700, total loss = 0.50, batch loss = 0.24 (110.0 examples/sec; 0.073 sec/batch; 0h:38m:33s remains)
INFO - root - 2022-02-24 21:09:21.891060: step 167710, total loss = 0.56, batch loss = 0.31 (89.0 examples/sec; 0.090 sec/batch; 0h:47m:38s remains)
INFO - root - 2022-02-24 21:09:22.279151: step 167720, total loss = 0.57, batch loss = 0.32 (236.5 examples/sec; 0.034 sec/batch; 0h:17m:55s remains)
INFO - root - 2022-02-24 21:09:23.108261: step 167730, total loss = 0.50, batch loss = 0.24 (267.5 examples/sec; 0.030 sec/batch; 0h:15m:50s remains)
INFO - root - 2022-02-24 21:09:23.519393: step 167740, total loss = 0.49, batch loss = 0.23 (179.3 examples/sec; 0.045 sec/batch; 0h:23m:37s remains)
INFO - root - 2022-02-24 21:09:23.950731: step 167750, total loss = 0.68, batch loss = 0.42 (188.0 examples/sec; 0.043 sec/batch; 0h:22m:31s remains)
INFO - root - 2022-02-24 21:09:24.348461: step 167760, total loss = 0.49, batch loss = 0.24 (132.6 examples/sec; 0.060 sec/batch; 0h:31m:54s remains)
INFO - root - 2022-02-24 21:09:24.741952: step 167770, total loss = 0.59, batch loss = 0.33 (298.6 examples/sec; 0.027 sec/batch; 0h:14m:10s remains)
INFO - root - 2022-02-24 21:09:25.004575: step 167780, total loss = 0.61, batch loss = 0.35 (313.4 examples/sec; 0.026 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:09:25.372993: step 167790, total loss = 0.50, batch loss = 0.24 (83.8 examples/sec; 0.096 sec/batch; 0h:50m:28s remains)
INFO - root - 2022-02-24 21:09:25.728901: step 167800, total loss = 0.55, batch loss = 0.29 (306.8 examples/sec; 0.026 sec/batch; 0h:13m:46s remains)
INFO - root - 2022-02-24 21:09:26.214128: step 167810, total loss = 0.51, batch loss = 0.26 (208.4 examples/sec; 0.038 sec/batch; 0h:20m:16s remains)
INFO - root - 2022-02-24 21:09:26.584045: step 167820, total loss = 0.55, batch loss = 0.29 (270.8 examples/sec; 0.030 sec/batch; 0h:15m:35s remains)
INFO - root - 2022-02-24 21:09:26.940552: step 167830, total loss = 0.59, batch loss = 0.34 (223.3 examples/sec; 0.036 sec/batch; 0h:18m:54s remains)
INFO - root - 2022-02-24 21:09:27.301974: step 167840, total loss = 0.59, batch loss = 0.33 (268.9 examples/sec; 0.030 sec/batch; 0h:15m:42s remains)
INFO - root - 2022-02-24 21:09:27.645527: step 167850, total loss = 0.51, batch loss = 0.26 (238.5 examples/sec; 0.034 sec/batch; 0h:17m:41s remains)
INFO - root - 2022-02-24 21:09:28.116623: step 167860, total loss = 0.54, batch loss = 0.29 (131.9 examples/sec; 0.061 sec/batch; 0h:31m:58s remains)
INFO - root - 2022-02-24 21:09:28.489512: step 167870, total loss = 0.49, batch loss = 0.23 (342.9 examples/sec; 0.023 sec/batch; 0h:12m:17s remains)
INFO - root - 2022-02-24 21:09:28.801315: step 167880, total loss = 0.52, batch loss = 0.26 (303.8 examples/sec; 0.026 sec/batch; 0h:13m:52s remains)
INFO - root - 2022-02-24 21:09:29.102060: step 167890, total loss = 0.59, batch loss = 0.33 (368.6 examples/sec; 0.022 sec/batch; 0h:11m:26s remains)
INFO - root - 2022-02-24 21:09:29.476416: step 167900, total loss = 0.54, batch loss = 0.28 (174.3 examples/sec; 0.046 sec/batch; 0h:24m:10s remains)
INFO - root - 2022-02-24 21:09:30.023975: step 167910, total loss = 0.59, batch loss = 0.33 (142.2 examples/sec; 0.056 sec/batch; 0h:29m:37s remains)
INFO - root - 2022-02-24 21:09:30.460749: step 167920, total loss = 0.57, batch loss = 0.32 (147.8 examples/sec; 0.054 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 21:09:30.777530: step 167930, total loss = 0.51, batch loss = 0.25 (219.8 examples/sec; 0.036 sec/batch; 0h:19m:09s remains)
INFO - root - 2022-02-24 21:09:31.122540: step 167940, total loss = 0.53, batch loss = 0.27 (195.2 examples/sec; 0.041 sec/batch; 0h:21m:33s remains)
INFO - root - 2022-02-24 21:09:31.439688: step 167950, total loss = 0.52, batch loss = 0.26 (183.4 examples/sec; 0.044 sec/batch; 0h:22m:56s remains)
INFO - root - 2022-02-24 21:09:31.831592: step 167960, total loss = 0.49, batch loss = 0.24 (247.0 examples/sec; 0.032 sec/batch; 0h:17m:01s remains)
INFO - root - 2022-02-24 21:09:32.232961: step 167970, total loss = 0.51, batch loss = 0.25 (207.0 examples/sec; 0.039 sec/batch; 0h:20m:18s remains)
INFO - root - 2022-02-24 21:09:32.633119: step 167980, total loss = 0.46, batch loss = 0.20 (365.5 examples/sec; 0.022 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:09:32.982937: step 167990, total loss = 0.49, batch loss = 0.23 (260.6 examples/sec; 0.031 sec/batch; 0h:16m:07s remains)
INFO - root - 2022-02-24 21:09:33.315070: step 168000, total loss = 0.50, batch loss = 0.24 (252.2 examples/sec; 0.032 sec/batch; 0h:16m:39s remains)
INFO - root - 2022-02-24 21:09:33.821915: step 168010, total loss = 0.63, batch loss = 0.38 (303.6 examples/sec; 0.026 sec/batch; 0h:13m:49s remains)
INFO - root - 2022-02-24 21:09:34.276106: step 168020, total loss = 0.50, batch loss = 0.25 (108.6 examples/sec; 0.074 sec/batch; 0h:38m:38s remains)
INFO - root - 2022-02-24 21:09:34.568957: step 168030, total loss = 0.48, batch loss = 0.22 (255.0 examples/sec; 0.031 sec/batch; 0h:16m:27s remains)
INFO - root - 2022-02-24 21:09:34.930613: step 168040, total loss = 0.64, batch loss = 0.38 (194.3 examples/sec; 0.041 sec/batch; 0h:21m:35s remains)
INFO - root - 2022-02-24 21:09:35.219335: step 168050, total loss = 0.57, batch loss = 0.32 (312.5 examples/sec; 0.026 sec/batch; 0h:13m:25s remains)
INFO - root - 2022-02-24 21:09:35.541343: step 168060, total loss = 0.48, batch loss = 0.22 (131.6 examples/sec; 0.061 sec/batch; 0h:31m:50s remains)
INFO - root - 2022-02-24 21:09:35.995125: step 168070, total loss = 0.67, batch loss = 0.41 (141.5 examples/sec; 0.057 sec/batch; 0h:29m:36s remains)
INFO - root - 2022-02-24 21:09:36.389159: step 168080, total loss = 0.48, batch loss = 0.22 (211.7 examples/sec; 0.038 sec/batch; 0h:19m:47s remains)
INFO - root - 2022-02-24 21:09:36.781371: step 168090, total loss = 0.61, batch loss = 0.35 (271.8 examples/sec; 0.029 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:09:37.061987: step 168100, total loss = 0.58, batch loss = 0.32 (261.0 examples/sec; 0.031 sec/batch; 0h:16m:02s remains)
INFO - root - 2022-02-24 21:09:37.557641: step 168110, total loss = 0.52, batch loss = 0.27 (285.2 examples/sec; 0.028 sec/batch; 0h:14m:40s remains)
INFO - root - 2022-02-24 21:09:37.959992: step 168120, total loss = 0.52, batch loss = 0.26 (165.0 examples/sec; 0.048 sec/batch; 0h:25m:21s remains)
INFO - root - 2022-02-24 21:09:38.490585: step 168130, total loss = 0.51, batch loss = 0.26 (124.3 examples/sec; 0.064 sec/batch; 0h:33m:39s remains)
INFO - root - 2022-02-24 21:09:38.855914: step 168140, total loss = 0.48, batch loss = 0.22 (339.5 examples/sec; 0.024 sec/batch; 0h:12m:19s remains)
INFO - root - 2022-02-24 21:09:39.225563: step 168150, total loss = 0.52, batch loss = 0.27 (345.0 examples/sec; 0.023 sec/batch; 0h:12m:06s remains)
INFO - root - 2022-02-24 21:09:39.519252: step 168160, total loss = 0.58, batch loss = 0.32 (324.1 examples/sec; 0.025 sec/batch; 0h:12m:53s remains)
INFO - root - 2022-02-24 21:09:39.946849: step 168170, total loss = 0.55, batch loss = 0.29 (228.5 examples/sec; 0.035 sec/batch; 0h:18m:16s remains)
INFO - root - 2022-02-24 21:09:40.410229: step 168180, total loss = 0.59, batch loss = 0.33 (231.1 examples/sec; 0.035 sec/batch; 0h:18m:04s remains)
INFO - root - 2022-02-24 21:09:40.729685: step 168190, total loss = 0.59, batch loss = 0.34 (202.8 examples/sec; 0.039 sec/batch; 0h:20m:34s remains)
INFO - root - 2022-02-24 21:09:41.108954: step 168200, total loss = 0.52, batch loss = 0.26 (188.0 examples/sec; 0.043 sec/batch; 0h:22m:11s remains)
INFO - root - 2022-02-24 21:09:41.489541: step 168210, total loss = 0.52, batch loss = 0.26 (358.5 examples/sec; 0.022 sec/batch; 0h:11m:38s remains)
INFO - root - 2022-02-24 21:09:41.922723: step 168220, total loss = 0.55, batch loss = 0.30 (324.5 examples/sec; 0.025 sec/batch; 0h:12m:51s remains)
INFO - root - 2022-02-24 21:09:42.429264: step 168230, total loss = 0.56, batch loss = 0.30 (323.8 examples/sec; 0.025 sec/batch; 0h:12m:52s remains)
INFO - root - 2022-02-24 21:09:42.765405: step 168240, total loss = 0.50, batch loss = 0.24 (334.1 examples/sec; 0.024 sec/batch; 0h:12m:28s remains)
INFO - root - 2022-02-24 21:09:43.114270: step 168250, total loss = 0.56, batch loss = 0.31 (347.6 examples/sec; 0.023 sec/batch; 0h:11m:59s remains)
INFO - root - 2022-02-24 21:09:43.426801: step 168260, total loss = 0.63, batch loss = 0.37 (362.2 examples/sec; 0.022 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:09:43.822499: step 168270, total loss = 0.53, batch loss = 0.27 (389.7 examples/sec; 0.021 sec/batch; 0h:10m:41s remains)
INFO - root - 2022-02-24 21:09:44.265710: step 168280, total loss = 0.59, batch loss = 0.34 (203.2 examples/sec; 0.039 sec/batch; 0h:20m:29s remains)
INFO - root - 2022-02-24 21:09:44.616017: step 168290, total loss = 0.55, batch loss = 0.29 (357.0 examples/sec; 0.022 sec/batch; 0h:11m:39s remains)
INFO - root - 2022-02-24 21:09:45.000984: step 168300, total loss = 0.52, batch loss = 0.26 (282.4 examples/sec; 0.028 sec/batch; 0h:14m:43s remains)
INFO - root - 2022-02-24 21:09:45.449302: step 168310, total loss = 0.58, batch loss = 0.32 (376.0 examples/sec; 0.021 sec/batch; 0h:11m:03s remains)
INFO - root - 2022-02-24 21:09:45.927220: step 168320, total loss = 0.59, batch loss = 0.33 (164.2 examples/sec; 0.049 sec/batch; 0h:25m:19s remains)
INFO - root - 2022-02-24 21:09:46.435145: step 168330, total loss = 0.49, batch loss = 0.24 (141.5 examples/sec; 0.057 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 21:09:46.713171: step 168340, total loss = 0.48, batch loss = 0.22 (307.2 examples/sec; 0.026 sec/batch; 0h:13m:31s remains)
INFO - root - 2022-02-24 21:09:47.061109: step 168350, total loss = 0.49, batch loss = 0.23 (334.7 examples/sec; 0.024 sec/batch; 0h:12m:24s remains)
INFO - root - 2022-02-24 21:09:47.387274: step 168360, total loss = 0.53, batch loss = 0.27 (352.9 examples/sec; 0.023 sec/batch; 0h:11m:45s remains)
INFO - root - 2022-02-24 21:09:47.766635: step 168370, total loss = 0.48, batch loss = 0.22 (335.9 examples/sec; 0.024 sec/batch; 0h:12m:21s remains)
INFO - root - 2022-02-24 21:09:48.328454: step 168380, total loss = 0.58, batch loss = 0.32 (183.2 examples/sec; 0.044 sec/batch; 0h:22m:39s remains)
INFO - root - 2022-02-24 21:09:48.772851: step 168390, total loss = 0.59, batch loss = 0.34 (351.0 examples/sec; 0.023 sec/batch; 0h:11m:49s remains)
INFO - root - 2022-02-24 21:09:49.179016: step 168400, total loss = 0.53, batch loss = 0.28 (312.0 examples/sec; 0.026 sec/batch; 0h:13m:17s remains)
INFO - root - 2022-02-24 21:09:49.616353: step 168410, total loss = 0.56, batch loss = 0.30 (317.4 examples/sec; 0.025 sec/batch; 0h:13m:03s remains)
INFO - root - 2022-02-24 21:09:50.059137: step 168420, total loss = 0.69, batch loss = 0.43 (124.4 examples/sec; 0.064 sec/batch; 0h:33m:19s remains)
INFO - root - 2022-02-24 21:09:50.515297: step 168430, total loss = 0.61, batch loss = 0.36 (191.0 examples/sec; 0.042 sec/batch; 0h:21m:41s remains)
INFO - root - 2022-02-24 21:09:50.965134: step 168440, total loss = 0.52, batch loss = 0.27 (239.8 examples/sec; 0.033 sec/batch; 0h:17m:16s remains)
INFO - root - 2022-02-24 21:09:51.355150: step 168450, total loss = 0.59, batch loss = 0.33 (366.0 examples/sec; 0.022 sec/batch; 0h:11m:18s remains)
INFO - root - 2022-02-24 21:09:51.726154: step 168460, total loss = 0.48, batch loss = 0.23 (97.1 examples/sec; 0.082 sec/batch; 0h:42m:38s remains)
INFO - root - 2022-02-24 21:09:52.138905: step 168470, total loss = 0.58, batch loss = 0.33 (297.2 examples/sec; 0.027 sec/batch; 0h:13m:55s remains)
INFO - root - 2022-02-24 21:09:52.642704: step 168480, total loss = 0.48, batch loss = 0.23 (208.4 examples/sec; 0.038 sec/batch; 0h:19m:50s remains)
INFO - root - 2022-02-24 21:09:53.134815: step 168490, total loss = 0.58, batch loss = 0.32 (187.8 examples/sec; 0.043 sec/batch; 0h:22m:00s remains)
INFO - root - 2022-02-24 21:09:53.521299: step 168500, total loss = 0.49, batch loss = 0.24 (268.2 examples/sec; 0.030 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:09:53.951658: step 168510, total loss = 0.54, batch loss = 0.28 (345.5 examples/sec; 0.023 sec/batch; 0h:11m:57s remains)
INFO - root - 2022-02-24 21:09:54.399936: step 168520, total loss = 0.45, batch loss = 0.19 (162.3 examples/sec; 0.049 sec/batch; 0h:25m:26s remains)
INFO - root - 2022-02-24 21:09:54.794774: step 168530, total loss = 0.61, batch loss = 0.36 (354.5 examples/sec; 0.023 sec/batch; 0h:11m:38s remains)
INFO - root - 2022-02-24 21:09:55.240080: step 168540, total loss = 0.45, batch loss = 0.19 (214.5 examples/sec; 0.037 sec/batch; 0h:19m:14s remains)
INFO - root - 2022-02-24 21:09:55.593131: step 168550, total loss = 0.52, batch loss = 0.26 (229.6 examples/sec; 0.035 sec/batch; 0h:17m:58s remains)
INFO - root - 2022-02-24 21:09:55.909156: step 168560, total loss = 0.54, batch loss = 0.29 (314.5 examples/sec; 0.025 sec/batch; 0h:13m:06s remains)
INFO - root - 2022-02-24 21:09:56.205621: step 168570, total loss = 0.59, batch loss = 0.33 (310.9 examples/sec; 0.026 sec/batch; 0h:13m:15s remains)
INFO - root - 2022-02-24 21:09:56.547198: step 168580, total loss = 0.45, batch loss = 0.20 (243.4 examples/sec; 0.033 sec/batch; 0h:16m:56s remains)
INFO - root - 2022-02-24 21:09:57.073724: step 168590, total loss = 0.58, batch loss = 0.32 (64.3 examples/sec; 0.124 sec/batch; 1h:04m:06s remains)
INFO - root - 2022-02-24 21:09:57.521341: step 168600, total loss = 0.55, batch loss = 0.29 (256.9 examples/sec; 0.031 sec/batch; 0h:16m:02s remains)
INFO - root - 2022-02-24 21:09:58.127455: step 168610, total loss = 0.54, batch loss = 0.29 (212.1 examples/sec; 0.038 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 21:09:58.475995: step 168620, total loss = 0.55, batch loss = 0.30 (306.4 examples/sec; 0.026 sec/batch; 0h:13m:26s remains)
INFO - root - 2022-02-24 21:09:58.877813: step 168630, total loss = 0.49, batch loss = 0.23 (179.0 examples/sec; 0.045 sec/batch; 0h:22m:59s remains)
INFO - root - 2022-02-24 21:09:59.383738: step 168640, total loss = 0.55, batch loss = 0.29 (236.3 examples/sec; 0.034 sec/batch; 0h:17m:24s remains)
INFO - root - 2022-02-24 21:09:59.719206: step 168650, total loss = 0.50, batch loss = 0.24 (362.1 examples/sec; 0.022 sec/batch; 0h:11m:21s remains)
INFO - root - 2022-02-24 21:10:00.161000: step 168660, total loss = 0.61, batch loss = 0.36 (225.5 examples/sec; 0.035 sec/batch; 0h:18m:14s remains)
INFO - root - 2022-02-24 21:10:00.703024: step 168670, total loss = 0.47, batch loss = 0.21 (98.2 examples/sec; 0.081 sec/batch; 0h:41m:50s remains)
INFO - root - 2022-02-24 21:10:01.205357: step 168680, total loss = 0.58, batch loss = 0.32 (110.7 examples/sec; 0.072 sec/batch; 0h:37m:06s remains)
INFO - root - 2022-02-24 21:10:01.730137: step 168690, total loss = 0.58, batch loss = 0.32 (193.5 examples/sec; 0.041 sec/batch; 0h:21m:13s remains)
INFO - root - 2022-02-24 21:10:02.342041: step 168700, total loss = 0.56, batch loss = 0.31 (319.1 examples/sec; 0.025 sec/batch; 0h:12m:52s remains)
INFO - root - 2022-02-24 21:10:03.366116: step 168710, total loss = 0.54, batch loss = 0.28 (361.9 examples/sec; 0.022 sec/batch; 0h:11m:20s remains)
INFO - root - 2022-02-24 21:10:03.931567: step 168720, total loss = 0.50, batch loss = 0.24 (313.2 examples/sec; 0.026 sec/batch; 0h:13m:06s remains)
INFO - root - 2022-02-24 21:10:04.342523: step 168730, total loss = 0.58, batch loss = 0.32 (161.6 examples/sec; 0.050 sec/batch; 0h:25m:23s remains)
INFO - root - 2022-02-24 21:10:04.668936: step 168740, total loss = 0.55, batch loss = 0.30 (327.9 examples/sec; 0.024 sec/batch; 0h:12m:30s remains)
INFO - root - 2022-02-24 21:10:04.958600: step 168750, total loss = 0.54, batch loss = 0.29 (342.3 examples/sec; 0.023 sec/batch; 0h:11m:58s remains)
INFO - root - 2022-02-24 21:10:05.342573: step 168760, total loss = 0.58, batch loss = 0.32 (145.0 examples/sec; 0.055 sec/batch; 0h:28m:15s remains)
INFO - root - 2022-02-24 21:10:05.752837: step 168770, total loss = 0.72, batch loss = 0.47 (296.3 examples/sec; 0.027 sec/batch; 0h:13m:49s remains)
INFO - root - 2022-02-24 21:10:06.282441: step 168780, total loss = 0.60, batch loss = 0.35 (120.1 examples/sec; 0.067 sec/batch; 0h:34m:06s remains)
INFO - root - 2022-02-24 21:10:06.615595: step 168790, total loss = 0.49, batch loss = 0.23 (321.5 examples/sec; 0.025 sec/batch; 0h:12m:44s remains)
INFO - root - 2022-02-24 21:10:06.976881: step 168800, total loss = 0.56, batch loss = 0.30 (338.3 examples/sec; 0.024 sec/batch; 0h:12m:05s remains)
INFO - root - 2022-02-24 21:10:07.450691: step 168810, total loss = 0.46, batch loss = 0.20 (209.1 examples/sec; 0.038 sec/batch; 0h:19m:34s remains)
INFO - root - 2022-02-24 21:10:07.923745: step 168820, total loss = 0.55, batch loss = 0.30 (269.0 examples/sec; 0.030 sec/batch; 0h:15m:12s remains)
INFO - root - 2022-02-24 21:10:08.344449: step 168830, total loss = 0.48, batch loss = 0.22 (215.0 examples/sec; 0.037 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:10:08.692931: step 168840, total loss = 0.59, batch loss = 0.33 (375.6 examples/sec; 0.021 sec/batch; 0h:10m:53s remains)
INFO - root - 2022-02-24 21:10:09.021650: step 168850, total loss = 0.58, batch loss = 0.32 (327.8 examples/sec; 0.024 sec/batch; 0h:12m:27s remains)
INFO - root - 2022-02-24 21:10:09.375051: step 168860, total loss = 0.55, batch loss = 0.29 (306.3 examples/sec; 0.026 sec/batch; 0h:13m:20s remains)
INFO - root - 2022-02-24 21:10:09.818856: step 168870, total loss = 0.53, batch loss = 0.27 (119.3 examples/sec; 0.067 sec/batch; 0h:34m:13s remains)
INFO - root - 2022-02-24 21:10:10.170731: step 168880, total loss = 0.58, batch loss = 0.32 (171.2 examples/sec; 0.047 sec/batch; 0h:23m:50s remains)
INFO - root - 2022-02-24 21:10:10.573759: step 168890, total loss = 0.54, batch loss = 0.29 (160.0 examples/sec; 0.050 sec/batch; 0h:25m:30s remains)
INFO - root - 2022-02-24 21:10:10.915275: step 168900, total loss = 0.55, batch loss = 0.30 (172.7 examples/sec; 0.046 sec/batch; 0h:23m:37s remains)
INFO - root - 2022-02-24 21:10:11.347796: step 168910, total loss = 0.56, batch loss = 0.30 (171.9 examples/sec; 0.047 sec/batch; 0h:23m:43s remains)
INFO - root - 2022-02-24 21:10:11.777431: step 168920, total loss = 0.50, batch loss = 0.24 (251.6 examples/sec; 0.032 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:10:12.179558: step 168930, total loss = 0.53, batch loss = 0.27 (325.3 examples/sec; 0.025 sec/batch; 0h:12m:31s remains)
INFO - root - 2022-02-24 21:10:12.567151: step 168940, total loss = 0.54, batch loss = 0.28 (350.3 examples/sec; 0.023 sec/batch; 0h:11m:37s remains)
INFO - root - 2022-02-24 21:10:12.883269: step 168950, total loss = 0.61, batch loss = 0.35 (354.1 examples/sec; 0.023 sec/batch; 0h:11m:30s remains)
INFO - root - 2022-02-24 21:10:13.282716: step 168960, total loss = 0.51, batch loss = 0.26 (150.1 examples/sec; 0.053 sec/batch; 0h:27m:08s remains)
INFO - root - 2022-02-24 21:10:13.657448: step 168970, total loss = 0.63, batch loss = 0.38 (183.9 examples/sec; 0.043 sec/batch; 0h:22m:08s remains)
INFO - root - 2022-02-24 21:10:14.075085: step 168980, total loss = 0.52, batch loss = 0.26 (346.2 examples/sec; 0.023 sec/batch; 0h:11m:45s remains)
INFO - root - 2022-02-24 21:10:14.434287: step 168990, total loss = 0.52, batch loss = 0.27 (192.7 examples/sec; 0.042 sec/batch; 0h:21m:06s remains)
INFO - root - 2022-02-24 21:10:14.774354: step 169000, total loss = 0.51, batch loss = 0.25 (298.9 examples/sec; 0.027 sec/batch; 0h:13m:36s remains)
INFO - root - 2022-02-24 21:10:15.222763: step 169010, total loss = 0.57, batch loss = 0.31 (257.1 examples/sec; 0.031 sec/batch; 0h:15m:48s remains)
INFO - root - 2022-02-24 21:10:15.660201: step 169020, total loss = 0.48, batch loss = 0.23 (160.6 examples/sec; 0.050 sec/batch; 0h:25m:18s remains)
INFO - root - 2022-02-24 21:10:15.995257: step 169030, total loss = 0.56, batch loss = 0.30 (345.9 examples/sec; 0.023 sec/batch; 0h:11m:44s remains)
INFO - root - 2022-02-24 21:10:16.352923: step 169040, total loss = 0.45, batch loss = 0.19 (209.9 examples/sec; 0.038 sec/batch; 0h:19m:20s remains)
INFO - root - 2022-02-24 21:10:16.716118: step 169050, total loss = 0.59, batch loss = 0.33 (144.9 examples/sec; 0.055 sec/batch; 0h:28m:01s remains)
INFO - root - 2022-02-24 21:10:17.013997: step 169060, total loss = 0.53, batch loss = 0.28 (254.6 examples/sec; 0.031 sec/batch; 0h:15m:56s remains)
INFO - root - 2022-02-24 21:10:17.338865: step 169070, total loss = 0.56, batch loss = 0.30 (312.1 examples/sec; 0.026 sec/batch; 0h:12m:59s remains)
INFO - root - 2022-02-24 21:10:17.665889: step 169080, total loss = 0.51, batch loss = 0.25 (168.4 examples/sec; 0.048 sec/batch; 0h:24m:05s remains)
INFO - root - 2022-02-24 21:10:18.023362: step 169090, total loss = 0.54, batch loss = 0.29 (172.8 examples/sec; 0.046 sec/batch; 0h:23m:28s remains)
INFO - root - 2022-02-24 21:10:18.495501: step 169100, total loss = 0.56, batch loss = 0.30 (306.0 examples/sec; 0.026 sec/batch; 0h:13m:14s remains)
INFO - root - 2022-02-24 21:10:18.984943: step 169110, total loss = 0.55, batch loss = 0.29 (151.6 examples/sec; 0.053 sec/batch; 0h:26m:44s remains)
INFO - root - 2022-02-24 21:10:19.306336: step 169120, total loss = 0.52, batch loss = 0.27 (330.7 examples/sec; 0.024 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:10:19.650069: step 169130, total loss = 0.62, batch loss = 0.36 (219.9 examples/sec; 0.036 sec/batch; 0h:18m:24s remains)
INFO - root - 2022-02-24 21:10:20.034646: step 169140, total loss = 0.55, batch loss = 0.30 (244.8 examples/sec; 0.033 sec/batch; 0h:16m:32s remains)
INFO - root - 2022-02-24 21:10:20.463621: step 169150, total loss = 0.51, batch loss = 0.25 (130.7 examples/sec; 0.061 sec/batch; 0h:30m:57s remains)
INFO - root - 2022-02-24 21:10:20.848869: step 169160, total loss = 0.50, batch loss = 0.25 (334.7 examples/sec; 0.024 sec/batch; 0h:12m:05s remains)
INFO - root - 2022-02-24 21:10:21.187860: step 169170, total loss = 0.50, batch loss = 0.24 (294.1 examples/sec; 0.027 sec/batch; 0h:13m:45s remains)
INFO - root - 2022-02-24 21:10:21.536507: step 169180, total loss = 0.46, batch loss = 0.21 (304.3 examples/sec; 0.026 sec/batch; 0h:13m:17s remains)
INFO - root - 2022-02-24 21:10:21.957189: step 169190, total loss = 0.61, batch loss = 0.36 (355.4 examples/sec; 0.023 sec/batch; 0h:11m:22s remains)
INFO - root - 2022-02-24 21:10:22.445863: step 169200, total loss = 0.57, batch loss = 0.31 (192.8 examples/sec; 0.041 sec/batch; 0h:20m:56s remains)
INFO - root - 2022-02-24 21:10:22.881593: step 169210, total loss = 0.47, batch loss = 0.21 (320.8 examples/sec; 0.025 sec/batch; 0h:12m:35s remains)
INFO - root - 2022-02-24 21:10:23.144498: step 169220, total loss = 0.50, batch loss = 0.24 (261.8 examples/sec; 0.031 sec/batch; 0h:15m:25s remains)
INFO - root - 2022-02-24 21:10:23.493062: step 169230, total loss = 0.62, batch loss = 0.36 (89.1 examples/sec; 0.090 sec/batch; 0h:45m:17s remains)
INFO - root - 2022-02-24 21:10:23.893540: step 169240, total loss = 0.49, batch loss = 0.24 (237.8 examples/sec; 0.034 sec/batch; 0h:16m:58s remains)
INFO - root - 2022-02-24 21:10:24.475393: step 169250, total loss = 0.46, batch loss = 0.21 (133.6 examples/sec; 0.060 sec/batch; 0h:30m:10s remains)
INFO - root - 2022-02-24 21:10:24.854967: step 169260, total loss = 0.55, batch loss = 0.29 (159.1 examples/sec; 0.050 sec/batch; 0h:25m:20s remains)
INFO - root - 2022-02-24 21:10:25.164908: step 169270, total loss = 0.51, batch loss = 0.26 (229.1 examples/sec; 0.035 sec/batch; 0h:17m:35s remains)
INFO - root - 2022-02-24 21:10:25.516540: step 169280, total loss = 0.49, batch loss = 0.24 (137.8 examples/sec; 0.058 sec/batch; 0h:29m:13s remains)
INFO - root - 2022-02-24 21:10:25.861122: step 169290, total loss = 0.48, batch loss = 0.22 (214.1 examples/sec; 0.037 sec/batch; 0h:18m:48s remains)
INFO - root - 2022-02-24 21:10:26.234930: step 169300, total loss = 0.47, batch loss = 0.21 (196.9 examples/sec; 0.041 sec/batch; 0h:20m:27s remains)
INFO - root - 2022-02-24 21:10:26.784866: step 169310, total loss = 0.54, batch loss = 0.28 (303.8 examples/sec; 0.026 sec/batch; 0h:13m:15s remains)
INFO - root - 2022-02-24 21:10:27.098907: step 169320, total loss = 0.52, batch loss = 0.26 (360.8 examples/sec; 0.022 sec/batch; 0h:11m:09s remains)
INFO - root - 2022-02-24 21:10:27.425480: step 169330, total loss = 0.46, batch loss = 0.21 (293.2 examples/sec; 0.027 sec/batch; 0h:13m:43s remains)
INFO - root - 2022-02-24 21:10:27.741053: step 169340, total loss = 0.49, batch loss = 0.24 (346.3 examples/sec; 0.023 sec/batch; 0h:11m:36s remains)
INFO - root - 2022-02-24 21:10:28.150497: step 169350, total loss = 0.59, batch loss = 0.33 (253.7 examples/sec; 0.032 sec/batch; 0h:15m:50s remains)
INFO - root - 2022-02-24 21:10:28.599720: step 169360, total loss = 0.60, batch loss = 0.35 (325.1 examples/sec; 0.025 sec/batch; 0h:12m:21s remains)
INFO - root - 2022-02-24 21:10:28.887621: step 169370, total loss = 0.52, batch loss = 0.26 (334.7 examples/sec; 0.024 sec/batch; 0h:12m:00s remains)
INFO - root - 2022-02-24 21:10:29.228413: step 169380, total loss = 0.60, batch loss = 0.34 (174.1 examples/sec; 0.046 sec/batch; 0h:23m:04s remains)
INFO - root - 2022-02-24 21:10:29.532561: step 169390, total loss = 0.53, batch loss = 0.28 (365.2 examples/sec; 0.022 sec/batch; 0h:10m:59s remains)
INFO - root - 2022-02-24 21:10:29.863440: step 169400, total loss = 0.52, batch loss = 0.26 (261.1 examples/sec; 0.031 sec/batch; 0h:15m:22s remains)
INFO - root - 2022-02-24 21:10:30.469455: step 169410, total loss = 0.58, batch loss = 0.32 (204.2 examples/sec; 0.039 sec/batch; 0h:19m:38s remains)
INFO - root - 2022-02-24 21:10:30.925387: step 169420, total loss = 0.48, batch loss = 0.23 (259.1 examples/sec; 0.031 sec/batch; 0h:15m:28s remains)
INFO - root - 2022-02-24 21:10:31.297832: step 169430, total loss = 0.58, batch loss = 0.32 (216.8 examples/sec; 0.037 sec/batch; 0h:18m:29s remains)
INFO - root - 2022-02-24 21:10:31.576280: step 169440, total loss = 0.49, batch loss = 0.24 (343.6 examples/sec; 0.023 sec/batch; 0h:11m:39s remains)
INFO - root - 2022-02-24 21:10:31.860803: step 169450, total loss = 0.50, batch loss = 0.24 (297.4 examples/sec; 0.027 sec/batch; 0h:13m:28s remains)
INFO - root - 2022-02-24 21:10:32.192014: step 169460, total loss = 0.52, batch loss = 0.26 (198.1 examples/sec; 0.040 sec/batch; 0h:20m:13s remains)
INFO - root - 2022-02-24 21:10:32.596821: step 169470, total loss = 0.52, batch loss = 0.27 (269.2 examples/sec; 0.030 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:10:33.089973: step 169480, total loss = 0.48, batch loss = 0.22 (255.1 examples/sec; 0.031 sec/batch; 0h:15m:41s remains)
INFO - root - 2022-02-24 21:10:33.410868: step 169490, total loss = 0.54, batch loss = 0.28 (228.4 examples/sec; 0.035 sec/batch; 0h:17m:31s remains)
INFO - root - 2022-02-24 21:10:33.765157: step 169500, total loss = 0.68, batch loss = 0.42 (278.8 examples/sec; 0.029 sec/batch; 0h:14m:20s remains)
INFO - root - 2022-02-24 21:10:34.271889: step 169510, total loss = 0.62, batch loss = 0.36 (64.8 examples/sec; 0.124 sec/batch; 1h:01m:44s remains)
INFO - root - 2022-02-24 21:10:34.671971: step 169520, total loss = 0.49, batch loss = 0.23 (136.1 examples/sec; 0.059 sec/batch; 0h:29m:22s remains)
INFO - root - 2022-02-24 21:10:35.018508: step 169530, total loss = 0.64, batch loss = 0.38 (341.6 examples/sec; 0.023 sec/batch; 0h:11m:41s remains)
INFO - root - 2022-02-24 21:10:35.711124: step 169540, total loss = 0.50, batch loss = 0.25 (104.7 examples/sec; 0.076 sec/batch; 0h:38m:10s remains)
INFO - root - 2022-02-24 21:10:36.200436: step 169550, total loss = 0.51, batch loss = 0.26 (260.2 examples/sec; 0.031 sec/batch; 0h:15m:20s remains)
INFO - root - 2022-02-24 21:10:36.849122: step 169560, total loss = 0.56, batch loss = 0.30 (132.4 examples/sec; 0.060 sec/batch; 0h:30m:09s remains)
INFO - root - 2022-02-24 21:10:37.421730: step 169570, total loss = 0.57, batch loss = 0.32 (129.7 examples/sec; 0.062 sec/batch; 0h:30m:46s remains)
INFO - root - 2022-02-24 21:10:38.499425: step 169580, total loss = 0.52, batch loss = 0.26 (287.2 examples/sec; 0.028 sec/batch; 0h:13m:53s remains)
INFO - root - 2022-02-24 21:10:38.878620: step 169590, total loss = 0.52, batch loss = 0.26 (232.3 examples/sec; 0.034 sec/batch; 0h:17m:09s remains)
INFO - root - 2022-02-24 21:10:39.423106: step 169600, total loss = 0.45, batch loss = 0.19 (162.1 examples/sec; 0.049 sec/batch; 0h:24m:35s remains)
INFO - root - 2022-02-24 21:10:39.845055: step 169610, total loss = 0.55, batch loss = 0.29 (214.7 examples/sec; 0.037 sec/batch; 0h:18m:33s remains)
INFO - root - 2022-02-24 21:10:40.210037: step 169620, total loss = 0.55, batch loss = 0.29 (189.2 examples/sec; 0.042 sec/batch; 0h:21m:03s remains)
INFO - root - 2022-02-24 21:10:40.536121: step 169630, total loss = 0.51, batch loss = 0.26 (216.3 examples/sec; 0.037 sec/batch; 0h:18m:24s remains)
INFO - root - 2022-02-24 21:10:40.985536: step 169640, total loss = 0.70, batch loss = 0.45 (274.8 examples/sec; 0.029 sec/batch; 0h:14m:29s remains)
INFO - root - 2022-02-24 21:10:41.496819: step 169650, total loss = 0.58, batch loss = 0.32 (146.6 examples/sec; 0.055 sec/batch; 0h:27m:08s remains)
INFO - root - 2022-02-24 21:10:41.839255: step 169660, total loss = 0.51, batch loss = 0.26 (286.0 examples/sec; 0.028 sec/batch; 0h:13m:54s remains)
INFO - root - 2022-02-24 21:10:42.208291: step 169670, total loss = 0.49, batch loss = 0.24 (322.4 examples/sec; 0.025 sec/batch; 0h:12m:20s remains)
INFO - root - 2022-02-24 21:10:42.573184: step 169680, total loss = 0.57, batch loss = 0.31 (175.4 examples/sec; 0.046 sec/batch; 0h:22m:40s remains)
INFO - root - 2022-02-24 21:10:43.005320: step 169690, total loss = 0.51, batch loss = 0.25 (92.4 examples/sec; 0.087 sec/batch; 0h:43m:02s remains)
INFO - root - 2022-02-24 21:10:43.425632: step 169700, total loss = 0.50, batch loss = 0.25 (123.7 examples/sec; 0.065 sec/batch; 0h:32m:07s remains)
INFO - root - 2022-02-24 21:10:43.894884: step 169710, total loss = 0.53, batch loss = 0.27 (245.3 examples/sec; 0.033 sec/batch; 0h:16m:11s remains)
INFO - root - 2022-02-24 21:10:44.302804: step 169720, total loss = 0.53, batch loss = 0.28 (230.1 examples/sec; 0.035 sec/batch; 0h:17m:15s remains)
INFO - root - 2022-02-24 21:10:44.664109: step 169730, total loss = 0.50, batch loss = 0.24 (173.8 examples/sec; 0.046 sec/batch; 0h:22m:50s remains)
INFO - root - 2022-02-24 21:10:45.110680: step 169740, total loss = 0.80, batch loss = 0.54 (325.3 examples/sec; 0.025 sec/batch; 0h:12m:11s remains)
INFO - root - 2022-02-24 21:10:45.510995: step 169750, total loss = 0.63, batch loss = 0.37 (234.0 examples/sec; 0.034 sec/batch; 0h:16m:56s remains)
INFO - root - 2022-02-24 21:10:45.865933: step 169760, total loss = 0.49, batch loss = 0.24 (303.9 examples/sec; 0.026 sec/batch; 0h:13m:02s remains)
INFO - root - 2022-02-24 21:10:46.223435: step 169770, total loss = 0.53, batch loss = 0.27 (106.3 examples/sec; 0.075 sec/batch; 0h:37m:17s remains)
INFO - root - 2022-02-24 21:10:46.558080: step 169780, total loss = 0.53, batch loss = 0.27 (322.1 examples/sec; 0.025 sec/batch; 0h:12m:18s remains)
INFO - root - 2022-02-24 21:10:46.880194: step 169790, total loss = 0.62, batch loss = 0.36 (347.1 examples/sec; 0.023 sec/batch; 0h:11m:24s remains)
INFO - root - 2022-02-24 21:10:47.380394: step 169800, total loss = 0.46, batch loss = 0.21 (123.2 examples/sec; 0.065 sec/batch; 0h:32m:08s remains)
INFO - root - 2022-02-24 21:10:47.926596: step 169810, total loss = 0.55, batch loss = 0.29 (144.3 examples/sec; 0.055 sec/batch; 0h:27m:26s remains)
INFO - root - 2022-02-24 21:10:48.302919: step 169820, total loss = 0.52, batch loss = 0.27 (279.1 examples/sec; 0.029 sec/batch; 0h:14m:10s remains)
INFO - root - 2022-02-24 21:10:48.696201: step 169830, total loss = 0.46, batch loss = 0.20 (103.0 examples/sec; 0.078 sec/batch; 0h:38m:23s remains)
INFO - root - 2022-02-24 21:10:49.119730: step 169840, total loss = 0.63, batch loss = 0.37 (177.7 examples/sec; 0.045 sec/batch; 0h:22m:15s remains)
INFO - root - 2022-02-24 21:10:49.568834: step 169850, total loss = 0.49, batch loss = 0.23 (258.7 examples/sec; 0.031 sec/batch; 0h:15m:16s remains)
INFO - root - 2022-02-24 21:10:50.020512: step 169860, total loss = 0.52, batch loss = 0.26 (299.6 examples/sec; 0.027 sec/batch; 0h:13m:11s remains)
INFO - root - 2022-02-24 21:10:50.292359: step 169870, total loss = 0.69, batch loss = 0.43 (204.8 examples/sec; 0.039 sec/batch; 0h:19m:17s remains)
INFO - root - 2022-02-24 21:10:50.633113: step 169880, total loss = 0.56, batch loss = 0.30 (184.8 examples/sec; 0.043 sec/batch; 0h:21m:22s remains)
INFO - root - 2022-02-24 21:10:50.987656: step 169890, total loss = 0.46, batch loss = 0.20 (269.4 examples/sec; 0.030 sec/batch; 0h:14m:39s remains)
INFO - root - 2022-02-24 21:10:51.292268: step 169900, total loss = 0.51, batch loss = 0.25 (195.0 examples/sec; 0.041 sec/batch; 0h:20m:14s remains)
INFO - root - 2022-02-24 21:10:51.866634: step 169910, total loss = 0.60, batch loss = 0.34 (114.8 examples/sec; 0.070 sec/batch; 0h:34m:21s remains)
INFO - root - 2022-02-24 21:10:52.306319: step 169920, total loss = 0.49, batch loss = 0.24 (368.4 examples/sec; 0.022 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:10:52.634967: step 169930, total loss = 0.48, batch loss = 0.23 (189.1 examples/sec; 0.042 sec/batch; 0h:20m:51s remains)
INFO - root - 2022-02-24 21:10:52.991001: step 169940, total loss = 0.58, batch loss = 0.32 (210.5 examples/sec; 0.038 sec/batch; 0h:18m:43s remains)
INFO - root - 2022-02-24 21:10:53.364248: step 169950, total loss = 0.51, batch loss = 0.25 (184.5 examples/sec; 0.043 sec/batch; 0h:21m:21s remains)
INFO - root - 2022-02-24 21:10:53.759169: step 169960, total loss = 0.54, batch loss = 0.28 (143.2 examples/sec; 0.056 sec/batch; 0h:27m:30s remains)
INFO - root - 2022-02-24 21:10:54.138694: step 169970, total loss = 0.53, batch loss = 0.28 (346.1 examples/sec; 0.023 sec/batch; 0h:11m:22s remains)
INFO - root - 2022-02-24 21:10:54.584339: step 169980, total loss = 0.51, batch loss = 0.25 (312.8 examples/sec; 0.026 sec/batch; 0h:12m:34s remains)
INFO - root - 2022-02-24 21:10:54.857363: step 169990, total loss = 0.52, batch loss = 0.27 (303.6 examples/sec; 0.026 sec/batch; 0h:12m:57s remains)
INFO - root - 2022-02-24 21:10:55.210916: step 170000, total loss = 0.59, batch loss = 0.33 (207.4 examples/sec; 0.039 sec/batch; 0h:18m:57s remains)
INFO - root - 2022-02-24 21:10:55.651365: step 170010, total loss = 0.52, batch loss = 0.26 (145.9 examples/sec; 0.055 sec/batch; 0h:26m:56s remains)
INFO - root - 2022-02-24 21:10:56.054647: step 170020, total loss = 0.58, batch loss = 0.33 (195.5 examples/sec; 0.041 sec/batch; 0h:20m:06s remains)
INFO - root - 2022-02-24 21:10:56.462220: step 170030, total loss = 0.57, batch loss = 0.32 (234.4 examples/sec; 0.034 sec/batch; 0h:16m:45s remains)
INFO - root - 2022-02-24 21:10:56.841140: step 170040, total loss = 0.56, batch loss = 0.31 (318.3 examples/sec; 0.025 sec/batch; 0h:12m:20s remains)
INFO - root - 2022-02-24 21:10:57.183695: step 170050, total loss = 0.53, batch loss = 0.27 (209.1 examples/sec; 0.038 sec/batch; 0h:18m:46s remains)
INFO - root - 2022-02-24 21:10:57.623872: step 170060, total loss = 0.63, batch loss = 0.38 (213.5 examples/sec; 0.037 sec/batch; 0h:18m:23s remains)
INFO - root - 2022-02-24 21:10:58.043248: step 170070, total loss = 0.60, batch loss = 0.34 (296.9 examples/sec; 0.027 sec/batch; 0h:13m:12s remains)
INFO - root - 2022-02-24 21:10:58.590638: step 170080, total loss = 0.53, batch loss = 0.28 (124.2 examples/sec; 0.064 sec/batch; 0h:31m:34s remains)
INFO - root - 2022-02-24 21:10:58.987383: step 170090, total loss = 0.54, batch loss = 0.29 (361.7 examples/sec; 0.022 sec/batch; 0h:10m:50s remains)
INFO - root - 2022-02-24 21:10:59.336773: step 170100, total loss = 0.65, batch loss = 0.40 (342.1 examples/sec; 0.023 sec/batch; 0h:11m:27s remains)
INFO - root - 2022-02-24 21:10:59.690956: step 170110, total loss = 0.57, batch loss = 0.31 (222.5 examples/sec; 0.036 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:11:00.110433: step 170120, total loss = 0.59, batch loss = 0.33 (343.2 examples/sec; 0.023 sec/batch; 0h:11m:24s remains)
INFO - root - 2022-02-24 21:11:00.599893: step 170130, total loss = 0.44, batch loss = 0.19 (160.9 examples/sec; 0.050 sec/batch; 0h:24m:19s remains)
INFO - root - 2022-02-24 21:11:00.979786: step 170140, total loss = 0.50, batch loss = 0.24 (119.4 examples/sec; 0.067 sec/batch; 0h:32m:47s remains)
INFO - root - 2022-02-24 21:11:01.337918: step 170150, total loss = 0.47, batch loss = 0.22 (272.1 examples/sec; 0.029 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:11:01.745177: step 170160, total loss = 0.50, batch loss = 0.24 (146.7 examples/sec; 0.055 sec/batch; 0h:26m:40s remains)
INFO - root - 2022-02-24 21:11:02.068945: step 170170, total loss = 0.59, batch loss = 0.33 (220.4 examples/sec; 0.036 sec/batch; 0h:17m:44s remains)
INFO - root - 2022-02-24 21:11:02.514705: step 170180, total loss = 0.49, batch loss = 0.24 (227.8 examples/sec; 0.035 sec/batch; 0h:17m:09s remains)
INFO - root - 2022-02-24 21:11:02.977794: step 170190, total loss = 0.59, batch loss = 0.33 (134.5 examples/sec; 0.059 sec/batch; 0h:29m:02s remains)
INFO - root - 2022-02-24 21:11:03.289802: step 170200, total loss = 0.66, batch loss = 0.40 (240.4 examples/sec; 0.033 sec/batch; 0h:16m:14s remains)
INFO - root - 2022-02-24 21:11:03.750650: step 170210, total loss = 0.44, batch loss = 0.18 (153.8 examples/sec; 0.052 sec/batch; 0h:25m:23s remains)
INFO - root - 2022-02-24 21:11:04.278229: step 170220, total loss = 0.55, batch loss = 0.29 (205.5 examples/sec; 0.039 sec/batch; 0h:18m:59s remains)
INFO - root - 2022-02-24 21:11:04.691572: step 170230, total loss = 0.58, batch loss = 0.33 (159.4 examples/sec; 0.050 sec/batch; 0h:24m:29s remains)
INFO - root - 2022-02-24 21:11:05.149332: step 170240, total loss = 0.66, batch loss = 0.40 (140.7 examples/sec; 0.057 sec/batch; 0h:27m:43s remains)
INFO - root - 2022-02-24 21:11:05.473024: step 170250, total loss = 0.55, batch loss = 0.30 (331.5 examples/sec; 0.024 sec/batch; 0h:11m:45s remains)
INFO - root - 2022-02-24 21:11:05.833096: step 170260, total loss = 0.54, batch loss = 0.28 (144.4 examples/sec; 0.055 sec/batch; 0h:26m:59s remains)
INFO - root - 2022-02-24 21:11:06.178539: step 170270, total loss = 0.60, batch loss = 0.35 (172.4 examples/sec; 0.046 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 21:11:06.597341: step 170280, total loss = 0.52, batch loss = 0.26 (207.8 examples/sec; 0.039 sec/batch; 0h:18m:45s remains)
INFO - root - 2022-02-24 21:11:06.999122: step 170290, total loss = 0.46, batch loss = 0.20 (271.2 examples/sec; 0.029 sec/batch; 0h:14m:21s remains)
INFO - root - 2022-02-24 21:11:07.289919: step 170300, total loss = 0.57, batch loss = 0.32 (316.2 examples/sec; 0.025 sec/batch; 0h:12m:18s remains)
INFO - root - 2022-02-24 21:11:07.625866: step 170310, total loss = 0.51, batch loss = 0.26 (284.0 examples/sec; 0.028 sec/batch; 0h:13m:42s remains)
INFO - root - 2022-02-24 21:11:07.899082: step 170320, total loss = 0.66, batch loss = 0.40 (180.7 examples/sec; 0.044 sec/batch; 0h:21m:32s remains)
INFO - root - 2022-02-24 21:11:08.200152: step 170330, total loss = 0.51, batch loss = 0.25 (360.4 examples/sec; 0.022 sec/batch; 0h:10m:47s remains)
INFO - root - 2022-02-24 21:11:08.651748: step 170340, total loss = 0.56, batch loss = 0.31 (85.5 examples/sec; 0.094 sec/batch; 0h:45m:29s remains)
INFO - root - 2022-02-24 21:11:09.132284: step 170350, total loss = 0.56, batch loss = 0.31 (96.7 examples/sec; 0.083 sec/batch; 0h:40m:10s remains)
INFO - root - 2022-02-24 21:11:09.510764: step 170360, total loss = 0.52, batch loss = 0.26 (196.2 examples/sec; 0.041 sec/batch; 0h:19m:48s remains)
INFO - root - 2022-02-24 21:11:09.894237: step 170370, total loss = 0.62, batch loss = 0.36 (141.2 examples/sec; 0.057 sec/batch; 0h:27m:30s remains)
INFO - root - 2022-02-24 21:11:10.211286: step 170380, total loss = 0.49, batch loss = 0.23 (330.3 examples/sec; 0.024 sec/batch; 0h:11m:45s remains)
INFO - root - 2022-02-24 21:11:10.713677: step 170390, total loss = 0.59, batch loss = 0.34 (210.4 examples/sec; 0.038 sec/batch; 0h:18m:27s remains)
INFO - root - 2022-02-24 21:11:11.070499: step 170400, total loss = 0.51, batch loss = 0.25 (220.3 examples/sec; 0.036 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:11:11.493929: step 170410, total loss = 0.63, batch loss = 0.37 (339.5 examples/sec; 0.024 sec/batch; 0h:11m:25s remains)
INFO - root - 2022-02-24 21:11:11.825128: step 170420, total loss = 0.46, batch loss = 0.21 (204.8 examples/sec; 0.039 sec/batch; 0h:18m:56s remains)
INFO - root - 2022-02-24 21:11:12.153904: step 170430, total loss = 0.53, batch loss = 0.28 (132.1 examples/sec; 0.061 sec/batch; 0h:29m:20s remains)
INFO - root - 2022-02-24 21:11:12.530069: step 170440, total loss = 0.49, batch loss = 0.24 (305.6 examples/sec; 0.026 sec/batch; 0h:12m:40s remains)
INFO - root - 2022-02-24 21:11:12.824954: step 170450, total loss = 0.51, batch loss = 0.25 (318.2 examples/sec; 0.025 sec/batch; 0h:12m:10s remains)
INFO - root - 2022-02-24 21:11:13.163097: step 170460, total loss = 0.46, batch loss = 0.20 (370.2 examples/sec; 0.022 sec/batch; 0h:10m:27s remains)
INFO - root - 2022-02-24 21:11:13.583799: step 170470, total loss = 0.53, batch loss = 0.28 (328.7 examples/sec; 0.024 sec/batch; 0h:11m:46s remains)
INFO - root - 2022-02-24 21:11:14.188406: step 170480, total loss = 0.48, batch loss = 0.22 (117.3 examples/sec; 0.068 sec/batch; 0h:33m:00s remains)
INFO - root - 2022-02-24 21:11:14.945639: step 170490, total loss = 0.54, batch loss = 0.29 (317.2 examples/sec; 0.025 sec/batch; 0h:12m:11s remains)
INFO - root - 2022-02-24 21:11:15.447721: step 170500, total loss = 0.50, batch loss = 0.24 (160.9 examples/sec; 0.050 sec/batch; 0h:24m:01s remains)
INFO - root - 2022-02-24 21:11:15.858546: step 170510, total loss = 0.56, batch loss = 0.31 (212.8 examples/sec; 0.038 sec/batch; 0h:18m:09s remains)
INFO - root - 2022-02-24 21:11:16.254884: step 170520, total loss = 0.53, batch loss = 0.27 (155.9 examples/sec; 0.051 sec/batch; 0h:24m:46s remains)
INFO - root - 2022-02-24 21:11:16.731235: step 170530, total loss = 0.48, batch loss = 0.23 (374.8 examples/sec; 0.021 sec/batch; 0h:10m:18s remains)
INFO - root - 2022-02-24 21:11:17.342187: step 170540, total loss = 0.61, batch loss = 0.35 (128.5 examples/sec; 0.062 sec/batch; 0h:30m:03s remains)
INFO - root - 2022-02-24 21:11:17.810554: step 170550, total loss = 0.61, batch loss = 0.35 (161.3 examples/sec; 0.050 sec/batch; 0h:23m:55s remains)
INFO - root - 2022-02-24 21:11:18.171079: step 170560, total loss = 0.58, batch loss = 0.32 (194.1 examples/sec; 0.041 sec/batch; 0h:19m:52s remains)
INFO - root - 2022-02-24 21:11:18.476779: step 170570, total loss = 0.54, batch loss = 0.28 (338.3 examples/sec; 0.024 sec/batch; 0h:11m:24s remains)
INFO - root - 2022-02-24 21:11:18.883940: step 170580, total loss = 0.58, batch loss = 0.32 (123.2 examples/sec; 0.065 sec/batch; 0h:31m:18s remains)
INFO - root - 2022-02-24 21:11:19.627577: step 170590, total loss = 0.63, batch loss = 0.38 (137.9 examples/sec; 0.058 sec/batch; 0h:27m:57s remains)
INFO - root - 2022-02-24 21:11:20.088680: step 170600, total loss = 0.58, batch loss = 0.33 (139.5 examples/sec; 0.057 sec/batch; 0h:27m:37s remains)
INFO - root - 2022-02-24 21:11:20.451288: step 170610, total loss = 0.45, batch loss = 0.19 (232.4 examples/sec; 0.034 sec/batch; 0h:16m:34s remains)
INFO - root - 2022-02-24 21:11:20.750884: step 170620, total loss = 0.56, batch loss = 0.31 (352.9 examples/sec; 0.023 sec/batch; 0h:10m:54s remains)
INFO - root - 2022-02-24 21:11:21.103704: step 170630, total loss = 0.62, batch loss = 0.37 (317.7 examples/sec; 0.025 sec/batch; 0h:12m:07s remains)
INFO - root - 2022-02-24 21:11:21.547499: step 170640, total loss = 0.52, batch loss = 0.27 (334.9 examples/sec; 0.024 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:11:21.994254: step 170650, total loss = 0.66, batch loss = 0.40 (275.0 examples/sec; 0.029 sec/batch; 0h:13m:59s remains)
INFO - root - 2022-02-24 21:11:22.301124: step 170660, total loss = 0.56, batch loss = 0.30 (337.7 examples/sec; 0.024 sec/batch; 0h:11m:23s remains)
INFO - root - 2022-02-24 21:11:22.623714: step 170670, total loss = 0.62, batch loss = 0.36 (335.1 examples/sec; 0.024 sec/batch; 0h:11m:28s remains)
INFO - root - 2022-02-24 21:11:22.927870: step 170680, total loss = 0.66, batch loss = 0.41 (337.1 examples/sec; 0.024 sec/batch; 0h:11m:23s remains)
INFO - root - 2022-02-24 21:11:23.239499: step 170690, total loss = 0.61, batch loss = 0.35 (313.1 examples/sec; 0.026 sec/batch; 0h:12m:16s remains)
INFO - root - 2022-02-24 21:11:23.610653: step 170700, total loss = 0.57, batch loss = 0.31 (272.3 examples/sec; 0.029 sec/batch; 0h:14m:06s remains)
INFO - root - 2022-02-24 21:11:24.172661: step 170710, total loss = 0.47, batch loss = 0.22 (149.3 examples/sec; 0.054 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 21:11:24.554032: step 170720, total loss = 0.44, batch loss = 0.19 (148.9 examples/sec; 0.054 sec/batch; 0h:25m:46s remains)
INFO - root - 2022-02-24 21:11:24.929108: step 170730, total loss = 0.55, batch loss = 0.30 (349.4 examples/sec; 0.023 sec/batch; 0h:10m:58s remains)
INFO - root - 2022-02-24 21:11:25.310496: step 170740, total loss = 0.42, batch loss = 0.17 (178.0 examples/sec; 0.045 sec/batch; 0h:21m:32s remains)
INFO - root - 2022-02-24 21:11:25.661161: step 170750, total loss = 0.45, batch loss = 0.19 (291.0 examples/sec; 0.027 sec/batch; 0h:13m:10s remains)
INFO - root - 2022-02-24 21:11:26.060237: step 170760, total loss = 0.64, batch loss = 0.38 (246.6 examples/sec; 0.032 sec/batch; 0h:15m:32s remains)
INFO - root - 2022-02-24 21:11:26.511694: step 170770, total loss = 0.49, batch loss = 0.23 (233.3 examples/sec; 0.034 sec/batch; 0h:16m:25s remains)
INFO - root - 2022-02-24 21:11:26.954572: step 170780, total loss = 0.52, batch loss = 0.26 (334.4 examples/sec; 0.024 sec/batch; 0h:11m:27s remains)
INFO - root - 2022-02-24 21:11:27.350333: step 170790, total loss = 0.46, batch loss = 0.20 (206.4 examples/sec; 0.039 sec/batch; 0h:18m:32s remains)
INFO - root - 2022-02-24 21:11:27.718580: step 170800, total loss = 0.45, batch loss = 0.20 (200.6 examples/sec; 0.040 sec/batch; 0h:19m:04s remains)
INFO - root - 2022-02-24 21:11:28.161877: step 170810, total loss = 0.55, batch loss = 0.30 (133.8 examples/sec; 0.060 sec/batch; 0h:28m:35s remains)
INFO - root - 2022-02-24 21:11:28.548963: step 170820, total loss = 0.61, batch loss = 0.35 (338.0 examples/sec; 0.024 sec/batch; 0h:11m:18s remains)
INFO - root - 2022-02-24 21:11:28.983550: step 170830, total loss = 0.64, batch loss = 0.38 (293.4 examples/sec; 0.027 sec/batch; 0h:13m:01s remains)
INFO - root - 2022-02-24 21:11:29.274920: step 170840, total loss = 0.66, batch loss = 0.41 (360.2 examples/sec; 0.022 sec/batch; 0h:10m:36s remains)
INFO - root - 2022-02-24 21:11:29.538152: step 170850, total loss = 0.48, batch loss = 0.22 (318.7 examples/sec; 0.025 sec/batch; 0h:11m:59s remains)
INFO - root - 2022-02-24 21:11:29.950116: step 170860, total loss = 0.60, batch loss = 0.34 (200.8 examples/sec; 0.040 sec/batch; 0h:19m:01s remains)
INFO - root - 2022-02-24 21:11:30.343680: step 170870, total loss = 0.55, batch loss = 0.29 (195.8 examples/sec; 0.041 sec/batch; 0h:19m:29s remains)
INFO - root - 2022-02-24 21:11:30.816254: step 170880, total loss = 0.60, batch loss = 0.35 (149.4 examples/sec; 0.054 sec/batch; 0h:25m:32s remains)
INFO - root - 2022-02-24 21:11:31.147981: step 170890, total loss = 0.50, batch loss = 0.24 (223.6 examples/sec; 0.036 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:11:31.468951: step 170900, total loss = 0.53, batch loss = 0.27 (361.1 examples/sec; 0.022 sec/batch; 0h:10m:33s remains)
INFO - root - 2022-02-24 21:11:31.842568: step 170910, total loss = 0.49, batch loss = 0.23 (309.9 examples/sec; 0.026 sec/batch; 0h:12m:18s remains)
INFO - root - 2022-02-24 21:11:32.270279: step 170920, total loss = 0.52, batch loss = 0.26 (290.4 examples/sec; 0.028 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:11:32.658505: step 170930, total loss = 0.60, batch loss = 0.34 (350.5 examples/sec; 0.023 sec/batch; 0h:10m:52s remains)
INFO - root - 2022-02-24 21:11:33.044799: step 170940, total loss = 0.47, batch loss = 0.22 (364.1 examples/sec; 0.022 sec/batch; 0h:10m:27s remains)
INFO - root - 2022-02-24 21:11:33.416308: step 170950, total loss = 0.55, batch loss = 0.29 (302.6 examples/sec; 0.026 sec/batch; 0h:12m:34s remains)
INFO - root - 2022-02-24 21:11:33.745826: step 170960, total loss = 0.54, batch loss = 0.28 (355.6 examples/sec; 0.022 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:11:34.079218: step 170970, total loss = 0.52, batch loss = 0.27 (175.7 examples/sec; 0.046 sec/batch; 0h:21m:38s remains)
INFO - root - 2022-02-24 21:11:34.432507: step 170980, total loss = 0.53, batch loss = 0.27 (217.8 examples/sec; 0.037 sec/batch; 0h:17m:27s remains)
INFO - root - 2022-02-24 21:11:34.791817: step 170990, total loss = 0.52, batch loss = 0.26 (200.0 examples/sec; 0.040 sec/batch; 0h:19m:00s remains)
INFO - root - 2022-02-24 21:11:35.210970: step 171000, total loss = 0.58, batch loss = 0.32 (138.0 examples/sec; 0.058 sec/batch; 0h:27m:31s remains)
INFO - root - 2022-02-24 21:11:35.656919: step 171010, total loss = 0.53, batch loss = 0.28 (205.3 examples/sec; 0.039 sec/batch; 0h:18m:30s remains)
INFO - root - 2022-02-24 21:11:35.999712: step 171020, total loss = 0.60, batch loss = 0.35 (191.7 examples/sec; 0.042 sec/batch; 0h:19m:48s remains)
INFO - root - 2022-02-24 21:11:36.306228: step 171030, total loss = 0.47, batch loss = 0.21 (297.6 examples/sec; 0.027 sec/batch; 0h:12m:45s remains)
INFO - root - 2022-02-24 21:11:36.611277: step 171040, total loss = 0.58, batch loss = 0.32 (303.2 examples/sec; 0.026 sec/batch; 0h:12m:30s remains)
INFO - root - 2022-02-24 21:11:37.019390: step 171050, total loss = 0.52, batch loss = 0.26 (226.9 examples/sec; 0.035 sec/batch; 0h:16m:42s remains)
INFO - root - 2022-02-24 21:11:37.433946: step 171060, total loss = 0.60, batch loss = 0.35 (147.2 examples/sec; 0.054 sec/batch; 0h:25m:45s remains)
INFO - root - 2022-02-24 21:11:37.787791: step 171070, total loss = 0.52, batch loss = 0.26 (270.2 examples/sec; 0.030 sec/batch; 0h:14m:01s remains)
INFO - root - 2022-02-24 21:11:38.093932: step 171080, total loss = 0.59, batch loss = 0.33 (247.5 examples/sec; 0.032 sec/batch; 0h:15m:18s remains)
INFO - root - 2022-02-24 21:11:38.444992: step 171090, total loss = 0.53, batch loss = 0.28 (363.2 examples/sec; 0.022 sec/batch; 0h:10m:25s remains)
INFO - root - 2022-02-24 21:11:38.761132: step 171100, total loss = 0.53, batch loss = 0.28 (208.4 examples/sec; 0.038 sec/batch; 0h:18m:10s remains)
INFO - root - 2022-02-24 21:11:39.225638: step 171110, total loss = 0.52, batch loss = 0.26 (232.9 examples/sec; 0.034 sec/batch; 0h:16m:15s remains)
INFO - root - 2022-02-24 21:11:39.656057: step 171120, total loss = 0.59, batch loss = 0.34 (188.3 examples/sec; 0.042 sec/batch; 0h:20m:05s remains)
INFO - root - 2022-02-24 21:11:40.003485: step 171130, total loss = 0.72, batch loss = 0.47 (352.6 examples/sec; 0.023 sec/batch; 0h:10m:43s remains)
INFO - root - 2022-02-24 21:11:40.293528: step 171140, total loss = 0.53, batch loss = 0.27 (244.7 examples/sec; 0.033 sec/batch; 0h:15m:27s remains)
INFO - root - 2022-02-24 21:11:40.582573: step 171150, total loss = 0.58, batch loss = 0.32 (292.6 examples/sec; 0.027 sec/batch; 0h:12m:55s remains)
INFO - root - 2022-02-24 21:11:40.868601: step 171160, total loss = 0.49, batch loss = 0.23 (314.5 examples/sec; 0.025 sec/batch; 0h:12m:00s remains)
INFO - root - 2022-02-24 21:11:41.201616: step 171170, total loss = 0.77, batch loss = 0.51 (316.1 examples/sec; 0.025 sec/batch; 0h:11m:56s remains)
INFO - root - 2022-02-24 21:11:41.612849: step 171180, total loss = 0.56, batch loss = 0.31 (171.3 examples/sec; 0.047 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:11:41.947895: step 171190, total loss = 0.62, batch loss = 0.37 (224.5 examples/sec; 0.036 sec/batch; 0h:16m:48s remains)
INFO - root - 2022-02-24 21:11:42.359758: step 171200, total loss = 0.60, batch loss = 0.34 (354.9 examples/sec; 0.023 sec/batch; 0h:10m:37s remains)
INFO - root - 2022-02-24 21:11:42.754229: step 171210, total loss = 0.47, batch loss = 0.21 (332.3 examples/sec; 0.024 sec/batch; 0h:11m:21s remains)
INFO - root - 2022-02-24 21:11:43.099367: step 171220, total loss = 0.55, batch loss = 0.29 (158.7 examples/sec; 0.050 sec/batch; 0h:23m:45s remains)
INFO - root - 2022-02-24 21:11:43.508377: step 171230, total loss = 0.49, batch loss = 0.24 (139.0 examples/sec; 0.058 sec/batch; 0h:27m:07s remains)
INFO - root - 2022-02-24 21:11:43.890459: step 171240, total loss = 0.50, batch loss = 0.25 (163.6 examples/sec; 0.049 sec/batch; 0h:23m:01s remains)
INFO - root - 2022-02-24 21:11:44.208625: step 171250, total loss = 0.52, batch loss = 0.27 (215.6 examples/sec; 0.037 sec/batch; 0h:17m:27s remains)
INFO - root - 2022-02-24 21:11:44.532809: step 171260, total loss = 0.56, batch loss = 0.30 (215.8 examples/sec; 0.037 sec/batch; 0h:17m:26s remains)
INFO - root - 2022-02-24 21:11:44.863293: step 171270, total loss = 0.53, batch loss = 0.27 (168.8 examples/sec; 0.047 sec/batch; 0h:22m:17s remains)
INFO - root - 2022-02-24 21:11:45.233940: step 171280, total loss = 0.47, batch loss = 0.21 (166.1 examples/sec; 0.048 sec/batch; 0h:22m:38s remains)
INFO - root - 2022-02-24 21:11:45.665579: step 171290, total loss = 0.51, batch loss = 0.25 (232.0 examples/sec; 0.034 sec/batch; 0h:16m:12s remains)
INFO - root - 2022-02-24 21:11:46.016729: step 171300, total loss = 0.48, batch loss = 0.22 (329.8 examples/sec; 0.024 sec/batch; 0h:11m:23s remains)
INFO - root - 2022-02-24 21:11:46.375809: step 171310, total loss = 0.49, batch loss = 0.24 (305.9 examples/sec; 0.026 sec/batch; 0h:12m:17s remains)
INFO - root - 2022-02-24 21:11:46.670516: step 171320, total loss = 0.60, batch loss = 0.35 (259.1 examples/sec; 0.031 sec/batch; 0h:14m:30s remains)
INFO - root - 2022-02-24 21:11:47.004741: step 171330, total loss = 0.48, batch loss = 0.22 (264.4 examples/sec; 0.030 sec/batch; 0h:14m:12s remains)
INFO - root - 2022-02-24 21:11:47.619507: step 171340, total loss = 0.45, batch loss = 0.20 (138.3 examples/sec; 0.058 sec/batch; 0h:27m:09s remains)
INFO - root - 2022-02-24 21:11:48.017046: step 171350, total loss = 0.54, batch loss = 0.28 (220.1 examples/sec; 0.036 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:11:48.367684: step 171360, total loss = 0.45, batch loss = 0.19 (277.1 examples/sec; 0.029 sec/batch; 0h:13m:32s remains)
INFO - root - 2022-02-24 21:11:48.750999: step 171370, total loss = 0.54, batch loss = 0.29 (252.4 examples/sec; 0.032 sec/batch; 0h:14m:51s remains)
INFO - root - 2022-02-24 21:11:49.140051: step 171380, total loss = 0.69, batch loss = 0.44 (240.2 examples/sec; 0.033 sec/batch; 0h:15m:36s remains)
INFO - root - 2022-02-24 21:11:49.538422: step 171390, total loss = 0.45, batch loss = 0.20 (231.8 examples/sec; 0.035 sec/batch; 0h:16m:10s remains)
INFO - root - 2022-02-24 21:11:49.977637: step 171400, total loss = 0.61, batch loss = 0.36 (275.4 examples/sec; 0.029 sec/batch; 0h:13m:36s remains)
INFO - root - 2022-02-24 21:11:50.510648: step 171410, total loss = 0.49, batch loss = 0.23 (354.0 examples/sec; 0.023 sec/batch; 0h:10m:34s remains)
INFO - root - 2022-02-24 21:11:50.919175: step 171420, total loss = 0.62, batch loss = 0.36 (321.8 examples/sec; 0.025 sec/batch; 0h:11m:38s remains)
INFO - root - 2022-02-24 21:11:51.436350: step 171430, total loss = 0.53, batch loss = 0.28 (100.9 examples/sec; 0.079 sec/batch; 0h:37m:05s remains)
INFO - root - 2022-02-24 21:11:51.986344: step 171440, total loss = 0.69, batch loss = 0.43 (151.8 examples/sec; 0.053 sec/batch; 0h:24m:38s remains)
INFO - root - 2022-02-24 21:11:52.966787: step 171450, total loss = 0.58, batch loss = 0.32 (18.6 examples/sec; 0.431 sec/batch; 3h:21m:20s remains)
INFO - root - 2022-02-24 21:11:53.305690: step 171460, total loss = 0.61, batch loss = 0.35 (351.2 examples/sec; 0.023 sec/batch; 0h:10m:38s remains)
INFO - root - 2022-02-24 21:11:53.648945: step 171470, total loss = 0.51, batch loss = 0.25 (346.7 examples/sec; 0.023 sec/batch; 0h:10m:46s remains)
INFO - root - 2022-02-24 21:11:54.134163: step 171480, total loss = 0.53, batch loss = 0.28 (164.4 examples/sec; 0.049 sec/batch; 0h:22m:43s remains)
INFO - root - 2022-02-24 21:11:54.665002: step 171490, total loss = 0.48, batch loss = 0.23 (99.1 examples/sec; 0.081 sec/batch; 0h:37m:41s remains)
INFO - root - 2022-02-24 21:11:55.014834: step 171500, total loss = 0.48, batch loss = 0.22 (204.1 examples/sec; 0.039 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:11:55.451501: step 171510, total loss = 0.73, batch loss = 0.47 (268.6 examples/sec; 0.030 sec/batch; 0h:13m:53s remains)
INFO - root - 2022-02-24 21:11:55.889371: step 171520, total loss = 0.54, batch loss = 0.28 (130.8 examples/sec; 0.061 sec/batch; 0h:28m:31s remains)
INFO - root - 2022-02-24 21:11:56.385586: step 171530, total loss = 0.55, batch loss = 0.29 (153.6 examples/sec; 0.052 sec/batch; 0h:24m:17s remains)
INFO - root - 2022-02-24 21:11:56.740250: step 171540, total loss = 0.57, batch loss = 0.32 (225.8 examples/sec; 0.035 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:11:57.079685: step 171550, total loss = 0.43, batch loss = 0.17 (262.1 examples/sec; 0.031 sec/batch; 0h:14m:13s remains)
INFO - root - 2022-02-24 21:11:57.416976: step 171560, total loss = 0.54, batch loss = 0.28 (161.3 examples/sec; 0.050 sec/batch; 0h:23m:05s remains)
INFO - root - 2022-02-24 21:11:57.716864: step 171570, total loss = 0.50, batch loss = 0.25 (328.7 examples/sec; 0.024 sec/batch; 0h:11m:19s remains)
INFO - root - 2022-02-24 21:11:58.188435: step 171580, total loss = 0.58, batch loss = 0.33 (333.8 examples/sec; 0.024 sec/batch; 0h:11m:09s remains)
INFO - root - 2022-02-24 21:11:58.529549: step 171590, total loss = 0.47, batch loss = 0.21 (179.1 examples/sec; 0.045 sec/batch; 0h:20m:46s remains)
INFO - root - 2022-02-24 21:11:58.894298: step 171600, total loss = 0.57, batch loss = 0.32 (247.6 examples/sec; 0.032 sec/batch; 0h:15m:01s remains)
INFO - root - 2022-02-24 21:11:59.274384: step 171610, total loss = 0.57, batch loss = 0.31 (308.4 examples/sec; 0.026 sec/batch; 0h:12m:03s remains)
INFO - root - 2022-02-24 21:11:59.534860: step 171620, total loss = 0.55, batch loss = 0.29 (346.7 examples/sec; 0.023 sec/batch; 0h:10m:43s remains)
INFO - root - 2022-02-24 21:11:59.929666: step 171630, total loss = 0.61, batch loss = 0.35 (323.1 examples/sec; 0.025 sec/batch; 0h:11m:30s remains)
INFO - root - 2022-02-24 21:12:00.366880: step 171640, total loss = 0.51, batch loss = 0.25 (223.1 examples/sec; 0.036 sec/batch; 0h:16m:39s remains)
INFO - root - 2022-02-24 21:12:00.738628: step 171650, total loss = 0.67, batch loss = 0.42 (291.5 examples/sec; 0.027 sec/batch; 0h:12m:44s remains)
INFO - root - 2022-02-24 21:12:01.122014: step 171660, total loss = 0.52, batch loss = 0.26 (166.3 examples/sec; 0.048 sec/batch; 0h:22m:19s remains)
INFO - root - 2022-02-24 21:12:01.425329: step 171670, total loss = 0.53, batch loss = 0.27 (290.9 examples/sec; 0.027 sec/batch; 0h:12m:45s remains)
INFO - root - 2022-02-24 21:12:01.889431: step 171680, total loss = 0.57, batch loss = 0.31 (319.5 examples/sec; 0.025 sec/batch; 0h:11m:36s remains)
INFO - root - 2022-02-24 21:12:02.349071: step 171690, total loss = 0.51, batch loss = 0.25 (147.5 examples/sec; 0.054 sec/batch; 0h:25m:08s remains)
INFO - root - 2022-02-24 21:12:02.860623: step 171700, total loss = 0.46, batch loss = 0.20 (311.2 examples/sec; 0.026 sec/batch; 0h:11m:54s remains)
INFO - root - 2022-02-24 21:12:03.379984: step 171710, total loss = 0.53, batch loss = 0.27 (188.7 examples/sec; 0.042 sec/batch; 0h:19m:37s remains)
INFO - root - 2022-02-24 21:12:03.902011: step 171720, total loss = 0.44, batch loss = 0.19 (147.5 examples/sec; 0.054 sec/batch; 0h:25m:07s remains)
INFO - root - 2022-02-24 21:12:04.295426: step 171730, total loss = 0.49, batch loss = 0.23 (136.9 examples/sec; 0.058 sec/batch; 0h:27m:02s remains)
INFO - root - 2022-02-24 21:12:04.630733: step 171740, total loss = 0.51, batch loss = 0.26 (261.7 examples/sec; 0.031 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:12:04.927394: step 171750, total loss = 0.51, batch loss = 0.25 (273.5 examples/sec; 0.029 sec/batch; 0h:13m:31s remains)
INFO - root - 2022-02-24 21:12:05.336832: step 171760, total loss = 0.46, batch loss = 0.21 (199.3 examples/sec; 0.040 sec/batch; 0h:18m:33s remains)
INFO - root - 2022-02-24 21:12:05.632307: step 171770, total loss = 0.52, batch loss = 0.27 (185.4 examples/sec; 0.043 sec/batch; 0h:19m:56s remains)
INFO - root - 2022-02-24 21:12:06.095701: step 171780, total loss = 0.54, batch loss = 0.29 (335.1 examples/sec; 0.024 sec/batch; 0h:11m:01s remains)
INFO - root - 2022-02-24 21:12:06.537808: step 171790, total loss = 0.62, batch loss = 0.36 (244.0 examples/sec; 0.033 sec/batch; 0h:15m:08s remains)
INFO - root - 2022-02-24 21:12:06.981677: step 171800, total loss = 0.58, batch loss = 0.32 (191.2 examples/sec; 0.042 sec/batch; 0h:19m:19s remains)
INFO - root - 2022-02-24 21:12:07.332653: step 171810, total loss = 0.60, batch loss = 0.34 (342.7 examples/sec; 0.023 sec/batch; 0h:10m:46s remains)
INFO - root - 2022-02-24 21:12:07.629257: step 171820, total loss = 0.47, batch loss = 0.22 (243.3 examples/sec; 0.033 sec/batch; 0h:15m:10s remains)
INFO - root - 2022-02-24 21:12:08.024028: step 171830, total loss = 0.52, batch loss = 0.26 (130.2 examples/sec; 0.061 sec/batch; 0h:28m:19s remains)
INFO - root - 2022-02-24 21:12:08.519899: step 171840, total loss = 0.52, batch loss = 0.26 (202.4 examples/sec; 0.040 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 21:12:08.980715: step 171850, total loss = 0.49, batch loss = 0.23 (236.0 examples/sec; 0.034 sec/batch; 0h:15m:37s remains)
INFO - root - 2022-02-24 21:12:09.386610: step 171860, total loss = 0.56, batch loss = 0.31 (292.4 examples/sec; 0.027 sec/batch; 0h:12m:36s remains)
INFO - root - 2022-02-24 21:12:09.695530: step 171870, total loss = 0.56, batch loss = 0.30 (331.1 examples/sec; 0.024 sec/batch; 0h:11m:07s remains)
INFO - root - 2022-02-24 21:12:09.999113: step 171880, total loss = 0.52, batch loss = 0.26 (237.9 examples/sec; 0.034 sec/batch; 0h:15m:28s remains)
INFO - root - 2022-02-24 21:12:10.280091: step 171890, total loss = 0.53, batch loss = 0.27 (315.0 examples/sec; 0.025 sec/batch; 0h:11m:41s remains)
INFO - root - 2022-02-24 21:12:10.674466: step 171900, total loss = 0.54, batch loss = 0.29 (321.1 examples/sec; 0.025 sec/batch; 0h:11m:27s remains)
INFO - root - 2022-02-24 21:12:11.172374: step 171910, total loss = 0.53, batch loss = 0.28 (147.8 examples/sec; 0.054 sec/batch; 0h:24m:52s remains)
INFO - root - 2022-02-24 21:12:11.666453: step 171920, total loss = 0.56, batch loss = 0.30 (199.8 examples/sec; 0.040 sec/batch; 0h:18m:24s remains)
INFO - root - 2022-02-24 21:12:12.014524: step 171930, total loss = 0.52, batch loss = 0.26 (148.6 examples/sec; 0.054 sec/batch; 0h:24m:44s remains)
INFO - root - 2022-02-24 21:12:12.347310: step 171940, total loss = 0.49, batch loss = 0.24 (209.2 examples/sec; 0.038 sec/batch; 0h:17m:33s remains)
INFO - root - 2022-02-24 21:12:12.698821: step 171950, total loss = 0.45, batch loss = 0.20 (340.5 examples/sec; 0.023 sec/batch; 0h:10m:47s remains)
INFO - root - 2022-02-24 21:12:13.034674: step 171960, total loss = 0.59, batch loss = 0.34 (317.2 examples/sec; 0.025 sec/batch; 0h:11m:34s remains)
INFO - root - 2022-02-24 21:12:13.482298: step 171970, total loss = 0.61, batch loss = 0.35 (224.7 examples/sec; 0.036 sec/batch; 0h:16m:20s remains)
INFO - root - 2022-02-24 21:12:13.827478: step 171980, total loss = 0.56, batch loss = 0.31 (317.0 examples/sec; 0.025 sec/batch; 0h:11m:34s remains)
INFO - root - 2022-02-24 21:12:14.130813: step 171990, total loss = 0.53, batch loss = 0.28 (261.5 examples/sec; 0.031 sec/batch; 0h:14m:01s remains)
INFO - root - 2022-02-24 21:12:14.445314: step 172000, total loss = 0.49, batch loss = 0.23 (254.9 examples/sec; 0.031 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:12:14.873643: step 172010, total loss = 0.50, batch loss = 0.24 (72.3 examples/sec; 0.111 sec/batch; 0h:50m:43s remains)
INFO - root - 2022-02-24 21:12:15.221183: step 172020, total loss = 0.58, batch loss = 0.32 (173.1 examples/sec; 0.046 sec/batch; 0h:21m:09s remains)
INFO - root - 2022-02-24 21:12:15.678135: step 172030, total loss = 0.49, batch loss = 0.23 (236.1 examples/sec; 0.034 sec/batch; 0h:15m:30s remains)
INFO - root - 2022-02-24 21:12:16.054887: step 172040, total loss = 0.50, batch loss = 0.25 (385.1 examples/sec; 0.021 sec/batch; 0h:09m:30s remains)
INFO - root - 2022-02-24 21:12:16.349907: step 172050, total loss = 0.53, batch loss = 0.27 (370.9 examples/sec; 0.022 sec/batch; 0h:09m:52s remains)
INFO - root - 2022-02-24 21:12:16.761096: step 172060, total loss = 0.56, batch loss = 0.30 (136.9 examples/sec; 0.058 sec/batch; 0h:26m:43s remains)
INFO - root - 2022-02-24 21:12:17.216809: step 172070, total loss = 0.58, batch loss = 0.33 (155.0 examples/sec; 0.052 sec/batch; 0h:23m:35s remains)
INFO - root - 2022-02-24 21:12:17.549932: step 172080, total loss = 0.49, batch loss = 0.24 (306.2 examples/sec; 0.026 sec/batch; 0h:11m:56s remains)
INFO - root - 2022-02-24 21:12:17.836694: step 172090, total loss = 0.52, batch loss = 0.27 (332.8 examples/sec; 0.024 sec/batch; 0h:10m:58s remains)
INFO - root - 2022-02-24 21:12:18.165891: step 172100, total loss = 0.63, batch loss = 0.37 (333.4 examples/sec; 0.024 sec/batch; 0h:10m:57s remains)
INFO - root - 2022-02-24 21:12:18.638209: step 172110, total loss = 0.62, batch loss = 0.36 (316.5 examples/sec; 0.025 sec/batch; 0h:11m:32s remains)
INFO - root - 2022-02-24 21:12:19.036759: step 172120, total loss = 0.52, batch loss = 0.27 (147.0 examples/sec; 0.054 sec/batch; 0h:24m:49s remains)
INFO - root - 2022-02-24 21:12:19.467207: step 172130, total loss = 0.56, batch loss = 0.30 (339.7 examples/sec; 0.024 sec/batch; 0h:10m:44s remains)
INFO - root - 2022-02-24 21:12:19.747921: step 172140, total loss = 0.46, batch loss = 0.21 (268.1 examples/sec; 0.030 sec/batch; 0h:13m:36s remains)
INFO - root - 2022-02-24 21:12:20.098131: step 172150, total loss = 0.51, batch loss = 0.25 (144.2 examples/sec; 0.055 sec/batch; 0h:25m:16s remains)
INFO - root - 2022-02-24 21:12:20.382643: step 172160, total loss = 0.60, batch loss = 0.35 (322.3 examples/sec; 0.025 sec/batch; 0h:11m:18s remains)
INFO - root - 2022-02-24 21:12:20.773346: step 172170, total loss = 0.59, batch loss = 0.34 (202.8 examples/sec; 0.039 sec/batch; 0h:17m:58s remains)
INFO - root - 2022-02-24 21:12:21.209757: step 172180, total loss = 0.68, batch loss = 0.42 (210.9 examples/sec; 0.038 sec/batch; 0h:17m:16s remains)
INFO - root - 2022-02-24 21:12:21.651844: step 172190, total loss = 0.43, batch loss = 0.18 (151.8 examples/sec; 0.053 sec/batch; 0h:23m:59s remains)
INFO - root - 2022-02-24 21:12:22.063632: step 172200, total loss = 0.56, batch loss = 0.31 (230.8 examples/sec; 0.035 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:12:22.430549: step 172210, total loss = 0.47, batch loss = 0.21 (185.3 examples/sec; 0.043 sec/batch; 0h:19m:38s remains)
INFO - root - 2022-02-24 21:12:22.763902: step 172220, total loss = 0.56, batch loss = 0.30 (333.3 examples/sec; 0.024 sec/batch; 0h:10m:54s remains)
INFO - root - 2022-02-24 21:12:23.096619: step 172230, total loss = 0.45, batch loss = 0.19 (298.4 examples/sec; 0.027 sec/batch; 0h:12m:11s remains)
INFO - root - 2022-02-24 21:12:23.632577: step 172240, total loss = 0.58, batch loss = 0.32 (160.0 examples/sec; 0.050 sec/batch; 0h:22m:42s remains)
INFO - root - 2022-02-24 21:12:24.004020: step 172250, total loss = 0.47, batch loss = 0.22 (345.1 examples/sec; 0.023 sec/batch; 0h:10m:31s remains)
INFO - root - 2022-02-24 21:12:24.374719: step 172260, total loss = 0.58, batch loss = 0.33 (208.6 examples/sec; 0.038 sec/batch; 0h:17m:24s remains)
INFO - root - 2022-02-24 21:12:24.770093: step 172270, total loss = 0.52, batch loss = 0.26 (103.0 examples/sec; 0.078 sec/batch; 0h:35m:14s remains)
INFO - root - 2022-02-24 21:12:25.155519: step 172280, total loss = 0.68, batch loss = 0.42 (329.0 examples/sec; 0.024 sec/batch; 0h:11m:01s remains)
INFO - root - 2022-02-24 21:12:25.593827: step 172290, total loss = 0.59, batch loss = 0.33 (111.7 examples/sec; 0.072 sec/batch; 0h:32m:28s remains)
INFO - root - 2022-02-24 21:12:26.115079: step 172300, total loss = 0.53, batch loss = 0.27 (122.1 examples/sec; 0.066 sec/batch; 0h:29m:42s remains)
INFO - root - 2022-02-24 21:12:26.552582: step 172310, total loss = 0.69, batch loss = 0.43 (304.6 examples/sec; 0.026 sec/batch; 0h:11m:54s remains)
INFO - root - 2022-02-24 21:12:26.976389: step 172320, total loss = 0.51, batch loss = 0.25 (159.6 examples/sec; 0.050 sec/batch; 0h:22m:42s remains)
INFO - root - 2022-02-24 21:12:27.572578: step 172330, total loss = 0.49, batch loss = 0.24 (163.7 examples/sec; 0.049 sec/batch; 0h:22m:07s remains)
INFO - root - 2022-02-24 21:12:28.152911: step 172340, total loss = 0.51, batch loss = 0.26 (159.1 examples/sec; 0.050 sec/batch; 0h:22m:45s remains)
INFO - root - 2022-02-24 21:12:29.099115: step 172350, total loss = 0.55, batch loss = 0.30 (177.3 examples/sec; 0.045 sec/batch; 0h:20m:25s remains)
INFO - root - 2022-02-24 21:12:29.526795: step 172360, total loss = 0.53, batch loss = 0.28 (107.2 examples/sec; 0.075 sec/batch; 0h:33m:44s remains)
INFO - root - 2022-02-24 21:12:30.001743: step 172370, total loss = 0.52, batch loss = 0.26 (256.1 examples/sec; 0.031 sec/batch; 0h:14m:07s remains)
INFO - root - 2022-02-24 21:12:30.533353: step 172380, total loss = 0.48, batch loss = 0.22 (153.0 examples/sec; 0.052 sec/batch; 0h:23m:38s remains)
INFO - root - 2022-02-24 21:12:30.827535: step 172390, total loss = 0.55, batch loss = 0.29 (300.2 examples/sec; 0.027 sec/batch; 0h:12m:02s remains)
INFO - root - 2022-02-24 21:12:31.207154: step 172400, total loss = 0.54, batch loss = 0.28 (220.4 examples/sec; 0.036 sec/batch; 0h:16m:23s remains)
INFO - root - 2022-02-24 21:12:31.626223: step 172410, total loss = 0.62, batch loss = 0.36 (285.4 examples/sec; 0.028 sec/batch; 0h:12m:39s remains)
INFO - root - 2022-02-24 21:12:32.067792: step 172420, total loss = 0.58, batch loss = 0.32 (139.9 examples/sec; 0.057 sec/batch; 0h:25m:48s remains)
INFO - root - 2022-02-24 21:12:32.421309: step 172430, total loss = 0.56, batch loss = 0.31 (271.6 examples/sec; 0.029 sec/batch; 0h:13m:17s remains)
INFO - root - 2022-02-24 21:12:32.778971: step 172440, total loss = 0.57, batch loss = 0.31 (109.1 examples/sec; 0.073 sec/batch; 0h:33m:03s remains)
INFO - root - 2022-02-24 21:12:33.095312: step 172450, total loss = 0.51, batch loss = 0.26 (247.1 examples/sec; 0.032 sec/batch; 0h:14m:35s remains)
INFO - root - 2022-02-24 21:12:33.439021: step 172460, total loss = 0.48, batch loss = 0.22 (270.8 examples/sec; 0.030 sec/batch; 0h:13m:18s remains)
INFO - root - 2022-02-24 21:12:34.034799: step 172470, total loss = 0.49, batch loss = 0.24 (191.8 examples/sec; 0.042 sec/batch; 0h:18m:47s remains)
INFO - root - 2022-02-24 21:12:34.440263: step 172480, total loss = 0.49, batch loss = 0.24 (234.7 examples/sec; 0.034 sec/batch; 0h:15m:20s remains)
INFO - root - 2022-02-24 21:12:34.778745: step 172490, total loss = 0.54, batch loss = 0.28 (289.4 examples/sec; 0.028 sec/batch; 0h:12m:26s remains)
INFO - root - 2022-02-24 21:12:35.104797: step 172500, total loss = 0.47, batch loss = 0.21 (339.5 examples/sec; 0.024 sec/batch; 0h:10m:36s remains)
INFO - root - 2022-02-24 21:12:35.482861: step 172510, total loss = 0.49, batch loss = 0.24 (329.0 examples/sec; 0.024 sec/batch; 0h:10m:56s remains)
INFO - root - 2022-02-24 21:12:35.738952: step 172520, total loss = 0.49, batch loss = 0.24 (338.1 examples/sec; 0.024 sec/batch; 0h:10m:38s remains)
INFO - root - 2022-02-24 21:12:36.110737: step 172530, total loss = 0.50, batch loss = 0.24 (324.7 examples/sec; 0.025 sec/batch; 0h:11m:04s remains)
INFO - root - 2022-02-24 21:12:36.529152: step 172540, total loss = 0.47, batch loss = 0.22 (171.3 examples/sec; 0.047 sec/batch; 0h:20m:59s remains)
INFO - root - 2022-02-24 21:12:36.855314: step 172550, total loss = 0.52, batch loss = 0.27 (350.1 examples/sec; 0.023 sec/batch; 0h:10m:15s remains)
INFO - root - 2022-02-24 21:12:37.194200: step 172560, total loss = 0.47, batch loss = 0.22 (341.6 examples/sec; 0.023 sec/batch; 0h:10m:31s remains)
INFO - root - 2022-02-24 21:12:37.525201: step 172570, total loss = 0.61, batch loss = 0.36 (197.9 examples/sec; 0.040 sec/batch; 0h:18m:08s remains)
INFO - root - 2022-02-24 21:12:37.874734: step 172580, total loss = 0.63, batch loss = 0.38 (357.5 examples/sec; 0.022 sec/batch; 0h:10m:02s remains)
INFO - root - 2022-02-24 21:12:38.289372: step 172590, total loss = 0.60, batch loss = 0.35 (325.7 examples/sec; 0.025 sec/batch; 0h:11m:00s remains)
INFO - root - 2022-02-24 21:12:38.771407: step 172600, total loss = 0.48, batch loss = 0.22 (118.2 examples/sec; 0.068 sec/batch; 0h:30m:20s remains)
INFO - root - 2022-02-24 21:12:39.149175: step 172610, total loss = 0.50, batch loss = 0.24 (301.7 examples/sec; 0.027 sec/batch; 0h:11m:52s remains)
INFO - root - 2022-02-24 21:12:39.479366: step 172620, total loss = 0.47, batch loss = 0.22 (208.6 examples/sec; 0.038 sec/batch; 0h:17m:10s remains)
INFO - root - 2022-02-24 21:12:39.767751: step 172630, total loss = 0.66, batch loss = 0.41 (321.4 examples/sec; 0.025 sec/batch; 0h:11m:08s remains)
INFO - root - 2022-02-24 21:12:40.101695: step 172640, total loss = 0.72, batch loss = 0.47 (100.7 examples/sec; 0.079 sec/batch; 0h:35m:34s remains)
INFO - root - 2022-02-24 21:12:40.494908: step 172650, total loss = 0.73, batch loss = 0.47 (244.2 examples/sec; 0.033 sec/batch; 0h:14m:39s remains)
INFO - root - 2022-02-24 21:12:40.845143: step 172660, total loss = 0.63, batch loss = 0.38 (126.8 examples/sec; 0.063 sec/batch; 0h:28m:13s remains)
INFO - root - 2022-02-24 21:12:41.204409: step 172670, total loss = 0.53, batch loss = 0.27 (218.7 examples/sec; 0.037 sec/batch; 0h:16m:21s remains)
INFO - root - 2022-02-24 21:12:41.555692: step 172680, total loss = 0.56, batch loss = 0.30 (142.6 examples/sec; 0.056 sec/batch; 0h:25m:04s remains)
INFO - root - 2022-02-24 21:12:41.864676: step 172690, total loss = 0.57, batch loss = 0.31 (136.2 examples/sec; 0.059 sec/batch; 0h:26m:14s remains)
INFO - root - 2022-02-24 21:12:42.262023: step 172700, total loss = 0.52, batch loss = 0.26 (340.2 examples/sec; 0.024 sec/batch; 0h:10m:30s remains)
INFO - root - 2022-02-24 21:12:42.755029: step 172710, total loss = 0.56, batch loss = 0.30 (321.5 examples/sec; 0.025 sec/batch; 0h:11m:06s remains)
INFO - root - 2022-02-24 21:12:43.056518: step 172720, total loss = 0.60, batch loss = 0.34 (363.0 examples/sec; 0.022 sec/batch; 0h:09m:50s remains)
INFO - root - 2022-02-24 21:12:43.402423: step 172730, total loss = 0.55, batch loss = 0.29 (319.4 examples/sec; 0.025 sec/batch; 0h:11m:10s remains)
INFO - root - 2022-02-24 21:12:43.733982: step 172740, total loss = 0.62, batch loss = 0.36 (302.7 examples/sec; 0.026 sec/batch; 0h:11m:47s remains)
INFO - root - 2022-02-24 21:12:44.284309: step 172750, total loss = 0.56, batch loss = 0.31 (146.1 examples/sec; 0.055 sec/batch; 0h:24m:24s remains)
INFO - root - 2022-02-24 21:12:44.713311: step 172760, total loss = 0.57, batch loss = 0.32 (243.6 examples/sec; 0.033 sec/batch; 0h:14m:38s remains)
INFO - root - 2022-02-24 21:12:45.049999: step 172770, total loss = 0.52, batch loss = 0.26 (312.4 examples/sec; 0.026 sec/batch; 0h:11m:24s remains)
INFO - root - 2022-02-24 21:12:45.289730: step 172780, total loss = 0.50, batch loss = 0.25 (341.3 examples/sec; 0.023 sec/batch; 0h:10m:26s remains)
INFO - root - 2022-02-24 21:12:45.685536: step 172790, total loss = 0.51, batch loss = 0.26 (328.2 examples/sec; 0.024 sec/batch; 0h:10m:50s remains)
INFO - root - 2022-02-24 21:12:45.942913: step 172800, total loss = 0.66, batch loss = 0.41 (272.7 examples/sec; 0.029 sec/batch; 0h:13m:03s remains)
INFO - root - 2022-02-24 21:12:46.320835: step 172810, total loss = 0.49, batch loss = 0.23 (329.0 examples/sec; 0.024 sec/batch; 0h:10m:48s remains)
INFO - root - 2022-02-24 21:12:46.698262: step 172820, total loss = 0.58, batch loss = 0.33 (167.7 examples/sec; 0.048 sec/batch; 0h:21m:13s remains)
INFO - root - 2022-02-24 21:12:47.114408: step 172830, total loss = 0.58, batch loss = 0.32 (264.5 examples/sec; 0.030 sec/batch; 0h:13m:26s remains)
INFO - root - 2022-02-24 21:12:47.490205: step 172840, total loss = 0.56, batch loss = 0.30 (196.8 examples/sec; 0.041 sec/batch; 0h:18m:03s remains)
INFO - root - 2022-02-24 21:12:47.802376: step 172850, total loss = 0.54, batch loss = 0.28 (335.5 examples/sec; 0.024 sec/batch; 0h:10m:35s remains)
INFO - root - 2022-02-24 21:12:48.120624: step 172860, total loss = 0.53, batch loss = 0.27 (330.2 examples/sec; 0.024 sec/batch; 0h:10m:45s remains)
INFO - root - 2022-02-24 21:12:48.576608: step 172870, total loss = 0.64, batch loss = 0.39 (126.3 examples/sec; 0.063 sec/batch; 0h:28m:06s remains)
INFO - root - 2022-02-24 21:12:48.978380: step 172880, total loss = 0.64, batch loss = 0.38 (211.7 examples/sec; 0.038 sec/batch; 0h:16m:45s remains)
INFO - root - 2022-02-24 21:12:49.342243: step 172890, total loss = 0.53, batch loss = 0.27 (256.1 examples/sec; 0.031 sec/batch; 0h:13m:51s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-172899 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-172899 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:12:49.970412: step 172900, total loss = 0.59, batch loss = 0.34 (311.4 examples/sec; 0.026 sec/batch; 0h:11m:23s remains)
INFO - root - 2022-02-24 21:12:50.327937: step 172910, total loss = 0.57, batch loss = 0.31 (363.6 examples/sec; 0.022 sec/batch; 0h:09m:45s remains)
INFO - root - 2022-02-24 21:12:50.650278: step 172920, total loss = 0.60, batch loss = 0.35 (221.3 examples/sec; 0.036 sec/batch; 0h:16m:00s remains)
INFO - root - 2022-02-24 21:12:51.084549: step 172930, total loss = 0.48, batch loss = 0.22 (175.6 examples/sec; 0.046 sec/batch; 0h:20m:10s remains)
INFO - root - 2022-02-24 21:12:51.448837: step 172940, total loss = 0.74, batch loss = 0.48 (204.1 examples/sec; 0.039 sec/batch; 0h:17m:20s remains)
INFO - root - 2022-02-24 21:12:51.766987: step 172950, total loss = 0.57, batch loss = 0.31 (301.8 examples/sec; 0.027 sec/batch; 0h:11m:43s remains)
INFO - root - 2022-02-24 21:12:52.058763: step 172960, total loss = 0.55, batch loss = 0.29 (205.2 examples/sec; 0.039 sec/batch; 0h:17m:14s remains)
INFO - root - 2022-02-24 21:12:52.459812: step 172970, total loss = 0.49, batch loss = 0.24 (169.2 examples/sec; 0.047 sec/batch; 0h:20m:54s remains)
INFO - root - 2022-02-24 21:12:52.801698: step 172980, total loss = 0.65, batch loss = 0.39 (354.6 examples/sec; 0.023 sec/batch; 0h:09m:58s remains)
INFO - root - 2022-02-24 21:12:53.244449: step 172990, total loss = 0.53, batch loss = 0.27 (337.9 examples/sec; 0.024 sec/batch; 0h:10m:27s remains)
INFO - root - 2022-02-24 21:12:53.558579: step 173000, total loss = 0.64, batch loss = 0.38 (354.5 examples/sec; 0.023 sec/batch; 0h:09m:57s remains)
INFO - root - 2022-02-24 21:12:53.973109: step 173010, total loss = 0.67, batch loss = 0.42 (243.9 examples/sec; 0.033 sec/batch; 0h:14m:28s remains)
INFO - root - 2022-02-24 21:12:54.248088: step 173020, total loss = 0.51, batch loss = 0.25 (334.3 examples/sec; 0.024 sec/batch; 0h:10m:33s remains)
INFO - root - 2022-02-24 21:12:54.590036: step 173030, total loss = 0.52, batch loss = 0.26 (352.7 examples/sec; 0.023 sec/batch; 0h:10m:00s remains)
INFO - root - 2022-02-24 21:12:55.075934: step 173040, total loss = 0.57, batch loss = 0.31 (113.8 examples/sec; 0.070 sec/batch; 0h:31m:00s remains)
INFO - root - 2022-02-24 21:12:55.466894: step 173050, total loss = 0.55, batch loss = 0.30 (197.6 examples/sec; 0.040 sec/batch; 0h:17m:50s remains)
INFO - root - 2022-02-24 21:12:55.862274: step 173060, total loss = 0.51, batch loss = 0.26 (299.2 examples/sec; 0.027 sec/batch; 0h:11m:46s remains)
INFO - root - 2022-02-24 21:12:56.293486: step 173070, total loss = 0.49, batch loss = 0.24 (141.3 examples/sec; 0.057 sec/batch; 0h:24m:56s remains)
INFO - root - 2022-02-24 21:12:56.707709: step 173080, total loss = 0.60, batch loss = 0.34 (182.0 examples/sec; 0.044 sec/batch; 0h:19m:21s remains)
INFO - root - 2022-02-24 21:12:57.075325: step 173090, total loss = 0.44, batch loss = 0.18 (197.7 examples/sec; 0.040 sec/batch; 0h:17m:48s remains)
INFO - root - 2022-02-24 21:12:57.565651: step 173100, total loss = 0.46, batch loss = 0.20 (128.3 examples/sec; 0.062 sec/batch; 0h:27m:25s remains)
INFO - root - 2022-02-24 21:12:58.072503: step 173110, total loss = 0.51, batch loss = 0.25 (245.4 examples/sec; 0.033 sec/batch; 0h:14m:20s remains)
INFO - root - 2022-02-24 21:12:58.512973: step 173120, total loss = 0.49, batch loss = 0.23 (349.1 examples/sec; 0.023 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:12:59.575367: step 173130, total loss = 0.51, batch loss = 0.26 (107.5 examples/sec; 0.074 sec/batch; 0h:32m:41s remains)
INFO - root - 2022-02-24 21:13:00.015326: step 173140, total loss = 0.53, batch loss = 0.27 (179.1 examples/sec; 0.045 sec/batch; 0h:19m:37s remains)
INFO - root - 2022-02-24 21:13:00.419962: step 173150, total loss = 0.53, batch loss = 0.27 (281.3 examples/sec; 0.028 sec/batch; 0h:12m:29s remains)
INFO - root - 2022-02-24 21:13:00.779321: step 173160, total loss = 0.55, batch loss = 0.29 (233.8 examples/sec; 0.034 sec/batch; 0h:15m:01s remains)
INFO - root - 2022-02-24 21:13:01.138436: step 173170, total loss = 0.49, batch loss = 0.23 (159.8 examples/sec; 0.050 sec/batch; 0h:21m:57s remains)
INFO - root - 2022-02-24 21:13:01.422827: step 173180, total loss = 0.65, batch loss = 0.40 (305.1 examples/sec; 0.026 sec/batch; 0h:11m:30s remains)
INFO - root - 2022-02-24 21:13:01.899299: step 173190, total loss = 0.63, batch loss = 0.37 (140.0 examples/sec; 0.057 sec/batch; 0h:25m:02s remains)
INFO - root - 2022-02-24 21:13:02.290971: step 173200, total loss = 0.64, batch loss = 0.39 (305.1 examples/sec; 0.026 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:13:02.676340: step 173210, total loss = 0.45, batch loss = 0.19 (185.5 examples/sec; 0.043 sec/batch; 0h:18m:53s remains)
INFO - root - 2022-02-24 21:13:02.986722: step 173220, total loss = 0.48, batch loss = 0.22 (312.4 examples/sec; 0.026 sec/batch; 0h:11m:12s remains)
INFO - root - 2022-02-24 21:13:03.576238: step 173230, total loss = 0.53, batch loss = 0.27 (126.0 examples/sec; 0.064 sec/batch; 0h:27m:48s remains)
INFO - root - 2022-02-24 21:13:04.117293: step 173240, total loss = 0.44, batch loss = 0.18 (172.2 examples/sec; 0.046 sec/batch; 0h:20m:19s remains)
INFO - root - 2022-02-24 21:13:04.640728: step 173250, total loss = 0.52, batch loss = 0.26 (107.9 examples/sec; 0.074 sec/batch; 0h:32m:26s remains)
INFO - root - 2022-02-24 21:13:04.964551: step 173260, total loss = 0.51, batch loss = 0.26 (331.1 examples/sec; 0.024 sec/batch; 0h:10m:33s remains)
INFO - root - 2022-02-24 21:13:05.262268: step 173270, total loss = 0.58, batch loss = 0.32 (233.0 examples/sec; 0.034 sec/batch; 0h:15m:00s remains)
INFO - root - 2022-02-24 21:13:05.656785: step 173280, total loss = 0.57, batch loss = 0.32 (261.8 examples/sec; 0.031 sec/batch; 0h:13m:21s remains)
INFO - root - 2022-02-24 21:13:06.063114: step 173290, total loss = 0.50, batch loss = 0.24 (159.1 examples/sec; 0.050 sec/batch; 0h:21m:57s remains)
INFO - root - 2022-02-24 21:13:06.479766: step 173300, total loss = 0.59, batch loss = 0.34 (216.8 examples/sec; 0.037 sec/batch; 0h:16m:06s remains)
INFO - root - 2022-02-24 21:13:06.926010: step 173310, total loss = 0.58, batch loss = 0.33 (189.4 examples/sec; 0.042 sec/batch; 0h:18m:25s remains)
INFO - root - 2022-02-24 21:13:07.288002: step 173320, total loss = 0.53, batch loss = 0.27 (326.5 examples/sec; 0.025 sec/batch; 0h:10m:41s remains)
INFO - root - 2022-02-24 21:13:07.607185: step 173330, total loss = 0.54, batch loss = 0.28 (227.8 examples/sec; 0.035 sec/batch; 0h:15m:19s remains)
INFO - root - 2022-02-24 21:13:07.951959: step 173340, total loss = 0.55, batch loss = 0.29 (325.2 examples/sec; 0.025 sec/batch; 0h:10m:43s remains)
INFO - root - 2022-02-24 21:13:08.311816: step 173350, total loss = 0.56, batch loss = 0.30 (201.4 examples/sec; 0.040 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:13:08.758818: step 173360, total loss = 0.55, batch loss = 0.29 (272.5 examples/sec; 0.029 sec/batch; 0h:12m:47s remains)
INFO - root - 2022-02-24 21:13:09.141061: step 173370, total loss = 0.59, batch loss = 0.33 (94.1 examples/sec; 0.085 sec/batch; 0h:37m:01s remains)
INFO - root - 2022-02-24 21:13:09.444349: step 173380, total loss = 0.54, batch loss = 0.29 (334.8 examples/sec; 0.024 sec/batch; 0h:10m:24s remains)
INFO - root - 2022-02-24 21:13:09.789943: step 173390, total loss = 0.61, batch loss = 0.35 (205.7 examples/sec; 0.039 sec/batch; 0h:16m:55s remains)
INFO - root - 2022-02-24 21:13:10.135398: step 173400, total loss = 0.60, batch loss = 0.34 (159.3 examples/sec; 0.050 sec/batch; 0h:21m:50s remains)
INFO - root - 2022-02-24 21:13:10.537853: step 173410, total loss = 0.53, batch loss = 0.27 (221.1 examples/sec; 0.036 sec/batch; 0h:15m:44s remains)
INFO - root - 2022-02-24 21:13:11.013755: step 173420, total loss = 0.50, batch loss = 0.25 (109.6 examples/sec; 0.073 sec/batch; 0h:31m:44s remains)
INFO - root - 2022-02-24 21:13:11.394532: step 173430, total loss = 0.56, batch loss = 0.31 (329.6 examples/sec; 0.024 sec/batch; 0h:10m:32s remains)
INFO - root - 2022-02-24 21:13:11.735455: step 173440, total loss = 0.46, batch loss = 0.20 (155.8 examples/sec; 0.051 sec/batch; 0h:22m:18s remains)
INFO - root - 2022-02-24 21:13:12.085972: step 173450, total loss = 0.47, batch loss = 0.22 (262.4 examples/sec; 0.030 sec/batch; 0h:13m:14s remains)
INFO - root - 2022-02-24 21:13:12.486102: step 173460, total loss = 0.45, batch loss = 0.20 (353.6 examples/sec; 0.023 sec/batch; 0h:09m:49s remains)
INFO - root - 2022-02-24 21:13:12.947943: step 173470, total loss = 0.59, batch loss = 0.34 (101.3 examples/sec; 0.079 sec/batch; 0h:34m:16s remains)
INFO - root - 2022-02-24 21:13:13.285728: step 173480, total loss = 0.59, batch loss = 0.33 (296.7 examples/sec; 0.027 sec/batch; 0h:11m:41s remains)
INFO - root - 2022-02-24 21:13:13.573788: step 173490, total loss = 0.52, batch loss = 0.27 (178.6 examples/sec; 0.045 sec/batch; 0h:19m:24s remains)
INFO - root - 2022-02-24 21:13:13.914051: step 173500, total loss = 0.55, batch loss = 0.29 (133.1 examples/sec; 0.060 sec/batch; 0h:26m:03s remains)
INFO - root - 2022-02-24 21:13:14.302823: step 173510, total loss = 0.66, batch loss = 0.40 (316.4 examples/sec; 0.025 sec/batch; 0h:10m:57s remains)
INFO - root - 2022-02-24 21:13:14.735117: step 173520, total loss = 0.52, batch loss = 0.27 (96.1 examples/sec; 0.083 sec/batch; 0h:36m:01s remains)
INFO - root - 2022-02-24 21:13:15.128819: step 173530, total loss = 0.54, batch loss = 0.28 (318.3 examples/sec; 0.025 sec/batch; 0h:10m:52s remains)
INFO - root - 2022-02-24 21:13:15.493506: step 173540, total loss = 0.61, batch loss = 0.36 (299.6 examples/sec; 0.027 sec/batch; 0h:11m:33s remains)
INFO - root - 2022-02-24 21:13:15.850060: step 173550, total loss = 0.51, batch loss = 0.26 (278.8 examples/sec; 0.029 sec/batch; 0h:12m:24s remains)
INFO - root - 2022-02-24 21:13:16.108558: step 173560, total loss = 0.55, batch loss = 0.30 (366.9 examples/sec; 0.022 sec/batch; 0h:09m:25s remains)
INFO - root - 2022-02-24 21:13:16.381076: step 173570, total loss = 0.46, batch loss = 0.21 (332.5 examples/sec; 0.024 sec/batch; 0h:10m:23s remains)
INFO - root - 2022-02-24 21:13:16.738267: step 173580, total loss = 0.55, batch loss = 0.29 (332.8 examples/sec; 0.024 sec/batch; 0h:10m:23s remains)
INFO - root - 2022-02-24 21:13:17.100422: step 173590, total loss = 0.51, batch loss = 0.25 (232.4 examples/sec; 0.034 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:13:17.479808: step 173600, total loss = 0.54, batch loss = 0.28 (346.8 examples/sec; 0.023 sec/batch; 0h:09m:57s remains)
INFO - root - 2022-02-24 21:13:17.895145: step 173610, total loss = 0.55, batch loss = 0.29 (192.2 examples/sec; 0.042 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:13:18.249241: step 173620, total loss = 0.61, batch loss = 0.35 (229.9 examples/sec; 0.035 sec/batch; 0h:15m:00s remains)
INFO - root - 2022-02-24 21:13:18.532793: step 173630, total loss = 0.45, batch loss = 0.20 (255.5 examples/sec; 0.031 sec/batch; 0h:13m:30s remains)
INFO - root - 2022-02-24 21:13:18.899854: step 173640, total loss = 0.52, batch loss = 0.26 (218.6 examples/sec; 0.037 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:13:19.318469: step 173650, total loss = 0.52, batch loss = 0.26 (233.3 examples/sec; 0.034 sec/batch; 0h:14m:46s remains)
INFO - root - 2022-02-24 21:13:19.688337: step 173660, total loss = 0.58, batch loss = 0.32 (291.0 examples/sec; 0.027 sec/batch; 0h:11m:50s remains)
INFO - root - 2022-02-24 21:13:20.065830: step 173670, total loss = 0.60, batch loss = 0.35 (183.5 examples/sec; 0.044 sec/batch; 0h:18m:46s remains)
INFO - root - 2022-02-24 21:13:20.401804: step 173680, total loss = 0.50, batch loss = 0.25 (316.2 examples/sec; 0.025 sec/batch; 0h:10m:53s remains)
INFO - root - 2022-02-24 21:13:20.847925: step 173690, total loss = 0.47, batch loss = 0.22 (197.5 examples/sec; 0.041 sec/batch; 0h:17m:25s remains)
INFO - root - 2022-02-24 21:13:21.188405: step 173700, total loss = 0.52, batch loss = 0.26 (194.8 examples/sec; 0.041 sec/batch; 0h:17m:39s remains)
INFO - root - 2022-02-24 21:13:21.603886: step 173710, total loss = 0.53, batch loss = 0.27 (136.8 examples/sec; 0.058 sec/batch; 0h:25m:08s remains)
INFO - root - 2022-02-24 21:13:21.941210: step 173720, total loss = 0.56, batch loss = 0.30 (140.0 examples/sec; 0.057 sec/batch; 0h:24m:33s remains)
INFO - root - 2022-02-24 21:13:22.275822: step 173730, total loss = 0.48, batch loss = 0.23 (252.0 examples/sec; 0.032 sec/batch; 0h:13m:38s remains)
INFO - root - 2022-02-24 21:13:22.579373: step 173740, total loss = 0.61, batch loss = 0.36 (326.2 examples/sec; 0.025 sec/batch; 0h:10m:31s remains)
INFO - root - 2022-02-24 21:13:22.876850: step 173750, total loss = 0.53, batch loss = 0.27 (173.9 examples/sec; 0.046 sec/batch; 0h:19m:44s remains)
INFO - root - 2022-02-24 21:13:23.291883: step 173760, total loss = 0.50, batch loss = 0.25 (174.3 examples/sec; 0.046 sec/batch; 0h:19m:41s remains)
INFO - root - 2022-02-24 21:13:23.714654: step 173770, total loss = 0.48, batch loss = 0.22 (183.8 examples/sec; 0.044 sec/batch; 0h:18m:40s remains)
INFO - root - 2022-02-24 21:13:24.033637: step 173780, total loss = 0.54, batch loss = 0.28 (293.2 examples/sec; 0.027 sec/batch; 0h:11m:41s remains)
INFO - root - 2022-02-24 21:13:24.326017: step 173790, total loss = 0.48, batch loss = 0.23 (219.2 examples/sec; 0.037 sec/batch; 0h:15m:38s remains)
INFO - root - 2022-02-24 21:13:24.611035: step 173800, total loss = 0.65, batch loss = 0.39 (203.1 examples/sec; 0.039 sec/batch; 0h:16m:52s remains)
INFO - root - 2022-02-24 21:13:25.049074: step 173810, total loss = 0.59, batch loss = 0.33 (230.3 examples/sec; 0.035 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:13:25.440298: step 173820, total loss = 0.58, batch loss = 0.33 (356.8 examples/sec; 0.022 sec/batch; 0h:09m:35s remains)
INFO - root - 2022-02-24 21:13:25.816236: step 173830, total loss = 0.60, batch loss = 0.35 (152.8 examples/sec; 0.052 sec/batch; 0h:22m:23s remains)
INFO - root - 2022-02-24 21:13:26.171237: step 173840, total loss = 0.52, batch loss = 0.26 (339.1 examples/sec; 0.024 sec/batch; 0h:10m:05s remains)
INFO - root - 2022-02-24 21:13:26.474801: step 173850, total loss = 0.53, batch loss = 0.27 (236.5 examples/sec; 0.034 sec/batch; 0h:14m:27s remains)
INFO - root - 2022-02-24 21:13:26.789104: step 173860, total loss = 0.59, batch loss = 0.34 (225.4 examples/sec; 0.035 sec/batch; 0h:15m:10s remains)
INFO - root - 2022-02-24 21:13:27.192878: step 173870, total loss = 0.61, batch loss = 0.35 (239.6 examples/sec; 0.033 sec/batch; 0h:14m:15s remains)
INFO - root - 2022-02-24 21:13:27.624042: step 173880, total loss = 0.50, batch loss = 0.24 (103.2 examples/sec; 0.077 sec/batch; 0h:33m:05s remains)
INFO - root - 2022-02-24 21:13:27.910949: step 173890, total loss = 0.53, batch loss = 0.28 (342.4 examples/sec; 0.023 sec/batch; 0h:09m:58s remains)
INFO - root - 2022-02-24 21:13:28.236804: step 173900, total loss = 0.55, batch loss = 0.29 (322.4 examples/sec; 0.025 sec/batch; 0h:10m:35s remains)
INFO - root - 2022-02-24 21:13:28.618476: step 173910, total loss = 0.55, batch loss = 0.29 (249.4 examples/sec; 0.032 sec/batch; 0h:13m:40s remains)
INFO - root - 2022-02-24 21:13:28.970868: step 173920, total loss = 0.68, batch loss = 0.42 (133.1 examples/sec; 0.060 sec/batch; 0h:25m:37s remains)
INFO - root - 2022-02-24 21:13:29.412417: step 173930, total loss = 0.42, batch loss = 0.16 (141.3 examples/sec; 0.057 sec/batch; 0h:24m:08s remains)
INFO - root - 2022-02-24 21:13:29.778272: step 173940, total loss = 0.54, batch loss = 0.28 (208.0 examples/sec; 0.038 sec/batch; 0h:16m:23s remains)
INFO - root - 2022-02-24 21:13:30.114670: step 173950, total loss = 0.83, batch loss = 0.57 (215.6 examples/sec; 0.037 sec/batch; 0h:15m:47s remains)
INFO - root - 2022-02-24 21:13:30.420167: step 173960, total loss = 0.65, batch loss = 0.39 (339.5 examples/sec; 0.024 sec/batch; 0h:10m:01s remains)
INFO - root - 2022-02-24 21:13:30.743856: step 173970, total loss = 0.55, batch loss = 0.29 (179.3 examples/sec; 0.045 sec/batch; 0h:18m:59s remains)
INFO - root - 2022-02-24 21:13:31.243196: step 173980, total loss = 0.56, batch loss = 0.30 (173.0 examples/sec; 0.046 sec/batch; 0h:19m:40s remains)
INFO - root - 2022-02-24 21:13:31.612461: step 173990, total loss = 0.51, batch loss = 0.25 (152.6 examples/sec; 0.052 sec/batch; 0h:22m:17s remains)
INFO - root - 2022-02-24 21:13:31.955368: step 174000, total loss = 0.51, batch loss = 0.26 (319.7 examples/sec; 0.025 sec/batch; 0h:10m:38s remains)
INFO - root - 2022-02-24 21:13:32.311502: step 174010, total loss = 0.47, batch loss = 0.22 (398.9 examples/sec; 0.020 sec/batch; 0h:08m:31s remains)
INFO - root - 2022-02-24 21:13:32.603085: step 174020, total loss = 0.52, batch loss = 0.27 (332.4 examples/sec; 0.024 sec/batch; 0h:10m:13s remains)
INFO - root - 2022-02-24 21:13:32.936761: step 174030, total loss = 0.58, batch loss = 0.33 (312.0 examples/sec; 0.026 sec/batch; 0h:10m:53s remains)
INFO - root - 2022-02-24 21:13:33.360112: step 174040, total loss = 0.53, batch loss = 0.27 (121.0 examples/sec; 0.066 sec/batch; 0h:28m:02s remains)
INFO - root - 2022-02-24 21:13:33.687222: step 174050, total loss = 0.49, batch loss = 0.24 (264.8 examples/sec; 0.030 sec/batch; 0h:12m:48s remains)
INFO - root - 2022-02-24 21:13:34.083030: step 174060, total loss = 0.53, batch loss = 0.27 (279.4 examples/sec; 0.029 sec/batch; 0h:12m:08s remains)
INFO - root - 2022-02-24 21:13:34.505255: step 174070, total loss = 0.67, batch loss = 0.41 (208.9 examples/sec; 0.038 sec/batch; 0h:16m:13s remains)
INFO - root - 2022-02-24 21:13:35.667045: step 174080, total loss = 0.49, batch loss = 0.23 (106.5 examples/sec; 0.075 sec/batch; 0h:31m:50s remains)
INFO - root - 2022-02-24 21:13:36.082579: step 174090, total loss = 0.51, batch loss = 0.25 (169.7 examples/sec; 0.047 sec/batch; 0h:19m:57s remains)
INFO - root - 2022-02-24 21:13:36.436902: step 174100, total loss = 0.45, batch loss = 0.20 (137.2 examples/sec; 0.058 sec/batch; 0h:24m:40s remains)
INFO - root - 2022-02-24 21:13:36.854464: step 174110, total loss = 0.46, batch loss = 0.21 (196.3 examples/sec; 0.041 sec/batch; 0h:17m:14s remains)
INFO - root - 2022-02-24 21:13:37.326899: step 174120, total loss = 0.52, batch loss = 0.26 (174.6 examples/sec; 0.046 sec/batch; 0h:19m:22s remains)
INFO - root - 2022-02-24 21:13:37.809682: step 174130, total loss = 0.50, batch loss = 0.24 (199.8 examples/sec; 0.040 sec/batch; 0h:16m:56s remains)
INFO - root - 2022-02-24 21:13:38.366980: step 174140, total loss = 0.59, batch loss = 0.33 (134.1 examples/sec; 0.060 sec/batch; 0h:25m:12s remains)
INFO - root - 2022-02-24 21:13:38.855539: step 174150, total loss = 0.56, batch loss = 0.30 (170.1 examples/sec; 0.047 sec/batch; 0h:19m:51s remains)
INFO - root - 2022-02-24 21:13:39.156793: step 174160, total loss = 0.54, batch loss = 0.29 (296.4 examples/sec; 0.027 sec/batch; 0h:11m:23s remains)
INFO - root - 2022-02-24 21:13:39.580002: step 174170, total loss = 0.69, batch loss = 0.44 (339.0 examples/sec; 0.024 sec/batch; 0h:09m:57s remains)
INFO - root - 2022-02-24 21:13:40.114782: step 174180, total loss = 0.57, batch loss = 0.31 (132.1 examples/sec; 0.061 sec/batch; 0h:25m:32s remains)
INFO - root - 2022-02-24 21:13:40.502161: step 174190, total loss = 0.49, batch loss = 0.23 (204.2 examples/sec; 0.039 sec/batch; 0h:16m:31s remains)
INFO - root - 2022-02-24 21:13:41.160185: step 174200, total loss = 0.68, batch loss = 0.42 (81.9 examples/sec; 0.098 sec/batch; 0h:41m:10s remains)
INFO - root - 2022-02-24 21:13:41.574874: step 174210, total loss = 0.49, batch loss = 0.23 (181.2 examples/sec; 0.044 sec/batch; 0h:18m:36s remains)
INFO - root - 2022-02-24 21:13:41.969975: step 174220, total loss = 0.59, batch loss = 0.33 (304.1 examples/sec; 0.026 sec/batch; 0h:11m:05s remains)
INFO - root - 2022-02-24 21:13:42.366775: step 174230, total loss = 0.47, batch loss = 0.21 (194.7 examples/sec; 0.041 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:13:42.688783: step 174240, total loss = 0.51, batch loss = 0.26 (182.0 examples/sec; 0.044 sec/batch; 0h:18m:30s remains)
INFO - root - 2022-02-24 21:13:43.008833: step 174250, total loss = 0.56, batch loss = 0.30 (341.3 examples/sec; 0.023 sec/batch; 0h:09m:51s remains)
INFO - root - 2022-02-24 21:13:43.341370: step 174260, total loss = 0.52, batch loss = 0.26 (332.6 examples/sec; 0.024 sec/batch; 0h:10m:07s remains)
INFO - root - 2022-02-24 21:13:43.659640: step 174270, total loss = 0.53, batch loss = 0.27 (290.0 examples/sec; 0.028 sec/batch; 0h:11m:36s remains)
INFO - root - 2022-02-24 21:13:44.006967: step 174280, total loss = 0.62, batch loss = 0.36 (208.1 examples/sec; 0.038 sec/batch; 0h:16m:09s remains)
INFO - root - 2022-02-24 21:13:44.349295: step 174290, total loss = 0.47, batch loss = 0.22 (319.3 examples/sec; 0.025 sec/batch; 0h:10m:31s remains)
INFO - root - 2022-02-24 21:13:44.694089: step 174300, total loss = 0.61, batch loss = 0.36 (330.1 examples/sec; 0.024 sec/batch; 0h:10m:10s remains)
INFO - root - 2022-02-24 21:13:45.107394: step 174310, total loss = 0.52, batch loss = 0.26 (335.7 examples/sec; 0.024 sec/batch; 0h:10m:00s remains)
INFO - root - 2022-02-24 21:13:45.417460: step 174320, total loss = 0.52, batch loss = 0.26 (368.8 examples/sec; 0.022 sec/batch; 0h:09m:06s remains)
INFO - root - 2022-02-24 21:13:45.753600: step 174330, total loss = 0.61, batch loss = 0.36 (195.1 examples/sec; 0.041 sec/batch; 0h:17m:11s remains)
INFO - root - 2022-02-24 21:13:46.250507: step 174340, total loss = 0.52, batch loss = 0.27 (180.8 examples/sec; 0.044 sec/batch; 0h:18m:33s remains)
INFO - root - 2022-02-24 21:13:46.599159: step 174350, total loss = 0.50, batch loss = 0.24 (306.7 examples/sec; 0.026 sec/batch; 0h:10m:56s remains)
INFO - root - 2022-02-24 21:13:46.941116: step 174360, total loss = 0.48, batch loss = 0.22 (176.5 examples/sec; 0.045 sec/batch; 0h:18m:59s remains)
INFO - root - 2022-02-24 21:13:47.252991: step 174370, total loss = 0.61, batch loss = 0.35 (234.5 examples/sec; 0.034 sec/batch; 0h:14m:17s remains)
INFO - root - 2022-02-24 21:13:47.594888: step 174380, total loss = 0.47, batch loss = 0.21 (232.0 examples/sec; 0.034 sec/batch; 0h:14m:26s remains)
INFO - root - 2022-02-24 21:13:47.925938: step 174390, total loss = 0.61, batch loss = 0.35 (361.7 examples/sec; 0.022 sec/batch; 0h:09m:15s remains)
INFO - root - 2022-02-24 21:13:48.326519: step 174400, total loss = 0.54, batch loss = 0.28 (132.5 examples/sec; 0.060 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 21:13:48.743624: step 174410, total loss = 0.53, batch loss = 0.27 (236.8 examples/sec; 0.034 sec/batch; 0h:14m:07s remains)
INFO - root - 2022-02-24 21:13:49.058714: step 174420, total loss = 0.63, batch loss = 0.37 (171.4 examples/sec; 0.047 sec/batch; 0h:19m:30s remains)
INFO - root - 2022-02-24 21:13:49.377762: step 174430, total loss = 0.59, batch loss = 0.33 (222.7 examples/sec; 0.036 sec/batch; 0h:15m:00s remains)
INFO - root - 2022-02-24 21:13:49.729864: step 174440, total loss = 0.60, batch loss = 0.34 (246.8 examples/sec; 0.032 sec/batch; 0h:13m:32s remains)
INFO - root - 2022-02-24 21:13:50.133602: step 174450, total loss = 0.57, batch loss = 0.32 (130.2 examples/sec; 0.061 sec/batch; 0h:25m:39s remains)
INFO - root - 2022-02-24 21:13:50.498546: step 174460, total loss = 0.55, batch loss = 0.29 (175.0 examples/sec; 0.046 sec/batch; 0h:19m:04s remains)
INFO - root - 2022-02-24 21:13:50.967645: step 174470, total loss = 0.48, batch loss = 0.23 (246.0 examples/sec; 0.033 sec/batch; 0h:13m:34s remains)
INFO - root - 2022-02-24 21:13:51.307025: step 174480, total loss = 0.53, batch loss = 0.28 (177.3 examples/sec; 0.045 sec/batch; 0h:18m:48s remains)
INFO - root - 2022-02-24 21:13:51.679408: step 174490, total loss = 0.53, batch loss = 0.27 (236.6 examples/sec; 0.034 sec/batch; 0h:14m:05s remains)
INFO - root - 2022-02-24 21:13:51.980268: step 174500, total loss = 0.50, batch loss = 0.25 (309.2 examples/sec; 0.026 sec/batch; 0h:10m:46s remains)
INFO - root - 2022-02-24 21:13:52.526652: step 174510, total loss = 0.55, batch loss = 0.29 (305.7 examples/sec; 0.026 sec/batch; 0h:10m:53s remains)
INFO - root - 2022-02-24 21:13:52.935312: step 174520, total loss = 0.51, batch loss = 0.25 (202.3 examples/sec; 0.040 sec/batch; 0h:16m:27s remains)
INFO - root - 2022-02-24 21:13:53.302008: step 174530, total loss = 0.49, batch loss = 0.23 (212.1 examples/sec; 0.038 sec/batch; 0h:15m:42s remains)
INFO - root - 2022-02-24 21:13:53.608731: step 174540, total loss = 0.53, batch loss = 0.27 (339.5 examples/sec; 0.024 sec/batch; 0h:09m:48s remains)
INFO - root - 2022-02-24 21:13:53.958476: step 174550, total loss = 0.51, batch loss = 0.25 (226.8 examples/sec; 0.035 sec/batch; 0h:14m:39s remains)
INFO - root - 2022-02-24 21:13:54.363612: step 174560, total loss = 0.52, batch loss = 0.27 (274.9 examples/sec; 0.029 sec/batch; 0h:12m:05s remains)
INFO - root - 2022-02-24 21:13:54.832643: step 174570, total loss = 0.54, batch loss = 0.28 (219.7 examples/sec; 0.036 sec/batch; 0h:15m:07s remains)
INFO - root - 2022-02-24 21:13:55.183922: step 174580, total loss = 0.65, batch loss = 0.40 (344.3 examples/sec; 0.023 sec/batch; 0h:09m:39s remains)
INFO - root - 2022-02-24 21:13:55.510182: step 174590, total loss = 0.58, batch loss = 0.32 (315.2 examples/sec; 0.025 sec/batch; 0h:10m:32s remains)
INFO - root - 2022-02-24 21:13:55.854753: step 174600, total loss = 0.54, batch loss = 0.29 (311.2 examples/sec; 0.026 sec/batch; 0h:10m:40s remains)
INFO - root - 2022-02-24 21:13:56.344298: step 174610, total loss = 0.63, batch loss = 0.37 (117.9 examples/sec; 0.068 sec/batch; 0h:28m:08s remains)
INFO - root - 2022-02-24 21:13:56.706674: step 174620, total loss = 0.52, batch loss = 0.26 (255.0 examples/sec; 0.031 sec/batch; 0h:13m:00s remains)
INFO - root - 2022-02-24 21:13:57.048267: step 174630, total loss = 0.56, batch loss = 0.30 (287.6 examples/sec; 0.028 sec/batch; 0h:11m:31s remains)
INFO - root - 2022-02-24 21:13:57.417781: step 174640, total loss = 0.50, batch loss = 0.24 (211.6 examples/sec; 0.038 sec/batch; 0h:15m:39s remains)
INFO - root - 2022-02-24 21:13:57.690097: step 174650, total loss = 0.64, batch loss = 0.39 (310.0 examples/sec; 0.026 sec/batch; 0h:10m:41s remains)
INFO - root - 2022-02-24 21:13:58.067807: step 174660, total loss = 0.52, batch loss = 0.26 (229.3 examples/sec; 0.035 sec/batch; 0h:14m:26s remains)
INFO - root - 2022-02-24 21:13:58.393804: step 174670, total loss = 0.48, batch loss = 0.22 (195.4 examples/sec; 0.041 sec/batch; 0h:16m:56s remains)
INFO - root - 2022-02-24 21:13:58.791481: step 174680, total loss = 0.55, batch loss = 0.29 (171.7 examples/sec; 0.047 sec/batch; 0h:19m:16s remains)
INFO - root - 2022-02-24 21:13:59.260592: step 174690, total loss = 0.49, batch loss = 0.24 (322.6 examples/sec; 0.025 sec/batch; 0h:10m:15s remains)
INFO - root - 2022-02-24 21:13:59.593825: step 174700, total loss = 0.63, batch loss = 0.38 (330.7 examples/sec; 0.024 sec/batch; 0h:10m:00s remains)
INFO - root - 2022-02-24 21:13:59.999618: step 174710, total loss = 0.55, batch loss = 0.30 (257.6 examples/sec; 0.031 sec/batch; 0h:12m:49s remains)
INFO - root - 2022-02-24 21:14:00.323297: step 174720, total loss = 0.54, batch loss = 0.29 (221.7 examples/sec; 0.036 sec/batch; 0h:14m:54s remains)
INFO - root - 2022-02-24 21:14:00.735518: step 174730, total loss = 0.53, batch loss = 0.27 (138.3 examples/sec; 0.058 sec/batch; 0h:23m:52s remains)
INFO - root - 2022-02-24 21:14:01.145060: step 174740, total loss = 0.52, batch loss = 0.26 (214.5 examples/sec; 0.037 sec/batch; 0h:15m:23s remains)
INFO - root - 2022-02-24 21:14:01.570051: step 174750, total loss = 0.53, batch loss = 0.27 (182.4 examples/sec; 0.044 sec/batch; 0h:18m:05s remains)
INFO - root - 2022-02-24 21:14:01.947983: step 174760, total loss = 0.47, batch loss = 0.21 (175.8 examples/sec; 0.046 sec/batch; 0h:18m:45s remains)
INFO - root - 2022-02-24 21:14:02.270637: step 174770, total loss = 0.60, batch loss = 0.35 (321.0 examples/sec; 0.025 sec/batch; 0h:10m:16s remains)
INFO - root - 2022-02-24 21:14:02.602196: step 174780, total loss = 0.64, batch loss = 0.38 (286.2 examples/sec; 0.028 sec/batch; 0h:11m:30s remains)
INFO - root - 2022-02-24 21:14:03.106822: step 174790, total loss = 0.59, batch loss = 0.34 (212.4 examples/sec; 0.038 sec/batch; 0h:15m:30s remains)
INFO - root - 2022-02-24 21:14:03.489596: step 174800, total loss = 0.56, batch loss = 0.31 (343.8 examples/sec; 0.023 sec/batch; 0h:09m:34s remains)
INFO - root - 2022-02-24 21:14:03.871575: step 174810, total loss = 0.52, batch loss = 0.27 (232.9 examples/sec; 0.034 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:14:04.144341: step 174820, total loss = 0.48, batch loss = 0.22 (329.6 examples/sec; 0.024 sec/batch; 0h:09m:59s remains)
INFO - root - 2022-02-24 21:14:04.462481: step 174830, total loss = 0.53, batch loss = 0.27 (247.4 examples/sec; 0.032 sec/batch; 0h:13m:17s remains)
INFO - root - 2022-02-24 21:14:04.791444: step 174840, total loss = 0.54, batch loss = 0.28 (307.0 examples/sec; 0.026 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:14:05.229686: step 174850, total loss = 0.48, batch loss = 0.22 (253.6 examples/sec; 0.032 sec/batch; 0h:12m:57s remains)
INFO - root - 2022-02-24 21:14:05.572477: step 174860, total loss = 0.50, batch loss = 0.24 (330.1 examples/sec; 0.024 sec/batch; 0h:09m:57s remains)
INFO - root - 2022-02-24 21:14:05.857596: step 174870, total loss = 0.54, batch loss = 0.29 (341.3 examples/sec; 0.023 sec/batch; 0h:09m:37s remains)
INFO - root - 2022-02-24 21:14:06.144838: step 174880, total loss = 0.56, batch loss = 0.31 (124.7 examples/sec; 0.064 sec/batch; 0h:26m:19s remains)
INFO - root - 2022-02-24 21:14:06.493641: step 174890, total loss = 0.71, batch loss = 0.45 (327.5 examples/sec; 0.024 sec/batch; 0h:10m:01s remains)
INFO - root - 2022-02-24 21:14:06.896205: step 174900, total loss = 0.46, batch loss = 0.21 (146.2 examples/sec; 0.055 sec/batch; 0h:22m:26s remains)
INFO - root - 2022-02-24 21:14:07.378414: step 174910, total loss = 0.51, batch loss = 0.26 (214.8 examples/sec; 0.037 sec/batch; 0h:15m:15s remains)
INFO - root - 2022-02-24 21:14:07.821347: step 174920, total loss = 0.45, batch loss = 0.19 (97.6 examples/sec; 0.082 sec/batch; 0h:33m:35s remains)
INFO - root - 2022-02-24 21:14:08.199730: step 174930, total loss = 0.40, batch loss = 0.14 (314.6 examples/sec; 0.025 sec/batch; 0h:10m:24s remains)
INFO - root - 2022-02-24 21:14:08.536026: step 174940, total loss = 0.46, batch loss = 0.21 (323.0 examples/sec; 0.025 sec/batch; 0h:10m:08s remains)
INFO - root - 2022-02-24 21:14:08.823035: step 174950, total loss = 0.54, batch loss = 0.28 (350.5 examples/sec; 0.023 sec/batch; 0h:09m:20s remains)
INFO - root - 2022-02-24 21:14:09.144147: step 174960, total loss = 0.52, batch loss = 0.26 (289.6 examples/sec; 0.028 sec/batch; 0h:11m:17s remains)
INFO - root - 2022-02-24 21:14:09.643589: step 174970, total loss = 0.45, batch loss = 0.19 (334.1 examples/sec; 0.024 sec/batch; 0h:09m:47s remains)
INFO - root - 2022-02-24 21:14:10.121064: step 174980, total loss = 0.53, batch loss = 0.27 (354.3 examples/sec; 0.023 sec/batch; 0h:09m:13s remains)
INFO - root - 2022-02-24 21:14:10.547732: step 174990, total loss = 0.63, batch loss = 0.37 (238.8 examples/sec; 0.033 sec/batch; 0h:13m:41s remains)
INFO - root - 2022-02-24 21:14:11.084000: step 175000, total loss = 0.47, batch loss = 0.22 (90.6 examples/sec; 0.088 sec/batch; 0h:36m:03s remains)
INFO - root - 2022-02-24 21:14:12.067537: step 175010, total loss = 0.51, batch loss = 0.25 (189.6 examples/sec; 0.042 sec/batch; 0h:17m:13s remains)
INFO - root - 2022-02-24 21:14:12.454948: step 175020, total loss = 0.53, batch loss = 0.27 (171.3 examples/sec; 0.047 sec/batch; 0h:19m:03s remains)
INFO - root - 2022-02-24 21:14:12.919482: step 175030, total loss = 0.50, batch loss = 0.24 (308.9 examples/sec; 0.026 sec/batch; 0h:10m:33s remains)
INFO - root - 2022-02-24 21:14:13.344262: step 175040, total loss = 0.53, batch loss = 0.27 (143.0 examples/sec; 0.056 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 21:14:13.893524: step 175050, total loss = 0.52, batch loss = 0.26 (255.0 examples/sec; 0.031 sec/batch; 0h:12m:47s remains)
INFO - root - 2022-02-24 21:14:14.322469: step 175060, total loss = 0.51, batch loss = 0.25 (172.9 examples/sec; 0.046 sec/batch; 0h:18m:50s remains)
INFO - root - 2022-02-24 21:14:14.683330: step 175070, total loss = 0.57, batch loss = 0.31 (270.8 examples/sec; 0.030 sec/batch; 0h:12m:01s remains)
INFO - root - 2022-02-24 21:14:15.035273: step 175080, total loss = 0.56, batch loss = 0.30 (263.8 examples/sec; 0.030 sec/batch; 0h:12m:20s remains)
INFO - root - 2022-02-24 21:14:15.427667: step 175090, total loss = 0.53, batch loss = 0.28 (157.3 examples/sec; 0.051 sec/batch; 0h:20m:41s remains)
INFO - root - 2022-02-24 21:14:15.906775: step 175100, total loss = 0.50, batch loss = 0.25 (119.4 examples/sec; 0.067 sec/batch; 0h:27m:14s remains)
INFO - root - 2022-02-24 21:14:16.869327: step 175110, total loss = 0.53, batch loss = 0.28 (359.6 examples/sec; 0.022 sec/batch; 0h:09m:02s remains)
INFO - root - 2022-02-24 21:14:17.144882: step 175120, total loss = 0.65, batch loss = 0.39 (345.3 examples/sec; 0.023 sec/batch; 0h:09m:24s remains)
INFO - root - 2022-02-24 21:14:17.414779: step 175130, total loss = 0.51, batch loss = 0.26 (360.0 examples/sec; 0.022 sec/batch; 0h:09m:01s remains)
INFO - root - 2022-02-24 21:14:17.722180: step 175140, total loss = 0.55, batch loss = 0.29 (191.6 examples/sec; 0.042 sec/batch; 0h:16m:57s remains)
INFO - root - 2022-02-24 21:14:18.037979: step 175150, total loss = 0.43, batch loss = 0.17 (240.3 examples/sec; 0.033 sec/batch; 0h:13m:30s remains)
INFO - root - 2022-02-24 21:14:18.356666: step 175160, total loss = 0.57, batch loss = 0.31 (147.2 examples/sec; 0.054 sec/batch; 0h:22m:02s remains)
INFO - root - 2022-02-24 21:14:18.790073: step 175170, total loss = 0.54, batch loss = 0.29 (229.3 examples/sec; 0.035 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:14:19.161983: step 175180, total loss = 0.57, batch loss = 0.31 (327.0 examples/sec; 0.024 sec/batch; 0h:09m:55s remains)
INFO - root - 2022-02-24 21:14:19.473265: step 175190, total loss = 0.53, batch loss = 0.27 (358.4 examples/sec; 0.022 sec/batch; 0h:09m:02s remains)
INFO - root - 2022-02-24 21:14:19.782547: step 175200, total loss = 0.53, batch loss = 0.27 (134.3 examples/sec; 0.060 sec/batch; 0h:24m:07s remains)
INFO - root - 2022-02-24 21:14:20.139805: step 175210, total loss = 0.74, batch loss = 0.48 (288.0 examples/sec; 0.028 sec/batch; 0h:11m:14s remains)
INFO - root - 2022-02-24 21:14:20.489440: step 175220, total loss = 0.55, batch loss = 0.29 (170.9 examples/sec; 0.047 sec/batch; 0h:18m:56s remains)
INFO - root - 2022-02-24 21:14:20.902963: step 175230, total loss = 0.59, batch loss = 0.33 (215.0 examples/sec; 0.037 sec/batch; 0h:15m:03s remains)
INFO - root - 2022-02-24 21:14:21.332713: step 175240, total loss = 0.50, batch loss = 0.24 (200.6 examples/sec; 0.040 sec/batch; 0h:16m:07s remains)
INFO - root - 2022-02-24 21:14:21.727499: step 175250, total loss = 0.56, batch loss = 0.30 (309.9 examples/sec; 0.026 sec/batch; 0h:10m:26s remains)
INFO - root - 2022-02-24 21:14:22.016090: step 175260, total loss = 0.55, batch loss = 0.30 (332.6 examples/sec; 0.024 sec/batch; 0h:09m:42s remains)
INFO - root - 2022-02-24 21:14:22.419420: step 175270, total loss = 0.63, batch loss = 0.37 (101.5 examples/sec; 0.079 sec/batch; 0h:31m:49s remains)
INFO - root - 2022-02-24 21:14:22.786821: step 175280, total loss = 0.60, batch loss = 0.35 (284.9 examples/sec; 0.028 sec/batch; 0h:11m:20s remains)
INFO - root - 2022-02-24 21:14:23.239908: step 175290, total loss = 0.51, batch loss = 0.25 (224.0 examples/sec; 0.036 sec/batch; 0h:14m:24s remains)
INFO - root - 2022-02-24 21:14:23.638651: step 175300, total loss = 0.48, batch loss = 0.22 (247.5 examples/sec; 0.032 sec/batch; 0h:13m:02s remains)
INFO - root - 2022-02-24 21:14:23.994001: step 175310, total loss = 0.52, batch loss = 0.27 (306.1 examples/sec; 0.026 sec/batch; 0h:10m:32s remains)
INFO - root - 2022-02-24 21:14:24.302469: step 175320, total loss = 0.53, batch loss = 0.28 (319.7 examples/sec; 0.025 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:14:24.639013: step 175330, total loss = 0.52, batch loss = 0.26 (270.5 examples/sec; 0.030 sec/batch; 0h:11m:54s remains)
INFO - root - 2022-02-24 21:14:25.044464: step 175340, total loss = 0.58, batch loss = 0.32 (349.2 examples/sec; 0.023 sec/batch; 0h:09m:13s remains)
INFO - root - 2022-02-24 21:14:25.447032: step 175350, total loss = 0.70, batch loss = 0.44 (128.3 examples/sec; 0.062 sec/batch; 0h:25m:05s remains)
INFO - root - 2022-02-24 21:14:25.730755: step 175360, total loss = 0.59, batch loss = 0.33 (311.2 examples/sec; 0.026 sec/batch; 0h:10m:20s remains)
INFO - root - 2022-02-24 21:14:26.035944: step 175370, total loss = 0.57, batch loss = 0.32 (341.6 examples/sec; 0.023 sec/batch; 0h:09m:25s remains)
INFO - root - 2022-02-24 21:14:26.355254: step 175380, total loss = 0.50, batch loss = 0.25 (319.3 examples/sec; 0.025 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:14:26.862000: step 175390, total loss = 0.57, batch loss = 0.31 (80.6 examples/sec; 0.099 sec/batch; 0h:39m:52s remains)
INFO - root - 2022-02-24 21:14:27.304797: step 175400, total loss = 0.55, batch loss = 0.30 (191.9 examples/sec; 0.042 sec/batch; 0h:16m:44s remains)
INFO - root - 2022-02-24 21:14:27.692124: step 175410, total loss = 0.58, batch loss = 0.33 (198.0 examples/sec; 0.040 sec/batch; 0h:16m:13s remains)
INFO - root - 2022-02-24 21:14:28.073493: step 175420, total loss = 0.60, batch loss = 0.34 (157.9 examples/sec; 0.051 sec/batch; 0h:20m:19s remains)
INFO - root - 2022-02-24 21:14:28.325101: step 175430, total loss = 0.54, batch loss = 0.28 (321.3 examples/sec; 0.025 sec/batch; 0h:09m:59s remains)
INFO - root - 2022-02-24 21:14:28.606503: step 175440, total loss = 0.50, batch loss = 0.24 (299.6 examples/sec; 0.027 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:14:29.107319: step 175450, total loss = 0.54, batch loss = 0.29 (135.2 examples/sec; 0.059 sec/batch; 0h:23m:42s remains)
INFO - root - 2022-02-24 21:14:29.459229: step 175460, total loss = 0.57, batch loss = 0.31 (279.3 examples/sec; 0.029 sec/batch; 0h:11m:28s remains)
INFO - root - 2022-02-24 21:14:29.869678: step 175470, total loss = 0.53, batch loss = 0.27 (134.8 examples/sec; 0.059 sec/batch; 0h:23m:46s remains)
INFO - root - 2022-02-24 21:14:30.205708: step 175480, total loss = 0.65, batch loss = 0.39 (225.1 examples/sec; 0.036 sec/batch; 0h:14m:13s remains)
INFO - root - 2022-02-24 21:14:30.521822: step 175490, total loss = 0.58, batch loss = 0.32 (350.1 examples/sec; 0.023 sec/batch; 0h:09m:08s remains)
INFO - root - 2022-02-24 21:14:30.793787: step 175500, total loss = 0.54, batch loss = 0.28 (333.7 examples/sec; 0.024 sec/batch; 0h:09m:35s remains)
INFO - root - 2022-02-24 21:14:31.228119: step 175510, total loss = 0.57, batch loss = 0.32 (186.3 examples/sec; 0.043 sec/batch; 0h:17m:10s remains)
INFO - root - 2022-02-24 21:14:31.571772: step 175520, total loss = 0.57, batch loss = 0.31 (142.5 examples/sec; 0.056 sec/batch; 0h:22m:25s remains)
INFO - root - 2022-02-24 21:14:31.916349: step 175530, total loss = 0.62, batch loss = 0.37 (323.1 examples/sec; 0.025 sec/batch; 0h:09m:53s remains)
INFO - root - 2022-02-24 21:14:32.332168: step 175540, total loss = 0.54, batch loss = 0.29 (216.1 examples/sec; 0.037 sec/batch; 0h:14m:47s remains)
INFO - root - 2022-02-24 21:14:32.649388: step 175550, total loss = 0.61, batch loss = 0.35 (184.0 examples/sec; 0.043 sec/batch; 0h:17m:21s remains)
INFO - root - 2022-02-24 21:14:33.024765: step 175560, total loss = 0.47, batch loss = 0.22 (165.1 examples/sec; 0.048 sec/batch; 0h:19m:19s remains)
INFO - root - 2022-02-24 21:14:33.433088: step 175570, total loss = 0.51, batch loss = 0.26 (229.1 examples/sec; 0.035 sec/batch; 0h:13m:55s remains)
INFO - root - 2022-02-24 21:14:33.784088: step 175580, total loss = 0.61, batch loss = 0.36 (145.5 examples/sec; 0.055 sec/batch; 0h:21m:55s remains)
INFO - root - 2022-02-24 21:14:34.070401: step 175590, total loss = 0.66, batch loss = 0.40 (379.1 examples/sec; 0.021 sec/batch; 0h:08m:24s remains)
INFO - root - 2022-02-24 21:14:34.421603: step 175600, total loss = 0.49, batch loss = 0.23 (327.0 examples/sec; 0.024 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:14:34.764845: step 175610, total loss = 0.49, batch loss = 0.23 (288.1 examples/sec; 0.028 sec/batch; 0h:11m:03s remains)
INFO - root - 2022-02-24 21:14:35.060156: step 175620, total loss = 0.57, batch loss = 0.31 (192.4 examples/sec; 0.042 sec/batch; 0h:16m:32s remains)
INFO - root - 2022-02-24 21:14:35.461361: step 175630, total loss = 0.47, batch loss = 0.22 (163.8 examples/sec; 0.049 sec/batch; 0h:19m:25s remains)
INFO - root - 2022-02-24 21:14:35.853328: step 175640, total loss = 0.56, batch loss = 0.31 (161.5 examples/sec; 0.050 sec/batch; 0h:19m:41s remains)
INFO - root - 2022-02-24 21:14:36.097777: step 175650, total loss = 0.50, batch loss = 0.25 (334.2 examples/sec; 0.024 sec/batch; 0h:09m:30s remains)
INFO - root - 2022-02-24 21:14:36.374462: step 175660, total loss = 0.56, batch loss = 0.30 (230.7 examples/sec; 0.035 sec/batch; 0h:13m:46s remains)
INFO - root - 2022-02-24 21:14:36.783735: step 175670, total loss = 0.66, batch loss = 0.41 (242.2 examples/sec; 0.033 sec/batch; 0h:13m:06s remains)
INFO - root - 2022-02-24 21:14:37.169743: step 175680, total loss = 0.57, batch loss = 0.32 (345.8 examples/sec; 0.023 sec/batch; 0h:09m:11s remains)
INFO - root - 2022-02-24 21:14:37.510269: step 175690, total loss = 0.47, batch loss = 0.21 (169.1 examples/sec; 0.047 sec/batch; 0h:18m:46s remains)
INFO - root - 2022-02-24 21:14:37.835740: step 175700, total loss = 0.53, batch loss = 0.27 (328.1 examples/sec; 0.024 sec/batch; 0h:09m:40s remains)
INFO - root - 2022-02-24 21:14:38.175218: step 175710, total loss = 0.53, batch loss = 0.28 (345.0 examples/sec; 0.023 sec/batch; 0h:09m:11s remains)
INFO - root - 2022-02-24 21:14:38.522937: step 175720, total loss = 0.50, batch loss = 0.24 (196.1 examples/sec; 0.041 sec/batch; 0h:16m:10s remains)
INFO - root - 2022-02-24 21:14:38.904472: step 175730, total loss = 0.59, batch loss = 0.33 (246.5 examples/sec; 0.032 sec/batch; 0h:12m:51s remains)
INFO - root - 2022-02-24 21:14:39.406007: step 175740, total loss = 0.50, batch loss = 0.24 (145.2 examples/sec; 0.055 sec/batch; 0h:21m:49s remains)
INFO - root - 2022-02-24 21:14:39.711654: step 175750, total loss = 0.56, batch loss = 0.30 (305.7 examples/sec; 0.026 sec/batch; 0h:10m:21s remains)
INFO - root - 2022-02-24 21:14:39.982905: step 175760, total loss = 0.57, batch loss = 0.31 (354.4 examples/sec; 0.023 sec/batch; 0h:08m:55s remains)
INFO - root - 2022-02-24 21:14:40.286876: step 175770, total loss = 0.57, batch loss = 0.32 (349.1 examples/sec; 0.023 sec/batch; 0h:09m:03s remains)
INFO - root - 2022-02-24 21:14:40.621972: step 175780, total loss = 0.50, batch loss = 0.24 (328.4 examples/sec; 0.024 sec/batch; 0h:09m:37s remains)
INFO - root - 2022-02-24 21:14:41.081719: step 175790, total loss = 0.54, batch loss = 0.29 (357.4 examples/sec; 0.022 sec/batch; 0h:08m:50s remains)
INFO - root - 2022-02-24 21:14:41.470972: step 175800, total loss = 0.57, batch loss = 0.32 (171.3 examples/sec; 0.047 sec/batch; 0h:18m:27s remains)
INFO - root - 2022-02-24 21:14:41.884299: step 175810, total loss = 0.49, batch loss = 0.23 (322.3 examples/sec; 0.025 sec/batch; 0h:09m:48s remains)
INFO - root - 2022-02-24 21:14:42.178108: step 175820, total loss = 0.51, batch loss = 0.26 (328.0 examples/sec; 0.024 sec/batch; 0h:09m:37s remains)
INFO - root - 2022-02-24 21:14:42.576443: step 175830, total loss = 0.55, batch loss = 0.30 (214.7 examples/sec; 0.037 sec/batch; 0h:14m:41s remains)
INFO - root - 2022-02-24 21:14:42.969273: step 175840, total loss = 0.55, batch loss = 0.29 (328.6 examples/sec; 0.024 sec/batch; 0h:09m:36s remains)
INFO - root - 2022-02-24 21:14:43.399415: step 175850, total loss = 0.54, batch loss = 0.28 (355.9 examples/sec; 0.022 sec/batch; 0h:08m:51s remains)
INFO - root - 2022-02-24 21:14:43.720342: step 175860, total loss = 0.48, batch loss = 0.23 (279.0 examples/sec; 0.029 sec/batch; 0h:11m:17s remains)
INFO - root - 2022-02-24 21:14:44.025003: step 175870, total loss = 0.53, batch loss = 0.28 (368.1 examples/sec; 0.022 sec/batch; 0h:08m:33s remains)
INFO - root - 2022-02-24 21:14:44.312020: step 175880, total loss = 0.52, batch loss = 0.26 (369.8 examples/sec; 0.022 sec/batch; 0h:08m:30s remains)
INFO - root - 2022-02-24 21:14:44.636298: step 175890, total loss = 0.53, batch loss = 0.28 (184.6 examples/sec; 0.043 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:14:45.080031: step 175900, total loss = 0.56, batch loss = 0.30 (138.5 examples/sec; 0.058 sec/batch; 0h:22m:42s remains)
INFO - root - 2022-02-24 21:14:45.635385: step 175910, total loss = 0.46, batch loss = 0.20 (107.9 examples/sec; 0.074 sec/batch; 0h:29m:09s remains)
INFO - root - 2022-02-24 21:14:45.984085: step 175920, total loss = 0.70, batch loss = 0.44 (257.5 examples/sec; 0.031 sec/batch; 0h:12m:12s remains)
INFO - root - 2022-02-24 21:14:46.419489: step 175930, total loss = 0.58, batch loss = 0.32 (205.0 examples/sec; 0.039 sec/batch; 0h:15m:19s remains)
INFO - root - 2022-02-24 21:14:47.364346: step 175940, total loss = 0.52, batch loss = 0.26 (206.9 examples/sec; 0.039 sec/batch; 0h:15m:11s remains)
INFO - root - 2022-02-24 21:14:47.719001: step 175950, total loss = 0.51, batch loss = 0.26 (279.9 examples/sec; 0.029 sec/batch; 0h:11m:13s remains)
INFO - root - 2022-02-24 21:14:48.137373: step 175960, total loss = 0.65, batch loss = 0.39 (248.9 examples/sec; 0.032 sec/batch; 0h:12m:36s remains)
INFO - root - 2022-02-24 21:14:48.541485: step 175970, total loss = 0.70, batch loss = 0.44 (260.3 examples/sec; 0.031 sec/batch; 0h:12m:03s remains)
INFO - root - 2022-02-24 21:14:48.929198: step 175980, total loss = 0.63, batch loss = 0.37 (169.8 examples/sec; 0.047 sec/batch; 0h:18m:27s remains)
INFO - root - 2022-02-24 21:14:49.443184: step 175990, total loss = 0.44, batch loss = 0.18 (204.3 examples/sec; 0.039 sec/batch; 0h:15m:20s remains)
INFO - root - 2022-02-24 21:14:49.850199: step 176000, total loss = 0.58, batch loss = 0.33 (165.8 examples/sec; 0.048 sec/batch; 0h:18m:53s remains)
INFO - root - 2022-02-24 21:14:50.356105: step 176010, total loss = 0.48, batch loss = 0.22 (203.5 examples/sec; 0.039 sec/batch; 0h:15m:23s remains)
INFO - root - 2022-02-24 21:14:50.710702: step 176020, total loss = 0.50, batch loss = 0.24 (141.9 examples/sec; 0.056 sec/batch; 0h:22m:04s remains)
INFO - root - 2022-02-24 21:14:51.102081: step 176030, total loss = 0.48, batch loss = 0.22 (126.9 examples/sec; 0.063 sec/batch; 0h:24m:39s remains)
INFO - root - 2022-02-24 21:14:51.429741: step 176040, total loss = 0.47, batch loss = 0.22 (254.7 examples/sec; 0.031 sec/batch; 0h:12m:16s remains)
INFO - root - 2022-02-24 21:14:51.835189: step 176050, total loss = 0.54, batch loss = 0.29 (233.4 examples/sec; 0.034 sec/batch; 0h:13m:23s remains)
INFO - root - 2022-02-24 21:14:52.675226: step 176060, total loss = 0.54, batch loss = 0.28 (321.0 examples/sec; 0.025 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:14:53.024840: step 176070, total loss = 0.52, batch loss = 0.27 (202.1 examples/sec; 0.040 sec/batch; 0h:15m:27s remains)
INFO - root - 2022-02-24 21:14:53.433161: step 176080, total loss = 0.51, batch loss = 0.26 (123.7 examples/sec; 0.065 sec/batch; 0h:25m:15s remains)
INFO - root - 2022-02-24 21:14:53.808410: step 176090, total loss = 0.51, batch loss = 0.25 (174.8 examples/sec; 0.046 sec/batch; 0h:17m:51s remains)
INFO - root - 2022-02-24 21:14:54.196035: step 176100, total loss = 0.61, batch loss = 0.35 (233.2 examples/sec; 0.034 sec/batch; 0h:13m:22s remains)
INFO - root - 2022-02-24 21:14:54.567538: step 176110, total loss = 0.59, batch loss = 0.33 (301.0 examples/sec; 0.027 sec/batch; 0h:10m:21s remains)
INFO - root - 2022-02-24 21:14:54.960119: step 176120, total loss = 0.54, batch loss = 0.29 (128.8 examples/sec; 0.062 sec/batch; 0h:24m:12s remains)
INFO - root - 2022-02-24 21:14:55.258227: step 176130, total loss = 0.51, batch loss = 0.25 (352.4 examples/sec; 0.023 sec/batch; 0h:08m:50s remains)
INFO - root - 2022-02-24 21:14:55.671346: step 176140, total loss = 0.58, batch loss = 0.33 (161.7 examples/sec; 0.049 sec/batch; 0h:19m:15s remains)
INFO - root - 2022-02-24 21:14:56.025498: step 176150, total loss = 0.60, batch loss = 0.35 (318.0 examples/sec; 0.025 sec/batch; 0h:09m:47s remains)
INFO - root - 2022-02-24 21:14:56.375450: step 176160, total loss = 0.59, batch loss = 0.34 (237.3 examples/sec; 0.034 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:14:56.689974: step 176170, total loss = 0.52, batch loss = 0.27 (342.0 examples/sec; 0.023 sec/batch; 0h:09m:05s remains)
INFO - root - 2022-02-24 21:14:57.010271: step 176180, total loss = 0.58, batch loss = 0.32 (157.8 examples/sec; 0.051 sec/batch; 0h:19m:42s remains)
INFO - root - 2022-02-24 21:14:57.465221: step 176190, total loss = 0.60, batch loss = 0.35 (365.9 examples/sec; 0.022 sec/batch; 0h:08m:29s remains)
INFO - root - 2022-02-24 21:14:57.855712: step 176200, total loss = 0.50, batch loss = 0.24 (211.0 examples/sec; 0.038 sec/batch; 0h:14m:43s remains)
INFO - root - 2022-02-24 21:14:58.259583: step 176210, total loss = 0.70, batch loss = 0.44 (230.4 examples/sec; 0.035 sec/batch; 0h:13m:28s remains)
INFO - root - 2022-02-24 21:14:58.653618: step 176220, total loss = 0.51, batch loss = 0.26 (157.0 examples/sec; 0.051 sec/batch; 0h:19m:46s remains)
INFO - root - 2022-02-24 21:14:58.987110: step 176230, total loss = 0.46, batch loss = 0.21 (192.8 examples/sec; 0.042 sec/batch; 0h:16m:05s remains)
INFO - root - 2022-02-24 21:14:59.293602: step 176240, total loss = 0.53, batch loss = 0.28 (312.7 examples/sec; 0.026 sec/batch; 0h:09m:55s remains)
INFO - root - 2022-02-24 21:14:59.724893: step 176250, total loss = 0.57, batch loss = 0.31 (281.9 examples/sec; 0.028 sec/batch; 0h:10m:59s remains)
INFO - root - 2022-02-24 21:15:00.135185: step 176260, total loss = 0.50, batch loss = 0.25 (282.9 examples/sec; 0.028 sec/batch; 0h:10m:57s remains)
INFO - root - 2022-02-24 21:15:00.407921: step 176270, total loss = 0.67, batch loss = 0.42 (308.5 examples/sec; 0.026 sec/batch; 0h:10m:02s remains)
INFO - root - 2022-02-24 21:15:00.740564: step 176280, total loss = 0.52, batch loss = 0.27 (187.1 examples/sec; 0.043 sec/batch; 0h:16m:32s remains)
INFO - root - 2022-02-24 21:15:01.042196: step 176290, total loss = 0.52, batch loss = 0.26 (279.8 examples/sec; 0.029 sec/batch; 0h:11m:03s remains)
INFO - root - 2022-02-24 21:15:01.568449: step 176300, total loss = 0.64, batch loss = 0.38 (171.9 examples/sec; 0.047 sec/batch; 0h:17m:59s remains)
INFO - root - 2022-02-24 21:15:01.949218: step 176310, total loss = 0.56, batch loss = 0.31 (307.8 examples/sec; 0.026 sec/batch; 0h:10m:02s remains)
INFO - root - 2022-02-24 21:15:02.298853: step 176320, total loss = 0.52, batch loss = 0.26 (238.8 examples/sec; 0.034 sec/batch; 0h:12m:56s remains)
INFO - root - 2022-02-24 21:15:02.659036: step 176330, total loss = 0.57, batch loss = 0.32 (185.0 examples/sec; 0.043 sec/batch; 0h:16m:41s remains)
INFO - root - 2022-02-24 21:15:02.980110: step 176340, total loss = 0.54, batch loss = 0.28 (188.9 examples/sec; 0.042 sec/batch; 0h:16m:20s remains)
INFO - root - 2022-02-24 21:15:03.387787: step 176350, total loss = 0.50, batch loss = 0.24 (165.5 examples/sec; 0.048 sec/batch; 0h:18m:38s remains)
INFO - root - 2022-02-24 21:15:03.821267: step 176360, total loss = 0.56, batch loss = 0.31 (300.3 examples/sec; 0.027 sec/batch; 0h:10m:16s remains)
INFO - root - 2022-02-24 21:15:04.214717: step 176370, total loss = 0.56, batch loss = 0.30 (245.9 examples/sec; 0.033 sec/batch; 0h:12m:32s remains)
INFO - root - 2022-02-24 21:15:04.549839: step 176380, total loss = 0.59, batch loss = 0.33 (240.1 examples/sec; 0.033 sec/batch; 0h:12m:50s remains)
INFO - root - 2022-02-24 21:15:04.848648: step 176390, total loss = 0.52, batch loss = 0.26 (296.7 examples/sec; 0.027 sec/batch; 0h:10m:23s remains)
INFO - root - 2022-02-24 21:15:05.137939: step 176400, total loss = 0.58, batch loss = 0.32 (341.0 examples/sec; 0.023 sec/batch; 0h:09m:01s remains)
INFO - root - 2022-02-24 21:15:05.531763: step 176410, total loss = 0.56, batch loss = 0.31 (173.2 examples/sec; 0.046 sec/batch; 0h:17m:46s remains)
INFO - root - 2022-02-24 21:15:05.918996: step 176420, total loss = 0.57, batch loss = 0.31 (213.9 examples/sec; 0.037 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:15:06.370577: step 176430, total loss = 0.46, batch loss = 0.20 (321.9 examples/sec; 0.025 sec/batch; 0h:09m:33s remains)
INFO - root - 2022-02-24 21:15:06.671848: step 176440, total loss = 0.55, batch loss = 0.29 (349.1 examples/sec; 0.023 sec/batch; 0h:08m:48s remains)
INFO - root - 2022-02-24 21:15:06.989991: step 176450, total loss = 0.51, batch loss = 0.26 (257.2 examples/sec; 0.031 sec/batch; 0h:11m:56s remains)
INFO - root - 2022-02-24 21:15:07.308594: step 176460, total loss = 0.49, batch loss = 0.23 (186.9 examples/sec; 0.043 sec/batch; 0h:16m:25s remains)
INFO - root - 2022-02-24 21:15:07.744048: step 176470, total loss = 0.57, batch loss = 0.32 (137.0 examples/sec; 0.058 sec/batch; 0h:22m:25s remains)
INFO - root - 2022-02-24 21:15:08.170059: step 176480, total loss = 0.51, batch loss = 0.26 (167.3 examples/sec; 0.048 sec/batch; 0h:18m:21s remains)
INFO - root - 2022-02-24 21:15:08.550385: step 176490, total loss = 0.49, batch loss = 0.23 (157.8 examples/sec; 0.051 sec/batch; 0h:19m:26s remains)
INFO - root - 2022-02-24 21:15:08.878179: step 176500, total loss = 0.56, batch loss = 0.31 (330.1 examples/sec; 0.024 sec/batch; 0h:09m:17s remains)
INFO - root - 2022-02-24 21:15:09.198845: step 176510, total loss = 0.47, batch loss = 0.22 (380.0 examples/sec; 0.021 sec/batch; 0h:08m:03s remains)
INFO - root - 2022-02-24 21:15:09.443398: step 176520, total loss = 0.55, batch loss = 0.29 (285.8 examples/sec; 0.028 sec/batch; 0h:10m:43s remains)
INFO - root - 2022-02-24 21:15:09.796168: step 176530, total loss = 0.54, batch loss = 0.28 (342.4 examples/sec; 0.023 sec/batch; 0h:08m:56s remains)
INFO - root - 2022-02-24 21:15:10.232620: step 176540, total loss = 0.62, batch loss = 0.37 (139.5 examples/sec; 0.057 sec/batch; 0h:21m:56s remains)
INFO - root - 2022-02-24 21:15:10.535765: step 176550, total loss = 0.63, batch loss = 0.37 (267.0 examples/sec; 0.030 sec/batch; 0h:11m:27s remains)
INFO - root - 2022-02-24 21:15:10.815357: step 176560, total loss = 0.55, batch loss = 0.29 (227.0 examples/sec; 0.035 sec/batch; 0h:13m:28s remains)
INFO - root - 2022-02-24 21:15:11.107750: step 176570, total loss = 0.58, batch loss = 0.32 (329.4 examples/sec; 0.024 sec/batch; 0h:09m:16s remains)
INFO - root - 2022-02-24 21:15:11.382039: step 176580, total loss = 0.62, batch loss = 0.36 (222.9 examples/sec; 0.036 sec/batch; 0h:13m:42s remains)
INFO - root - 2022-02-24 21:15:11.686149: step 176590, total loss = 0.51, batch loss = 0.25 (310.7 examples/sec; 0.026 sec/batch; 0h:09m:49s remains)
INFO - root - 2022-02-24 21:15:12.097899: step 176600, total loss = 0.64, batch loss = 0.39 (244.2 examples/sec; 0.033 sec/batch; 0h:12m:30s remains)
INFO - root - 2022-02-24 21:15:12.622871: step 176610, total loss = 0.50, batch loss = 0.25 (205.6 examples/sec; 0.039 sec/batch; 0h:14m:50s remains)
INFO - root - 2022-02-24 21:15:12.948273: step 176620, total loss = 0.71, batch loss = 0.45 (320.6 examples/sec; 0.025 sec/batch; 0h:09m:30s remains)
INFO - root - 2022-02-24 21:15:13.277182: step 176630, total loss = 0.66, batch loss = 0.41 (344.1 examples/sec; 0.023 sec/batch; 0h:08m:51s remains)
INFO - root - 2022-02-24 21:15:13.578359: step 176640, total loss = 0.51, batch loss = 0.26 (201.6 examples/sec; 0.040 sec/batch; 0h:15m:07s remains)
INFO - root - 2022-02-24 21:15:13.975951: step 176650, total loss = 0.62, batch loss = 0.36 (326.1 examples/sec; 0.025 sec/batch; 0h:09m:20s remains)
INFO - root - 2022-02-24 21:15:14.439639: step 176660, total loss = 0.60, batch loss = 0.34 (211.5 examples/sec; 0.038 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:15:14.816791: step 176670, total loss = 0.60, batch loss = 0.35 (208.5 examples/sec; 0.038 sec/batch; 0h:14m:35s remains)
INFO - root - 2022-02-24 21:15:15.102456: step 176680, total loss = 0.83, batch loss = 0.58 (336.8 examples/sec; 0.024 sec/batch; 0h:09m:02s remains)
INFO - root - 2022-02-24 21:15:15.429051: step 176690, total loss = 0.48, batch loss = 0.22 (211.3 examples/sec; 0.038 sec/batch; 0h:14m:23s remains)
INFO - root - 2022-02-24 21:15:15.806734: step 176700, total loss = 0.66, batch loss = 0.41 (181.5 examples/sec; 0.044 sec/batch; 0h:16m:45s remains)
INFO - root - 2022-02-24 21:15:16.310251: step 176710, total loss = 0.64, batch loss = 0.38 (192.1 examples/sec; 0.042 sec/batch; 0h:15m:49s remains)
INFO - root - 2022-02-24 21:15:16.860027: step 176720, total loss = 0.51, batch loss = 0.25 (64.9 examples/sec; 0.123 sec/batch; 0h:46m:48s remains)
INFO - root - 2022-02-24 21:15:17.323359: step 176730, total loss = 0.49, batch loss = 0.23 (174.1 examples/sec; 0.046 sec/batch; 0h:17m:26s remains)
INFO - root - 2022-02-24 21:15:17.862810: step 176740, total loss = 0.54, batch loss = 0.28 (334.6 examples/sec; 0.024 sec/batch; 0h:09m:04s remains)
INFO - root - 2022-02-24 21:15:18.364867: step 176750, total loss = 0.48, batch loss = 0.22 (151.0 examples/sec; 0.053 sec/batch; 0h:20m:05s remains)
INFO - root - 2022-02-24 21:15:18.784305: step 176760, total loss = 0.60, batch loss = 0.35 (192.1 examples/sec; 0.042 sec/batch; 0h:15m:46s remains)
INFO - root - 2022-02-24 21:15:19.240975: step 176770, total loss = 0.56, batch loss = 0.30 (165.7 examples/sec; 0.048 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:15:19.779502: step 176780, total loss = 0.57, batch loss = 0.31 (276.9 examples/sec; 0.029 sec/batch; 0h:10m:56s remains)
INFO - root - 2022-02-24 21:15:20.104525: step 176790, total loss = 0.47, batch loss = 0.21 (212.2 examples/sec; 0.038 sec/batch; 0h:14m:16s remains)
INFO - root - 2022-02-24 21:15:20.440892: step 176800, total loss = 0.64, batch loss = 0.39 (177.3 examples/sec; 0.045 sec/batch; 0h:17m:04s remains)
INFO - root - 2022-02-24 21:15:20.792793: step 176810, total loss = 0.54, batch loss = 0.29 (301.1 examples/sec; 0.027 sec/batch; 0h:10m:02s remains)
INFO - root - 2022-02-24 21:15:21.179956: step 176820, total loss = 0.48, batch loss = 0.22 (104.4 examples/sec; 0.077 sec/batch; 0h:28m:57s remains)
INFO - root - 2022-02-24 21:15:21.610826: step 176830, total loss = 0.52, batch loss = 0.27 (201.8 examples/sec; 0.040 sec/batch; 0h:14m:58s remains)
INFO - root - 2022-02-24 21:15:22.090422: step 176840, total loss = 0.55, batch loss = 0.29 (82.4 examples/sec; 0.097 sec/batch; 0h:36m:40s remains)
INFO - root - 2022-02-24 21:15:22.475687: step 176850, total loss = 0.54, batch loss = 0.28 (196.9 examples/sec; 0.041 sec/batch; 0h:15m:20s remains)
INFO - root - 2022-02-24 21:15:22.783609: step 176860, total loss = 0.54, batch loss = 0.28 (319.1 examples/sec; 0.025 sec/batch; 0h:09m:27s remains)
INFO - root - 2022-02-24 21:15:23.057077: step 176870, total loss = 0.56, batch loss = 0.31 (318.1 examples/sec; 0.025 sec/batch; 0h:09m:29s remains)
INFO - root - 2022-02-24 21:15:23.871705: step 176880, total loss = 0.53, batch loss = 0.28 (274.6 examples/sec; 0.029 sec/batch; 0h:10m:59s remains)
INFO - root - 2022-02-24 21:15:24.284186: step 176890, total loss = 0.58, batch loss = 0.32 (309.3 examples/sec; 0.026 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:15:24.723207: step 176900, total loss = 0.52, batch loss = 0.26 (138.1 examples/sec; 0.058 sec/batch; 0h:21m:48s remains)
INFO - root - 2022-02-24 21:15:25.132421: step 176910, total loss = 0.51, batch loss = 0.26 (289.0 examples/sec; 0.028 sec/batch; 0h:10m:25s remains)
INFO - root - 2022-02-24 21:15:25.450493: step 176920, total loss = 0.49, batch loss = 0.23 (319.0 examples/sec; 0.025 sec/batch; 0h:09m:26s remains)
INFO - root - 2022-02-24 21:15:25.827293: step 176930, total loss = 0.58, batch loss = 0.32 (152.2 examples/sec; 0.053 sec/batch; 0h:19m:46s remains)
INFO - root - 2022-02-24 21:15:26.309604: step 176940, total loss = 0.55, batch loss = 0.29 (165.1 examples/sec; 0.048 sec/batch; 0h:18m:13s remains)
INFO - root - 2022-02-24 21:15:26.784134: step 176950, total loss = 0.51, batch loss = 0.25 (185.1 examples/sec; 0.043 sec/batch; 0h:16m:14s remains)
INFO - root - 2022-02-24 21:15:27.235780: step 176960, total loss = 0.52, batch loss = 0.26 (251.1 examples/sec; 0.032 sec/batch; 0h:11m:58s remains)
INFO - root - 2022-02-24 21:15:28.271114: step 176970, total loss = 0.58, batch loss = 0.32 (200.0 examples/sec; 0.040 sec/batch; 0h:15m:01s remains)
INFO - root - 2022-02-24 21:15:28.740635: step 176980, total loss = 0.49, batch loss = 0.23 (164.9 examples/sec; 0.049 sec/batch; 0h:18m:12s remains)
INFO - root - 2022-02-24 21:15:29.286801: step 176990, total loss = 0.60, batch loss = 0.34 (158.4 examples/sec; 0.050 sec/batch; 0h:18m:56s remains)
INFO - root - 2022-02-24 21:15:29.616171: step 177000, total loss = 0.46, batch loss = 0.20 (335.2 examples/sec; 0.024 sec/batch; 0h:08m:56s remains)
INFO - root - 2022-02-24 21:15:30.058761: step 177010, total loss = 0.51, batch loss = 0.26 (341.5 examples/sec; 0.023 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:15:30.411707: step 177020, total loss = 0.55, batch loss = 0.30 (282.8 examples/sec; 0.028 sec/batch; 0h:10m:35s remains)
INFO - root - 2022-02-24 21:15:30.927092: step 177030, total loss = 0.55, batch loss = 0.30 (327.3 examples/sec; 0.024 sec/batch; 0h:09m:09s remains)
INFO - root - 2022-02-24 21:15:31.343188: step 177040, total loss = 0.53, batch loss = 0.27 (120.3 examples/sec; 0.067 sec/batch; 0h:24m:54s remains)
INFO - root - 2022-02-24 21:15:31.727001: step 177050, total loss = 0.53, batch loss = 0.28 (83.9 examples/sec; 0.095 sec/batch; 0h:35m:40s remains)
INFO - root - 2022-02-24 21:15:32.069571: step 177060, total loss = 0.49, batch loss = 0.23 (296.6 examples/sec; 0.027 sec/batch; 0h:10m:05s remains)
INFO - root - 2022-02-24 21:15:32.456436: step 177070, total loss = 0.54, batch loss = 0.28 (296.3 examples/sec; 0.027 sec/batch; 0h:10m:05s remains)
INFO - root - 2022-02-24 21:15:32.842091: step 177080, total loss = 0.67, batch loss = 0.42 (269.5 examples/sec; 0.030 sec/batch; 0h:11m:05s remains)
INFO - root - 2022-02-24 21:15:33.280699: step 177090, total loss = 0.60, batch loss = 0.34 (336.6 examples/sec; 0.024 sec/batch; 0h:08m:52s remains)
INFO - root - 2022-02-24 21:15:33.528918: step 177100, total loss = 0.54, batch loss = 0.29 (310.9 examples/sec; 0.026 sec/batch; 0h:09m:36s remains)
INFO - root - 2022-02-24 21:15:33.884825: step 177110, total loss = 0.53, batch loss = 0.28 (352.6 examples/sec; 0.023 sec/batch; 0h:08m:28s remains)
INFO - root - 2022-02-24 21:15:34.168884: step 177120, total loss = 0.56, batch loss = 0.31 (330.4 examples/sec; 0.024 sec/batch; 0h:09m:01s remains)
INFO - root - 2022-02-24 21:15:34.555122: step 177130, total loss = 0.58, batch loss = 0.32 (366.6 examples/sec; 0.022 sec/batch; 0h:08m:08s remains)
INFO - root - 2022-02-24 21:15:34.970275: step 177140, total loss = 0.53, batch loss = 0.28 (200.6 examples/sec; 0.040 sec/batch; 0h:14m:51s remains)
INFO - root - 2022-02-24 21:15:35.369348: step 177150, total loss = 0.48, batch loss = 0.23 (326.6 examples/sec; 0.024 sec/batch; 0h:09m:07s remains)
INFO - root - 2022-02-24 21:15:35.682902: step 177160, total loss = 0.54, batch loss = 0.29 (145.4 examples/sec; 0.055 sec/batch; 0h:20m:29s remains)
INFO - root - 2022-02-24 21:15:35.954173: step 177170, total loss = 0.55, batch loss = 0.29 (338.4 examples/sec; 0.024 sec/batch; 0h:08m:47s remains)
INFO - root - 2022-02-24 21:15:36.267483: step 177180, total loss = 0.56, batch loss = 0.30 (341.6 examples/sec; 0.023 sec/batch; 0h:08m:42s remains)
INFO - root - 2022-02-24 21:15:36.582531: step 177190, total loss = 0.59, batch loss = 0.34 (342.1 examples/sec; 0.023 sec/batch; 0h:08m:41s remains)
INFO - root - 2022-02-24 21:15:37.276728: step 177200, total loss = 0.59, batch loss = 0.34 (174.3 examples/sec; 0.046 sec/batch; 0h:17m:03s remains)
INFO - root - 2022-02-24 21:15:37.694834: step 177210, total loss = 0.56, batch loss = 0.30 (329.0 examples/sec; 0.024 sec/batch; 0h:09m:02s remains)
INFO - root - 2022-02-24 21:15:38.046145: step 177220, total loss = 0.72, batch loss = 0.47 (193.1 examples/sec; 0.041 sec/batch; 0h:15m:23s remains)
INFO - root - 2022-02-24 21:15:38.433818: step 177230, total loss = 0.51, batch loss = 0.26 (75.7 examples/sec; 0.106 sec/batch; 0h:39m:12s remains)
INFO - root - 2022-02-24 21:15:38.949496: step 177240, total loss = 0.65, batch loss = 0.40 (116.5 examples/sec; 0.069 sec/batch; 0h:25m:28s remains)
INFO - root - 2022-02-24 21:15:39.317187: step 177250, total loss = 0.57, batch loss = 0.32 (258.6 examples/sec; 0.031 sec/batch; 0h:11m:28s remains)
INFO - root - 2022-02-24 21:15:39.636172: step 177260, total loss = 0.63, batch loss = 0.37 (300.5 examples/sec; 0.027 sec/batch; 0h:09m:52s remains)
INFO - root - 2022-02-24 21:15:39.945108: step 177270, total loss = 0.54, batch loss = 0.28 (323.2 examples/sec; 0.025 sec/batch; 0h:09m:10s remains)
INFO - root - 2022-02-24 21:15:40.231080: step 177280, total loss = 0.47, batch loss = 0.21 (310.6 examples/sec; 0.026 sec/batch; 0h:09m:32s remains)
INFO - root - 2022-02-24 21:15:40.644451: step 177290, total loss = 0.69, batch loss = 0.43 (244.4 examples/sec; 0.033 sec/batch; 0h:12m:07s remains)
INFO - root - 2022-02-24 21:15:41.071210: step 177300, total loss = 0.52, batch loss = 0.26 (332.2 examples/sec; 0.024 sec/batch; 0h:08m:54s remains)
INFO - root - 2022-02-24 21:15:41.551968: step 177310, total loss = 0.52, batch loss = 0.26 (100.0 examples/sec; 0.080 sec/batch; 0h:29m:34s remains)
INFO - root - 2022-02-24 21:15:41.908652: step 177320, total loss = 0.58, batch loss = 0.32 (310.7 examples/sec; 0.026 sec/batch; 0h:09m:31s remains)
INFO - root - 2022-02-24 21:15:42.322307: step 177330, total loss = 0.74, batch loss = 0.48 (319.2 examples/sec; 0.025 sec/batch; 0h:09m:15s remains)
INFO - root - 2022-02-24 21:15:42.657728: step 177340, total loss = 0.56, batch loss = 0.30 (310.7 examples/sec; 0.026 sec/batch; 0h:09m:30s remains)
INFO - root - 2022-02-24 21:15:43.082751: step 177350, total loss = 0.56, batch loss = 0.30 (282.4 examples/sec; 0.028 sec/batch; 0h:10m:27s remains)
INFO - root - 2022-02-24 21:15:43.469135: step 177360, total loss = 0.60, batch loss = 0.35 (241.2 examples/sec; 0.033 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:15:43.827789: step 177370, total loss = 0.53, batch loss = 0.27 (345.2 examples/sec; 0.023 sec/batch; 0h:08m:32s remains)
INFO - root - 2022-02-24 21:15:44.181969: step 177380, total loss = 0.59, batch loss = 0.34 (287.6 examples/sec; 0.028 sec/batch; 0h:10m:15s remains)
INFO - root - 2022-02-24 21:15:44.557107: step 177390, total loss = 0.54, batch loss = 0.28 (172.7 examples/sec; 0.046 sec/batch; 0h:17m:04s remains)
INFO - root - 2022-02-24 21:15:44.865808: step 177400, total loss = 0.55, batch loss = 0.29 (157.3 examples/sec; 0.051 sec/batch; 0h:18m:44s remains)
INFO - root - 2022-02-24 21:15:45.366844: step 177410, total loss = 0.62, batch loss = 0.37 (216.9 examples/sec; 0.037 sec/batch; 0h:13m:34s remains)
INFO - root - 2022-02-24 21:15:45.743042: step 177420, total loss = 0.60, batch loss = 0.35 (163.9 examples/sec; 0.049 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:15:46.044156: step 177430, total loss = 0.55, batch loss = 0.30 (292.2 examples/sec; 0.027 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:15:46.344950: step 177440, total loss = 0.52, batch loss = 0.26 (336.4 examples/sec; 0.024 sec/batch; 0h:08m:44s remains)
INFO - root - 2022-02-24 21:15:46.622804: step 177450, total loss = 0.56, batch loss = 0.30 (325.0 examples/sec; 0.025 sec/batch; 0h:09m:02s remains)
INFO - root - 2022-02-24 21:15:46.953532: step 177460, total loss = 0.50, batch loss = 0.25 (93.7 examples/sec; 0.085 sec/batch; 0h:31m:21s remains)
INFO - root - 2022-02-24 21:15:47.411999: step 177470, total loss = 0.55, batch loss = 0.30 (363.2 examples/sec; 0.022 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:15:47.789285: step 177480, total loss = 0.57, batch loss = 0.32 (214.9 examples/sec; 0.037 sec/batch; 0h:13m:39s remains)
INFO - root - 2022-02-24 21:15:48.076515: step 177490, total loss = 0.56, batch loss = 0.31 (313.8 examples/sec; 0.025 sec/batch; 0h:09m:21s remains)
INFO - root - 2022-02-24 21:15:48.367148: step 177500, total loss = 0.48, batch loss = 0.23 (352.9 examples/sec; 0.023 sec/batch; 0h:08m:18s remains)
INFO - root - 2022-02-24 21:15:48.811275: step 177510, total loss = 0.54, batch loss = 0.29 (328.1 examples/sec; 0.024 sec/batch; 0h:08m:56s remains)
INFO - root - 2022-02-24 21:15:49.230001: step 177520, total loss = 0.57, batch loss = 0.32 (218.6 examples/sec; 0.037 sec/batch; 0h:13m:24s remains)
INFO - root - 2022-02-24 21:15:49.602614: step 177530, total loss = 0.49, batch loss = 0.24 (146.5 examples/sec; 0.055 sec/batch; 0h:19m:59s remains)
INFO - root - 2022-02-24 21:15:49.943120: step 177540, total loss = 0.75, batch loss = 0.50 (315.4 examples/sec; 0.025 sec/batch; 0h:09m:16s remains)
INFO - root - 2022-02-24 21:15:50.247190: step 177550, total loss = 0.52, batch loss = 0.26 (361.7 examples/sec; 0.022 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:15:50.565641: step 177560, total loss = 0.66, batch loss = 0.40 (273.5 examples/sec; 0.029 sec/batch; 0h:10m:41s remains)
INFO - root - 2022-02-24 21:15:50.868043: step 177570, total loss = 0.48, batch loss = 0.22 (362.9 examples/sec; 0.022 sec/batch; 0h:08m:03s remains)
INFO - root - 2022-02-24 21:15:51.332269: step 177580, total loss = 0.53, batch loss = 0.27 (206.3 examples/sec; 0.039 sec/batch; 0h:14m:10s remains)
INFO - root - 2022-02-24 21:15:51.754678: step 177590, total loss = 0.50, batch loss = 0.25 (210.9 examples/sec; 0.038 sec/batch; 0h:13m:51s remains)
INFO - root - 2022-02-24 21:15:52.162513: step 177600, total loss = 0.59, batch loss = 0.33 (170.8 examples/sec; 0.047 sec/batch; 0h:17m:05s remains)
INFO - root - 2022-02-24 21:15:52.518884: step 177610, total loss = 0.57, batch loss = 0.32 (328.2 examples/sec; 0.024 sec/batch; 0h:08m:53s remains)
INFO - root - 2022-02-24 21:15:52.810440: step 177620, total loss = 0.58, batch loss = 0.33 (223.2 examples/sec; 0.036 sec/batch; 0h:13m:04s remains)
INFO - root - 2022-02-24 21:15:53.133206: step 177630, total loss = 0.55, batch loss = 0.29 (257.6 examples/sec; 0.031 sec/batch; 0h:11m:19s remains)
INFO - root - 2022-02-24 21:15:53.592084: step 177640, total loss = 0.67, batch loss = 0.41 (200.6 examples/sec; 0.040 sec/batch; 0h:14m:31s remains)
INFO - root - 2022-02-24 21:15:53.943210: step 177650, total loss = 0.56, batch loss = 0.30 (335.3 examples/sec; 0.024 sec/batch; 0h:08m:41s remains)
INFO - root - 2022-02-24 21:15:54.233133: step 177660, total loss = 0.59, batch loss = 0.33 (299.9 examples/sec; 0.027 sec/batch; 0h:09m:42s remains)
INFO - root - 2022-02-24 21:15:54.568366: step 177670, total loss = 0.48, batch loss = 0.22 (216.3 examples/sec; 0.037 sec/batch; 0h:13m:27s remains)
INFO - root - 2022-02-24 21:15:54.950620: step 177680, total loss = 0.58, batch loss = 0.32 (140.3 examples/sec; 0.057 sec/batch; 0h:20m:44s remains)
INFO - root - 2022-02-24 21:15:55.338402: step 177690, total loss = 0.57, batch loss = 0.31 (136.1 examples/sec; 0.059 sec/batch; 0h:21m:21s remains)
INFO - root - 2022-02-24 21:15:55.793589: step 177700, total loss = 0.46, batch loss = 0.20 (286.2 examples/sec; 0.028 sec/batch; 0h:10m:09s remains)
INFO - root - 2022-02-24 21:15:56.212061: step 177710, total loss = 0.61, batch loss = 0.36 (268.7 examples/sec; 0.030 sec/batch; 0h:10m:48s remains)
INFO - root - 2022-02-24 21:15:56.573039: step 177720, total loss = 0.68, batch loss = 0.42 (276.7 examples/sec; 0.029 sec/batch; 0h:10m:29s remains)
INFO - root - 2022-02-24 21:15:56.919543: step 177730, total loss = 0.57, batch loss = 0.31 (312.3 examples/sec; 0.026 sec/batch; 0h:09m:17s remains)
INFO - root - 2022-02-24 21:15:57.354646: step 177740, total loss = 0.50, batch loss = 0.25 (223.0 examples/sec; 0.036 sec/batch; 0h:13m:00s remains)
INFO - root - 2022-02-24 21:15:57.763550: step 177750, total loss = 0.53, batch loss = 0.28 (215.8 examples/sec; 0.037 sec/batch; 0h:13m:26s remains)
INFO - root - 2022-02-24 21:15:58.228359: step 177760, total loss = 0.51, batch loss = 0.25 (221.9 examples/sec; 0.036 sec/batch; 0h:13m:03s remains)
INFO - root - 2022-02-24 21:15:58.600736: step 177770, total loss = 0.55, batch loss = 0.29 (202.9 examples/sec; 0.039 sec/batch; 0h:14m:16s remains)
INFO - root - 2022-02-24 21:15:58.940276: step 177780, total loss = 0.54, batch loss = 0.28 (353.0 examples/sec; 0.023 sec/batch; 0h:08m:12s remains)
INFO - root - 2022-02-24 21:15:59.360654: step 177790, total loss = 0.50, batch loss = 0.25 (269.7 examples/sec; 0.030 sec/batch; 0h:10m:44s remains)
INFO - root - 2022-02-24 21:15:59.873365: step 177800, total loss = 0.50, batch loss = 0.24 (238.7 examples/sec; 0.034 sec/batch; 0h:12m:07s remains)
INFO - root - 2022-02-24 21:16:00.316135: step 177810, total loss = 0.47, batch loss = 0.22 (151.2 examples/sec; 0.053 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 21:16:00.604359: step 177820, total loss = 0.56, batch loss = 0.30 (235.9 examples/sec; 0.034 sec/batch; 0h:12m:15s remains)
INFO - root - 2022-02-24 21:16:01.223332: step 177830, total loss = 0.53, batch loss = 0.27 (216.6 examples/sec; 0.037 sec/batch; 0h:13m:20s remains)
INFO - root - 2022-02-24 21:16:01.727188: step 177840, total loss = 0.45, batch loss = 0.19 (162.8 examples/sec; 0.049 sec/batch; 0h:17m:44s remains)
INFO - root - 2022-02-24 21:16:02.123529: step 177850, total loss = 0.56, batch loss = 0.30 (206.4 examples/sec; 0.039 sec/batch; 0h:13m:58s remains)
INFO - root - 2022-02-24 21:16:02.911068: step 177860, total loss = 0.47, batch loss = 0.22 (134.3 examples/sec; 0.060 sec/batch; 0h:21m:29s remains)
INFO - root - 2022-02-24 21:16:03.296596: step 177870, total loss = 0.53, batch loss = 0.27 (246.4 examples/sec; 0.032 sec/batch; 0h:11m:42s remains)
INFO - root - 2022-02-24 21:16:03.700549: step 177880, total loss = 0.50, batch loss = 0.25 (338.9 examples/sec; 0.024 sec/batch; 0h:08m:30s remains)
INFO - root - 2022-02-24 21:16:04.115259: step 177890, total loss = 0.53, batch loss = 0.27 (284.7 examples/sec; 0.028 sec/batch; 0h:10m:07s remains)
INFO - root - 2022-02-24 21:16:04.798401: step 177900, total loss = 0.53, batch loss = 0.28 (187.1 examples/sec; 0.043 sec/batch; 0h:15m:23s remains)
INFO - root - 2022-02-24 21:16:05.157705: step 177910, total loss = 0.57, batch loss = 0.31 (160.9 examples/sec; 0.050 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 21:16:05.592904: step 177920, total loss = 0.50, batch loss = 0.24 (167.3 examples/sec; 0.048 sec/batch; 0h:17m:11s remains)
INFO - root - 2022-02-24 21:16:06.045454: step 177930, total loss = 0.50, batch loss = 0.25 (240.4 examples/sec; 0.033 sec/batch; 0h:11m:57s remains)
INFO - root - 2022-02-24 21:16:06.432564: step 177940, total loss = 0.60, batch loss = 0.34 (287.2 examples/sec; 0.028 sec/batch; 0h:10m:00s remains)
INFO - root - 2022-02-24 21:16:06.791977: step 177950, total loss = 0.53, batch loss = 0.27 (327.4 examples/sec; 0.024 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:16:07.166764: step 177960, total loss = 0.57, batch loss = 0.31 (84.7 examples/sec; 0.094 sec/batch; 0h:33m:55s remains)
INFO - root - 2022-02-24 21:16:07.882519: step 177970, total loss = 0.50, batch loss = 0.25 (23.3 examples/sec; 0.344 sec/batch; 2h:03m:28s remains)
INFO - root - 2022-02-24 21:16:08.364578: step 177980, total loss = 0.50, batch loss = 0.24 (232.5 examples/sec; 0.034 sec/batch; 0h:12m:20s remains)
INFO - root - 2022-02-24 21:16:08.746982: step 177990, total loss = 0.66, batch loss = 0.41 (192.7 examples/sec; 0.042 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:16:09.005473: step 178000, total loss = 0.51, batch loss = 0.26 (342.6 examples/sec; 0.023 sec/batch; 0h:08m:22s remains)
INFO - root - 2022-02-24 21:16:09.460567: step 178010, total loss = 0.55, batch loss = 0.30 (172.1 examples/sec; 0.046 sec/batch; 0h:16m:39s remains)
INFO - root - 2022-02-24 21:16:09.830938: step 178020, total loss = 0.58, batch loss = 0.32 (209.9 examples/sec; 0.038 sec/batch; 0h:13m:38s remains)
INFO - root - 2022-02-24 21:16:10.182772: step 178030, total loss = 0.55, batch loss = 0.29 (378.8 examples/sec; 0.021 sec/batch; 0h:07m:33s remains)
INFO - root - 2022-02-24 21:16:10.593942: step 178040, total loss = 0.55, batch loss = 0.30 (318.8 examples/sec; 0.025 sec/batch; 0h:08m:58s remains)
INFO - root - 2022-02-24 21:16:10.931659: step 178050, total loss = 0.58, batch loss = 0.32 (162.4 examples/sec; 0.049 sec/batch; 0h:17m:36s remains)
INFO - root - 2022-02-24 21:16:11.242467: step 178060, total loss = 0.55, batch loss = 0.29 (256.4 examples/sec; 0.031 sec/batch; 0h:11m:09s remains)
INFO - root - 2022-02-24 21:16:11.597812: step 178070, total loss = 0.47, batch loss = 0.22 (142.2 examples/sec; 0.056 sec/batch; 0h:20m:05s remains)
INFO - root - 2022-02-24 21:16:11.944713: step 178080, total loss = 0.48, batch loss = 0.23 (239.8 examples/sec; 0.033 sec/batch; 0h:11m:54s remains)
INFO - root - 2022-02-24 21:16:12.427936: step 178090, total loss = 0.56, batch loss = 0.30 (291.7 examples/sec; 0.027 sec/batch; 0h:09m:47s remains)
INFO - root - 2022-02-24 21:16:12.868203: step 178100, total loss = 0.49, batch loss = 0.24 (165.3 examples/sec; 0.048 sec/batch; 0h:17m:15s remains)
INFO - root - 2022-02-24 21:16:13.290987: step 178110, total loss = 0.48, batch loss = 0.23 (347.9 examples/sec; 0.023 sec/batch; 0h:08m:11s remains)
INFO - root - 2022-02-24 21:16:13.594388: step 178120, total loss = 0.59, batch loss = 0.33 (188.0 examples/sec; 0.043 sec/batch; 0h:15m:09s remains)
INFO - root - 2022-02-24 21:16:13.997255: step 178130, total loss = 0.57, batch loss = 0.32 (233.2 examples/sec; 0.034 sec/batch; 0h:12m:13s remains)
INFO - root - 2022-02-24 21:16:14.470740: step 178140, total loss = 0.73, batch loss = 0.48 (142.5 examples/sec; 0.056 sec/batch; 0h:19m:59s remains)
INFO - root - 2022-02-24 21:16:14.805608: step 178150, total loss = 0.58, batch loss = 0.32 (312.3 examples/sec; 0.026 sec/batch; 0h:09m:06s remains)
INFO - root - 2022-02-24 21:16:15.109161: step 178160, total loss = 0.54, batch loss = 0.28 (172.4 examples/sec; 0.046 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:16:15.359815: step 178170, total loss = 0.59, batch loss = 0.33 (335.0 examples/sec; 0.024 sec/batch; 0h:08m:29s remains)
INFO - root - 2022-02-24 21:16:15.665319: step 178180, total loss = 0.58, batch loss = 0.32 (183.5 examples/sec; 0.044 sec/batch; 0h:15m:29s remains)
INFO - root - 2022-02-24 21:16:16.073550: step 178190, total loss = 0.50, batch loss = 0.24 (131.2 examples/sec; 0.061 sec/batch; 0h:21m:39s remains)
INFO - root - 2022-02-24 21:16:16.508594: step 178200, total loss = 0.43, batch loss = 0.17 (350.4 examples/sec; 0.023 sec/batch; 0h:08m:06s remains)
INFO - root - 2022-02-24 21:16:16.909662: step 178210, total loss = 0.54, batch loss = 0.28 (285.6 examples/sec; 0.028 sec/batch; 0h:09m:56s remains)
INFO - root - 2022-02-24 21:16:17.271922: step 178220, total loss = 0.56, batch loss = 0.31 (259.8 examples/sec; 0.031 sec/batch; 0h:10m:55s remains)
INFO - root - 2022-02-24 21:16:17.589329: step 178230, total loss = 0.49, batch loss = 0.23 (257.6 examples/sec; 0.031 sec/batch; 0h:11m:00s remains)
INFO - root - 2022-02-24 21:16:18.099178: step 178240, total loss = 0.53, batch loss = 0.28 (131.7 examples/sec; 0.061 sec/batch; 0h:21m:31s remains)
INFO - root - 2022-02-24 21:16:18.530907: step 178250, total loss = 0.62, batch loss = 0.36 (288.4 examples/sec; 0.028 sec/batch; 0h:09m:49s remains)
INFO - root - 2022-02-24 21:16:18.836061: step 178260, total loss = 0.58, batch loss = 0.32 (262.3 examples/sec; 0.031 sec/batch; 0h:10m:47s remains)
INFO - root - 2022-02-24 21:16:19.162658: step 178270, total loss = 0.48, batch loss = 0.22 (230.1 examples/sec; 0.035 sec/batch; 0h:12m:18s remains)
INFO - root - 2022-02-24 21:16:19.434048: step 178280, total loss = 0.50, batch loss = 0.24 (341.9 examples/sec; 0.023 sec/batch; 0h:08m:16s remains)
INFO - root - 2022-02-24 21:16:19.755343: step 178290, total loss = 0.56, batch loss = 0.31 (170.1 examples/sec; 0.047 sec/batch; 0h:16m:37s remains)
INFO - root - 2022-02-24 21:16:20.115704: step 178300, total loss = 0.59, batch loss = 0.33 (169.3 examples/sec; 0.047 sec/batch; 0h:16m:41s remains)
INFO - root - 2022-02-24 21:16:20.611108: step 178310, total loss = 0.54, batch loss = 0.28 (290.2 examples/sec; 0.028 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:16:20.917448: step 178320, total loss = 0.55, batch loss = 0.30 (310.6 examples/sec; 0.026 sec/batch; 0h:09m:05s remains)
INFO - root - 2022-02-24 21:16:21.257314: step 178330, total loss = 0.48, batch loss = 0.22 (230.7 examples/sec; 0.035 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:16:21.578814: step 178340, total loss = 0.60, batch loss = 0.34 (158.0 examples/sec; 0.051 sec/batch; 0h:17m:51s remains)
INFO - root - 2022-02-24 21:16:21.925648: step 178350, total loss = 0.51, batch loss = 0.25 (156.5 examples/sec; 0.051 sec/batch; 0h:18m:00s remains)
INFO - root - 2022-02-24 21:16:22.315541: step 178360, total loss = 0.62, batch loss = 0.36 (138.8 examples/sec; 0.058 sec/batch; 0h:20m:18s remains)
INFO - root - 2022-02-24 21:16:22.636057: step 178370, total loss = 0.55, batch loss = 0.30 (135.8 examples/sec; 0.059 sec/batch; 0h:20m:44s remains)
INFO - root - 2022-02-24 21:16:23.034054: step 178380, total loss = 0.52, batch loss = 0.26 (175.6 examples/sec; 0.046 sec/batch; 0h:16m:01s remains)
INFO - root - 2022-02-24 21:16:23.322852: step 178390, total loss = 0.44, batch loss = 0.19 (330.7 examples/sec; 0.024 sec/batch; 0h:08m:30s remains)
INFO - root - 2022-02-24 21:16:23.650799: step 178400, total loss = 0.49, batch loss = 0.23 (259.6 examples/sec; 0.031 sec/batch; 0h:10m:50s remains)
INFO - root - 2022-02-24 21:16:24.042671: step 178410, total loss = 0.60, batch loss = 0.35 (177.4 examples/sec; 0.045 sec/batch; 0h:15m:51s remains)
INFO - root - 2022-02-24 21:16:24.397729: step 178420, total loss = 0.54, batch loss = 0.29 (282.6 examples/sec; 0.028 sec/batch; 0h:09m:56s remains)
INFO - root - 2022-02-24 21:16:24.747779: step 178430, total loss = 0.56, batch loss = 0.30 (306.3 examples/sec; 0.026 sec/batch; 0h:09m:10s remains)
INFO - root - 2022-02-24 21:16:25.070647: step 178440, total loss = 0.58, batch loss = 0.32 (233.9 examples/sec; 0.034 sec/batch; 0h:12m:00s remains)
INFO - root - 2022-02-24 21:16:25.353073: step 178450, total loss = 0.51, batch loss = 0.25 (237.5 examples/sec; 0.034 sec/batch; 0h:11m:49s remains)
INFO - root - 2022-02-24 21:16:25.675318: step 178460, total loss = 0.48, batch loss = 0.22 (213.5 examples/sec; 0.037 sec/batch; 0h:13m:08s remains)
INFO - root - 2022-02-24 21:16:25.995051: step 178470, total loss = 0.45, batch loss = 0.20 (192.3 examples/sec; 0.042 sec/batch; 0h:14m:34s remains)
INFO - root - 2022-02-24 21:16:26.356697: step 178480, total loss = 0.51, batch loss = 0.25 (160.2 examples/sec; 0.050 sec/batch; 0h:17m:29s remains)
INFO - root - 2022-02-24 21:16:26.723840: step 178490, total loss = 0.48, batch loss = 0.23 (319.0 examples/sec; 0.025 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:16:27.080708: step 178500, total loss = 0.47, batch loss = 0.22 (82.4 examples/sec; 0.097 sec/batch; 0h:33m:58s remains)
INFO - root - 2022-02-24 21:16:27.476917: step 178510, total loss = 0.48, batch loss = 0.23 (285.3 examples/sec; 0.028 sec/batch; 0h:09m:48s remains)
INFO - root - 2022-02-24 21:16:27.832725: step 178520, total loss = 0.54, batch loss = 0.28 (122.9 examples/sec; 0.065 sec/batch; 0h:22m:45s remains)
INFO - root - 2022-02-24 21:16:28.270639: step 178530, total loss = 0.51, batch loss = 0.26 (152.8 examples/sec; 0.052 sec/batch; 0h:18m:18s remains)
INFO - root - 2022-02-24 21:16:28.712322: step 178540, total loss = 0.46, batch loss = 0.20 (159.0 examples/sec; 0.050 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 21:16:29.091589: step 178550, total loss = 0.51, batch loss = 0.25 (322.6 examples/sec; 0.025 sec/batch; 0h:08m:39s remains)
INFO - root - 2022-02-24 21:16:29.389793: step 178560, total loss = 0.55, batch loss = 0.30 (206.4 examples/sec; 0.039 sec/batch; 0h:13m:31s remains)
INFO - root - 2022-02-24 21:16:29.723467: step 178570, total loss = 0.58, batch loss = 0.33 (356.3 examples/sec; 0.022 sec/batch; 0h:07m:49s remains)
INFO - root - 2022-02-24 21:16:30.103223: step 178580, total loss = 0.50, batch loss = 0.24 (129.7 examples/sec; 0.062 sec/batch; 0h:21m:30s remains)
INFO - root - 2022-02-24 21:16:30.589327: step 178590, total loss = 0.52, batch loss = 0.26 (152.4 examples/sec; 0.053 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:16:30.924412: step 178600, total loss = 0.45, batch loss = 0.19 (313.7 examples/sec; 0.026 sec/batch; 0h:08m:53s remains)
INFO - root - 2022-02-24 21:16:31.264077: step 178610, total loss = 0.55, batch loss = 0.29 (322.4 examples/sec; 0.025 sec/batch; 0h:08m:38s remains)
INFO - root - 2022-02-24 21:16:31.596454: step 178620, total loss = 0.61, batch loss = 0.35 (229.4 examples/sec; 0.035 sec/batch; 0h:12m:08s remains)
INFO - root - 2022-02-24 21:16:31.934505: step 178630, total loss = 0.55, batch loss = 0.29 (342.5 examples/sec; 0.023 sec/batch; 0h:08m:07s remains)
INFO - root - 2022-02-24 21:16:32.440668: step 178640, total loss = 0.60, batch loss = 0.34 (342.0 examples/sec; 0.023 sec/batch; 0h:08m:07s remains)
INFO - root - 2022-02-24 21:16:32.838332: step 178650, total loss = 0.64, batch loss = 0.38 (135.3 examples/sec; 0.059 sec/batch; 0h:20m:32s remains)
INFO - root - 2022-02-24 21:16:33.167512: step 178660, total loss = 0.46, batch loss = 0.20 (268.9 examples/sec; 0.030 sec/batch; 0h:10m:19s remains)
INFO - root - 2022-02-24 21:16:33.466337: step 178670, total loss = 0.55, batch loss = 0.30 (360.2 examples/sec; 0.022 sec/batch; 0h:07m:42s remains)
INFO - root - 2022-02-24 21:16:33.726958: step 178680, total loss = 0.49, batch loss = 0.23 (321.7 examples/sec; 0.025 sec/batch; 0h:08m:37s remains)
INFO - root - 2022-02-24 21:16:34.048295: step 178690, total loss = 0.51, batch loss = 0.26 (311.5 examples/sec; 0.026 sec/batch; 0h:08m:54s remains)
INFO - root - 2022-02-24 21:16:34.495236: step 178700, total loss = 0.51, batch loss = 0.25 (137.3 examples/sec; 0.058 sec/batch; 0h:20m:11s remains)
INFO - root - 2022-02-24 21:16:35.007287: step 178710, total loss = 0.55, batch loss = 0.30 (197.0 examples/sec; 0.041 sec/batch; 0h:14m:04s remains)
INFO - root - 2022-02-24 21:16:35.300254: step 178720, total loss = 0.68, batch loss = 0.42 (318.6 examples/sec; 0.025 sec/batch; 0h:08m:41s remains)
INFO - root - 2022-02-24 21:16:35.652068: step 178730, total loss = 0.54, batch loss = 0.28 (316.9 examples/sec; 0.025 sec/batch; 0h:08m:44s remains)
INFO - root - 2022-02-24 21:16:36.126488: step 178740, total loss = 0.53, batch loss = 0.27 (252.5 examples/sec; 0.032 sec/batch; 0h:10m:57s remains)
INFO - root - 2022-02-24 21:16:36.641320: step 178750, total loss = 0.64, batch loss = 0.38 (313.1 examples/sec; 0.026 sec/batch; 0h:08m:50s remains)
INFO - root - 2022-02-24 21:16:37.147080: step 178760, total loss = 0.47, batch loss = 0.21 (320.4 examples/sec; 0.025 sec/batch; 0h:08m:37s remains)
INFO - root - 2022-02-24 21:16:37.639552: step 178770, total loss = 0.57, batch loss = 0.31 (317.0 examples/sec; 0.025 sec/batch; 0h:08m:43s remains)
INFO - root - 2022-02-24 21:16:38.570458: step 178780, total loss = 0.54, batch loss = 0.29 (14.5 examples/sec; 0.550 sec/batch; 3h:10m:03s remains)
INFO - root - 2022-02-24 21:16:38.976340: step 178790, total loss = 0.43, batch loss = 0.17 (327.3 examples/sec; 0.024 sec/batch; 0h:08m:26s remains)
INFO - root - 2022-02-24 21:16:39.456939: step 178800, total loss = 0.58, batch loss = 0.32 (186.1 examples/sec; 0.043 sec/batch; 0h:14m:49s remains)
INFO - root - 2022-02-24 21:16:39.859385: step 178810, total loss = 0.54, batch loss = 0.28 (210.9 examples/sec; 0.038 sec/batch; 0h:13m:04s remains)
INFO - root - 2022-02-24 21:16:40.212663: step 178820, total loss = 0.50, batch loss = 0.24 (272.4 examples/sec; 0.029 sec/batch; 0h:10m:07s remains)
INFO - root - 2022-02-24 21:16:40.545450: step 178830, total loss = 0.55, batch loss = 0.29 (253.5 examples/sec; 0.032 sec/batch; 0h:10m:52s remains)
INFO - root - 2022-02-24 21:16:40.916225: step 178840, total loss = 0.58, batch loss = 0.32 (351.6 examples/sec; 0.023 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:16:41.304543: step 178850, total loss = 0.49, batch loss = 0.24 (140.8 examples/sec; 0.057 sec/batch; 0h:19m:33s remains)
INFO - root - 2022-02-24 21:16:41.737803: step 178860, total loss = 0.56, batch loss = 0.31 (368.8 examples/sec; 0.022 sec/batch; 0h:07m:27s remains)
INFO - root - 2022-02-24 21:16:42.108699: step 178870, total loss = 0.57, batch loss = 0.32 (268.9 examples/sec; 0.030 sec/batch; 0h:10m:13s remains)
INFO - root - 2022-02-24 21:16:42.485867: step 178880, total loss = 0.64, batch loss = 0.38 (285.4 examples/sec; 0.028 sec/batch; 0h:09m:37s remains)
INFO - root - 2022-02-24 21:16:42.856684: step 178890, total loss = 0.58, batch loss = 0.32 (347.3 examples/sec; 0.023 sec/batch; 0h:07m:54s remains)
INFO - root - 2022-02-24 21:16:43.420643: step 178900, total loss = 0.49, batch loss = 0.23 (184.6 examples/sec; 0.043 sec/batch; 0h:14m:52s remains)
INFO - root - 2022-02-24 21:16:44.083904: step 178910, total loss = 0.48, batch loss = 0.22 (191.0 examples/sec; 0.042 sec/batch; 0h:14m:22s remains)
INFO - root - 2022-02-24 21:16:44.385521: step 178920, total loss = 0.60, batch loss = 0.34 (189.0 examples/sec; 0.042 sec/batch; 0h:14m:31s remains)
INFO - root - 2022-02-24 21:16:44.675555: step 178930, total loss = 0.58, batch loss = 0.32 (298.1 examples/sec; 0.027 sec/batch; 0h:09m:12s remains)
INFO - root - 2022-02-24 21:16:45.151805: step 178940, total loss = 0.59, batch loss = 0.34 (76.4 examples/sec; 0.105 sec/batch; 0h:35m:53s remains)
INFO - root - 2022-02-24 21:16:45.479173: step 178950, total loss = 0.63, batch loss = 0.38 (161.1 examples/sec; 0.050 sec/batch; 0h:17m:00s remains)
INFO - root - 2022-02-24 21:16:45.774341: step 178960, total loss = 0.59, batch loss = 0.34 (356.3 examples/sec; 0.022 sec/batch; 0h:07m:41s remains)
INFO - root - 2022-02-24 21:16:46.065428: step 178970, total loss = 0.55, batch loss = 0.29 (317.2 examples/sec; 0.025 sec/batch; 0h:08m:37s remains)
INFO - root - 2022-02-24 21:16:46.384492: step 178980, total loss = 0.58, batch loss = 0.33 (328.9 examples/sec; 0.024 sec/batch; 0h:08m:19s remains)
INFO - root - 2022-02-24 21:16:46.788403: step 178990, total loss = 0.46, batch loss = 0.20 (137.2 examples/sec; 0.058 sec/batch; 0h:19m:56s remains)
INFO - root - 2022-02-24 21:16:47.260771: step 179000, total loss = 0.46, batch loss = 0.20 (162.9 examples/sec; 0.049 sec/batch; 0h:16m:46s remains)
INFO - root - 2022-02-24 21:16:47.666544: step 179010, total loss = 0.53, batch loss = 0.27 (384.1 examples/sec; 0.021 sec/batch; 0h:07m:06s remains)
INFO - root - 2022-02-24 21:16:47.942527: step 179020, total loss = 0.50, batch loss = 0.24 (283.2 examples/sec; 0.028 sec/batch; 0h:09m:38s remains)
INFO - root - 2022-02-24 21:16:48.327738: step 179030, total loss = 0.52, batch loss = 0.27 (333.0 examples/sec; 0.024 sec/batch; 0h:08m:11s remains)
INFO - root - 2022-02-24 21:16:48.724995: step 179040, total loss = 0.49, batch loss = 0.24 (176.2 examples/sec; 0.045 sec/batch; 0h:15m:28s remains)
INFO - root - 2022-02-24 21:16:49.136435: step 179050, total loss = 0.58, batch loss = 0.33 (84.4 examples/sec; 0.095 sec/batch; 0h:32m:19s remains)
INFO - root - 2022-02-24 21:16:49.433242: step 179060, total loss = 0.53, batch loss = 0.28 (248.3 examples/sec; 0.032 sec/batch; 0h:10m:58s remains)
INFO - root - 2022-02-24 21:16:49.827140: step 179070, total loss = 0.53, batch loss = 0.27 (188.3 examples/sec; 0.042 sec/batch; 0h:14m:28s remains)
INFO - root - 2022-02-24 21:16:50.338919: step 179080, total loss = 0.60, batch loss = 0.35 (315.3 examples/sec; 0.025 sec/batch; 0h:08m:38s remains)
INFO - root - 2022-02-24 21:16:50.887947: step 179090, total loss = 0.58, batch loss = 0.32 (95.6 examples/sec; 0.084 sec/batch; 0h:28m:28s remains)
INFO - root - 2022-02-24 21:16:51.973604: step 179100, total loss = 0.57, batch loss = 0.32 (92.2 examples/sec; 0.087 sec/batch; 0h:29m:29s remains)
INFO - root - 2022-02-24 21:16:52.344469: step 179110, total loss = 0.58, batch loss = 0.33 (326.9 examples/sec; 0.024 sec/batch; 0h:08m:19s remains)
INFO - root - 2022-02-24 21:16:53.262150: step 179120, total loss = 0.61, batch loss = 0.35 (323.3 examples/sec; 0.025 sec/batch; 0h:08m:24s remains)
INFO - root - 2022-02-24 21:16:54.218514: step 179130, total loss = 0.51, batch loss = 0.25 (293.1 examples/sec; 0.027 sec/batch; 0h:09m:15s remains)
INFO - root - 2022-02-24 21:16:54.886090: step 179140, total loss = 0.49, batch loss = 0.24 (71.6 examples/sec; 0.112 sec/batch; 0h:37m:53s remains)
INFO - root - 2022-02-24 21:16:55.424564: step 179150, total loss = 0.73, batch loss = 0.47 (115.1 examples/sec; 0.069 sec/batch; 0h:23m:33s remains)
INFO - root - 2022-02-24 21:16:56.001234: step 179160, total loss = 0.58, batch loss = 0.33 (56.2 examples/sec; 0.142 sec/batch; 0h:48m:16s remains)
INFO - root - 2022-02-24 21:16:56.376151: step 179170, total loss = 0.53, batch loss = 0.27 (302.7 examples/sec; 0.026 sec/batch; 0h:08m:57s remains)
INFO - root - 2022-02-24 21:16:56.855399: step 179180, total loss = 0.44, batch loss = 0.18 (187.9 examples/sec; 0.043 sec/batch; 0h:14m:25s remains)
INFO - root - 2022-02-24 21:16:57.264067: step 179190, total loss = 0.59, batch loss = 0.33 (195.9 examples/sec; 0.041 sec/batch; 0h:13m:49s remains)
INFO - root - 2022-02-24 21:16:57.757282: step 179200, total loss = 0.59, batch loss = 0.33 (221.4 examples/sec; 0.036 sec/batch; 0h:12m:13s remains)
INFO - root - 2022-02-24 21:16:58.302343: step 179210, total loss = 0.55, batch loss = 0.30 (94.9 examples/sec; 0.084 sec/batch; 0h:28m:30s remains)
INFO - root - 2022-02-24 21:16:58.836422: step 179220, total loss = 0.58, batch loss = 0.32 (367.3 examples/sec; 0.022 sec/batch; 0h:07m:21s remains)
INFO - root - 2022-02-24 21:16:59.257592: step 179230, total loss = 0.51, batch loss = 0.25 (371.2 examples/sec; 0.022 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:16:59.768379: step 179240, total loss = 0.57, batch loss = 0.31 (196.9 examples/sec; 0.041 sec/batch; 0h:13m:43s remains)
INFO - root - 2022-02-24 21:17:00.246025: step 179250, total loss = 0.57, batch loss = 0.32 (136.9 examples/sec; 0.058 sec/batch; 0h:19m:43s remains)
INFO - root - 2022-02-24 21:17:00.811741: step 179260, total loss = 0.51, batch loss = 0.25 (246.5 examples/sec; 0.032 sec/batch; 0h:10m:56s remains)
INFO - root - 2022-02-24 21:17:01.152087: step 179270, total loss = 0.52, batch loss = 0.26 (307.3 examples/sec; 0.026 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:17:01.474021: step 179280, total loss = 0.56, batch loss = 0.30 (292.5 examples/sec; 0.027 sec/batch; 0h:09m:13s remains)
INFO - root - 2022-02-24 21:17:01.878896: step 179290, total loss = 0.54, batch loss = 0.29 (251.8 examples/sec; 0.032 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:17:02.348713: step 179300, total loss = 0.74, batch loss = 0.48 (339.5 examples/sec; 0.024 sec/batch; 0h:07m:55s remains)
INFO - root - 2022-02-24 21:17:02.740172: step 179310, total loss = 0.49, batch loss = 0.23 (356.7 examples/sec; 0.022 sec/batch; 0h:07m:32s remains)
INFO - root - 2022-02-24 21:17:03.078739: step 179320, total loss = 0.56, batch loss = 0.30 (313.6 examples/sec; 0.026 sec/batch; 0h:08m:34s remains)
INFO - root - 2022-02-24 21:17:03.368226: step 179330, total loss = 0.51, batch loss = 0.25 (172.3 examples/sec; 0.046 sec/batch; 0h:15m:36s remains)
INFO - root - 2022-02-24 21:17:03.702957: step 179340, total loss = 0.59, batch loss = 0.33 (365.7 examples/sec; 0.022 sec/batch; 0h:07m:21s remains)
INFO - root - 2022-02-24 21:17:04.097225: step 179350, total loss = 0.52, batch loss = 0.27 (329.4 examples/sec; 0.024 sec/batch; 0h:08m:09s remains)
INFO - root - 2022-02-24 21:17:04.553973: step 179360, total loss = 0.58, batch loss = 0.33 (148.0 examples/sec; 0.054 sec/batch; 0h:18m:08s remains)
INFO - root - 2022-02-24 21:17:04.909538: step 179370, total loss = 0.53, batch loss = 0.27 (223.0 examples/sec; 0.036 sec/batch; 0h:12m:02s remains)
INFO - root - 2022-02-24 21:17:05.211063: step 179380, total loss = 0.61, batch loss = 0.35 (343.4 examples/sec; 0.023 sec/batch; 0h:07m:48s remains)
INFO - root - 2022-02-24 21:17:05.497791: step 179390, total loss = 0.62, batch loss = 0.36 (209.2 examples/sec; 0.038 sec/batch; 0h:12m:49s remains)
INFO - root - 2022-02-24 21:17:05.849679: step 179400, total loss = 0.60, batch loss = 0.34 (372.7 examples/sec; 0.021 sec/batch; 0h:07m:11s remains)
INFO - root - 2022-02-24 21:17:06.192367: step 179410, total loss = 0.54, batch loss = 0.29 (330.9 examples/sec; 0.024 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:17:06.560783: step 179420, total loss = 0.51, batch loss = 0.26 (359.3 examples/sec; 0.022 sec/batch; 0h:07m:27s remains)
INFO - root - 2022-02-24 21:17:07.006597: step 179430, total loss = 0.60, batch loss = 0.34 (169.0 examples/sec; 0.047 sec/batch; 0h:15m:50s remains)
INFO - root - 2022-02-24 21:17:07.408081: step 179440, total loss = 0.54, batch loss = 0.29 (172.8 examples/sec; 0.046 sec/batch; 0h:15m:28s remains)
INFO - root - 2022-02-24 21:17:07.703704: step 179450, total loss = 0.56, batch loss = 0.30 (314.1 examples/sec; 0.025 sec/batch; 0h:08m:30s remains)
INFO - root - 2022-02-24 21:17:07.946282: step 179460, total loss = 0.53, batch loss = 0.28 (281.7 examples/sec; 0.028 sec/batch; 0h:09m:29s remains)
INFO - root - 2022-02-24 21:17:08.269175: step 179470, total loss = 0.52, batch loss = 0.26 (291.7 examples/sec; 0.027 sec/batch; 0h:09m:09s remains)
INFO - root - 2022-02-24 21:17:08.685475: step 179480, total loss = 0.57, batch loss = 0.31 (139.8 examples/sec; 0.057 sec/batch; 0h:19m:05s remains)
INFO - root - 2022-02-24 21:17:09.163591: step 179490, total loss = 0.57, batch loss = 0.31 (283.5 examples/sec; 0.028 sec/batch; 0h:09m:24s remains)
INFO - root - 2022-02-24 21:17:09.486842: step 179500, total loss = 0.53, batch loss = 0.28 (325.8 examples/sec; 0.025 sec/batch; 0h:08m:11s remains)
INFO - root - 2022-02-24 21:17:09.874435: step 179510, total loss = 0.54, batch loss = 0.28 (329.6 examples/sec; 0.024 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:17:10.201045: step 179520, total loss = 0.51, batch loss = 0.26 (263.0 examples/sec; 0.030 sec/batch; 0h:10m:07s remains)
INFO - root - 2022-02-24 21:17:10.626123: step 179530, total loss = 0.59, batch loss = 0.33 (105.9 examples/sec; 0.076 sec/batch; 0h:25m:08s remains)
INFO - root - 2022-02-24 21:17:11.019346: step 179540, total loss = 0.58, batch loss = 0.32 (140.7 examples/sec; 0.057 sec/batch; 0h:18m:54s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-179549 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-179549 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:17:11.893480: step 179550, total loss = 0.55, batch loss = 0.29 (333.1 examples/sec; 0.024 sec/batch; 0h:07m:59s remains)
INFO - root - 2022-02-24 21:17:12.146122: step 179560, total loss = 0.56, batch loss = 0.30 (314.7 examples/sec; 0.025 sec/batch; 0h:08m:26s remains)
INFO - root - 2022-02-24 21:17:12.424876: step 179570, total loss = 0.63, batch loss = 0.38 (148.7 examples/sec; 0.054 sec/batch; 0h:17m:51s remains)
INFO - root - 2022-02-24 21:17:13.019140: step 179580, total loss = 0.41, batch loss = 0.16 (103.3 examples/sec; 0.077 sec/batch; 0h:25m:43s remains)
INFO - root - 2022-02-24 21:17:13.414545: step 179590, total loss = 0.55, batch loss = 0.30 (318.7 examples/sec; 0.025 sec/batch; 0h:08m:19s remains)
INFO - root - 2022-02-24 21:17:13.848413: step 179600, total loss = 0.51, batch loss = 0.26 (114.7 examples/sec; 0.070 sec/batch; 0h:23m:08s remains)
INFO - root - 2022-02-24 21:17:15.028401: step 179610, total loss = 0.55, batch loss = 0.29 (135.2 examples/sec; 0.059 sec/batch; 0h:19m:36s remains)
INFO - root - 2022-02-24 21:17:15.386615: step 179620, total loss = 0.55, batch loss = 0.30 (130.8 examples/sec; 0.061 sec/batch; 0h:20m:15s remains)
INFO - root - 2022-02-24 21:17:15.876006: step 179630, total loss = 0.51, batch loss = 0.25 (251.9 examples/sec; 0.032 sec/batch; 0h:10m:31s remains)
INFO - root - 2022-02-24 21:17:16.240229: step 179640, total loss = 0.54, batch loss = 0.28 (213.3 examples/sec; 0.038 sec/batch; 0h:12m:24s remains)
INFO - root - 2022-02-24 21:17:16.648727: step 179650, total loss = 0.50, batch loss = 0.24 (130.1 examples/sec; 0.061 sec/batch; 0h:20m:20s remains)
INFO - root - 2022-02-24 21:17:16.992019: step 179660, total loss = 0.46, batch loss = 0.20 (309.1 examples/sec; 0.026 sec/batch; 0h:08m:33s remains)
INFO - root - 2022-02-24 21:17:17.463112: step 179670, total loss = 0.52, batch loss = 0.26 (168.9 examples/sec; 0.047 sec/batch; 0h:15m:39s remains)
INFO - root - 2022-02-24 21:17:17.832839: step 179680, total loss = 0.57, batch loss = 0.31 (197.1 examples/sec; 0.041 sec/batch; 0h:13m:24s remains)
INFO - root - 2022-02-24 21:17:18.262297: step 179690, total loss = 0.53, batch loss = 0.28 (125.6 examples/sec; 0.064 sec/batch; 0h:21m:01s remains)
INFO - root - 2022-02-24 21:17:18.752459: step 179700, total loss = 0.46, batch loss = 0.21 (152.9 examples/sec; 0.052 sec/batch; 0h:17m:16s remains)
INFO - root - 2022-02-24 21:17:19.303950: step 179710, total loss = 0.83, batch loss = 0.57 (75.8 examples/sec; 0.106 sec/batch; 0h:34m:49s remains)
INFO - root - 2022-02-24 21:17:19.703669: step 179720, total loss = 0.57, batch loss = 0.32 (366.1 examples/sec; 0.022 sec/batch; 0h:07m:12s remains)
INFO - root - 2022-02-24 21:17:20.033579: step 179730, total loss = 0.56, batch loss = 0.31 (229.7 examples/sec; 0.035 sec/batch; 0h:11m:28s remains)
INFO - root - 2022-02-24 21:17:20.381089: step 179740, total loss = 0.54, batch loss = 0.28 (232.8 examples/sec; 0.034 sec/batch; 0h:11m:18s remains)
INFO - root - 2022-02-24 21:17:20.719061: step 179750, total loss = 0.53, batch loss = 0.27 (323.2 examples/sec; 0.025 sec/batch; 0h:08m:08s remains)
INFO - root - 2022-02-24 21:17:21.136521: step 179760, total loss = 0.60, batch loss = 0.34 (90.3 examples/sec; 0.089 sec/batch; 0h:29m:08s remains)
INFO - root - 2022-02-24 21:17:21.578519: step 179770, total loss = 0.50, batch loss = 0.25 (123.1 examples/sec; 0.065 sec/batch; 0h:21m:22s remains)
INFO - root - 2022-02-24 21:17:21.903196: step 179780, total loss = 0.62, batch loss = 0.37 (307.7 examples/sec; 0.026 sec/batch; 0h:08m:32s remains)
INFO - root - 2022-02-24 21:17:22.137443: step 179790, total loss = 0.54, batch loss = 0.28 (337.8 examples/sec; 0.024 sec/batch; 0h:07m:46s remains)
INFO - root - 2022-02-24 21:17:22.468585: step 179800, total loss = 0.49, batch loss = 0.24 (228.6 examples/sec; 0.035 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:17:22.882964: step 179810, total loss = 0.55, batch loss = 0.29 (182.0 examples/sec; 0.044 sec/batch; 0h:14m:25s remains)
INFO - root - 2022-02-24 21:17:23.187672: step 179820, total loss = 0.52, batch loss = 0.26 (222.9 examples/sec; 0.036 sec/batch; 0h:11m:46s remains)
INFO - root - 2022-02-24 21:17:23.507536: step 179830, total loss = 0.84, batch loss = 0.58 (148.5 examples/sec; 0.054 sec/batch; 0h:17m:39s remains)
INFO - root - 2022-02-24 21:17:23.881790: step 179840, total loss = 0.49, batch loss = 0.24 (190.5 examples/sec; 0.042 sec/batch; 0h:13m:45s remains)
INFO - root - 2022-02-24 21:17:24.313039: step 179850, total loss = 0.53, batch loss = 0.27 (320.5 examples/sec; 0.025 sec/batch; 0h:08m:10s remains)
INFO - root - 2022-02-24 21:17:24.658454: step 179860, total loss = 0.46, batch loss = 0.21 (247.2 examples/sec; 0.032 sec/batch; 0h:10m:35s remains)
INFO - root - 2022-02-24 21:17:25.000526: step 179870, total loss = 0.56, batch loss = 0.30 (152.0 examples/sec; 0.053 sec/batch; 0h:17m:13s remains)
INFO - root - 2022-02-24 21:17:25.407088: step 179880, total loss = 0.54, batch loss = 0.28 (100.1 examples/sec; 0.080 sec/batch; 0h:26m:07s remains)
INFO - root - 2022-02-24 21:17:25.829205: step 179890, total loss = 0.51, batch loss = 0.26 (325.2 examples/sec; 0.025 sec/batch; 0h:08m:02s remains)
INFO - root - 2022-02-24 21:17:26.144956: step 179900, total loss = 0.53, batch loss = 0.27 (274.1 examples/sec; 0.029 sec/batch; 0h:09m:32s remains)
INFO - root - 2022-02-24 21:17:26.527338: step 179910, total loss = 0.60, batch loss = 0.34 (358.9 examples/sec; 0.022 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:17:26.823294: step 179920, total loss = 0.50, batch loss = 0.24 (340.2 examples/sec; 0.024 sec/batch; 0h:07m:40s remains)
INFO - root - 2022-02-24 21:17:27.103216: step 179930, total loss = 0.54, batch loss = 0.28 (289.4 examples/sec; 0.028 sec/batch; 0h:09m:00s remains)
INFO - root - 2022-02-24 21:17:27.513711: step 179940, total loss = 0.44, batch loss = 0.18 (159.8 examples/sec; 0.050 sec/batch; 0h:16m:19s remains)
INFO - root - 2022-02-24 21:17:27.908023: step 179950, total loss = 0.55, batch loss = 0.29 (181.7 examples/sec; 0.044 sec/batch; 0h:14m:20s remains)
INFO - root - 2022-02-24 21:17:28.307426: step 179960, total loss = 0.45, batch loss = 0.19 (166.6 examples/sec; 0.048 sec/batch; 0h:15m:38s remains)
INFO - root - 2022-02-24 21:17:28.580147: step 179970, total loss = 0.51, batch loss = 0.26 (299.9 examples/sec; 0.027 sec/batch; 0h:08m:41s remains)
INFO - root - 2022-02-24 21:17:28.918709: step 179980, total loss = 0.47, batch loss = 0.22 (329.1 examples/sec; 0.024 sec/batch; 0h:07m:54s remains)
INFO - root - 2022-02-24 21:17:29.270309: step 179990, total loss = 0.60, batch loss = 0.34 (331.2 examples/sec; 0.024 sec/batch; 0h:07m:51s remains)
INFO - root - 2022-02-24 21:17:29.698942: step 180000, total loss = 0.49, batch loss = 0.23 (166.5 examples/sec; 0.048 sec/batch; 0h:15m:37s remains)
INFO - root - 2022-02-24 21:17:30.329855: step 180010, total loss = 0.51, batch loss = 0.26 (208.8 examples/sec; 0.038 sec/batch; 0h:12m:26s remains)
INFO - root - 2022-02-24 21:17:30.673405: step 180020, total loss = 0.58, batch loss = 0.33 (368.9 examples/sec; 0.022 sec/batch; 0h:07m:02s remains)
INFO - root - 2022-02-24 21:17:31.004205: step 180030, total loss = 0.55, batch loss = 0.30 (325.7 examples/sec; 0.025 sec/batch; 0h:07m:58s remains)
INFO - root - 2022-02-24 21:17:31.369688: step 180040, total loss = 0.50, batch loss = 0.24 (212.7 examples/sec; 0.038 sec/batch; 0h:12m:11s remains)
INFO - root - 2022-02-24 21:17:31.732183: step 180050, total loss = 0.54, batch loss = 0.28 (113.0 examples/sec; 0.071 sec/batch; 0h:22m:57s remains)
INFO - root - 2022-02-24 21:17:32.181137: step 180060, total loss = 0.51, batch loss = 0.25 (242.0 examples/sec; 0.033 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:17:32.559286: step 180070, total loss = 0.52, batch loss = 0.27 (335.8 examples/sec; 0.024 sec/batch; 0h:07m:42s remains)
INFO - root - 2022-02-24 21:17:32.884383: step 180080, total loss = 0.50, batch loss = 0.24 (208.6 examples/sec; 0.038 sec/batch; 0h:12m:24s remains)
INFO - root - 2022-02-24 21:17:33.203938: step 180090, total loss = 0.60, batch loss = 0.35 (201.5 examples/sec; 0.040 sec/batch; 0h:12m:50s remains)
INFO - root - 2022-02-24 21:17:33.492883: step 180100, total loss = 0.50, batch loss = 0.25 (315.6 examples/sec; 0.025 sec/batch; 0h:08m:11s remains)
INFO - root - 2022-02-24 21:17:34.020728: step 180110, total loss = 0.54, batch loss = 0.28 (182.5 examples/sec; 0.044 sec/batch; 0h:14m:09s remains)
INFO - root - 2022-02-24 21:17:34.399724: step 180120, total loss = 0.56, batch loss = 0.31 (126.4 examples/sec; 0.063 sec/batch; 0h:20m:26s remains)
INFO - root - 2022-02-24 21:17:34.759604: step 180130, total loss = 0.59, batch loss = 0.34 (341.4 examples/sec; 0.023 sec/batch; 0h:07m:33s remains)
INFO - root - 2022-02-24 21:17:35.042627: step 180140, total loss = 0.56, batch loss = 0.30 (374.5 examples/sec; 0.021 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:17:35.377792: step 180150, total loss = 0.48, batch loss = 0.22 (233.5 examples/sec; 0.034 sec/batch; 0h:11m:02s remains)
INFO - root - 2022-02-24 21:17:35.819377: step 180160, total loss = 0.52, batch loss = 0.27 (207.3 examples/sec; 0.039 sec/batch; 0h:12m:26s remains)
INFO - root - 2022-02-24 21:17:36.254203: step 180170, total loss = 0.50, batch loss = 0.24 (343.7 examples/sec; 0.023 sec/batch; 0h:07m:29s remains)
INFO - root - 2022-02-24 21:17:36.660830: step 180180, total loss = 0.50, batch loss = 0.24 (355.4 examples/sec; 0.023 sec/batch; 0h:07m:14s remains)
INFO - root - 2022-02-24 21:17:37.008763: step 180190, total loss = 0.70, batch loss = 0.45 (355.4 examples/sec; 0.023 sec/batch; 0h:07m:14s remains)
INFO - root - 2022-02-24 21:17:37.347072: step 180200, total loss = 0.50, batch loss = 0.25 (200.2 examples/sec; 0.040 sec/batch; 0h:12m:51s remains)
INFO - root - 2022-02-24 21:17:37.911140: step 180210, total loss = 0.59, batch loss = 0.33 (140.3 examples/sec; 0.057 sec/batch; 0h:18m:19s remains)
INFO - root - 2022-02-24 21:17:38.301276: step 180220, total loss = 0.70, batch loss = 0.44 (220.6 examples/sec; 0.036 sec/batch; 0h:11m:39s remains)
INFO - root - 2022-02-24 21:17:38.641420: step 180230, total loss = 0.56, batch loss = 0.30 (323.5 examples/sec; 0.025 sec/batch; 0h:07m:56s remains)
INFO - root - 2022-02-24 21:17:38.976714: step 180240, total loss = 0.48, batch loss = 0.23 (322.4 examples/sec; 0.025 sec/batch; 0h:07m:57s remains)
INFO - root - 2022-02-24 21:17:39.352332: step 180250, total loss = 0.60, batch loss = 0.34 (310.8 examples/sec; 0.026 sec/batch; 0h:08m:15s remains)
INFO - root - 2022-02-24 21:17:39.797031: step 180260, total loss = 0.47, batch loss = 0.21 (110.7 examples/sec; 0.072 sec/batch; 0h:23m:10s remains)
INFO - root - 2022-02-24 21:17:40.173000: step 180270, total loss = 0.64, batch loss = 0.39 (361.2 examples/sec; 0.022 sec/batch; 0h:07m:05s remains)
INFO - root - 2022-02-24 21:17:40.568118: step 180280, total loss = 0.52, batch loss = 0.26 (318.0 examples/sec; 0.025 sec/batch; 0h:08m:03s remains)
INFO - root - 2022-02-24 21:17:40.932936: step 180290, total loss = 0.50, batch loss = 0.24 (198.3 examples/sec; 0.040 sec/batch; 0h:12m:54s remains)
INFO - root - 2022-02-24 21:17:41.230534: step 180300, total loss = 0.51, batch loss = 0.26 (339.7 examples/sec; 0.024 sec/batch; 0h:07m:32s remains)
INFO - root - 2022-02-24 21:17:41.618520: step 180310, total loss = 0.49, batch loss = 0.23 (303.1 examples/sec; 0.026 sec/batch; 0h:08m:26s remains)
INFO - root - 2022-02-24 21:17:42.055956: step 180320, total loss = 0.62, batch loss = 0.37 (159.4 examples/sec; 0.050 sec/batch; 0h:16m:02s remains)
INFO - root - 2022-02-24 21:17:42.386220: step 180330, total loss = 0.54, batch loss = 0.28 (296.2 examples/sec; 0.027 sec/batch; 0h:08m:37s remains)
INFO - root - 2022-02-24 21:17:42.663205: step 180340, total loss = 0.53, batch loss = 0.27 (341.0 examples/sec; 0.023 sec/batch; 0h:07m:29s remains)
INFO - root - 2022-02-24 21:17:42.989860: step 180350, total loss = 0.53, batch loss = 0.27 (334.4 examples/sec; 0.024 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:17:43.271488: step 180360, total loss = 0.58, batch loss = 0.32 (334.7 examples/sec; 0.024 sec/batch; 0h:07m:37s remains)
INFO - root - 2022-02-24 21:17:43.591340: step 180370, total loss = 0.53, batch loss = 0.28 (277.5 examples/sec; 0.029 sec/batch; 0h:09m:11s remains)
INFO - root - 2022-02-24 21:17:44.155717: step 180380, total loss = 0.62, batch loss = 0.36 (178.8 examples/sec; 0.045 sec/batch; 0h:14m:15s remains)
INFO - root - 2022-02-24 21:17:44.497134: step 180390, total loss = 0.57, batch loss = 0.31 (325.2 examples/sec; 0.025 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:17:44.846157: step 180400, total loss = 0.47, batch loss = 0.21 (130.0 examples/sec; 0.062 sec/batch; 0h:19m:35s remains)
INFO - root - 2022-02-24 21:17:45.268093: step 180410, total loss = 0.53, batch loss = 0.27 (331.3 examples/sec; 0.024 sec/batch; 0h:07m:41s remains)
INFO - root - 2022-02-24 21:17:45.562981: step 180420, total loss = 0.43, batch loss = 0.18 (311.8 examples/sec; 0.026 sec/batch; 0h:08m:09s remains)
INFO - root - 2022-02-24 21:17:46.053899: step 180430, total loss = 0.43, batch loss = 0.18 (100.5 examples/sec; 0.080 sec/batch; 0h:25m:18s remains)
INFO - root - 2022-02-24 21:17:46.440821: step 180440, total loss = 0.61, batch loss = 0.36 (263.6 examples/sec; 0.030 sec/batch; 0h:09m:38s remains)
INFO - root - 2022-02-24 21:17:46.818502: step 180450, total loss = 0.44, batch loss = 0.19 (276.8 examples/sec; 0.029 sec/batch; 0h:09m:10s remains)
INFO - root - 2022-02-24 21:17:47.257388: step 180460, total loss = 0.55, batch loss = 0.29 (268.5 examples/sec; 0.030 sec/batch; 0h:09m:27s remains)
INFO - root - 2022-02-24 21:17:47.807575: step 180470, total loss = 0.67, batch loss = 0.42 (292.2 examples/sec; 0.027 sec/batch; 0h:08m:41s remains)
INFO - root - 2022-02-24 21:17:48.336169: step 180480, total loss = 0.67, batch loss = 0.41 (105.8 examples/sec; 0.076 sec/batch; 0h:23m:58s remains)
INFO - root - 2022-02-24 21:17:48.758966: step 180490, total loss = 0.63, batch loss = 0.37 (277.8 examples/sec; 0.029 sec/batch; 0h:09m:07s remains)
INFO - root - 2022-02-24 21:17:49.462237: step 180500, total loss = 0.51, batch loss = 0.25 (131.9 examples/sec; 0.061 sec/batch; 0h:19m:12s remains)
INFO - root - 2022-02-24 21:17:50.606109: step 180510, total loss = 0.56, batch loss = 0.30 (307.7 examples/sec; 0.026 sec/batch; 0h:08m:13s remains)
INFO - root - 2022-02-24 21:17:50.962318: step 180520, total loss = 0.54, batch loss = 0.28 (187.5 examples/sec; 0.043 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:17:51.383772: step 180530, total loss = 0.50, batch loss = 0.25 (322.5 examples/sec; 0.025 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:17:51.715022: step 180540, total loss = 0.56, batch loss = 0.30 (345.9 examples/sec; 0.023 sec/batch; 0h:07m:18s remains)
INFO - root - 2022-02-24 21:17:52.026968: step 180550, total loss = 0.59, batch loss = 0.33 (325.8 examples/sec; 0.025 sec/batch; 0h:07m:45s remains)
INFO - root - 2022-02-24 21:17:52.292185: step 180560, total loss = 0.63, batch loss = 0.37 (346.1 examples/sec; 0.023 sec/batch; 0h:07m:17s remains)
INFO - root - 2022-02-24 21:17:52.631051: step 180570, total loss = 0.54, batch loss = 0.29 (335.0 examples/sec; 0.024 sec/batch; 0h:07m:32s remains)
INFO - root - 2022-02-24 21:17:53.023358: step 180580, total loss = 0.46, batch loss = 0.20 (131.5 examples/sec; 0.061 sec/batch; 0h:19m:10s remains)
INFO - root - 2022-02-24 21:17:53.429455: step 180590, total loss = 0.57, batch loss = 0.31 (210.7 examples/sec; 0.038 sec/batch; 0h:11m:58s remains)
INFO - root - 2022-02-24 21:17:53.775071: step 180600, total loss = 0.59, batch loss = 0.33 (304.0 examples/sec; 0.026 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:17:54.220186: step 180610, total loss = 0.59, batch loss = 0.34 (321.3 examples/sec; 0.025 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:17:54.560421: step 180620, total loss = 0.54, batch loss = 0.29 (123.7 examples/sec; 0.065 sec/batch; 0h:20m:21s remains)
INFO - root - 2022-02-24 21:17:54.932132: step 180630, total loss = 0.47, batch loss = 0.21 (250.7 examples/sec; 0.032 sec/batch; 0h:10m:02s remains)
INFO - root - 2022-02-24 21:17:55.292124: step 180640, total loss = 0.50, batch loss = 0.24 (331.4 examples/sec; 0.024 sec/batch; 0h:07m:35s remains)
INFO - root - 2022-02-24 21:17:55.651801: step 180650, total loss = 0.41, batch loss = 0.15 (322.2 examples/sec; 0.025 sec/batch; 0h:07m:48s remains)
INFO - root - 2022-02-24 21:17:55.953893: step 180660, total loss = 0.58, batch loss = 0.32 (305.3 examples/sec; 0.026 sec/batch; 0h:08m:13s remains)
INFO - root - 2022-02-24 21:17:56.323661: step 180670, total loss = 0.56, batch loss = 0.30 (146.8 examples/sec; 0.054 sec/batch; 0h:17m:05s remains)
INFO - root - 2022-02-24 21:17:56.640371: step 180680, total loss = 0.55, batch loss = 0.30 (263.2 examples/sec; 0.030 sec/batch; 0h:09m:31s remains)
INFO - root - 2022-02-24 21:17:57.010231: step 180690, total loss = 0.58, batch loss = 0.33 (213.8 examples/sec; 0.037 sec/batch; 0h:11m:43s remains)
INFO - root - 2022-02-24 21:17:57.462978: step 180700, total loss = 0.53, batch loss = 0.27 (136.1 examples/sec; 0.059 sec/batch; 0h:18m:25s remains)
INFO - root - 2022-02-24 21:17:57.833139: step 180710, total loss = 0.76, batch loss = 0.50 (326.4 examples/sec; 0.025 sec/batch; 0h:07m:40s remains)
INFO - root - 2022-02-24 21:17:58.129362: step 180720, total loss = 0.55, batch loss = 0.29 (269.4 examples/sec; 0.030 sec/batch; 0h:09m:17s remains)
INFO - root - 2022-02-24 21:17:58.411356: step 180730, total loss = 0.45, batch loss = 0.20 (316.2 examples/sec; 0.025 sec/batch; 0h:07m:54s remains)
INFO - root - 2022-02-24 21:17:58.709999: step 180740, total loss = 0.61, batch loss = 0.36 (358.5 examples/sec; 0.022 sec/batch; 0h:06m:58s remains)
INFO - root - 2022-02-24 21:17:59.092246: step 180750, total loss = 0.53, batch loss = 0.27 (333.3 examples/sec; 0.024 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:17:59.557519: step 180760, total loss = 0.52, batch loss = 0.27 (341.5 examples/sec; 0.023 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:17:59.854114: step 180770, total loss = 0.49, batch loss = 0.23 (303.1 examples/sec; 0.026 sec/batch; 0h:08m:14s remains)
INFO - root - 2022-02-24 21:18:00.199708: step 180780, total loss = 0.49, batch loss = 0.24 (334.9 examples/sec; 0.024 sec/batch; 0h:07m:27s remains)
INFO - root - 2022-02-24 21:18:00.516458: step 180790, total loss = 0.54, batch loss = 0.29 (321.4 examples/sec; 0.025 sec/batch; 0h:07m:45s remains)
INFO - root - 2022-02-24 21:18:00.946451: step 180800, total loss = 0.52, batch loss = 0.26 (339.4 examples/sec; 0.024 sec/batch; 0h:07m:20s remains)
INFO - root - 2022-02-24 21:18:01.361527: step 180810, total loss = 0.67, batch loss = 0.41 (109.4 examples/sec; 0.073 sec/batch; 0h:22m:46s remains)
INFO - root - 2022-02-24 21:18:01.751190: step 180820, total loss = 0.66, batch loss = 0.40 (314.9 examples/sec; 0.025 sec/batch; 0h:07m:54s remains)
INFO - root - 2022-02-24 21:18:02.053203: step 180830, total loss = 0.48, batch loss = 0.22 (163.8 examples/sec; 0.049 sec/batch; 0h:15m:11s remains)
INFO - root - 2022-02-24 21:18:02.331786: step 180840, total loss = 0.58, batch loss = 0.32 (278.8 examples/sec; 0.029 sec/batch; 0h:08m:55s remains)
INFO - root - 2022-02-24 21:18:02.595385: step 180850, total loss = 0.66, batch loss = 0.41 (290.9 examples/sec; 0.027 sec/batch; 0h:08m:32s remains)
INFO - root - 2022-02-24 21:18:02.966680: step 180860, total loss = 0.51, batch loss = 0.26 (279.7 examples/sec; 0.029 sec/batch; 0h:08m:53s remains)
INFO - root - 2022-02-24 21:18:03.386663: step 180870, total loss = 0.65, batch loss = 0.39 (296.5 examples/sec; 0.027 sec/batch; 0h:08m:22s remains)
INFO - root - 2022-02-24 21:18:03.781883: step 180880, total loss = 0.51, batch loss = 0.25 (239.2 examples/sec; 0.033 sec/batch; 0h:10m:22s remains)
INFO - root - 2022-02-24 21:18:04.161003: step 180890, total loss = 0.51, batch loss = 0.25 (301.5 examples/sec; 0.027 sec/batch; 0h:08m:13s remains)
INFO - root - 2022-02-24 21:18:04.442005: step 180900, total loss = 0.48, batch loss = 0.22 (354.8 examples/sec; 0.023 sec/batch; 0h:06m:59s remains)
INFO - root - 2022-02-24 21:18:04.830259: step 180910, total loss = 0.65, batch loss = 0.39 (268.8 examples/sec; 0.030 sec/batch; 0h:09m:13s remains)
INFO - root - 2022-02-24 21:18:05.279581: step 180920, total loss = 0.64, batch loss = 0.38 (342.4 examples/sec; 0.023 sec/batch; 0h:07m:14s remains)
INFO - root - 2022-02-24 21:18:05.631119: step 180930, total loss = 0.47, batch loss = 0.21 (159.2 examples/sec; 0.050 sec/batch; 0h:15m:33s remains)
INFO - root - 2022-02-24 21:18:05.915433: step 180940, total loss = 0.49, batch loss = 0.23 (372.2 examples/sec; 0.021 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:18:06.242812: step 180950, total loss = 0.54, batch loss = 0.28 (220.9 examples/sec; 0.036 sec/batch; 0h:11m:11s remains)
INFO - root - 2022-02-24 21:18:06.518904: step 180960, total loss = 0.63, batch loss = 0.37 (356.5 examples/sec; 0.022 sec/batch; 0h:06m:55s remains)
INFO - root - 2022-02-24 21:18:06.961453: step 180970, total loss = 0.52, batch loss = 0.26 (80.3 examples/sec; 0.100 sec/batch; 0h:30m:47s remains)
INFO - root - 2022-02-24 21:18:07.343681: step 180980, total loss = 0.51, batch loss = 0.26 (231.0 examples/sec; 0.035 sec/batch; 0h:10m:41s remains)
INFO - root - 2022-02-24 21:18:07.719670: step 180990, total loss = 0.46, batch loss = 0.20 (229.3 examples/sec; 0.035 sec/batch; 0h:10m:45s remains)
INFO - root - 2022-02-24 21:18:08.020694: step 181000, total loss = 0.47, batch loss = 0.22 (195.8 examples/sec; 0.041 sec/batch; 0h:12m:36s remains)
INFO - root - 2022-02-24 21:18:08.410518: step 181010, total loss = 0.51, batch loss = 0.25 (258.1 examples/sec; 0.031 sec/batch; 0h:09m:33s remains)
INFO - root - 2022-02-24 21:18:08.800688: step 181020, total loss = 0.62, batch loss = 0.36 (178.2 examples/sec; 0.045 sec/batch; 0h:13m:49s remains)
INFO - root - 2022-02-24 21:18:09.160988: step 181030, total loss = 0.48, batch loss = 0.23 (239.9 examples/sec; 0.033 sec/batch; 0h:10m:15s remains)
INFO - root - 2022-02-24 21:18:09.574658: step 181040, total loss = 0.57, batch loss = 0.31 (339.3 examples/sec; 0.024 sec/batch; 0h:07m:15s remains)
INFO - root - 2022-02-24 21:18:09.922718: step 181050, total loss = 0.56, batch loss = 0.30 (205.9 examples/sec; 0.039 sec/batch; 0h:11m:56s remains)
INFO - root - 2022-02-24 21:18:10.330145: step 181060, total loss = 0.57, batch loss = 0.32 (255.0 examples/sec; 0.031 sec/batch; 0h:09m:38s remains)
INFO - root - 2022-02-24 21:18:10.684885: step 181070, total loss = 0.56, batch loss = 0.31 (304.6 examples/sec; 0.026 sec/batch; 0h:08m:04s remains)
INFO - root - 2022-02-24 21:18:11.041294: step 181080, total loss = 0.51, batch loss = 0.25 (312.6 examples/sec; 0.026 sec/batch; 0h:07m:51s remains)
INFO - root - 2022-02-24 21:18:11.450977: step 181090, total loss = 0.65, batch loss = 0.39 (358.4 examples/sec; 0.022 sec/batch; 0h:06m:50s remains)
INFO - root - 2022-02-24 21:18:11.846801: step 181100, total loss = 0.54, batch loss = 0.28 (250.9 examples/sec; 0.032 sec/batch; 0h:09m:46s remains)
INFO - root - 2022-02-24 21:18:12.245053: step 181110, total loss = 0.48, batch loss = 0.22 (158.7 examples/sec; 0.050 sec/batch; 0h:15m:27s remains)
INFO - root - 2022-02-24 21:18:12.566896: step 181120, total loss = 0.56, batch loss = 0.30 (272.3 examples/sec; 0.029 sec/batch; 0h:08m:59s remains)
INFO - root - 2022-02-24 21:18:12.838975: step 181130, total loss = 0.47, batch loss = 0.21 (334.4 examples/sec; 0.024 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:18:13.331329: step 181140, total loss = 0.45, batch loss = 0.19 (158.9 examples/sec; 0.050 sec/batch; 0h:15m:24s remains)
INFO - root - 2022-02-24 21:18:13.772492: step 181150, total loss = 0.50, batch loss = 0.25 (193.2 examples/sec; 0.041 sec/batch; 0h:12m:39s remains)
INFO - root - 2022-02-24 21:18:14.099197: step 181160, total loss = 0.54, batch loss = 0.28 (356.4 examples/sec; 0.022 sec/batch; 0h:06m:51s remains)
INFO - root - 2022-02-24 21:18:14.458583: step 181170, total loss = 0.50, batch loss = 0.25 (280.7 examples/sec; 0.029 sec/batch; 0h:08m:42s remains)
INFO - root - 2022-02-24 21:18:14.869306: step 181180, total loss = 0.50, batch loss = 0.25 (141.1 examples/sec; 0.057 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:18:15.383159: step 181190, total loss = 0.51, batch loss = 0.25 (287.3 examples/sec; 0.028 sec/batch; 0h:08m:29s remains)
INFO - root - 2022-02-24 21:18:15.660476: step 181200, total loss = 0.57, batch loss = 0.31 (307.0 examples/sec; 0.026 sec/batch; 0h:07m:56s remains)
INFO - root - 2022-02-24 21:18:16.011683: step 181210, total loss = 0.59, batch loss = 0.33 (330.3 examples/sec; 0.024 sec/batch; 0h:07m:22s remains)
INFO - root - 2022-02-24 21:18:16.368297: step 181220, total loss = 0.52, batch loss = 0.26 (179.7 examples/sec; 0.045 sec/batch; 0h:13m:33s remains)
INFO - root - 2022-02-24 21:18:16.772853: step 181230, total loss = 0.56, batch loss = 0.30 (138.6 examples/sec; 0.058 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 21:18:17.173713: step 181240, total loss = 0.49, batch loss = 0.23 (193.0 examples/sec; 0.041 sec/batch; 0h:12m:36s remains)
INFO - root - 2022-02-24 21:18:17.583079: step 181250, total loss = 0.47, batch loss = 0.21 (196.3 examples/sec; 0.041 sec/batch; 0h:12m:23s remains)
INFO - root - 2022-02-24 21:18:17.876550: step 181260, total loss = 0.64, batch loss = 0.38 (236.3 examples/sec; 0.034 sec/batch; 0h:10m:17s remains)
INFO - root - 2022-02-24 21:18:18.200962: step 181270, total loss = 0.46, batch loss = 0.21 (127.0 examples/sec; 0.063 sec/batch; 0h:19m:07s remains)
INFO - root - 2022-02-24 21:18:18.541539: step 181280, total loss = 0.60, batch loss = 0.35 (177.1 examples/sec; 0.045 sec/batch; 0h:13m:42s remains)
INFO - root - 2022-02-24 21:18:18.987998: step 181290, total loss = 0.53, batch loss = 0.27 (167.4 examples/sec; 0.048 sec/batch; 0h:14m:30s remains)
INFO - root - 2022-02-24 21:18:19.446649: step 181300, total loss = 0.62, batch loss = 0.36 (351.1 examples/sec; 0.023 sec/batch; 0h:06m:54s remains)
INFO - root - 2022-02-24 21:18:19.867812: step 181310, total loss = 0.52, batch loss = 0.27 (184.2 examples/sec; 0.043 sec/batch; 0h:13m:09s remains)
INFO - root - 2022-02-24 21:18:20.216549: step 181320, total loss = 0.51, batch loss = 0.26 (185.7 examples/sec; 0.043 sec/batch; 0h:13m:03s remains)
INFO - root - 2022-02-24 21:18:20.663507: step 181330, total loss = 0.58, batch loss = 0.33 (115.0 examples/sec; 0.070 sec/batch; 0h:21m:04s remains)
INFO - root - 2022-02-24 21:18:21.171986: step 181340, total loss = 0.55, batch loss = 0.29 (92.4 examples/sec; 0.087 sec/batch; 0h:26m:11s remains)
INFO - root - 2022-02-24 21:18:21.526650: step 181350, total loss = 0.61, batch loss = 0.36 (240.0 examples/sec; 0.033 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:18:21.847397: step 181360, total loss = 0.50, batch loss = 0.24 (330.9 examples/sec; 0.024 sec/batch; 0h:07m:18s remains)
INFO - root - 2022-02-24 21:18:22.185709: step 181370, total loss = 0.49, batch loss = 0.23 (236.9 examples/sec; 0.034 sec/batch; 0h:10m:12s remains)
INFO - root - 2022-02-24 21:18:22.487822: step 181380, total loss = 0.57, batch loss = 0.31 (298.3 examples/sec; 0.027 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:18:22.950949: step 181390, total loss = 0.51, batch loss = 0.26 (252.4 examples/sec; 0.032 sec/batch; 0h:09m:33s remains)
INFO - root - 2022-02-24 21:18:23.282189: step 181400, total loss = 0.47, batch loss = 0.22 (191.6 examples/sec; 0.042 sec/batch; 0h:12m:35s remains)
INFO - root - 2022-02-24 21:18:23.675035: step 181410, total loss = 0.50, batch loss = 0.25 (329.4 examples/sec; 0.024 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:18:24.054691: step 181420, total loss = 0.61, batch loss = 0.35 (248.9 examples/sec; 0.032 sec/batch; 0h:09m:41s remains)
INFO - root - 2022-02-24 21:18:24.339926: step 181430, total loss = 0.59, batch loss = 0.33 (234.6 examples/sec; 0.034 sec/batch; 0h:10m:16s remains)
INFO - root - 2022-02-24 21:18:24.639685: step 181440, total loss = 0.61, batch loss = 0.36 (355.2 examples/sec; 0.023 sec/batch; 0h:06m:46s remains)
INFO - root - 2022-02-24 21:18:25.089626: step 181450, total loss = 0.55, batch loss = 0.30 (83.1 examples/sec; 0.096 sec/batch; 0h:28m:58s remains)
INFO - root - 2022-02-24 21:18:25.437261: step 181460, total loss = 0.54, batch loss = 0.28 (350.4 examples/sec; 0.023 sec/batch; 0h:06m:51s remains)
INFO - root - 2022-02-24 21:18:25.883545: step 181470, total loss = 0.50, batch loss = 0.24 (334.6 examples/sec; 0.024 sec/batch; 0h:07m:11s remains)
INFO - root - 2022-02-24 21:18:26.133486: step 181480, total loss = 0.63, batch loss = 0.38 (348.4 examples/sec; 0.023 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:18:26.561440: step 181490, total loss = 0.63, batch loss = 0.37 (198.1 examples/sec; 0.040 sec/batch; 0h:12m:07s remains)
INFO - root - 2022-02-24 21:18:26.972465: step 181500, total loss = 0.55, batch loss = 0.30 (345.5 examples/sec; 0.023 sec/batch; 0h:06m:56s remains)
INFO - root - 2022-02-24 21:18:27.649716: step 181510, total loss = 0.55, batch loss = 0.29 (300.7 examples/sec; 0.027 sec/batch; 0h:07m:58s remains)
INFO - root - 2022-02-24 21:18:28.188083: step 181520, total loss = 0.51, batch loss = 0.26 (59.0 examples/sec; 0.135 sec/batch; 0h:40m:35s remains)
INFO - root - 2022-02-24 21:18:28.692972: step 181530, total loss = 0.58, batch loss = 0.32 (233.0 examples/sec; 0.034 sec/batch; 0h:10m:16s remains)
INFO - root - 2022-02-24 21:18:29.406472: step 181540, total loss = 0.51, batch loss = 0.25 (190.5 examples/sec; 0.042 sec/batch; 0h:12m:34s remains)
INFO - root - 2022-02-24 21:18:29.846342: step 181550, total loss = 0.56, batch loss = 0.31 (318.9 examples/sec; 0.025 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:18:30.312806: step 181560, total loss = 0.60, batch loss = 0.35 (80.2 examples/sec; 0.100 sec/batch; 0h:29m:49s remains)
INFO - root - 2022-02-24 21:18:31.190060: step 181570, total loss = 0.56, batch loss = 0.31 (118.4 examples/sec; 0.068 sec/batch; 0h:20m:11s remains)
INFO - root - 2022-02-24 21:18:31.586052: step 181580, total loss = 0.58, batch loss = 0.33 (260.2 examples/sec; 0.031 sec/batch; 0h:09m:10s remains)
INFO - root - 2022-02-24 21:18:32.008146: step 181590, total loss = 0.58, batch loss = 0.32 (181.5 examples/sec; 0.044 sec/batch; 0h:13m:09s remains)
INFO - root - 2022-02-24 21:18:32.368889: step 181600, total loss = 0.57, batch loss = 0.32 (255.6 examples/sec; 0.031 sec/batch; 0h:09m:20s remains)
INFO - root - 2022-02-24 21:18:32.727014: step 181610, total loss = 0.54, batch loss = 0.29 (198.0 examples/sec; 0.040 sec/batch; 0h:12m:02s remains)
INFO - root - 2022-02-24 21:18:33.113460: step 181620, total loss = 0.49, batch loss = 0.23 (171.1 examples/sec; 0.047 sec/batch; 0h:13m:56s remains)
INFO - root - 2022-02-24 21:18:33.467399: step 181630, total loss = 0.48, batch loss = 0.22 (162.6 examples/sec; 0.049 sec/batch; 0h:14m:39s remains)
INFO - root - 2022-02-24 21:18:33.856507: step 181640, total loss = 0.46, batch loss = 0.20 (107.8 examples/sec; 0.074 sec/batch; 0h:22m:05s remains)
INFO - root - 2022-02-24 21:18:34.317261: step 181650, total loss = 0.60, batch loss = 0.34 (287.0 examples/sec; 0.028 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:18:34.653710: step 181660, total loss = 0.50, batch loss = 0.24 (345.1 examples/sec; 0.023 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:18:34.957516: step 181670, total loss = 0.52, batch loss = 0.27 (244.7 examples/sec; 0.033 sec/batch; 0h:09m:43s remains)
INFO - root - 2022-02-24 21:18:35.251561: step 181680, total loss = 0.49, batch loss = 0.23 (330.5 examples/sec; 0.024 sec/batch; 0h:07m:11s remains)
INFO - root - 2022-02-24 21:18:35.533379: step 181690, total loss = 0.56, batch loss = 0.30 (346.4 examples/sec; 0.023 sec/batch; 0h:06m:51s remains)
INFO - root - 2022-02-24 21:18:35.904574: step 181700, total loss = 0.55, batch loss = 0.30 (266.1 examples/sec; 0.030 sec/batch; 0h:08m:55s remains)
INFO - root - 2022-02-24 21:18:36.414696: step 181710, total loss = 0.52, batch loss = 0.26 (319.2 examples/sec; 0.025 sec/batch; 0h:07m:25s remains)
INFO - root - 2022-02-24 21:18:36.696606: step 181720, total loss = 0.57, batch loss = 0.31 (217.8 examples/sec; 0.037 sec/batch; 0h:10m:53s remains)
INFO - root - 2022-02-24 21:18:37.032048: step 181730, total loss = 0.52, batch loss = 0.26 (320.7 examples/sec; 0.025 sec/batch; 0h:07m:23s remains)
INFO - root - 2022-02-24 21:18:37.343428: step 181740, total loss = 0.50, batch loss = 0.25 (263.5 examples/sec; 0.030 sec/batch; 0h:08m:59s remains)
INFO - root - 2022-02-24 21:18:37.791215: step 181750, total loss = 0.55, batch loss = 0.30 (131.8 examples/sec; 0.061 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:18:38.229312: step 181760, total loss = 0.50, batch loss = 0.24 (239.8 examples/sec; 0.033 sec/batch; 0h:09m:51s remains)
INFO - root - 2022-02-24 21:18:38.645852: step 181770, total loss = 0.58, batch loss = 0.32 (128.2 examples/sec; 0.062 sec/batch; 0h:18m:26s remains)
INFO - root - 2022-02-24 21:18:38.932940: step 181780, total loss = 0.62, batch loss = 0.36 (332.4 examples/sec; 0.024 sec/batch; 0h:07m:06s remains)
INFO - root - 2022-02-24 21:18:39.247638: step 181790, total loss = 0.50, batch loss = 0.24 (266.3 examples/sec; 0.030 sec/batch; 0h:08m:51s remains)
INFO - root - 2022-02-24 21:18:39.534219: step 181800, total loss = 0.54, batch loss = 0.29 (324.3 examples/sec; 0.025 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:18:40.052786: step 181810, total loss = 0.53, batch loss = 0.27 (122.6 examples/sec; 0.065 sec/batch; 0h:19m:14s remains)
INFO - root - 2022-02-24 21:18:40.465331: step 181820, total loss = 0.61, batch loss = 0.36 (176.3 examples/sec; 0.045 sec/batch; 0h:13m:22s remains)
INFO - root - 2022-02-24 21:18:40.773343: step 181830, total loss = 0.64, batch loss = 0.39 (173.6 examples/sec; 0.046 sec/batch; 0h:13m:34s remains)
INFO - root - 2022-02-24 21:18:41.077981: step 181840, total loss = 0.47, batch loss = 0.21 (274.5 examples/sec; 0.029 sec/batch; 0h:08m:34s remains)
INFO - root - 2022-02-24 21:18:41.341991: step 181850, total loss = 0.50, batch loss = 0.24 (334.7 examples/sec; 0.024 sec/batch; 0h:07m:01s remains)
INFO - root - 2022-02-24 21:18:41.741966: step 181860, total loss = 0.69, batch loss = 0.43 (344.3 examples/sec; 0.023 sec/batch; 0h:06m:49s remains)
INFO - root - 2022-02-24 21:18:42.147357: step 181870, total loss = 0.52, batch loss = 0.26 (151.0 examples/sec; 0.053 sec/batch; 0h:15m:33s remains)
INFO - root - 2022-02-24 21:18:42.545589: step 181880, total loss = 0.58, batch loss = 0.33 (381.6 examples/sec; 0.021 sec/batch; 0h:06m:09s remains)
INFO - root - 2022-02-24 21:18:42.904254: step 181890, total loss = 0.53, batch loss = 0.27 (243.4 examples/sec; 0.033 sec/batch; 0h:09m:38s remains)
INFO - root - 2022-02-24 21:18:43.248100: step 181900, total loss = 0.47, batch loss = 0.21 (337.3 examples/sec; 0.024 sec/batch; 0h:06m:57s remains)
INFO - root - 2022-02-24 21:18:43.619221: step 181910, total loss = 0.49, batch loss = 0.23 (366.7 examples/sec; 0.022 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:18:43.975647: step 181920, total loss = 0.59, batch loss = 0.34 (135.4 examples/sec; 0.059 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:18:44.303761: step 181930, total loss = 0.55, batch loss = 0.30 (125.5 examples/sec; 0.064 sec/batch; 0h:18m:39s remains)
INFO - root - 2022-02-24 21:18:44.672239: step 181940, total loss = 0.55, batch loss = 0.29 (137.5 examples/sec; 0.058 sec/batch; 0h:17m:01s remains)
INFO - root - 2022-02-24 21:18:44.967911: step 181950, total loss = 0.50, batch loss = 0.25 (253.1 examples/sec; 0.032 sec/batch; 0h:09m:14s remains)
INFO - root - 2022-02-24 21:18:45.304840: step 181960, total loss = 0.47, batch loss = 0.21 (208.3 examples/sec; 0.038 sec/batch; 0h:11m:13s remains)
INFO - root - 2022-02-24 21:18:45.630362: step 181970, total loss = 0.51, batch loss = 0.26 (316.8 examples/sec; 0.025 sec/batch; 0h:07m:22s remains)
INFO - root - 2022-02-24 21:18:46.029295: step 181980, total loss = 0.51, batch loss = 0.26 (141.8 examples/sec; 0.056 sec/batch; 0h:16m:28s remains)
INFO - root - 2022-02-24 21:18:46.548462: step 181990, total loss = 0.51, batch loss = 0.26 (127.7 examples/sec; 0.063 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:18:46.940063: step 182000, total loss = 0.54, batch loss = 0.28 (188.3 examples/sec; 0.042 sec/batch; 0h:12m:23s remains)
INFO - root - 2022-02-24 21:18:47.320165: step 182010, total loss = 0.51, batch loss = 0.25 (336.9 examples/sec; 0.024 sec/batch; 0h:06m:55s remains)
INFO - root - 2022-02-24 21:18:47.696813: step 182020, total loss = 0.75, batch loss = 0.49 (169.2 examples/sec; 0.047 sec/batch; 0h:13m:46s remains)
INFO - root - 2022-02-24 21:18:48.016718: step 182030, total loss = 0.47, batch loss = 0.21 (317.3 examples/sec; 0.025 sec/batch; 0h:07m:20s remains)
INFO - root - 2022-02-24 21:18:48.456662: step 182040, total loss = 0.50, batch loss = 0.24 (369.4 examples/sec; 0.022 sec/batch; 0h:06m:18s remains)
INFO - root - 2022-02-24 21:18:48.828974: step 182050, total loss = 0.53, batch loss = 0.27 (123.6 examples/sec; 0.065 sec/batch; 0h:18m:49s remains)
INFO - root - 2022-02-24 21:18:49.086233: step 182060, total loss = 0.59, batch loss = 0.33 (282.2 examples/sec; 0.028 sec/batch; 0h:08m:14s remains)
INFO - root - 2022-02-24 21:18:49.421300: step 182070, total loss = 0.60, batch loss = 0.35 (275.6 examples/sec; 0.029 sec/batch; 0h:08m:25s remains)
INFO - root - 2022-02-24 21:18:49.726921: step 182080, total loss = 0.50, batch loss = 0.24 (336.3 examples/sec; 0.024 sec/batch; 0h:06m:54s remains)
INFO - root - 2022-02-24 21:18:50.077185: step 182090, total loss = 0.49, batch loss = 0.24 (204.3 examples/sec; 0.039 sec/batch; 0h:11m:21s remains)
INFO - root - 2022-02-24 21:18:50.546296: step 182100, total loss = 0.47, batch loss = 0.21 (102.8 examples/sec; 0.078 sec/batch; 0h:22m:33s remains)
INFO - root - 2022-02-24 21:18:51.005445: step 182110, total loss = 0.49, batch loss = 0.23 (311.7 examples/sec; 0.026 sec/batch; 0h:07m:26s remains)
INFO - root - 2022-02-24 21:18:51.336194: step 182120, total loss = 0.52, batch loss = 0.26 (377.3 examples/sec; 0.021 sec/batch; 0h:06m:08s remains)
INFO - root - 2022-02-24 21:18:51.725141: step 182130, total loss = 0.63, batch loss = 0.37 (232.5 examples/sec; 0.034 sec/batch; 0h:09m:57s remains)
INFO - root - 2022-02-24 21:18:51.990311: step 182140, total loss = 0.49, batch loss = 0.23 (281.2 examples/sec; 0.028 sec/batch; 0h:08m:13s remains)
INFO - root - 2022-02-24 21:18:52.305429: step 182150, total loss = 0.61, batch loss = 0.35 (136.8 examples/sec; 0.058 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:18:52.643623: step 182160, total loss = 0.55, batch loss = 0.29 (290.2 examples/sec; 0.028 sec/batch; 0h:07m:58s remains)
INFO - root - 2022-02-24 21:18:53.021267: step 182170, total loss = 0.50, batch loss = 0.24 (264.5 examples/sec; 0.030 sec/batch; 0h:08m:44s remains)
INFO - root - 2022-02-24 21:18:53.322372: step 182180, total loss = 0.55, batch loss = 0.30 (168.6 examples/sec; 0.047 sec/batch; 0h:13m:41s remains)
INFO - root - 2022-02-24 21:18:53.590868: step 182190, total loss = 0.51, batch loss = 0.26 (382.4 examples/sec; 0.021 sec/batch; 0h:06m:02s remains)
INFO - root - 2022-02-24 21:18:53.927082: step 182200, total loss = 0.52, batch loss = 0.27 (158.6 examples/sec; 0.050 sec/batch; 0h:14m:32s remains)
INFO - root - 2022-02-24 21:18:54.266961: step 182210, total loss = 0.57, batch loss = 0.31 (307.1 examples/sec; 0.026 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:18:54.674804: step 182220, total loss = 0.49, batch loss = 0.23 (146.2 examples/sec; 0.055 sec/batch; 0h:15m:45s remains)
INFO - root - 2022-02-24 21:18:55.052027: step 182230, total loss = 0.55, batch loss = 0.29 (329.2 examples/sec; 0.024 sec/batch; 0h:06m:59s remains)
INFO - root - 2022-02-24 21:18:55.326541: step 182240, total loss = 0.49, batch loss = 0.23 (334.5 examples/sec; 0.024 sec/batch; 0h:06m:52s remains)
INFO - root - 2022-02-24 21:18:55.703437: step 182250, total loss = 0.55, batch loss = 0.30 (219.2 examples/sec; 0.036 sec/batch; 0h:10m:29s remains)
INFO - root - 2022-02-24 21:18:56.010290: step 182260, total loss = 0.45, batch loss = 0.20 (320.4 examples/sec; 0.025 sec/batch; 0h:07m:10s remains)
INFO - root - 2022-02-24 21:18:56.425123: step 182270, total loss = 0.67, batch loss = 0.42 (321.9 examples/sec; 0.025 sec/batch; 0h:07m:08s remains)
INFO - root - 2022-02-24 21:18:56.855207: step 182280, total loss = 0.50, batch loss = 0.24 (177.0 examples/sec; 0.045 sec/batch; 0h:12m:58s remains)
INFO - root - 2022-02-24 21:18:57.144110: step 182290, total loss = 0.53, batch loss = 0.28 (312.2 examples/sec; 0.026 sec/batch; 0h:07m:20s remains)
INFO - root - 2022-02-24 21:18:57.477257: step 182300, total loss = 0.50, batch loss = 0.24 (307.9 examples/sec; 0.026 sec/batch; 0h:07m:26s remains)
INFO - root - 2022-02-24 21:18:57.882166: step 182310, total loss = 0.53, batch loss = 0.28 (351.5 examples/sec; 0.023 sec/batch; 0h:06m:31s remains)
INFO - root - 2022-02-24 21:18:58.294738: step 182320, total loss = 0.49, batch loss = 0.23 (309.0 examples/sec; 0.026 sec/batch; 0h:07m:24s remains)
INFO - root - 2022-02-24 21:18:58.686168: step 182330, total loss = 0.50, batch loss = 0.24 (185.4 examples/sec; 0.043 sec/batch; 0h:12m:20s remains)
INFO - root - 2022-02-24 21:18:59.006262: step 182340, total loss = 0.55, batch loss = 0.30 (220.0 examples/sec; 0.036 sec/batch; 0h:10m:23s remains)
INFO - root - 2022-02-24 21:18:59.311495: step 182350, total loss = 0.77, batch loss = 0.51 (195.3 examples/sec; 0.041 sec/batch; 0h:11m:42s remains)
INFO - root - 2022-02-24 21:18:59.679514: step 182360, total loss = 0.67, batch loss = 0.42 (136.3 examples/sec; 0.059 sec/batch; 0h:16m:46s remains)
INFO - root - 2022-02-24 21:19:00.119073: step 182370, total loss = 0.47, batch loss = 0.22 (147.1 examples/sec; 0.054 sec/batch; 0h:15m:31s remains)
INFO - root - 2022-02-24 21:19:00.686097: step 182380, total loss = 0.48, batch loss = 0.22 (355.1 examples/sec; 0.023 sec/batch; 0h:06m:25s remains)
INFO - root - 2022-02-24 21:19:01.098618: step 182390, total loss = 0.57, batch loss = 0.31 (150.0 examples/sec; 0.053 sec/batch; 0h:15m:12s remains)
INFO - root - 2022-02-24 21:19:01.536946: step 182400, total loss = 0.45, batch loss = 0.20 (313.0 examples/sec; 0.026 sec/batch; 0h:07m:17s remains)
INFO - root - 2022-02-24 21:19:02.422616: step 182410, total loss = 0.57, batch loss = 0.31 (99.9 examples/sec; 0.080 sec/batch; 0h:22m:48s remains)
INFO - root - 2022-02-24 21:19:02.847871: step 182420, total loss = 0.50, batch loss = 0.25 (147.1 examples/sec; 0.054 sec/batch; 0h:15m:29s remains)
INFO - root - 2022-02-24 21:19:03.155081: step 182430, total loss = 0.51, batch loss = 0.26 (380.5 examples/sec; 0.021 sec/batch; 0h:05m:58s remains)
INFO - root - 2022-02-24 21:19:03.510536: step 182440, total loss = 0.57, batch loss = 0.31 (205.6 examples/sec; 0.039 sec/batch; 0h:11m:03s remains)
INFO - root - 2022-02-24 21:19:03.964714: step 182450, total loss = 0.56, batch loss = 0.30 (109.0 examples/sec; 0.073 sec/batch; 0h:20m:51s remains)
INFO - root - 2022-02-24 21:19:04.334550: step 182460, total loss = 0.53, batch loss = 0.27 (193.2 examples/sec; 0.041 sec/batch; 0h:11m:45s remains)
INFO - root - 2022-02-24 21:19:04.798539: step 182470, total loss = 0.55, batch loss = 0.30 (122.5 examples/sec; 0.065 sec/batch; 0h:18m:31s remains)
INFO - root - 2022-02-24 21:19:05.172682: step 182480, total loss = 0.50, batch loss = 0.24 (286.1 examples/sec; 0.028 sec/batch; 0h:07m:55s remains)
INFO - root - 2022-02-24 21:19:05.532386: step 182490, total loss = 0.44, batch loss = 0.18 (137.3 examples/sec; 0.058 sec/batch; 0h:16m:30s remains)
INFO - root - 2022-02-24 21:19:05.880444: step 182500, total loss = 0.58, batch loss = 0.33 (314.6 examples/sec; 0.025 sec/batch; 0h:07m:12s remains)
INFO - root - 2022-02-24 21:19:06.355242: step 182510, total loss = 0.55, batch loss = 0.30 (126.1 examples/sec; 0.063 sec/batch; 0h:17m:57s remains)
INFO - root - 2022-02-24 21:19:07.003747: step 182520, total loss = 0.56, batch loss = 0.30 (196.3 examples/sec; 0.041 sec/batch; 0h:11m:31s remains)
INFO - root - 2022-02-24 21:19:07.377611: step 182530, total loss = 0.51, batch loss = 0.25 (272.8 examples/sec; 0.029 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:19:07.715262: step 182540, total loss = 0.54, batch loss = 0.29 (302.0 examples/sec; 0.026 sec/batch; 0h:07m:29s remains)
INFO - root - 2022-02-24 21:19:08.105482: step 182550, total loss = 0.54, batch loss = 0.29 (188.9 examples/sec; 0.042 sec/batch; 0h:11m:57s remains)
INFO - root - 2022-02-24 21:19:08.522125: step 182560, total loss = 0.51, batch loss = 0.25 (110.2 examples/sec; 0.073 sec/batch; 0h:20m:30s remains)
INFO - root - 2022-02-24 21:19:08.861161: step 182570, total loss = 0.54, batch loss = 0.28 (288.7 examples/sec; 0.028 sec/batch; 0h:07m:49s remains)
INFO - root - 2022-02-24 21:19:09.180453: step 182580, total loss = 0.55, batch loss = 0.29 (156.1 examples/sec; 0.051 sec/batch; 0h:14m:27s remains)
INFO - root - 2022-02-24 21:19:09.478054: step 182590, total loss = 0.54, batch loss = 0.28 (337.0 examples/sec; 0.024 sec/batch; 0h:06m:41s remains)
INFO - root - 2022-02-24 21:19:09.759031: step 182600, total loss = 0.53, batch loss = 0.27 (266.2 examples/sec; 0.030 sec/batch; 0h:08m:27s remains)
INFO - root - 2022-02-24 21:19:10.231326: step 182610, total loss = 0.50, batch loss = 0.24 (157.8 examples/sec; 0.051 sec/batch; 0h:14m:16s remains)
INFO - root - 2022-02-24 21:19:10.660186: step 182620, total loss = 0.54, batch loss = 0.28 (345.3 examples/sec; 0.023 sec/batch; 0h:06m:31s remains)
INFO - root - 2022-02-24 21:19:10.984099: step 182630, total loss = 0.49, batch loss = 0.24 (257.1 examples/sec; 0.031 sec/batch; 0h:08m:44s remains)
INFO - root - 2022-02-24 21:19:11.295973: step 182640, total loss = 0.48, batch loss = 0.22 (318.6 examples/sec; 0.025 sec/batch; 0h:07m:03s remains)
INFO - root - 2022-02-24 21:19:11.609690: step 182650, total loss = 0.56, batch loss = 0.31 (323.5 examples/sec; 0.025 sec/batch; 0h:06m:56s remains)
INFO - root - 2022-02-24 21:19:11.985921: step 182660, total loss = 0.46, batch loss = 0.21 (276.7 examples/sec; 0.029 sec/batch; 0h:08m:06s remains)
INFO - root - 2022-02-24 21:19:12.379251: step 182670, total loss = 0.60, batch loss = 0.34 (163.1 examples/sec; 0.049 sec/batch; 0h:13m:45s remains)
INFO - root - 2022-02-24 21:19:12.804156: step 182680, total loss = 0.56, batch loss = 0.31 (88.2 examples/sec; 0.091 sec/batch; 0h:25m:25s remains)
INFO - root - 2022-02-24 21:19:13.112905: step 182690, total loss = 0.60, batch loss = 0.34 (317.2 examples/sec; 0.025 sec/batch; 0h:07m:03s remains)
INFO - root - 2022-02-24 21:19:13.374479: step 182700, total loss = 0.49, batch loss = 0.23 (158.5 examples/sec; 0.050 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:19:13.784723: step 182710, total loss = 0.53, batch loss = 0.27 (156.5 examples/sec; 0.051 sec/batch; 0h:14m:18s remains)
INFO - root - 2022-02-24 21:19:14.120340: step 182720, total loss = 0.59, batch loss = 0.34 (287.5 examples/sec; 0.028 sec/batch; 0h:07m:46s remains)
INFO - root - 2022-02-24 21:19:14.488636: step 182730, total loss = 0.56, batch loss = 0.30 (345.0 examples/sec; 0.023 sec/batch; 0h:06m:28s remains)
INFO - root - 2022-02-24 21:19:14.850925: step 182740, total loss = 0.55, batch loss = 0.29 (170.3 examples/sec; 0.047 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:19:15.106486: step 182750, total loss = 0.59, batch loss = 0.34 (300.2 examples/sec; 0.027 sec/batch; 0h:07m:26s remains)
INFO - root - 2022-02-24 21:19:15.395381: step 182760, total loss = 0.52, batch loss = 0.27 (311.5 examples/sec; 0.026 sec/batch; 0h:07m:09s remains)
INFO - root - 2022-02-24 21:19:15.711512: step 182770, total loss = 0.60, batch loss = 0.34 (311.7 examples/sec; 0.026 sec/batch; 0h:07m:09s remains)
INFO - root - 2022-02-24 21:19:16.040008: step 182780, total loss = 0.53, batch loss = 0.28 (357.6 examples/sec; 0.022 sec/batch; 0h:06m:14s remains)
INFO - root - 2022-02-24 21:19:16.448349: step 182790, total loss = 0.58, batch loss = 0.32 (265.0 examples/sec; 0.030 sec/batch; 0h:08m:24s remains)
INFO - root - 2022-02-24 21:19:16.895994: step 182800, total loss = 0.50, batch loss = 0.25 (229.8 examples/sec; 0.035 sec/batch; 0h:09m:41s remains)
INFO - root - 2022-02-24 21:19:17.235980: step 182810, total loss = 0.48, batch loss = 0.22 (371.6 examples/sec; 0.022 sec/batch; 0h:05m:59s remains)
INFO - root - 2022-02-24 21:19:17.490117: step 182820, total loss = 0.50, batch loss = 0.25 (365.7 examples/sec; 0.022 sec/batch; 0h:06m:04s remains)
INFO - root - 2022-02-24 21:19:17.812526: step 182830, total loss = 0.51, batch loss = 0.25 (322.5 examples/sec; 0.025 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:19:18.197732: step 182840, total loss = 0.48, batch loss = 0.23 (382.8 examples/sec; 0.021 sec/batch; 0h:05m:48s remains)
INFO - root - 2022-02-24 21:19:18.600518: step 182850, total loss = 0.55, batch loss = 0.29 (203.1 examples/sec; 0.039 sec/batch; 0h:10m:55s remains)
INFO - root - 2022-02-24 21:19:18.907884: step 182860, total loss = 0.53, batch loss = 0.27 (323.0 examples/sec; 0.025 sec/batch; 0h:06m:52s remains)
INFO - root - 2022-02-24 21:19:19.244911: step 182870, total loss = 0.50, batch loss = 0.24 (281.7 examples/sec; 0.028 sec/batch; 0h:07m:52s remains)
INFO - root - 2022-02-24 21:19:19.628348: step 182880, total loss = 0.49, batch loss = 0.23 (269.0 examples/sec; 0.030 sec/batch; 0h:08m:14s remains)
INFO - root - 2022-02-24 21:19:20.040238: step 182890, total loss = 0.67, batch loss = 0.41 (230.5 examples/sec; 0.035 sec/batch; 0h:09m:36s remains)
INFO - root - 2022-02-24 21:19:20.441905: step 182900, total loss = 0.45, batch loss = 0.20 (358.3 examples/sec; 0.022 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:19:20.824947: step 182910, total loss = 0.49, batch loss = 0.24 (319.0 examples/sec; 0.025 sec/batch; 0h:06m:55s remains)
INFO - root - 2022-02-24 21:19:21.174475: step 182920, total loss = 0.48, batch loss = 0.22 (185.4 examples/sec; 0.043 sec/batch; 0h:11m:55s remains)
INFO - root - 2022-02-24 21:19:21.502550: step 182930, total loss = 0.66, batch loss = 0.40 (176.4 examples/sec; 0.045 sec/batch; 0h:12m:31s remains)
INFO - root - 2022-02-24 21:19:21.912995: step 182940, total loss = 0.49, batch loss = 0.24 (130.6 examples/sec; 0.061 sec/batch; 0h:16m:54s remains)
INFO - root - 2022-02-24 21:19:22.287849: step 182950, total loss = 0.49, batch loss = 0.23 (197.3 examples/sec; 0.041 sec/batch; 0h:11m:10s remains)
INFO - root - 2022-02-24 21:19:22.585602: step 182960, total loss = 0.60, batch loss = 0.34 (210.0 examples/sec; 0.038 sec/batch; 0h:10m:30s remains)
INFO - root - 2022-02-24 21:19:22.866484: step 182970, total loss = 0.50, batch loss = 0.24 (337.4 examples/sec; 0.024 sec/batch; 0h:06m:31s remains)
INFO - root - 2022-02-24 21:19:23.245297: step 182980, total loss = 0.57, batch loss = 0.31 (226.2 examples/sec; 0.035 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:19:23.608150: step 182990, total loss = 0.52, batch loss = 0.26 (144.3 examples/sec; 0.055 sec/batch; 0h:15m:15s remains)
INFO - root - 2022-02-24 21:19:23.997214: step 183000, total loss = 0.51, batch loss = 0.26 (159.9 examples/sec; 0.050 sec/batch; 0h:13m:45s remains)
INFO - root - 2022-02-24 21:19:24.382373: step 183010, total loss = 0.56, batch loss = 0.30 (274.8 examples/sec; 0.029 sec/batch; 0h:08m:00s remains)
INFO - root - 2022-02-24 21:19:24.680488: step 183020, total loss = 0.55, batch loss = 0.29 (271.5 examples/sec; 0.029 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:19:24.946150: step 183030, total loss = 0.50, batch loss = 0.25 (241.9 examples/sec; 0.033 sec/batch; 0h:09m:04s remains)
INFO - root - 2022-02-24 21:19:25.273380: step 183040, total loss = 0.45, batch loss = 0.19 (330.4 examples/sec; 0.024 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:19:25.620690: step 183050, total loss = 0.58, batch loss = 0.32 (229.3 examples/sec; 0.035 sec/batch; 0h:09m:33s remains)
INFO - root - 2022-02-24 21:19:26.008131: step 183060, total loss = 0.52, batch loss = 0.26 (301.2 examples/sec; 0.027 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:19:26.310071: step 183070, total loss = 0.61, batch loss = 0.36 (347.7 examples/sec; 0.023 sec/batch; 0h:06m:17s remains)
INFO - root - 2022-02-24 21:19:26.579707: step 183080, total loss = 0.52, batch loss = 0.26 (324.2 examples/sec; 0.025 sec/batch; 0h:06m:45s remains)
INFO - root - 2022-02-24 21:19:26.942565: step 183090, total loss = 0.48, batch loss = 0.23 (183.5 examples/sec; 0.044 sec/batch; 0h:11m:55s remains)
INFO - root - 2022-02-24 21:19:27.355938: step 183100, total loss = 0.50, batch loss = 0.24 (135.6 examples/sec; 0.059 sec/batch; 0h:16m:07s remains)
INFO - root - 2022-02-24 21:19:27.839264: step 183110, total loss = 0.52, batch loss = 0.26 (249.1 examples/sec; 0.032 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:19:28.221097: step 183120, total loss = 0.69, batch loss = 0.43 (363.8 examples/sec; 0.022 sec/batch; 0h:06m:00s remains)
INFO - root - 2022-02-24 21:19:28.544819: step 183130, total loss = 0.51, batch loss = 0.26 (352.4 examples/sec; 0.023 sec/batch; 0h:06m:11s remains)
INFO - root - 2022-02-24 21:19:28.797128: step 183140, total loss = 0.61, batch loss = 0.35 (361.9 examples/sec; 0.022 sec/batch; 0h:06m:01s remains)
INFO - root - 2022-02-24 21:19:29.094497: step 183150, total loss = 0.60, batch loss = 0.34 (188.4 examples/sec; 0.042 sec/batch; 0h:11m:34s remains)
INFO - root - 2022-02-24 21:19:29.463118: step 183160, total loss = 0.51, batch loss = 0.25 (155.6 examples/sec; 0.051 sec/batch; 0h:13m:59s remains)
INFO - root - 2022-02-24 21:19:29.938119: step 183170, total loss = 0.59, batch loss = 0.33 (187.4 examples/sec; 0.043 sec/batch; 0h:11m:36s remains)
INFO - root - 2022-02-24 21:19:30.335022: step 183180, total loss = 0.70, batch loss = 0.44 (160.5 examples/sec; 0.050 sec/batch; 0h:13m:33s remains)
INFO - root - 2022-02-24 21:19:30.615691: step 183190, total loss = 0.64, batch loss = 0.38 (249.7 examples/sec; 0.032 sec/batch; 0h:08m:42s remains)
INFO - root - 2022-02-24 21:19:30.916686: step 183200, total loss = 0.48, batch loss = 0.22 (329.5 examples/sec; 0.024 sec/batch; 0h:06m:35s remains)
INFO - root - 2022-02-24 21:19:31.281027: step 183210, total loss = 0.52, batch loss = 0.26 (261.6 examples/sec; 0.031 sec/batch; 0h:08m:18s remains)
INFO - root - 2022-02-24 21:19:31.607167: step 183220, total loss = 0.51, batch loss = 0.25 (289.2 examples/sec; 0.028 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:19:32.160037: step 183230, total loss = 0.59, batch loss = 0.34 (178.9 examples/sec; 0.045 sec/batch; 0h:12m:07s remains)
INFO - root - 2022-02-24 21:19:32.488553: step 183240, total loss = 0.51, batch loss = 0.25 (254.5 examples/sec; 0.031 sec/batch; 0h:08m:31s remains)
INFO - root - 2022-02-24 21:19:32.899968: step 183250, total loss = 0.59, batch loss = 0.33 (180.7 examples/sec; 0.044 sec/batch; 0h:11m:59s remains)
INFO - root - 2022-02-24 21:19:33.253437: step 183260, total loss = 0.54, batch loss = 0.28 (271.5 examples/sec; 0.029 sec/batch; 0h:07m:58s remains)
INFO - root - 2022-02-24 21:19:33.587803: step 183270, total loss = 0.46, batch loss = 0.20 (249.7 examples/sec; 0.032 sec/batch; 0h:08m:40s remains)
INFO - root - 2022-02-24 21:19:33.977254: step 183280, total loss = 0.54, batch loss = 0.29 (204.8 examples/sec; 0.039 sec/batch; 0h:10m:33s remains)
INFO - root - 2022-02-24 21:19:34.287789: step 183290, total loss = 0.67, batch loss = 0.42 (303.2 examples/sec; 0.026 sec/batch; 0h:07m:07s remains)
INFO - root - 2022-02-24 21:19:34.569349: step 183300, total loss = 0.52, batch loss = 0.27 (258.4 examples/sec; 0.031 sec/batch; 0h:08m:21s remains)
INFO - root - 2022-02-24 21:19:35.125911: step 183310, total loss = 0.60, batch loss = 0.34 (157.9 examples/sec; 0.051 sec/batch; 0h:13m:40s remains)
INFO - root - 2022-02-24 21:19:35.585863: step 183320, total loss = 0.56, batch loss = 0.31 (238.3 examples/sec; 0.034 sec/batch; 0h:09m:03s remains)
INFO - root - 2022-02-24 21:19:36.079213: step 183330, total loss = 0.66, batch loss = 0.40 (386.3 examples/sec; 0.021 sec/batch; 0h:05m:34s remains)
INFO - root - 2022-02-24 21:19:36.655160: step 183340, total loss = 0.48, batch loss = 0.22 (363.9 examples/sec; 0.022 sec/batch; 0h:05m:55s remains)
INFO - root - 2022-02-24 21:19:37.183167: step 183350, total loss = 0.48, batch loss = 0.23 (331.4 examples/sec; 0.024 sec/batch; 0h:06m:29s remains)
INFO - root - 2022-02-24 21:19:38.281293: step 183360, total loss = 0.61, batch loss = 0.35 (15.0 examples/sec; 0.532 sec/batch; 2h:23m:06s remains)
INFO - root - 2022-02-24 21:19:38.719175: step 183370, total loss = 0.54, batch loss = 0.29 (354.0 examples/sec; 0.023 sec/batch; 0h:06m:04s remains)
INFO - root - 2022-02-24 21:19:39.082969: step 183380, total loss = 0.56, batch loss = 0.30 (286.5 examples/sec; 0.028 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:19:39.366442: step 183390, total loss = 0.56, batch loss = 0.31 (229.2 examples/sec; 0.035 sec/batch; 0h:09m:22s remains)
INFO - root - 2022-02-24 21:19:39.660799: step 183400, total loss = 0.61, batch loss = 0.35 (292.0 examples/sec; 0.027 sec/batch; 0h:07m:21s remains)
INFO - root - 2022-02-24 21:19:40.096729: step 183410, total loss = 0.60, batch loss = 0.34 (95.6 examples/sec; 0.084 sec/batch; 0h:22m:25s remains)
INFO - root - 2022-02-24 21:19:40.553472: step 183420, total loss = 0.49, batch loss = 0.23 (153.8 examples/sec; 0.052 sec/batch; 0h:13m:56s remains)
INFO - root - 2022-02-24 21:19:40.891352: step 183430, total loss = 0.49, batch loss = 0.23 (207.0 examples/sec; 0.039 sec/batch; 0h:10m:21s remains)
INFO - root - 2022-02-24 21:19:41.233228: step 183440, total loss = 0.62, batch loss = 0.36 (219.6 examples/sec; 0.036 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:19:41.541456: step 183450, total loss = 0.56, batch loss = 0.30 (299.5 examples/sec; 0.027 sec/batch; 0h:07m:08s remains)
INFO - root - 2022-02-24 21:19:41.863994: step 183460, total loss = 0.50, batch loss = 0.25 (313.3 examples/sec; 0.026 sec/batch; 0h:06m:49s remains)
INFO - root - 2022-02-24 21:19:42.330220: step 183470, total loss = 0.52, batch loss = 0.26 (140.8 examples/sec; 0.057 sec/batch; 0h:15m:10s remains)
INFO - root - 2022-02-24 21:19:42.723925: step 183480, total loss = 0.55, batch loss = 0.29 (345.7 examples/sec; 0.023 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:19:43.035083: step 183490, total loss = 0.48, batch loss = 0.23 (306.9 examples/sec; 0.026 sec/batch; 0h:06m:57s remains)
INFO - root - 2022-02-24 21:19:43.314881: step 183500, total loss = 0.53, batch loss = 0.27 (245.1 examples/sec; 0.033 sec/batch; 0h:08m:42s remains)
INFO - root - 2022-02-24 21:19:43.658061: step 183510, total loss = 0.67, batch loss = 0.41 (341.8 examples/sec; 0.023 sec/batch; 0h:06m:14s remains)
INFO - root - 2022-02-24 21:19:43.965766: step 183520, total loss = 0.54, batch loss = 0.28 (224.1 examples/sec; 0.036 sec/batch; 0h:09m:30s remains)
INFO - root - 2022-02-24 21:19:44.397292: step 183530, total loss = 0.52, batch loss = 0.26 (115.9 examples/sec; 0.069 sec/batch; 0h:18m:22s remains)
INFO - root - 2022-02-24 21:19:44.791410: step 183540, total loss = 0.58, batch loss = 0.32 (345.0 examples/sec; 0.023 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:19:45.158826: step 183550, total loss = 0.63, batch loss = 0.37 (176.9 examples/sec; 0.045 sec/batch; 0h:12m:01s remains)
INFO - root - 2022-02-24 21:19:45.452805: step 183560, total loss = 0.50, batch loss = 0.24 (242.0 examples/sec; 0.033 sec/batch; 0h:08m:47s remains)
INFO - root - 2022-02-24 21:19:45.783212: step 183570, total loss = 0.69, batch loss = 0.43 (265.5 examples/sec; 0.030 sec/batch; 0h:08m:00s remains)
INFO - root - 2022-02-24 21:19:46.082917: step 183580, total loss = 0.53, batch loss = 0.27 (278.8 examples/sec; 0.029 sec/batch; 0h:07m:36s remains)
INFO - root - 2022-02-24 21:19:46.454092: step 183590, total loss = 0.46, batch loss = 0.21 (357.3 examples/sec; 0.022 sec/batch; 0h:05m:56s remains)
INFO - root - 2022-02-24 21:19:46.845943: step 183600, total loss = 0.56, batch loss = 0.31 (224.8 examples/sec; 0.036 sec/batch; 0h:09m:25s remains)
INFO - root - 2022-02-24 21:19:47.222529: step 183610, total loss = 0.58, batch loss = 0.32 (343.9 examples/sec; 0.023 sec/batch; 0h:06m:09s remains)
INFO - root - 2022-02-24 21:19:47.459838: step 183620, total loss = 0.57, batch loss = 0.31 (327.5 examples/sec; 0.024 sec/batch; 0h:06m:27s remains)
INFO - root - 2022-02-24 21:19:47.821690: step 183630, total loss = 0.65, batch loss = 0.39 (314.2 examples/sec; 0.025 sec/batch; 0h:06m:44s remains)
INFO - root - 2022-02-24 21:19:48.136596: step 183640, total loss = 0.55, batch loss = 0.30 (169.8 examples/sec; 0.047 sec/batch; 0h:12m:27s remains)
INFO - root - 2022-02-24 21:19:48.597366: step 183650, total loss = 0.50, batch loss = 0.25 (164.9 examples/sec; 0.049 sec/batch; 0h:12m:49s remains)
INFO - root - 2022-02-24 21:19:48.954249: step 183660, total loss = 0.57, batch loss = 0.32 (342.6 examples/sec; 0.023 sec/batch; 0h:06m:09s remains)
INFO - root - 2022-02-24 21:19:49.281163: step 183670, total loss = 0.51, batch loss = 0.26 (152.4 examples/sec; 0.052 sec/batch; 0h:13m:51s remains)
INFO - root - 2022-02-24 21:19:49.612095: step 183680, total loss = 0.54, batch loss = 0.28 (194.2 examples/sec; 0.041 sec/batch; 0h:10m:51s remains)
INFO - root - 2022-02-24 21:19:49.909216: step 183690, total loss = 0.49, batch loss = 0.24 (279.2 examples/sec; 0.029 sec/batch; 0h:07m:33s remains)
INFO - root - 2022-02-24 21:19:50.290772: step 183700, total loss = 0.61, batch loss = 0.35 (378.5 examples/sec; 0.021 sec/batch; 0h:05m:33s remains)
INFO - root - 2022-02-24 21:19:50.661786: step 183710, total loss = 0.64, batch loss = 0.38 (333.4 examples/sec; 0.024 sec/batch; 0h:06m:18s remains)
INFO - root - 2022-02-24 21:19:51.104907: step 183720, total loss = 0.54, batch loss = 0.29 (139.5 examples/sec; 0.057 sec/batch; 0h:15m:04s remains)
INFO - root - 2022-02-24 21:19:51.457811: step 183730, total loss = 0.56, batch loss = 0.30 (317.2 examples/sec; 0.025 sec/batch; 0h:06m:37s remains)
INFO - root - 2022-02-24 21:19:51.733322: step 183740, total loss = 0.43, batch loss = 0.17 (294.3 examples/sec; 0.027 sec/batch; 0h:07m:08s remains)
INFO - root - 2022-02-24 21:19:52.117314: step 183750, total loss = 0.48, batch loss = 0.22 (109.5 examples/sec; 0.073 sec/batch; 0h:19m:10s remains)
INFO - root - 2022-02-24 21:19:52.561365: step 183760, total loss = 0.47, batch loss = 0.21 (140.3 examples/sec; 0.057 sec/batch; 0h:14m:57s remains)
INFO - root - 2022-02-24 21:19:52.996632: step 183770, total loss = 0.56, batch loss = 0.30 (382.7 examples/sec; 0.021 sec/batch; 0h:05m:28s remains)
INFO - root - 2022-02-24 21:19:53.338803: step 183780, total loss = 0.58, batch loss = 0.33 (311.3 examples/sec; 0.026 sec/batch; 0h:06m:43s remains)
INFO - root - 2022-02-24 21:19:53.662951: step 183790, total loss = 0.50, batch loss = 0.25 (284.3 examples/sec; 0.028 sec/batch; 0h:07m:22s remains)
INFO - root - 2022-02-24 21:19:53.938461: step 183800, total loss = 0.47, batch loss = 0.21 (223.6 examples/sec; 0.036 sec/batch; 0h:09m:21s remains)
INFO - root - 2022-02-24 21:19:54.321507: step 183810, total loss = 0.63, batch loss = 0.38 (192.9 examples/sec; 0.041 sec/batch; 0h:10m:50s remains)
INFO - root - 2022-02-24 21:19:54.755441: step 183820, total loss = 0.56, batch loss = 0.31 (234.8 examples/sec; 0.034 sec/batch; 0h:08m:54s remains)
INFO - root - 2022-02-24 21:19:55.134793: step 183830, total loss = 0.52, batch loss = 0.27 (334.7 examples/sec; 0.024 sec/batch; 0h:06m:14s remains)
INFO - root - 2022-02-24 21:19:55.431021: step 183840, total loss = 0.58, batch loss = 0.33 (338.2 examples/sec; 0.024 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:19:55.702465: step 183850, total loss = 0.62, batch loss = 0.36 (329.8 examples/sec; 0.024 sec/batch; 0h:06m:19s remains)
INFO - root - 2022-02-24 21:19:55.997063: step 183860, total loss = 0.65, batch loss = 0.39 (376.6 examples/sec; 0.021 sec/batch; 0h:05m:32s remains)
INFO - root - 2022-02-24 21:19:56.380616: step 183870, total loss = 0.45, batch loss = 0.20 (221.1 examples/sec; 0.036 sec/batch; 0h:09m:25s remains)
INFO - root - 2022-02-24 21:19:56.753924: step 183880, total loss = 0.66, batch loss = 0.40 (351.4 examples/sec; 0.023 sec/batch; 0h:05m:55s remains)
INFO - root - 2022-02-24 21:19:57.245152: step 183890, total loss = 0.57, batch loss = 0.31 (392.6 examples/sec; 0.020 sec/batch; 0h:05m:18s remains)
INFO - root - 2022-02-24 21:19:57.544978: step 183900, total loss = 0.60, batch loss = 0.35 (210.4 examples/sec; 0.038 sec/batch; 0h:09m:53s remains)
INFO - root - 2022-02-24 21:19:57.952763: step 183910, total loss = 0.63, batch loss = 0.37 (273.2 examples/sec; 0.029 sec/batch; 0h:07m:36s remains)
INFO - root - 2022-02-24 21:19:58.250303: step 183920, total loss = 0.57, batch loss = 0.31 (256.3 examples/sec; 0.031 sec/batch; 0h:08m:06s remains)
INFO - root - 2022-02-24 21:19:58.637265: step 183930, total loss = 0.56, batch loss = 0.30 (141.8 examples/sec; 0.056 sec/batch; 0h:14m:38s remains)
INFO - root - 2022-02-24 21:19:59.083768: step 183940, total loss = 0.48, batch loss = 0.23 (182.5 examples/sec; 0.044 sec/batch; 0h:11m:22s remains)
INFO - root - 2022-02-24 21:19:59.356063: step 183950, total loss = 0.44, batch loss = 0.19 (371.8 examples/sec; 0.022 sec/batch; 0h:05m:34s remains)
INFO - root - 2022-02-24 21:19:59.695401: step 183960, total loss = 0.58, batch loss = 0.32 (333.6 examples/sec; 0.024 sec/batch; 0h:06m:12s remains)
INFO - root - 2022-02-24 21:20:00.020371: step 183970, total loss = 0.51, batch loss = 0.25 (232.1 examples/sec; 0.034 sec/batch; 0h:08m:55s remains)
INFO - root - 2022-02-24 21:20:00.271903: step 183980, total loss = 0.54, batch loss = 0.29 (335.2 examples/sec; 0.024 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:20:00.665056: step 183990, total loss = 0.51, batch loss = 0.25 (203.5 examples/sec; 0.039 sec/batch; 0h:10m:09s remains)
INFO - root - 2022-02-24 21:20:01.126035: step 184000, total loss = 0.60, batch loss = 0.34 (164.7 examples/sec; 0.049 sec/batch; 0h:12m:32s remains)
INFO - root - 2022-02-24 21:20:01.487359: step 184010, total loss = 0.61, batch loss = 0.35 (317.9 examples/sec; 0.025 sec/batch; 0h:06m:29s remains)
INFO - root - 2022-02-24 21:20:01.807412: step 184020, total loss = 0.50, batch loss = 0.24 (295.3 examples/sec; 0.027 sec/batch; 0h:06m:59s remains)
INFO - root - 2022-02-24 21:20:02.103390: step 184030, total loss = 0.48, batch loss = 0.23 (138.9 examples/sec; 0.058 sec/batch; 0h:14m:51s remains)
INFO - root - 2022-02-24 21:20:02.424335: step 184040, total loss = 0.62, batch loss = 0.36 (141.4 examples/sec; 0.057 sec/batch; 0h:14m:34s remains)
INFO - root - 2022-02-24 21:20:02.832388: step 184050, total loss = 0.55, batch loss = 0.29 (123.3 examples/sec; 0.065 sec/batch; 0h:16m:42s remains)
INFO - root - 2022-02-24 21:20:03.215608: step 184060, total loss = 0.67, batch loss = 0.41 (378.1 examples/sec; 0.021 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:20:03.560153: step 184070, total loss = 0.53, batch loss = 0.27 (154.7 examples/sec; 0.052 sec/batch; 0h:13m:17s remains)
INFO - root - 2022-02-24 21:20:03.819854: step 184080, total loss = 0.54, batch loss = 0.28 (355.2 examples/sec; 0.023 sec/batch; 0h:05m:47s remains)
INFO - root - 2022-02-24 21:20:04.100947: step 184090, total loss = 0.53, batch loss = 0.27 (259.0 examples/sec; 0.031 sec/batch; 0h:07m:56s remains)
INFO - root - 2022-02-24 21:20:04.461208: step 184100, total loss = 0.45, batch loss = 0.19 (302.6 examples/sec; 0.026 sec/batch; 0h:06m:47s remains)
INFO - root - 2022-02-24 21:20:04.835535: step 184110, total loss = 0.58, batch loss = 0.32 (348.8 examples/sec; 0.023 sec/batch; 0h:05m:52s remains)
INFO - root - 2022-02-24 21:20:05.272683: step 184120, total loss = 0.60, batch loss = 0.34 (153.9 examples/sec; 0.052 sec/batch; 0h:13m:19s remains)
INFO - root - 2022-02-24 21:20:05.544785: step 184130, total loss = 0.53, batch loss = 0.27 (239.3 examples/sec; 0.033 sec/batch; 0h:08m:33s remains)
INFO - root - 2022-02-24 21:20:05.856650: step 184140, total loss = 0.48, batch loss = 0.22 (337.9 examples/sec; 0.024 sec/batch; 0h:06m:03s remains)
INFO - root - 2022-02-24 21:20:06.139714: step 184150, total loss = 0.68, batch loss = 0.42 (342.5 examples/sec; 0.023 sec/batch; 0h:05m:58s remains)
INFO - root - 2022-02-24 21:20:06.487862: step 184160, total loss = 0.41, batch loss = 0.15 (235.0 examples/sec; 0.034 sec/batch; 0h:08m:42s remains)
INFO - root - 2022-02-24 21:20:06.837781: step 184170, total loss = 0.68, batch loss = 0.42 (358.3 examples/sec; 0.022 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:20:07.245151: step 184180, total loss = 0.54, batch loss = 0.29 (261.0 examples/sec; 0.031 sec/batch; 0h:07m:49s remains)
INFO - root - 2022-02-24 21:20:07.507367: step 184190, total loss = 0.55, batch loss = 0.29 (272.3 examples/sec; 0.029 sec/batch; 0h:07m:29s remains)
INFO - root - 2022-02-24 21:20:07.791985: step 184200, total loss = 0.57, batch loss = 0.31 (200.7 examples/sec; 0.040 sec/batch; 0h:10m:09s remains)
INFO - root - 2022-02-24 21:20:08.188481: step 184210, total loss = 0.52, batch loss = 0.26 (336.8 examples/sec; 0.024 sec/batch; 0h:06m:03s remains)
INFO - root - 2022-02-24 21:20:08.543440: step 184220, total loss = 0.57, batch loss = 0.31 (315.5 examples/sec; 0.025 sec/batch; 0h:06m:27s remains)
INFO - root - 2022-02-24 21:20:08.980794: step 184230, total loss = 0.65, batch loss = 0.39 (346.2 examples/sec; 0.023 sec/batch; 0h:05m:52s remains)
INFO - root - 2022-02-24 21:20:09.324908: step 184240, total loss = 0.57, batch loss = 0.31 (198.5 examples/sec; 0.040 sec/batch; 0h:10m:14s remains)
INFO - root - 2022-02-24 21:20:09.592652: step 184250, total loss = 0.51, batch loss = 0.25 (377.5 examples/sec; 0.021 sec/batch; 0h:05m:23s remains)
INFO - root - 2022-02-24 21:20:09.924549: step 184260, total loss = 0.54, batch loss = 0.29 (192.0 examples/sec; 0.042 sec/batch; 0h:10m:35s remains)
INFO - root - 2022-02-24 21:20:10.266884: step 184270, total loss = 0.56, batch loss = 0.30 (179.8 examples/sec; 0.044 sec/batch; 0h:11m:17s remains)
INFO - root - 2022-02-24 21:20:10.604358: step 184280, total loss = 0.52, batch loss = 0.27 (247.0 examples/sec; 0.032 sec/batch; 0h:08m:12s remains)
INFO - root - 2022-02-24 21:20:11.019079: step 184290, total loss = 0.49, batch loss = 0.24 (358.0 examples/sec; 0.022 sec/batch; 0h:05m:39s remains)
INFO - root - 2022-02-24 21:20:11.382043: step 184300, total loss = 0.54, batch loss = 0.28 (178.8 examples/sec; 0.045 sec/batch; 0h:11m:20s remains)
INFO - root - 2022-02-24 21:20:11.727769: step 184310, total loss = 0.48, batch loss = 0.23 (330.6 examples/sec; 0.024 sec/batch; 0h:06m:07s remains)
INFO - root - 2022-02-24 21:20:12.029704: step 184320, total loss = 0.51, batch loss = 0.26 (184.7 examples/sec; 0.043 sec/batch; 0h:10m:57s remains)
INFO - root - 2022-02-24 21:20:12.349757: step 184330, total loss = 0.47, batch loss = 0.21 (361.7 examples/sec; 0.022 sec/batch; 0h:05m:35s remains)
INFO - root - 2022-02-24 21:20:12.776082: step 184340, total loss = 0.58, batch loss = 0.33 (174.2 examples/sec; 0.046 sec/batch; 0h:11m:36s remains)
INFO - root - 2022-02-24 21:20:13.145636: step 184350, total loss = 0.57, batch loss = 0.31 (343.6 examples/sec; 0.023 sec/batch; 0h:05m:52s remains)
INFO - root - 2022-02-24 21:20:13.450975: step 184360, total loss = 0.66, batch loss = 0.40 (216.4 examples/sec; 0.037 sec/batch; 0h:09m:19s remains)
INFO - root - 2022-02-24 21:20:13.866973: step 184370, total loss = 0.62, batch loss = 0.37 (110.3 examples/sec; 0.073 sec/batch; 0h:18m:17s remains)
INFO - root - 2022-02-24 21:20:14.405079: step 184380, total loss = 0.55, batch loss = 0.30 (304.5 examples/sec; 0.026 sec/batch; 0h:06m:37s remains)
INFO - root - 2022-02-24 21:20:14.871742: step 184390, total loss = 0.53, batch loss = 0.28 (161.4 examples/sec; 0.050 sec/batch; 0h:12m:28s remains)
INFO - root - 2022-02-24 21:20:15.206413: step 184400, total loss = 0.50, batch loss = 0.24 (347.3 examples/sec; 0.023 sec/batch; 0h:05m:47s remains)
INFO - root - 2022-02-24 21:20:15.692060: step 184410, total loss = 0.47, batch loss = 0.21 (199.9 examples/sec; 0.040 sec/batch; 0h:10m:03s remains)
INFO - root - 2022-02-24 21:20:16.090023: step 184420, total loss = 0.54, batch loss = 0.28 (182.1 examples/sec; 0.044 sec/batch; 0h:11m:02s remains)
INFO - root - 2022-02-24 21:20:16.545133: step 184430, total loss = 0.53, batch loss = 0.28 (347.6 examples/sec; 0.023 sec/batch; 0h:05m:46s remains)
INFO - root - 2022-02-24 21:20:16.943589: step 184440, total loss = 0.51, batch loss = 0.26 (356.3 examples/sec; 0.022 sec/batch; 0h:05m:38s remains)
INFO - root - 2022-02-24 21:20:17.494628: step 184450, total loss = 0.53, batch loss = 0.28 (112.1 examples/sec; 0.071 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 21:20:17.965832: step 184460, total loss = 0.53, batch loss = 0.28 (351.0 examples/sec; 0.023 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:20:18.900139: step 184470, total loss = 0.50, batch loss = 0.24 (239.2 examples/sec; 0.033 sec/batch; 0h:08m:22s remains)
INFO - root - 2022-02-24 21:20:19.349141: step 184480, total loss = 0.62, batch loss = 0.36 (148.5 examples/sec; 0.054 sec/batch; 0h:13m:28s remains)
INFO - root - 2022-02-24 21:20:19.614788: step 184490, total loss = 0.59, batch loss = 0.34 (330.0 examples/sec; 0.024 sec/batch; 0h:06m:03s remains)
INFO - root - 2022-02-24 21:20:19.961854: step 184500, total loss = 0.56, batch loss = 0.31 (128.8 examples/sec; 0.062 sec/batch; 0h:15m:31s remains)
INFO - root - 2022-02-24 21:20:20.401379: step 184510, total loss = 0.63, batch loss = 0.37 (269.6 examples/sec; 0.030 sec/batch; 0h:07m:24s remains)
INFO - root - 2022-02-24 21:20:20.687757: step 184520, total loss = 0.50, batch loss = 0.24 (356.2 examples/sec; 0.022 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:20:21.045883: step 184530, total loss = 0.50, batch loss = 0.24 (145.7 examples/sec; 0.055 sec/batch; 0h:13m:42s remains)
INFO - root - 2022-02-24 21:20:21.403031: step 184540, total loss = 0.66, batch loss = 0.40 (304.0 examples/sec; 0.026 sec/batch; 0h:06m:33s remains)
INFO - root - 2022-02-24 21:20:21.772663: step 184550, total loss = 0.54, batch loss = 0.29 (314.5 examples/sec; 0.025 sec/batch; 0h:06m:20s remains)
INFO - root - 2022-02-24 21:20:22.069956: step 184560, total loss = 0.56, batch loss = 0.30 (311.7 examples/sec; 0.026 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:20:22.413213: step 184570, total loss = 0.65, batch loss = 0.39 (162.5 examples/sec; 0.049 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:20:22.714666: step 184580, total loss = 0.57, batch loss = 0.31 (317.3 examples/sec; 0.025 sec/batch; 0h:06m:16s remains)
INFO - root - 2022-02-24 21:20:23.097580: step 184590, total loss = 0.57, batch loss = 0.31 (142.2 examples/sec; 0.056 sec/batch; 0h:13m:58s remains)
INFO - root - 2022-02-24 21:20:23.542819: step 184600, total loss = 0.57, batch loss = 0.32 (178.5 examples/sec; 0.045 sec/batch; 0h:11m:07s remains)
INFO - root - 2022-02-24 21:20:24.005551: step 184610, total loss = 0.53, batch loss = 0.27 (157.4 examples/sec; 0.051 sec/batch; 0h:12m:36s remains)
INFO - root - 2022-02-24 21:20:24.302682: step 184620, total loss = 0.56, batch loss = 0.31 (242.8 examples/sec; 0.033 sec/batch; 0h:08m:10s remains)
INFO - root - 2022-02-24 21:20:24.597047: step 184630, total loss = 0.52, batch loss = 0.27 (313.3 examples/sec; 0.026 sec/batch; 0h:06m:19s remains)
INFO - root - 2022-02-24 21:20:24.891736: step 184640, total loss = 0.51, batch loss = 0.25 (345.8 examples/sec; 0.023 sec/batch; 0h:05m:43s remains)
INFO - root - 2022-02-24 21:20:25.201290: step 184650, total loss = 0.56, batch loss = 0.31 (371.7 examples/sec; 0.022 sec/batch; 0h:05m:19s remains)
INFO - root - 2022-02-24 21:20:25.610705: step 184660, total loss = 0.53, batch loss = 0.28 (355.4 examples/sec; 0.023 sec/batch; 0h:05m:34s remains)
INFO - root - 2022-02-24 21:20:26.010601: step 184670, total loss = 0.51, batch loss = 0.25 (364.4 examples/sec; 0.022 sec/batch; 0h:05m:25s remains)
INFO - root - 2022-02-24 21:20:26.278116: step 184680, total loss = 0.60, batch loss = 0.34 (181.2 examples/sec; 0.044 sec/batch; 0h:10m:54s remains)
INFO - root - 2022-02-24 21:20:26.601798: step 184690, total loss = 0.54, batch loss = 0.28 (335.0 examples/sec; 0.024 sec/batch; 0h:05m:53s remains)
INFO - root - 2022-02-24 21:20:26.889794: step 184700, total loss = 0.61, batch loss = 0.35 (323.8 examples/sec; 0.025 sec/batch; 0h:06m:05s remains)
INFO - root - 2022-02-24 21:20:27.284187: step 184710, total loss = 0.56, batch loss = 0.30 (320.7 examples/sec; 0.025 sec/batch; 0h:06m:08s remains)
INFO - root - 2022-02-24 21:20:27.717303: step 184720, total loss = 0.51, batch loss = 0.26 (184.5 examples/sec; 0.043 sec/batch; 0h:10m:40s remains)
INFO - root - 2022-02-24 21:20:28.182344: step 184730, total loss = 0.53, batch loss = 0.27 (109.7 examples/sec; 0.073 sec/batch; 0h:17m:56s remains)
INFO - root - 2022-02-24 21:20:28.525604: step 184740, total loss = 0.48, batch loss = 0.23 (266.7 examples/sec; 0.030 sec/batch; 0h:07m:22s remains)
INFO - root - 2022-02-24 21:20:28.825752: step 184750, total loss = 0.51, batch loss = 0.26 (335.4 examples/sec; 0.024 sec/batch; 0h:05m:51s remains)
INFO - root - 2022-02-24 21:20:29.150649: step 184760, total loss = 0.66, batch loss = 0.40 (240.6 examples/sec; 0.033 sec/batch; 0h:08m:10s remains)
INFO - root - 2022-02-24 21:20:29.505739: step 184770, total loss = 0.58, batch loss = 0.32 (121.6 examples/sec; 0.066 sec/batch; 0h:16m:09s remains)
INFO - root - 2022-02-24 21:20:29.931919: step 184780, total loss = 0.48, batch loss = 0.22 (169.3 examples/sec; 0.047 sec/batch; 0h:11m:35s remains)
INFO - root - 2022-02-24 21:20:30.259731: step 184790, total loss = 0.62, batch loss = 0.37 (174.6 examples/sec; 0.046 sec/batch; 0h:11m:13s remains)
INFO - root - 2022-02-24 21:20:30.597072: step 184800, total loss = 0.52, batch loss = 0.27 (139.3 examples/sec; 0.057 sec/batch; 0h:14m:04s remains)
INFO - root - 2022-02-24 21:20:31.017529: step 184810, total loss = 0.55, batch loss = 0.30 (190.2 examples/sec; 0.042 sec/batch; 0h:10m:17s remains)
INFO - root - 2022-02-24 21:20:31.341982: step 184820, total loss = 0.54, batch loss = 0.28 (330.7 examples/sec; 0.024 sec/batch; 0h:05m:55s remains)
INFO - root - 2022-02-24 21:20:31.743078: step 184830, total loss = 0.49, batch loss = 0.24 (226.5 examples/sec; 0.035 sec/batch; 0h:08m:38s remains)
INFO - root - 2022-02-24 21:20:32.166918: step 184840, total loss = 0.48, batch loss = 0.23 (112.3 examples/sec; 0.071 sec/batch; 0h:17m:23s remains)
INFO - root - 2022-02-24 21:20:32.497577: step 184850, total loss = 0.52, batch loss = 0.26 (323.2 examples/sec; 0.025 sec/batch; 0h:06m:02s remains)
INFO - root - 2022-02-24 21:20:32.810497: step 184860, total loss = 0.58, batch loss = 0.32 (255.7 examples/sec; 0.031 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:20:33.059686: step 184870, total loss = 0.51, batch loss = 0.25 (341.5 examples/sec; 0.023 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:20:33.450118: step 184880, total loss = 0.51, batch loss = 0.26 (248.4 examples/sec; 0.032 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:20:33.861095: step 184890, total loss = 0.56, batch loss = 0.30 (112.6 examples/sec; 0.071 sec/batch; 0h:17m:17s remains)
INFO - root - 2022-02-24 21:20:34.204834: step 184900, total loss = 0.55, batch loss = 0.29 (348.4 examples/sec; 0.023 sec/batch; 0h:05m:35s remains)
INFO - root - 2022-02-24 21:20:34.618347: step 184910, total loss = 0.52, batch loss = 0.26 (345.1 examples/sec; 0.023 sec/batch; 0h:05m:38s remains)
INFO - root - 2022-02-24 21:20:34.903984: step 184920, total loss = 0.49, batch loss = 0.23 (274.4 examples/sec; 0.029 sec/batch; 0h:07m:05s remains)
INFO - root - 2022-02-24 21:20:35.317396: step 184930, total loss = 0.52, batch loss = 0.26 (189.4 examples/sec; 0.042 sec/batch; 0h:10m:15s remains)
INFO - root - 2022-02-24 21:20:35.690725: step 184940, total loss = 0.53, batch loss = 0.28 (156.1 examples/sec; 0.051 sec/batch; 0h:12m:26s remains)
INFO - root - 2022-02-24 21:20:36.039837: step 184950, total loss = 0.51, batch loss = 0.25 (310.2 examples/sec; 0.026 sec/batch; 0h:06m:15s remains)
INFO - root - 2022-02-24 21:20:36.308547: step 184960, total loss = 0.55, batch loss = 0.29 (208.0 examples/sec; 0.038 sec/batch; 0h:09m:19s remains)
INFO - root - 2022-02-24 21:20:36.632718: step 184970, total loss = 0.50, batch loss = 0.25 (191.1 examples/sec; 0.042 sec/batch; 0h:10m:08s remains)
INFO - root - 2022-02-24 21:20:37.020201: step 184980, total loss = 0.56, batch loss = 0.30 (157.5 examples/sec; 0.051 sec/batch; 0h:12m:17s remains)
INFO - root - 2022-02-24 21:20:37.411950: step 184990, total loss = 0.53, batch loss = 0.28 (136.8 examples/sec; 0.058 sec/batch; 0h:14m:08s remains)
INFO - root - 2022-02-24 21:20:37.776616: step 185000, total loss = 0.58, batch loss = 0.32 (218.4 examples/sec; 0.037 sec/batch; 0h:08m:51s remains)
INFO - root - 2022-02-24 21:20:38.144598: step 185010, total loss = 0.59, batch loss = 0.33 (308.4 examples/sec; 0.026 sec/batch; 0h:06m:15s remains)
INFO - root - 2022-02-24 21:20:38.451645: step 185020, total loss = 0.54, batch loss = 0.29 (355.4 examples/sec; 0.023 sec/batch; 0h:05m:25s remains)
INFO - root - 2022-02-24 21:20:38.742174: step 185030, total loss = 0.55, batch loss = 0.30 (290.3 examples/sec; 0.028 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:20:39.098087: step 185040, total loss = 0.60, batch loss = 0.34 (109.7 examples/sec; 0.073 sec/batch; 0h:17m:34s remains)
INFO - root - 2022-02-24 21:20:39.523932: step 185050, total loss = 0.67, batch loss = 0.42 (165.8 examples/sec; 0.048 sec/batch; 0h:11m:37s remains)
INFO - root - 2022-02-24 21:20:39.944863: step 185060, total loss = 0.58, batch loss = 0.32 (296.7 examples/sec; 0.027 sec/batch; 0h:06m:29s remains)
INFO - root - 2022-02-24 21:20:40.278475: step 185070, total loss = 0.49, batch loss = 0.23 (273.2 examples/sec; 0.029 sec/batch; 0h:07m:02s remains)
INFO - root - 2022-02-24 21:20:40.593557: step 185080, total loss = 0.66, batch loss = 0.40 (303.7 examples/sec; 0.026 sec/batch; 0h:06m:19s remains)
INFO - root - 2022-02-24 21:20:40.904975: step 185090, total loss = 0.46, batch loss = 0.21 (216.0 examples/sec; 0.037 sec/batch; 0h:08m:53s remains)
INFO - root - 2022-02-24 21:20:41.266958: step 185100, total loss = 0.55, batch loss = 0.29 (337.8 examples/sec; 0.024 sec/batch; 0h:05m:41s remains)
INFO - root - 2022-02-24 21:20:41.791220: step 185110, total loss = 0.61, batch loss = 0.35 (161.9 examples/sec; 0.049 sec/batch; 0h:11m:51s remains)
INFO - root - 2022-02-24 21:20:42.124666: step 185120, total loss = 0.55, batch loss = 0.29 (395.3 examples/sec; 0.020 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:20:42.429271: step 185130, total loss = 0.41, batch loss = 0.15 (327.1 examples/sec; 0.024 sec/batch; 0h:05m:51s remains)
INFO - root - 2022-02-24 21:20:42.730905: step 185140, total loss = 0.67, batch loss = 0.41 (281.6 examples/sec; 0.028 sec/batch; 0h:06m:47s remains)
INFO - root - 2022-02-24 21:20:43.034886: step 185150, total loss = 0.55, batch loss = 0.29 (332.9 examples/sec; 0.024 sec/batch; 0h:05m:44s remains)
INFO - root - 2022-02-24 21:20:43.394496: step 185160, total loss = 0.58, batch loss = 0.32 (268.8 examples/sec; 0.030 sec/batch; 0h:07m:06s remains)
INFO - root - 2022-02-24 21:20:44.045244: step 185170, total loss = 0.51, batch loss = 0.25 (172.8 examples/sec; 0.046 sec/batch; 0h:11m:03s remains)
INFO - root - 2022-02-24 21:20:44.338587: step 185180, total loss = 0.49, batch loss = 0.24 (312.5 examples/sec; 0.026 sec/batch; 0h:06m:06s remains)
INFO - root - 2022-02-24 21:20:44.673431: step 185190, total loss = 0.55, batch loss = 0.29 (169.6 examples/sec; 0.047 sec/batch; 0h:11m:14s remains)
INFO - root - 2022-02-24 21:20:44.954967: step 185200, total loss = 0.63, batch loss = 0.38 (205.6 examples/sec; 0.039 sec/batch; 0h:09m:16s remains)
INFO - root - 2022-02-24 21:20:45.441216: step 185210, total loss = 0.51, batch loss = 0.25 (298.3 examples/sec; 0.027 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:20:45.821391: step 185220, total loss = 0.54, batch loss = 0.28 (258.9 examples/sec; 0.031 sec/batch; 0h:07m:21s remains)
INFO - root - 2022-02-24 21:20:46.259486: step 185230, total loss = 0.54, batch loss = 0.28 (325.0 examples/sec; 0.025 sec/batch; 0h:05m:51s remains)
INFO - root - 2022-02-24 21:20:46.557905: step 185240, total loss = 0.60, batch loss = 0.35 (314.6 examples/sec; 0.025 sec/batch; 0h:06m:02s remains)
INFO - root - 2022-02-24 21:20:46.869364: step 185250, total loss = 0.53, batch loss = 0.27 (211.1 examples/sec; 0.038 sec/batch; 0h:08m:59s remains)
INFO - root - 2022-02-24 21:20:47.217868: step 185260, total loss = 0.61, batch loss = 0.35 (195.0 examples/sec; 0.041 sec/batch; 0h:09m:44s remains)
INFO - root - 2022-02-24 21:20:47.539198: step 185270, total loss = 0.51, batch loss = 0.26 (211.1 examples/sec; 0.038 sec/batch; 0h:08m:59s remains)
INFO - root - 2022-02-24 21:20:48.024937: step 185280, total loss = 0.60, batch loss = 0.35 (176.8 examples/sec; 0.045 sec/batch; 0h:10m:43s remains)
INFO - root - 2022-02-24 21:20:48.366549: step 185290, total loss = 0.67, batch loss = 0.41 (350.7 examples/sec; 0.023 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:20:48.677103: step 185300, total loss = 0.51, batch loss = 0.25 (226.8 examples/sec; 0.035 sec/batch; 0h:08m:20s remains)
INFO - root - 2022-02-24 21:20:49.036644: step 185310, total loss = 0.58, batch loss = 0.32 (362.7 examples/sec; 0.022 sec/batch; 0h:05m:13s remains)
INFO - root - 2022-02-24 21:20:49.335289: step 185320, total loss = 0.50, batch loss = 0.25 (318.2 examples/sec; 0.025 sec/batch; 0h:05m:56s remains)
INFO - root - 2022-02-24 21:20:49.651404: step 185330, total loss = 0.57, batch loss = 0.31 (345.5 examples/sec; 0.023 sec/batch; 0h:05m:28s remains)
INFO - root - 2022-02-24 21:20:50.132958: step 185340, total loss = 0.63, batch loss = 0.37 (165.3 examples/sec; 0.048 sec/batch; 0h:11m:25s remains)
INFO - root - 2022-02-24 21:20:50.490465: step 185350, total loss = 0.54, batch loss = 0.28 (336.5 examples/sec; 0.024 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:20:50.874804: step 185360, total loss = 0.51, batch loss = 0.26 (112.8 examples/sec; 0.071 sec/batch; 0h:16m:42s remains)
INFO - root - 2022-02-24 21:20:51.151881: step 185370, total loss = 0.51, batch loss = 0.26 (278.9 examples/sec; 0.029 sec/batch; 0h:06m:45s remains)
INFO - root - 2022-02-24 21:20:51.461942: step 185380, total loss = 0.57, batch loss = 0.32 (246.2 examples/sec; 0.032 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:20:51.858332: step 185390, total loss = 0.53, batch loss = 0.28 (178.0 examples/sec; 0.045 sec/batch; 0h:10m:34s remains)
INFO - root - 2022-02-24 21:20:52.294882: step 185400, total loss = 0.53, batch loss = 0.27 (259.8 examples/sec; 0.031 sec/batch; 0h:07m:14s remains)
INFO - root - 2022-02-24 21:20:52.751748: step 185410, total loss = 0.58, batch loss = 0.33 (256.4 examples/sec; 0.031 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:20:53.044674: step 185420, total loss = 0.49, batch loss = 0.24 (236.0 examples/sec; 0.034 sec/batch; 0h:07m:57s remains)
INFO - root - 2022-02-24 21:20:53.367999: step 185430, total loss = 0.59, batch loss = 0.34 (333.6 examples/sec; 0.024 sec/batch; 0h:05m:37s remains)
INFO - root - 2022-02-24 21:20:53.638674: step 185440, total loss = 0.55, batch loss = 0.29 (287.9 examples/sec; 0.028 sec/batch; 0h:06m:30s remains)
INFO - root - 2022-02-24 21:20:54.097764: step 185450, total loss = 0.47, batch loss = 0.21 (105.9 examples/sec; 0.076 sec/batch; 0h:17m:41s remains)
INFO - root - 2022-02-24 21:20:54.415043: step 185460, total loss = 0.50, batch loss = 0.24 (148.6 examples/sec; 0.054 sec/batch; 0h:12m:35s remains)
INFO - root - 2022-02-24 21:20:54.847386: step 185470, total loss = 0.55, batch loss = 0.30 (306.1 examples/sec; 0.026 sec/batch; 0h:06m:06s remains)
INFO - root - 2022-02-24 21:20:55.177493: step 185480, total loss = 0.65, batch loss = 0.40 (332.2 examples/sec; 0.024 sec/batch; 0h:05m:37s remains)
INFO - root - 2022-02-24 21:20:55.413859: step 185490, total loss = 0.54, batch loss = 0.29 (320.3 examples/sec; 0.025 sec/batch; 0h:05m:49s remains)
INFO - root - 2022-02-24 21:20:55.721252: step 185500, total loss = 0.50, batch loss = 0.24 (323.1 examples/sec; 0.025 sec/batch; 0h:05m:46s remains)
INFO - root - 2022-02-24 21:20:56.197590: step 185510, total loss = 0.63, batch loss = 0.38 (198.7 examples/sec; 0.040 sec/batch; 0h:09m:23s remains)
INFO - root - 2022-02-24 21:20:56.683345: step 185520, total loss = 0.50, batch loss = 0.24 (207.1 examples/sec; 0.039 sec/batch; 0h:09m:00s remains)
INFO - root - 2022-02-24 21:20:57.234744: step 185530, total loss = 0.52, batch loss = 0.27 (85.7 examples/sec; 0.093 sec/batch; 0h:21m:44s remains)
INFO - root - 2022-02-24 21:20:57.648492: step 185540, total loss = 0.64, batch loss = 0.38 (132.6 examples/sec; 0.060 sec/batch; 0h:14m:02s remains)
INFO - root - 2022-02-24 21:20:58.270262: step 185550, total loss = 0.61, batch loss = 0.35 (70.4 examples/sec; 0.114 sec/batch; 0h:26m:25s remains)
INFO - root - 2022-02-24 21:20:58.740897: step 185560, total loss = 0.52, batch loss = 0.26 (225.8 examples/sec; 0.035 sec/batch; 0h:08m:13s remains)
INFO - root - 2022-02-24 21:20:59.248182: step 185570, total loss = 0.45, batch loss = 0.20 (89.6 examples/sec; 0.089 sec/batch; 0h:20m:43s remains)
INFO - root - 2022-02-24 21:21:00.109033: step 185580, total loss = 0.51, batch loss = 0.26 (137.5 examples/sec; 0.058 sec/batch; 0h:13m:29s remains)
INFO - root - 2022-02-24 21:21:00.583451: step 185590, total loss = 0.52, batch loss = 0.26 (82.1 examples/sec; 0.097 sec/batch; 0h:22m:36s remains)
INFO - root - 2022-02-24 21:21:01.087013: step 185600, total loss = 0.63, batch loss = 0.37 (278.8 examples/sec; 0.029 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:21:01.501303: step 185610, total loss = 0.65, batch loss = 0.39 (363.4 examples/sec; 0.022 sec/batch; 0h:05m:05s remains)
INFO - root - 2022-02-24 21:21:01.870526: step 185620, total loss = 0.53, batch loss = 0.28 (122.5 examples/sec; 0.065 sec/batch; 0h:15m:06s remains)
INFO - root - 2022-02-24 21:21:02.177280: step 185630, total loss = 0.49, batch loss = 0.24 (188.2 examples/sec; 0.043 sec/batch; 0h:09m:49s remains)
INFO - root - 2022-02-24 21:21:02.560126: step 185640, total loss = 0.48, batch loss = 0.22 (151.0 examples/sec; 0.053 sec/batch; 0h:12m:14s remains)
INFO - root - 2022-02-24 21:21:02.942496: step 185650, total loss = 0.75, batch loss = 0.49 (335.9 examples/sec; 0.024 sec/batch; 0h:05m:29s remains)
INFO - root - 2022-02-24 21:21:03.280113: step 185660, total loss = 0.44, batch loss = 0.18 (192.7 examples/sec; 0.042 sec/batch; 0h:09m:34s remains)
INFO - root - 2022-02-24 21:21:03.553120: step 185670, total loss = 0.55, batch loss = 0.29 (383.5 examples/sec; 0.021 sec/batch; 0h:04m:48s remains)
INFO - root - 2022-02-24 21:21:03.889296: step 185680, total loss = 0.53, batch loss = 0.27 (274.6 examples/sec; 0.029 sec/batch; 0h:06m:42s remains)
INFO - root - 2022-02-24 21:21:04.297769: step 185690, total loss = 0.54, batch loss = 0.28 (116.7 examples/sec; 0.069 sec/batch; 0h:15m:47s remains)
INFO - root - 2022-02-24 21:21:04.764388: step 185700, total loss = 0.55, batch loss = 0.29 (174.6 examples/sec; 0.046 sec/batch; 0h:10m:32s remains)
INFO - root - 2022-02-24 21:21:05.143096: step 185710, total loss = 0.59, batch loss = 0.34 (284.9 examples/sec; 0.028 sec/batch; 0h:06m:27s remains)
INFO - root - 2022-02-24 21:21:05.429940: step 185720, total loss = 0.62, batch loss = 0.37 (317.0 examples/sec; 0.025 sec/batch; 0h:05m:47s remains)
INFO - root - 2022-02-24 21:21:05.769768: step 185730, total loss = 0.51, batch loss = 0.26 (178.8 examples/sec; 0.045 sec/batch; 0h:10m:16s remains)
INFO - root - 2022-02-24 21:21:06.085059: step 185740, total loss = 0.51, batch loss = 0.25 (333.5 examples/sec; 0.024 sec/batch; 0h:05m:30s remains)
INFO - root - 2022-02-24 21:21:06.401680: step 185750, total loss = 0.47, batch loss = 0.21 (302.0 examples/sec; 0.026 sec/batch; 0h:06m:04s remains)
INFO - root - 2022-02-24 21:21:06.814937: step 185760, total loss = 0.67, batch loss = 0.42 (167.6 examples/sec; 0.048 sec/batch; 0h:10m:55s remains)
INFO - root - 2022-02-24 21:21:07.226886: step 185770, total loss = 0.56, batch loss = 0.30 (214.6 examples/sec; 0.037 sec/batch; 0h:08m:31s remains)
INFO - root - 2022-02-24 21:21:07.509496: step 185780, total loss = 0.54, batch loss = 0.28 (322.3 examples/sec; 0.025 sec/batch; 0h:05m:40s remains)
INFO - root - 2022-02-24 21:21:07.837114: step 185790, total loss = 0.48, batch loss = 0.22 (335.6 examples/sec; 0.024 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:21:08.155034: step 185800, total loss = 0.52, batch loss = 0.27 (160.8 examples/sec; 0.050 sec/batch; 0h:11m:21s remains)
INFO - root - 2022-02-24 21:21:08.604895: step 185810, total loss = 0.57, batch loss = 0.32 (120.0 examples/sec; 0.067 sec/batch; 0h:15m:12s remains)
INFO - root - 2022-02-24 21:21:09.033261: step 185820, total loss = 0.62, batch loss = 0.36 (258.7 examples/sec; 0.031 sec/batch; 0h:07m:03s remains)
INFO - root - 2022-02-24 21:21:09.437491: step 185830, total loss = 0.48, batch loss = 0.22 (253.6 examples/sec; 0.032 sec/batch; 0h:07m:11s remains)
INFO - root - 2022-02-24 21:21:09.810183: step 185840, total loss = 0.54, batch loss = 0.28 (232.8 examples/sec; 0.034 sec/batch; 0h:07m:49s remains)
INFO - root - 2022-02-24 21:21:10.122055: step 185850, total loss = 0.63, batch loss = 0.37 (314.2 examples/sec; 0.025 sec/batch; 0h:05m:47s remains)
INFO - root - 2022-02-24 21:21:10.445508: step 185860, total loss = 0.55, batch loss = 0.29 (371.7 examples/sec; 0.022 sec/batch; 0h:04m:53s remains)
INFO - root - 2022-02-24 21:21:10.735382: step 185870, total loss = 0.55, batch loss = 0.30 (205.4 examples/sec; 0.039 sec/batch; 0h:08m:50s remains)
INFO - root - 2022-02-24 21:21:11.129201: step 185880, total loss = 0.56, batch loss = 0.30 (103.6 examples/sec; 0.077 sec/batch; 0h:17m:31s remains)
INFO - root - 2022-02-24 21:21:11.521098: step 185890, total loss = 0.48, batch loss = 0.23 (213.8 examples/sec; 0.037 sec/batch; 0h:08m:29s remains)
INFO - root - 2022-02-24 21:21:11.863728: step 185900, total loss = 0.60, batch loss = 0.34 (191.6 examples/sec; 0.042 sec/batch; 0h:09m:27s remains)
INFO - root - 2022-02-24 21:21:12.297465: step 185910, total loss = 0.45, batch loss = 0.19 (323.1 examples/sec; 0.025 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:21:12.568133: step 185920, total loss = 0.59, batch loss = 0.34 (215.9 examples/sec; 0.037 sec/batch; 0h:08m:23s remains)
INFO - root - 2022-02-24 21:21:12.925628: step 185930, total loss = 0.52, batch loss = 0.26 (206.1 examples/sec; 0.039 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:21:13.302772: step 185940, total loss = 0.56, batch loss = 0.31 (219.2 examples/sec; 0.036 sec/batch; 0h:08m:14s remains)
INFO - root - 2022-02-24 21:21:13.701126: step 185950, total loss = 0.66, batch loss = 0.40 (236.4 examples/sec; 0.034 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:21:14.005251: step 185960, total loss = 0.58, batch loss = 0.33 (302.9 examples/sec; 0.026 sec/batch; 0h:05m:57s remains)
INFO - root - 2022-02-24 21:21:14.328995: step 185970, total loss = 0.51, batch loss = 0.26 (371.5 examples/sec; 0.022 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:21:14.683831: step 185980, total loss = 0.51, batch loss = 0.25 (188.1 examples/sec; 0.043 sec/batch; 0h:09m:34s remains)
INFO - root - 2022-02-24 21:21:15.207647: step 185990, total loss = 0.62, batch loss = 0.37 (80.5 examples/sec; 0.099 sec/batch; 0h:22m:22s remains)
INFO - root - 2022-02-24 21:21:15.578341: step 186000, total loss = 0.46, batch loss = 0.20 (261.7 examples/sec; 0.031 sec/batch; 0h:06m:52s remains)
INFO - root - 2022-02-24 21:21:15.931827: step 186010, total loss = 0.54, batch loss = 0.28 (339.1 examples/sec; 0.024 sec/batch; 0h:05m:18s remains)
INFO - root - 2022-02-24 21:21:16.259125: step 186020, total loss = 0.62, batch loss = 0.36 (247.1 examples/sec; 0.032 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:21:16.596190: step 186030, total loss = 0.54, batch loss = 0.28 (128.1 examples/sec; 0.062 sec/batch; 0h:14m:01s remains)
INFO - root - 2022-02-24 21:21:17.062944: step 186040, total loss = 0.47, batch loss = 0.21 (259.0 examples/sec; 0.031 sec/batch; 0h:06m:55s remains)
INFO - root - 2022-02-24 21:21:17.442208: step 186050, total loss = 0.47, batch loss = 0.22 (204.2 examples/sec; 0.039 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:21:17.842289: step 186060, total loss = 0.52, batch loss = 0.26 (131.0 examples/sec; 0.061 sec/batch; 0h:13m:40s remains)
INFO - root - 2022-02-24 21:21:18.135654: step 186070, total loss = 0.60, batch loss = 0.34 (313.6 examples/sec; 0.026 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:21:18.394984: step 186080, total loss = 0.48, batch loss = 0.22 (319.7 examples/sec; 0.025 sec/batch; 0h:05m:35s remains)
INFO - root - 2022-02-24 21:21:18.840006: step 186090, total loss = 0.50, batch loss = 0.25 (221.1 examples/sec; 0.036 sec/batch; 0h:08m:05s remains)
INFO - root - 2022-02-24 21:21:19.233432: step 186100, total loss = 0.60, batch loss = 0.34 (355.2 examples/sec; 0.023 sec/batch; 0h:05m:01s remains)
INFO - root - 2022-02-24 21:21:19.665785: step 186110, total loss = 0.62, batch loss = 0.36 (329.6 examples/sec; 0.024 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:21:19.945486: step 186120, total loss = 0.57, batch loss = 0.32 (215.1 examples/sec; 0.037 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:21:20.242430: step 186130, total loss = 0.52, batch loss = 0.26 (222.8 examples/sec; 0.036 sec/batch; 0h:08m:00s remains)
INFO - root - 2022-02-24 21:21:20.600628: step 186140, total loss = 0.65, batch loss = 0.39 (345.2 examples/sec; 0.023 sec/batch; 0h:05m:09s remains)
INFO - root - 2022-02-24 21:21:20.987479: step 186150, total loss = 0.55, batch loss = 0.30 (147.3 examples/sec; 0.054 sec/batch; 0h:12m:04s remains)
INFO - root - 2022-02-24 21:21:21.334756: step 186160, total loss = 0.52, batch loss = 0.26 (222.7 examples/sec; 0.036 sec/batch; 0h:07m:59s remains)
INFO - root - 2022-02-24 21:21:21.657379: step 186170, total loss = 0.50, batch loss = 0.24 (334.0 examples/sec; 0.024 sec/batch; 0h:05m:19s remains)
INFO - root - 2022-02-24 21:21:21.975586: step 186180, total loss = 0.59, batch loss = 0.33 (281.7 examples/sec; 0.028 sec/batch; 0h:06m:18s remains)
INFO - root - 2022-02-24 21:21:22.273422: step 186190, total loss = 0.64, batch loss = 0.38 (234.2 examples/sec; 0.034 sec/batch; 0h:07m:34s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-186199 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-186199 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:21:22.922281: step 186200, total loss = 0.52, batch loss = 0.26 (349.8 examples/sec; 0.023 sec/batch; 0h:05m:04s remains)
INFO - root - 2022-02-24 21:21:23.259389: step 186210, total loss = 0.55, batch loss = 0.29 (334.6 examples/sec; 0.024 sec/batch; 0h:05m:17s remains)
INFO - root - 2022-02-24 21:21:23.501513: step 186220, total loss = 0.54, batch loss = 0.28 (330.0 examples/sec; 0.024 sec/batch; 0h:05m:21s remains)
INFO - root - 2022-02-24 21:21:23.764057: step 186230, total loss = 0.57, batch loss = 0.31 (205.5 examples/sec; 0.039 sec/batch; 0h:08m:36s remains)
INFO - root - 2022-02-24 21:21:24.033229: step 186240, total loss = 0.53, batch loss = 0.27 (363.6 examples/sec; 0.022 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:21:24.375466: step 186250, total loss = 0.50, batch loss = 0.25 (119.6 examples/sec; 0.067 sec/batch; 0h:14m:46s remains)
INFO - root - 2022-02-24 21:21:24.804012: step 186260, total loss = 0.61, batch loss = 0.35 (154.3 examples/sec; 0.052 sec/batch; 0h:11m:26s remains)
INFO - root - 2022-02-24 21:21:25.305862: step 186270, total loss = 0.60, batch loss = 0.34 (106.3 examples/sec; 0.075 sec/batch; 0h:16m:35s remains)
INFO - root - 2022-02-24 21:21:25.620051: step 186280, total loss = 0.59, batch loss = 0.34 (163.5 examples/sec; 0.049 sec/batch; 0h:10m:46s remains)
INFO - root - 2022-02-24 21:21:25.937258: step 186290, total loss = 0.55, batch loss = 0.30 (169.1 examples/sec; 0.047 sec/batch; 0h:10m:24s remains)
INFO - root - 2022-02-24 21:21:26.234316: step 186300, total loss = 0.47, batch loss = 0.21 (331.3 examples/sec; 0.024 sec/batch; 0h:05m:18s remains)
INFO - root - 2022-02-24 21:21:26.577575: step 186310, total loss = 0.53, batch loss = 0.27 (305.1 examples/sec; 0.026 sec/batch; 0h:05m:45s remains)
INFO - root - 2022-02-24 21:21:26.949557: step 186320, total loss = 0.51, batch loss = 0.26 (320.7 examples/sec; 0.025 sec/batch; 0h:05m:28s remains)
INFO - root - 2022-02-24 21:21:27.328890: step 186330, total loss = 0.60, batch loss = 0.34 (167.4 examples/sec; 0.048 sec/batch; 0h:10m:29s remains)
INFO - root - 2022-02-24 21:21:27.662115: step 186340, total loss = 0.62, batch loss = 0.36 (229.2 examples/sec; 0.035 sec/batch; 0h:07m:39s remains)
INFO - root - 2022-02-24 21:21:27.931153: step 186350, total loss = 0.47, batch loss = 0.21 (280.5 examples/sec; 0.029 sec/batch; 0h:06m:15s remains)
INFO - root - 2022-02-24 21:21:28.246713: step 186360, total loss = 0.47, batch loss = 0.22 (300.0 examples/sec; 0.027 sec/batch; 0h:05m:50s remains)
INFO - root - 2022-02-24 21:21:28.520617: step 186370, total loss = 0.55, batch loss = 0.29 (340.7 examples/sec; 0.023 sec/batch; 0h:05m:08s remains)
INFO - root - 2022-02-24 21:21:28.816345: step 186380, total loss = 0.53, batch loss = 0.28 (267.7 examples/sec; 0.030 sec/batch; 0h:06m:32s remains)
INFO - root - 2022-02-24 21:21:29.257042: step 186390, total loss = 0.54, batch loss = 0.28 (148.2 examples/sec; 0.054 sec/batch; 0h:11m:47s remains)
INFO - root - 2022-02-24 21:21:29.607822: step 186400, total loss = 0.52, batch loss = 0.27 (281.9 examples/sec; 0.028 sec/batch; 0h:06m:11s remains)
INFO - root - 2022-02-24 21:21:30.061576: step 186410, total loss = 0.46, batch loss = 0.20 (331.8 examples/sec; 0.024 sec/batch; 0h:05m:15s remains)
INFO - root - 2022-02-24 21:21:30.399089: step 186420, total loss = 0.63, batch loss = 0.37 (330.4 examples/sec; 0.024 sec/batch; 0h:05m:16s remains)
INFO - root - 2022-02-24 21:21:30.825820: step 186430, total loss = 0.58, batch loss = 0.32 (352.3 examples/sec; 0.023 sec/batch; 0h:04m:56s remains)
INFO - root - 2022-02-24 21:21:31.276854: step 186440, total loss = 0.55, batch loss = 0.29 (347.8 examples/sec; 0.023 sec/batch; 0h:05m:00s remains)
INFO - root - 2022-02-24 21:21:31.620370: step 186450, total loss = 0.56, batch loss = 0.30 (100.7 examples/sec; 0.079 sec/batch; 0h:17m:17s remains)
INFO - root - 2022-02-24 21:21:32.116924: step 186460, total loss = 0.61, batch loss = 0.35 (90.5 examples/sec; 0.088 sec/batch; 0h:19m:13s remains)
INFO - root - 2022-02-24 21:21:32.628739: step 186470, total loss = 0.54, batch loss = 0.28 (333.6 examples/sec; 0.024 sec/batch; 0h:05m:12s remains)
INFO - root - 2022-02-24 21:21:33.153831: step 186480, total loss = 0.54, batch loss = 0.29 (236.6 examples/sec; 0.034 sec/batch; 0h:07m:20s remains)
INFO - root - 2022-02-24 21:21:33.811911: step 186490, total loss = 0.57, batch loss = 0.31 (166.6 examples/sec; 0.048 sec/batch; 0h:10m:24s remains)
INFO - root - 2022-02-24 21:21:34.293300: step 186500, total loss = 0.49, batch loss = 0.23 (327.4 examples/sec; 0.024 sec/batch; 0h:05m:17s remains)
INFO - root - 2022-02-24 21:21:35.208439: step 186510, total loss = 0.57, batch loss = 0.32 (172.0 examples/sec; 0.047 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:21:35.621602: step 186520, total loss = 0.53, batch loss = 0.27 (160.8 examples/sec; 0.050 sec/batch; 0h:10m:45s remains)
INFO - root - 2022-02-24 21:21:36.054130: step 186530, total loss = 0.49, batch loss = 0.23 (217.1 examples/sec; 0.037 sec/batch; 0h:07m:57s remains)
INFO - root - 2022-02-24 21:21:36.342197: step 186540, total loss = 0.53, batch loss = 0.28 (341.5 examples/sec; 0.023 sec/batch; 0h:05m:03s remains)
INFO - root - 2022-02-24 21:21:36.641255: step 186550, total loss = 0.50, batch loss = 0.24 (225.5 examples/sec; 0.035 sec/batch; 0h:07m:39s remains)
INFO - root - 2022-02-24 21:21:36.963200: step 186560, total loss = 0.57, batch loss = 0.31 (304.6 examples/sec; 0.026 sec/batch; 0h:05m:39s remains)
INFO - root - 2022-02-24 21:21:37.301393: step 186570, total loss = 0.51, batch loss = 0.25 (107.4 examples/sec; 0.075 sec/batch; 0h:16m:03s remains)
INFO - root - 2022-02-24 21:21:37.656137: step 186580, total loss = 0.53, batch loss = 0.28 (164.9 examples/sec; 0.049 sec/batch; 0h:10m:26s remains)
INFO - root - 2022-02-24 21:21:38.051746: step 186590, total loss = 0.56, batch loss = 0.30 (161.8 examples/sec; 0.049 sec/batch; 0h:10m:38s remains)
INFO - root - 2022-02-24 21:21:38.344533: step 186600, total loss = 0.43, batch loss = 0.17 (328.8 examples/sec; 0.024 sec/batch; 0h:05m:13s remains)
INFO - root - 2022-02-24 21:21:38.691531: step 186610, total loss = 0.48, batch loss = 0.22 (336.9 examples/sec; 0.024 sec/batch; 0h:05m:06s remains)
INFO - root - 2022-02-24 21:21:38.988416: step 186620, total loss = 0.59, batch loss = 0.34 (237.7 examples/sec; 0.034 sec/batch; 0h:07m:13s remains)
INFO - root - 2022-02-24 21:21:39.368316: step 186630, total loss = 0.52, batch loss = 0.26 (315.4 examples/sec; 0.025 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:21:39.785125: step 186640, total loss = 0.57, batch loss = 0.31 (310.7 examples/sec; 0.026 sec/batch; 0h:05m:31s remains)
INFO - root - 2022-02-24 21:21:40.172562: step 186650, total loss = 0.55, batch loss = 0.29 (286.9 examples/sec; 0.028 sec/batch; 0h:05m:58s remains)
INFO - root - 2022-02-24 21:21:40.450405: step 186660, total loss = 0.61, batch loss = 0.36 (314.4 examples/sec; 0.025 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:21:40.757688: step 186670, total loss = 0.49, batch loss = 0.24 (165.5 examples/sec; 0.048 sec/batch; 0h:10m:20s remains)
INFO - root - 2022-02-24 21:21:41.048697: step 186680, total loss = 0.56, batch loss = 0.30 (334.8 examples/sec; 0.024 sec/batch; 0h:05m:06s remains)
INFO - root - 2022-02-24 21:21:41.393837: step 186690, total loss = 0.54, batch loss = 0.28 (164.7 examples/sec; 0.049 sec/batch; 0h:10m:22s remains)
INFO - root - 2022-02-24 21:21:41.792636: step 186700, total loss = 0.50, batch loss = 0.24 (252.4 examples/sec; 0.032 sec/batch; 0h:06m:45s remains)
INFO - root - 2022-02-24 21:21:42.180747: step 186710, total loss = 0.53, batch loss = 0.27 (356.7 examples/sec; 0.022 sec/batch; 0h:04m:46s remains)
INFO - root - 2022-02-24 21:21:42.484475: step 186720, total loss = 0.44, batch loss = 0.19 (331.0 examples/sec; 0.024 sec/batch; 0h:05m:08s remains)
INFO - root - 2022-02-24 21:21:42.792238: step 186730, total loss = 0.61, batch loss = 0.36 (220.2 examples/sec; 0.036 sec/batch; 0h:07m:43s remains)
INFO - root - 2022-02-24 21:21:43.110790: step 186740, total loss = 0.56, batch loss = 0.30 (337.4 examples/sec; 0.024 sec/batch; 0h:05m:02s remains)
INFO - root - 2022-02-24 21:21:43.506305: step 186750, total loss = 0.58, batch loss = 0.32 (104.0 examples/sec; 0.077 sec/batch; 0h:16m:21s remains)
INFO - root - 2022-02-24 21:21:43.895259: step 186760, total loss = 0.47, batch loss = 0.21 (151.0 examples/sec; 0.053 sec/batch; 0h:11m:15s remains)
INFO - root - 2022-02-24 21:21:44.297668: step 186770, total loss = 0.62, batch loss = 0.37 (147.4 examples/sec; 0.054 sec/batch; 0h:11m:31s remains)
INFO - root - 2022-02-24 21:21:44.666499: step 186780, total loss = 0.50, batch loss = 0.24 (234.9 examples/sec; 0.034 sec/batch; 0h:07m:13s remains)
INFO - root - 2022-02-24 21:21:44.951410: step 186790, total loss = 0.57, batch loss = 0.32 (226.8 examples/sec; 0.035 sec/batch; 0h:07m:28s remains)
INFO - root - 2022-02-24 21:21:45.251696: step 186800, total loss = 0.46, batch loss = 0.20 (153.7 examples/sec; 0.052 sec/batch; 0h:11m:01s remains)
INFO - root - 2022-02-24 21:21:45.713999: step 186810, total loss = 0.47, batch loss = 0.21 (126.4 examples/sec; 0.063 sec/batch; 0h:13m:23s remains)
INFO - root - 2022-02-24 21:21:46.150543: step 186820, total loss = 0.53, batch loss = 0.28 (170.4 examples/sec; 0.047 sec/batch; 0h:09m:55s remains)
INFO - root - 2022-02-24 21:21:46.538775: step 186830, total loss = 0.56, batch loss = 0.31 (143.5 examples/sec; 0.056 sec/batch; 0h:11m:46s remains)
INFO - root - 2022-02-24 21:21:46.870025: step 186840, total loss = 0.47, batch loss = 0.21 (226.5 examples/sec; 0.035 sec/batch; 0h:07m:27s remains)
INFO - root - 2022-02-24 21:21:47.161327: step 186850, total loss = 0.53, batch loss = 0.27 (227.7 examples/sec; 0.035 sec/batch; 0h:07m:24s remains)
INFO - root - 2022-02-24 21:21:47.492008: step 186860, total loss = 0.62, batch loss = 0.37 (219.9 examples/sec; 0.036 sec/batch; 0h:07m:39s remains)
INFO - root - 2022-02-24 21:21:47.767952: step 186870, total loss = 0.64, batch loss = 0.38 (311.0 examples/sec; 0.026 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:21:48.199302: step 186880, total loss = 0.53, batch loss = 0.27 (137.7 examples/sec; 0.058 sec/batch; 0h:12m:13s remains)
INFO - root - 2022-02-24 21:21:48.560517: step 186890, total loss = 0.48, batch loss = 0.23 (191.6 examples/sec; 0.042 sec/batch; 0h:08m:46s remains)
INFO - root - 2022-02-24 21:21:48.858454: step 186900, total loss = 0.53, batch loss = 0.28 (179.7 examples/sec; 0.045 sec/batch; 0h:09m:21s remains)
INFO - root - 2022-02-24 21:21:49.213691: step 186910, total loss = 0.61, batch loss = 0.35 (312.6 examples/sec; 0.026 sec/batch; 0h:05m:22s remains)
INFO - root - 2022-02-24 21:21:49.456140: step 186920, total loss = 0.53, batch loss = 0.28 (331.9 examples/sec; 0.024 sec/batch; 0h:05m:03s remains)
INFO - root - 2022-02-24 21:21:49.795201: step 186930, total loss = 0.56, batch loss = 0.30 (187.4 examples/sec; 0.043 sec/batch; 0h:08m:56s remains)
INFO - root - 2022-02-24 21:21:50.255286: step 186940, total loss = 0.54, batch loss = 0.29 (179.9 examples/sec; 0.044 sec/batch; 0h:09m:18s remains)
INFO - root - 2022-02-24 21:21:50.660472: step 186950, total loss = 0.52, batch loss = 0.27 (209.3 examples/sec; 0.038 sec/batch; 0h:07m:59s remains)
INFO - root - 2022-02-24 21:21:51.080618: step 186960, total loss = 0.57, batch loss = 0.32 (93.4 examples/sec; 0.086 sec/batch; 0h:17m:53s remains)
INFO - root - 2022-02-24 21:21:51.384576: step 186970, total loss = 0.42, batch loss = 0.17 (324.8 examples/sec; 0.025 sec/batch; 0h:05m:08s remains)
INFO - root - 2022-02-24 21:21:51.669913: step 186980, total loss = 0.58, batch loss = 0.32 (335.9 examples/sec; 0.024 sec/batch; 0h:04m:58s remains)
INFO - root - 2022-02-24 21:21:51.949217: step 186990, total loss = 0.47, batch loss = 0.21 (300.4 examples/sec; 0.027 sec/batch; 0h:05m:33s remains)
INFO - root - 2022-02-24 21:21:52.313853: step 187000, total loss = 0.53, batch loss = 0.28 (367.6 examples/sec; 0.022 sec/batch; 0h:04m:32s remains)
INFO - root - 2022-02-24 21:21:52.799414: step 187010, total loss = 0.58, batch loss = 0.32 (241.4 examples/sec; 0.033 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:21:53.100323: step 187020, total loss = 0.61, batch loss = 0.36 (301.2 examples/sec; 0.027 sec/batch; 0h:05m:31s remains)
INFO - root - 2022-02-24 21:21:53.417761: step 187030, total loss = 0.48, batch loss = 0.23 (204.6 examples/sec; 0.039 sec/batch; 0h:08m:07s remains)
INFO - root - 2022-02-24 21:21:53.706793: step 187040, total loss = 0.58, batch loss = 0.33 (336.8 examples/sec; 0.024 sec/batch; 0h:04m:55s remains)
INFO - root - 2022-02-24 21:21:54.047012: step 187050, total loss = 0.59, batch loss = 0.33 (179.8 examples/sec; 0.044 sec/batch; 0h:09m:13s remains)
INFO - root - 2022-02-24 21:21:54.393551: step 187060, total loss = 0.60, batch loss = 0.34 (354.0 examples/sec; 0.023 sec/batch; 0h:04m:41s remains)
INFO - root - 2022-02-24 21:21:54.862024: step 187070, total loss = 0.47, batch loss = 0.22 (164.4 examples/sec; 0.049 sec/batch; 0h:10m:04s remains)
INFO - root - 2022-02-24 21:21:55.365096: step 187080, total loss = 0.51, batch loss = 0.25 (141.5 examples/sec; 0.057 sec/batch; 0h:11m:42s remains)
INFO - root - 2022-02-24 21:21:55.735765: step 187090, total loss = 0.45, batch loss = 0.19 (163.3 examples/sec; 0.049 sec/batch; 0h:10m:07s remains)
INFO - root - 2022-02-24 21:21:56.067958: step 187100, total loss = 0.49, batch loss = 0.23 (146.4 examples/sec; 0.055 sec/batch; 0h:11m:17s remains)
INFO - root - 2022-02-24 21:21:56.493181: step 187110, total loss = 0.62, batch loss = 0.36 (196.7 examples/sec; 0.041 sec/batch; 0h:08m:23s remains)
INFO - root - 2022-02-24 21:21:56.788120: step 187120, total loss = 0.54, batch loss = 0.28 (325.3 examples/sec; 0.025 sec/batch; 0h:05m:04s remains)
INFO - root - 2022-02-24 21:21:57.043199: step 187130, total loss = 0.49, batch loss = 0.23 (332.0 examples/sec; 0.024 sec/batch; 0h:04m:58s remains)
INFO - root - 2022-02-24 21:21:57.367710: step 187140, total loss = 0.59, batch loss = 0.33 (298.9 examples/sec; 0.027 sec/batch; 0h:05m:30s remains)
INFO - root - 2022-02-24 21:21:57.653977: step 187150, total loss = 0.62, batch loss = 0.37 (333.1 examples/sec; 0.024 sec/batch; 0h:04m:56s remains)
INFO - root - 2022-02-24 21:21:58.035552: step 187160, total loss = 0.49, batch loss = 0.24 (115.0 examples/sec; 0.070 sec/batch; 0h:14m:18s remains)
INFO - root - 2022-02-24 21:21:58.426180: step 187170, total loss = 0.49, batch loss = 0.24 (121.2 examples/sec; 0.066 sec/batch; 0h:13m:33s remains)
INFO - root - 2022-02-24 21:21:58.742097: step 187180, total loss = 0.53, batch loss = 0.27 (336.0 examples/sec; 0.024 sec/batch; 0h:04m:53s remains)
INFO - root - 2022-02-24 21:21:59.086671: step 187190, total loss = 0.52, batch loss = 0.26 (169.7 examples/sec; 0.047 sec/batch; 0h:09m:40s remains)
INFO - root - 2022-02-24 21:21:59.391084: step 187200, total loss = 0.52, batch loss = 0.26 (339.3 examples/sec; 0.024 sec/batch; 0h:04m:50s remains)
INFO - root - 2022-02-24 21:21:59.818023: step 187210, total loss = 0.53, batch loss = 0.27 (142.7 examples/sec; 0.056 sec/batch; 0h:11m:29s remains)
INFO - root - 2022-02-24 21:22:00.326345: step 187220, total loss = 0.52, batch loss = 0.27 (199.7 examples/sec; 0.040 sec/batch; 0h:08m:11s remains)
INFO - root - 2022-02-24 21:22:00.643154: step 187230, total loss = 0.48, batch loss = 0.22 (325.6 examples/sec; 0.025 sec/batch; 0h:05m:01s remains)
INFO - root - 2022-02-24 21:22:01.026546: step 187240, total loss = 0.50, batch loss = 0.25 (180.6 examples/sec; 0.044 sec/batch; 0h:09m:03s remains)
INFO - root - 2022-02-24 21:22:01.315213: step 187250, total loss = 0.50, batch loss = 0.24 (338.8 examples/sec; 0.024 sec/batch; 0h:04m:49s remains)
INFO - root - 2022-02-24 21:22:01.664625: step 187260, total loss = 0.50, batch loss = 0.24 (194.2 examples/sec; 0.041 sec/batch; 0h:08m:24s remains)
INFO - root - 2022-02-24 21:22:02.036424: step 187270, total loss = 0.61, batch loss = 0.35 (388.1 examples/sec; 0.021 sec/batch; 0h:04m:12s remains)
INFO - root - 2022-02-24 21:22:02.469920: step 187280, total loss = 0.64, batch loss = 0.39 (364.7 examples/sec; 0.022 sec/batch; 0h:04m:28s remains)
INFO - root - 2022-02-24 21:22:02.789621: step 187290, total loss = 0.50, batch loss = 0.25 (287.4 examples/sec; 0.028 sec/batch; 0h:05m:39s remains)
INFO - root - 2022-02-24 21:22:03.102018: step 187300, total loss = 0.62, batch loss = 0.37 (264.0 examples/sec; 0.030 sec/batch; 0h:06m:09s remains)
INFO - root - 2022-02-24 21:22:03.479756: step 187310, total loss = 0.46, batch loss = 0.20 (194.3 examples/sec; 0.041 sec/batch; 0h:08m:21s remains)
INFO - root - 2022-02-24 21:22:03.798094: step 187320, total loss = 0.53, batch loss = 0.28 (338.0 examples/sec; 0.024 sec/batch; 0h:04m:48s remains)
INFO - root - 2022-02-24 21:22:04.175110: step 187330, total loss = 0.55, batch loss = 0.30 (263.1 examples/sec; 0.030 sec/batch; 0h:06m:10s remains)
INFO - root - 2022-02-24 21:22:04.572975: step 187340, total loss = 0.58, batch loss = 0.32 (351.6 examples/sec; 0.023 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:22:04.994009: step 187350, total loss = 0.57, batch loss = 0.31 (311.9 examples/sec; 0.026 sec/batch; 0h:05m:11s remains)
INFO - root - 2022-02-24 21:22:05.398726: step 187360, total loss = 0.54, batch loss = 0.29 (238.1 examples/sec; 0.034 sec/batch; 0h:06m:47s remains)
INFO - root - 2022-02-24 21:22:06.151863: step 187370, total loss = 0.57, batch loss = 0.31 (61.5 examples/sec; 0.130 sec/batch; 0h:26m:17s remains)
INFO - root - 2022-02-24 21:22:06.853485: step 187380, total loss = 0.49, batch loss = 0.24 (324.4 examples/sec; 0.025 sec/batch; 0h:04m:58s remains)
INFO - root - 2022-02-24 21:22:07.375352: step 187390, total loss = 0.47, batch loss = 0.22 (173.0 examples/sec; 0.046 sec/batch; 0h:09m:20s remains)
INFO - root - 2022-02-24 21:22:07.725357: step 187400, total loss = 0.52, batch loss = 0.27 (294.9 examples/sec; 0.027 sec/batch; 0h:05m:28s remains)
INFO - root - 2022-02-24 21:22:08.163547: step 187410, total loss = 0.49, batch loss = 0.23 (130.1 examples/sec; 0.061 sec/batch; 0h:12m:23s remains)
INFO - root - 2022-02-24 21:22:08.542033: step 187420, total loss = 0.61, batch loss = 0.35 (286.9 examples/sec; 0.028 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:22:08.913553: step 187430, total loss = 0.63, batch loss = 0.37 (118.9 examples/sec; 0.067 sec/batch; 0h:13m:31s remains)
INFO - root - 2022-02-24 21:22:09.321214: step 187440, total loss = 0.60, batch loss = 0.35 (157.8 examples/sec; 0.051 sec/batch; 0h:10m:11s remains)
INFO - root - 2022-02-24 21:22:09.649911: step 187450, total loss = 0.49, batch loss = 0.24 (194.1 examples/sec; 0.041 sec/batch; 0h:08m:16s remains)
INFO - root - 2022-02-24 21:22:10.443587: step 187460, total loss = 0.53, batch loss = 0.27 (170.0 examples/sec; 0.047 sec/batch; 0h:09m:26s remains)
INFO - root - 2022-02-24 21:22:10.968852: step 187470, total loss = 0.54, batch loss = 0.29 (125.9 examples/sec; 0.064 sec/batch; 0h:12m:44s remains)
INFO - root - 2022-02-24 21:22:11.333540: step 187480, total loss = 0.48, batch loss = 0.22 (217.2 examples/sec; 0.037 sec/batch; 0h:07m:22s remains)
INFO - root - 2022-02-24 21:22:11.601222: step 187490, total loss = 0.53, batch loss = 0.27 (335.6 examples/sec; 0.024 sec/batch; 0h:04m:46s remains)
INFO - root - 2022-02-24 21:22:11.901663: step 187500, total loss = 0.48, batch loss = 0.22 (265.6 examples/sec; 0.030 sec/batch; 0h:06m:01s remains)
INFO - root - 2022-02-24 21:22:12.255038: step 187510, total loss = 0.62, batch loss = 0.36 (186.4 examples/sec; 0.043 sec/batch; 0h:08m:34s remains)
INFO - root - 2022-02-24 21:22:12.701792: step 187520, total loss = 0.55, batch loss = 0.30 (118.8 examples/sec; 0.067 sec/batch; 0h:13m:26s remains)
INFO - root - 2022-02-24 21:22:13.137669: step 187530, total loss = 0.70, batch loss = 0.44 (295.5 examples/sec; 0.027 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:22:13.411118: step 187540, total loss = 0.43, batch loss = 0.18 (356.8 examples/sec; 0.022 sec/batch; 0h:04m:28s remains)
INFO - root - 2022-02-24 21:22:13.738817: step 187550, total loss = 0.52, batch loss = 0.26 (285.9 examples/sec; 0.028 sec/batch; 0h:05m:34s remains)
INFO - root - 2022-02-24 21:22:14.097299: step 187560, total loss = 0.50, batch loss = 0.24 (150.5 examples/sec; 0.053 sec/batch; 0h:10m:34s remains)
INFO - root - 2022-02-24 21:22:14.385544: step 187570, total loss = 0.49, batch loss = 0.23 (205.6 examples/sec; 0.039 sec/batch; 0h:07m:44s remains)
INFO - root - 2022-02-24 21:22:14.793927: step 187580, total loss = 0.47, batch loss = 0.21 (276.4 examples/sec; 0.029 sec/batch; 0h:05m:45s remains)
INFO - root - 2022-02-24 21:22:15.187705: step 187590, total loss = 0.55, batch loss = 0.30 (234.9 examples/sec; 0.034 sec/batch; 0h:06m:45s remains)
INFO - root - 2022-02-24 21:22:15.619949: step 187600, total loss = 0.54, batch loss = 0.28 (221.7 examples/sec; 0.036 sec/batch; 0h:07m:09s remains)
INFO - root - 2022-02-24 21:22:16.062966: step 187610, total loss = 0.53, batch loss = 0.27 (246.1 examples/sec; 0.033 sec/batch; 0h:06m:26s remains)
INFO - root - 2022-02-24 21:22:16.436186: step 187620, total loss = 0.56, batch loss = 0.30 (345.9 examples/sec; 0.023 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:22:16.802150: step 187630, total loss = 0.67, batch loss = 0.41 (338.7 examples/sec; 0.024 sec/batch; 0h:04m:40s remains)
INFO - root - 2022-02-24 21:22:17.230308: step 187640, total loss = 0.63, batch loss = 0.37 (226.1 examples/sec; 0.035 sec/batch; 0h:06m:59s remains)
INFO - root - 2022-02-24 21:22:17.491429: step 187650, total loss = 0.55, batch loss = 0.30 (329.7 examples/sec; 0.024 sec/batch; 0h:04m:47s remains)
INFO - root - 2022-02-24 21:22:17.765269: step 187660, total loss = 0.57, batch loss = 0.31 (247.3 examples/sec; 0.032 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:22:18.086109: step 187670, total loss = 0.46, batch loss = 0.21 (343.1 examples/sec; 0.023 sec/batch; 0h:04m:35s remains)
INFO - root - 2022-02-24 21:22:18.405802: step 187680, total loss = 0.54, batch loss = 0.29 (309.6 examples/sec; 0.026 sec/batch; 0h:05m:05s remains)
INFO - root - 2022-02-24 21:22:18.799126: step 187690, total loss = 0.53, batch loss = 0.28 (251.2 examples/sec; 0.032 sec/batch; 0h:06m:16s remains)
INFO - root - 2022-02-24 21:22:19.149277: step 187700, total loss = 0.57, batch loss = 0.31 (347.2 examples/sec; 0.023 sec/batch; 0h:04m:31s remains)
INFO - root - 2022-02-24 21:22:19.514152: step 187710, total loss = 0.51, batch loss = 0.26 (349.5 examples/sec; 0.023 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:22:19.893606: step 187720, total loss = 0.53, batch loss = 0.28 (293.1 examples/sec; 0.027 sec/batch; 0h:05m:21s remains)
INFO - root - 2022-02-24 21:22:20.202793: step 187730, total loss = 0.71, batch loss = 0.45 (359.5 examples/sec; 0.022 sec/batch; 0h:04m:21s remains)
INFO - root - 2022-02-24 21:22:20.621263: step 187740, total loss = 0.48, batch loss = 0.23 (128.3 examples/sec; 0.062 sec/batch; 0h:12m:13s remains)
INFO - root - 2022-02-24 21:22:21.007531: step 187750, total loss = 0.69, batch loss = 0.44 (341.0 examples/sec; 0.023 sec/batch; 0h:04m:35s remains)
INFO - root - 2022-02-24 21:22:21.361507: step 187760, total loss = 0.49, batch loss = 0.24 (201.6 examples/sec; 0.040 sec/batch; 0h:07m:45s remains)
INFO - root - 2022-02-24 21:22:21.641426: step 187770, total loss = 0.50, batch loss = 0.24 (339.8 examples/sec; 0.024 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:22:21.974167: step 187780, total loss = 0.48, batch loss = 0.22 (187.3 examples/sec; 0.043 sec/batch; 0h:08m:20s remains)
INFO - root - 2022-02-24 21:22:22.334672: step 187790, total loss = 0.59, batch loss = 0.34 (347.8 examples/sec; 0.023 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:22:22.702885: step 187800, total loss = 0.51, batch loss = 0.26 (321.9 examples/sec; 0.025 sec/batch; 0h:04m:50s remains)
INFO - root - 2022-02-24 21:22:23.146171: step 187810, total loss = 0.72, batch loss = 0.46 (332.6 examples/sec; 0.024 sec/batch; 0h:04m:41s remains)
INFO - root - 2022-02-24 21:22:23.384062: step 187820, total loss = 0.61, batch loss = 0.35 (337.8 examples/sec; 0.024 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:22:23.668563: step 187830, total loss = 0.46, batch loss = 0.21 (169.5 examples/sec; 0.047 sec/batch; 0h:09m:10s remains)
INFO - root - 2022-02-24 21:22:23.982789: step 187840, total loss = 0.59, batch loss = 0.34 (232.7 examples/sec; 0.034 sec/batch; 0h:06m:40s remains)
INFO - root - 2022-02-24 21:22:24.272649: step 187850, total loss = 0.52, batch loss = 0.26 (329.0 examples/sec; 0.024 sec/batch; 0h:04m:43s remains)
INFO - root - 2022-02-24 21:22:24.616053: step 187860, total loss = 0.48, batch loss = 0.22 (246.3 examples/sec; 0.032 sec/batch; 0h:06m:18s remains)
INFO - root - 2022-02-24 21:22:25.033759: step 187870, total loss = 0.56, batch loss = 0.31 (242.5 examples/sec; 0.033 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:22:25.355870: step 187880, total loss = 0.58, batch loss = 0.32 (338.6 examples/sec; 0.024 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:22:25.684043: step 187890, total loss = 0.49, batch loss = 0.23 (330.5 examples/sec; 0.024 sec/batch; 0h:04m:40s remains)
INFO - root - 2022-02-24 21:22:26.032167: step 187900, total loss = 0.48, batch loss = 0.22 (310.6 examples/sec; 0.026 sec/batch; 0h:04m:58s remains)
INFO - root - 2022-02-24 21:22:26.376462: step 187910, total loss = 0.52, batch loss = 0.26 (303.0 examples/sec; 0.026 sec/batch; 0h:05m:06s remains)
INFO - root - 2022-02-24 21:22:26.740043: step 187920, total loss = 0.49, batch loss = 0.23 (195.8 examples/sec; 0.041 sec/batch; 0h:07m:53s remains)
INFO - root - 2022-02-24 21:22:27.106141: step 187930, total loss = 0.57, batch loss = 0.32 (345.4 examples/sec; 0.023 sec/batch; 0h:04m:27s remains)
INFO - root - 2022-02-24 21:22:27.402477: step 187940, total loss = 0.60, batch loss = 0.34 (334.4 examples/sec; 0.024 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:22:27.663162: step 187950, total loss = 0.49, batch loss = 0.24 (278.0 examples/sec; 0.029 sec/batch; 0h:05m:32s remains)
INFO - root - 2022-02-24 21:22:27.976734: step 187960, total loss = 0.61, batch loss = 0.35 (250.2 examples/sec; 0.032 sec/batch; 0h:06m:08s remains)
INFO - root - 2022-02-24 21:22:28.224598: step 187970, total loss = 0.51, batch loss = 0.26 (288.3 examples/sec; 0.028 sec/batch; 0h:05m:19s remains)
INFO - root - 2022-02-24 21:22:28.640222: step 187980, total loss = 0.53, batch loss = 0.28 (242.3 examples/sec; 0.033 sec/batch; 0h:06m:20s remains)
INFO - root - 2022-02-24 21:22:29.065823: step 187990, total loss = 0.55, batch loss = 0.29 (203.6 examples/sec; 0.039 sec/batch; 0h:07m:32s remains)
INFO - root - 2022-02-24 21:22:29.369353: step 188000, total loss = 0.50, batch loss = 0.25 (304.2 examples/sec; 0.026 sec/batch; 0h:05m:02s remains)
INFO - root - 2022-02-24 21:22:29.703048: step 188010, total loss = 0.61, batch loss = 0.35 (341.4 examples/sec; 0.023 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:22:29.950838: step 188020, total loss = 0.54, batch loss = 0.28 (269.5 examples/sec; 0.030 sec/batch; 0h:05m:40s remains)
INFO - root - 2022-02-24 21:22:30.231437: step 188030, total loss = 0.55, batch loss = 0.29 (283.0 examples/sec; 0.028 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:22:30.561203: step 188040, total loss = 0.55, batch loss = 0.29 (328.1 examples/sec; 0.024 sec/batch; 0h:04m:39s remains)
INFO - root - 2022-02-24 21:22:31.057027: step 188050, total loss = 0.51, batch loss = 0.25 (199.9 examples/sec; 0.040 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:22:31.339689: step 188060, total loss = 0.48, batch loss = 0.22 (374.9 examples/sec; 0.021 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:22:31.599285: step 188070, total loss = 0.60, batch loss = 0.34 (268.7 examples/sec; 0.030 sec/batch; 0h:05m:40s remains)
INFO - root - 2022-02-24 21:22:31.928722: step 188080, total loss = 0.47, batch loss = 0.22 (277.4 examples/sec; 0.029 sec/batch; 0h:05m:29s remains)
INFO - root - 2022-02-24 21:22:32.220317: step 188090, total loss = 0.56, batch loss = 0.30 (323.6 examples/sec; 0.025 sec/batch; 0h:04m:42s remains)
INFO - root - 2022-02-24 21:22:32.504614: step 188100, total loss = 0.49, batch loss = 0.24 (315.6 examples/sec; 0.025 sec/batch; 0h:04m:49s remains)
INFO - root - 2022-02-24 21:22:32.951900: step 188110, total loss = 0.63, batch loss = 0.37 (335.3 examples/sec; 0.024 sec/batch; 0h:04m:31s remains)
INFO - root - 2022-02-24 21:22:33.313924: step 188120, total loss = 0.55, batch loss = 0.29 (128.2 examples/sec; 0.062 sec/batch; 0h:11m:50s remains)
INFO - root - 2022-02-24 21:22:33.624235: step 188130, total loss = 0.50, batch loss = 0.25 (324.0 examples/sec; 0.025 sec/batch; 0h:04m:40s remains)
INFO - root - 2022-02-24 21:22:33.908879: step 188140, total loss = 0.49, batch loss = 0.23 (352.5 examples/sec; 0.023 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:22:34.274986: step 188150, total loss = 0.49, batch loss = 0.23 (99.3 examples/sec; 0.081 sec/batch; 0h:15m:14s remains)
INFO - root - 2022-02-24 21:22:34.693663: step 188160, total loss = 0.56, batch loss = 0.31 (187.6 examples/sec; 0.043 sec/batch; 0h:08m:03s remains)
INFO - root - 2022-02-24 21:22:35.052615: step 188170, total loss = 0.54, batch loss = 0.29 (340.5 examples/sec; 0.023 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:22:35.307279: step 188180, total loss = 0.50, batch loss = 0.24 (309.1 examples/sec; 0.026 sec/batch; 0h:04m:53s remains)
INFO - root - 2022-02-24 21:22:35.588849: step 188190, total loss = 0.57, batch loss = 0.32 (335.6 examples/sec; 0.024 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:22:35.932274: step 188200, total loss = 0.69, batch loss = 0.44 (257.7 examples/sec; 0.031 sec/batch; 0h:05m:50s remains)
INFO - root - 2022-02-24 21:22:36.276663: step 188210, total loss = 0.54, batch loss = 0.28 (312.3 examples/sec; 0.026 sec/batch; 0h:04m:49s remains)
INFO - root - 2022-02-24 21:22:36.691322: step 188220, total loss = 0.56, batch loss = 0.31 (312.5 examples/sec; 0.026 sec/batch; 0h:04m:48s remains)
INFO - root - 2022-02-24 21:22:37.039491: step 188230, total loss = 0.47, batch loss = 0.21 (287.5 examples/sec; 0.028 sec/batch; 0h:05m:13s remains)
INFO - root - 2022-02-24 21:22:37.350883: step 188240, total loss = 0.54, batch loss = 0.28 (363.2 examples/sec; 0.022 sec/batch; 0h:04m:07s remains)
INFO - root - 2022-02-24 21:22:37.674787: step 188250, total loss = 0.66, batch loss = 0.41 (154.8 examples/sec; 0.052 sec/batch; 0h:09m:41s remains)
INFO - root - 2022-02-24 21:22:37.968346: step 188260, total loss = 0.49, batch loss = 0.23 (261.4 examples/sec; 0.031 sec/batch; 0h:05m:43s remains)
INFO - root - 2022-02-24 21:22:38.281292: step 188270, total loss = 0.65, batch loss = 0.40 (361.1 examples/sec; 0.022 sec/batch; 0h:04m:08s remains)
INFO - root - 2022-02-24 21:22:38.761455: step 188280, total loss = 0.58, batch loss = 0.33 (173.1 examples/sec; 0.046 sec/batch; 0h:08m:38s remains)
INFO - root - 2022-02-24 21:22:39.400573: step 188290, total loss = 0.46, batch loss = 0.21 (236.0 examples/sec; 0.034 sec/batch; 0h:06m:20s remains)
INFO - root - 2022-02-24 21:22:40.069575: step 188300, total loss = 0.55, batch loss = 0.29 (104.9 examples/sec; 0.076 sec/batch; 0h:14m:14s remains)
INFO - root - 2022-02-24 21:22:40.612996: step 188310, total loss = 0.51, batch loss = 0.25 (231.9 examples/sec; 0.034 sec/batch; 0h:06m:25s remains)
INFO - root - 2022-02-24 21:22:41.024607: step 188320, total loss = 0.47, batch loss = 0.22 (238.6 examples/sec; 0.034 sec/batch; 0h:06m:14s remains)
INFO - root - 2022-02-24 21:22:41.829787: step 188330, total loss = 0.53, batch loss = 0.27 (335.2 examples/sec; 0.024 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:22:42.131270: step 188340, total loss = 0.65, batch loss = 0.39 (276.2 examples/sec; 0.029 sec/batch; 0h:05m:23s remains)
INFO - root - 2022-02-24 21:22:42.486657: step 188350, total loss = 0.64, batch loss = 0.38 (276.6 examples/sec; 0.029 sec/batch; 0h:05m:22s remains)
INFO - root - 2022-02-24 21:22:42.939211: step 188360, total loss = 0.50, batch loss = 0.24 (151.5 examples/sec; 0.053 sec/batch; 0h:09m:48s remains)
INFO - root - 2022-02-24 21:22:43.279256: step 188370, total loss = 0.51, batch loss = 0.25 (288.6 examples/sec; 0.028 sec/batch; 0h:05m:08s remains)
INFO - root - 2022-02-24 21:22:43.595978: step 188380, total loss = 0.52, batch loss = 0.26 (211.4 examples/sec; 0.038 sec/batch; 0h:07m:00s remains)
INFO - root - 2022-02-24 21:22:43.875315: step 188390, total loss = 0.57, batch loss = 0.32 (173.1 examples/sec; 0.046 sec/batch; 0h:08m:33s remains)
INFO - root - 2022-02-24 21:22:44.227074: step 188400, total loss = 0.57, batch loss = 0.32 (184.7 examples/sec; 0.043 sec/batch; 0h:08m:00s remains)
INFO - root - 2022-02-24 21:22:44.581230: step 188410, total loss = 0.48, batch loss = 0.22 (370.0 examples/sec; 0.022 sec/batch; 0h:03m:59s remains)
INFO - root - 2022-02-24 21:22:45.049411: step 188420, total loss = 0.56, batch loss = 0.30 (131.8 examples/sec; 0.061 sec/batch; 0h:11m:12s remains)
INFO - root - 2022-02-24 21:22:45.329138: step 188430, total loss = 0.63, batch loss = 0.37 (325.6 examples/sec; 0.025 sec/batch; 0h:04m:31s remains)
INFO - root - 2022-02-24 21:22:45.693440: step 188440, total loss = 0.47, batch loss = 0.22 (280.7 examples/sec; 0.029 sec/batch; 0h:05m:15s remains)
INFO - root - 2022-02-24 21:22:46.018884: step 188450, total loss = 0.52, batch loss = 0.26 (335.0 examples/sec; 0.024 sec/batch; 0h:04m:23s remains)
INFO - root - 2022-02-24 21:22:46.498977: step 188460, total loss = 0.57, batch loss = 0.31 (205.5 examples/sec; 0.039 sec/batch; 0h:07m:09s remains)
INFO - root - 2022-02-24 21:22:46.840096: step 188470, total loss = 0.50, batch loss = 0.24 (207.5 examples/sec; 0.039 sec/batch; 0h:07m:05s remains)
INFO - root - 2022-02-24 21:22:47.249023: step 188480, total loss = 0.66, batch loss = 0.40 (200.5 examples/sec; 0.040 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:22:47.510888: step 188490, total loss = 0.64, batch loss = 0.38 (343.5 examples/sec; 0.023 sec/batch; 0h:04m:16s remains)
INFO - root - 2022-02-24 21:22:47.800116: step 188500, total loss = 0.49, batch loss = 0.24 (341.9 examples/sec; 0.023 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:22:48.118383: step 188510, total loss = 0.66, batch loss = 0.41 (243.6 examples/sec; 0.033 sec/batch; 0h:06m:00s remains)
INFO - root - 2022-02-24 21:22:48.442741: step 188520, total loss = 0.62, batch loss = 0.36 (183.7 examples/sec; 0.044 sec/batch; 0h:07m:58s remains)
INFO - root - 2022-02-24 21:22:48.916547: step 188530, total loss = 0.64, batch loss = 0.39 (153.4 examples/sec; 0.052 sec/batch; 0h:09m:32s remains)
INFO - root - 2022-02-24 21:22:49.263885: step 188540, total loss = 0.50, batch loss = 0.24 (174.2 examples/sec; 0.046 sec/batch; 0h:08m:23s remains)
INFO - root - 2022-02-24 21:22:49.602595: step 188550, total loss = 0.52, batch loss = 0.27 (310.5 examples/sec; 0.026 sec/batch; 0h:04m:42s remains)
INFO - root - 2022-02-24 21:22:49.926889: step 188560, total loss = 0.60, batch loss = 0.34 (268.1 examples/sec; 0.030 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:22:50.269564: step 188570, total loss = 0.60, batch loss = 0.34 (346.5 examples/sec; 0.023 sec/batch; 0h:04m:12s remains)
INFO - root - 2022-02-24 21:22:50.620718: step 188580, total loss = 0.46, batch loss = 0.21 (114.4 examples/sec; 0.070 sec/batch; 0h:12m:43s remains)
INFO - root - 2022-02-24 21:22:50.963135: step 188590, total loss = 0.56, batch loss = 0.30 (247.9 examples/sec; 0.032 sec/batch; 0h:05m:52s remains)
INFO - root - 2022-02-24 21:22:51.383150: step 188600, total loss = 0.54, batch loss = 0.28 (173.0 examples/sec; 0.046 sec/batch; 0h:08m:24s remains)
INFO - root - 2022-02-24 21:22:51.803485: step 188610, total loss = 0.55, batch loss = 0.29 (168.4 examples/sec; 0.048 sec/batch; 0h:08m:37s remains)
INFO - root - 2022-02-24 21:22:52.121096: step 188620, total loss = 0.60, batch loss = 0.35 (187.8 examples/sec; 0.043 sec/batch; 0h:07m:43s remains)
INFO - root - 2022-02-24 21:22:52.474025: step 188630, total loss = 0.52, batch loss = 0.27 (360.1 examples/sec; 0.022 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:22:52.796212: step 188640, total loss = 0.56, batch loss = 0.30 (325.0 examples/sec; 0.025 sec/batch; 0h:04m:27s remains)
INFO - root - 2022-02-24 21:22:53.203804: step 188650, total loss = 0.55, batch loss = 0.29 (326.7 examples/sec; 0.024 sec/batch; 0h:04m:25s remains)
INFO - root - 2022-02-24 21:22:53.654052: step 188660, total loss = 0.42, batch loss = 0.16 (143.0 examples/sec; 0.056 sec/batch; 0h:10m:06s remains)
INFO - root - 2022-02-24 21:22:53.958598: step 188670, total loss = 0.54, batch loss = 0.29 (168.6 examples/sec; 0.047 sec/batch; 0h:08m:34s remains)
INFO - root - 2022-02-24 21:22:54.245341: step 188680, total loss = 0.51, batch loss = 0.25 (317.8 examples/sec; 0.025 sec/batch; 0h:04m:32s remains)
INFO - root - 2022-02-24 21:22:54.535660: step 188690, total loss = 0.49, batch loss = 0.23 (345.6 examples/sec; 0.023 sec/batch; 0h:04m:10s remains)
INFO - root - 2022-02-24 21:22:54.855258: step 188700, total loss = 0.50, batch loss = 0.25 (220.1 examples/sec; 0.036 sec/batch; 0h:06m:32s remains)
INFO - root - 2022-02-24 21:22:55.234205: step 188710, total loss = 0.62, batch loss = 0.37 (359.7 examples/sec; 0.022 sec/batch; 0h:04m:00s remains)
INFO - root - 2022-02-24 21:22:55.607202: step 188720, total loss = 0.55, batch loss = 0.29 (377.4 examples/sec; 0.021 sec/batch; 0h:03m:48s remains)
INFO - root - 2022-02-24 21:22:55.942418: step 188730, total loss = 0.50, batch loss = 0.24 (167.4 examples/sec; 0.048 sec/batch; 0h:08m:34s remains)
INFO - root - 2022-02-24 21:22:56.193532: step 188740, total loss = 0.54, batch loss = 0.28 (349.3 examples/sec; 0.023 sec/batch; 0h:04m:06s remains)
INFO - root - 2022-02-24 21:22:56.502987: step 188750, total loss = 0.59, batch loss = 0.33 (341.1 examples/sec; 0.023 sec/batch; 0h:04m:12s remains)
INFO - root - 2022-02-24 21:22:56.835747: step 188760, total loss = 0.56, batch loss = 0.30 (349.1 examples/sec; 0.023 sec/batch; 0h:04m:06s remains)
INFO - root - 2022-02-24 21:22:57.208770: step 188770, total loss = 0.54, batch loss = 0.28 (242.9 examples/sec; 0.033 sec/batch; 0h:05m:53s remains)
INFO - root - 2022-02-24 21:22:57.553802: step 188780, total loss = 0.48, batch loss = 0.22 (355.3 examples/sec; 0.023 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:22:57.887900: step 188790, total loss = 0.57, batch loss = 0.31 (183.2 examples/sec; 0.044 sec/batch; 0h:07m:47s remains)
INFO - root - 2022-02-24 21:22:58.186536: step 188800, total loss = 0.48, batch loss = 0.22 (292.2 examples/sec; 0.027 sec/batch; 0h:04m:52s remains)
INFO - root - 2022-02-24 21:22:58.541050: step 188810, total loss = 0.74, batch loss = 0.48 (353.6 examples/sec; 0.023 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:22:58.806233: step 188820, total loss = 0.52, batch loss = 0.27 (318.3 examples/sec; 0.025 sec/batch; 0h:04m:28s remains)
INFO - root - 2022-02-24 21:22:59.132239: step 188830, total loss = 0.55, batch loss = 0.30 (108.5 examples/sec; 0.074 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:22:59.519461: step 188840, total loss = 0.61, batch loss = 0.35 (213.2 examples/sec; 0.038 sec/batch; 0h:06m:40s remains)
INFO - root - 2022-02-24 21:22:59.805270: step 188850, total loss = 0.56, batch loss = 0.30 (253.8 examples/sec; 0.032 sec/batch; 0h:05m:35s remains)
INFO - root - 2022-02-24 21:23:00.203774: step 188860, total loss = 0.54, batch loss = 0.28 (171.2 examples/sec; 0.047 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:23:00.579462: step 188870, total loss = 0.56, batch loss = 0.30 (252.6 examples/sec; 0.032 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:23:00.860620: step 188880, total loss = 0.46, batch loss = 0.21 (261.1 examples/sec; 0.031 sec/batch; 0h:05m:25s remains)
INFO - root - 2022-02-24 21:23:01.325219: step 188890, total loss = 0.58, batch loss = 0.32 (354.1 examples/sec; 0.023 sec/batch; 0h:03m:59s remains)
INFO - root - 2022-02-24 21:23:01.705067: step 188900, total loss = 0.46, batch loss = 0.20 (325.1 examples/sec; 0.025 sec/batch; 0h:04m:20s remains)
INFO - root - 2022-02-24 21:23:02.055364: step 188910, total loss = 0.62, batch loss = 0.37 (339.2 examples/sec; 0.024 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:23:02.326974: step 188920, total loss = 0.53, batch loss = 0.27 (328.1 examples/sec; 0.024 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:23:02.679213: step 188930, total loss = 0.56, batch loss = 0.30 (149.9 examples/sec; 0.053 sec/batch; 0h:09m:24s remains)
INFO - root - 2022-02-24 21:23:02.991690: step 188940, total loss = 0.75, batch loss = 0.49 (357.0 examples/sec; 0.022 sec/batch; 0h:03m:56s remains)
INFO - root - 2022-02-24 21:23:03.444074: step 188950, total loss = 0.49, batch loss = 0.24 (176.6 examples/sec; 0.045 sec/batch; 0h:07m:57s remains)
INFO - root - 2022-02-24 21:23:03.764751: step 188960, total loss = 0.48, batch loss = 0.23 (325.9 examples/sec; 0.025 sec/batch; 0h:04m:18s remains)
INFO - root - 2022-02-24 21:23:04.046685: step 188970, total loss = 0.49, batch loss = 0.24 (250.1 examples/sec; 0.032 sec/batch; 0h:05m:36s remains)
INFO - root - 2022-02-24 21:23:04.362402: step 188980, total loss = 0.56, batch loss = 0.31 (142.2 examples/sec; 0.056 sec/batch; 0h:09m:52s remains)
INFO - root - 2022-02-24 21:23:04.637706: step 188990, total loss = 0.53, batch loss = 0.27 (303.1 examples/sec; 0.026 sec/batch; 0h:04m:37s remains)
INFO - root - 2022-02-24 21:23:05.009527: step 189000, total loss = 0.56, batch loss = 0.31 (294.4 examples/sec; 0.027 sec/batch; 0h:04m:45s remains)
INFO - root - 2022-02-24 21:23:05.442465: step 189010, total loss = 0.58, batch loss = 0.33 (119.6 examples/sec; 0.067 sec/batch; 0h:11m:41s remains)
INFO - root - 2022-02-24 21:23:05.874629: step 189020, total loss = 0.49, batch loss = 0.23 (362.7 examples/sec; 0.022 sec/batch; 0h:03m:51s remains)
INFO - root - 2022-02-24 21:23:06.205061: step 189030, total loss = 0.49, batch loss = 0.24 (147.7 examples/sec; 0.054 sec/batch; 0h:09m:27s remains)
INFO - root - 2022-02-24 21:23:06.560594: step 189040, total loss = 0.60, batch loss = 0.35 (362.8 examples/sec; 0.022 sec/batch; 0h:03m:50s remains)
INFO - root - 2022-02-24 21:23:06.845436: step 189050, total loss = 0.45, batch loss = 0.20 (200.8 examples/sec; 0.040 sec/batch; 0h:06m:56s remains)
INFO - root - 2022-02-24 21:23:07.185845: step 189060, total loss = 0.52, batch loss = 0.26 (213.0 examples/sec; 0.038 sec/batch; 0h:06m:32s remains)
INFO - root - 2022-02-24 21:23:07.613555: step 189070, total loss = 0.48, batch loss = 0.23 (341.5 examples/sec; 0.023 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:23:07.975882: step 189080, total loss = 0.56, batch loss = 0.30 (343.3 examples/sec; 0.023 sec/batch; 0h:04m:02s remains)
INFO - root - 2022-02-24 21:23:08.291030: step 189090, total loss = 0.55, batch loss = 0.30 (308.5 examples/sec; 0.026 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:23:08.617580: step 189100, total loss = 0.55, batch loss = 0.30 (320.3 examples/sec; 0.025 sec/batch; 0h:04m:19s remains)
INFO - root - 2022-02-24 21:23:08.992277: step 189110, total loss = 0.63, batch loss = 0.37 (335.2 examples/sec; 0.024 sec/batch; 0h:04m:07s remains)
INFO - root - 2022-02-24 21:23:09.331309: step 189120, total loss = 0.56, batch loss = 0.31 (206.4 examples/sec; 0.039 sec/batch; 0h:06m:42s remains)
INFO - root - 2022-02-24 21:23:09.720524: step 189130, total loss = 0.64, batch loss = 0.38 (337.4 examples/sec; 0.024 sec/batch; 0h:04m:05s remains)
INFO - root - 2022-02-24 21:23:09.993933: step 189140, total loss = 0.54, batch loss = 0.28 (329.4 examples/sec; 0.024 sec/batch; 0h:04m:11s remains)
INFO - root - 2022-02-24 21:23:10.315688: step 189150, total loss = 0.50, batch loss = 0.24 (203.5 examples/sec; 0.039 sec/batch; 0h:06m:46s remains)
INFO - root - 2022-02-24 21:23:10.593215: step 189160, total loss = 0.57, batch loss = 0.31 (319.0 examples/sec; 0.025 sec/batch; 0h:04m:19s remains)
INFO - root - 2022-02-24 21:23:10.933325: step 189170, total loss = 0.55, batch loss = 0.29 (207.7 examples/sec; 0.039 sec/batch; 0h:06m:37s remains)
INFO - root - 2022-02-24 21:23:11.338211: step 189180, total loss = 0.52, batch loss = 0.26 (359.0 examples/sec; 0.022 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:23:11.783882: step 189190, total loss = 0.49, batch loss = 0.23 (167.5 examples/sec; 0.048 sec/batch; 0h:08m:12s remains)
INFO - root - 2022-02-24 21:23:12.134523: step 189200, total loss = 0.50, batch loss = 0.24 (337.7 examples/sec; 0.024 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:23:12.472415: step 189210, total loss = 0.50, batch loss = 0.25 (341.5 examples/sec; 0.023 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:23:12.737522: step 189220, total loss = 0.52, batch loss = 0.26 (332.5 examples/sec; 0.024 sec/batch; 0h:04m:07s remains)
INFO - root - 2022-02-24 21:23:13.075003: step 189230, total loss = 0.49, batch loss = 0.24 (260.7 examples/sec; 0.031 sec/batch; 0h:05m:15s remains)
INFO - root - 2022-02-24 21:23:13.438037: step 189240, total loss = 0.50, batch loss = 0.25 (260.8 examples/sec; 0.031 sec/batch; 0h:05m:14s remains)
INFO - root - 2022-02-24 21:23:13.841965: step 189250, total loss = 0.59, batch loss = 0.34 (332.4 examples/sec; 0.024 sec/batch; 0h:04m:06s remains)
INFO - root - 2022-02-24 21:23:14.155789: step 189260, total loss = 0.62, batch loss = 0.36 (281.2 examples/sec; 0.028 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:23:14.405776: step 189270, total loss = 0.57, batch loss = 0.32 (348.6 examples/sec; 0.023 sec/batch; 0h:03m:54s remains)
INFO - root - 2022-02-24 21:23:14.735118: step 189280, total loss = 0.55, batch loss = 0.29 (250.3 examples/sec; 0.032 sec/batch; 0h:05m:26s remains)
INFO - root - 2022-02-24 21:23:15.086883: step 189290, total loss = 0.53, batch loss = 0.28 (143.5 examples/sec; 0.056 sec/batch; 0h:09m:29s remains)
INFO - root - 2022-02-24 21:23:15.454651: step 189300, total loss = 0.54, batch loss = 0.28 (202.3 examples/sec; 0.040 sec/batch; 0h:06m:43s remains)
INFO - root - 2022-02-24 21:23:15.886742: step 189310, total loss = 0.50, batch loss = 0.24 (267.4 examples/sec; 0.030 sec/batch; 0h:05m:04s remains)
INFO - root - 2022-02-24 21:23:16.384639: step 189320, total loss = 0.56, batch loss = 0.30 (299.8 examples/sec; 0.027 sec/batch; 0h:04m:31s remains)
INFO - root - 2022-02-24 21:23:16.821062: step 189330, total loss = 0.50, batch loss = 0.24 (250.6 examples/sec; 0.032 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:23:17.278947: step 189340, total loss = 0.49, batch loss = 0.24 (213.1 examples/sec; 0.038 sec/batch; 0h:06m:21s remains)
INFO - root - 2022-02-24 21:23:17.688173: step 189350, total loss = 0.54, batch loss = 0.28 (233.7 examples/sec; 0.034 sec/batch; 0h:05m:47s remains)
INFO - root - 2022-02-24 21:23:18.167420: step 189360, total loss = 0.66, batch loss = 0.40 (108.1 examples/sec; 0.074 sec/batch; 0h:12m:30s remains)
INFO - root - 2022-02-24 21:23:18.508107: step 189370, total loss = 0.54, batch loss = 0.28 (295.1 examples/sec; 0.027 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:23:18.929550: step 189380, total loss = 0.43, batch loss = 0.17 (292.9 examples/sec; 0.027 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:23:19.312466: step 189390, total loss = 0.49, batch loss = 0.24 (135.8 examples/sec; 0.059 sec/batch; 0h:09m:55s remains)
INFO - root - 2022-02-24 21:23:19.789779: step 189400, total loss = 0.50, batch loss = 0.25 (85.9 examples/sec; 0.093 sec/batch; 0h:15m:40s remains)
INFO - root - 2022-02-24 21:23:20.170927: step 189410, total loss = 0.61, batch loss = 0.36 (298.4 examples/sec; 0.027 sec/batch; 0h:04m:30s remains)
INFO - root - 2022-02-24 21:23:20.600776: step 189420, total loss = 0.51, batch loss = 0.26 (366.8 examples/sec; 0.022 sec/batch; 0h:03m:39s remains)
INFO - root - 2022-02-24 21:23:21.030678: step 189430, total loss = 0.52, batch loss = 0.26 (198.0 examples/sec; 0.040 sec/batch; 0h:06m:46s remains)
INFO - root - 2022-02-24 21:23:21.403455: step 189440, total loss = 0.54, batch loss = 0.28 (195.3 examples/sec; 0.041 sec/batch; 0h:06m:52s remains)
INFO - root - 2022-02-24 21:23:22.284921: step 189450, total loss = 0.52, batch loss = 0.26 (77.4 examples/sec; 0.103 sec/batch; 0h:17m:18s remains)
INFO - root - 2022-02-24 21:23:22.735743: step 189460, total loss = 0.49, batch loss = 0.24 (182.6 examples/sec; 0.044 sec/batch; 0h:07m:19s remains)
INFO - root - 2022-02-24 21:23:23.045377: step 189470, total loss = 0.61, batch loss = 0.36 (313.1 examples/sec; 0.026 sec/batch; 0h:04m:16s remains)
INFO - root - 2022-02-24 21:23:23.403585: step 189480, total loss = 0.60, batch loss = 0.35 (305.6 examples/sec; 0.026 sec/batch; 0h:04m:22s remains)
INFO - root - 2022-02-24 21:23:23.800280: step 189490, total loss = 0.52, batch loss = 0.26 (298.2 examples/sec; 0.027 sec/batch; 0h:04m:28s remains)
INFO - root - 2022-02-24 21:23:24.229590: step 189500, total loss = 0.55, batch loss = 0.29 (101.6 examples/sec; 0.079 sec/batch; 0h:13m:07s remains)
INFO - root - 2022-02-24 21:23:24.859982: step 189510, total loss = 0.54, batch loss = 0.29 (227.9 examples/sec; 0.035 sec/batch; 0h:05m:50s remains)
INFO - root - 2022-02-24 21:23:25.222924: step 189520, total loss = 0.57, batch loss = 0.32 (153.7 examples/sec; 0.052 sec/batch; 0h:08m:39s remains)
INFO - root - 2022-02-24 21:23:25.524779: step 189530, total loss = 0.61, batch loss = 0.36 (151.3 examples/sec; 0.053 sec/batch; 0h:08m:47s remains)
INFO - root - 2022-02-24 21:23:25.836503: step 189540, total loss = 0.51, batch loss = 0.25 (349.8 examples/sec; 0.023 sec/batch; 0h:03m:47s remains)
INFO - root - 2022-02-24 21:23:26.164147: step 189550, total loss = 0.67, batch loss = 0.42 (337.4 examples/sec; 0.024 sec/batch; 0h:03m:55s remains)
INFO - root - 2022-02-24 21:23:26.510034: step 189560, total loss = 0.49, batch loss = 0.23 (259.9 examples/sec; 0.031 sec/batch; 0h:05m:05s remains)
INFO - root - 2022-02-24 21:23:27.226365: step 189570, total loss = 0.50, batch loss = 0.25 (161.4 examples/sec; 0.050 sec/batch; 0h:08m:12s remains)
INFO - root - 2022-02-24 21:23:27.630569: step 189580, total loss = 0.56, batch loss = 0.30 (354.6 examples/sec; 0.023 sec/batch; 0h:03m:43s remains)
INFO - root - 2022-02-24 21:23:27.928116: step 189590, total loss = 0.62, batch loss = 0.36 (373.3 examples/sec; 0.021 sec/batch; 0h:03m:32s remains)
INFO - root - 2022-02-24 21:23:28.244862: step 189600, total loss = 0.68, batch loss = 0.42 (307.6 examples/sec; 0.026 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:23:28.606322: step 189610, total loss = 0.52, batch loss = 0.27 (311.2 examples/sec; 0.026 sec/batch; 0h:04m:14s remains)
INFO - root - 2022-02-24 21:23:28.918719: step 189620, total loss = 0.66, batch loss = 0.40 (356.8 examples/sec; 0.022 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:23:29.239202: step 189630, total loss = 0.59, batch loss = 0.33 (362.0 examples/sec; 0.022 sec/batch; 0h:03m:38s remains)
INFO - root - 2022-02-24 21:23:29.542483: step 189640, total loss = 0.49, batch loss = 0.24 (180.7 examples/sec; 0.044 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:23:29.839735: step 189650, total loss = 0.52, batch loss = 0.27 (355.7 examples/sec; 0.022 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:23:30.110832: step 189660, total loss = 0.49, batch loss = 0.23 (176.0 examples/sec; 0.045 sec/batch; 0h:07m:27s remains)
INFO - root - 2022-02-24 21:23:30.395571: step 189670, total loss = 0.60, batch loss = 0.34 (176.3 examples/sec; 0.045 sec/batch; 0h:07m:26s remains)
INFO - root - 2022-02-24 21:23:30.760206: step 189680, total loss = 0.55, batch loss = 0.29 (182.7 examples/sec; 0.044 sec/batch; 0h:07m:10s remains)
INFO - root - 2022-02-24 21:23:31.125293: step 189690, total loss = 0.44, batch loss = 0.18 (361.4 examples/sec; 0.022 sec/batch; 0h:03m:37s remains)
INFO - root - 2022-02-24 21:23:31.421563: step 189700, total loss = 0.62, batch loss = 0.37 (357.9 examples/sec; 0.022 sec/batch; 0h:03m:39s remains)
INFO - root - 2022-02-24 21:23:31.870810: step 189710, total loss = 0.79, batch loss = 0.53 (175.5 examples/sec; 0.046 sec/batch; 0h:07m:26s remains)
INFO - root - 2022-02-24 21:23:32.168837: step 189720, total loss = 0.55, batch loss = 0.30 (200.8 examples/sec; 0.040 sec/batch; 0h:06m:29s remains)
INFO - root - 2022-02-24 21:23:32.512671: step 189730, total loss = 0.50, batch loss = 0.24 (109.9 examples/sec; 0.073 sec/batch; 0h:11m:51s remains)
INFO - root - 2022-02-24 21:23:32.926562: step 189740, total loss = 0.54, batch loss = 0.29 (338.5 examples/sec; 0.024 sec/batch; 0h:03m:50s remains)
INFO - root - 2022-02-24 21:23:33.345551: step 189750, total loss = 0.64, batch loss = 0.38 (312.5 examples/sec; 0.026 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:23:33.661266: step 189760, total loss = 0.50, batch loss = 0.24 (230.4 examples/sec; 0.035 sec/batch; 0h:05m:38s remains)
INFO - root - 2022-02-24 21:23:33.942654: step 189770, total loss = 0.50, batch loss = 0.24 (301.3 examples/sec; 0.027 sec/batch; 0h:04m:18s remains)
INFO - root - 2022-02-24 21:23:34.322555: step 189780, total loss = 0.58, batch loss = 0.33 (285.3 examples/sec; 0.028 sec/batch; 0h:04m:32s remains)
INFO - root - 2022-02-24 21:23:34.641265: step 189790, total loss = 0.60, batch loss = 0.34 (191.6 examples/sec; 0.042 sec/batch; 0h:06m:45s remains)
INFO - root - 2022-02-24 21:23:35.056475: step 189800, total loss = 0.56, batch loss = 0.30 (301.4 examples/sec; 0.027 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:23:35.447664: step 189810, total loss = 0.45, batch loss = 0.19 (151.3 examples/sec; 0.053 sec/batch; 0h:08m:32s remains)
INFO - root - 2022-02-24 21:23:35.777943: step 189820, total loss = 0.59, batch loss = 0.34 (311.0 examples/sec; 0.026 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:23:36.064984: step 189830, total loss = 0.55, batch loss = 0.29 (348.7 examples/sec; 0.023 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:23:36.362442: step 189840, total loss = 0.55, batch loss = 0.29 (355.1 examples/sec; 0.023 sec/batch; 0h:03m:37s remains)
INFO - root - 2022-02-24 21:23:36.837200: step 189850, total loss = 0.51, batch loss = 0.25 (343.6 examples/sec; 0.023 sec/batch; 0h:03m:44s remains)
INFO - root - 2022-02-24 21:23:37.188711: step 189860, total loss = 0.54, batch loss = 0.29 (404.0 examples/sec; 0.020 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:23:37.519038: step 189870, total loss = 0.51, batch loss = 0.26 (200.5 examples/sec; 0.040 sec/batch; 0h:06m:24s remains)
INFO - root - 2022-02-24 21:23:37.857733: step 189880, total loss = 0.67, batch loss = 0.41 (193.3 examples/sec; 0.041 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:23:38.124297: step 189890, total loss = 0.51, batch loss = 0.25 (363.4 examples/sec; 0.022 sec/batch; 0h:03m:31s remains)
INFO - root - 2022-02-24 21:23:38.412435: step 189900, total loss = 0.57, batch loss = 0.31 (239.8 examples/sec; 0.033 sec/batch; 0h:05m:20s remains)
INFO - root - 2022-02-24 21:23:38.740300: step 189910, total loss = 0.62, batch loss = 0.36 (366.2 examples/sec; 0.022 sec/batch; 0h:03m:29s remains)
INFO - root - 2022-02-24 21:23:39.053984: step 189920, total loss = 0.54, batch loss = 0.29 (344.7 examples/sec; 0.023 sec/batch; 0h:03m:42s remains)
INFO - root - 2022-02-24 21:23:39.480343: step 189930, total loss = 0.57, batch loss = 0.32 (146.0 examples/sec; 0.055 sec/batch; 0h:08m:44s remains)
INFO - root - 2022-02-24 21:23:39.882100: step 189940, total loss = 0.62, batch loss = 0.36 (230.2 examples/sec; 0.035 sec/batch; 0h:05m:32s remains)
INFO - root - 2022-02-24 21:23:40.231826: step 189950, total loss = 0.65, batch loss = 0.39 (325.7 examples/sec; 0.025 sec/batch; 0h:03m:54s remains)
INFO - root - 2022-02-24 21:23:40.570683: step 189960, total loss = 0.52, batch loss = 0.26 (187.1 examples/sec; 0.043 sec/batch; 0h:06m:47s remains)
INFO - root - 2022-02-24 21:23:41.015441: step 189970, total loss = 0.53, batch loss = 0.27 (118.2 examples/sec; 0.068 sec/batch; 0h:10m:44s remains)
INFO - root - 2022-02-24 21:23:41.379631: step 189980, total loss = 0.49, batch loss = 0.23 (178.6 examples/sec; 0.045 sec/batch; 0h:07m:06s remains)
INFO - root - 2022-02-24 21:23:41.711699: step 189990, total loss = 0.47, batch loss = 0.21 (234.3 examples/sec; 0.034 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:23:42.053263: step 190000, total loss = 0.67, batch loss = 0.41 (160.9 examples/sec; 0.050 sec/batch; 0h:07m:52s remains)
INFO - root - 2022-02-24 21:23:42.472847: step 190010, total loss = 0.48, batch loss = 0.22 (255.6 examples/sec; 0.031 sec/batch; 0h:04m:56s remains)
INFO - root - 2022-02-24 21:23:42.789681: step 190020, total loss = 0.48, batch loss = 0.22 (118.0 examples/sec; 0.068 sec/batch; 0h:10m:42s remains)
INFO - root - 2022-02-24 21:23:43.105867: step 190030, total loss = 0.61, batch loss = 0.36 (355.5 examples/sec; 0.023 sec/batch; 0h:03m:33s remains)
INFO - root - 2022-02-24 21:23:43.405024: step 190040, total loss = 0.63, batch loss = 0.38 (366.8 examples/sec; 0.022 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:23:43.699926: step 190050, total loss = 0.52, batch loss = 0.27 (182.1 examples/sec; 0.044 sec/batch; 0h:06m:55s remains)
INFO - root - 2022-02-24 21:23:44.014616: step 190060, total loss = 0.54, batch loss = 0.29 (326.7 examples/sec; 0.024 sec/batch; 0h:03m:51s remains)
INFO - root - 2022-02-24 21:23:44.298756: step 190070, total loss = 0.54, batch loss = 0.28 (327.6 examples/sec; 0.024 sec/batch; 0h:03m:50s remains)
INFO - root - 2022-02-24 21:23:44.584284: step 190080, total loss = 0.49, batch loss = 0.24 (310.3 examples/sec; 0.026 sec/batch; 0h:04m:02s remains)
INFO - root - 2022-02-24 21:23:44.883705: step 190090, total loss = 0.50, batch loss = 0.24 (326.5 examples/sec; 0.025 sec/batch; 0h:03m:50s remains)
INFO - root - 2022-02-24 21:23:45.304866: step 190100, total loss = 0.54, batch loss = 0.28 (169.1 examples/sec; 0.047 sec/batch; 0h:07m:24s remains)
INFO - root - 2022-02-24 21:23:45.623227: step 190110, total loss = 0.46, batch loss = 0.21 (283.1 examples/sec; 0.028 sec/batch; 0h:04m:25s remains)
INFO - root - 2022-02-24 21:23:45.954859: step 190120, total loss = 0.53, batch loss = 0.28 (346.6 examples/sec; 0.023 sec/batch; 0h:03m:36s remains)
INFO - root - 2022-02-24 21:23:46.268560: step 190130, total loss = 0.47, batch loss = 0.21 (160.5 examples/sec; 0.050 sec/batch; 0h:07m:47s remains)
INFO - root - 2022-02-24 21:23:46.567850: step 190140, total loss = 0.47, batch loss = 0.22 (160.7 examples/sec; 0.050 sec/batch; 0h:07m:45s remains)
INFO - root - 2022-02-24 21:23:46.886132: step 190150, total loss = 0.57, batch loss = 0.32 (217.1 examples/sec; 0.037 sec/batch; 0h:05m:44s remains)
INFO - root - 2022-02-24 21:23:47.327660: step 190160, total loss = 0.63, batch loss = 0.37 (220.1 examples/sec; 0.036 sec/batch; 0h:05m:39s remains)
INFO - root - 2022-02-24 21:23:47.717794: step 190170, total loss = 0.47, batch loss = 0.21 (187.8 examples/sec; 0.043 sec/batch; 0h:06m:37s remains)
INFO - root - 2022-02-24 21:23:47.979891: step 190180, total loss = 0.57, batch loss = 0.31 (361.0 examples/sec; 0.022 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:23:48.345946: step 190190, total loss = 0.53, batch loss = 0.28 (281.1 examples/sec; 0.028 sec/batch; 0h:04m:24s remains)
INFO - root - 2022-02-24 21:23:48.644044: step 190200, total loss = 0.63, batch loss = 0.38 (126.4 examples/sec; 0.063 sec/batch; 0h:09m:48s remains)
INFO - root - 2022-02-24 21:23:49.086867: step 190210, total loss = 0.60, batch loss = 0.34 (258.2 examples/sec; 0.031 sec/batch; 0h:04m:47s remains)
INFO - root - 2022-02-24 21:23:49.546686: step 190220, total loss = 0.55, batch loss = 0.30 (143.7 examples/sec; 0.056 sec/batch; 0h:08m:36s remains)
INFO - root - 2022-02-24 21:23:49.879343: step 190230, total loss = 0.57, batch loss = 0.32 (330.7 examples/sec; 0.024 sec/batch; 0h:03m:44s remains)
INFO - root - 2022-02-24 21:23:50.130956: step 190240, total loss = 0.83, batch loss = 0.57 (328.4 examples/sec; 0.024 sec/batch; 0h:03m:45s remains)
INFO - root - 2022-02-24 21:23:50.420272: step 190250, total loss = 0.58, batch loss = 0.32 (205.9 examples/sec; 0.039 sec/batch; 0h:05m:59s remains)
INFO - root - 2022-02-24 21:23:50.701405: step 190260, total loss = 0.54, batch loss = 0.28 (148.5 examples/sec; 0.054 sec/batch; 0h:08m:17s remains)
INFO - root - 2022-02-24 21:23:51.013119: step 190270, total loss = 0.52, batch loss = 0.27 (215.4 examples/sec; 0.037 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:23:51.434385: step 190280, total loss = 0.46, batch loss = 0.20 (138.5 examples/sec; 0.058 sec/batch; 0h:08m:52s remains)
INFO - root - 2022-02-24 21:23:51.842280: step 190290, total loss = 0.50, batch loss = 0.24 (316.4 examples/sec; 0.025 sec/batch; 0h:03m:52s remains)
INFO - root - 2022-02-24 21:23:52.092678: step 190300, total loss = 0.56, batch loss = 0.30 (359.6 examples/sec; 0.022 sec/batch; 0h:03m:24s remains)
INFO - root - 2022-02-24 21:23:52.543375: step 190310, total loss = 0.69, batch loss = 0.44 (342.3 examples/sec; 0.023 sec/batch; 0h:03m:34s remains)
INFO - root - 2022-02-24 21:23:52.895267: step 190320, total loss = 0.52, batch loss = 0.27 (299.3 examples/sec; 0.027 sec/batch; 0h:04m:05s remains)
INFO - root - 2022-02-24 21:23:53.254762: step 190330, total loss = 0.59, batch loss = 0.33 (162.4 examples/sec; 0.049 sec/batch; 0h:07m:31s remains)
INFO - root - 2022-02-24 21:23:53.686473: step 190340, total loss = 0.50, batch loss = 0.24 (181.8 examples/sec; 0.044 sec/batch; 0h:06m:43s remains)
INFO - root - 2022-02-24 21:23:54.115097: step 190350, total loss = 0.55, batch loss = 0.29 (171.5 examples/sec; 0.047 sec/batch; 0h:07m:06s remains)
INFO - root - 2022-02-24 21:23:54.386181: step 190360, total loss = 0.59, batch loss = 0.33 (319.1 examples/sec; 0.025 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:23:54.708615: step 190370, total loss = 0.46, batch loss = 0.21 (318.8 examples/sec; 0.025 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:23:55.023577: step 190380, total loss = 0.47, batch loss = 0.22 (142.6 examples/sec; 0.056 sec/batch; 0h:08m:31s remains)
INFO - root - 2022-02-24 21:23:55.388424: step 190390, total loss = 0.62, batch loss = 0.36 (316.7 examples/sec; 0.025 sec/batch; 0h:03m:50s remains)
INFO - root - 2022-02-24 21:23:55.861863: step 190400, total loss = 0.48, batch loss = 0.22 (132.4 examples/sec; 0.060 sec/batch; 0h:09m:09s remains)
INFO - root - 2022-02-24 21:23:56.236812: step 190410, total loss = 0.61, batch loss = 0.36 (254.5 examples/sec; 0.031 sec/batch; 0h:04m:45s remains)
INFO - root - 2022-02-24 21:23:56.713506: step 190420, total loss = 0.58, batch loss = 0.33 (297.8 examples/sec; 0.027 sec/batch; 0h:04m:03s remains)
INFO - root - 2022-02-24 21:23:57.134968: step 190430, total loss = 0.56, batch loss = 0.30 (187.2 examples/sec; 0.043 sec/batch; 0h:06m:27s remains)
INFO - root - 2022-02-24 21:23:57.858727: step 190440, total loss = 0.48, batch loss = 0.22 (173.1 examples/sec; 0.046 sec/batch; 0h:06m:58s remains)
INFO - root - 2022-02-24 21:23:58.278768: step 190450, total loss = 0.51, batch loss = 0.25 (180.4 examples/sec; 0.044 sec/batch; 0h:06m:41s remains)
INFO - root - 2022-02-24 21:23:58.625957: step 190460, total loss = 0.47, batch loss = 0.22 (174.8 examples/sec; 0.046 sec/batch; 0h:06m:53s remains)
INFO - root - 2022-02-24 21:23:58.933635: step 190470, total loss = 0.62, batch loss = 0.37 (362.7 examples/sec; 0.022 sec/batch; 0h:03m:19s remains)
INFO - root - 2022-02-24 21:23:59.408348: step 190480, total loss = 0.52, batch loss = 0.27 (86.3 examples/sec; 0.093 sec/batch; 0h:13m:56s remains)
INFO - root - 2022-02-24 21:23:59.823896: step 190490, total loss = 0.44, batch loss = 0.19 (198.7 examples/sec; 0.040 sec/batch; 0h:06m:02s remains)
INFO - root - 2022-02-24 21:24:00.315513: step 190500, total loss = 0.58, batch loss = 0.32 (322.2 examples/sec; 0.025 sec/batch; 0h:03m:43s remains)
INFO - root - 2022-02-24 21:24:00.782848: step 190510, total loss = 0.52, batch loss = 0.26 (331.8 examples/sec; 0.024 sec/batch; 0h:03m:36s remains)
INFO - root - 2022-02-24 21:24:01.121943: step 190520, total loss = 0.43, batch loss = 0.18 (246.7 examples/sec; 0.032 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:24:01.564024: step 190530, total loss = 0.57, batch loss = 0.32 (340.4 examples/sec; 0.023 sec/batch; 0h:03m:30s remains)
INFO - root - 2022-02-24 21:24:01.965152: step 190540, total loss = 0.54, batch loss = 0.29 (214.2 examples/sec; 0.037 sec/batch; 0h:05m:34s remains)
INFO - root - 2022-02-24 21:24:02.268444: step 190550, total loss = 0.59, batch loss = 0.33 (316.3 examples/sec; 0.025 sec/batch; 0h:03m:46s remains)
INFO - root - 2022-02-24 21:24:02.568412: step 190560, total loss = 0.55, batch loss = 0.29 (208.4 examples/sec; 0.038 sec/batch; 0h:05m:43s remains)
INFO - root - 2022-02-24 21:24:03.272259: step 190570, total loss = 0.46, batch loss = 0.20 (190.7 examples/sec; 0.042 sec/batch; 0h:06m:14s remains)
INFO - root - 2022-02-24 21:24:03.623474: step 190580, total loss = 0.45, batch loss = 0.19 (115.5 examples/sec; 0.069 sec/batch; 0h:10m:17s remains)
INFO - root - 2022-02-24 21:24:04.015590: step 190590, total loss = 0.53, batch loss = 0.27 (119.6 examples/sec; 0.067 sec/batch; 0h:09m:55s remains)
INFO - root - 2022-02-24 21:24:04.376802: step 190600, total loss = 0.63, batch loss = 0.38 (309.9 examples/sec; 0.026 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:24:04.732373: step 190610, total loss = 0.52, batch loss = 0.27 (349.6 examples/sec; 0.023 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:24:05.024335: step 190620, total loss = 0.71, batch loss = 0.45 (290.2 examples/sec; 0.028 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:24:05.280791: step 190630, total loss = 0.59, batch loss = 0.33 (248.5 examples/sec; 0.032 sec/batch; 0h:04m:45s remains)
INFO - root - 2022-02-24 21:24:05.611824: step 190640, total loss = 0.45, batch loss = 0.20 (300.1 examples/sec; 0.027 sec/batch; 0h:03m:56s remains)
INFO - root - 2022-02-24 21:24:05.997344: step 190650, total loss = 0.50, batch loss = 0.24 (315.0 examples/sec; 0.025 sec/batch; 0h:03m:44s remains)
INFO - root - 2022-02-24 21:24:06.366394: step 190660, total loss = 0.50, batch loss = 0.25 (333.9 examples/sec; 0.024 sec/batch; 0h:03m:31s remains)
INFO - root - 2022-02-24 21:24:06.691904: step 190670, total loss = 0.49, batch loss = 0.23 (324.6 examples/sec; 0.025 sec/batch; 0h:03m:37s remains)
INFO - root - 2022-02-24 21:24:07.059017: step 190680, total loss = 0.50, batch loss = 0.25 (130.3 examples/sec; 0.061 sec/batch; 0h:09m:01s remains)
INFO - root - 2022-02-24 21:24:07.327963: step 190690, total loss = 0.56, batch loss = 0.30 (358.1 examples/sec; 0.022 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:24:07.631799: step 190700, total loss = 0.59, batch loss = 0.33 (151.0 examples/sec; 0.053 sec/batch; 0h:07m:46s remains)
INFO - root - 2022-02-24 21:24:08.120344: step 190710, total loss = 0.58, batch loss = 0.33 (221.1 examples/sec; 0.036 sec/batch; 0h:05m:17s remains)
INFO - root - 2022-02-24 21:24:08.430931: step 190720, total loss = 0.57, batch loss = 0.31 (156.6 examples/sec; 0.051 sec/batch; 0h:07m:28s remains)
INFO - root - 2022-02-24 21:24:08.735036: step 190730, total loss = 0.54, batch loss = 0.29 (196.5 examples/sec; 0.041 sec/batch; 0h:05m:56s remains)
INFO - root - 2022-02-24 21:24:09.042780: step 190740, total loss = 0.48, batch loss = 0.22 (250.3 examples/sec; 0.032 sec/batch; 0h:04m:39s remains)
INFO - root - 2022-02-24 21:24:09.321891: step 190750, total loss = 0.56, batch loss = 0.31 (344.5 examples/sec; 0.023 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:24:09.724452: step 190760, total loss = 0.60, batch loss = 0.35 (160.7 examples/sec; 0.050 sec/batch; 0h:07m:15s remains)
INFO - root - 2022-02-24 21:24:10.129418: step 190770, total loss = 0.59, batch loss = 0.33 (223.9 examples/sec; 0.036 sec/batch; 0h:05m:11s remains)
INFO - root - 2022-02-24 21:24:10.452069: step 190780, total loss = 0.51, batch loss = 0.25 (256.6 examples/sec; 0.031 sec/batch; 0h:04m:31s remains)
INFO - root - 2022-02-24 21:24:10.751832: step 190790, total loss = 0.46, batch loss = 0.20 (181.8 examples/sec; 0.044 sec/batch; 0h:06m:23s remains)
INFO - root - 2022-02-24 21:24:11.010561: step 190800, total loss = 0.49, batch loss = 0.24 (326.9 examples/sec; 0.024 sec/batch; 0h:03m:32s remains)
INFO - root - 2022-02-24 21:24:11.371338: step 190810, total loss = 0.49, batch loss = 0.23 (313.1 examples/sec; 0.026 sec/batch; 0h:03m:42s remains)
INFO - root - 2022-02-24 21:24:11.683510: step 190820, total loss = 0.57, batch loss = 0.31 (294.9 examples/sec; 0.027 sec/batch; 0h:03m:55s remains)
INFO - root - 2022-02-24 21:24:12.155023: step 190830, total loss = 0.61, batch loss = 0.35 (346.0 examples/sec; 0.023 sec/batch; 0h:03m:20s remains)
INFO - root - 2022-02-24 21:24:12.479463: step 190840, total loss = 0.48, batch loss = 0.22 (315.6 examples/sec; 0.025 sec/batch; 0h:03m:39s remains)
INFO - root - 2022-02-24 21:24:12.755116: step 190850, total loss = 0.60, batch loss = 0.35 (136.9 examples/sec; 0.058 sec/batch; 0h:08m:25s remains)
INFO - root - 2022-02-24 21:24:13.124795: step 190860, total loss = 0.59, batch loss = 0.34 (199.9 examples/sec; 0.040 sec/batch; 0h:05m:45s remains)
INFO - root - 2022-02-24 21:24:13.401143: step 190870, total loss = 0.52, batch loss = 0.26 (216.7 examples/sec; 0.037 sec/batch; 0h:05m:18s remains)
INFO - root - 2022-02-24 21:24:13.813917: step 190880, total loss = 0.59, batch loss = 0.33 (242.2 examples/sec; 0.033 sec/batch; 0h:04m:44s remains)
INFO - root - 2022-02-24 21:24:14.203881: step 190890, total loss = 0.52, batch loss = 0.27 (224.0 examples/sec; 0.036 sec/batch; 0h:05m:07s remains)
INFO - root - 2022-02-24 21:24:14.509789: step 190900, total loss = 0.48, batch loss = 0.22 (351.4 examples/sec; 0.023 sec/batch; 0h:03m:15s remains)
INFO - root - 2022-02-24 21:24:14.886267: step 190910, total loss = 0.52, batch loss = 0.26 (334.8 examples/sec; 0.024 sec/batch; 0h:03m:25s remains)
INFO - root - 2022-02-24 21:24:15.150171: step 190920, total loss = 0.73, batch loss = 0.47 (331.7 examples/sec; 0.024 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:24:15.522709: step 190930, total loss = 0.56, batch loss = 0.31 (281.3 examples/sec; 0.028 sec/batch; 0h:04m:03s remains)
INFO - root - 2022-02-24 21:24:15.902881: step 190940, total loss = 0.62, batch loss = 0.36 (274.9 examples/sec; 0.029 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:24:16.201300: step 190950, total loss = 0.54, batch loss = 0.28 (303.7 examples/sec; 0.026 sec/batch; 0h:03m:45s remains)
INFO - root - 2022-02-24 21:24:16.512368: step 190960, total loss = 0.51, batch loss = 0.25 (146.8 examples/sec; 0.055 sec/batch; 0h:07m:45s remains)
INFO - root - 2022-02-24 21:24:16.840681: step 190970, total loss = 0.49, batch loss = 0.23 (244.2 examples/sec; 0.033 sec/batch; 0h:04m:39s remains)
INFO - root - 2022-02-24 21:24:17.191285: step 190980, total loss = 0.59, batch loss = 0.34 (229.4 examples/sec; 0.035 sec/batch; 0h:04m:57s remains)
INFO - root - 2022-02-24 21:24:17.619621: step 190990, total loss = 0.55, batch loss = 0.30 (177.0 examples/sec; 0.045 sec/batch; 0h:06m:24s remains)
INFO - root - 2022-02-24 21:24:18.008666: step 191000, total loss = 0.49, batch loss = 0.24 (310.3 examples/sec; 0.026 sec/batch; 0h:03m:39s remains)
INFO - root - 2022-02-24 21:24:18.395527: step 191010, total loss = 0.48, batch loss = 0.23 (225.1 examples/sec; 0.036 sec/batch; 0h:05m:01s remains)
INFO - root - 2022-02-24 21:24:18.703363: step 191020, total loss = 0.49, batch loss = 0.24 (225.5 examples/sec; 0.035 sec/batch; 0h:05m:00s remains)
INFO - root - 2022-02-24 21:24:19.124213: step 191030, total loss = 0.53, batch loss = 0.28 (104.0 examples/sec; 0.077 sec/batch; 0h:10m:51s remains)
INFO - root - 2022-02-24 21:24:19.602514: step 191040, total loss = 0.59, batch loss = 0.33 (199.9 examples/sec; 0.040 sec/batch; 0h:05m:38s remains)
INFO - root - 2022-02-24 21:24:19.912224: step 191050, total loss = 0.65, batch loss = 0.39 (325.2 examples/sec; 0.025 sec/batch; 0h:03m:27s remains)
INFO - root - 2022-02-24 21:24:20.175998: step 191060, total loss = 0.51, batch loss = 0.26 (331.1 examples/sec; 0.024 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:24:20.452174: step 191070, total loss = 0.59, batch loss = 0.33 (333.9 examples/sec; 0.024 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:24:20.784525: step 191080, total loss = 0.49, batch loss = 0.23 (120.8 examples/sec; 0.066 sec/batch; 0h:09m:17s remains)
INFO - root - 2022-02-24 21:24:21.152011: step 191090, total loss = 0.49, batch loss = 0.24 (298.3 examples/sec; 0.027 sec/batch; 0h:03m:45s remains)
INFO - root - 2022-02-24 21:24:21.621737: step 191100, total loss = 0.54, batch loss = 0.29 (152.7 examples/sec; 0.052 sec/batch; 0h:07m:20s remains)
INFO - root - 2022-02-24 21:24:22.024197: step 191110, total loss = 0.63, batch loss = 0.37 (320.9 examples/sec; 0.025 sec/batch; 0h:03m:29s remains)
INFO - root - 2022-02-24 21:24:22.326642: step 191120, total loss = 0.48, batch loss = 0.23 (356.9 examples/sec; 0.022 sec/batch; 0h:03m:07s remains)
INFO - root - 2022-02-24 21:24:22.624058: step 191130, total loss = 0.67, batch loss = 0.41 (269.1 examples/sec; 0.030 sec/batch; 0h:04m:08s remains)
INFO - root - 2022-02-24 21:24:22.906631: step 191140, total loss = 0.57, batch loss = 0.31 (342.4 examples/sec; 0.023 sec/batch; 0h:03m:15s remains)
INFO - root - 2022-02-24 21:24:23.354941: step 191150, total loss = 0.55, batch loss = 0.30 (174.4 examples/sec; 0.046 sec/batch; 0h:06m:22s remains)
INFO - root - 2022-02-24 21:24:23.796793: step 191160, total loss = 0.54, batch loss = 0.29 (163.4 examples/sec; 0.049 sec/batch; 0h:06m:48s remains)
INFO - root - 2022-02-24 21:24:24.108733: step 191170, total loss = 0.66, batch loss = 0.40 (265.2 examples/sec; 0.030 sec/batch; 0h:04m:11s remains)
INFO - root - 2022-02-24 21:24:24.482421: step 191180, total loss = 0.50, batch loss = 0.25 (240.0 examples/sec; 0.033 sec/batch; 0h:04m:37s remains)
INFO - root - 2022-02-24 21:24:24.815652: step 191190, total loss = 0.59, batch loss = 0.33 (238.0 examples/sec; 0.034 sec/batch; 0h:04m:39s remains)
INFO - root - 2022-02-24 21:24:25.214563: step 191200, total loss = 0.52, batch loss = 0.26 (257.2 examples/sec; 0.031 sec/batch; 0h:04m:18s remains)
INFO - root - 2022-02-24 21:24:25.639837: step 191210, total loss = 0.78, batch loss = 0.52 (185.1 examples/sec; 0.043 sec/batch; 0h:05m:58s remains)
INFO - root - 2022-02-24 21:24:26.077103: step 191220, total loss = 0.45, batch loss = 0.19 (359.2 examples/sec; 0.022 sec/batch; 0h:03m:04s remains)
INFO - root - 2022-02-24 21:24:26.434850: step 191230, total loss = 0.50, batch loss = 0.25 (254.2 examples/sec; 0.031 sec/batch; 0h:04m:20s remains)
INFO - root - 2022-02-24 21:24:26.691155: step 191240, total loss = 0.56, batch loss = 0.30 (337.0 examples/sec; 0.024 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:24:26.939892: step 191250, total loss = 0.45, batch loss = 0.19 (319.6 examples/sec; 0.025 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:24:27.260727: step 191260, total loss = 0.60, batch loss = 0.34 (130.0 examples/sec; 0.062 sec/batch; 0h:08m:27s remains)
INFO - root - 2022-02-24 21:24:27.582264: step 191270, total loss = 0.56, batch loss = 0.30 (341.5 examples/sec; 0.023 sec/batch; 0h:03m:12s remains)
INFO - root - 2022-02-24 21:24:27.964611: step 191280, total loss = 0.60, batch loss = 0.34 (198.3 examples/sec; 0.040 sec/batch; 0h:05m:31s remains)
INFO - root - 2022-02-24 21:24:28.283931: step 191290, total loss = 0.54, batch loss = 0.28 (324.7 examples/sec; 0.025 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:24:28.592157: step 191300, total loss = 0.57, batch loss = 0.32 (332.8 examples/sec; 0.024 sec/batch; 0h:03m:17s remains)
INFO - root - 2022-02-24 21:24:28.975060: step 191310, total loss = 0.57, batch loss = 0.32 (136.7 examples/sec; 0.059 sec/batch; 0h:07m:59s remains)
INFO - root - 2022-02-24 21:24:29.254615: step 191320, total loss = 0.60, batch loss = 0.34 (318.3 examples/sec; 0.025 sec/batch; 0h:03m:25s remains)
INFO - root - 2022-02-24 21:24:29.594897: step 191330, total loss = 0.49, batch loss = 0.24 (201.5 examples/sec; 0.040 sec/batch; 0h:05m:24s remains)
INFO - root - 2022-02-24 21:24:30.001951: step 191340, total loss = 0.56, batch loss = 0.30 (195.9 examples/sec; 0.041 sec/batch; 0h:05m:33s remains)
INFO - root - 2022-02-24 21:24:30.348907: step 191350, total loss = 0.56, batch loss = 0.31 (137.2 examples/sec; 0.058 sec/batch; 0h:07m:55s remains)
INFO - root - 2022-02-24 21:24:30.618063: step 191360, total loss = 0.46, batch loss = 0.21 (355.0 examples/sec; 0.023 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:24:30.898847: step 191370, total loss = 0.56, batch loss = 0.31 (340.9 examples/sec; 0.023 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:24:31.206413: step 191380, total loss = 0.58, batch loss = 0.32 (241.1 examples/sec; 0.033 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:24:31.546175: step 191390, total loss = 0.47, batch loss = 0.22 (342.9 examples/sec; 0.023 sec/batch; 0h:03m:09s remains)
INFO - root - 2022-02-24 21:24:32.146674: step 191400, total loss = 0.70, batch loss = 0.44 (302.8 examples/sec; 0.026 sec/batch; 0h:03m:34s remains)
INFO - root - 2022-02-24 21:24:32.879111: step 191410, total loss = 0.57, batch loss = 0.31 (271.2 examples/sec; 0.029 sec/batch; 0h:03m:58s remains)
INFO - root - 2022-02-24 21:24:33.288701: step 191420, total loss = 0.61, batch loss = 0.35 (156.9 examples/sec; 0.051 sec/batch; 0h:06m:52s remains)
INFO - root - 2022-02-24 21:24:33.638628: step 191430, total loss = 0.52, batch loss = 0.27 (208.4 examples/sec; 0.038 sec/batch; 0h:05m:09s remains)
INFO - root - 2022-02-24 21:24:34.008883: step 191440, total loss = 0.57, batch loss = 0.32 (149.7 examples/sec; 0.053 sec/batch; 0h:07m:10s remains)
INFO - root - 2022-02-24 21:24:34.424438: step 191450, total loss = 0.60, batch loss = 0.34 (163.0 examples/sec; 0.049 sec/batch; 0h:06m:35s remains)
INFO - root - 2022-02-24 21:24:34.898102: step 191460, total loss = 0.52, batch loss = 0.26 (127.3 examples/sec; 0.063 sec/batch; 0h:08m:25s remains)
INFO - root - 2022-02-24 21:24:35.379633: step 191470, total loss = 0.47, batch loss = 0.21 (345.2 examples/sec; 0.023 sec/batch; 0h:03m:06s remains)
INFO - root - 2022-02-24 21:24:35.890482: step 191480, total loss = 0.49, batch loss = 0.24 (89.2 examples/sec; 0.090 sec/batch; 0h:11m:58s remains)
INFO - root - 2022-02-24 21:24:36.401579: step 191490, total loss = 0.56, batch loss = 0.30 (118.0 examples/sec; 0.068 sec/batch; 0h:09m:03s remains)
INFO - root - 2022-02-24 21:24:37.366259: step 191500, total loss = 0.53, batch loss = 0.27 (218.7 examples/sec; 0.037 sec/batch; 0h:04m:52s remains)
INFO - root - 2022-02-24 21:24:37.729091: step 191510, total loss = 0.53, batch loss = 0.27 (319.3 examples/sec; 0.025 sec/batch; 0h:03m:20s remains)
INFO - root - 2022-02-24 21:24:38.028929: step 191520, total loss = 0.57, batch loss = 0.32 (335.6 examples/sec; 0.024 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:24:38.307320: step 191530, total loss = 0.46, batch loss = 0.20 (269.7 examples/sec; 0.030 sec/batch; 0h:03m:56s remains)
INFO - root - 2022-02-24 21:24:38.640615: step 191540, total loss = 0.48, batch loss = 0.22 (168.9 examples/sec; 0.047 sec/batch; 0h:06m:17s remains)
INFO - root - 2022-02-24 21:24:39.027505: step 191550, total loss = 0.64, batch loss = 0.38 (318.2 examples/sec; 0.025 sec/batch; 0h:03m:19s remains)
INFO - root - 2022-02-24 21:24:39.465105: step 191560, total loss = 0.47, batch loss = 0.22 (323.1 examples/sec; 0.025 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:24:39.770410: step 191570, total loss = 0.51, batch loss = 0.25 (291.6 examples/sec; 0.027 sec/batch; 0h:03m:37s remains)
INFO - root - 2022-02-24 21:24:40.071547: step 191580, total loss = 0.49, batch loss = 0.24 (216.3 examples/sec; 0.037 sec/batch; 0h:04m:52s remains)
INFO - root - 2022-02-24 21:24:40.371245: step 191590, total loss = 0.47, batch loss = 0.21 (230.9 examples/sec; 0.035 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:24:40.664871: step 191600, total loss = 0.60, batch loss = 0.35 (231.4 examples/sec; 0.035 sec/batch; 0h:04m:33s remains)
INFO - root - 2022-02-24 21:24:41.198574: step 191610, total loss = 0.51, batch loss = 0.25 (177.6 examples/sec; 0.045 sec/batch; 0h:05m:55s remains)
INFO - root - 2022-02-24 21:24:41.577226: step 191620, total loss = 0.59, batch loss = 0.34 (326.7 examples/sec; 0.024 sec/batch; 0h:03m:12s remains)
INFO - root - 2022-02-24 21:24:41.917958: step 191630, total loss = 0.57, batch loss = 0.31 (368.9 examples/sec; 0.022 sec/batch; 0h:02m:50s remains)
INFO - root - 2022-02-24 21:24:42.176978: step 191640, total loss = 0.66, batch loss = 0.40 (303.1 examples/sec; 0.026 sec/batch; 0h:03m:27s remains)
INFO - root - 2022-02-24 21:24:42.457427: step 191650, total loss = 0.54, batch loss = 0.28 (319.0 examples/sec; 0.025 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:24:42.812670: step 191660, total loss = 0.54, batch loss = 0.29 (343.4 examples/sec; 0.023 sec/batch; 0h:03m:02s remains)
INFO - root - 2022-02-24 21:24:43.296262: step 191670, total loss = 0.54, batch loss = 0.28 (193.8 examples/sec; 0.041 sec/batch; 0h:05m:23s remains)
INFO - root - 2022-02-24 21:24:43.577408: step 191680, total loss = 0.61, batch loss = 0.35 (364.8 examples/sec; 0.022 sec/batch; 0h:02m:51s remains)
INFO - root - 2022-02-24 21:24:43.865358: step 191690, total loss = 0.51, batch loss = 0.25 (340.6 examples/sec; 0.023 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:24:44.182194: step 191700, total loss = 0.47, batch loss = 0.22 (314.6 examples/sec; 0.025 sec/batch; 0h:03m:18s remains)
INFO - root - 2022-02-24 21:24:44.547210: step 191710, total loss = 0.64, batch loss = 0.38 (165.9 examples/sec; 0.048 sec/batch; 0h:06m:15s remains)
INFO - root - 2022-02-24 21:24:44.940512: step 191720, total loss = 0.53, batch loss = 0.27 (193.9 examples/sec; 0.041 sec/batch; 0h:05m:21s remains)
INFO - root - 2022-02-24 21:24:45.344283: step 191730, total loss = 0.49, batch loss = 0.23 (200.4 examples/sec; 0.040 sec/batch; 0h:05m:10s remains)
INFO - root - 2022-02-24 21:24:45.753554: step 191740, total loss = 0.70, batch loss = 0.45 (177.6 examples/sec; 0.045 sec/batch; 0h:05m:49s remains)
INFO - root - 2022-02-24 21:24:46.078090: step 191750, total loss = 0.59, batch loss = 0.33 (308.1 examples/sec; 0.026 sec/batch; 0h:03m:21s remains)
INFO - root - 2022-02-24 21:24:46.327547: step 191760, total loss = 0.45, batch loss = 0.19 (223.1 examples/sec; 0.036 sec/batch; 0h:04m:37s remains)
INFO - root - 2022-02-24 21:24:46.703632: step 191770, total loss = 0.57, batch loss = 0.31 (180.4 examples/sec; 0.044 sec/batch; 0h:05m:42s remains)
INFO - root - 2022-02-24 21:24:47.099776: step 191780, total loss = 0.52, batch loss = 0.27 (352.9 examples/sec; 0.023 sec/batch; 0h:02m:54s remains)
INFO - root - 2022-02-24 21:24:47.547758: step 191790, total loss = 0.52, batch loss = 0.27 (141.7 examples/sec; 0.056 sec/batch; 0h:07m:15s remains)
INFO - root - 2022-02-24 21:24:47.879844: step 191800, total loss = 0.62, batch loss = 0.36 (167.7 examples/sec; 0.048 sec/batch; 0h:06m:07s remains)
INFO - root - 2022-02-24 21:24:48.334173: step 191810, total loss = 0.49, batch loss = 0.24 (313.7 examples/sec; 0.025 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:24:48.614581: step 191820, total loss = 0.55, batch loss = 0.29 (330.5 examples/sec; 0.024 sec/batch; 0h:03m:05s remains)
INFO - root - 2022-02-24 21:24:49.027552: step 191830, total loss = 0.52, batch loss = 0.26 (201.1 examples/sec; 0.040 sec/batch; 0h:05m:05s remains)
INFO - root - 2022-02-24 21:24:49.521800: step 191840, total loss = 0.52, batch loss = 0.26 (349.7 examples/sec; 0.023 sec/batch; 0h:02m:55s remains)
INFO - root - 2022-02-24 21:24:49.856733: step 191850, total loss = 0.51, batch loss = 0.25 (269.3 examples/sec; 0.030 sec/batch; 0h:03m:47s remains)
INFO - root - 2022-02-24 21:24:50.170933: step 191860, total loss = 0.54, batch loss = 0.29 (154.6 examples/sec; 0.052 sec/batch; 0h:06m:35s remains)
INFO - root - 2022-02-24 21:24:50.450465: step 191870, total loss = 0.63, batch loss = 0.37 (288.2 examples/sec; 0.028 sec/batch; 0h:03m:31s remains)
INFO - root - 2022-02-24 21:24:50.755215: step 191880, total loss = 0.62, batch loss = 0.36 (332.9 examples/sec; 0.024 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:24:51.203916: step 191890, total loss = 0.50, batch loss = 0.24 (380.9 examples/sec; 0.021 sec/batch; 0h:02m:39s remains)
INFO - root - 2022-02-24 21:24:51.585076: step 191900, total loss = 0.58, batch loss = 0.32 (175.3 examples/sec; 0.046 sec/batch; 0h:05m:46s remains)
INFO - root - 2022-02-24 21:24:51.978078: step 191910, total loss = 0.48, batch loss = 0.22 (296.4 examples/sec; 0.027 sec/batch; 0h:03m:24s remains)
INFO - root - 2022-02-24 21:24:52.267297: step 191920, total loss = 0.54, batch loss = 0.29 (208.1 examples/sec; 0.038 sec/batch; 0h:04m:51s remains)
INFO - root - 2022-02-24 21:24:52.510475: step 191930, total loss = 0.51, batch loss = 0.26 (332.6 examples/sec; 0.024 sec/batch; 0h:03m:02s remains)
INFO - root - 2022-02-24 21:24:52.897116: step 191940, total loss = 0.50, batch loss = 0.25 (147.3 examples/sec; 0.054 sec/batch; 0h:06m:50s remains)
INFO - root - 2022-02-24 21:24:53.314004: step 191950, total loss = 0.61, batch loss = 0.35 (164.0 examples/sec; 0.049 sec/batch; 0h:06m:08s remains)
INFO - root - 2022-02-24 21:24:53.606863: step 191960, total loss = 0.59, batch loss = 0.33 (298.3 examples/sec; 0.027 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:24:53.900433: step 191970, total loss = 0.45, batch loss = 0.20 (178.6 examples/sec; 0.045 sec/batch; 0h:05m:37s remains)
INFO - root - 2022-02-24 21:24:54.180067: step 191980, total loss = 0.50, batch loss = 0.25 (310.6 examples/sec; 0.026 sec/batch; 0h:03m:13s remains)
INFO - root - 2022-02-24 21:24:54.514725: step 191990, total loss = 0.55, batch loss = 0.29 (207.3 examples/sec; 0.039 sec/batch; 0h:04m:49s remains)
INFO - root - 2022-02-24 21:24:54.922393: step 192000, total loss = 0.58, batch loss = 0.32 (271.4 examples/sec; 0.029 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:24:55.327606: step 192010, total loss = 0.60, batch loss = 0.34 (249.1 examples/sec; 0.032 sec/batch; 0h:04m:00s remains)
INFO - root - 2022-02-24 21:24:55.760079: step 192020, total loss = 0.55, batch loss = 0.29 (165.9 examples/sec; 0.048 sec/batch; 0h:06m:00s remains)
INFO - root - 2022-02-24 21:24:56.019035: step 192030, total loss = 0.49, batch loss = 0.24 (293.5 examples/sec; 0.027 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:24:56.318796: step 192040, total loss = 0.76, batch loss = 0.51 (172.2 examples/sec; 0.046 sec/batch; 0h:05m:46s remains)
INFO - root - 2022-02-24 21:24:56.742547: step 192050, total loss = 0.60, batch loss = 0.34 (93.6 examples/sec; 0.085 sec/batch; 0h:10m:36s remains)
INFO - root - 2022-02-24 21:24:57.103475: step 192060, total loss = 0.49, batch loss = 0.23 (274.9 examples/sec; 0.029 sec/batch; 0h:03m:36s remains)
INFO - root - 2022-02-24 21:24:57.419920: step 192070, total loss = 0.50, batch loss = 0.24 (255.2 examples/sec; 0.031 sec/batch; 0h:03m:52s remains)
INFO - root - 2022-02-24 21:24:57.797353: step 192080, total loss = 0.44, batch loss = 0.18 (323.9 examples/sec; 0.025 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:24:58.076245: step 192090, total loss = 0.50, batch loss = 0.24 (286.6 examples/sec; 0.028 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:24:58.327321: step 192100, total loss = 0.60, batch loss = 0.35 (350.0 examples/sec; 0.023 sec/batch; 0h:02m:49s remains)
INFO - root - 2022-02-24 21:24:58.687139: step 192110, total loss = 0.54, batch loss = 0.28 (318.9 examples/sec; 0.025 sec/batch; 0h:03m:05s remains)
INFO - root - 2022-02-24 21:24:58.932363: step 192120, total loss = 0.59, batch loss = 0.33 (319.0 examples/sec; 0.025 sec/batch; 0h:03m:05s remains)
INFO - root - 2022-02-24 21:24:59.318826: step 192130, total loss = 0.53, batch loss = 0.27 (228.1 examples/sec; 0.035 sec/batch; 0h:04m:18s remains)
INFO - root - 2022-02-24 21:24:59.666722: step 192140, total loss = 0.55, batch loss = 0.29 (254.7 examples/sec; 0.031 sec/batch; 0h:03m:51s remains)
INFO - root - 2022-02-24 21:24:59.953090: step 192150, total loss = 0.46, batch loss = 0.20 (317.1 examples/sec; 0.025 sec/batch; 0h:03m:05s remains)
INFO - root - 2022-02-24 21:25:00.270930: step 192160, total loss = 0.59, batch loss = 0.33 (266.8 examples/sec; 0.030 sec/batch; 0h:03m:40s remains)
INFO - root - 2022-02-24 21:25:00.567490: step 192170, total loss = 0.57, batch loss = 0.32 (191.1 examples/sec; 0.042 sec/batch; 0h:05m:06s remains)
INFO - root - 2022-02-24 21:25:01.020703: step 192180, total loss = 0.53, batch loss = 0.27 (278.1 examples/sec; 0.029 sec/batch; 0h:03m:30s remains)
INFO - root - 2022-02-24 21:25:01.471693: step 192190, total loss = 0.51, batch loss = 0.25 (150.7 examples/sec; 0.053 sec/batch; 0h:06m:28s remains)
INFO - root - 2022-02-24 21:25:01.910502: step 192200, total loss = 0.66, batch loss = 0.40 (180.5 examples/sec; 0.044 sec/batch; 0h:05m:23s remains)
INFO - root - 2022-02-24 21:25:02.288790: step 192210, total loss = 0.47, batch loss = 0.21 (221.7 examples/sec; 0.036 sec/batch; 0h:04m:23s remains)
INFO - root - 2022-02-24 21:25:02.604774: step 192220, total loss = 0.56, batch loss = 0.30 (169.6 examples/sec; 0.047 sec/batch; 0h:05m:43s remains)
INFO - root - 2022-02-24 21:25:02.921031: step 192230, total loss = 0.52, batch loss = 0.26 (171.8 examples/sec; 0.047 sec/batch; 0h:05m:38s remains)
INFO - root - 2022-02-24 21:25:03.231539: step 192240, total loss = 0.53, batch loss = 0.27 (267.8 examples/sec; 0.030 sec/batch; 0h:03m:36s remains)
INFO - root - 2022-02-24 21:25:03.578795: step 192250, total loss = 0.55, batch loss = 0.30 (144.3 examples/sec; 0.055 sec/batch; 0h:06m:41s remains)
INFO - root - 2022-02-24 21:25:03.939174: step 192260, total loss = 0.64, batch loss = 0.38 (126.3 examples/sec; 0.063 sec/batch; 0h:07m:38s remains)
INFO - root - 2022-02-24 21:25:04.244655: step 192270, total loss = 0.53, batch loss = 0.27 (164.1 examples/sec; 0.049 sec/batch; 0h:05m:52s remains)
INFO - root - 2022-02-24 21:25:04.555005: step 192280, total loss = 0.56, batch loss = 0.30 (356.1 examples/sec; 0.022 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:25:04.910738: step 192290, total loss = 0.65, batch loss = 0.39 (321.6 examples/sec; 0.025 sec/batch; 0h:02m:59s remains)
INFO - root - 2022-02-24 21:25:05.293833: step 192300, total loss = 0.51, batch loss = 0.26 (295.6 examples/sec; 0.027 sec/batch; 0h:03m:14s remains)
INFO - root - 2022-02-24 21:25:05.753111: step 192310, total loss = 0.64, batch loss = 0.39 (328.5 examples/sec; 0.024 sec/batch; 0h:02m:55s remains)
INFO - root - 2022-02-24 21:25:06.146202: step 192320, total loss = 0.55, batch loss = 0.29 (318.7 examples/sec; 0.025 sec/batch; 0h:03m:00s remains)
INFO - root - 2022-02-24 21:25:06.472523: step 192330, total loss = 0.47, batch loss = 0.21 (300.3 examples/sec; 0.027 sec/batch; 0h:03m:11s remains)
INFO - root - 2022-02-24 21:25:06.740601: step 192340, total loss = 0.49, batch loss = 0.23 (328.3 examples/sec; 0.024 sec/batch; 0h:02m:54s remains)
INFO - root - 2022-02-24 21:25:07.167060: step 192350, total loss = 0.61, batch loss = 0.35 (103.1 examples/sec; 0.078 sec/batch; 0h:09m:15s remains)
INFO - root - 2022-02-24 21:25:07.548236: step 192360, total loss = 0.60, batch loss = 0.34 (248.9 examples/sec; 0.032 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:25:08.072127: step 192370, total loss = 0.62, batch loss = 0.36 (106.7 examples/sec; 0.075 sec/batch; 0h:08m:54s remains)
INFO - root - 2022-02-24 21:25:08.591906: step 192380, total loss = 0.62, batch loss = 0.36 (136.5 examples/sec; 0.059 sec/batch; 0h:06m:57s remains)
INFO - root - 2022-02-24 21:25:08.993459: step 192390, total loss = 0.54, batch loss = 0.29 (272.5 examples/sec; 0.029 sec/batch; 0h:03m:28s remains)
INFO - root - 2022-02-24 21:25:09.570313: step 192400, total loss = 0.55, batch loss = 0.29 (119.6 examples/sec; 0.067 sec/batch; 0h:07m:54s remains)
INFO - root - 2022-02-24 21:25:10.126121: step 192410, total loss = 0.47, batch loss = 0.21 (249.4 examples/sec; 0.032 sec/batch; 0h:03m:47s remains)
INFO - root - 2022-02-24 21:25:10.648893: step 192420, total loss = 0.60, batch loss = 0.35 (337.8 examples/sec; 0.024 sec/batch; 0h:02m:47s remains)
INFO - root - 2022-02-24 21:25:11.023750: step 192430, total loss = 0.56, batch loss = 0.31 (344.3 examples/sec; 0.023 sec/batch; 0h:02m:44s remains)
INFO - root - 2022-02-24 21:25:11.386719: step 192440, total loss = 0.52, batch loss = 0.26 (163.2 examples/sec; 0.049 sec/batch; 0h:05m:46s remains)
INFO - root - 2022-02-24 21:25:11.808004: step 192450, total loss = 0.47, batch loss = 0.22 (141.2 examples/sec; 0.057 sec/batch; 0h:06m:39s remains)
INFO - root - 2022-02-24 21:25:12.697856: step 192460, total loss = 0.54, batch loss = 0.28 (211.2 examples/sec; 0.038 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:25:13.088689: step 192470, total loss = 0.54, batch loss = 0.28 (358.9 examples/sec; 0.022 sec/batch; 0h:02m:36s remains)
INFO - root - 2022-02-24 21:25:13.349229: step 192480, total loss = 0.47, batch loss = 0.21 (299.3 examples/sec; 0.027 sec/batch; 0h:03m:07s remains)
INFO - root - 2022-02-24 21:25:13.630124: step 192490, total loss = 0.59, batch loss = 0.33 (268.8 examples/sec; 0.030 sec/batch; 0h:03m:28s remains)
INFO - root - 2022-02-24 21:25:13.933574: step 192500, total loss = 0.50, batch loss = 0.25 (329.1 examples/sec; 0.024 sec/batch; 0h:02m:50s remains)
INFO - root - 2022-02-24 21:25:14.334427: step 192510, total loss = 0.51, batch loss = 0.25 (217.6 examples/sec; 0.037 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:25:14.805045: step 192520, total loss = 0.52, batch loss = 0.26 (128.0 examples/sec; 0.062 sec/batch; 0h:07m:16s remains)
INFO - root - 2022-02-24 21:25:15.053323: step 192530, total loss = 0.59, batch loss = 0.33 (360.2 examples/sec; 0.022 sec/batch; 0h:02m:34s remains)
INFO - root - 2022-02-24 21:25:15.373651: step 192540, total loss = 0.50, batch loss = 0.25 (349.1 examples/sec; 0.023 sec/batch; 0h:02m:39s remains)
INFO - root - 2022-02-24 21:25:15.663008: step 192550, total loss = 0.48, batch loss = 0.23 (226.1 examples/sec; 0.035 sec/batch; 0h:04m:05s remains)
INFO - root - 2022-02-24 21:25:15.968237: step 192560, total loss = 0.55, batch loss = 0.29 (334.4 examples/sec; 0.024 sec/batch; 0h:02m:46s remains)
INFO - root - 2022-02-24 21:25:16.253590: step 192570, total loss = 0.54, batch loss = 0.28 (270.1 examples/sec; 0.030 sec/batch; 0h:03m:25s remains)
INFO - root - 2022-02-24 21:25:16.650221: step 192580, total loss = 0.61, batch loss = 0.36 (228.5 examples/sec; 0.035 sec/batch; 0h:04m:02s remains)
INFO - root - 2022-02-24 21:25:17.115351: step 192590, total loss = 0.46, batch loss = 0.21 (196.9 examples/sec; 0.041 sec/batch; 0h:04m:40s remains)
INFO - root - 2022-02-24 21:25:17.443040: step 192600, total loss = 0.57, batch loss = 0.31 (245.1 examples/sec; 0.033 sec/batch; 0h:03m:45s remains)
INFO - root - 2022-02-24 21:25:17.845228: step 192610, total loss = 0.59, batch loss = 0.34 (226.3 examples/sec; 0.035 sec/batch; 0h:04m:03s remains)
INFO - root - 2022-02-24 21:25:18.164601: step 192620, total loss = 0.49, batch loss = 0.24 (187.5 examples/sec; 0.043 sec/batch; 0h:04m:53s remains)
INFO - root - 2022-02-24 21:25:18.465137: step 192630, total loss = 0.56, batch loss = 0.31 (275.9 examples/sec; 0.029 sec/batch; 0h:03m:19s remains)
INFO - root - 2022-02-24 21:25:18.924382: step 192640, total loss = 0.47, batch loss = 0.21 (171.6 examples/sec; 0.047 sec/batch; 0h:05m:19s remains)
INFO - root - 2022-02-24 21:25:19.227372: step 192650, total loss = 0.46, batch loss = 0.21 (205.8 examples/sec; 0.039 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:25:19.530693: step 192660, total loss = 0.51, batch loss = 0.26 (362.4 examples/sec; 0.022 sec/batch; 0h:02m:31s remains)
INFO - root - 2022-02-24 21:25:19.810311: step 192670, total loss = 0.44, batch loss = 0.18 (331.8 examples/sec; 0.024 sec/batch; 0h:02m:44s remains)
INFO - root - 2022-02-24 21:25:20.085829: step 192680, total loss = 0.53, batch loss = 0.27 (317.5 examples/sec; 0.025 sec/batch; 0h:02m:51s remains)
INFO - root - 2022-02-24 21:25:20.458034: step 192690, total loss = 0.58, batch loss = 0.33 (218.1 examples/sec; 0.037 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:25:20.923665: step 192700, total loss = 0.56, batch loss = 0.30 (150.2 examples/sec; 0.053 sec/batch; 0h:06m:02s remains)
INFO - root - 2022-02-24 21:25:21.400334: step 192710, total loss = 0.54, batch loss = 0.28 (356.9 examples/sec; 0.022 sec/batch; 0h:02m:32s remains)
INFO - root - 2022-02-24 21:25:21.710734: step 192720, total loss = 0.48, batch loss = 0.23 (314.5 examples/sec; 0.025 sec/batch; 0h:02m:52s remains)
INFO - root - 2022-02-24 21:25:22.009372: step 192730, total loss = 0.46, batch loss = 0.21 (225.6 examples/sec; 0.035 sec/batch; 0h:04m:00s remains)
INFO - root - 2022-02-24 21:25:22.404765: step 192740, total loss = 0.55, batch loss = 0.29 (279.4 examples/sec; 0.029 sec/batch; 0h:03m:13s remains)
INFO - root - 2022-02-24 21:25:22.796206: step 192750, total loss = 0.58, batch loss = 0.32 (139.5 examples/sec; 0.057 sec/batch; 0h:06m:27s remains)
INFO - root - 2022-02-24 21:25:23.113751: step 192760, total loss = 0.55, batch loss = 0.29 (341.6 examples/sec; 0.023 sec/batch; 0h:02m:37s remains)
INFO - root - 2022-02-24 21:25:23.517375: step 192770, total loss = 0.47, batch loss = 0.22 (194.9 examples/sec; 0.041 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:25:23.861452: step 192780, total loss = 0.59, batch loss = 0.34 (294.3 examples/sec; 0.027 sec/batch; 0h:03m:02s remains)
INFO - root - 2022-02-24 21:25:24.216964: step 192790, total loss = 0.42, batch loss = 0.16 (176.5 examples/sec; 0.045 sec/batch; 0h:05m:04s remains)
INFO - root - 2022-02-24 21:25:24.527953: step 192800, total loss = 0.45, batch loss = 0.20 (254.0 examples/sec; 0.031 sec/batch; 0h:03m:31s remains)
INFO - root - 2022-02-24 21:25:25.018118: step 192810, total loss = 0.48, batch loss = 0.22 (113.9 examples/sec; 0.070 sec/batch; 0h:07m:50s remains)
INFO - root - 2022-02-24 21:25:25.406036: step 192820, total loss = 0.52, batch loss = 0.26 (198.3 examples/sec; 0.040 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:25:25.699034: step 192830, total loss = 0.60, batch loss = 0.34 (300.5 examples/sec; 0.027 sec/batch; 0h:02m:57s remains)
INFO - root - 2022-02-24 21:25:25.948264: step 192840, total loss = 0.60, batch loss = 0.35 (341.5 examples/sec; 0.023 sec/batch; 0h:02m:36s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-192849 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-192849 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2022-02-24 21:25:26.605387: step 192850, total loss = 0.59, batch loss = 0.33 (315.7 examples/sec; 0.025 sec/batch; 0h:02m:48s remains)
INFO - root - 2022-02-24 21:25:26.844702: step 192860, total loss = 0.55, batch loss = 0.29 (315.2 examples/sec; 0.025 sec/batch; 0h:02m:48s remains)
INFO - root - 2022-02-24 21:25:27.140434: step 192870, total loss = 0.52, batch loss = 0.26 (147.5 examples/sec; 0.054 sec/batch; 0h:05m:59s remains)
INFO - root - 2022-02-24 21:25:27.600613: step 192880, total loss = 0.57, batch loss = 0.32 (269.3 examples/sec; 0.030 sec/batch; 0h:03m:16s remains)
INFO - root - 2022-02-24 21:25:27.924161: step 192890, total loss = 0.52, batch loss = 0.26 (314.4 examples/sec; 0.025 sec/batch; 0h:02m:48s remains)
INFO - root - 2022-02-24 21:25:28.224402: step 192900, total loss = 0.48, batch loss = 0.23 (325.8 examples/sec; 0.025 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:25:28.581530: step 192910, total loss = 0.50, batch loss = 0.25 (275.4 examples/sec; 0.029 sec/batch; 0h:03m:11s remains)
INFO - root - 2022-02-24 21:25:28.898070: step 192920, total loss = 0.52, batch loss = 0.27 (223.1 examples/sec; 0.036 sec/batch; 0h:03m:55s remains)
INFO - root - 2022-02-24 21:25:29.366511: step 192930, total loss = 0.57, batch loss = 0.31 (99.1 examples/sec; 0.081 sec/batch; 0h:08m:50s remains)
INFO - root - 2022-02-24 21:25:29.652207: step 192940, total loss = 0.53, batch loss = 0.27 (339.5 examples/sec; 0.024 sec/batch; 0h:02m:34s remains)
INFO - root - 2022-02-24 21:25:29.894365: step 192950, total loss = 0.56, batch loss = 0.30 (324.2 examples/sec; 0.025 sec/batch; 0h:02m:41s remains)
INFO - root - 2022-02-24 21:25:30.205991: step 192960, total loss = 0.40, batch loss = 0.14 (271.6 examples/sec; 0.029 sec/batch; 0h:03m:12s remains)
INFO - root - 2022-02-24 21:25:30.564984: step 192970, total loss = 0.69, batch loss = 0.44 (213.8 examples/sec; 0.037 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:25:30.881513: step 192980, total loss = 0.52, batch loss = 0.26 (221.5 examples/sec; 0.036 sec/batch; 0h:03m:55s remains)
INFO - root - 2022-02-24 21:25:31.274610: step 192990, total loss = 0.55, batch loss = 0.30 (206.9 examples/sec; 0.039 sec/batch; 0h:04m:11s remains)
INFO - root - 2022-02-24 21:25:31.651490: step 193000, total loss = 0.51, batch loss = 0.26 (185.6 examples/sec; 0.043 sec/batch; 0h:04m:40s remains)
INFO - root - 2022-02-24 21:25:32.149445: step 193010, total loss = 0.51, batch loss = 0.26 (146.3 examples/sec; 0.055 sec/batch; 0h:05m:54s remains)
INFO - root - 2022-02-24 21:25:32.505277: step 193020, total loss = 0.59, batch loss = 0.33 (210.2 examples/sec; 0.038 sec/batch; 0h:04m:06s remains)
INFO - root - 2022-02-24 21:25:32.868886: step 193030, total loss = 0.51, batch loss = 0.26 (340.9 examples/sec; 0.023 sec/batch; 0h:02m:31s remains)
INFO - root - 2022-02-24 21:25:33.152528: step 193040, total loss = 0.49, batch loss = 0.24 (379.3 examples/sec; 0.021 sec/batch; 0h:02m:16s remains)
INFO - root - 2022-02-24 21:25:33.447341: step 193050, total loss = 0.55, batch loss = 0.29 (276.2 examples/sec; 0.029 sec/batch; 0h:03m:06s remains)
INFO - root - 2022-02-24 21:25:33.772478: step 193060, total loss = 0.46, batch loss = 0.20 (249.4 examples/sec; 0.032 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:25:34.024824: step 193070, total loss = 0.63, batch loss = 0.38 (342.4 examples/sec; 0.023 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:25:34.378407: step 193080, total loss = 0.47, batch loss = 0.22 (80.5 examples/sec; 0.099 sec/batch; 0h:10m:37s remains)
INFO - root - 2022-02-24 21:25:35.368250: step 193090, total loss = 0.62, batch loss = 0.37 (202.5 examples/sec; 0.040 sec/batch; 0h:04m:13s remains)
INFO - root - 2022-02-24 21:25:35.974064: step 193100, total loss = 0.48, batch loss = 0.22 (75.8 examples/sec; 0.106 sec/batch; 0h:11m:15s remains)
INFO - root - 2022-02-24 21:25:36.735467: step 193110, total loss = 0.51, batch loss = 0.25 (69.8 examples/sec; 0.115 sec/batch; 0h:12m:12s remains)
INFO - root - 2022-02-24 21:25:37.597373: step 193120, total loss = 0.53, batch loss = 0.27 (317.0 examples/sec; 0.025 sec/batch; 0h:02m:40s remains)
INFO - root - 2022-02-24 21:25:38.191110: step 193130, total loss = 0.51, batch loss = 0.25 (128.8 examples/sec; 0.062 sec/batch; 0h:06m:35s remains)
INFO - root - 2022-02-24 21:25:38.952394: step 193140, total loss = 0.59, batch loss = 0.34 (333.3 examples/sec; 0.024 sec/batch; 0h:02m:32s remains)
INFO - root - 2022-02-24 21:25:39.343794: step 193150, total loss = 0.50, batch loss = 0.24 (355.6 examples/sec; 0.023 sec/batch; 0h:02m:22s remains)
INFO - root - 2022-02-24 21:25:39.928259: step 193160, total loss = 0.59, batch loss = 0.33 (380.7 examples/sec; 0.021 sec/batch; 0h:02m:13s remains)
INFO - root - 2022-02-24 21:25:40.428669: step 193170, total loss = 0.53, batch loss = 0.28 (305.5 examples/sec; 0.026 sec/batch; 0h:02m:45s remains)
INFO - root - 2022-02-24 21:25:40.935242: step 193180, total loss = 0.63, batch loss = 0.37 (310.4 examples/sec; 0.026 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:25:41.551270: step 193190, total loss = 0.60, batch loss = 0.34 (247.8 examples/sec; 0.032 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:25:42.144153: step 193200, total loss = 0.46, batch loss = 0.21 (180.2 examples/sec; 0.044 sec/batch; 0h:04m:39s remains)
INFO - root - 2022-02-24 21:25:42.712064: step 193210, total loss = 0.50, batch loss = 0.25 (93.8 examples/sec; 0.085 sec/batch; 0h:08m:56s remains)
INFO - root - 2022-02-24 21:25:43.383201: step 193220, total loss = 0.48, batch loss = 0.22 (322.2 examples/sec; 0.025 sec/batch; 0h:02m:35s remains)
INFO - root - 2022-02-24 21:25:43.754005: step 193230, total loss = 0.57, batch loss = 0.32 (202.7 examples/sec; 0.039 sec/batch; 0h:04m:07s remains)
INFO - root - 2022-02-24 21:25:44.112298: step 193240, total loss = 0.46, batch loss = 0.21 (174.0 examples/sec; 0.046 sec/batch; 0h:04m:47s remains)
INFO - root - 2022-02-24 21:25:44.411655: step 193250, total loss = 0.61, batch loss = 0.35 (261.9 examples/sec; 0.031 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:25:44.690097: step 193260, total loss = 0.58, batch loss = 0.33 (260.5 examples/sec; 0.031 sec/batch; 0h:03m:11s remains)
INFO - root - 2022-02-24 21:25:45.025068: step 193270, total loss = 0.53, batch loss = 0.27 (252.4 examples/sec; 0.032 sec/batch; 0h:03m:17s remains)
INFO - root - 2022-02-24 21:25:45.401722: step 193280, total loss = 0.62, batch loss = 0.37 (374.3 examples/sec; 0.021 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:25:45.824422: step 193290, total loss = 0.50, batch loss = 0.24 (154.1 examples/sec; 0.052 sec/batch; 0h:05m:22s remains)
INFO - root - 2022-02-24 21:25:46.191164: step 193300, total loss = 0.45, batch loss = 0.20 (173.3 examples/sec; 0.046 sec/batch; 0h:04m:46s remains)
INFO - root - 2022-02-24 21:25:46.595219: step 193310, total loss = 0.60, batch loss = 0.34 (167.5 examples/sec; 0.048 sec/batch; 0h:04m:55s remains)
INFO - root - 2022-02-24 21:25:46.975803: step 193320, total loss = 0.52, batch loss = 0.26 (194.9 examples/sec; 0.041 sec/batch; 0h:04m:13s remains)
INFO - root - 2022-02-24 21:25:47.403249: step 193330, total loss = 0.62, batch loss = 0.36 (148.3 examples/sec; 0.054 sec/batch; 0h:05m:32s remains)
INFO - root - 2022-02-24 21:25:48.032742: step 193340, total loss = 0.58, batch loss = 0.32 (327.4 examples/sec; 0.024 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:25:48.393789: step 193350, total loss = 0.54, batch loss = 0.29 (262.1 examples/sec; 0.031 sec/batch; 0h:03m:07s remains)
INFO - root - 2022-02-24 21:25:48.816673: step 193360, total loss = 0.50, batch loss = 0.24 (137.0 examples/sec; 0.058 sec/batch; 0h:05m:58s remains)
INFO - root - 2022-02-24 21:25:49.053242: step 193370, total loss = 0.58, batch loss = 0.32 (342.8 examples/sec; 0.023 sec/batch; 0h:02m:23s remains)
INFO - root - 2022-02-24 21:25:49.435906: step 193380, total loss = 0.54, batch loss = 0.28 (126.9 examples/sec; 0.063 sec/batch; 0h:06m:25s remains)
INFO - root - 2022-02-24 21:25:49.756886: step 193390, total loss = 0.55, batch loss = 0.29 (306.2 examples/sec; 0.026 sec/batch; 0h:02m:39s remains)
INFO - root - 2022-02-24 21:25:50.264998: step 193400, total loss = 0.55, batch loss = 0.30 (227.9 examples/sec; 0.035 sec/batch; 0h:03m:34s remains)
INFO - root - 2022-02-24 21:25:50.773862: step 193410, total loss = 0.51, batch loss = 0.25 (356.8 examples/sec; 0.022 sec/batch; 0h:02m:16s remains)
INFO - root - 2022-02-24 21:25:51.195126: step 193420, total loss = 0.54, batch loss = 0.28 (328.8 examples/sec; 0.024 sec/batch; 0h:02m:27s remains)
INFO - root - 2022-02-24 21:25:51.674530: step 193430, total loss = 0.52, batch loss = 0.27 (248.4 examples/sec; 0.032 sec/batch; 0h:03m:15s remains)
INFO - root - 2022-02-24 21:25:52.130988: step 193440, total loss = 0.50, batch loss = 0.24 (273.3 examples/sec; 0.029 sec/batch; 0h:02m:57s remains)
INFO - root - 2022-02-24 21:25:52.569482: step 193450, total loss = 0.52, batch loss = 0.27 (221.1 examples/sec; 0.036 sec/batch; 0h:03m:38s remains)
INFO - root - 2022-02-24 21:25:52.984387: step 193460, total loss = 0.57, batch loss = 0.32 (99.4 examples/sec; 0.080 sec/batch; 0h:08m:06s remains)
INFO - root - 2022-02-24 21:25:53.883873: step 193470, total loss = 0.55, batch loss = 0.30 (209.9 examples/sec; 0.038 sec/batch; 0h:03m:49s remains)
INFO - root - 2022-02-24 21:25:54.264828: step 193480, total loss = 0.55, batch loss = 0.30 (242.3 examples/sec; 0.033 sec/batch; 0h:03m:18s remains)
INFO - root - 2022-02-24 21:25:54.638262: step 193490, total loss = 0.53, batch loss = 0.27 (214.3 examples/sec; 0.037 sec/batch; 0h:03m:44s remains)
INFO - root - 2022-02-24 21:25:54.878242: step 193500, total loss = 0.60, batch loss = 0.35 (314.2 examples/sec; 0.025 sec/batch; 0h:02m:32s remains)
INFO - root - 2022-02-24 21:25:55.295647: step 193510, total loss = 0.52, batch loss = 0.27 (262.9 examples/sec; 0.030 sec/batch; 0h:03m:02s remains)
INFO - root - 2022-02-24 21:25:55.639237: step 193520, total loss = 0.51, batch loss = 0.26 (369.3 examples/sec; 0.022 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:25:56.025345: step 193530, total loss = 0.45, batch loss = 0.20 (291.3 examples/sec; 0.027 sec/batch; 0h:02m:43s remains)
INFO - root - 2022-02-24 21:25:56.403389: step 193540, total loss = 0.64, batch loss = 0.38 (353.2 examples/sec; 0.023 sec/batch; 0h:02m:15s remains)
INFO - root - 2022-02-24 21:25:56.659352: step 193550, total loss = 0.59, batch loss = 0.34 (332.7 examples/sec; 0.024 sec/batch; 0h:02m:23s remains)
INFO - root - 2022-02-24 21:25:56.963959: step 193560, total loss = 0.50, batch loss = 0.25 (240.3 examples/sec; 0.033 sec/batch; 0h:03m:17s remains)
INFO - root - 2022-02-24 21:25:57.291468: step 193570, total loss = 0.54, batch loss = 0.28 (339.8 examples/sec; 0.024 sec/batch; 0h:02m:19s remains)
INFO - root - 2022-02-24 21:25:57.704771: step 193580, total loss = 0.55, batch loss = 0.29 (105.1 examples/sec; 0.076 sec/batch; 0h:07m:30s remains)
INFO - root - 2022-02-24 21:25:58.166742: step 193590, total loss = 0.56, batch loss = 0.31 (73.3 examples/sec; 0.109 sec/batch; 0h:10m:45s remains)
INFO - root - 2022-02-24 21:25:58.717566: step 193600, total loss = 0.57, batch loss = 0.32 (116.1 examples/sec; 0.069 sec/batch; 0h:06m:46s remains)
INFO - root - 2022-02-24 21:25:59.111094: step 193610, total loss = 0.55, batch loss = 0.29 (268.1 examples/sec; 0.030 sec/batch; 0h:02m:55s remains)
INFO - root - 2022-02-24 21:25:59.393080: step 193620, total loss = 0.56, batch loss = 0.30 (328.4 examples/sec; 0.024 sec/batch; 0h:02m:23s remains)
INFO - root - 2022-02-24 21:25:59.793190: step 193630, total loss = 0.52, batch loss = 0.26 (117.7 examples/sec; 0.068 sec/batch; 0h:06m:38s remains)
INFO - root - 2022-02-24 21:26:00.199973: step 193640, total loss = 0.50, batch loss = 0.25 (193.9 examples/sec; 0.041 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:26:00.592281: step 193650, total loss = 0.56, batch loss = 0.30 (276.0 examples/sec; 0.029 sec/batch; 0h:02m:49s remains)
INFO - root - 2022-02-24 21:26:01.014840: step 193660, total loss = 0.50, batch loss = 0.25 (90.6 examples/sec; 0.088 sec/batch; 0h:08m:35s remains)
INFO - root - 2022-02-24 21:26:01.278644: step 193670, total loss = 0.57, batch loss = 0.32 (276.6 examples/sec; 0.029 sec/batch; 0h:02m:48s remains)
INFO - root - 2022-02-24 21:26:01.531557: step 193680, total loss = 0.52, batch loss = 0.26 (330.9 examples/sec; 0.024 sec/batch; 0h:02m:20s remains)
INFO - root - 2022-02-24 21:26:01.860913: step 193690, total loss = 0.50, batch loss = 0.24 (162.2 examples/sec; 0.049 sec/batch; 0h:04m:46s remains)
INFO - root - 2022-02-24 21:26:02.238627: step 193700, total loss = 0.63, batch loss = 0.37 (326.4 examples/sec; 0.025 sec/batch; 0h:02m:22s remains)
INFO - root - 2022-02-24 21:26:02.715658: step 193710, total loss = 0.51, batch loss = 0.25 (317.3 examples/sec; 0.025 sec/batch; 0h:02m:25s remains)
INFO - root - 2022-02-24 21:26:03.100036: step 193720, total loss = 0.55, batch loss = 0.29 (291.8 examples/sec; 0.027 sec/batch; 0h:02m:38s remains)
INFO - root - 2022-02-24 21:26:03.502316: step 193730, total loss = 0.50, batch loss = 0.24 (356.0 examples/sec; 0.022 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:26:03.815350: step 193740, total loss = 0.47, batch loss = 0.21 (291.8 examples/sec; 0.027 sec/batch; 0h:02m:37s remains)
INFO - root - 2022-02-24 21:26:04.111639: step 193750, total loss = 0.50, batch loss = 0.24 (310.0 examples/sec; 0.026 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:26:04.447883: step 193760, total loss = 0.48, batch loss = 0.23 (316.8 examples/sec; 0.025 sec/batch; 0h:02m:24s remains)
INFO - root - 2022-02-24 21:26:04.932088: step 193770, total loss = 0.60, batch loss = 0.35 (335.8 examples/sec; 0.024 sec/batch; 0h:02m:16s remains)
INFO - root - 2022-02-24 21:26:05.246618: step 193780, total loss = 0.65, batch loss = 0.39 (305.0 examples/sec; 0.026 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:26:05.554350: step 193790, total loss = 0.51, batch loss = 0.26 (329.5 examples/sec; 0.024 sec/batch; 0h:02m:18s remains)
INFO - root - 2022-02-24 21:26:05.892247: step 193800, total loss = 0.50, batch loss = 0.24 (324.1 examples/sec; 0.025 sec/batch; 0h:02m:20s remains)
INFO - root - 2022-02-24 21:26:06.405189: step 193810, total loss = 0.62, batch loss = 0.37 (146.5 examples/sec; 0.055 sec/batch; 0h:05m:10s remains)
INFO - root - 2022-02-24 21:26:06.803809: step 193820, total loss = 0.64, batch loss = 0.38 (111.6 examples/sec; 0.072 sec/batch; 0h:06m:47s remains)
INFO - root - 2022-02-24 21:26:07.117039: step 193830, total loss = 0.51, batch loss = 0.26 (305.8 examples/sec; 0.026 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:26:07.407535: step 193840, total loss = 0.65, batch loss = 0.40 (327.2 examples/sec; 0.024 sec/batch; 0h:02m:18s remains)
INFO - root - 2022-02-24 21:26:07.740822: step 193850, total loss = 0.51, batch loss = 0.25 (311.1 examples/sec; 0.026 sec/batch; 0h:02m:25s remains)
INFO - root - 2022-02-24 21:26:08.059701: step 193860, total loss = 0.66, batch loss = 0.40 (316.1 examples/sec; 0.025 sec/batch; 0h:02m:22s remains)
INFO - root - 2022-02-24 21:26:08.368836: step 193870, total loss = 0.54, batch loss = 0.28 (339.0 examples/sec; 0.024 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:26:08.805245: step 193880, total loss = 0.47, batch loss = 0.22 (124.7 examples/sec; 0.064 sec/batch; 0h:06m:00s remains)
INFO - root - 2022-02-24 21:26:09.133676: step 193890, total loss = 0.50, batch loss = 0.24 (341.5 examples/sec; 0.023 sec/batch; 0h:02m:11s remains)
INFO - root - 2022-02-24 21:26:09.469131: step 193900, total loss = 0.51, batch loss = 0.25 (276.4 examples/sec; 0.029 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:26:09.866810: step 193910, total loss = 0.47, batch loss = 0.21 (262.5 examples/sec; 0.030 sec/batch; 0h:02m:50s remains)
INFO - root - 2022-02-24 21:26:10.240693: step 193920, total loss = 0.57, batch loss = 0.31 (274.5 examples/sec; 0.029 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:26:10.668809: step 193930, total loss = 0.75, batch loss = 0.50 (165.2 examples/sec; 0.048 sec/batch; 0h:04m:29s remains)
INFO - root - 2022-02-24 21:26:11.066466: step 193940, total loss = 0.67, batch loss = 0.41 (231.5 examples/sec; 0.035 sec/batch; 0h:03m:12s remains)
INFO - root - 2022-02-24 21:26:11.329378: step 193950, total loss = 0.47, batch loss = 0.21 (345.1 examples/sec; 0.023 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:26:11.636940: step 193960, total loss = 0.51, batch loss = 0.26 (181.6 examples/sec; 0.044 sec/batch; 0h:04m:04s remains)
INFO - root - 2022-02-24 21:26:11.917038: step 193970, total loss = 0.51, batch loss = 0.25 (321.0 examples/sec; 0.025 sec/batch; 0h:02m:17s remains)
INFO - root - 2022-02-24 21:26:12.209223: step 193980, total loss = 0.57, batch loss = 0.31 (310.7 examples/sec; 0.026 sec/batch; 0h:02m:22s remains)
INFO - root - 2022-02-24 21:26:12.562962: step 193990, total loss = 0.47, batch loss = 0.21 (333.5 examples/sec; 0.024 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:26:13.015718: step 194000, total loss = 0.50, batch loss = 0.24 (302.1 examples/sec; 0.026 sec/batch; 0h:02m:25s remains)
INFO - root - 2022-02-24 21:26:13.457560: step 194010, total loss = 0.57, batch loss = 0.31 (221.7 examples/sec; 0.036 sec/batch; 0h:03m:18s remains)
INFO - root - 2022-02-24 21:26:13.764713: step 194020, total loss = 0.61, batch loss = 0.36 (227.4 examples/sec; 0.035 sec/batch; 0h:03m:12s remains)
INFO - root - 2022-02-24 21:26:14.068179: step 194030, total loss = 0.47, batch loss = 0.21 (294.0 examples/sec; 0.027 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:26:14.407516: step 194040, total loss = 0.48, batch loss = 0.23 (197.0 examples/sec; 0.041 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:26:14.816172: step 194050, total loss = 0.45, batch loss = 0.19 (90.5 examples/sec; 0.088 sec/batch; 0h:08m:01s remains)
INFO - root - 2022-02-24 21:26:15.204097: step 194060, total loss = 0.62, batch loss = 0.36 (238.9 examples/sec; 0.033 sec/batch; 0h:03m:02s remains)
INFO - root - 2022-02-24 21:26:15.517522: step 194070, total loss = 0.67, batch loss = 0.42 (342.7 examples/sec; 0.023 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:26:15.872907: step 194080, total loss = 0.57, batch loss = 0.31 (150.1 examples/sec; 0.053 sec/batch; 0h:04m:48s remains)
INFO - root - 2022-02-24 21:26:16.184800: step 194090, total loss = 0.53, batch loss = 0.28 (335.1 examples/sec; 0.024 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:26:16.515878: step 194100, total loss = 0.46, batch loss = 0.20 (259.3 examples/sec; 0.031 sec/batch; 0h:02m:46s remains)
INFO - root - 2022-02-24 21:26:16.969939: step 194110, total loss = 0.55, batch loss = 0.29 (198.3 examples/sec; 0.040 sec/batch; 0h:03m:37s remains)
INFO - root - 2022-02-24 21:26:17.420174: step 194120, total loss = 0.50, batch loss = 0.25 (220.0 examples/sec; 0.036 sec/batch; 0h:03m:15s remains)
INFO - root - 2022-02-24 21:26:17.683567: step 194130, total loss = 0.57, batch loss = 0.32 (275.2 examples/sec; 0.029 sec/batch; 0h:02m:36s remains)
INFO - root - 2022-02-24 21:26:17.959243: step 194140, total loss = 0.51, batch loss = 0.26 (324.1 examples/sec; 0.025 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:26:18.342728: step 194150, total loss = 0.61, batch loss = 0.35 (251.9 examples/sec; 0.032 sec/batch; 0h:02m:49s remains)
INFO - root - 2022-02-24 21:26:18.721746: step 194160, total loss = 0.67, batch loss = 0.41 (362.8 examples/sec; 0.022 sec/batch; 0h:01m:57s remains)
INFO - root - 2022-02-24 21:26:19.064208: step 194170, total loss = 0.49, batch loss = 0.23 (177.5 examples/sec; 0.045 sec/batch; 0h:04m:00s remains)
INFO - root - 2022-02-24 21:26:19.470306: step 194180, total loss = 0.54, batch loss = 0.29 (347.0 examples/sec; 0.023 sec/batch; 0h:02m:02s remains)
INFO - root - 2022-02-24 21:26:19.783991: step 194190, total loss = 0.52, batch loss = 0.26 (283.0 examples/sec; 0.028 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:26:20.030532: step 194200, total loss = 0.54, batch loss = 0.29 (285.2 examples/sec; 0.028 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:26:20.418891: step 194210, total loss = 0.56, batch loss = 0.30 (154.0 examples/sec; 0.052 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:26:20.787005: step 194220, total loss = 0.55, batch loss = 0.30 (181.6 examples/sec; 0.044 sec/batch; 0h:03m:52s remains)
INFO - root - 2022-02-24 21:26:21.247238: step 194230, total loss = 0.49, batch loss = 0.24 (160.1 examples/sec; 0.050 sec/batch; 0h:04m:23s remains)
INFO - root - 2022-02-24 21:26:21.614331: step 194240, total loss = 0.50, batch loss = 0.24 (125.6 examples/sec; 0.064 sec/batch; 0h:05m:35s remains)
INFO - root - 2022-02-24 21:26:21.944167: step 194250, total loss = 0.52, batch loss = 0.26 (116.7 examples/sec; 0.069 sec/batch; 0h:05m:59s remains)
INFO - root - 2022-02-24 21:26:22.242313: step 194260, total loss = 0.53, batch loss = 0.27 (127.8 examples/sec; 0.063 sec/batch; 0h:05m:28s remains)
INFO - root - 2022-02-24 21:26:22.527139: step 194270, total loss = 0.59, batch loss = 0.34 (354.9 examples/sec; 0.023 sec/batch; 0h:01m:57s remains)
INFO - root - 2022-02-24 21:26:22.817258: step 194280, total loss = 0.49, batch loss = 0.24 (156.7 examples/sec; 0.051 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:26:23.224438: step 194290, total loss = 0.59, batch loss = 0.33 (132.0 examples/sec; 0.061 sec/batch; 0h:05m:15s remains)
INFO - root - 2022-02-24 21:26:23.659027: step 194300, total loss = 0.51, batch loss = 0.26 (308.8 examples/sec; 0.026 sec/batch; 0h:02m:14s remains)
INFO - root - 2022-02-24 21:26:23.995351: step 194310, total loss = 0.55, batch loss = 0.30 (325.8 examples/sec; 0.025 sec/batch; 0h:02m:07s remains)
INFO - root - 2022-02-24 21:26:24.276300: step 194320, total loss = 0.48, batch loss = 0.22 (150.0 examples/sec; 0.053 sec/batch; 0h:04m:36s remains)
INFO - root - 2022-02-24 21:26:24.730085: step 194330, total loss = 0.52, batch loss = 0.26 (200.4 examples/sec; 0.040 sec/batch; 0h:03m:26s remains)
INFO - root - 2022-02-24 21:26:25.264214: step 194340, total loss = 0.54, batch loss = 0.28 (327.2 examples/sec; 0.024 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:26:25.748071: step 194350, total loss = 0.48, batch loss = 0.22 (91.3 examples/sec; 0.088 sec/batch; 0h:07m:31s remains)
INFO - root - 2022-02-24 21:26:26.205199: step 194360, total loss = 0.53, batch loss = 0.27 (281.0 examples/sec; 0.028 sec/batch; 0h:02m:26s remains)
INFO - root - 2022-02-24 21:26:26.807344: step 194370, total loss = 0.75, batch loss = 0.49 (308.8 examples/sec; 0.026 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:26:27.410208: step 194380, total loss = 0.56, batch loss = 0.31 (299.9 examples/sec; 0.027 sec/batch; 0h:02m:16s remains)
INFO - root - 2022-02-24 21:26:28.405695: step 194390, total loss = 0.59, batch loss = 0.33 (341.0 examples/sec; 0.023 sec/batch; 0h:01m:59s remains)
INFO - root - 2022-02-24 21:26:28.716203: step 194400, total loss = 0.56, batch loss = 0.31 (307.7 examples/sec; 0.026 sec/batch; 0h:02m:12s remains)
INFO - root - 2022-02-24 21:26:29.098418: step 194410, total loss = 0.48, batch loss = 0.22 (379.4 examples/sec; 0.021 sec/batch; 0h:01m:47s remains)
INFO - root - 2022-02-24 21:26:29.417201: step 194420, total loss = 0.54, batch loss = 0.29 (301.9 examples/sec; 0.027 sec/batch; 0h:02m:14s remains)
INFO - root - 2022-02-24 21:26:29.802973: step 194430, total loss = 0.49, batch loss = 0.24 (210.0 examples/sec; 0.038 sec/batch; 0h:03m:13s remains)
INFO - root - 2022-02-24 21:26:30.095112: step 194440, total loss = 0.58, batch loss = 0.32 (301.4 examples/sec; 0.027 sec/batch; 0h:02m:14s remains)
INFO - root - 2022-02-24 21:26:30.488160: step 194450, total loss = 0.57, batch loss = 0.31 (153.1 examples/sec; 0.052 sec/batch; 0h:04m:23s remains)
INFO - root - 2022-02-24 21:26:30.797154: step 194460, total loss = 0.59, batch loss = 0.34 (361.5 examples/sec; 0.022 sec/batch; 0h:01m:51s remains)
INFO - root - 2022-02-24 21:26:31.137599: step 194470, total loss = 0.50, batch loss = 0.24 (278.9 examples/sec; 0.029 sec/batch; 0h:02m:24s remains)
INFO - root - 2022-02-24 21:26:31.410482: step 194480, total loss = 0.62, batch loss = 0.36 (340.8 examples/sec; 0.023 sec/batch; 0h:01m:57s remains)
INFO - root - 2022-02-24 21:26:31.697479: step 194490, total loss = 0.55, batch loss = 0.30 (352.4 examples/sec; 0.023 sec/batch; 0h:01m:53s remains)
INFO - root - 2022-02-24 21:26:32.036088: step 194500, total loss = 0.55, batch loss = 0.29 (268.7 examples/sec; 0.030 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:26:32.508001: step 194510, total loss = 0.56, batch loss = 0.30 (203.9 examples/sec; 0.039 sec/batch; 0h:03m:15s remains)
INFO - root - 2022-02-24 21:26:32.955451: step 194520, total loss = 0.58, batch loss = 0.33 (99.0 examples/sec; 0.081 sec/batch; 0h:06m:42s remains)
INFO - root - 2022-02-24 21:26:33.235292: step 194530, total loss = 0.53, batch loss = 0.27 (322.4 examples/sec; 0.025 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:26:33.569502: step 194540, total loss = 0.48, batch loss = 0.22 (284.3 examples/sec; 0.028 sec/batch; 0h:02m:19s remains)
INFO - root - 2022-02-24 21:26:33.959716: step 194550, total loss = 0.56, batch loss = 0.31 (229.7 examples/sec; 0.035 sec/batch; 0h:02m:52s remains)
INFO - root - 2022-02-24 21:26:34.395722: step 194560, total loss = 0.56, batch loss = 0.30 (120.6 examples/sec; 0.066 sec/batch; 0h:05m:27s remains)
INFO - root - 2022-02-24 21:26:34.714031: step 194570, total loss = 0.64, batch loss = 0.38 (246.2 examples/sec; 0.032 sec/batch; 0h:02m:40s remains)
INFO - root - 2022-02-24 21:26:35.005909: step 194580, total loss = 0.46, batch loss = 0.21 (327.1 examples/sec; 0.024 sec/batch; 0h:02m:00s remains)
INFO - root - 2022-02-24 21:26:35.298442: step 194590, total loss = 0.53, batch loss = 0.27 (340.9 examples/sec; 0.023 sec/batch; 0h:01m:55s remains)
INFO - root - 2022-02-24 21:26:35.718981: step 194600, total loss = 0.59, batch loss = 0.34 (166.0 examples/sec; 0.048 sec/batch; 0h:03m:56s remains)
INFO - root - 2022-02-24 21:26:36.329451: step 194610, total loss = 0.55, batch loss = 0.29 (353.1 examples/sec; 0.023 sec/batch; 0h:01m:50s remains)
INFO - root - 2022-02-24 21:26:36.918349: step 194620, total loss = 0.64, batch loss = 0.39 (234.5 examples/sec; 0.034 sec/batch; 0h:02m:46s remains)
INFO - root - 2022-02-24 21:26:37.252087: step 194630, total loss = 0.54, batch loss = 0.28 (315.0 examples/sec; 0.025 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:26:37.557096: step 194640, total loss = 0.51, batch loss = 0.25 (338.1 examples/sec; 0.024 sec/batch; 0h:01m:54s remains)
INFO - root - 2022-02-24 21:26:37.874424: step 194650, total loss = 0.58, batch loss = 0.32 (148.6 examples/sec; 0.054 sec/batch; 0h:04m:21s remains)
INFO - root - 2022-02-24 21:26:38.204689: step 194660, total loss = 0.60, batch loss = 0.34 (255.0 examples/sec; 0.031 sec/batch; 0h:02m:31s remains)
INFO - root - 2022-02-24 21:26:38.552801: step 194670, total loss = 0.59, batch loss = 0.33 (154.7 examples/sec; 0.052 sec/batch; 0h:04m:09s remains)
INFO - root - 2022-02-24 21:26:38.913004: step 194680, total loss = 0.53, batch loss = 0.28 (195.0 examples/sec; 0.041 sec/batch; 0h:03m:17s remains)
INFO - root - 2022-02-24 21:26:39.211289: step 194690, total loss = 0.48, batch loss = 0.22 (164.5 examples/sec; 0.049 sec/batch; 0h:03m:53s remains)
INFO - root - 2022-02-24 21:26:39.497995: step 194700, total loss = 0.53, batch loss = 0.27 (264.0 examples/sec; 0.030 sec/batch; 0h:02m:25s remains)
INFO - root - 2022-02-24 21:26:39.834015: step 194710, total loss = 0.61, batch loss = 0.35 (344.3 examples/sec; 0.023 sec/batch; 0h:01m:51s remains)
INFO - root - 2022-02-24 21:26:40.153112: step 194720, total loss = 0.62, batch loss = 0.37 (147.8 examples/sec; 0.054 sec/batch; 0h:04m:18s remains)
INFO - root - 2022-02-24 21:26:40.580461: step 194730, total loss = 0.53, batch loss = 0.27 (246.5 examples/sec; 0.032 sec/batch; 0h:02m:34s remains)
INFO - root - 2022-02-24 21:26:40.931653: step 194740, total loss = 0.53, batch loss = 0.27 (148.4 examples/sec; 0.054 sec/batch; 0h:04m:16s remains)
INFO - root - 2022-02-24 21:26:41.258463: step 194750, total loss = 0.52, batch loss = 0.26 (311.2 examples/sec; 0.026 sec/batch; 0h:02m:02s remains)
INFO - root - 2022-02-24 21:26:41.560904: step 194760, total loss = 0.65, batch loss = 0.40 (336.6 examples/sec; 0.024 sec/batch; 0h:01m:52s remains)
INFO - root - 2022-02-24 21:26:41.874188: step 194770, total loss = 0.61, batch loss = 0.36 (202.9 examples/sec; 0.039 sec/batch; 0h:03m:06s remains)
INFO - root - 2022-02-24 21:26:42.158623: step 194780, total loss = 0.61, batch loss = 0.35 (350.5 examples/sec; 0.023 sec/batch; 0h:01m:47s remains)
INFO - root - 2022-02-24 21:26:42.550699: step 194790, total loss = 0.55, batch loss = 0.29 (154.6 examples/sec; 0.052 sec/batch; 0h:04m:03s remains)
INFO - root - 2022-02-24 21:26:42.880313: step 194800, total loss = 0.51, batch loss = 0.25 (155.8 examples/sec; 0.051 sec/batch; 0h:04m:01s remains)
INFO - root - 2022-02-24 21:26:43.284861: step 194810, total loss = 0.60, batch loss = 0.35 (356.7 examples/sec; 0.022 sec/batch; 0h:01m:45s remains)
INFO - root - 2022-02-24 21:26:43.577930: step 194820, total loss = 0.52, batch loss = 0.27 (343.7 examples/sec; 0.023 sec/batch; 0h:01m:48s remains)
INFO - root - 2022-02-24 21:26:43.962696: step 194830, total loss = 0.57, batch loss = 0.31 (332.1 examples/sec; 0.024 sec/batch; 0h:01m:52s remains)
INFO - root - 2022-02-24 21:26:44.219864: step 194840, total loss = 0.60, batch loss = 0.34 (231.3 examples/sec; 0.035 sec/batch; 0h:02m:41s remains)
INFO - root - 2022-02-24 21:26:44.511217: step 194850, total loss = 0.73, batch loss = 0.47 (334.3 examples/sec; 0.024 sec/batch; 0h:01m:51s remains)
INFO - root - 2022-02-24 21:26:44.930942: step 194860, total loss = 0.60, batch loss = 0.34 (221.3 examples/sec; 0.036 sec/batch; 0h:02m:47s remains)
INFO - root - 2022-02-24 21:26:45.278323: step 194870, total loss = 0.52, batch loss = 0.26 (191.0 examples/sec; 0.042 sec/batch; 0h:03m:13s remains)
INFO - root - 2022-02-24 21:26:45.686441: step 194880, total loss = 0.54, batch loss = 0.28 (316.4 examples/sec; 0.025 sec/batch; 0h:01m:56s remains)
INFO - root - 2022-02-24 21:26:45.968600: step 194890, total loss = 0.54, batch loss = 0.28 (346.3 examples/sec; 0.023 sec/batch; 0h:01m:46s remains)
INFO - root - 2022-02-24 21:26:46.213596: step 194900, total loss = 0.50, batch loss = 0.24 (348.7 examples/sec; 0.023 sec/batch; 0h:01m:45s remains)
INFO - root - 2022-02-24 21:26:46.591963: step 194910, total loss = 0.59, batch loss = 0.34 (202.9 examples/sec; 0.039 sec/batch; 0h:03m:00s remains)
INFO - root - 2022-02-24 21:26:46.975597: step 194920, total loss = 0.48, batch loss = 0.23 (222.7 examples/sec; 0.036 sec/batch; 0h:02m:44s remains)
INFO - root - 2022-02-24 21:26:47.421702: step 194930, total loss = 0.52, batch loss = 0.27 (180.3 examples/sec; 0.044 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:26:47.760936: step 194940, total loss = 0.53, batch loss = 0.27 (132.9 examples/sec; 0.060 sec/batch; 0h:04m:34s remains)
INFO - root - 2022-02-24 21:26:48.136754: step 194950, total loss = 0.53, batch loss = 0.27 (353.4 examples/sec; 0.023 sec/batch; 0h:01m:43s remains)
INFO - root - 2022-02-24 21:26:48.476615: step 194960, total loss = 0.57, batch loss = 0.32 (342.4 examples/sec; 0.023 sec/batch; 0h:01m:46s remains)
INFO - root - 2022-02-24 21:26:48.841938: step 194970, total loss = 0.61, batch loss = 0.35 (353.4 examples/sec; 0.023 sec/batch; 0h:01m:42s remains)
INFO - root - 2022-02-24 21:26:49.219482: step 194980, total loss = 0.52, batch loss = 0.26 (339.4 examples/sec; 0.024 sec/batch; 0h:01m:46s remains)
INFO - root - 2022-02-24 21:26:49.652488: step 194990, total loss = 0.52, batch loss = 0.26 (327.9 examples/sec; 0.024 sec/batch; 0h:01m:50s remains)
INFO - root - 2022-02-24 21:26:49.928406: step 195000, total loss = 0.57, batch loss = 0.31 (369.3 examples/sec; 0.022 sec/batch; 0h:01m:37s remains)
INFO - root - 2022-02-24 21:26:50.268733: step 195010, total loss = 0.50, batch loss = 0.25 (348.3 examples/sec; 0.023 sec/batch; 0h:01m:43s remains)
INFO - root - 2022-02-24 21:26:50.587365: step 195020, total loss = 0.55, batch loss = 0.29 (169.2 examples/sec; 0.047 sec/batch; 0h:03m:31s remains)
INFO - root - 2022-02-24 21:26:51.002679: step 195030, total loss = 0.57, batch loss = 0.31 (244.8 examples/sec; 0.033 sec/batch; 0h:02m:26s remains)
INFO - root - 2022-02-24 21:26:51.382122: step 195040, total loss = 0.63, batch loss = 0.37 (178.0 examples/sec; 0.045 sec/batch; 0h:03m:20s remains)
INFO - root - 2022-02-24 21:26:51.651407: step 195050, total loss = 0.48, batch loss = 0.22 (306.0 examples/sec; 0.026 sec/batch; 0h:01m:56s remains)
INFO - root - 2022-02-24 21:26:51.946192: step 195060, total loss = 0.51, batch loss = 0.25 (207.3 examples/sec; 0.039 sec/batch; 0h:02m:51s remains)
INFO - root - 2022-02-24 21:26:52.239357: step 195070, total loss = 0.68, batch loss = 0.42 (311.4 examples/sec; 0.026 sec/batch; 0h:01m:53s remains)
INFO - root - 2022-02-24 21:26:52.691708: step 195080, total loss = 0.56, batch loss = 0.30 (137.3 examples/sec; 0.058 sec/batch; 0h:04m:17s remains)
INFO - root - 2022-02-24 21:26:53.148456: step 195090, total loss = 0.58, batch loss = 0.33 (83.3 examples/sec; 0.096 sec/batch; 0h:07m:03s remains)
INFO - root - 2022-02-24 21:26:53.515146: step 195100, total loss = 0.55, batch loss = 0.29 (337.0 examples/sec; 0.024 sec/batch; 0h:01m:44s remains)
INFO - root - 2022-02-24 21:26:53.914859: step 195110, total loss = 0.46, batch loss = 0.21 (321.6 examples/sec; 0.025 sec/batch; 0h:01m:49s remains)
INFO - root - 2022-02-24 21:26:54.208245: step 195120, total loss = 0.55, batch loss = 0.29 (342.5 examples/sec; 0.023 sec/batch; 0h:01m:42s remains)
INFO - root - 2022-02-24 21:26:54.506296: step 195130, total loss = 0.56, batch loss = 0.30 (155.3 examples/sec; 0.052 sec/batch; 0h:03m:45s remains)
INFO - root - 2022-02-24 21:26:54.860107: step 195140, total loss = 0.66, batch loss = 0.40 (171.9 examples/sec; 0.047 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:26:55.219819: step 195150, total loss = 0.61, batch loss = 0.35 (217.3 examples/sec; 0.037 sec/batch; 0h:02m:40s remains)
INFO - root - 2022-02-24 21:26:55.516487: step 195160, total loss = 0.57, batch loss = 0.31 (269.8 examples/sec; 0.030 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:26:55.798763: step 195170, total loss = 0.54, batch loss = 0.29 (319.8 examples/sec; 0.025 sec/batch; 0h:01m:48s remains)
INFO - root - 2022-02-24 21:26:56.126045: step 195180, total loss = 0.48, batch loss = 0.22 (299.8 examples/sec; 0.027 sec/batch; 0h:01m:55s remains)
INFO - root - 2022-02-24 21:26:56.457142: step 195190, total loss = 0.63, batch loss = 0.37 (258.9 examples/sec; 0.031 sec/batch; 0h:02m:13s remains)
INFO - root - 2022-02-24 21:26:56.877569: step 195200, total loss = 0.56, batch loss = 0.30 (129.1 examples/sec; 0.062 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:26:57.348897: step 195210, total loss = 0.49, batch loss = 0.23 (134.9 examples/sec; 0.059 sec/batch; 0h:04m:14s remains)
INFO - root - 2022-02-24 21:26:57.621116: step 195220, total loss = 0.60, batch loss = 0.34 (311.9 examples/sec; 0.026 sec/batch; 0h:01m:49s remains)
INFO - root - 2022-02-24 21:26:57.888440: step 195230, total loss = 0.69, batch loss = 0.43 (332.8 examples/sec; 0.024 sec/batch; 0h:01m:42s remains)
INFO - root - 2022-02-24 21:26:58.183140: step 195240, total loss = 0.45, batch loss = 0.19 (182.2 examples/sec; 0.044 sec/batch; 0h:03m:07s remains)
INFO - root - 2022-02-24 21:26:58.547796: step 195250, total loss = 0.54, batch loss = 0.29 (179.1 examples/sec; 0.045 sec/batch; 0h:03m:09s remains)
INFO - root - 2022-02-24 21:26:58.839411: step 195260, total loss = 0.53, batch loss = 0.27 (325.9 examples/sec; 0.025 sec/batch; 0h:01m:44s remains)
INFO - root - 2022-02-24 21:26:59.199228: step 195270, total loss = 0.57, batch loss = 0.31 (351.6 examples/sec; 0.023 sec/batch; 0h:01m:36s remains)
INFO - root - 2022-02-24 21:26:59.484311: step 195280, total loss = 0.51, batch loss = 0.25 (287.5 examples/sec; 0.028 sec/batch; 0h:01m:57s remains)
INFO - root - 2022-02-24 21:26:59.825582: step 195290, total loss = 0.55, batch loss = 0.29 (325.6 examples/sec; 0.025 sec/batch; 0h:01m:43s remains)
INFO - root - 2022-02-24 21:27:00.136599: step 195300, total loss = 0.49, batch loss = 0.23 (179.1 examples/sec; 0.045 sec/batch; 0h:03m:07s remains)
INFO - root - 2022-02-24 21:27:00.557321: step 195310, total loss = 0.52, batch loss = 0.26 (228.6 examples/sec; 0.035 sec/batch; 0h:02m:26s remains)
INFO - root - 2022-02-24 21:27:00.949170: step 195320, total loss = 0.53, batch loss = 0.27 (192.5 examples/sec; 0.042 sec/batch; 0h:02m:53s remains)
INFO - root - 2022-02-24 21:27:01.362486: step 195330, total loss = 0.45, batch loss = 0.20 (231.6 examples/sec; 0.035 sec/batch; 0h:02m:24s remains)
INFO - root - 2022-02-24 21:27:01.665798: step 195340, total loss = 0.60, batch loss = 0.34 (353.2 examples/sec; 0.023 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:01.942610: step 195350, total loss = 0.48, batch loss = 0.23 (320.6 examples/sec; 0.025 sec/batch; 0h:01m:43s remains)
INFO - root - 2022-02-24 21:27:02.240697: step 195360, total loss = 0.54, batch loss = 0.28 (162.9 examples/sec; 0.049 sec/batch; 0h:03m:23s remains)
INFO - root - 2022-02-24 21:27:02.541871: step 195370, total loss = 0.54, batch loss = 0.29 (359.8 examples/sec; 0.022 sec/batch; 0h:01m:31s remains)
INFO - root - 2022-02-24 21:27:02.900632: step 195380, total loss = 0.54, batch loss = 0.28 (333.5 examples/sec; 0.024 sec/batch; 0h:01m:38s remains)
INFO - root - 2022-02-24 21:27:03.258967: step 195390, total loss = 0.56, batch loss = 0.30 (370.7 examples/sec; 0.022 sec/batch; 0h:01m:28s remains)
INFO - root - 2022-02-24 21:27:03.849337: step 195400, total loss = 0.52, batch loss = 0.27 (355.4 examples/sec; 0.023 sec/batch; 0h:01m:32s remains)
INFO - root - 2022-02-24 21:27:04.285523: step 195410, total loss = 0.53, batch loss = 0.27 (145.9 examples/sec; 0.055 sec/batch; 0h:03m:44s remains)
INFO - root - 2022-02-24 21:27:04.679086: step 195420, total loss = 0.54, batch loss = 0.29 (200.6 examples/sec; 0.040 sec/batch; 0h:02m:42s remains)
INFO - root - 2022-02-24 21:27:05.141878: step 195430, total loss = 0.47, batch loss = 0.22 (271.0 examples/sec; 0.030 sec/batch; 0h:02m:00s remains)
INFO - root - 2022-02-24 21:27:05.441540: step 195440, total loss = 0.56, batch loss = 0.30 (170.2 examples/sec; 0.047 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:27:05.888619: step 195450, total loss = 0.63, batch loss = 0.37 (341.6 examples/sec; 0.023 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:06.289421: step 195460, total loss = 0.46, batch loss = 0.21 (121.1 examples/sec; 0.066 sec/batch; 0h:04m:26s remains)
INFO - root - 2022-02-24 21:27:06.806128: step 195470, total loss = 0.67, batch loss = 0.42 (238.5 examples/sec; 0.034 sec/batch; 0h:02m:15s remains)
INFO - root - 2022-02-24 21:27:07.270555: step 195480, total loss = 0.59, batch loss = 0.33 (185.1 examples/sec; 0.043 sec/batch; 0h:02m:53s remains)
INFO - root - 2022-02-24 21:27:07.740114: step 195490, total loss = 0.54, batch loss = 0.28 (121.3 examples/sec; 0.066 sec/batch; 0h:04m:24s remains)
INFO - root - 2022-02-24 21:27:08.124563: step 195500, total loss = 0.48, batch loss = 0.23 (331.6 examples/sec; 0.024 sec/batch; 0h:01m:36s remains)
INFO - root - 2022-02-24 21:27:08.501854: step 195510, total loss = 0.57, batch loss = 0.31 (259.2 examples/sec; 0.031 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:27:09.329856: step 195520, total loss = 0.55, batch loss = 0.29 (339.4 examples/sec; 0.024 sec/batch; 0h:01m:33s remains)
INFO - root - 2022-02-24 21:27:09.750185: step 195530, total loss = 0.51, batch loss = 0.25 (380.8 examples/sec; 0.021 sec/batch; 0h:01m:23s remains)
INFO - root - 2022-02-24 21:27:10.264268: step 195540, total loss = 0.49, batch loss = 0.23 (321.1 examples/sec; 0.025 sec/batch; 0h:01m:38s remains)
INFO - root - 2022-02-24 21:27:10.533556: step 195550, total loss = 0.59, batch loss = 0.33 (322.8 examples/sec; 0.025 sec/batch; 0h:01m:37s remains)
INFO - root - 2022-02-24 21:27:10.821607: step 195560, total loss = 0.45, batch loss = 0.20 (217.6 examples/sec; 0.037 sec/batch; 0h:02m:24s remains)
INFO - root - 2022-02-24 21:27:11.084810: step 195570, total loss = 0.62, batch loss = 0.36 (337.3 examples/sec; 0.024 sec/batch; 0h:01m:33s remains)
INFO - root - 2022-02-24 21:27:11.494207: step 195580, total loss = 0.42, batch loss = 0.16 (170.8 examples/sec; 0.047 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:27:11.879838: step 195590, total loss = 0.69, batch loss = 0.44 (341.4 examples/sec; 0.023 sec/batch; 0h:01m:31s remains)
INFO - root - 2022-02-24 21:27:12.255975: step 195600, total loss = 0.50, batch loss = 0.25 (342.9 examples/sec; 0.023 sec/batch; 0h:01m:30s remains)
INFO - root - 2022-02-24 21:27:12.613113: step 195610, total loss = 0.47, batch loss = 0.21 (329.8 examples/sec; 0.024 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:12.890793: step 195620, total loss = 0.48, batch loss = 0.22 (209.2 examples/sec; 0.038 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:27:13.170493: step 195630, total loss = 0.63, batch loss = 0.37 (340.7 examples/sec; 0.023 sec/batch; 0h:01m:30s remains)
INFO - root - 2022-02-24 21:27:13.491773: step 195640, total loss = 0.53, batch loss = 0.28 (224.2 examples/sec; 0.036 sec/batch; 0h:02m:17s remains)
INFO - root - 2022-02-24 21:27:13.821226: step 195650, total loss = 0.52, batch loss = 0.27 (339.0 examples/sec; 0.024 sec/batch; 0h:01m:30s remains)
INFO - root - 2022-02-24 21:27:14.250729: step 195660, total loss = 0.68, batch loss = 0.42 (315.8 examples/sec; 0.025 sec/batch; 0h:01m:37s remains)
INFO - root - 2022-02-24 21:27:14.584348: step 195670, total loss = 0.49, batch loss = 0.23 (360.1 examples/sec; 0.022 sec/batch; 0h:01m:25s remains)
INFO - root - 2022-02-24 21:27:14.870939: step 195680, total loss = 0.52, batch loss = 0.26 (353.0 examples/sec; 0.023 sec/batch; 0h:01m:26s remains)
INFO - root - 2022-02-24 21:27:15.135025: step 195690, total loss = 0.50, batch loss = 0.24 (321.4 examples/sec; 0.025 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:15.457792: step 195700, total loss = 0.60, batch loss = 0.34 (201.5 examples/sec; 0.040 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:27:15.920382: step 195710, total loss = 0.48, batch loss = 0.22 (136.8 examples/sec; 0.058 sec/batch; 0h:03m:41s remains)
INFO - root - 2022-02-24 21:27:16.243543: step 195720, total loss = 0.51, batch loss = 0.26 (354.3 examples/sec; 0.023 sec/batch; 0h:01m:25s remains)
INFO - root - 2022-02-24 21:27:16.536790: step 195730, total loss = 0.51, batch loss = 0.25 (371.3 examples/sec; 0.022 sec/batch; 0h:01m:21s remains)
INFO - root - 2022-02-24 21:27:16.834701: step 195740, total loss = 0.60, batch loss = 0.34 (326.0 examples/sec; 0.025 sec/batch; 0h:01m:32s remains)
INFO - root - 2022-02-24 21:27:17.109152: step 195750, total loss = 0.54, batch loss = 0.28 (326.2 examples/sec; 0.025 sec/batch; 0h:01m:31s remains)
INFO - root - 2022-02-24 21:27:17.440049: step 195760, total loss = 0.58, batch loss = 0.32 (295.9 examples/sec; 0.027 sec/batch; 0h:01m:41s remains)
INFO - root - 2022-02-24 21:27:17.733320: step 195770, total loss = 0.63, batch loss = 0.37 (346.4 examples/sec; 0.023 sec/batch; 0h:01m:26s remains)
INFO - root - 2022-02-24 21:27:18.161306: step 195780, total loss = 0.49, batch loss = 0.23 (209.4 examples/sec; 0.038 sec/batch; 0h:02m:22s remains)
INFO - root - 2022-02-24 21:27:18.515790: step 195790, total loss = 0.52, batch loss = 0.27 (197.1 examples/sec; 0.041 sec/batch; 0h:02m:30s remains)
INFO - root - 2022-02-24 21:27:18.830280: step 195800, total loss = 0.56, batch loss = 0.30 (264.4 examples/sec; 0.030 sec/batch; 0h:01m:51s remains)
INFO - root - 2022-02-24 21:27:19.263863: step 195810, total loss = 0.60, batch loss = 0.34 (228.0 examples/sec; 0.035 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:27:19.655136: step 195820, total loss = 0.63, batch loss = 0.38 (171.1 examples/sec; 0.047 sec/batch; 0h:02m:52s remains)
INFO - root - 2022-02-24 21:27:20.060872: step 195830, total loss = 0.48, batch loss = 0.23 (283.3 examples/sec; 0.028 sec/batch; 0h:01m:43s remains)
INFO - root - 2022-02-24 21:27:20.395764: step 195840, total loss = 0.45, batch loss = 0.20 (168.0 examples/sec; 0.048 sec/batch; 0h:02m:54s remains)
INFO - root - 2022-02-24 21:27:20.695008: step 195850, total loss = 0.64, batch loss = 0.39 (92.0 examples/sec; 0.087 sec/batch; 0h:05m:17s remains)
INFO - root - 2022-02-24 21:27:21.011983: step 195860, total loss = 0.55, batch loss = 0.30 (347.6 examples/sec; 0.023 sec/batch; 0h:01m:23s remains)
INFO - root - 2022-02-24 21:27:21.422753: step 195870, total loss = 0.55, batch loss = 0.29 (158.5 examples/sec; 0.050 sec/batch; 0h:03m:03s remains)
INFO - root - 2022-02-24 21:27:21.909050: step 195880, total loss = 0.51, batch loss = 0.26 (334.0 examples/sec; 0.024 sec/batch; 0h:01m:26s remains)
INFO - root - 2022-02-24 21:27:22.264089: step 195890, total loss = 0.61, batch loss = 0.35 (361.2 examples/sec; 0.022 sec/batch; 0h:01m:19s remains)
INFO - root - 2022-02-24 21:27:22.608199: step 195900, total loss = 0.60, batch loss = 0.35 (87.5 examples/sec; 0.091 sec/batch; 0h:05m:29s remains)
INFO - root - 2022-02-24 21:27:22.985391: step 195910, total loss = 0.45, batch loss = 0.19 (350.3 examples/sec; 0.023 sec/batch; 0h:01m:21s remains)
INFO - root - 2022-02-24 21:27:23.478347: step 195920, total loss = 0.57, batch loss = 0.31 (223.2 examples/sec; 0.036 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:27:23.924683: step 195930, total loss = 0.45, batch loss = 0.20 (313.6 examples/sec; 0.026 sec/batch; 0h:01m:31s remains)
INFO - root - 2022-02-24 21:27:24.293611: step 195940, total loss = 0.48, batch loss = 0.23 (384.6 examples/sec; 0.021 sec/batch; 0h:01m:14s remains)
INFO - root - 2022-02-24 21:27:24.621391: step 195950, total loss = 0.59, batch loss = 0.33 (115.1 examples/sec; 0.069 sec/batch; 0h:04m:06s remains)
INFO - root - 2022-02-24 21:27:24.918530: step 195960, total loss = 0.53, batch loss = 0.27 (311.4 examples/sec; 0.026 sec/batch; 0h:01m:30s remains)
INFO - root - 2022-02-24 21:27:25.162385: step 195970, total loss = 0.59, batch loss = 0.34 (362.5 examples/sec; 0.022 sec/batch; 0h:01m:17s remains)
INFO - root - 2022-02-24 21:27:25.485052: step 195980, total loss = 0.55, batch loss = 0.30 (274.0 examples/sec; 0.029 sec/batch; 0h:01m:42s remains)
INFO - root - 2022-02-24 21:27:25.901288: step 195990, total loss = 0.51, batch loss = 0.25 (233.0 examples/sec; 0.034 sec/batch; 0h:02m:00s remains)
INFO - root - 2022-02-24 21:27:26.180774: step 196000, total loss = 0.57, batch loss = 0.31 (301.0 examples/sec; 0.027 sec/batch; 0h:01m:33s remains)
INFO - root - 2022-02-24 21:27:26.609562: step 196010, total loss = 0.58, batch loss = 0.32 (312.0 examples/sec; 0.026 sec/batch; 0h:01m:29s remains)
INFO - root - 2022-02-24 21:27:26.973826: step 196020, total loss = 0.49, batch loss = 0.23 (168.7 examples/sec; 0.047 sec/batch; 0h:02m:45s remains)
INFO - root - 2022-02-24 21:27:27.376326: step 196030, total loss = 0.55, batch loss = 0.30 (273.9 examples/sec; 0.029 sec/batch; 0h:01m:41s remains)
INFO - root - 2022-02-24 21:27:27.871901: step 196040, total loss = 0.60, batch loss = 0.34 (244.9 examples/sec; 0.033 sec/batch; 0h:01m:53s remains)
INFO - root - 2022-02-24 21:27:28.220969: step 196050, total loss = 0.49, batch loss = 0.24 (369.0 examples/sec; 0.022 sec/batch; 0h:01m:14s remains)
INFO - root - 2022-02-24 21:27:28.611942: step 196060, total loss = 0.59, batch loss = 0.34 (288.2 examples/sec; 0.028 sec/batch; 0h:01m:35s remains)
INFO - root - 2022-02-24 21:27:28.935081: step 196070, total loss = 0.56, batch loss = 0.30 (317.5 examples/sec; 0.025 sec/batch; 0h:01m:26s remains)
INFO - root - 2022-02-24 21:27:29.355948: step 196080, total loss = 0.63, batch loss = 0.37 (107.5 examples/sec; 0.074 sec/batch; 0h:04m:14s remains)
INFO - root - 2022-02-24 21:27:29.834871: step 196090, total loss = 0.60, batch loss = 0.34 (278.7 examples/sec; 0.029 sec/batch; 0h:01m:37s remains)
INFO - root - 2022-02-24 21:27:30.191887: step 196100, total loss = 0.56, batch loss = 0.31 (343.8 examples/sec; 0.023 sec/batch; 0h:01m:19s remains)
INFO - root - 2022-02-24 21:27:30.582148: step 196110, total loss = 0.57, batch loss = 0.31 (329.6 examples/sec; 0.024 sec/batch; 0h:01m:22s remains)
INFO - root - 2022-02-24 21:27:30.866538: step 196120, total loss = 0.63, batch loss = 0.37 (148.8 examples/sec; 0.054 sec/batch; 0h:03m:01s remains)
INFO - root - 2022-02-24 21:27:31.204133: step 196130, total loss = 0.47, batch loss = 0.21 (218.2 examples/sec; 0.037 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:27:31.601639: step 196140, total loss = 0.56, batch loss = 0.30 (270.9 examples/sec; 0.030 sec/batch; 0h:01m:39s remains)
INFO - root - 2022-02-24 21:27:32.005432: step 196150, total loss = 0.47, batch loss = 0.21 (347.0 examples/sec; 0.023 sec/batch; 0h:01m:17s remains)
INFO - root - 2022-02-24 21:27:32.334588: step 196160, total loss = 0.54, batch loss = 0.28 (131.9 examples/sec; 0.061 sec/batch; 0h:03m:22s remains)
INFO - root - 2022-02-24 21:27:32.625072: step 196170, total loss = 0.58, batch loss = 0.32 (228.3 examples/sec; 0.035 sec/batch; 0h:01m:56s remains)
INFO - root - 2022-02-24 21:27:32.916721: step 196180, total loss = 0.69, batch loss = 0.43 (360.8 examples/sec; 0.022 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:27:33.187480: step 196190, total loss = 0.42, batch loss = 0.17 (280.4 examples/sec; 0.029 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:33.544065: step 196200, total loss = 0.56, batch loss = 0.30 (205.9 examples/sec; 0.039 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:27:33.908353: step 196210, total loss = 0.45, batch loss = 0.20 (347.8 examples/sec; 0.023 sec/batch; 0h:01m:15s remains)
INFO - root - 2022-02-24 21:27:34.297574: step 196220, total loss = 0.51, batch loss = 0.26 (281.6 examples/sec; 0.028 sec/batch; 0h:01m:33s remains)
INFO - root - 2022-02-24 21:27:34.699484: step 196230, total loss = 0.47, batch loss = 0.22 (213.4 examples/sec; 0.037 sec/batch; 0h:02m:02s remains)
INFO - root - 2022-02-24 21:27:35.059776: step 196240, total loss = 0.46, batch loss = 0.21 (334.2 examples/sec; 0.024 sec/batch; 0h:01m:18s remains)
INFO - root - 2022-02-24 21:27:35.389769: step 196250, total loss = 0.62, batch loss = 0.37 (290.7 examples/sec; 0.028 sec/batch; 0h:01m:29s remains)
INFO - root - 2022-02-24 21:27:35.641228: step 196260, total loss = 0.52, batch loss = 0.26 (328.9 examples/sec; 0.024 sec/batch; 0h:01m:18s remains)
INFO - root - 2022-02-24 21:27:35.962428: step 196270, total loss = 0.54, batch loss = 0.29 (325.3 examples/sec; 0.025 sec/batch; 0h:01m:19s remains)
INFO - root - 2022-02-24 21:27:36.370437: step 196280, total loss = 0.48, batch loss = 0.22 (267.8 examples/sec; 0.030 sec/batch; 0h:01m:36s remains)
INFO - root - 2022-02-24 21:27:36.698407: step 196290, total loss = 0.52, batch loss = 0.26 (172.5 examples/sec; 0.046 sec/batch; 0h:02m:28s remains)
INFO - root - 2022-02-24 21:27:37.090321: step 196300, total loss = 0.59, batch loss = 0.34 (201.7 examples/sec; 0.040 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:27:37.457399: step 196310, total loss = 0.56, batch loss = 0.31 (215.0 examples/sec; 0.037 sec/batch; 0h:01m:58s remains)
INFO - root - 2022-02-24 21:27:37.802886: step 196320, total loss = 0.53, batch loss = 0.27 (358.8 examples/sec; 0.022 sec/batch; 0h:01m:10s remains)
INFO - root - 2022-02-24 21:27:38.187716: step 196330, total loss = 0.52, batch loss = 0.26 (136.1 examples/sec; 0.059 sec/batch; 0h:03m:06s remains)
INFO - root - 2022-02-24 21:27:38.495866: step 196340, total loss = 0.50, batch loss = 0.24 (363.9 examples/sec; 0.022 sec/batch; 0h:01m:09s remains)
INFO - root - 2022-02-24 21:27:38.772876: step 196350, total loss = 0.55, batch loss = 0.30 (349.1 examples/sec; 0.023 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:27:39.167256: step 196360, total loss = 0.58, batch loss = 0.33 (174.1 examples/sec; 0.046 sec/batch; 0h:02m:24s remains)
INFO - root - 2022-02-24 21:27:39.619875: step 196370, total loss = 0.51, batch loss = 0.25 (157.9 examples/sec; 0.051 sec/batch; 0h:02m:38s remains)
INFO - root - 2022-02-24 21:27:40.564449: step 196380, total loss = 0.54, batch loss = 0.29 (345.1 examples/sec; 0.023 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:27:40.942840: step 196390, total loss = 0.53, batch loss = 0.27 (202.0 examples/sec; 0.040 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:27:41.331416: step 196400, total loss = 0.49, batch loss = 0.23 (298.7 examples/sec; 0.027 sec/batch; 0h:01m:23s remains)
INFO - root - 2022-02-24 21:27:41.753374: step 196410, total loss = 0.52, batch loss = 0.26 (344.8 examples/sec; 0.023 sec/batch; 0h:01m:11s remains)
INFO - root - 2022-02-24 21:27:42.101413: step 196420, total loss = 0.50, batch loss = 0.25 (333.2 examples/sec; 0.024 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:27:42.444963: step 196430, total loss = 0.57, batch loss = 0.32 (183.5 examples/sec; 0.044 sec/batch; 0h:02m:13s remains)
INFO - root - 2022-02-24 21:27:42.976377: step 196440, total loss = 0.56, batch loss = 0.31 (155.1 examples/sec; 0.052 sec/batch; 0h:02m:37s remains)
INFO - root - 2022-02-24 21:27:43.327571: step 196450, total loss = 0.58, batch loss = 0.32 (339.2 examples/sec; 0.024 sec/batch; 0h:01m:11s remains)
INFO - root - 2022-02-24 21:27:43.768836: step 196460, total loss = 0.53, batch loss = 0.28 (294.7 examples/sec; 0.027 sec/batch; 0h:01m:22s remains)
INFO - root - 2022-02-24 21:27:44.100294: step 196470, total loss = 0.55, batch loss = 0.29 (304.8 examples/sec; 0.026 sec/batch; 0h:01m:19s remains)
INFO - root - 2022-02-24 21:27:44.472471: step 196480, total loss = 0.57, batch loss = 0.32 (129.8 examples/sec; 0.062 sec/batch; 0h:03m:06s remains)
INFO - root - 2022-02-24 21:27:44.851575: step 196490, total loss = 0.54, batch loss = 0.28 (101.6 examples/sec; 0.079 sec/batch; 0h:03m:57s remains)
INFO - root - 2022-02-24 21:27:45.564089: step 196500, total loss = 0.52, batch loss = 0.27 (217.0 examples/sec; 0.037 sec/batch; 0h:01m:50s remains)
INFO - root - 2022-02-24 21:27:45.985453: step 196510, total loss = 0.54, batch loss = 0.28 (110.6 examples/sec; 0.072 sec/batch; 0h:03m:36s remains)
INFO - root - 2022-02-24 21:27:46.329286: step 196520, total loss = 0.56, batch loss = 0.30 (201.4 examples/sec; 0.040 sec/batch; 0h:01m:58s remains)
INFO - root - 2022-02-24 21:27:46.657611: step 196530, total loss = 0.55, batch loss = 0.29 (220.3 examples/sec; 0.036 sec/batch; 0h:01m:47s remains)
INFO - root - 2022-02-24 21:27:46.939958: step 196540, total loss = 0.50, batch loss = 0.24 (195.5 examples/sec; 0.041 sec/batch; 0h:02m:01s remains)
INFO - root - 2022-02-24 21:27:47.212176: step 196550, total loss = 0.60, batch loss = 0.35 (333.6 examples/sec; 0.024 sec/batch; 0h:01m:10s remains)
INFO - root - 2022-02-24 21:27:47.604558: step 196560, total loss = 0.61, batch loss = 0.35 (329.9 examples/sec; 0.024 sec/batch; 0h:01m:11s remains)
INFO - root - 2022-02-24 21:27:47.942605: step 196570, total loss = 0.58, batch loss = 0.32 (123.2 examples/sec; 0.065 sec/batch; 0h:03m:10s remains)
INFO - root - 2022-02-24 21:27:48.352694: step 196580, total loss = 0.58, batch loss = 0.32 (386.6 examples/sec; 0.021 sec/batch; 0h:01m:00s remains)
INFO - root - 2022-02-24 21:27:48.726583: step 196590, total loss = 0.58, batch loss = 0.33 (320.8 examples/sec; 0.025 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:27:49.044067: step 196600, total loss = 0.57, batch loss = 0.32 (147.8 examples/sec; 0.054 sec/batch; 0h:02m:36s remains)
INFO - root - 2022-02-24 21:27:49.416842: step 196610, total loss = 0.49, batch loss = 0.24 (349.0 examples/sec; 0.023 sec/batch; 0h:01m:06s remains)
INFO - root - 2022-02-24 21:27:49.690576: step 196620, total loss = 0.50, batch loss = 0.25 (166.7 examples/sec; 0.048 sec/batch; 0h:02m:18s remains)
INFO - root - 2022-02-24 21:27:50.081677: step 196630, total loss = 0.52, batch loss = 0.26 (347.8 examples/sec; 0.023 sec/batch; 0h:01m:06s remains)
INFO - root - 2022-02-24 21:27:50.423647: step 196640, total loss = 0.51, batch loss = 0.25 (189.4 examples/sec; 0.042 sec/batch; 0h:02m:00s remains)
INFO - root - 2022-02-24 21:27:50.748493: step 196650, total loss = 0.58, batch loss = 0.32 (241.6 examples/sec; 0.033 sec/batch; 0h:01m:34s remains)
INFO - root - 2022-02-24 21:27:51.017856: step 196660, total loss = 0.62, batch loss = 0.36 (351.7 examples/sec; 0.023 sec/batch; 0h:01m:04s remains)
INFO - root - 2022-02-24 21:27:51.297034: step 196670, total loss = 0.54, batch loss = 0.29 (255.1 examples/sec; 0.031 sec/batch; 0h:01m:28s remains)
INFO - root - 2022-02-24 21:27:51.570997: step 196680, total loss = 0.46, batch loss = 0.20 (321.2 examples/sec; 0.025 sec/batch; 0h:01m:10s remains)
INFO - root - 2022-02-24 21:27:51.920094: step 196690, total loss = 0.57, batch loss = 0.31 (253.4 examples/sec; 0.032 sec/batch; 0h:01m:28s remains)
INFO - root - 2022-02-24 21:27:52.344254: step 196700, total loss = 0.48, batch loss = 0.22 (192.2 examples/sec; 0.042 sec/batch; 0h:01m:56s remains)
INFO - root - 2022-02-24 21:27:52.727384: step 196710, total loss = 0.43, batch loss = 0.18 (365.2 examples/sec; 0.022 sec/batch; 0h:01m:01s remains)
INFO - root - 2022-02-24 21:27:53.090310: step 196720, total loss = 0.56, batch loss = 0.30 (254.1 examples/sec; 0.031 sec/batch; 0h:01m:27s remains)
INFO - root - 2022-02-24 21:27:53.387916: step 196730, total loss = 0.54, batch loss = 0.28 (338.8 examples/sec; 0.024 sec/batch; 0h:01m:05s remains)
INFO - root - 2022-02-24 21:27:53.633293: step 196740, total loss = 0.66, batch loss = 0.41 (333.1 examples/sec; 0.024 sec/batch; 0h:01m:06s remains)
INFO - root - 2022-02-24 21:27:53.992684: step 196750, total loss = 0.61, batch loss = 0.35 (201.1 examples/sec; 0.040 sec/batch; 0h:01m:49s remains)
INFO - root - 2022-02-24 21:27:54.307978: step 196760, total loss = 0.53, batch loss = 0.27 (331.0 examples/sec; 0.024 sec/batch; 0h:01m:06s remains)
INFO - root - 2022-02-24 21:27:54.701702: step 196770, total loss = 0.67, batch loss = 0.42 (314.1 examples/sec; 0.025 sec/batch; 0h:01m:09s remains)
INFO - root - 2022-02-24 21:27:55.104481: step 196780, total loss = 0.54, batch loss = 0.29 (317.3 examples/sec; 0.025 sec/batch; 0h:01m:08s remains)
INFO - root - 2022-02-24 21:27:55.403522: step 196790, total loss = 0.57, batch loss = 0.31 (189.0 examples/sec; 0.042 sec/batch; 0h:01m:54s remains)
INFO - root - 2022-02-24 21:27:55.700584: step 196800, total loss = 0.54, batch loss = 0.28 (299.8 examples/sec; 0.027 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:27:56.115733: step 196810, total loss = 0.62, batch loss = 0.37 (296.4 examples/sec; 0.027 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:27:56.421721: step 196820, total loss = 0.51, batch loss = 0.26 (149.1 examples/sec; 0.054 sec/batch; 0h:02m:23s remains)
INFO - root - 2022-02-24 21:27:56.825943: step 196830, total loss = 0.51, batch loss = 0.25 (230.7 examples/sec; 0.035 sec/batch; 0h:01m:32s remains)
INFO - root - 2022-02-24 21:27:57.159095: step 196840, total loss = 0.50, batch loss = 0.25 (359.9 examples/sec; 0.022 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:27:57.459179: step 196850, total loss = 0.55, batch loss = 0.29 (187.3 examples/sec; 0.043 sec/batch; 0h:01m:53s remains)
INFO - root - 2022-02-24 21:27:57.784120: step 196860, total loss = 0.51, batch loss = 0.26 (185.1 examples/sec; 0.043 sec/batch; 0h:01m:54s remains)
INFO - root - 2022-02-24 21:27:58.137914: step 196870, total loss = 0.53, batch loss = 0.28 (122.2 examples/sec; 0.065 sec/batch; 0h:02m:52s remains)
INFO - root - 2022-02-24 21:27:58.508078: step 196880, total loss = 0.57, batch loss = 0.32 (307.2 examples/sec; 0.026 sec/batch; 0h:01m:08s remains)
INFO - root - 2022-02-24 21:27:58.905831: step 196890, total loss = 0.58, batch loss = 0.32 (348.5 examples/sec; 0.023 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:27:59.299250: step 196900, total loss = 0.52, batch loss = 0.26 (335.4 examples/sec; 0.024 sec/batch; 0h:01m:02s remains)
INFO - root - 2022-02-24 21:27:59.643053: step 196910, total loss = 0.57, batch loss = 0.32 (332.2 examples/sec; 0.024 sec/batch; 0h:01m:02s remains)
INFO - root - 2022-02-24 21:27:59.922459: step 196920, total loss = 0.51, batch loss = 0.25 (280.5 examples/sec; 0.029 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:28:00.252918: step 196930, total loss = 0.53, batch loss = 0.27 (295.7 examples/sec; 0.027 sec/batch; 0h:01m:09s remains)
INFO - root - 2022-02-24 21:28:00.715631: step 196940, total loss = 0.57, batch loss = 0.31 (314.2 examples/sec; 0.025 sec/batch; 0h:01m:05s remains)
INFO - root - 2022-02-24 21:28:01.108590: step 196950, total loss = 0.61, batch loss = 0.35 (316.4 examples/sec; 0.025 sec/batch; 0h:01m:04s remains)
INFO - root - 2022-02-24 21:28:01.410851: step 196960, total loss = 0.58, batch loss = 0.32 (279.4 examples/sec; 0.029 sec/batch; 0h:01m:12s remains)
INFO - root - 2022-02-24 21:28:01.666873: step 196970, total loss = 0.59, batch loss = 0.34 (322.8 examples/sec; 0.025 sec/batch; 0h:01m:02s remains)
INFO - root - 2022-02-24 21:28:01.951933: step 196980, total loss = 0.58, batch loss = 0.32 (326.9 examples/sec; 0.024 sec/batch; 0h:01m:01s remains)
INFO - root - 2022-02-24 21:28:02.240954: step 196990, total loss = 0.56, batch loss = 0.31 (328.0 examples/sec; 0.024 sec/batch; 0h:01m:01s remains)
INFO - root - 2022-02-24 21:28:02.605413: step 197000, total loss = 0.47, batch loss = 0.22 (346.4 examples/sec; 0.023 sec/batch; 0h:00m:57s remains)
INFO - root - 2022-02-24 21:28:03.001656: step 197010, total loss = 0.42, batch loss = 0.16 (308.3 examples/sec; 0.026 sec/batch; 0h:01m:04s remains)
INFO - root - 2022-02-24 21:28:03.389560: step 197020, total loss = 0.57, batch loss = 0.31 (226.0 examples/sec; 0.035 sec/batch; 0h:01m:27s remains)
INFO - root - 2022-02-24 21:28:03.719288: step 197030, total loss = 0.60, batch loss = 0.34 (234.4 examples/sec; 0.034 sec/batch; 0h:01m:24s remains)
INFO - root - 2022-02-24 21:28:04.005534: step 197040, total loss = 0.51, batch loss = 0.25 (119.1 examples/sec; 0.067 sec/batch; 0h:02m:45s remains)
INFO - root - 2022-02-24 21:28:04.286913: step 197050, total loss = 0.54, batch loss = 0.28 (346.7 examples/sec; 0.023 sec/batch; 0h:00m:56s remains)
INFO - root - 2022-02-24 21:28:04.645859: step 197060, total loss = 0.52, batch loss = 0.26 (240.6 examples/sec; 0.033 sec/batch; 0h:01m:21s remains)
INFO - root - 2022-02-24 21:28:05.091433: step 197070, total loss = 0.59, batch loss = 0.33 (151.6 examples/sec; 0.053 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:28:05.422991: step 197080, total loss = 0.53, batch loss = 0.27 (236.1 examples/sec; 0.034 sec/batch; 0h:01m:21s remains)
INFO - root - 2022-02-24 21:28:05.726489: step 197090, total loss = 0.51, batch loss = 0.25 (331.5 examples/sec; 0.024 sec/batch; 0h:00m:58s remains)
INFO - root - 2022-02-24 21:28:06.016816: step 197100, total loss = 0.64, batch loss = 0.39 (207.8 examples/sec; 0.039 sec/batch; 0h:01m:32s remains)
INFO - root - 2022-02-24 21:28:06.359128: step 197110, total loss = 0.55, batch loss = 0.29 (341.2 examples/sec; 0.023 sec/batch; 0h:00m:56s remains)
INFO - root - 2022-02-24 21:28:06.765743: step 197120, total loss = 0.45, batch loss = 0.20 (150.5 examples/sec; 0.053 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:28:07.137877: step 197130, total loss = 0.50, batch loss = 0.24 (286.7 examples/sec; 0.028 sec/batch; 0h:01m:06s remains)
INFO - root - 2022-02-24 21:28:07.406857: step 197140, total loss = 0.45, batch loss = 0.20 (326.3 examples/sec; 0.025 sec/batch; 0h:00m:57s remains)
INFO - root - 2022-02-24 21:28:07.730543: step 197150, total loss = 0.61, batch loss = 0.35 (146.0 examples/sec; 0.055 sec/batch; 0h:02m:08s remains)
INFO - root - 2022-02-24 21:28:08.040820: step 197160, total loss = 0.69, batch loss = 0.44 (363.4 examples/sec; 0.022 sec/batch; 0h:00m:51s remains)
INFO - root - 2022-02-24 21:28:08.344395: step 197170, total loss = 0.64, batch loss = 0.39 (273.4 examples/sec; 0.029 sec/batch; 0h:01m:08s remains)
INFO - root - 2022-02-24 21:28:08.746880: step 197180, total loss = 0.46, batch loss = 0.21 (143.3 examples/sec; 0.056 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:28:09.161888: step 197190, total loss = 0.47, batch loss = 0.21 (184.9 examples/sec; 0.043 sec/batch; 0h:01m:39s remains)
INFO - root - 2022-02-24 21:28:09.514383: step 197200, total loss = 0.46, batch loss = 0.20 (265.3 examples/sec; 0.030 sec/batch; 0h:01m:09s remains)
INFO - root - 2022-02-24 21:28:09.854663: step 197210, total loss = 0.53, batch loss = 0.28 (326.2 examples/sec; 0.025 sec/batch; 0h:00m:56s remains)
INFO - root - 2022-02-24 21:28:10.094079: step 197220, total loss = 0.59, batch loss = 0.33 (331.5 examples/sec; 0.024 sec/batch; 0h:00m:55s remains)
INFO - root - 2022-02-24 21:28:10.392987: step 197230, total loss = 0.67, batch loss = 0.42 (256.2 examples/sec; 0.031 sec/batch; 0h:01m:10s remains)
INFO - root - 2022-02-24 21:28:10.704267: step 197240, total loss = 0.58, batch loss = 0.32 (167.2 examples/sec; 0.048 sec/batch; 0h:01m:48s remains)
INFO - root - 2022-02-24 21:28:11.134139: step 197250, total loss = 0.63, batch loss = 0.37 (362.1 examples/sec; 0.022 sec/batch; 0h:00m:49s remains)
INFO - root - 2022-02-24 21:28:11.573226: step 197260, total loss = 0.47, batch loss = 0.22 (143.5 examples/sec; 0.056 sec/batch; 0h:02m:04s remains)
INFO - root - 2022-02-24 21:28:11.932052: step 197270, total loss = 0.52, batch loss = 0.26 (227.2 examples/sec; 0.035 sec/batch; 0h:01m:18s remains)
INFO - root - 2022-02-24 21:28:12.268459: step 197280, total loss = 0.51, batch loss = 0.25 (269.9 examples/sec; 0.030 sec/batch; 0h:01m:05s remains)
INFO - root - 2022-02-24 21:28:12.549318: step 197290, total loss = 0.57, batch loss = 0.32 (324.9 examples/sec; 0.025 sec/batch; 0h:00m:54s remains)
INFO - root - 2022-02-24 21:28:12.873331: step 197300, total loss = 0.51, batch loss = 0.26 (141.6 examples/sec; 0.057 sec/batch; 0h:02m:04s remains)
INFO - root - 2022-02-24 21:28:13.414916: step 197310, total loss = 0.62, batch loss = 0.36 (118.5 examples/sec; 0.067 sec/batch; 0h:02m:27s remains)
INFO - root - 2022-02-24 21:28:13.778877: step 197320, total loss = 0.57, batch loss = 0.31 (291.7 examples/sec; 0.027 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:28:14.130974: step 197330, total loss = 0.50, batch loss = 0.24 (322.5 examples/sec; 0.025 sec/batch; 0h:00m:53s remains)
INFO - root - 2022-02-24 21:28:14.550811: step 197340, total loss = 0.57, batch loss = 0.31 (59.9 examples/sec; 0.134 sec/batch; 0h:04m:48s remains)
INFO - root - 2022-02-24 21:28:14.968315: step 197350, total loss = 0.63, batch loss = 0.37 (91.0 examples/sec; 0.088 sec/batch; 0h:03m:09s remains)
INFO - root - 2022-02-24 21:28:15.353109: step 197360, total loss = 0.56, batch loss = 0.31 (359.9 examples/sec; 0.022 sec/batch; 0h:00m:47s remains)
INFO - root - 2022-02-24 21:28:16.342230: step 197370, total loss = 0.70, batch loss = 0.44 (134.4 examples/sec; 0.060 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:28:16.689058: step 197380, total loss = 0.80, batch loss = 0.54 (142.9 examples/sec; 0.056 sec/batch; 0h:01m:58s remains)
INFO - root - 2022-02-24 21:28:17.005907: step 197390, total loss = 0.45, batch loss = 0.19 (228.1 examples/sec; 0.035 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:28:17.496346: step 197400, total loss = 0.53, batch loss = 0.28 (157.8 examples/sec; 0.051 sec/batch; 0h:01m:46s remains)
INFO - root - 2022-02-24 21:28:18.000073: step 197410, total loss = 0.45, batch loss = 0.20 (338.8 examples/sec; 0.024 sec/batch; 0h:00m:49s remains)
INFO - root - 2022-02-24 21:28:18.294803: step 197420, total loss = 0.54, batch loss = 0.28 (277.8 examples/sec; 0.029 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:28:18.621258: step 197430, total loss = 0.55, batch loss = 0.29 (226.4 examples/sec; 0.035 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:28:19.004002: step 197440, total loss = 0.57, batch loss = 0.31 (214.5 examples/sec; 0.037 sec/batch; 0h:01m:16s remains)
INFO - root - 2022-02-24 21:28:19.321241: step 197450, total loss = 0.47, batch loss = 0.22 (308.4 examples/sec; 0.026 sec/batch; 0h:00m:53s remains)
INFO - root - 2022-02-24 21:28:19.634945: step 197460, total loss = 0.57, batch loss = 0.31 (316.4 examples/sec; 0.025 sec/batch; 0h:00m:51s remains)
INFO - root - 2022-02-24 21:28:19.979602: step 197470, total loss = 0.56, batch loss = 0.31 (125.0 examples/sec; 0.064 sec/batch; 0h:02m:09s remains)
INFO - root - 2022-02-24 21:28:20.399431: step 197480, total loss = 0.57, batch loss = 0.31 (195.4 examples/sec; 0.041 sec/batch; 0h:01m:22s remains)
INFO - root - 2022-02-24 21:28:20.766994: step 197490, total loss = 0.47, batch loss = 0.22 (134.0 examples/sec; 0.060 sec/batch; 0h:01m:59s remains)
INFO - root - 2022-02-24 21:28:21.140682: step 197500, total loss = 0.46, batch loss = 0.20 (352.8 examples/sec; 0.023 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:28:21.784454: step 197510, total loss = 0.61, batch loss = 0.35 (350.2 examples/sec; 0.023 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:28:22.089366: step 197520, total loss = 0.49, batch loss = 0.23 (341.7 examples/sec; 0.023 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:28:22.425357: step 197530, total loss = 0.55, batch loss = 0.29 (127.9 examples/sec; 0.063 sec/batch; 0h:02m:03s remains)
INFO - root - 2022-02-24 21:28:22.840423: step 197540, total loss = 0.55, batch loss = 0.29 (239.9 examples/sec; 0.033 sec/batch; 0h:01m:05s remains)
INFO - root - 2022-02-24 21:28:23.152971: step 197550, total loss = 0.48, batch loss = 0.22 (330.1 examples/sec; 0.024 sec/batch; 0h:00m:47s remains)
INFO - root - 2022-02-24 21:28:23.410838: step 197560, total loss = 0.45, batch loss = 0.20 (338.5 examples/sec; 0.024 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:28:23.736764: step 197570, total loss = 0.56, batch loss = 0.31 (316.2 examples/sec; 0.025 sec/batch; 0h:00m:48s remains)
INFO - root - 2022-02-24 21:28:24.018650: step 197580, total loss = 0.53, batch loss = 0.28 (349.8 examples/sec; 0.023 sec/batch; 0h:00m:43s remains)
INFO - root - 2022-02-24 21:28:24.336669: step 197590, total loss = 0.44, batch loss = 0.19 (236.2 examples/sec; 0.034 sec/batch; 0h:01m:04s remains)
INFO - root - 2022-02-24 21:28:24.659608: step 197600, total loss = 0.45, batch loss = 0.20 (331.6 examples/sec; 0.024 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:28:25.126517: step 197610, total loss = 0.55, batch loss = 0.30 (137.3 examples/sec; 0.058 sec/batch; 0h:01m:50s remains)
INFO - root - 2022-02-24 21:28:25.454688: step 197620, total loss = 0.47, batch loss = 0.21 (212.1 examples/sec; 0.038 sec/batch; 0h:01m:10s remains)
INFO - root - 2022-02-24 21:28:25.736230: step 197630, total loss = 0.52, batch loss = 0.27 (330.8 examples/sec; 0.024 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:28:26.017881: step 197640, total loss = 0.50, batch loss = 0.24 (119.8 examples/sec; 0.067 sec/batch; 0h:02m:04s remains)
INFO - root - 2022-02-24 21:28:26.362322: step 197650, total loss = 0.55, batch loss = 0.29 (152.9 examples/sec; 0.052 sec/batch; 0h:01m:36s remains)
INFO - root - 2022-02-24 21:28:26.766472: step 197660, total loss = 0.48, batch loss = 0.22 (179.7 examples/sec; 0.045 sec/batch; 0h:01m:21s remains)
INFO - root - 2022-02-24 21:28:27.252955: step 197670, total loss = 0.56, batch loss = 0.30 (205.1 examples/sec; 0.039 sec/batch; 0h:01m:11s remains)
INFO - root - 2022-02-24 21:28:27.586704: step 197680, total loss = 0.47, batch loss = 0.22 (347.0 examples/sec; 0.023 sec/batch; 0h:00m:41s remains)
INFO - root - 2022-02-24 21:28:27.870493: step 197690, total loss = 0.60, batch loss = 0.34 (197.4 examples/sec; 0.041 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:28:28.216373: step 197700, total loss = 0.57, batch loss = 0.31 (227.2 examples/sec; 0.035 sec/batch; 0h:01m:03s remains)
INFO - root - 2022-02-24 21:28:28.713579: step 197710, total loss = 0.61, batch loss = 0.35 (339.8 examples/sec; 0.024 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:28:29.100288: step 197720, total loss = 0.48, batch loss = 0.23 (237.7 examples/sec; 0.034 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:28:29.479908: step 197730, total loss = 0.57, batch loss = 0.32 (336.7 examples/sec; 0.024 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:28:29.751488: step 197740, total loss = 0.57, batch loss = 0.32 (266.1 examples/sec; 0.030 sec/batch; 0h:00m:52s remains)
INFO - root - 2022-02-24 21:28:30.036074: step 197750, total loss = 0.48, batch loss = 0.22 (336.3 examples/sec; 0.024 sec/batch; 0h:00m:41s remains)
INFO - root - 2022-02-24 21:28:30.316970: step 197760, total loss = 0.59, batch loss = 0.34 (330.8 examples/sec; 0.024 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:28:30.658597: step 197770, total loss = 0.52, batch loss = 0.26 (153.5 examples/sec; 0.052 sec/batch; 0h:01m:30s remains)
INFO - root - 2022-02-24 21:28:31.058756: step 197780, total loss = 0.58, batch loss = 0.32 (246.7 examples/sec; 0.032 sec/batch; 0h:00m:55s remains)
INFO - root - 2022-02-24 21:28:31.468891: step 197790, total loss = 0.62, batch loss = 0.37 (108.1 examples/sec; 0.074 sec/batch; 0h:02m:06s remains)
INFO - root - 2022-02-24 21:28:31.754302: step 197800, total loss = 0.51, batch loss = 0.26 (373.1 examples/sec; 0.021 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:32.132644: step 197810, total loss = 0.53, batch loss = 0.28 (380.1 examples/sec; 0.021 sec/batch; 0h:00m:35s remains)
INFO - root - 2022-02-24 21:28:32.442216: step 197820, total loss = 0.47, batch loss = 0.22 (308.2 examples/sec; 0.026 sec/batch; 0h:00m:43s remains)
INFO - root - 2022-02-24 21:28:32.858606: step 197830, total loss = 0.59, batch loss = 0.33 (361.6 examples/sec; 0.022 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:33.264954: step 197840, total loss = 0.61, batch loss = 0.35 (185.5 examples/sec; 0.043 sec/batch; 0h:01m:11s remains)
INFO - root - 2022-02-24 21:28:33.560243: step 197850, total loss = 0.52, batch loss = 0.27 (321.0 examples/sec; 0.025 sec/batch; 0h:00m:41s remains)
INFO - root - 2022-02-24 21:28:33.852040: step 197860, total loss = 0.45, batch loss = 0.20 (280.0 examples/sec; 0.029 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:28:34.149032: step 197870, total loss = 0.58, batch loss = 0.32 (279.0 examples/sec; 0.029 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:28:34.445335: step 197880, total loss = 0.53, batch loss = 0.27 (336.8 examples/sec; 0.024 sec/batch; 0h:00m:38s remains)
INFO - root - 2022-02-24 21:28:34.827209: step 197890, total loss = 0.49, batch loss = 0.23 (134.7 examples/sec; 0.059 sec/batch; 0h:01m:35s remains)
INFO - root - 2022-02-24 21:28:35.198891: step 197900, total loss = 0.54, batch loss = 0.28 (348.6 examples/sec; 0.023 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:35.538938: step 197910, total loss = 0.59, batch loss = 0.33 (221.7 examples/sec; 0.036 sec/batch; 0h:00m:57s remains)
INFO - root - 2022-02-24 21:28:35.861091: step 197920, total loss = 0.55, batch loss = 0.29 (352.5 examples/sec; 0.023 sec/batch; 0h:00m:35s remains)
INFO - root - 2022-02-24 21:28:36.177852: step 197930, total loss = 0.60, batch loss = 0.35 (309.8 examples/sec; 0.026 sec/batch; 0h:00m:40s remains)
INFO - root - 2022-02-24 21:28:36.620272: step 197940, total loss = 0.53, batch loss = 0.28 (144.6 examples/sec; 0.055 sec/batch; 0h:01m:26s remains)
INFO - root - 2022-02-24 21:28:36.889730: step 197950, total loss = 0.46, batch loss = 0.21 (235.9 examples/sec; 0.034 sec/batch; 0h:00m:52s remains)
INFO - root - 2022-02-24 21:28:37.228389: step 197960, total loss = 0.58, batch loss = 0.32 (167.3 examples/sec; 0.048 sec/batch; 0h:01m:13s remains)
INFO - root - 2022-02-24 21:28:37.510106: step 197970, total loss = 0.54, batch loss = 0.29 (284.7 examples/sec; 0.028 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:28:37.812306: step 197980, total loss = 0.58, batch loss = 0.33 (302.6 examples/sec; 0.026 sec/batch; 0h:00m:40s remains)
INFO - root - 2022-02-24 21:28:38.135822: step 197990, total loss = 0.52, batch loss = 0.26 (201.3 examples/sec; 0.040 sec/batch; 0h:01m:00s remains)
INFO - root - 2022-02-24 21:28:38.567073: step 198000, total loss = 0.46, batch loss = 0.20 (306.8 examples/sec; 0.026 sec/batch; 0h:00m:39s remains)
INFO - root - 2022-02-24 21:28:39.003544: step 198010, total loss = 0.50, batch loss = 0.24 (141.1 examples/sec; 0.057 sec/batch; 0h:01m:24s remains)
INFO - root - 2022-02-24 21:28:39.349408: step 198020, total loss = 0.50, batch loss = 0.24 (326.6 examples/sec; 0.024 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:39.684605: step 198030, total loss = 0.58, batch loss = 0.32 (371.4 examples/sec; 0.022 sec/batch; 0h:00m:31s remains)
INFO - root - 2022-02-24 21:28:39.959958: step 198040, total loss = 0.61, batch loss = 0.36 (361.4 examples/sec; 0.022 sec/batch; 0h:00m:32s remains)
INFO - root - 2022-02-24 21:28:40.256679: step 198050, total loss = 0.52, batch loss = 0.27 (315.1 examples/sec; 0.025 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:40.627807: step 198060, total loss = 0.57, batch loss = 0.32 (271.5 examples/sec; 0.029 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:28:41.030489: step 198070, total loss = 0.56, batch loss = 0.30 (304.0 examples/sec; 0.026 sec/batch; 0h:00m:37s remains)
INFO - root - 2022-02-24 21:28:41.354666: step 198080, total loss = 0.58, batch loss = 0.33 (242.0 examples/sec; 0.033 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:28:41.730243: step 198090, total loss = 0.50, batch loss = 0.24 (257.2 examples/sec; 0.031 sec/batch; 0h:00m:43s remains)
INFO - root - 2022-02-24 21:28:41.999306: step 198100, total loss = 0.47, batch loss = 0.22 (335.9 examples/sec; 0.024 sec/batch; 0h:00m:33s remains)
INFO - root - 2022-02-24 21:28:42.384990: step 198110, total loss = 0.54, batch loss = 0.29 (310.7 examples/sec; 0.026 sec/batch; 0h:00m:35s remains)
INFO - root - 2022-02-24 21:28:42.763509: step 198120, total loss = 0.58, batch loss = 0.32 (224.3 examples/sec; 0.036 sec/batch; 0h:00m:49s remains)
INFO - root - 2022-02-24 21:28:43.117103: step 198130, total loss = 0.61, batch loss = 0.35 (294.0 examples/sec; 0.027 sec/batch; 0h:00m:37s remains)
INFO - root - 2022-02-24 21:28:43.400132: step 198140, total loss = 0.52, batch loss = 0.26 (232.8 examples/sec; 0.034 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:28:43.693440: step 198150, total loss = 0.50, batch loss = 0.24 (301.6 examples/sec; 0.027 sec/batch; 0h:00m:35s remains)
INFO - root - 2022-02-24 21:28:43.975505: step 198160, total loss = 0.51, batch loss = 0.25 (382.4 examples/sec; 0.021 sec/batch; 0h:00m:28s remains)
INFO - root - 2022-02-24 21:28:44.341535: step 198170, total loss = 0.52, batch loss = 0.26 (354.1 examples/sec; 0.023 sec/batch; 0h:00m:30s remains)
INFO - root - 2022-02-24 21:28:44.775943: step 198180, total loss = 0.54, batch loss = 0.29 (198.9 examples/sec; 0.040 sec/batch; 0h:00m:53s remains)
INFO - root - 2022-02-24 21:28:45.158564: step 198190, total loss = 0.52, batch loss = 0.27 (177.3 examples/sec; 0.045 sec/batch; 0h:00m:59s remains)
INFO - root - 2022-02-24 21:28:45.461167: step 198200, total loss = 0.51, batch loss = 0.25 (166.3 examples/sec; 0.048 sec/batch; 0h:01m:02s remains)
INFO - root - 2022-02-24 21:28:45.822943: step 198210, total loss = 0.55, batch loss = 0.29 (323.9 examples/sec; 0.025 sec/batch; 0h:00m:31s remains)
INFO - root - 2022-02-24 21:28:46.067081: step 198220, total loss = 0.49, batch loss = 0.24 (331.2 examples/sec; 0.024 sec/batch; 0h:00m:30s remains)
INFO - root - 2022-02-24 21:28:46.438340: step 198230, total loss = 0.61, batch loss = 0.35 (155.0 examples/sec; 0.052 sec/batch; 0h:01m:05s remains)
INFO - root - 2022-02-24 21:28:46.900837: step 198240, total loss = 0.66, batch loss = 0.41 (323.8 examples/sec; 0.025 sec/batch; 0h:00m:31s remains)
INFO - root - 2022-02-24 21:28:47.201807: step 198250, total loss = 0.54, batch loss = 0.29 (278.6 examples/sec; 0.029 sec/batch; 0h:00m:35s remains)
INFO - root - 2022-02-24 21:28:47.498220: step 198260, total loss = 0.53, batch loss = 0.28 (362.0 examples/sec; 0.022 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:28:47.817835: step 198270, total loss = 0.42, batch loss = 0.17 (207.0 examples/sec; 0.039 sec/batch; 0h:00m:47s remains)
INFO - root - 2022-02-24 21:28:48.157062: step 198280, total loss = 0.53, batch loss = 0.28 (306.6 examples/sec; 0.026 sec/batch; 0h:00m:31s remains)
INFO - root - 2022-02-24 21:28:48.525388: step 198290, total loss = 0.55, batch loss = 0.29 (157.7 examples/sec; 0.051 sec/batch; 0h:01m:01s remains)
INFO - root - 2022-02-24 21:28:48.941895: step 198300, total loss = 0.56, batch loss = 0.30 (176.1 examples/sec; 0.045 sec/batch; 0h:00m:54s remains)
INFO - root - 2022-02-24 21:28:49.558171: step 198310, total loss = 0.50, batch loss = 0.25 (106.8 examples/sec; 0.075 sec/batch; 0h:01m:29s remains)
INFO - root - 2022-02-24 21:28:50.066534: step 198320, total loss = 0.53, batch loss = 0.27 (230.5 examples/sec; 0.035 sec/batch; 0h:00m:40s remains)
INFO - root - 2022-02-24 21:28:50.463805: step 198330, total loss = 0.48, batch loss = 0.22 (361.7 examples/sec; 0.022 sec/batch; 0h:00m:25s remains)
INFO - root - 2022-02-24 21:28:50.863503: step 198340, total loss = 0.51, batch loss = 0.26 (367.5 examples/sec; 0.022 sec/batch; 0h:00m:25s remains)
INFO - root - 2022-02-24 21:28:51.452281: step 198350, total loss = 0.55, batch loss = 0.29 (78.7 examples/sec; 0.102 sec/batch; 0h:01m:56s remains)
INFO - root - 2022-02-24 21:28:51.807348: step 198360, total loss = 0.55, batch loss = 0.30 (316.9 examples/sec; 0.025 sec/batch; 0h:00m:28s remains)
INFO - root - 2022-02-24 21:28:52.705358: step 198370, total loss = 0.63, batch loss = 0.38 (132.7 examples/sec; 0.060 sec/batch; 0h:01m:08s remains)
INFO - root - 2022-02-24 21:28:53.066759: step 198380, total loss = 0.82, batch loss = 0.57 (268.2 examples/sec; 0.030 sec/batch; 0h:00m:33s remains)
INFO - root - 2022-02-24 21:28:53.439579: step 198390, total loss = 0.48, batch loss = 0.23 (329.1 examples/sec; 0.024 sec/batch; 0h:00m:26s remains)
INFO - root - 2022-02-24 21:28:53.736227: step 198400, total loss = 0.53, batch loss = 0.28 (334.2 examples/sec; 0.024 sec/batch; 0h:00m:26s remains)
INFO - root - 2022-02-24 21:28:54.094912: step 198410, total loss = 0.60, batch loss = 0.35 (330.8 examples/sec; 0.024 sec/batch; 0h:00m:26s remains)
INFO - root - 2022-02-24 21:28:54.389138: step 198420, total loss = 0.54, batch loss = 0.28 (226.3 examples/sec; 0.035 sec/batch; 0h:00m:38s remains)
INFO - root - 2022-02-24 21:28:54.801939: step 198430, total loss = 0.46, batch loss = 0.21 (254.1 examples/sec; 0.031 sec/batch; 0h:00m:33s remains)
INFO - root - 2022-02-24 21:28:55.211597: step 198440, total loss = 0.55, batch loss = 0.30 (157.5 examples/sec; 0.051 sec/batch; 0h:00m:53s remains)
INFO - root - 2022-02-24 21:28:55.577142: step 198450, total loss = 0.60, batch loss = 0.35 (312.4 examples/sec; 0.026 sec/batch; 0h:00m:26s remains)
INFO - root - 2022-02-24 21:28:55.871976: step 198460, total loss = 0.58, batch loss = 0.32 (224.4 examples/sec; 0.036 sec/batch; 0h:00m:37s remains)
INFO - root - 2022-02-24 21:28:56.135618: step 198470, total loss = 0.56, batch loss = 0.30 (318.7 examples/sec; 0.025 sec/batch; 0h:00m:25s remains)
INFO - root - 2022-02-24 21:28:56.498919: step 198480, total loss = 0.57, batch loss = 0.32 (263.8 examples/sec; 0.030 sec/batch; 0h:00m:30s remains)
INFO - root - 2022-02-24 21:28:56.947762: step 198490, total loss = 0.46, batch loss = 0.20 (168.7 examples/sec; 0.047 sec/batch; 0h:00m:47s remains)
INFO - root - 2022-02-24 21:28:57.361504: step 198500, total loss = 0.60, batch loss = 0.34 (378.5 examples/sec; 0.021 sec/batch; 0h:00m:21s remains)
INFO - root - 2022-02-24 21:28:57.751461: step 198510, total loss = 0.50, batch loss = 0.24 (352.7 examples/sec; 0.023 sec/batch; 0h:00m:22s remains)
INFO - root - 2022-02-24 21:28:58.078673: step 198520, total loss = 0.52, batch loss = 0.27 (232.4 examples/sec; 0.034 sec/batch; 0h:00m:33s remains)
INFO - root - 2022-02-24 21:28:58.372511: step 198530, total loss = 0.53, batch loss = 0.27 (213.1 examples/sec; 0.038 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:28:58.655740: step 198540, total loss = 0.57, batch loss = 0.31 (329.3 examples/sec; 0.024 sec/batch; 0h:00m:23s remains)
INFO - root - 2022-02-24 21:28:59.019495: step 198550, total loss = 0.55, batch loss = 0.30 (232.0 examples/sec; 0.034 sec/batch; 0h:00m:32s remains)
INFO - root - 2022-02-24 21:28:59.464125: step 198560, total loss = 0.51, batch loss = 0.25 (356.0 examples/sec; 0.022 sec/batch; 0h:00m:21s remains)
INFO - root - 2022-02-24 21:28:59.798568: step 198570, total loss = 0.54, batch loss = 0.29 (136.4 examples/sec; 0.059 sec/batch; 0h:00m:54s remains)
INFO - root - 2022-02-24 21:29:00.076978: step 198580, total loss = 0.57, batch loss = 0.32 (374.8 examples/sec; 0.021 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:00.404280: step 198590, total loss = 0.53, batch loss = 0.28 (213.6 examples/sec; 0.037 sec/batch; 0h:00m:34s remains)
INFO - root - 2022-02-24 21:29:00.698894: step 198600, total loss = 0.51, batch loss = 0.25 (309.7 examples/sec; 0.026 sec/batch; 0h:00m:23s remains)
INFO - root - 2022-02-24 21:29:01.215964: step 198610, total loss = 0.45, batch loss = 0.19 (240.5 examples/sec; 0.033 sec/batch; 0h:00m:29s remains)
INFO - root - 2022-02-24 21:29:01.683035: step 198620, total loss = 0.53, batch loss = 0.27 (155.8 examples/sec; 0.051 sec/batch; 0h:00m:45s remains)
INFO - root - 2022-02-24 21:29:02.067674: step 198630, total loss = 0.60, batch loss = 0.34 (179.2 examples/sec; 0.045 sec/batch; 0h:00m:38s remains)
INFO - root - 2022-02-24 21:29:02.399241: step 198640, total loss = 0.54, batch loss = 0.29 (160.7 examples/sec; 0.050 sec/batch; 0h:00m:42s remains)
INFO - root - 2022-02-24 21:29:02.645062: step 198650, total loss = 0.59, batch loss = 0.33 (381.8 examples/sec; 0.021 sec/batch; 0h:00m:17s remains)
INFO - root - 2022-02-24 21:29:02.974001: step 198660, total loss = 0.48, batch loss = 0.22 (240.9 examples/sec; 0.033 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:29:03.365506: step 198670, total loss = 0.55, batch loss = 0.30 (143.5 examples/sec; 0.056 sec/batch; 0h:00m:46s remains)
INFO - root - 2022-02-24 21:29:03.764789: step 198680, total loss = 0.54, batch loss = 0.28 (305.9 examples/sec; 0.026 sec/batch; 0h:00m:21s remains)
INFO - root - 2022-02-24 21:29:04.075188: step 198690, total loss = 0.52, batch loss = 0.26 (247.5 examples/sec; 0.032 sec/batch; 0h:00m:26s remains)
INFO - root - 2022-02-24 21:29:04.385184: step 198700, total loss = 0.58, batch loss = 0.32 (320.7 examples/sec; 0.025 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:04.716271: step 198710, total loss = 0.49, batch loss = 0.23 (328.7 examples/sec; 0.024 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:05.014780: step 198720, total loss = 0.54, batch loss = 0.29 (347.8 examples/sec; 0.023 sec/batch; 0h:00m:17s remains)
INFO - root - 2022-02-24 21:29:05.376398: step 198730, total loss = 0.56, batch loss = 0.30 (392.6 examples/sec; 0.020 sec/batch; 0h:00m:15s remains)
INFO - root - 2022-02-24 21:29:05.778686: step 198740, total loss = 0.50, batch loss = 0.25 (253.9 examples/sec; 0.032 sec/batch; 0h:00m:23s remains)
INFO - root - 2022-02-24 21:29:06.140582: step 198750, total loss = 0.46, batch loss = 0.21 (307.8 examples/sec; 0.026 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:06.462720: step 198760, total loss = 0.50, batch loss = 0.25 (302.0 examples/sec; 0.026 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:06.794409: step 198770, total loss = 0.55, batch loss = 0.30 (151.6 examples/sec; 0.053 sec/batch; 0h:00m:38s remains)
INFO - root - 2022-02-24 21:29:07.164065: step 198780, total loss = 0.52, batch loss = 0.26 (207.3 examples/sec; 0.039 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:29:07.558304: step 198790, total loss = 0.65, batch loss = 0.39 (295.6 examples/sec; 0.027 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:07.912226: step 198800, total loss = 0.47, batch loss = 0.21 (324.5 examples/sec; 0.025 sec/batch; 0h:00m:17s remains)
INFO - root - 2022-02-24 21:29:08.334239: step 198810, total loss = 0.48, batch loss = 0.23 (367.2 examples/sec; 0.022 sec/batch; 0h:00m:15s remains)
INFO - root - 2022-02-24 21:29:08.639419: step 198820, total loss = 0.49, batch loss = 0.23 (197.3 examples/sec; 0.041 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:29:09.028417: step 198830, total loss = 0.46, batch loss = 0.21 (191.7 examples/sec; 0.042 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:29:09.428265: step 198840, total loss = 0.68, batch loss = 0.42 (143.8 examples/sec; 0.056 sec/batch; 0h:00m:36s remains)
INFO - root - 2022-02-24 21:29:09.800632: step 198850, total loss = 0.48, batch loss = 0.23 (88.5 examples/sec; 0.090 sec/batch; 0h:00m:58s remains)
INFO - root - 2022-02-24 21:29:10.130842: step 198860, total loss = 0.51, batch loss = 0.25 (263.3 examples/sec; 0.030 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:10.398390: step 198870, total loss = 0.53, batch loss = 0.28 (346.5 examples/sec; 0.023 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:10.645618: step 198880, total loss = 0.49, batch loss = 0.24 (337.6 examples/sec; 0.024 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:10.913082: step 198890, total loss = 0.51, batch loss = 0.25 (343.1 examples/sec; 0.023 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:11.266453: step 198900, total loss = 0.53, batch loss = 0.27 (138.7 examples/sec; 0.058 sec/batch; 0h:00m:34s remains)
INFO - root - 2022-02-24 21:29:11.724410: step 198910, total loss = 0.57, batch loss = 0.32 (243.1 examples/sec; 0.033 sec/batch; 0h:00m:19s remains)
INFO - root - 2022-02-24 21:29:12.034717: step 198920, total loss = 0.49, batch loss = 0.24 (349.4 examples/sec; 0.023 sec/batch; 0h:00m:13s remains)
INFO - root - 2022-02-24 21:29:12.401769: step 198930, total loss = 0.53, batch loss = 0.27 (315.9 examples/sec; 0.025 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:12.700032: step 198940, total loss = 0.52, batch loss = 0.26 (299.2 examples/sec; 0.027 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:12.939232: step 198950, total loss = 0.53, batch loss = 0.27 (299.2 examples/sec; 0.027 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:13.251998: step 198960, total loss = 0.55, batch loss = 0.29 (185.0 examples/sec; 0.043 sec/batch; 0h:00m:23s remains)
INFO - root - 2022-02-24 21:29:13.637414: step 198970, total loss = 0.53, batch loss = 0.27 (152.5 examples/sec; 0.052 sec/batch; 0h:00m:27s remains)
INFO - root - 2022-02-24 21:29:13.994572: step 198980, total loss = 0.58, batch loss = 0.33 (172.7 examples/sec; 0.046 sec/batch; 0h:00m:24s remains)
INFO - root - 2022-02-24 21:29:14.251912: step 198990, total loss = 0.65, batch loss = 0.39 (341.9 examples/sec; 0.023 sec/batch; 0h:00m:11s remains)
INFO - root - 2022-02-24 21:29:14.501595: step 199000, total loss = 0.62, batch loss = 0.37 (358.1 examples/sec; 0.022 sec/batch; 0h:00m:11s remains)
INFO - root - 2022-02-24 21:29:14.838812: step 199010, total loss = 0.52, batch loss = 0.27 (309.1 examples/sec; 0.026 sec/batch; 0h:00m:12s remains)
INFO - root - 2022-02-24 21:29:15.129693: step 199020, total loss = 0.51, batch loss = 0.26 (305.6 examples/sec; 0.026 sec/batch; 0h:00m:12s remains)
INFO - root - 2022-02-24 21:29:15.518311: step 199030, total loss = 0.50, batch loss = 0.25 (273.6 examples/sec; 0.029 sec/batch; 0h:00m:13s remains)
INFO - root - 2022-02-24 21:29:15.944705: step 199040, total loss = 0.49, batch loss = 0.23 (359.5 examples/sec; 0.022 sec/batch; 0h:00m:10s remains)
INFO - root - 2022-02-24 21:29:16.273329: step 199050, total loss = 0.55, batch loss = 0.30 (339.9 examples/sec; 0.024 sec/batch; 0h:00m:10s remains)
INFO - root - 2022-02-24 21:29:16.522174: step 199060, total loss = 0.43, batch loss = 0.17 (317.6 examples/sec; 0.025 sec/batch; 0h:00m:11s remains)
INFO - root - 2022-02-24 21:29:16.786572: step 199070, total loss = 0.59, batch loss = 0.33 (272.4 examples/sec; 0.029 sec/batch; 0h:00m:12s remains)
INFO - root - 2022-02-24 21:29:17.103543: step 199080, total loss = 0.59, batch loss = 0.33 (338.7 examples/sec; 0.024 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:17.516120: step 199090, total loss = 0.58, batch loss = 0.32 (195.5 examples/sec; 0.041 sec/batch; 0h:00m:16s remains)
INFO - root - 2022-02-24 21:29:18.033986: step 199100, total loss = 0.51, batch loss = 0.25 (92.3 examples/sec; 0.087 sec/batch; 0h:00m:34s remains)
INFO - root - 2022-02-24 21:29:18.391401: step 199110, total loss = 0.46, batch loss = 0.20 (237.8 examples/sec; 0.034 sec/batch; 0h:00m:13s remains)
INFO - root - 2022-02-24 21:29:18.690747: step 199120, total loss = 0.57, batch loss = 0.32 (321.9 examples/sec; 0.025 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:18.950666: step 199130, total loss = 0.51, batch loss = 0.26 (340.2 examples/sec; 0.024 sec/batch; 0h:00m:08s remains)
INFO - root - 2022-02-24 21:29:19.202890: step 199140, total loss = 0.54, batch loss = 0.29 (345.6 examples/sec; 0.023 sec/batch; 0h:00m:08s remains)
INFO - root - 2022-02-24 21:29:19.555454: step 199150, total loss = 0.51, batch loss = 0.26 (173.1 examples/sec; 0.046 sec/batch; 0h:00m:16s remains)
INFO - root - 2022-02-24 21:29:20.005905: step 199160, total loss = 0.56, batch loss = 0.31 (300.1 examples/sec; 0.027 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:20.300738: step 199170, total loss = 0.53, batch loss = 0.28 (194.3 examples/sec; 0.041 sec/batch; 0h:00m:13s remains)
INFO - root - 2022-02-24 21:29:20.603475: step 199180, total loss = 0.50, batch loss = 0.25 (371.1 examples/sec; 0.022 sec/batch; 0h:00m:06s remains)
INFO - root - 2022-02-24 21:29:20.881293: step 199190, total loss = 0.57, batch loss = 0.31 (314.0 examples/sec; 0.025 sec/batch; 0h:00m:07s remains)
INFO - root - 2022-02-24 21:29:21.201351: step 199200, total loss = 0.52, batch loss = 0.26 (325.7 examples/sec; 0.025 sec/batch; 0h:00m:07s remains)
INFO - root - 2022-02-24 21:29:21.635789: step 199210, total loss = 0.44, batch loss = 0.18 (131.6 examples/sec; 0.061 sec/batch; 0h:00m:17s remains)
INFO - root - 2022-02-24 21:29:21.953801: step 199220, total loss = 0.53, batch loss = 0.27 (231.5 examples/sec; 0.035 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:22.266746: step 199230, total loss = 0.56, batch loss = 0.31 (305.1 examples/sec; 0.026 sec/batch; 0h:00m:07s remains)
INFO - root - 2022-02-24 21:29:22.583459: step 199240, total loss = 0.52, batch loss = 0.26 (143.2 examples/sec; 0.056 sec/batch; 0h:00m:14s remains)
INFO - root - 2022-02-24 21:29:22.855676: step 199250, total loss = 0.72, batch loss = 0.47 (320.9 examples/sec; 0.025 sec/batch; 0h:00m:06s remains)
INFO - root - 2022-02-24 21:29:23.115305: step 199260, total loss = 0.54, batch loss = 0.28 (307.0 examples/sec; 0.026 sec/batch; 0h:00m:06s remains)
INFO - root - 2022-02-24 21:29:23.424662: step 199270, total loss = 0.61, batch loss = 0.35 (186.2 examples/sec; 0.043 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:23.779571: step 199280, total loss = 0.52, batch loss = 0.27 (182.8 examples/sec; 0.044 sec/batch; 0h:00m:09s remains)
INFO - root - 2022-02-24 21:29:24.111529: step 199290, total loss = 0.57, batch loss = 0.31 (339.6 examples/sec; 0.024 sec/batch; 0h:00m:04s remains)
INFO - root - 2022-02-24 21:29:24.468731: step 199300, total loss = 0.54, batch loss = 0.29 (368.4 examples/sec; 0.022 sec/batch; 0h:00m:04s remains)
INFO - root - 2022-02-24 21:29:24.853178: step 199310, total loss = 0.53, batch loss = 0.28 (134.4 examples/sec; 0.060 sec/batch; 0h:00m:11s remains)
INFO - root - 2022-02-24 21:29:25.166004: step 199320, total loss = 0.63, batch loss = 0.38 (272.1 examples/sec; 0.029 sec/batch; 0h:00m:05s remains)
INFO - root - 2022-02-24 21:29:25.529603: step 199330, total loss = 0.48, batch loss = 0.23 (325.3 examples/sec; 0.025 sec/batch; 0h:00m:04s remains)
INFO - root - 2022-02-24 21:29:25.937077: step 199340, total loss = 0.48, batch loss = 0.22 (153.6 examples/sec; 0.052 sec/batch; 0h:00m:08s remains)
INFO - root - 2022-02-24 21:29:26.277831: step 199350, total loss = 0.52, batch loss = 0.27 (382.0 examples/sec; 0.021 sec/batch; 0h:00m:03s remains)
INFO - root - 2022-02-24 21:29:26.583377: step 199360, total loss = 0.60, batch loss = 0.34 (350.9 examples/sec; 0.023 sec/batch; 0h:00m:03s remains)
INFO - root - 2022-02-24 21:29:26.867812: step 199370, total loss = 0.57, batch loss = 0.32 (338.6 examples/sec; 0.024 sec/batch; 0h:00m:03s remains)
INFO - root - 2022-02-24 21:29:27.130393: step 199380, total loss = 0.55, batch loss = 0.30 (349.2 examples/sec; 0.023 sec/batch; 0h:00m:02s remains)
INFO - root - 2022-02-24 21:29:27.794389: step 199390, total loss = 0.53, batch loss = 0.27 (164.6 examples/sec; 0.049 sec/batch; 0h:00m:05s remains)
INFO - root - 2022-02-24 21:29:28.258955: step 199400, total loss = 0.50, batch loss = 0.25 (230.8 examples/sec; 0.035 sec/batch; 0h:00m:03s remains)
INFO - root - 2022-02-24 21:29:28.652455: step 199410, total loss = 0.50, batch loss = 0.24 (163.1 examples/sec; 0.049 sec/batch; 0h:00m:04s remains)
INFO - root - 2022-02-24 21:29:28.977646: step 199420, total loss = 0.55, batch loss = 0.29 (259.7 examples/sec; 0.031 sec/batch; 0h:00m:02s remains)
INFO - root - 2022-02-24 21:29:29.303016: step 199430, total loss = 0.56, batch loss = 0.31 (253.0 examples/sec; 0.032 sec/batch; 0h:00m:02s remains)
INFO - root - 2022-02-24 21:29:29.728565: step 199440, total loss = 0.48, batch loss = 0.22 (348.6 examples/sec; 0.023 sec/batch; 0h:00m:01s remains)
INFO - root - 2022-02-24 21:29:30.255707: step 199450, total loss = 0.53, batch loss = 0.28 (246.2 examples/sec; 0.032 sec/batch; 0h:00m:01s remains)
INFO - root - 2022-02-24 21:29:30.647063: step 199460, total loss = 0.51, batch loss = 0.26 (224.1 examples/sec; 0.036 sec/batch; 0h:00m:01s remains)
INFO - root - 2022-02-24 21:29:31.224945: step 199470, total loss = 0.48, batch loss = 0.22 (61.2 examples/sec; 0.131 sec/batch; 0h:00m:03s remains)
INFO - root - 2022-02-24 21:29:31.678768: step 199480, total loss = 0.54, batch loss = 0.28 (123.4 examples/sec; 0.065 sec/batch; 0h:00m:01s remains)
INFO - root - 2022-02-24 21:29:32.069275: step 199490, total loss = 0.58, batch loss = 0.33 (167.1 examples/sec; 0.048 sec/batch; 0h:00m:00s remains)
INFO:tensorflow:./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-199499 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - ./Logs4/SA-Siam/track_model_checkpoints/SA-Siam-Semantic/model.ckpt-199499 is not in all_model_checkpoint_paths. Manually adding it.
INFO - SA-Siam-Semantic - Completed after 2:16:39
